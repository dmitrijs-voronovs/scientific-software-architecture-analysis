id,quality_attribute,keyword,matched_word,match_idx,sentence,source,author,repo,version,wiki,url
https://github.com/scverse/scanpy/issues/1468:452,energy efficiency,load,load,452,"scanpy cannot be imported in my windows system; Hi,. I couldn't import scanpy due to an error: DLL load failed. I have checked pre-existing issues, but all of them seem to be an h5py issue. My error report seems different from them. ```. >>> import scanpy as sc. D:\Anaconda\lib\site-packages\dask\config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details. data = yaml.load(f.read()) or {}. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\__init__.py"", line 36, in <module>. from . import tools as tl. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\tools\__init__.py"", line 17, in <module>. from ._sim import sim. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\tools\_sim.py"", line 23, in <module>. from .. import _utils, readwrite, logging as logg. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\readwrite.py"", line 10, in <module>. import tables. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\tables\__init__.py"", line 99, in <module>. from .utilsextension import (. ImportError: DLL load failed: The specified procedure could not be found. >>> print(sys.version). 3.7.3 (default, Mar 27 2019, 17:13:21) [MSC v.1915 64 bit (AMD64)]. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1468
https://github.com/scverse/scanpy/issues/1468:487,energy efficiency,load,load,487,"scanpy cannot be imported in my windows system; Hi,. I couldn't import scanpy due to an error: DLL load failed. I have checked pre-existing issues, but all of them seem to be an h5py issue. My error report seems different from them. ```. >>> import scanpy as sc. D:\Anaconda\lib\site-packages\dask\config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details. data = yaml.load(f.read()) or {}. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\__init__.py"", line 36, in <module>. from . import tools as tl. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\tools\__init__.py"", line 17, in <module>. from ._sim import sim. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\tools\_sim.py"", line 23, in <module>. from .. import _utils, readwrite, logging as logg. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\readwrite.py"", line 10, in <module>. import tables. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\tables\__init__.py"", line 99, in <module>. from .utilsextension import (. ImportError: DLL load failed: The specified procedure could not be found. >>> print(sys.version). 3.7.3 (default, Mar 27 2019, 17:13:21) [MSC v.1915 64 bit (AMD64)]. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1468
https://github.com/scverse/scanpy/issues/1468:1310,energy efficiency,load,load,1310,"scanpy cannot be imported in my windows system; Hi,. I couldn't import scanpy due to an error: DLL load failed. I have checked pre-existing issues, but all of them seem to be an h5py issue. My error report seems different from them. ```. >>> import scanpy as sc. D:\Anaconda\lib\site-packages\dask\config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details. data = yaml.load(f.read()) or {}. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\__init__.py"", line 36, in <module>. from . import tools as tl. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\tools\__init__.py"", line 17, in <module>. from ._sim import sim. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\tools\_sim.py"", line 23, in <module>. from .. import _utils, readwrite, logging as logg. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\readwrite.py"", line 10, in <module>. import tables. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\tables\__init__.py"", line 99, in <module>. from .utilsextension import (. ImportError: DLL load failed: The specified procedure could not be found. >>> print(sys.version). 3.7.3 (default, Mar 27 2019, 17:13:21) [MSC v.1915 64 bit (AMD64)]. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1468
https://github.com/scverse/scanpy/issues/1468:1381,integrability,version,version,1381,"scanpy cannot be imported in my windows system; Hi,. I couldn't import scanpy due to an error: DLL load failed. I have checked pre-existing issues, but all of them seem to be an h5py issue. My error report seems different from them. ```. >>> import scanpy as sc. D:\Anaconda\lib\site-packages\dask\config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details. data = yaml.load(f.read()) or {}. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\__init__.py"", line 36, in <module>. from . import tools as tl. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\tools\__init__.py"", line 17, in <module>. from ._sim import sim. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\tools\_sim.py"", line 23, in <module>. from .. import _utils, readwrite, logging as logg. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\readwrite.py"", line 10, in <module>. import tables. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\tables\__init__.py"", line 99, in <module>. from .utilsextension import (. ImportError: DLL load failed: The specified procedure could not be found. >>> print(sys.version). 3.7.3 (default, Mar 27 2019, 17:13:21) [MSC v.1915 64 bit (AMD64)]. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1468
https://github.com/scverse/scanpy/issues/1468:1327,interoperability,specif,specified,1327,"scanpy cannot be imported in my windows system; Hi,. I couldn't import scanpy due to an error: DLL load failed. I have checked pre-existing issues, but all of them seem to be an h5py issue. My error report seems different from them. ```. >>> import scanpy as sc. D:\Anaconda\lib\site-packages\dask\config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details. data = yaml.load(f.read()) or {}. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\__init__.py"", line 36, in <module>. from . import tools as tl. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\tools\__init__.py"", line 17, in <module>. from ._sim import sim. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\tools\_sim.py"", line 23, in <module>. from .. import _utils, readwrite, logging as logg. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\readwrite.py"", line 10, in <module>. import tables. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\tables\__init__.py"", line 99, in <module>. from .utilsextension import (. ImportError: DLL load failed: The specified procedure could not be found. >>> print(sys.version). 3.7.3 (default, Mar 27 2019, 17:13:21) [MSC v.1915 64 bit (AMD64)]. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1468
https://github.com/scverse/scanpy/issues/1468:284,modifiability,pac,packages,284,"scanpy cannot be imported in my windows system; Hi,. I couldn't import scanpy due to an error: DLL load failed. I have checked pre-existing issues, but all of them seem to be an h5py issue. My error report seems different from them. ```. >>> import scanpy as sc. D:\Anaconda\lib\site-packages\dask\config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details. data = yaml.load(f.read()) or {}. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\__init__.py"", line 36, in <module>. from . import tools as tl. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\tools\__init__.py"", line 17, in <module>. from ._sim import sim. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\tools\_sim.py"", line 23, in <module>. from .. import _utils, readwrite, logging as logg. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\readwrite.py"", line 10, in <module>. import tables. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\tables\__init__.py"", line 99, in <module>. from .utilsextension import (. ImportError: DLL load failed: The specified procedure could not be found. >>> print(sys.version). 3.7.3 (default, Mar 27 2019, 17:13:21) [MSC v.1915 64 bit (AMD64)]. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1468
https://github.com/scverse/scanpy/issues/1468:573,modifiability,modul,module,573,"scanpy cannot be imported in my windows system; Hi,. I couldn't import scanpy due to an error: DLL load failed. I have checked pre-existing issues, but all of them seem to be an h5py issue. My error report seems different from them. ```. >>> import scanpy as sc. D:\Anaconda\lib\site-packages\dask\config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details. data = yaml.load(f.read()) or {}. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\__init__.py"", line 36, in <module>. from . import tools as tl. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\tools\__init__.py"", line 17, in <module>. from ._sim import sim. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\tools\_sim.py"", line 23, in <module>. from .. import _utils, readwrite, logging as logg. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\readwrite.py"", line 10, in <module>. import tables. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\tables\__init__.py"", line 99, in <module>. from .utilsextension import (. ImportError: DLL load failed: The specified procedure could not be found. >>> print(sys.version). 3.7.3 (default, Mar 27 2019, 17:13:21) [MSC v.1915 64 bit (AMD64)]. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1468
https://github.com/scverse/scanpy/issues/1468:641,modifiability,pac,packages,641,"scanpy cannot be imported in my windows system; Hi,. I couldn't import scanpy due to an error: DLL load failed. I have checked pre-existing issues, but all of them seem to be an h5py issue. My error report seems different from them. ```. >>> import scanpy as sc. D:\Anaconda\lib\site-packages\dask\config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details. data = yaml.load(f.read()) or {}. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\__init__.py"", line 36, in <module>. from . import tools as tl. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\tools\__init__.py"", line 17, in <module>. from ._sim import sim. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\tools\_sim.py"", line 23, in <module>. from .. import _utils, readwrite, logging as logg. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\readwrite.py"", line 10, in <module>. import tables. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\tables\__init__.py"", line 99, in <module>. from .utilsextension import (. ImportError: DLL load failed: The specified procedure could not be found. >>> print(sys.version). 3.7.3 (default, Mar 27 2019, 17:13:21) [MSC v.1915 64 bit (AMD64)]. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1468
https://github.com/scverse/scanpy/issues/1468:684,modifiability,modul,module,684,"scanpy cannot be imported in my windows system; Hi,. I couldn't import scanpy due to an error: DLL load failed. I have checked pre-existing issues, but all of them seem to be an h5py issue. My error report seems different from them. ```. >>> import scanpy as sc. D:\Anaconda\lib\site-packages\dask\config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details. data = yaml.load(f.read()) or {}. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\__init__.py"", line 36, in <module>. from . import tools as tl. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\tools\__init__.py"", line 17, in <module>. from ._sim import sim. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\tools\_sim.py"", line 23, in <module>. from .. import _utils, readwrite, logging as logg. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\readwrite.py"", line 10, in <module>. import tables. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\tables\__init__.py"", line 99, in <module>. from .utilsextension import (. ImportError: DLL load failed: The specified procedure could not be found. >>> print(sys.version). 3.7.3 (default, Mar 27 2019, 17:13:21) [MSC v.1915 64 bit (AMD64)]. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1468
https://github.com/scverse/scanpy/issues/1468:779,modifiability,pac,packages,779,"scanpy cannot be imported in my windows system; Hi,. I couldn't import scanpy due to an error: DLL load failed. I have checked pre-existing issues, but all of them seem to be an h5py issue. My error report seems different from them. ```. >>> import scanpy as sc. D:\Anaconda\lib\site-packages\dask\config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details. data = yaml.load(f.read()) or {}. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\__init__.py"", line 36, in <module>. from . import tools as tl. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\tools\__init__.py"", line 17, in <module>. from ._sim import sim. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\tools\_sim.py"", line 23, in <module>. from .. import _utils, readwrite, logging as logg. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\readwrite.py"", line 10, in <module>. import tables. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\tables\__init__.py"", line 99, in <module>. from .utilsextension import (. ImportError: DLL load failed: The specified procedure could not be found. >>> print(sys.version). 3.7.3 (default, Mar 27 2019, 17:13:21) [MSC v.1915 64 bit (AMD64)]. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1468
https://github.com/scverse/scanpy/issues/1468:828,modifiability,modul,module,828,"scanpy cannot be imported in my windows system; Hi,. I couldn't import scanpy due to an error: DLL load failed. I have checked pre-existing issues, but all of them seem to be an h5py issue. My error report seems different from them. ```. >>> import scanpy as sc. D:\Anaconda\lib\site-packages\dask\config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details. data = yaml.load(f.read()) or {}. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\__init__.py"", line 36, in <module>. from . import tools as tl. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\tools\__init__.py"", line 17, in <module>. from ._sim import sim. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\tools\_sim.py"", line 23, in <module>. from .. import _utils, readwrite, logging as logg. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\readwrite.py"", line 10, in <module>. import tables. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\tables\__init__.py"", line 99, in <module>. from .utilsextension import (. ImportError: DLL load failed: The specified procedure could not be found. >>> print(sys.version). 3.7.3 (default, Mar 27 2019, 17:13:21) [MSC v.1915 64 bit (AMD64)]. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1468
https://github.com/scverse/scanpy/issues/1468:919,modifiability,pac,packages,919,"scanpy cannot be imported in my windows system; Hi,. I couldn't import scanpy due to an error: DLL load failed. I have checked pre-existing issues, but all of them seem to be an h5py issue. My error report seems different from them. ```. >>> import scanpy as sc. D:\Anaconda\lib\site-packages\dask\config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details. data = yaml.load(f.read()) or {}. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\__init__.py"", line 36, in <module>. from . import tools as tl. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\tools\__init__.py"", line 17, in <module>. from ._sim import sim. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\tools\_sim.py"", line 23, in <module>. from .. import _utils, readwrite, logging as logg. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\readwrite.py"", line 10, in <module>. import tables. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\tables\__init__.py"", line 99, in <module>. from .utilsextension import (. ImportError: DLL load failed: The specified procedure could not be found. >>> print(sys.version). 3.7.3 (default, Mar 27 2019, 17:13:21) [MSC v.1915 64 bit (AMD64)]. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1468
https://github.com/scverse/scanpy/issues/1468:964,modifiability,modul,module,964,"scanpy cannot be imported in my windows system; Hi,. I couldn't import scanpy due to an error: DLL load failed. I have checked pre-existing issues, but all of them seem to be an h5py issue. My error report seems different from them. ```. >>> import scanpy as sc. D:\Anaconda\lib\site-packages\dask\config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details. data = yaml.load(f.read()) or {}. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\__init__.py"", line 36, in <module>. from . import tools as tl. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\tools\__init__.py"", line 17, in <module>. from ._sim import sim. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\tools\_sim.py"", line 23, in <module>. from .. import _utils, readwrite, logging as logg. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\readwrite.py"", line 10, in <module>. import tables. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\tables\__init__.py"", line 99, in <module>. from .utilsextension import (. ImportError: DLL load failed: The specified procedure could not be found. >>> print(sys.version). 3.7.3 (default, Mar 27 2019, 17:13:21) [MSC v.1915 64 bit (AMD64)]. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1468
https://github.com/scverse/scanpy/issues/1468:1083,modifiability,pac,packages,1083,"scanpy cannot be imported in my windows system; Hi,. I couldn't import scanpy due to an error: DLL load failed. I have checked pre-existing issues, but all of them seem to be an h5py issue. My error report seems different from them. ```. >>> import scanpy as sc. D:\Anaconda\lib\site-packages\dask\config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details. data = yaml.load(f.read()) or {}. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\__init__.py"", line 36, in <module>. from . import tools as tl. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\tools\__init__.py"", line 17, in <module>. from ._sim import sim. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\tools\_sim.py"", line 23, in <module>. from .. import _utils, readwrite, logging as logg. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\readwrite.py"", line 10, in <module>. import tables. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\tables\__init__.py"", line 99, in <module>. from .utilsextension import (. ImportError: DLL load failed: The specified procedure could not be found. >>> print(sys.version). 3.7.3 (default, Mar 27 2019, 17:13:21) [MSC v.1915 64 bit (AMD64)]. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1468
https://github.com/scverse/scanpy/issues/1468:1127,modifiability,modul,module,1127,"scanpy cannot be imported in my windows system; Hi,. I couldn't import scanpy due to an error: DLL load failed. I have checked pre-existing issues, but all of them seem to be an h5py issue. My error report seems different from them. ```. >>> import scanpy as sc. D:\Anaconda\lib\site-packages\dask\config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details. data = yaml.load(f.read()) or {}. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\__init__.py"", line 36, in <module>. from . import tools as tl. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\tools\__init__.py"", line 17, in <module>. from ._sim import sim. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\tools\_sim.py"", line 23, in <module>. from .. import _utils, readwrite, logging as logg. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\readwrite.py"", line 10, in <module>. import tables. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\tables\__init__.py"", line 99, in <module>. from .utilsextension import (. ImportError: DLL load failed: The specified procedure could not be found. >>> print(sys.version). 3.7.3 (default, Mar 27 2019, 17:13:21) [MSC v.1915 64 bit (AMD64)]. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1468
https://github.com/scverse/scanpy/issues/1468:1210,modifiability,pac,packages,1210,"scanpy cannot be imported in my windows system; Hi,. I couldn't import scanpy due to an error: DLL load failed. I have checked pre-existing issues, but all of them seem to be an h5py issue. My error report seems different from them. ```. >>> import scanpy as sc. D:\Anaconda\lib\site-packages\dask\config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details. data = yaml.load(f.read()) or {}. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\__init__.py"", line 36, in <module>. from . import tools as tl. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\tools\__init__.py"", line 17, in <module>. from ._sim import sim. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\tools\_sim.py"", line 23, in <module>. from .. import _utils, readwrite, logging as logg. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\readwrite.py"", line 10, in <module>. import tables. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\tables\__init__.py"", line 99, in <module>. from .utilsextension import (. ImportError: DLL load failed: The specified procedure could not be found. >>> print(sys.version). 3.7.3 (default, Mar 27 2019, 17:13:21) [MSC v.1915 64 bit (AMD64)]. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1468
https://github.com/scverse/scanpy/issues/1468:1253,modifiability,modul,module,1253,"scanpy cannot be imported in my windows system; Hi,. I couldn't import scanpy due to an error: DLL load failed. I have checked pre-existing issues, but all of them seem to be an h5py issue. My error report seems different from them. ```. >>> import scanpy as sc. D:\Anaconda\lib\site-packages\dask\config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details. data = yaml.load(f.read()) or {}. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\__init__.py"", line 36, in <module>. from . import tools as tl. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\tools\__init__.py"", line 17, in <module>. from ._sim import sim. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\tools\_sim.py"", line 23, in <module>. from .. import _utils, readwrite, logging as logg. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\readwrite.py"", line 10, in <module>. import tables. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\tables\__init__.py"", line 99, in <module>. from .utilsextension import (. ImportError: DLL load failed: The specified procedure could not be found. >>> print(sys.version). 3.7.3 (default, Mar 27 2019, 17:13:21) [MSC v.1915 64 bit (AMD64)]. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1468
https://github.com/scverse/scanpy/issues/1468:1381,modifiability,version,version,1381,"scanpy cannot be imported in my windows system; Hi,. I couldn't import scanpy due to an error: DLL load failed. I have checked pre-existing issues, but all of them seem to be an h5py issue. My error report seems different from them. ```. >>> import scanpy as sc. D:\Anaconda\lib\site-packages\dask\config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details. data = yaml.load(f.read()) or {}. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\__init__.py"", line 36, in <module>. from . import tools as tl. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\tools\__init__.py"", line 17, in <module>. from ._sim import sim. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\tools\_sim.py"", line 23, in <module>. from .. import _utils, readwrite, logging as logg. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\readwrite.py"", line 10, in <module>. import tables. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\tables\__init__.py"", line 99, in <module>. from .utilsextension import (. ImportError: DLL load failed: The specified procedure could not be found. >>> print(sys.version). 3.7.3 (default, Mar 27 2019, 17:13:21) [MSC v.1915 64 bit (AMD64)]. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1468
https://github.com/scverse/scanpy/issues/1468:88,performance,error,error,88,"scanpy cannot be imported in my windows system; Hi,. I couldn't import scanpy due to an error: DLL load failed. I have checked pre-existing issues, but all of them seem to be an h5py issue. My error report seems different from them. ```. >>> import scanpy as sc. D:\Anaconda\lib\site-packages\dask\config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details. data = yaml.load(f.read()) or {}. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\__init__.py"", line 36, in <module>. from . import tools as tl. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\tools\__init__.py"", line 17, in <module>. from ._sim import sim. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\tools\_sim.py"", line 23, in <module>. from .. import _utils, readwrite, logging as logg. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\readwrite.py"", line 10, in <module>. import tables. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\tables\__init__.py"", line 99, in <module>. from .utilsextension import (. ImportError: DLL load failed: The specified procedure could not be found. >>> print(sys.version). 3.7.3 (default, Mar 27 2019, 17:13:21) [MSC v.1915 64 bit (AMD64)]. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1468
https://github.com/scverse/scanpy/issues/1468:99,performance,load,load,99,"scanpy cannot be imported in my windows system; Hi,. I couldn't import scanpy due to an error: DLL load failed. I have checked pre-existing issues, but all of them seem to be an h5py issue. My error report seems different from them. ```. >>> import scanpy as sc. D:\Anaconda\lib\site-packages\dask\config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details. data = yaml.load(f.read()) or {}. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\__init__.py"", line 36, in <module>. from . import tools as tl. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\tools\__init__.py"", line 17, in <module>. from ._sim import sim. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\tools\_sim.py"", line 23, in <module>. from .. import _utils, readwrite, logging as logg. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\readwrite.py"", line 10, in <module>. import tables. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\tables\__init__.py"", line 99, in <module>. from .utilsextension import (. ImportError: DLL load failed: The specified procedure could not be found. >>> print(sys.version). 3.7.3 (default, Mar 27 2019, 17:13:21) [MSC v.1915 64 bit (AMD64)]. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1468
https://github.com/scverse/scanpy/issues/1468:193,performance,error,error,193,"scanpy cannot be imported in my windows system; Hi,. I couldn't import scanpy due to an error: DLL load failed. I have checked pre-existing issues, but all of them seem to be an h5py issue. My error report seems different from them. ```. >>> import scanpy as sc. D:\Anaconda\lib\site-packages\dask\config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details. data = yaml.load(f.read()) or {}. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\__init__.py"", line 36, in <module>. from . import tools as tl. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\tools\__init__.py"", line 17, in <module>. from ._sim import sim. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\tools\_sim.py"", line 23, in <module>. from .. import _utils, readwrite, logging as logg. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\readwrite.py"", line 10, in <module>. import tables. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\tables\__init__.py"", line 99, in <module>. from .utilsextension import (. ImportError: DLL load failed: The specified procedure could not be found. >>> print(sys.version). 3.7.3 (default, Mar 27 2019, 17:13:21) [MSC v.1915 64 bit (AMD64)]. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1468
https://github.com/scverse/scanpy/issues/1468:343,performance,load,load,343,"scanpy cannot be imported in my windows system; Hi,. I couldn't import scanpy due to an error: DLL load failed. I have checked pre-existing issues, but all of them seem to be an h5py issue. My error report seems different from them. ```. >>> import scanpy as sc. D:\Anaconda\lib\site-packages\dask\config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details. data = yaml.load(f.read()) or {}. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\__init__.py"", line 36, in <module>. from . import tools as tl. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\tools\__init__.py"", line 17, in <module>. from ._sim import sim. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\tools\_sim.py"", line 23, in <module>. from .. import _utils, readwrite, logging as logg. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\readwrite.py"", line 10, in <module>. import tables. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\tables\__init__.py"", line 99, in <module>. from .utilsextension import (. ImportError: DLL load failed: The specified procedure could not be found. >>> print(sys.version). 3.7.3 (default, Mar 27 2019, 17:13:21) [MSC v.1915 64 bit (AMD64)]. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1468
https://github.com/scverse/scanpy/issues/1468:358,performance,Load,Loader,358,"scanpy cannot be imported in my windows system; Hi,. I couldn't import scanpy due to an error: DLL load failed. I have checked pre-existing issues, but all of them seem to be an h5py issue. My error report seems different from them. ```. >>> import scanpy as sc. D:\Anaconda\lib\site-packages\dask\config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details. data = yaml.load(f.read()) or {}. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\__init__.py"", line 36, in <module>. from . import tools as tl. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\tools\__init__.py"", line 17, in <module>. from ._sim import sim. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\tools\_sim.py"", line 23, in <module>. from .. import _utils, readwrite, logging as logg. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\readwrite.py"", line 10, in <module>. import tables. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\tables\__init__.py"", line 99, in <module>. from .utilsextension import (. ImportError: DLL load failed: The specified procedure could not be found. >>> print(sys.version). 3.7.3 (default, Mar 27 2019, 17:13:21) [MSC v.1915 64 bit (AMD64)]. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1468
https://github.com/scverse/scanpy/issues/1468:399,performance,Load,Loader,399,"scanpy cannot be imported in my windows system; Hi,. I couldn't import scanpy due to an error: DLL load failed. I have checked pre-existing issues, but all of them seem to be an h5py issue. My error report seems different from them. ```. >>> import scanpy as sc. D:\Anaconda\lib\site-packages\dask\config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details. data = yaml.load(f.read()) or {}. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\__init__.py"", line 36, in <module>. from . import tools as tl. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\tools\__init__.py"", line 17, in <module>. from ._sim import sim. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\tools\_sim.py"", line 23, in <module>. from .. import _utils, readwrite, logging as logg. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\readwrite.py"", line 10, in <module>. import tables. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\tables\__init__.py"", line 99, in <module>. from .utilsextension import (. ImportError: DLL load failed: The specified procedure could not be found. >>> print(sys.version). 3.7.3 (default, Mar 27 2019, 17:13:21) [MSC v.1915 64 bit (AMD64)]. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1468
https://github.com/scverse/scanpy/issues/1468:452,performance,load,load,452,"scanpy cannot be imported in my windows system; Hi,. I couldn't import scanpy due to an error: DLL load failed. I have checked pre-existing issues, but all of them seem to be an h5py issue. My error report seems different from them. ```. >>> import scanpy as sc. D:\Anaconda\lib\site-packages\dask\config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details. data = yaml.load(f.read()) or {}. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\__init__.py"", line 36, in <module>. from . import tools as tl. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\tools\__init__.py"", line 17, in <module>. from ._sim import sim. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\tools\_sim.py"", line 23, in <module>. from .. import _utils, readwrite, logging as logg. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\readwrite.py"", line 10, in <module>. import tables. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\tables\__init__.py"", line 99, in <module>. from .utilsextension import (. ImportError: DLL load failed: The specified procedure could not be found. >>> print(sys.version). 3.7.3 (default, Mar 27 2019, 17:13:21) [MSC v.1915 64 bit (AMD64)]. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1468
https://github.com/scverse/scanpy/issues/1468:487,performance,load,load,487,"scanpy cannot be imported in my windows system; Hi,. I couldn't import scanpy due to an error: DLL load failed. I have checked pre-existing issues, but all of them seem to be an h5py issue. My error report seems different from them. ```. >>> import scanpy as sc. D:\Anaconda\lib\site-packages\dask\config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details. data = yaml.load(f.read()) or {}. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\__init__.py"", line 36, in <module>. from . import tools as tl. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\tools\__init__.py"", line 17, in <module>. from ._sim import sim. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\tools\_sim.py"", line 23, in <module>. from .. import _utils, readwrite, logging as logg. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\readwrite.py"", line 10, in <module>. import tables. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\tables\__init__.py"", line 99, in <module>. from .utilsextension import (. ImportError: DLL load failed: The specified procedure could not be found. >>> print(sys.version). 3.7.3 (default, Mar 27 2019, 17:13:21) [MSC v.1915 64 bit (AMD64)]. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1468
https://github.com/scverse/scanpy/issues/1468:1310,performance,load,load,1310,"scanpy cannot be imported in my windows system; Hi,. I couldn't import scanpy due to an error: DLL load failed. I have checked pre-existing issues, but all of them seem to be an h5py issue. My error report seems different from them. ```. >>> import scanpy as sc. D:\Anaconda\lib\site-packages\dask\config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details. data = yaml.load(f.read()) or {}. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\__init__.py"", line 36, in <module>. from . import tools as tl. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\tools\__init__.py"", line 17, in <module>. from ._sim import sim. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\tools\_sim.py"", line 23, in <module>. from .. import _utils, readwrite, logging as logg. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\readwrite.py"", line 10, in <module>. import tables. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\tables\__init__.py"", line 99, in <module>. from .utilsextension import (. ImportError: DLL load failed: The specified procedure could not be found. >>> print(sys.version). 3.7.3 (default, Mar 27 2019, 17:13:21) [MSC v.1915 64 bit (AMD64)]. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1468
https://github.com/scverse/scanpy/issues/1468:104,reliability,fail,failed,104,"scanpy cannot be imported in my windows system; Hi,. I couldn't import scanpy due to an error: DLL load failed. I have checked pre-existing issues, but all of them seem to be an h5py issue. My error report seems different from them. ```. >>> import scanpy as sc. D:\Anaconda\lib\site-packages\dask\config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details. data = yaml.load(f.read()) or {}. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\__init__.py"", line 36, in <module>. from . import tools as tl. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\tools\__init__.py"", line 17, in <module>. from ._sim import sim. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\tools\_sim.py"", line 23, in <module>. from .. import _utils, readwrite, logging as logg. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\readwrite.py"", line 10, in <module>. import tables. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\tables\__init__.py"", line 99, in <module>. from .utilsextension import (. ImportError: DLL load failed: The specified procedure could not be found. >>> print(sys.version). 3.7.3 (default, Mar 27 2019, 17:13:21) [MSC v.1915 64 bit (AMD64)]. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1468
https://github.com/scverse/scanpy/issues/1468:1315,reliability,fail,failed,1315,"scanpy cannot be imported in my windows system; Hi,. I couldn't import scanpy due to an error: DLL load failed. I have checked pre-existing issues, but all of them seem to be an h5py issue. My error report seems different from them. ```. >>> import scanpy as sc. D:\Anaconda\lib\site-packages\dask\config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details. data = yaml.load(f.read()) or {}. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\__init__.py"", line 36, in <module>. from . import tools as tl. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\tools\__init__.py"", line 17, in <module>. from ._sim import sim. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\tools\_sim.py"", line 23, in <module>. from .. import _utils, readwrite, logging as logg. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\readwrite.py"", line 10, in <module>. import tables. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\tables\__init__.py"", line 99, in <module>. from .utilsextension import (. ImportError: DLL load failed: The specified procedure could not be found. >>> print(sys.version). 3.7.3 (default, Mar 27 2019, 17:13:21) [MSC v.1915 64 bit (AMD64)]. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1468
https://github.com/scverse/scanpy/issues/1468:88,safety,error,error,88,"scanpy cannot be imported in my windows system; Hi,. I couldn't import scanpy due to an error: DLL load failed. I have checked pre-existing issues, but all of them seem to be an h5py issue. My error report seems different from them. ```. >>> import scanpy as sc. D:\Anaconda\lib\site-packages\dask\config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details. data = yaml.load(f.read()) or {}. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\__init__.py"", line 36, in <module>. from . import tools as tl. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\tools\__init__.py"", line 17, in <module>. from ._sim import sim. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\tools\_sim.py"", line 23, in <module>. from .. import _utils, readwrite, logging as logg. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\readwrite.py"", line 10, in <module>. import tables. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\tables\__init__.py"", line 99, in <module>. from .utilsextension import (. ImportError: DLL load failed: The specified procedure could not be found. >>> print(sys.version). 3.7.3 (default, Mar 27 2019, 17:13:21) [MSC v.1915 64 bit (AMD64)]. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1468
https://github.com/scverse/scanpy/issues/1468:193,safety,error,error,193,"scanpy cannot be imported in my windows system; Hi,. I couldn't import scanpy due to an error: DLL load failed. I have checked pre-existing issues, but all of them seem to be an h5py issue. My error report seems different from them. ```. >>> import scanpy as sc. D:\Anaconda\lib\site-packages\dask\config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details. data = yaml.load(f.read()) or {}. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\__init__.py"", line 36, in <module>. from . import tools as tl. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\tools\__init__.py"", line 17, in <module>. from ._sim import sim. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\tools\_sim.py"", line 23, in <module>. from .. import _utils, readwrite, logging as logg. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\readwrite.py"", line 10, in <module>. import tables. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\tables\__init__.py"", line 99, in <module>. from .utilsextension import (. ImportError: DLL load failed: The specified procedure could not be found. >>> print(sys.version). 3.7.3 (default, Mar 27 2019, 17:13:21) [MSC v.1915 64 bit (AMD64)]. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1468
https://github.com/scverse/scanpy/issues/1468:409,safety,unsaf,unsafe,409,"scanpy cannot be imported in my windows system; Hi,. I couldn't import scanpy due to an error: DLL load failed. I have checked pre-existing issues, but all of them seem to be an h5py issue. My error report seems different from them. ```. >>> import scanpy as sc. D:\Anaconda\lib\site-packages\dask\config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details. data = yaml.load(f.read()) or {}. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\__init__.py"", line 36, in <module>. from . import tools as tl. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\tools\__init__.py"", line 17, in <module>. from ._sim import sim. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\tools\_sim.py"", line 23, in <module>. from .. import _utils, readwrite, logging as logg. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\readwrite.py"", line 10, in <module>. import tables. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\tables\__init__.py"", line 99, in <module>. from .utilsextension import (. ImportError: DLL load failed: The specified procedure could not be found. >>> print(sys.version). 3.7.3 (default, Mar 27 2019, 17:13:21) [MSC v.1915 64 bit (AMD64)]. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1468
https://github.com/scverse/scanpy/issues/1468:573,safety,modul,module,573,"scanpy cannot be imported in my windows system; Hi,. I couldn't import scanpy due to an error: DLL load failed. I have checked pre-existing issues, but all of them seem to be an h5py issue. My error report seems different from them. ```. >>> import scanpy as sc. D:\Anaconda\lib\site-packages\dask\config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details. data = yaml.load(f.read()) or {}. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\__init__.py"", line 36, in <module>. from . import tools as tl. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\tools\__init__.py"", line 17, in <module>. from ._sim import sim. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\tools\_sim.py"", line 23, in <module>. from .. import _utils, readwrite, logging as logg. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\readwrite.py"", line 10, in <module>. import tables. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\tables\__init__.py"", line 99, in <module>. from .utilsextension import (. ImportError: DLL load failed: The specified procedure could not be found. >>> print(sys.version). 3.7.3 (default, Mar 27 2019, 17:13:21) [MSC v.1915 64 bit (AMD64)]. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1468
https://github.com/scverse/scanpy/issues/1468:684,safety,modul,module,684,"scanpy cannot be imported in my windows system; Hi,. I couldn't import scanpy due to an error: DLL load failed. I have checked pre-existing issues, but all of them seem to be an h5py issue. My error report seems different from them. ```. >>> import scanpy as sc. D:\Anaconda\lib\site-packages\dask\config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details. data = yaml.load(f.read()) or {}. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\__init__.py"", line 36, in <module>. from . import tools as tl. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\tools\__init__.py"", line 17, in <module>. from ._sim import sim. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\tools\_sim.py"", line 23, in <module>. from .. import _utils, readwrite, logging as logg. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\readwrite.py"", line 10, in <module>. import tables. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\tables\__init__.py"", line 99, in <module>. from .utilsextension import (. ImportError: DLL load failed: The specified procedure could not be found. >>> print(sys.version). 3.7.3 (default, Mar 27 2019, 17:13:21) [MSC v.1915 64 bit (AMD64)]. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1468
https://github.com/scverse/scanpy/issues/1468:828,safety,modul,module,828,"scanpy cannot be imported in my windows system; Hi,. I couldn't import scanpy due to an error: DLL load failed. I have checked pre-existing issues, but all of them seem to be an h5py issue. My error report seems different from them. ```. >>> import scanpy as sc. D:\Anaconda\lib\site-packages\dask\config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details. data = yaml.load(f.read()) or {}. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\__init__.py"", line 36, in <module>. from . import tools as tl. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\tools\__init__.py"", line 17, in <module>. from ._sim import sim. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\tools\_sim.py"", line 23, in <module>. from .. import _utils, readwrite, logging as logg. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\readwrite.py"", line 10, in <module>. import tables. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\tables\__init__.py"", line 99, in <module>. from .utilsextension import (. ImportError: DLL load failed: The specified procedure could not be found. >>> print(sys.version). 3.7.3 (default, Mar 27 2019, 17:13:21) [MSC v.1915 64 bit (AMD64)]. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1468
https://github.com/scverse/scanpy/issues/1468:964,safety,modul,module,964,"scanpy cannot be imported in my windows system; Hi,. I couldn't import scanpy due to an error: DLL load failed. I have checked pre-existing issues, but all of them seem to be an h5py issue. My error report seems different from them. ```. >>> import scanpy as sc. D:\Anaconda\lib\site-packages\dask\config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details. data = yaml.load(f.read()) or {}. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\__init__.py"", line 36, in <module>. from . import tools as tl. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\tools\__init__.py"", line 17, in <module>. from ._sim import sim. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\tools\_sim.py"", line 23, in <module>. from .. import _utils, readwrite, logging as logg. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\readwrite.py"", line 10, in <module>. import tables. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\tables\__init__.py"", line 99, in <module>. from .utilsextension import (. ImportError: DLL load failed: The specified procedure could not be found. >>> print(sys.version). 3.7.3 (default, Mar 27 2019, 17:13:21) [MSC v.1915 64 bit (AMD64)]. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1468
https://github.com/scverse/scanpy/issues/1468:1007,safety,log,logging,1007,"scanpy cannot be imported in my windows system; Hi,. I couldn't import scanpy due to an error: DLL load failed. I have checked pre-existing issues, but all of them seem to be an h5py issue. My error report seems different from them. ```. >>> import scanpy as sc. D:\Anaconda\lib\site-packages\dask\config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details. data = yaml.load(f.read()) or {}. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\__init__.py"", line 36, in <module>. from . import tools as tl. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\tools\__init__.py"", line 17, in <module>. from ._sim import sim. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\tools\_sim.py"", line 23, in <module>. from .. import _utils, readwrite, logging as logg. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\readwrite.py"", line 10, in <module>. import tables. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\tables\__init__.py"", line 99, in <module>. from .utilsextension import (. ImportError: DLL load failed: The specified procedure could not be found. >>> print(sys.version). 3.7.3 (default, Mar 27 2019, 17:13:21) [MSC v.1915 64 bit (AMD64)]. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1468
https://github.com/scverse/scanpy/issues/1468:1018,safety,log,logg,1018,"scanpy cannot be imported in my windows system; Hi,. I couldn't import scanpy due to an error: DLL load failed. I have checked pre-existing issues, but all of them seem to be an h5py issue. My error report seems different from them. ```. >>> import scanpy as sc. D:\Anaconda\lib\site-packages\dask\config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details. data = yaml.load(f.read()) or {}. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\__init__.py"", line 36, in <module>. from . import tools as tl. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\tools\__init__.py"", line 17, in <module>. from ._sim import sim. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\tools\_sim.py"", line 23, in <module>. from .. import _utils, readwrite, logging as logg. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\readwrite.py"", line 10, in <module>. import tables. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\tables\__init__.py"", line 99, in <module>. from .utilsextension import (. ImportError: DLL load failed: The specified procedure could not be found. >>> print(sys.version). 3.7.3 (default, Mar 27 2019, 17:13:21) [MSC v.1915 64 bit (AMD64)]. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1468
https://github.com/scverse/scanpy/issues/1468:1127,safety,modul,module,1127,"scanpy cannot be imported in my windows system; Hi,. I couldn't import scanpy due to an error: DLL load failed. I have checked pre-existing issues, but all of them seem to be an h5py issue. My error report seems different from them. ```. >>> import scanpy as sc. D:\Anaconda\lib\site-packages\dask\config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details. data = yaml.load(f.read()) or {}. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\__init__.py"", line 36, in <module>. from . import tools as tl. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\tools\__init__.py"", line 17, in <module>. from ._sim import sim. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\tools\_sim.py"", line 23, in <module>. from .. import _utils, readwrite, logging as logg. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\readwrite.py"", line 10, in <module>. import tables. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\tables\__init__.py"", line 99, in <module>. from .utilsextension import (. ImportError: DLL load failed: The specified procedure could not be found. >>> print(sys.version). 3.7.3 (default, Mar 27 2019, 17:13:21) [MSC v.1915 64 bit (AMD64)]. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1468
https://github.com/scverse/scanpy/issues/1468:1253,safety,modul,module,1253,"scanpy cannot be imported in my windows system; Hi,. I couldn't import scanpy due to an error: DLL load failed. I have checked pre-existing issues, but all of them seem to be an h5py issue. My error report seems different from them. ```. >>> import scanpy as sc. D:\Anaconda\lib\site-packages\dask\config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details. data = yaml.load(f.read()) or {}. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\__init__.py"", line 36, in <module>. from . import tools as tl. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\tools\__init__.py"", line 17, in <module>. from ._sim import sim. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\tools\_sim.py"", line 23, in <module>. from .. import _utils, readwrite, logging as logg. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\readwrite.py"", line 10, in <module>. import tables. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\tables\__init__.py"", line 99, in <module>. from .utilsextension import (. ImportError: DLL load failed: The specified procedure could not be found. >>> print(sys.version). 3.7.3 (default, Mar 27 2019, 17:13:21) [MSC v.1915 64 bit (AMD64)]. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1468
https://github.com/scverse/scanpy/issues/1468:1007,security,log,logging,1007,"scanpy cannot be imported in my windows system; Hi,. I couldn't import scanpy due to an error: DLL load failed. I have checked pre-existing issues, but all of them seem to be an h5py issue. My error report seems different from them. ```. >>> import scanpy as sc. D:\Anaconda\lib\site-packages\dask\config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details. data = yaml.load(f.read()) or {}. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\__init__.py"", line 36, in <module>. from . import tools as tl. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\tools\__init__.py"", line 17, in <module>. from ._sim import sim. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\tools\_sim.py"", line 23, in <module>. from .. import _utils, readwrite, logging as logg. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\readwrite.py"", line 10, in <module>. import tables. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\tables\__init__.py"", line 99, in <module>. from .utilsextension import (. ImportError: DLL load failed: The specified procedure could not be found. >>> print(sys.version). 3.7.3 (default, Mar 27 2019, 17:13:21) [MSC v.1915 64 bit (AMD64)]. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1468
https://github.com/scverse/scanpy/issues/1468:1018,security,log,logg,1018,"scanpy cannot be imported in my windows system; Hi,. I couldn't import scanpy due to an error: DLL load failed. I have checked pre-existing issues, but all of them seem to be an h5py issue. My error report seems different from them. ```. >>> import scanpy as sc. D:\Anaconda\lib\site-packages\dask\config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details. data = yaml.load(f.read()) or {}. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\__init__.py"", line 36, in <module>. from . import tools as tl. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\tools\__init__.py"", line 17, in <module>. from ._sim import sim. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\tools\_sim.py"", line 23, in <module>. from .. import _utils, readwrite, logging as logg. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\readwrite.py"", line 10, in <module>. import tables. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\tables\__init__.py"", line 99, in <module>. from .utilsextension import (. ImportError: DLL load failed: The specified procedure could not be found. >>> print(sys.version). 3.7.3 (default, Mar 27 2019, 17:13:21) [MSC v.1915 64 bit (AMD64)]. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1468
https://github.com/scverse/scanpy/issues/1468:509,testability,Trace,Traceback,509,"scanpy cannot be imported in my windows system; Hi,. I couldn't import scanpy due to an error: DLL load failed. I have checked pre-existing issues, but all of them seem to be an h5py issue. My error report seems different from them. ```. >>> import scanpy as sc. D:\Anaconda\lib\site-packages\dask\config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details. data = yaml.load(f.read()) or {}. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\__init__.py"", line 36, in <module>. from . import tools as tl. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\tools\__init__.py"", line 17, in <module>. from ._sim import sim. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\tools\_sim.py"", line 23, in <module>. from .. import _utils, readwrite, logging as logg. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\readwrite.py"", line 10, in <module>. import tables. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\tables\__init__.py"", line 99, in <module>. from .utilsextension import (. ImportError: DLL load failed: The specified procedure could not be found. >>> print(sys.version). 3.7.3 (default, Mar 27 2019, 17:13:21) [MSC v.1915 64 bit (AMD64)]. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1468
https://github.com/scverse/scanpy/issues/1468:1007,testability,log,logging,1007,"scanpy cannot be imported in my windows system; Hi,. I couldn't import scanpy due to an error: DLL load failed. I have checked pre-existing issues, but all of them seem to be an h5py issue. My error report seems different from them. ```. >>> import scanpy as sc. D:\Anaconda\lib\site-packages\dask\config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details. data = yaml.load(f.read()) or {}. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\__init__.py"", line 36, in <module>. from . import tools as tl. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\tools\__init__.py"", line 17, in <module>. from ._sim import sim. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\tools\_sim.py"", line 23, in <module>. from .. import _utils, readwrite, logging as logg. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\readwrite.py"", line 10, in <module>. import tables. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\tables\__init__.py"", line 99, in <module>. from .utilsextension import (. ImportError: DLL load failed: The specified procedure could not be found. >>> print(sys.version). 3.7.3 (default, Mar 27 2019, 17:13:21) [MSC v.1915 64 bit (AMD64)]. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1468
https://github.com/scverse/scanpy/issues/1468:1018,testability,log,logg,1018,"scanpy cannot be imported in my windows system; Hi,. I couldn't import scanpy due to an error: DLL load failed. I have checked pre-existing issues, but all of them seem to be an h5py issue. My error report seems different from them. ```. >>> import scanpy as sc. D:\Anaconda\lib\site-packages\dask\config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details. data = yaml.load(f.read()) or {}. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\__init__.py"", line 36, in <module>. from . import tools as tl. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\tools\__init__.py"", line 17, in <module>. from ._sim import sim. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\tools\_sim.py"", line 23, in <module>. from .. import _utils, readwrite, logging as logg. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\readwrite.py"", line 10, in <module>. import tables. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\tables\__init__.py"", line 99, in <module>. from .utilsextension import (. ImportError: DLL load failed: The specified procedure could not be found. >>> print(sys.version). 3.7.3 (default, Mar 27 2019, 17:13:21) [MSC v.1915 64 bit (AMD64)]. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1468
https://github.com/scverse/scanpy/issues/1468:88,usability,error,error,88,"scanpy cannot be imported in my windows system; Hi,. I couldn't import scanpy due to an error: DLL load failed. I have checked pre-existing issues, but all of them seem to be an h5py issue. My error report seems different from them. ```. >>> import scanpy as sc. D:\Anaconda\lib\site-packages\dask\config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details. data = yaml.load(f.read()) or {}. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\__init__.py"", line 36, in <module>. from . import tools as tl. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\tools\__init__.py"", line 17, in <module>. from ._sim import sim. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\tools\_sim.py"", line 23, in <module>. from .. import _utils, readwrite, logging as logg. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\readwrite.py"", line 10, in <module>. import tables. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\tables\__init__.py"", line 99, in <module>. from .utilsextension import (. ImportError: DLL load failed: The specified procedure could not be found. >>> print(sys.version). 3.7.3 (default, Mar 27 2019, 17:13:21) [MSC v.1915 64 bit (AMD64)]. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1468
https://github.com/scverse/scanpy/issues/1468:193,usability,error,error,193,"scanpy cannot be imported in my windows system; Hi,. I couldn't import scanpy due to an error: DLL load failed. I have checked pre-existing issues, but all of them seem to be an h5py issue. My error report seems different from them. ```. >>> import scanpy as sc. D:\Anaconda\lib\site-packages\dask\config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details. data = yaml.load(f.read()) or {}. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\__init__.py"", line 36, in <module>. from . import tools as tl. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\tools\__init__.py"", line 17, in <module>. from ._sim import sim. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\tools\_sim.py"", line 23, in <module>. from .. import _utils, readwrite, logging as logg. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\readwrite.py"", line 10, in <module>. import tables. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\tables\__init__.py"", line 99, in <module>. from .utilsextension import (. ImportError: DLL load failed: The specified procedure could not be found. >>> print(sys.version). 3.7.3 (default, Mar 27 2019, 17:13:21) [MSC v.1915 64 bit (AMD64)]. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1468
https://github.com/scverse/scanpy/issues/1468:591,usability,User,Users,591,"scanpy cannot be imported in my windows system; Hi,. I couldn't import scanpy due to an error: DLL load failed. I have checked pre-existing issues, but all of them seem to be an h5py issue. My error report seems different from them. ```. >>> import scanpy as sc. D:\Anaconda\lib\site-packages\dask\config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details. data = yaml.load(f.read()) or {}. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\__init__.py"", line 36, in <module>. from . import tools as tl. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\tools\__init__.py"", line 17, in <module>. from ._sim import sim. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\tools\_sim.py"", line 23, in <module>. from .. import _utils, readwrite, logging as logg. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\readwrite.py"", line 10, in <module>. import tables. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\tables\__init__.py"", line 99, in <module>. from .utilsextension import (. ImportError: DLL load failed: The specified procedure could not be found. >>> print(sys.version). 3.7.3 (default, Mar 27 2019, 17:13:21) [MSC v.1915 64 bit (AMD64)]. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1468
https://github.com/scverse/scanpy/issues/1468:707,usability,tool,tools,707,"scanpy cannot be imported in my windows system; Hi,. I couldn't import scanpy due to an error: DLL load failed. I have checked pre-existing issues, but all of them seem to be an h5py issue. My error report seems different from them. ```. >>> import scanpy as sc. D:\Anaconda\lib\site-packages\dask\config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details. data = yaml.load(f.read()) or {}. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\__init__.py"", line 36, in <module>. from . import tools as tl. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\tools\__init__.py"", line 17, in <module>. from ._sim import sim. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\tools\_sim.py"", line 23, in <module>. from .. import _utils, readwrite, logging as logg. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\readwrite.py"", line 10, in <module>. import tables. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\tables\__init__.py"", line 99, in <module>. from .utilsextension import (. ImportError: DLL load failed: The specified procedure could not be found. >>> print(sys.version). 3.7.3 (default, Mar 27 2019, 17:13:21) [MSC v.1915 64 bit (AMD64)]. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1468
https://github.com/scverse/scanpy/issues/1468:729,usability,User,Users,729,"scanpy cannot be imported in my windows system; Hi,. I couldn't import scanpy due to an error: DLL load failed. I have checked pre-existing issues, but all of them seem to be an h5py issue. My error report seems different from them. ```. >>> import scanpy as sc. D:\Anaconda\lib\site-packages\dask\config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details. data = yaml.load(f.read()) or {}. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\__init__.py"", line 36, in <module>. from . import tools as tl. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\tools\__init__.py"", line 17, in <module>. from ._sim import sim. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\tools\_sim.py"", line 23, in <module>. from .. import _utils, readwrite, logging as logg. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\readwrite.py"", line 10, in <module>. import tables. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\tables\__init__.py"", line 99, in <module>. from .utilsextension import (. ImportError: DLL load failed: The specified procedure could not be found. >>> print(sys.version). 3.7.3 (default, Mar 27 2019, 17:13:21) [MSC v.1915 64 bit (AMD64)]. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1468
https://github.com/scverse/scanpy/issues/1468:795,usability,tool,tools,795,"scanpy cannot be imported in my windows system; Hi,. I couldn't import scanpy due to an error: DLL load failed. I have checked pre-existing issues, but all of them seem to be an h5py issue. My error report seems different from them. ```. >>> import scanpy as sc. D:\Anaconda\lib\site-packages\dask\config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details. data = yaml.load(f.read()) or {}. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\__init__.py"", line 36, in <module>. from . import tools as tl. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\tools\__init__.py"", line 17, in <module>. from ._sim import sim. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\tools\_sim.py"", line 23, in <module>. from .. import _utils, readwrite, logging as logg. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\readwrite.py"", line 10, in <module>. import tables. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\tables\__init__.py"", line 99, in <module>. from .utilsextension import (. ImportError: DLL load failed: The specified procedure could not be found. >>> print(sys.version). 3.7.3 (default, Mar 27 2019, 17:13:21) [MSC v.1915 64 bit (AMD64)]. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1468
https://github.com/scverse/scanpy/issues/1468:869,usability,User,Users,869,"scanpy cannot be imported in my windows system; Hi,. I couldn't import scanpy due to an error: DLL load failed. I have checked pre-existing issues, but all of them seem to be an h5py issue. My error report seems different from them. ```. >>> import scanpy as sc. D:\Anaconda\lib\site-packages\dask\config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details. data = yaml.load(f.read()) or {}. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\__init__.py"", line 36, in <module>. from . import tools as tl. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\tools\__init__.py"", line 17, in <module>. from ._sim import sim. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\tools\_sim.py"", line 23, in <module>. from .. import _utils, readwrite, logging as logg. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\readwrite.py"", line 10, in <module>. import tables. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\tables\__init__.py"", line 99, in <module>. from .utilsextension import (. ImportError: DLL load failed: The specified procedure could not be found. >>> print(sys.version). 3.7.3 (default, Mar 27 2019, 17:13:21) [MSC v.1915 64 bit (AMD64)]. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1468
https://github.com/scverse/scanpy/issues/1468:935,usability,tool,tools,935,"scanpy cannot be imported in my windows system; Hi,. I couldn't import scanpy due to an error: DLL load failed. I have checked pre-existing issues, but all of them seem to be an h5py issue. My error report seems different from them. ```. >>> import scanpy as sc. D:\Anaconda\lib\site-packages\dask\config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details. data = yaml.load(f.read()) or {}. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\__init__.py"", line 36, in <module>. from . import tools as tl. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\tools\__init__.py"", line 17, in <module>. from ._sim import sim. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\tools\_sim.py"", line 23, in <module>. from .. import _utils, readwrite, logging as logg. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\readwrite.py"", line 10, in <module>. import tables. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\tables\__init__.py"", line 99, in <module>. from .utilsextension import (. ImportError: DLL load failed: The specified procedure could not be found. >>> print(sys.version). 3.7.3 (default, Mar 27 2019, 17:13:21) [MSC v.1915 64 bit (AMD64)]. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1468
https://github.com/scverse/scanpy/issues/1468:1033,usability,User,Users,1033,"scanpy cannot be imported in my windows system; Hi,. I couldn't import scanpy due to an error: DLL load failed. I have checked pre-existing issues, but all of them seem to be an h5py issue. My error report seems different from them. ```. >>> import scanpy as sc. D:\Anaconda\lib\site-packages\dask\config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details. data = yaml.load(f.read()) or {}. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\__init__.py"", line 36, in <module>. from . import tools as tl. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\tools\__init__.py"", line 17, in <module>. from ._sim import sim. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\tools\_sim.py"", line 23, in <module>. from .. import _utils, readwrite, logging as logg. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\readwrite.py"", line 10, in <module>. import tables. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\tables\__init__.py"", line 99, in <module>. from .utilsextension import (. ImportError: DLL load failed: The specified procedure could not be found. >>> print(sys.version). 3.7.3 (default, Mar 27 2019, 17:13:21) [MSC v.1915 64 bit (AMD64)]. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1468
https://github.com/scverse/scanpy/issues/1468:1160,usability,User,Users,1160,"scanpy cannot be imported in my windows system; Hi,. I couldn't import scanpy due to an error: DLL load failed. I have checked pre-existing issues, but all of them seem to be an h5py issue. My error report seems different from them. ```. >>> import scanpy as sc. D:\Anaconda\lib\site-packages\dask\config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details. data = yaml.load(f.read()) or {}. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\__init__.py"", line 36, in <module>. from . import tools as tl. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\tools\__init__.py"", line 17, in <module>. from ._sim import sim. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\tools\_sim.py"", line 23, in <module>. from .. import _utils, readwrite, logging as logg. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\scanpy\readwrite.py"", line 10, in <module>. import tables. File ""C:\Users\yuhong\AppData\Roaming\Python\Python37\site-packages\tables\__init__.py"", line 99, in <module>. from .utilsextension import (. ImportError: DLL load failed: The specified procedure could not be found. >>> print(sys.version). 3.7.3 (default, Mar 27 2019, 17:13:21) [MSC v.1915 64 bit (AMD64)]. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1468
https://github.com/scverse/scanpy/issues/1469:386,deployability,log,log-ratio,386,"CITE-seq data normalization; Dear scanpy team,. In your CITE-seq vignette you use the function `sc.pp.normalize_geometric(protein)` to normalize CITE-seq data. However, I think the description and motivation for the method are not detailed enogh to understand what is going on under the hood. Could you please give me a brief explanation on how that works? I've been using the centered log-ratio in Seurat, but there is definetely room for improvement. Thanks a lot for you time and help!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1469
https://github.com/scverse/scanpy/issues/1469:474,performance,time,time,474,"CITE-seq data normalization; Dear scanpy team,. In your CITE-seq vignette you use the function `sc.pp.normalize_geometric(protein)` to normalize CITE-seq data. However, I think the description and motivation for the method are not detailed enogh to understand what is going on under the hood. Could you please give me a brief explanation on how that works? I've been using the centered log-ratio in Seurat, but there is definetely room for improvement. Thanks a lot for you time and help!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1469
https://github.com/scverse/scanpy/issues/1469:386,safety,log,log-ratio,386,"CITE-seq data normalization; Dear scanpy team,. In your CITE-seq vignette you use the function `sc.pp.normalize_geometric(protein)` to normalize CITE-seq data. However, I think the description and motivation for the method are not detailed enogh to understand what is going on under the hood. Could you please give me a brief explanation on how that works? I've been using the centered log-ratio in Seurat, but there is definetely room for improvement. Thanks a lot for you time and help!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1469
https://github.com/scverse/scanpy/issues/1469:41,security,team,team,41,"CITE-seq data normalization; Dear scanpy team,. In your CITE-seq vignette you use the function `sc.pp.normalize_geometric(protein)` to normalize CITE-seq data. However, I think the description and motivation for the method are not detailed enogh to understand what is going on under the hood. Could you please give me a brief explanation on how that works? I've been using the centered log-ratio in Seurat, but there is definetely room for improvement. Thanks a lot for you time and help!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1469
https://github.com/scverse/scanpy/issues/1469:386,security,log,log-ratio,386,"CITE-seq data normalization; Dear scanpy team,. In your CITE-seq vignette you use the function `sc.pp.normalize_geometric(protein)` to normalize CITE-seq data. However, I think the description and motivation for the method are not detailed enogh to understand what is going on under the hood. Could you please give me a brief explanation on how that works? I've been using the centered log-ratio in Seurat, but there is definetely room for improvement. Thanks a lot for you time and help!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1469
https://github.com/scverse/scanpy/issues/1469:249,testability,understand,understand,249,"CITE-seq data normalization; Dear scanpy team,. In your CITE-seq vignette you use the function `sc.pp.normalize_geometric(protein)` to normalize CITE-seq data. However, I think the description and motivation for the method are not detailed enogh to understand what is going on under the hood. Could you please give me a brief explanation on how that works? I've been using the centered log-ratio in Seurat, but there is definetely room for improvement. Thanks a lot for you time and help!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1469
https://github.com/scverse/scanpy/issues/1469:386,testability,log,log-ratio,386,"CITE-seq data normalization; Dear scanpy team,. In your CITE-seq vignette you use the function `sc.pp.normalize_geometric(protein)` to normalize CITE-seq data. However, I think the description and motivation for the method are not detailed enogh to understand what is going on under the hood. Could you please give me a brief explanation on how that works? I've been using the centered log-ratio in Seurat, but there is definetely room for improvement. Thanks a lot for you time and help!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1469
https://github.com/scverse/scanpy/issues/1469:483,usability,help,help,483,"CITE-seq data normalization; Dear scanpy team,. In your CITE-seq vignette you use the function `sc.pp.normalize_geometric(protein)` to normalize CITE-seq data. However, I think the description and motivation for the method are not detailed enogh to understand what is going on under the hood. Could you please give me a brief explanation on how that works? I've been using the centered log-ratio in Seurat, but there is definetely room for improvement. Thanks a lot for you time and help!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1469
https://github.com/scverse/scanpy/pull/1470:128,integrability,compon,component,128,Added annotate_var_explained parameter to pl.pca; Passing annotate_var_explained to sc.pl.pca() adds the explained variance per component into the axis labels. #1445,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1470
https://github.com/scverse/scanpy/pull/1470:128,interoperability,compon,component,128,Added annotate_var_explained parameter to pl.pca; Passing annotate_var_explained to sc.pl.pca() adds the explained variance per component into the axis labels. #1445,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1470
https://github.com/scverse/scanpy/pull/1470:29,modifiability,paramet,parameter,29,Added annotate_var_explained parameter to pl.pca; Passing annotate_var_explained to sc.pl.pca() adds the explained variance per component into the axis labels. #1445,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1470
https://github.com/scverse/scanpy/pull/1470:128,modifiability,compon,component,128,Added annotate_var_explained parameter to pl.pca; Passing annotate_var_explained to sc.pl.pca() adds the explained variance per component into the axis labels. #1445,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1470
https://github.com/scverse/scanpy/issues/1471:48,availability,down,download,48,"sc.datasets.pbmc3k_processed() returns 404; The download of the anndata object of the pbmc_3k_processed dataset doesn't work, as the branch from which the object should be downloaded from changed from `master` to `main`. https://github.com/theislab/scanpy/blob/256f5944cd03fc0b8b510d607502d7170f8e5813/scanpy/datasets/_datasets.py#L305",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1471
https://github.com/scverse/scanpy/issues/1471:172,availability,down,downloaded,172,"sc.datasets.pbmc3k_processed() returns 404; The download of the anndata object of the pbmc_3k_processed dataset doesn't work, as the branch from which the object should be downloaded from changed from `master` to `main`. https://github.com/theislab/scanpy/blob/256f5944cd03fc0b8b510d607502d7170f8e5813/scanpy/datasets/_datasets.py#L305",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1471
https://github.com/scverse/scanpy/issues/1471:112,reliability,doe,doesn,112,"sc.datasets.pbmc3k_processed() returns 404; The download of the anndata object of the pbmc_3k_processed dataset doesn't work, as the branch from which the object should be downloaded from changed from `master` to `main`. https://github.com/theislab/scanpy/blob/256f5944cd03fc0b8b510d607502d7170f8e5813/scanpy/datasets/_datasets.py#L305",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1471
https://github.com/scverse/scanpy/pull/1472:4,availability,down,download,4,Fix download path of pbmc3k_processed; The name of the `master` branch of the `cellxgene` repo changed to `main`. This results in a 404 error when trying to download the pbmc3k_processed dataset (see https://github.com/theislab/scanpy/issues/1471). This PR fixes that.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1472
https://github.com/scverse/scanpy/pull/1472:136,availability,error,error,136,Fix download path of pbmc3k_processed; The name of the `master` branch of the `cellxgene` repo changed to `main`. This results in a 404 error when trying to download the pbmc3k_processed dataset (see https://github.com/theislab/scanpy/issues/1471). This PR fixes that.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1472
https://github.com/scverse/scanpy/pull/1472:157,availability,down,download,157,Fix download path of pbmc3k_processed; The name of the `master` branch of the `cellxgene` repo changed to `main`. This results in a 404 error when trying to download the pbmc3k_processed dataset (see https://github.com/theislab/scanpy/issues/1471). This PR fixes that.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1472
https://github.com/scverse/scanpy/pull/1472:136,performance,error,error,136,Fix download path of pbmc3k_processed; The name of the `master` branch of the `cellxgene` repo changed to `main`. This results in a 404 error when trying to download the pbmc3k_processed dataset (see https://github.com/theislab/scanpy/issues/1471). This PR fixes that.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1472
https://github.com/scverse/scanpy/pull/1472:136,safety,error,error,136,Fix download path of pbmc3k_processed; The name of the `master` branch of the `cellxgene` repo changed to `main`. This results in a 404 error when trying to download the pbmc3k_processed dataset (see https://github.com/theislab/scanpy/issues/1471). This PR fixes that.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1472
https://github.com/scverse/scanpy/pull/1472:136,usability,error,error,136,Fix download path of pbmc3k_processed; The name of the `master` branch of the `cellxgene` repo changed to `main`. This results in a 404 error when trying to download the pbmc3k_processed dataset (see https://github.com/theislab/scanpy/issues/1471). This PR fixes that.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1472
https://github.com/scverse/scanpy/pull/1473:0,deployability,updat,update,0,update datasets; Update `sc.datasets.visium_sge` to include new datasets from 10x genomics and account for spaceranger version.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1473
https://github.com/scverse/scanpy/pull/1473:17,deployability,Updat,Update,17,update datasets; Update `sc.datasets.visium_sge` to include new datasets from 10x genomics and account for spaceranger version.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1473
https://github.com/scverse/scanpy/pull/1473:119,deployability,version,version,119,update datasets; Update `sc.datasets.visium_sge` to include new datasets from 10x genomics and account for spaceranger version.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1473
https://github.com/scverse/scanpy/pull/1473:119,integrability,version,version,119,update datasets; Update `sc.datasets.visium_sge` to include new datasets from 10x genomics and account for spaceranger version.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1473
https://github.com/scverse/scanpy/pull/1473:119,modifiability,version,version,119,update datasets; Update `sc.datasets.visium_sge` to include new datasets from 10x genomics and account for spaceranger version.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1473
https://github.com/scverse/scanpy/pull/1473:0,safety,updat,update,0,update datasets; Update `sc.datasets.visium_sge` to include new datasets from 10x genomics and account for spaceranger version.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1473
https://github.com/scverse/scanpy/pull/1473:17,safety,Updat,Update,17,update datasets; Update `sc.datasets.visium_sge` to include new datasets from 10x genomics and account for spaceranger version.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1473
https://github.com/scverse/scanpy/pull/1473:0,security,updat,update,0,update datasets; Update `sc.datasets.visium_sge` to include new datasets from 10x genomics and account for spaceranger version.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1473
https://github.com/scverse/scanpy/pull/1473:17,security,Updat,Update,17,update datasets; Update `sc.datasets.visium_sge` to include new datasets from 10x genomics and account for spaceranger version.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1473
https://github.com/scverse/scanpy/pull/1474:165,energy efficiency,estimat,estimator,165,[REVIEW] tool.umap: Support random_state in rapids umap; This is a very simple change to propagate the `random_state` argument from `tool.umap` into the RAPIDS UMAP estimator.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1474
https://github.com/scverse/scanpy/pull/1474:1,safety,REVIEW,REVIEW,1,[REVIEW] tool.umap: Support random_state in rapids umap; This is a very simple change to propagate the `random_state` argument from `tool.umap` into the RAPIDS UMAP estimator.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1474
https://github.com/scverse/scanpy/pull/1474:1,testability,REVIEW,REVIEW,1,[REVIEW] tool.umap: Support random_state in rapids umap; This is a very simple change to propagate the `random_state` argument from `tool.umap` into the RAPIDS UMAP estimator.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1474
https://github.com/scverse/scanpy/pull/1474:72,testability,simpl,simple,72,[REVIEW] tool.umap: Support random_state in rapids umap; This is a very simple change to propagate the `random_state` argument from `tool.umap` into the RAPIDS UMAP estimator.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1474
https://github.com/scverse/scanpy/pull/1474:9,usability,tool,tool,9,[REVIEW] tool.umap: Support random_state in rapids umap; This is a very simple change to propagate the `random_state` argument from `tool.umap` into the RAPIDS UMAP estimator.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1474
https://github.com/scverse/scanpy/pull/1474:20,usability,Support,Support,20,[REVIEW] tool.umap: Support random_state in rapids umap; This is a very simple change to propagate the `random_state` argument from `tool.umap` into the RAPIDS UMAP estimator.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1474
https://github.com/scverse/scanpy/pull/1474:72,usability,simpl,simple,72,[REVIEW] tool.umap: Support random_state in rapids umap; This is a very simple change to propagate the `random_state` argument from `tool.umap` into the RAPIDS UMAP estimator.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1474
https://github.com/scverse/scanpy/pull/1474:133,usability,tool,tool,133,[REVIEW] tool.umap: Support random_state in rapids umap; This is a very simple change to propagate the `random_state` argument from `tool.umap` into the RAPIDS UMAP estimator.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1474
https://github.com/scverse/scanpy/issues/1475:327,availability,error,errors,327,"Update function _download_visium_dataset; I noticed that 10x has released some new spatial gene expression datasets. Could you include them? It should be a simple change in this line [https://github.com/theislab/scanpy/blob/ab9247bdf8b7a3decc34a15b26fec813ea8fba0d/scanpy/datasets/_datasets.py#L323](url). Also, I've encounter errors when using `scanpy.datasets.visium_sge`. It seems that the url is outdated. The link to the datasets is changed to be. `. https://support.10xgenomics.com/spatial-gene-expression/datasets/{version_id}/{sample_id}. `. Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1475
https://github.com/scverse/scanpy/issues/1475:0,deployability,Updat,Update,0,"Update function _download_visium_dataset; I noticed that 10x has released some new spatial gene expression datasets. Could you include them? It should be a simple change in this line [https://github.com/theislab/scanpy/blob/ab9247bdf8b7a3decc34a15b26fec813ea8fba0d/scanpy/datasets/_datasets.py#L323](url). Also, I've encounter errors when using `scanpy.datasets.visium_sge`. It seems that the url is outdated. The link to the datasets is changed to be. `. https://support.10xgenomics.com/spatial-gene-expression/datasets/{version_id}/{sample_id}. `. Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1475
https://github.com/scverse/scanpy/issues/1475:65,deployability,releas,released,65,"Update function _download_visium_dataset; I noticed that 10x has released some new spatial gene expression datasets. Could you include them? It should be a simple change in this line [https://github.com/theislab/scanpy/blob/ab9247bdf8b7a3decc34a15b26fec813ea8fba0d/scanpy/datasets/_datasets.py#L323](url). Also, I've encounter errors when using `scanpy.datasets.visium_sge`. It seems that the url is outdated. The link to the datasets is changed to be. `. https://support.10xgenomics.com/spatial-gene-expression/datasets/{version_id}/{sample_id}. `. Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1475
https://github.com/scverse/scanpy/issues/1475:327,performance,error,errors,327,"Update function _download_visium_dataset; I noticed that 10x has released some new spatial gene expression datasets. Could you include them? It should be a simple change in this line [https://github.com/theislab/scanpy/blob/ab9247bdf8b7a3decc34a15b26fec813ea8fba0d/scanpy/datasets/_datasets.py#L323](url). Also, I've encounter errors when using `scanpy.datasets.visium_sge`. It seems that the url is outdated. The link to the datasets is changed to be. `. https://support.10xgenomics.com/spatial-gene-expression/datasets/{version_id}/{sample_id}. `. Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1475
https://github.com/scverse/scanpy/issues/1475:0,safety,Updat,Update,0,"Update function _download_visium_dataset; I noticed that 10x has released some new spatial gene expression datasets. Could you include them? It should be a simple change in this line [https://github.com/theislab/scanpy/blob/ab9247bdf8b7a3decc34a15b26fec813ea8fba0d/scanpy/datasets/_datasets.py#L323](url). Also, I've encounter errors when using `scanpy.datasets.visium_sge`. It seems that the url is outdated. The link to the datasets is changed to be. `. https://support.10xgenomics.com/spatial-gene-expression/datasets/{version_id}/{sample_id}. `. Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1475
https://github.com/scverse/scanpy/issues/1475:327,safety,error,errors,327,"Update function _download_visium_dataset; I noticed that 10x has released some new spatial gene expression datasets. Could you include them? It should be a simple change in this line [https://github.com/theislab/scanpy/blob/ab9247bdf8b7a3decc34a15b26fec813ea8fba0d/scanpy/datasets/_datasets.py#L323](url). Also, I've encounter errors when using `scanpy.datasets.visium_sge`. It seems that the url is outdated. The link to the datasets is changed to be. `. https://support.10xgenomics.com/spatial-gene-expression/datasets/{version_id}/{sample_id}. `. Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1475
https://github.com/scverse/scanpy/issues/1475:0,security,Updat,Update,0,"Update function _download_visium_dataset; I noticed that 10x has released some new spatial gene expression datasets. Could you include them? It should be a simple change in this line [https://github.com/theislab/scanpy/blob/ab9247bdf8b7a3decc34a15b26fec813ea8fba0d/scanpy/datasets/_datasets.py#L323](url). Also, I've encounter errors when using `scanpy.datasets.visium_sge`. It seems that the url is outdated. The link to the datasets is changed to be. `. https://support.10xgenomics.com/spatial-gene-expression/datasets/{version_id}/{sample_id}. `. Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1475
https://github.com/scverse/scanpy/issues/1475:156,testability,simpl,simple,156,"Update function _download_visium_dataset; I noticed that 10x has released some new spatial gene expression datasets. Could you include them? It should be a simple change in this line [https://github.com/theislab/scanpy/blob/ab9247bdf8b7a3decc34a15b26fec813ea8fba0d/scanpy/datasets/_datasets.py#L323](url). Also, I've encounter errors when using `scanpy.datasets.visium_sge`. It seems that the url is outdated. The link to the datasets is changed to be. `. https://support.10xgenomics.com/spatial-gene-expression/datasets/{version_id}/{sample_id}. `. Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1475
https://github.com/scverse/scanpy/issues/1475:156,usability,simpl,simple,156,"Update function _download_visium_dataset; I noticed that 10x has released some new spatial gene expression datasets. Could you include them? It should be a simple change in this line [https://github.com/theislab/scanpy/blob/ab9247bdf8b7a3decc34a15b26fec813ea8fba0d/scanpy/datasets/_datasets.py#L323](url). Also, I've encounter errors when using `scanpy.datasets.visium_sge`. It seems that the url is outdated. The link to the datasets is changed to be. `. https://support.10xgenomics.com/spatial-gene-expression/datasets/{version_id}/{sample_id}. `. Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1475
https://github.com/scverse/scanpy/issues/1475:327,usability,error,errors,327,"Update function _download_visium_dataset; I noticed that 10x has released some new spatial gene expression datasets. Could you include them? It should be a simple change in this line [https://github.com/theislab/scanpy/blob/ab9247bdf8b7a3decc34a15b26fec813ea8fba0d/scanpy/datasets/_datasets.py#L323](url). Also, I've encounter errors when using `scanpy.datasets.visium_sge`. It seems that the url is outdated. The link to the datasets is changed to be. `. https://support.10xgenomics.com/spatial-gene-expression/datasets/{version_id}/{sample_id}. `. Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1475
https://github.com/scverse/scanpy/issues/1475:464,usability,support,support,464,"Update function _download_visium_dataset; I noticed that 10x has released some new spatial gene expression datasets. Could you include them? It should be a simple change in this line [https://github.com/theislab/scanpy/blob/ab9247bdf8b7a3decc34a15b26fec813ea8fba0d/scanpy/datasets/_datasets.py#L323](url). Also, I've encounter errors when using `scanpy.datasets.visium_sge`. It seems that the url is outdated. The link to the datasets is changed to be. `. https://support.10xgenomics.com/spatial-gene-expression/datasets/{version_id}/{sample_id}. `. Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1475
https://github.com/scverse/scanpy/pull/1476:1269,availability,mainten,maintenance,1269,"Add Scrublet as an external tool; This is a PR attempting to address https://github.com/theislab/scanpy/issues/173, and building on the work of @swolock in his fork (see https://github.com/theislab/scanpy/compare/master...swolock:master). . I've taken a different approach to that fork:. - Various component functions wrapped individually (core Scrublet functionality, doublet simulation), to allow for custom workflows with different Scanpy preprocessing where required. - ... but a scrub_doublets() function that does pre-processing analogously with Scrublet (but using Scanpy calls) is what imagine most people will use. . - I've moved what was sensible to use Scanpy functions. . - ... but some parts are left alone. In particular the PCA seems like it's used a bit differently in Scrublet, fitting the model to the observed transcriptomes (.fit()) and then applying dimensionality reductions to both observed and simulated matrices (.transform()). That's complex to implement with Scanpy functions (which just uses fit_transform()), so thought I'd leave that in Scrublet (which calls the same libraries anyway). Similarly the neighbour graph generation done in the classifier is quite wired in, so I haven't tried to pull it into Scanpy. I hope that this is a low-maintenance solution, allowing use of Scrublet with Scanpy functions, without a large amount of re-implementation which might cause drift wrt Scrublet itself. . It does seem to work, but happy to make any changes you or @swolock want- would just be really useful for us to have this in Scanpy :-).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1476
https://github.com/scverse/scanpy/pull/1476:120,deployability,build,building,120,"Add Scrublet as an external tool; This is a PR attempting to address https://github.com/theislab/scanpy/issues/173, and building on the work of @swolock in his fork (see https://github.com/theislab/scanpy/compare/master...swolock:master). . I've taken a different approach to that fork:. - Various component functions wrapped individually (core Scrublet functionality, doublet simulation), to allow for custom workflows with different Scanpy preprocessing where required. - ... but a scrub_doublets() function that does pre-processing analogously with Scrublet (but using Scanpy calls) is what imagine most people will use. . - I've moved what was sensible to use Scanpy functions. . - ... but some parts are left alone. In particular the PCA seems like it's used a bit differently in Scrublet, fitting the model to the observed transcriptomes (.fit()) and then applying dimensionality reductions to both observed and simulated matrices (.transform()). That's complex to implement with Scanpy functions (which just uses fit_transform()), so thought I'd leave that in Scrublet (which calls the same libraries anyway). Similarly the neighbour graph generation done in the classifier is quite wired in, so I haven't tried to pull it into Scanpy. I hope that this is a low-maintenance solution, allowing use of Scrublet with Scanpy functions, without a large amount of re-implementation which might cause drift wrt Scrublet itself. . It does seem to work, but happy to make any changes you or @swolock want- would just be really useful for us to have this in Scanpy :-).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1476
https://github.com/scverse/scanpy/pull/1476:820,deployability,observ,observed,820,"Add Scrublet as an external tool; This is a PR attempting to address https://github.com/theislab/scanpy/issues/173, and building on the work of @swolock in his fork (see https://github.com/theislab/scanpy/compare/master...swolock:master). . I've taken a different approach to that fork:. - Various component functions wrapped individually (core Scrublet functionality, doublet simulation), to allow for custom workflows with different Scanpy preprocessing where required. - ... but a scrub_doublets() function that does pre-processing analogously with Scrublet (but using Scanpy calls) is what imagine most people will use. . - I've moved what was sensible to use Scanpy functions. . - ... but some parts are left alone. In particular the PCA seems like it's used a bit differently in Scrublet, fitting the model to the observed transcriptomes (.fit()) and then applying dimensionality reductions to both observed and simulated matrices (.transform()). That's complex to implement with Scanpy functions (which just uses fit_transform()), so thought I'd leave that in Scrublet (which calls the same libraries anyway). Similarly the neighbour graph generation done in the classifier is quite wired in, so I haven't tried to pull it into Scanpy. I hope that this is a low-maintenance solution, allowing use of Scrublet with Scanpy functions, without a large amount of re-implementation which might cause drift wrt Scrublet itself. . It does seem to work, but happy to make any changes you or @swolock want- would just be really useful for us to have this in Scanpy :-).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1476
https://github.com/scverse/scanpy/pull/1476:905,deployability,observ,observed,905,"Add Scrublet as an external tool; This is a PR attempting to address https://github.com/theislab/scanpy/issues/173, and building on the work of @swolock in his fork (see https://github.com/theislab/scanpy/compare/master...swolock:master). . I've taken a different approach to that fork:. - Various component functions wrapped individually (core Scrublet functionality, doublet simulation), to allow for custom workflows with different Scanpy preprocessing where required. - ... but a scrub_doublets() function that does pre-processing analogously with Scrublet (but using Scanpy calls) is what imagine most people will use. . - I've moved what was sensible to use Scanpy functions. . - ... but some parts are left alone. In particular the PCA seems like it's used a bit differently in Scrublet, fitting the model to the observed transcriptomes (.fit()) and then applying dimensionality reductions to both observed and simulated matrices (.transform()). That's complex to implement with Scanpy functions (which just uses fit_transform()), so thought I'd leave that in Scrublet (which calls the same libraries anyway). Similarly the neighbour graph generation done in the classifier is quite wired in, so I haven't tried to pull it into Scanpy. I hope that this is a low-maintenance solution, allowing use of Scrublet with Scanpy functions, without a large amount of re-implementation which might cause drift wrt Scrublet itself. . It does seem to work, but happy to make any changes you or @swolock want- would just be really useful for us to have this in Scanpy :-).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1476
https://github.com/scverse/scanpy/pull/1476:340,energy efficiency,core,core,340,"Add Scrublet as an external tool; This is a PR attempting to address https://github.com/theislab/scanpy/issues/173, and building on the work of @swolock in his fork (see https://github.com/theislab/scanpy/compare/master...swolock:master). . I've taken a different approach to that fork:. - Various component functions wrapped individually (core Scrublet functionality, doublet simulation), to allow for custom workflows with different Scanpy preprocessing where required. - ... but a scrub_doublets() function that does pre-processing analogously with Scrublet (but using Scanpy calls) is what imagine most people will use. . - I've moved what was sensible to use Scanpy functions. . - ... but some parts are left alone. In particular the PCA seems like it's used a bit differently in Scrublet, fitting the model to the observed transcriptomes (.fit()) and then applying dimensionality reductions to both observed and simulated matrices (.transform()). That's complex to implement with Scanpy functions (which just uses fit_transform()), so thought I'd leave that in Scrublet (which calls the same libraries anyway). Similarly the neighbour graph generation done in the classifier is quite wired in, so I haven't tried to pull it into Scanpy. I hope that this is a low-maintenance solution, allowing use of Scrublet with Scanpy functions, without a large amount of re-implementation which might cause drift wrt Scrublet itself. . It does seem to work, but happy to make any changes you or @swolock want- would just be really useful for us to have this in Scanpy :-).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1476
https://github.com/scverse/scanpy/pull/1476:807,energy efficiency,model,model,807,"Add Scrublet as an external tool; This is a PR attempting to address https://github.com/theislab/scanpy/issues/173, and building on the work of @swolock in his fork (see https://github.com/theislab/scanpy/compare/master...swolock:master). . I've taken a different approach to that fork:. - Various component functions wrapped individually (core Scrublet functionality, doublet simulation), to allow for custom workflows with different Scanpy preprocessing where required. - ... but a scrub_doublets() function that does pre-processing analogously with Scrublet (but using Scanpy calls) is what imagine most people will use. . - I've moved what was sensible to use Scanpy functions. . - ... but some parts are left alone. In particular the PCA seems like it's used a bit differently in Scrublet, fitting the model to the observed transcriptomes (.fit()) and then applying dimensionality reductions to both observed and simulated matrices (.transform()). That's complex to implement with Scanpy functions (which just uses fit_transform()), so thought I'd leave that in Scrublet (which calls the same libraries anyway). Similarly the neighbour graph generation done in the classifier is quite wired in, so I haven't tried to pull it into Scanpy. I hope that this is a low-maintenance solution, allowing use of Scrublet with Scanpy functions, without a large amount of re-implementation which might cause drift wrt Scrublet itself. . It does seem to work, but happy to make any changes you or @swolock want- would just be really useful for us to have this in Scanpy :-).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1476
https://github.com/scverse/scanpy/pull/1476:886,energy efficiency,reduc,reductions,886,"Add Scrublet as an external tool; This is a PR attempting to address https://github.com/theislab/scanpy/issues/173, and building on the work of @swolock in his fork (see https://github.com/theislab/scanpy/compare/master...swolock:master). . I've taken a different approach to that fork:. - Various component functions wrapped individually (core Scrublet functionality, doublet simulation), to allow for custom workflows with different Scanpy preprocessing where required. - ... but a scrub_doublets() function that does pre-processing analogously with Scrublet (but using Scanpy calls) is what imagine most people will use. . - I've moved what was sensible to use Scanpy functions. . - ... but some parts are left alone. In particular the PCA seems like it's used a bit differently in Scrublet, fitting the model to the observed transcriptomes (.fit()) and then applying dimensionality reductions to both observed and simulated matrices (.transform()). That's complex to implement with Scanpy functions (which just uses fit_transform()), so thought I'd leave that in Scrublet (which calls the same libraries anyway). Similarly the neighbour graph generation done in the classifier is quite wired in, so I haven't tried to pull it into Scanpy. I hope that this is a low-maintenance solution, allowing use of Scrublet with Scanpy functions, without a large amount of re-implementation which might cause drift wrt Scrublet itself. . It does seem to work, but happy to make any changes you or @swolock want- would just be really useful for us to have this in Scanpy :-).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1476
https://github.com/scverse/scanpy/pull/1476:298,integrability,compon,component,298,"Add Scrublet as an external tool; This is a PR attempting to address https://github.com/theislab/scanpy/issues/173, and building on the work of @swolock in his fork (see https://github.com/theislab/scanpy/compare/master...swolock:master). . I've taken a different approach to that fork:. - Various component functions wrapped individually (core Scrublet functionality, doublet simulation), to allow for custom workflows with different Scanpy preprocessing where required. - ... but a scrub_doublets() function that does pre-processing analogously with Scrublet (but using Scanpy calls) is what imagine most people will use. . - I've moved what was sensible to use Scanpy functions. . - ... but some parts are left alone. In particular the PCA seems like it's used a bit differently in Scrublet, fitting the model to the observed transcriptomes (.fit()) and then applying dimensionality reductions to both observed and simulated matrices (.transform()). That's complex to implement with Scanpy functions (which just uses fit_transform()), so thought I'd leave that in Scrublet (which calls the same libraries anyway). Similarly the neighbour graph generation done in the classifier is quite wired in, so I haven't tried to pull it into Scanpy. I hope that this is a low-maintenance solution, allowing use of Scrublet with Scanpy functions, without a large amount of re-implementation which might cause drift wrt Scrublet itself. . It does seem to work, but happy to make any changes you or @swolock want- would just be really useful for us to have this in Scanpy :-).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1476
https://github.com/scverse/scanpy/pull/1476:318,integrability,wrap,wrapped,318,"Add Scrublet as an external tool; This is a PR attempting to address https://github.com/theislab/scanpy/issues/173, and building on the work of @swolock in his fork (see https://github.com/theislab/scanpy/compare/master...swolock:master). . I've taken a different approach to that fork:. - Various component functions wrapped individually (core Scrublet functionality, doublet simulation), to allow for custom workflows with different Scanpy preprocessing where required. - ... but a scrub_doublets() function that does pre-processing analogously with Scrublet (but using Scanpy calls) is what imagine most people will use. . - I've moved what was sensible to use Scanpy functions. . - ... but some parts are left alone. In particular the PCA seems like it's used a bit differently in Scrublet, fitting the model to the observed transcriptomes (.fit()) and then applying dimensionality reductions to both observed and simulated matrices (.transform()). That's complex to implement with Scanpy functions (which just uses fit_transform()), so thought I'd leave that in Scrublet (which calls the same libraries anyway). Similarly the neighbour graph generation done in the classifier is quite wired in, so I haven't tried to pull it into Scanpy. I hope that this is a low-maintenance solution, allowing use of Scrublet with Scanpy functions, without a large amount of re-implementation which might cause drift wrt Scrublet itself. . It does seem to work, but happy to make any changes you or @swolock want- would just be really useful for us to have this in Scanpy :-).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1476
https://github.com/scverse/scanpy/pull/1476:939,integrability,transform,transform,939,"Add Scrublet as an external tool; This is a PR attempting to address https://github.com/theislab/scanpy/issues/173, and building on the work of @swolock in his fork (see https://github.com/theislab/scanpy/compare/master...swolock:master). . I've taken a different approach to that fork:. - Various component functions wrapped individually (core Scrublet functionality, doublet simulation), to allow for custom workflows with different Scanpy preprocessing where required. - ... but a scrub_doublets() function that does pre-processing analogously with Scrublet (but using Scanpy calls) is what imagine most people will use. . - I've moved what was sensible to use Scanpy functions. . - ... but some parts are left alone. In particular the PCA seems like it's used a bit differently in Scrublet, fitting the model to the observed transcriptomes (.fit()) and then applying dimensionality reductions to both observed and simulated matrices (.transform()). That's complex to implement with Scanpy functions (which just uses fit_transform()), so thought I'd leave that in Scrublet (which calls the same libraries anyway). Similarly the neighbour graph generation done in the classifier is quite wired in, so I haven't tried to pull it into Scanpy. I hope that this is a low-maintenance solution, allowing use of Scrublet with Scanpy functions, without a large amount of re-implementation which might cause drift wrt Scrublet itself. . It does seem to work, but happy to make any changes you or @swolock want- would just be really useful for us to have this in Scanpy :-).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1476
https://github.com/scverse/scanpy/pull/1476:298,interoperability,compon,component,298,"Add Scrublet as an external tool; This is a PR attempting to address https://github.com/theislab/scanpy/issues/173, and building on the work of @swolock in his fork (see https://github.com/theislab/scanpy/compare/master...swolock:master). . I've taken a different approach to that fork:. - Various component functions wrapped individually (core Scrublet functionality, doublet simulation), to allow for custom workflows with different Scanpy preprocessing where required. - ... but a scrub_doublets() function that does pre-processing analogously with Scrublet (but using Scanpy calls) is what imagine most people will use. . - I've moved what was sensible to use Scanpy functions. . - ... but some parts are left alone. In particular the PCA seems like it's used a bit differently in Scrublet, fitting the model to the observed transcriptomes (.fit()) and then applying dimensionality reductions to both observed and simulated matrices (.transform()). That's complex to implement with Scanpy functions (which just uses fit_transform()), so thought I'd leave that in Scrublet (which calls the same libraries anyway). Similarly the neighbour graph generation done in the classifier is quite wired in, so I haven't tried to pull it into Scanpy. I hope that this is a low-maintenance solution, allowing use of Scrublet with Scanpy functions, without a large amount of re-implementation which might cause drift wrt Scrublet itself. . It does seem to work, but happy to make any changes you or @swolock want- would just be really useful for us to have this in Scanpy :-).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1476
https://github.com/scverse/scanpy/pull/1476:939,interoperability,transform,transform,939,"Add Scrublet as an external tool; This is a PR attempting to address https://github.com/theislab/scanpy/issues/173, and building on the work of @swolock in his fork (see https://github.com/theislab/scanpy/compare/master...swolock:master). . I've taken a different approach to that fork:. - Various component functions wrapped individually (core Scrublet functionality, doublet simulation), to allow for custom workflows with different Scanpy preprocessing where required. - ... but a scrub_doublets() function that does pre-processing analogously with Scrublet (but using Scanpy calls) is what imagine most people will use. . - I've moved what was sensible to use Scanpy functions. . - ... but some parts are left alone. In particular the PCA seems like it's used a bit differently in Scrublet, fitting the model to the observed transcriptomes (.fit()) and then applying dimensionality reductions to both observed and simulated matrices (.transform()). That's complex to implement with Scanpy functions (which just uses fit_transform()), so thought I'd leave that in Scrublet (which calls the same libraries anyway). Similarly the neighbour graph generation done in the classifier is quite wired in, so I haven't tried to pull it into Scanpy. I hope that this is a low-maintenance solution, allowing use of Scrublet with Scanpy functions, without a large amount of re-implementation which might cause drift wrt Scrublet itself. . It does seem to work, but happy to make any changes you or @swolock want- would just be really useful for us to have this in Scanpy :-).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1476
https://github.com/scverse/scanpy/pull/1476:298,modifiability,compon,component,298,"Add Scrublet as an external tool; This is a PR attempting to address https://github.com/theislab/scanpy/issues/173, and building on the work of @swolock in his fork (see https://github.com/theislab/scanpy/compare/master...swolock:master). . I've taken a different approach to that fork:. - Various component functions wrapped individually (core Scrublet functionality, doublet simulation), to allow for custom workflows with different Scanpy preprocessing where required. - ... but a scrub_doublets() function that does pre-processing analogously with Scrublet (but using Scanpy calls) is what imagine most people will use. . - I've moved what was sensible to use Scanpy functions. . - ... but some parts are left alone. In particular the PCA seems like it's used a bit differently in Scrublet, fitting the model to the observed transcriptomes (.fit()) and then applying dimensionality reductions to both observed and simulated matrices (.transform()). That's complex to implement with Scanpy functions (which just uses fit_transform()), so thought I'd leave that in Scrublet (which calls the same libraries anyway). Similarly the neighbour graph generation done in the classifier is quite wired in, so I haven't tried to pull it into Scanpy. I hope that this is a low-maintenance solution, allowing use of Scrublet with Scanpy functions, without a large amount of re-implementation which might cause drift wrt Scrublet itself. . It does seem to work, but happy to make any changes you or @swolock want- would just be really useful for us to have this in Scanpy :-).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1476
https://github.com/scverse/scanpy/pull/1476:515,reliability,doe,does,515,"Add Scrublet as an external tool; This is a PR attempting to address https://github.com/theislab/scanpy/issues/173, and building on the work of @swolock in his fork (see https://github.com/theislab/scanpy/compare/master...swolock:master). . I've taken a different approach to that fork:. - Various component functions wrapped individually (core Scrublet functionality, doublet simulation), to allow for custom workflows with different Scanpy preprocessing where required. - ... but a scrub_doublets() function that does pre-processing analogously with Scrublet (but using Scanpy calls) is what imagine most people will use. . - I've moved what was sensible to use Scanpy functions. . - ... but some parts are left alone. In particular the PCA seems like it's used a bit differently in Scrublet, fitting the model to the observed transcriptomes (.fit()) and then applying dimensionality reductions to both observed and simulated matrices (.transform()). That's complex to implement with Scanpy functions (which just uses fit_transform()), so thought I'd leave that in Scrublet (which calls the same libraries anyway). Similarly the neighbour graph generation done in the classifier is quite wired in, so I haven't tried to pull it into Scanpy. I hope that this is a low-maintenance solution, allowing use of Scrublet with Scanpy functions, without a large amount of re-implementation which might cause drift wrt Scrublet itself. . It does seem to work, but happy to make any changes you or @swolock want- would just be really useful for us to have this in Scanpy :-).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1476
https://github.com/scverse/scanpy/pull/1476:1269,reliability,mainten,maintenance,1269,"Add Scrublet as an external tool; This is a PR attempting to address https://github.com/theislab/scanpy/issues/173, and building on the work of @swolock in his fork (see https://github.com/theislab/scanpy/compare/master...swolock:master). . I've taken a different approach to that fork:. - Various component functions wrapped individually (core Scrublet functionality, doublet simulation), to allow for custom workflows with different Scanpy preprocessing where required. - ... but a scrub_doublets() function that does pre-processing analogously with Scrublet (but using Scanpy calls) is what imagine most people will use. . - I've moved what was sensible to use Scanpy functions. . - ... but some parts are left alone. In particular the PCA seems like it's used a bit differently in Scrublet, fitting the model to the observed transcriptomes (.fit()) and then applying dimensionality reductions to both observed and simulated matrices (.transform()). That's complex to implement with Scanpy functions (which just uses fit_transform()), so thought I'd leave that in Scrublet (which calls the same libraries anyway). Similarly the neighbour graph generation done in the classifier is quite wired in, so I haven't tried to pull it into Scanpy. I hope that this is a low-maintenance solution, allowing use of Scrublet with Scanpy functions, without a large amount of re-implementation which might cause drift wrt Scrublet itself. . It does seem to work, but happy to make any changes you or @swolock want- would just be really useful for us to have this in Scanpy :-).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1476
https://github.com/scverse/scanpy/pull/1476:1433,reliability,doe,does,1433,"Add Scrublet as an external tool; This is a PR attempting to address https://github.com/theislab/scanpy/issues/173, and building on the work of @swolock in his fork (see https://github.com/theislab/scanpy/compare/master...swolock:master). . I've taken a different approach to that fork:. - Various component functions wrapped individually (core Scrublet functionality, doublet simulation), to allow for custom workflows with different Scanpy preprocessing where required. - ... but a scrub_doublets() function that does pre-processing analogously with Scrublet (but using Scanpy calls) is what imagine most people will use. . - I've moved what was sensible to use Scanpy functions. . - ... but some parts are left alone. In particular the PCA seems like it's used a bit differently in Scrublet, fitting the model to the observed transcriptomes (.fit()) and then applying dimensionality reductions to both observed and simulated matrices (.transform()). That's complex to implement with Scanpy functions (which just uses fit_transform()), so thought I'd leave that in Scrublet (which calls the same libraries anyway). Similarly the neighbour graph generation done in the classifier is quite wired in, so I haven't tried to pull it into Scanpy. I hope that this is a low-maintenance solution, allowing use of Scrublet with Scanpy functions, without a large amount of re-implementation which might cause drift wrt Scrublet itself. . It does seem to work, but happy to make any changes you or @swolock want- would just be really useful for us to have this in Scanpy :-).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1476
https://github.com/scverse/scanpy/pull/1476:960,safety,compl,complex,960,"Add Scrublet as an external tool; This is a PR attempting to address https://github.com/theislab/scanpy/issues/173, and building on the work of @swolock in his fork (see https://github.com/theislab/scanpy/compare/master...swolock:master). . I've taken a different approach to that fork:. - Various component functions wrapped individually (core Scrublet functionality, doublet simulation), to allow for custom workflows with different Scanpy preprocessing where required. - ... but a scrub_doublets() function that does pre-processing analogously with Scrublet (but using Scanpy calls) is what imagine most people will use. . - I've moved what was sensible to use Scanpy functions. . - ... but some parts are left alone. In particular the PCA seems like it's used a bit differently in Scrublet, fitting the model to the observed transcriptomes (.fit()) and then applying dimensionality reductions to both observed and simulated matrices (.transform()). That's complex to implement with Scanpy functions (which just uses fit_transform()), so thought I'd leave that in Scrublet (which calls the same libraries anyway). Similarly the neighbour graph generation done in the classifier is quite wired in, so I haven't tried to pull it into Scanpy. I hope that this is a low-maintenance solution, allowing use of Scrublet with Scanpy functions, without a large amount of re-implementation which might cause drift wrt Scrublet itself. . It does seem to work, but happy to make any changes you or @swolock want- would just be really useful for us to have this in Scanpy :-).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1476
https://github.com/scverse/scanpy/pull/1476:807,security,model,model,807,"Add Scrublet as an external tool; This is a PR attempting to address https://github.com/theislab/scanpy/issues/173, and building on the work of @swolock in his fork (see https://github.com/theislab/scanpy/compare/master...swolock:master). . I've taken a different approach to that fork:. - Various component functions wrapped individually (core Scrublet functionality, doublet simulation), to allow for custom workflows with different Scanpy preprocessing where required. - ... but a scrub_doublets() function that does pre-processing analogously with Scrublet (but using Scanpy calls) is what imagine most people will use. . - I've moved what was sensible to use Scanpy functions. . - ... but some parts are left alone. In particular the PCA seems like it's used a bit differently in Scrublet, fitting the model to the observed transcriptomes (.fit()) and then applying dimensionality reductions to both observed and simulated matrices (.transform()). That's complex to implement with Scanpy functions (which just uses fit_transform()), so thought I'd leave that in Scrublet (which calls the same libraries anyway). Similarly the neighbour graph generation done in the classifier is quite wired in, so I haven't tried to pull it into Scanpy. I hope that this is a low-maintenance solution, allowing use of Scrublet with Scanpy functions, without a large amount of re-implementation which might cause drift wrt Scrublet itself. . It does seem to work, but happy to make any changes you or @swolock want- would just be really useful for us to have this in Scanpy :-).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1476
https://github.com/scverse/scanpy/pull/1476:960,security,compl,complex,960,"Add Scrublet as an external tool; This is a PR attempting to address https://github.com/theislab/scanpy/issues/173, and building on the work of @swolock in his fork (see https://github.com/theislab/scanpy/compare/master...swolock:master). . I've taken a different approach to that fork:. - Various component functions wrapped individually (core Scrublet functionality, doublet simulation), to allow for custom workflows with different Scanpy preprocessing where required. - ... but a scrub_doublets() function that does pre-processing analogously with Scrublet (but using Scanpy calls) is what imagine most people will use. . - I've moved what was sensible to use Scanpy functions. . - ... but some parts are left alone. In particular the PCA seems like it's used a bit differently in Scrublet, fitting the model to the observed transcriptomes (.fit()) and then applying dimensionality reductions to both observed and simulated matrices (.transform()). That's complex to implement with Scanpy functions (which just uses fit_transform()), so thought I'd leave that in Scrublet (which calls the same libraries anyway). Similarly the neighbour graph generation done in the classifier is quite wired in, so I haven't tried to pull it into Scanpy. I hope that this is a low-maintenance solution, allowing use of Scrublet with Scanpy functions, without a large amount of re-implementation which might cause drift wrt Scrublet itself. . It does seem to work, but happy to make any changes you or @swolock want- would just be really useful for us to have this in Scanpy :-).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1476
https://github.com/scverse/scanpy/pull/1476:377,testability,simul,simulation,377,"Add Scrublet as an external tool; This is a PR attempting to address https://github.com/theislab/scanpy/issues/173, and building on the work of @swolock in his fork (see https://github.com/theislab/scanpy/compare/master...swolock:master). . I've taken a different approach to that fork:. - Various component functions wrapped individually (core Scrublet functionality, doublet simulation), to allow for custom workflows with different Scanpy preprocessing where required. - ... but a scrub_doublets() function that does pre-processing analogously with Scrublet (but using Scanpy calls) is what imagine most people will use. . - I've moved what was sensible to use Scanpy functions. . - ... but some parts are left alone. In particular the PCA seems like it's used a bit differently in Scrublet, fitting the model to the observed transcriptomes (.fit()) and then applying dimensionality reductions to both observed and simulated matrices (.transform()). That's complex to implement with Scanpy functions (which just uses fit_transform()), so thought I'd leave that in Scrublet (which calls the same libraries anyway). Similarly the neighbour graph generation done in the classifier is quite wired in, so I haven't tried to pull it into Scanpy. I hope that this is a low-maintenance solution, allowing use of Scrublet with Scanpy functions, without a large amount of re-implementation which might cause drift wrt Scrublet itself. . It does seem to work, but happy to make any changes you or @swolock want- would just be really useful for us to have this in Scanpy :-).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1476
https://github.com/scverse/scanpy/pull/1476:820,testability,observ,observed,820,"Add Scrublet as an external tool; This is a PR attempting to address https://github.com/theislab/scanpy/issues/173, and building on the work of @swolock in his fork (see https://github.com/theislab/scanpy/compare/master...swolock:master). . I've taken a different approach to that fork:. - Various component functions wrapped individually (core Scrublet functionality, doublet simulation), to allow for custom workflows with different Scanpy preprocessing where required. - ... but a scrub_doublets() function that does pre-processing analogously with Scrublet (but using Scanpy calls) is what imagine most people will use. . - I've moved what was sensible to use Scanpy functions. . - ... but some parts are left alone. In particular the PCA seems like it's used a bit differently in Scrublet, fitting the model to the observed transcriptomes (.fit()) and then applying dimensionality reductions to both observed and simulated matrices (.transform()). That's complex to implement with Scanpy functions (which just uses fit_transform()), so thought I'd leave that in Scrublet (which calls the same libraries anyway). Similarly the neighbour graph generation done in the classifier is quite wired in, so I haven't tried to pull it into Scanpy. I hope that this is a low-maintenance solution, allowing use of Scrublet with Scanpy functions, without a large amount of re-implementation which might cause drift wrt Scrublet itself. . It does seem to work, but happy to make any changes you or @swolock want- would just be really useful for us to have this in Scanpy :-).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1476
https://github.com/scverse/scanpy/pull/1476:905,testability,observ,observed,905,"Add Scrublet as an external tool; This is a PR attempting to address https://github.com/theislab/scanpy/issues/173, and building on the work of @swolock in his fork (see https://github.com/theislab/scanpy/compare/master...swolock:master). . I've taken a different approach to that fork:. - Various component functions wrapped individually (core Scrublet functionality, doublet simulation), to allow for custom workflows with different Scanpy preprocessing where required. - ... but a scrub_doublets() function that does pre-processing analogously with Scrublet (but using Scanpy calls) is what imagine most people will use. . - I've moved what was sensible to use Scanpy functions. . - ... but some parts are left alone. In particular the PCA seems like it's used a bit differently in Scrublet, fitting the model to the observed transcriptomes (.fit()) and then applying dimensionality reductions to both observed and simulated matrices (.transform()). That's complex to implement with Scanpy functions (which just uses fit_transform()), so thought I'd leave that in Scrublet (which calls the same libraries anyway). Similarly the neighbour graph generation done in the classifier is quite wired in, so I haven't tried to pull it into Scanpy. I hope that this is a low-maintenance solution, allowing use of Scrublet with Scanpy functions, without a large amount of re-implementation which might cause drift wrt Scrublet itself. . It does seem to work, but happy to make any changes you or @swolock want- would just be really useful for us to have this in Scanpy :-).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1476
https://github.com/scverse/scanpy/pull/1476:918,testability,simul,simulated,918,"Add Scrublet as an external tool; This is a PR attempting to address https://github.com/theislab/scanpy/issues/173, and building on the work of @swolock in his fork (see https://github.com/theislab/scanpy/compare/master...swolock:master). . I've taken a different approach to that fork:. - Various component functions wrapped individually (core Scrublet functionality, doublet simulation), to allow for custom workflows with different Scanpy preprocessing where required. - ... but a scrub_doublets() function that does pre-processing analogously with Scrublet (but using Scanpy calls) is what imagine most people will use. . - I've moved what was sensible to use Scanpy functions. . - ... but some parts are left alone. In particular the PCA seems like it's used a bit differently in Scrublet, fitting the model to the observed transcriptomes (.fit()) and then applying dimensionality reductions to both observed and simulated matrices (.transform()). That's complex to implement with Scanpy functions (which just uses fit_transform()), so thought I'd leave that in Scrublet (which calls the same libraries anyway). Similarly the neighbour graph generation done in the classifier is quite wired in, so I haven't tried to pull it into Scanpy. I hope that this is a low-maintenance solution, allowing use of Scrublet with Scanpy functions, without a large amount of re-implementation which might cause drift wrt Scrublet itself. . It does seem to work, but happy to make any changes you or @swolock want- would just be really useful for us to have this in Scanpy :-).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1476
https://github.com/scverse/scanpy/pull/1476:28,usability,tool,tool,28,"Add Scrublet as an external tool; This is a PR attempting to address https://github.com/theislab/scanpy/issues/173, and building on the work of @swolock in his fork (see https://github.com/theislab/scanpy/compare/master...swolock:master). . I've taken a different approach to that fork:. - Various component functions wrapped individually (core Scrublet functionality, doublet simulation), to allow for custom workflows with different Scanpy preprocessing where required. - ... but a scrub_doublets() function that does pre-processing analogously with Scrublet (but using Scanpy calls) is what imagine most people will use. . - I've moved what was sensible to use Scanpy functions. . - ... but some parts are left alone. In particular the PCA seems like it's used a bit differently in Scrublet, fitting the model to the observed transcriptomes (.fit()) and then applying dimensionality reductions to both observed and simulated matrices (.transform()). That's complex to implement with Scanpy functions (which just uses fit_transform()), so thought I'd leave that in Scrublet (which calls the same libraries anyway). Similarly the neighbour graph generation done in the classifier is quite wired in, so I haven't tried to pull it into Scanpy. I hope that this is a low-maintenance solution, allowing use of Scrublet with Scanpy functions, without a large amount of re-implementation which might cause drift wrt Scrublet itself. . It does seem to work, but happy to make any changes you or @swolock want- would just be really useful for us to have this in Scanpy :-).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1476
https://github.com/scverse/scanpy/pull/1476:403,usability,custom,custom,403,"Add Scrublet as an external tool; This is a PR attempting to address https://github.com/theislab/scanpy/issues/173, and building on the work of @swolock in his fork (see https://github.com/theislab/scanpy/compare/master...swolock:master). . I've taken a different approach to that fork:. - Various component functions wrapped individually (core Scrublet functionality, doublet simulation), to allow for custom workflows with different Scanpy preprocessing where required. - ... but a scrub_doublets() function that does pre-processing analogously with Scrublet (but using Scanpy calls) is what imagine most people will use. . - I've moved what was sensible to use Scanpy functions. . - ... but some parts are left alone. In particular the PCA seems like it's used a bit differently in Scrublet, fitting the model to the observed transcriptomes (.fit()) and then applying dimensionality reductions to both observed and simulated matrices (.transform()). That's complex to implement with Scanpy functions (which just uses fit_transform()), so thought I'd leave that in Scrublet (which calls the same libraries anyway). Similarly the neighbour graph generation done in the classifier is quite wired in, so I haven't tried to pull it into Scanpy. I hope that this is a low-maintenance solution, allowing use of Scrublet with Scanpy functions, without a large amount of re-implementation which might cause drift wrt Scrublet itself. . It does seem to work, but happy to make any changes you or @swolock want- would just be really useful for us to have this in Scanpy :-).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1476
https://github.com/scverse/scanpy/pull/1476:410,usability,workflow,workflows,410,"Add Scrublet as an external tool; This is a PR attempting to address https://github.com/theislab/scanpy/issues/173, and building on the work of @swolock in his fork (see https://github.com/theislab/scanpy/compare/master...swolock:master). . I've taken a different approach to that fork:. - Various component functions wrapped individually (core Scrublet functionality, doublet simulation), to allow for custom workflows with different Scanpy preprocessing where required. - ... but a scrub_doublets() function that does pre-processing analogously with Scrublet (but using Scanpy calls) is what imagine most people will use. . - I've moved what was sensible to use Scanpy functions. . - ... but some parts are left alone. In particular the PCA seems like it's used a bit differently in Scrublet, fitting the model to the observed transcriptomes (.fit()) and then applying dimensionality reductions to both observed and simulated matrices (.transform()). That's complex to implement with Scanpy functions (which just uses fit_transform()), so thought I'd leave that in Scrublet (which calls the same libraries anyway). Similarly the neighbour graph generation done in the classifier is quite wired in, so I haven't tried to pull it into Scanpy. I hope that this is a low-maintenance solution, allowing use of Scrublet with Scanpy functions, without a large amount of re-implementation which might cause drift wrt Scrublet itself. . It does seem to work, but happy to make any changes you or @swolock want- would just be really useful for us to have this in Scanpy :-).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1476
https://github.com/scverse/scanpy/issues/1477:2117,availability,sli,slipstream,2117,". ipython_format = [ipython_format]. IPython.display.set_matplotlib_formats(*ipython_format). except Exception:. pass. from matplotlib import rcParams. .....etc...... ```. where the:. ```. IPython.display.set_matplotlib_formats(*ipython_format). ```. produces this ""In :"" message loop. I think this bug could be fixed by adding ""if self._is_run_from_ipython():"" before the ""try: import IPython"": . ```. def set_figure_params(. ......etc..... if self._is_run_from_ipython():. try:. import IPython. if isinstance(ipython_format, str):. ipython_format = [ipython_format]. IPython.display.set_matplotlib_formats(*ipython_format). except Exception:. pass. ```. The ""try:"" . ```. >>> import IPython. ```. doesn't throw an exception, as IPython is installed:. ```. $ pip show IPython. Name: ipython. Version: 7.18.1. Summary: IPython: Productive Interactive Computing. Home-page: https://ipython.org. Author: The IPython Development Team. Author-email: ipython-dev@python.org. License: BSD. Location: /slipstream/home/sbridgett/miniconda3/lib/python3.8/site-packages. Requires: pygments, jedi, prompt-toolkit, backcall, pexpect, setuptools, decorator, traitlets, pickleshare. Required-by: ipywidgets, ipykernel. ```. whereas the _is_run_from_ipython() will correctly ``return False``, as ``__IPYTHON__`` gives an exception:. ```. def _is_run_from_ipython():. """"""Determines whether run from Ipython. Only affects progress bars. """""". try:. __IPYTHON__. return True. except NameError:. return False. ```. #### Versions. <details>. scanpy.logging.print_versions(). -----. anndata 0.7.4. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.0. anndata 0.7.4. cairo 1.20.0. cffi 1.14.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. h5py 2.10.0. igraph 0.8.3. joblib 0.17.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. leidenalg 0.8.2. llvmlite 0.34.0. matplotlib 3.3.2. mkl 2.3.0. mpl_toolkits NA. natsort 7.0.1. numba 0.51.2. numexpr 2.7.1. numpy 1.19.2. packaging 20.4. pandas 1.1.3. pkg_r",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1477
https://github.com/scverse/scanpy/issues/1477:177,deployability,version,version,177,"set_figure_params() bug when running at command-line; - [X ] I have checked that this issue has not already been reported. - [X ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. When I run scanpy over an ssh connection to a remote Ubuntu Linux server (so not using the IPython notebooks), the scanpy ""set_figure_params(...)"" command just outputs an ""In :"", and I need to exit using [Ctrl][D]: . ### Minimal code sample (that we can copy&paste without having any data). ```. import scanpy as sc. sc.set_figure_params(figsize=(4, 4)). ```. The output in console is:. ```. In :. In :. ```. and need to press [Crtrl][D] to exit, as otherwise this just loops ""In :"" repeatedly. If I add ""ipython_format=None"":. ```. sc.set_figure_params(figsize=(4, 4), ipython_format=None). ```. then this continues without any ""In :"", and I can continue with script. . I think the reason for this is in the scanpy ""_settings.py"" file:. ```. def set_figure_params(. ......etc..... try:. import IPython. if isinstance(ipython_format, str):. ipython_format = [ipython_format]. IPython.display.set_matplotlib_formats(*ipython_format). except Exception:. pass. from matplotlib import rcParams. .....etc...... ```. where the:. ```. IPython.display.set_matplotlib_formats(*ipython_format). ```. produces this ""In :"" message loop. I think this bug could be fixed by adding ""if self._is_run_from_ipython():"" before the ""try: import IPython"": . ```. def set_figure_params(. ......etc..... if self._is_run_from_ipython():. try:. import IPython. if isinstance(ipython_format, str):. ipython_format = [ipython_format]. IPython.display.set_matplotlib_formats(*ipython_format). except Exception:. pass. ```. The ""try:"" . ```. >>> import IPython. ```. doesn't throw an exception, as IPython is installed:. ```. $ pip show IPython. Name: ipython. Version: 7.18.1. Summary: IPython: Productive Interactive Computing. Home-page: https",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1477
https://github.com/scverse/scanpy/issues/1477:890,deployability,continu,continues,890,"set_figure_params() bug when running at command-line; - [X ] I have checked that this issue has not already been reported. - [X ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. When I run scanpy over an ssh connection to a remote Ubuntu Linux server (so not using the IPython notebooks), the scanpy ""set_figure_params(...)"" command just outputs an ""In :"", and I need to exit using [Ctrl][D]: . ### Minimal code sample (that we can copy&paste without having any data). ```. import scanpy as sc. sc.set_figure_params(figsize=(4, 4)). ```. The output in console is:. ```. In :. In :. ```. and need to press [Crtrl][D] to exit, as otherwise this just loops ""In :"" repeatedly. If I add ""ipython_format=None"":. ```. sc.set_figure_params(figsize=(4, 4), ipython_format=None). ```. then this continues without any ""In :"", and I can continue with script. . I think the reason for this is in the scanpy ""_settings.py"" file:. ```. def set_figure_params(. ......etc..... try:. import IPython. if isinstance(ipython_format, str):. ipython_format = [ipython_format]. IPython.display.set_matplotlib_formats(*ipython_format). except Exception:. pass. from matplotlib import rcParams. .....etc...... ```. where the:. ```. IPython.display.set_matplotlib_formats(*ipython_format). ```. produces this ""In :"" message loop. I think this bug could be fixed by adding ""if self._is_run_from_ipython():"" before the ""try: import IPython"": . ```. def set_figure_params(. ......etc..... if self._is_run_from_ipython():. try:. import IPython. if isinstance(ipython_format, str):. ipython_format = [ipython_format]. IPython.display.set_matplotlib_formats(*ipython_format). except Exception:. pass. ```. The ""try:"" . ```. >>> import IPython. ```. doesn't throw an exception, as IPython is installed:. ```. $ pip show IPython. Name: ipython. Version: 7.18.1. Summary: IPython: Productive Interactive Computing. Home-page: https",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1477
https://github.com/scverse/scanpy/issues/1477:930,deployability,continu,continue,930,"set_figure_params() bug when running at command-line; - [X ] I have checked that this issue has not already been reported. - [X ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. When I run scanpy over an ssh connection to a remote Ubuntu Linux server (so not using the IPython notebooks), the scanpy ""set_figure_params(...)"" command just outputs an ""In :"", and I need to exit using [Ctrl][D]: . ### Minimal code sample (that we can copy&paste without having any data). ```. import scanpy as sc. sc.set_figure_params(figsize=(4, 4)). ```. The output in console is:. ```. In :. In :. ```. and need to press [Crtrl][D] to exit, as otherwise this just loops ""In :"" repeatedly. If I add ""ipython_format=None"":. ```. sc.set_figure_params(figsize=(4, 4), ipython_format=None). ```. then this continues without any ""In :"", and I can continue with script. . I think the reason for this is in the scanpy ""_settings.py"" file:. ```. def set_figure_params(. ......etc..... try:. import IPython. if isinstance(ipython_format, str):. ipython_format = [ipython_format]. IPython.display.set_matplotlib_formats(*ipython_format). except Exception:. pass. from matplotlib import rcParams. .....etc...... ```. where the:. ```. IPython.display.set_matplotlib_formats(*ipython_format). ```. produces this ""In :"" message loop. I think this bug could be fixed by adding ""if self._is_run_from_ipython():"" before the ""try: import IPython"": . ```. def set_figure_params(. ......etc..... if self._is_run_from_ipython():. try:. import IPython. if isinstance(ipython_format, str):. ipython_format = [ipython_format]. IPython.display.set_matplotlib_formats(*ipython_format). except Exception:. pass. ```. The ""try:"" . ```. >>> import IPython. ```. doesn't throw an exception, as IPython is installed:. ```. $ pip show IPython. Name: ipython. Version: 7.18.1. Summary: IPython: Productive Interactive Computing. Home-page: https",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1477
https://github.com/scverse/scanpy/issues/1477:1863,deployability,instal,installed,1863,"None). ```. then this continues without any ""In :"", and I can continue with script. . I think the reason for this is in the scanpy ""_settings.py"" file:. ```. def set_figure_params(. ......etc..... try:. import IPython. if isinstance(ipython_format, str):. ipython_format = [ipython_format]. IPython.display.set_matplotlib_formats(*ipython_format). except Exception:. pass. from matplotlib import rcParams. .....etc...... ```. where the:. ```. IPython.display.set_matplotlib_formats(*ipython_format). ```. produces this ""In :"" message loop. I think this bug could be fixed by adding ""if self._is_run_from_ipython():"" before the ""try: import IPython"": . ```. def set_figure_params(. ......etc..... if self._is_run_from_ipython():. try:. import IPython. if isinstance(ipython_format, str):. ipython_format = [ipython_format]. IPython.display.set_matplotlib_formats(*ipython_format). except Exception:. pass. ```. The ""try:"" . ```. >>> import IPython. ```. doesn't throw an exception, as IPython is installed:. ```. $ pip show IPython. Name: ipython. Version: 7.18.1. Summary: IPython: Productive Interactive Computing. Home-page: https://ipython.org. Author: The IPython Development Team. Author-email: ipython-dev@python.org. License: BSD. Location: /slipstream/home/sbridgett/miniconda3/lib/python3.8/site-packages. Requires: pygments, jedi, prompt-toolkit, backcall, pexpect, setuptools, decorator, traitlets, pickleshare. Required-by: ipywidgets, ipykernel. ```. whereas the _is_run_from_ipython() will correctly ``return False``, as ``__IPYTHON__`` gives an exception:. ```. def _is_run_from_ipython():. """"""Determines whether run from Ipython. Only affects progress bars. """""". try:. __IPYTHON__. return True. except NameError:. return False. ```. #### Versions. <details>. scanpy.logging.print_versions(). -----. anndata 0.7.4. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.0. anndata 0.7.4. cairo 1.20.0. cffi 1.14.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1477
https://github.com/scverse/scanpy/issues/1477:1915,deployability,Version,Version,1915," and I can continue with script. . I think the reason for this is in the scanpy ""_settings.py"" file:. ```. def set_figure_params(. ......etc..... try:. import IPython. if isinstance(ipython_format, str):. ipython_format = [ipython_format]. IPython.display.set_matplotlib_formats(*ipython_format). except Exception:. pass. from matplotlib import rcParams. .....etc...... ```. where the:. ```. IPython.display.set_matplotlib_formats(*ipython_format). ```. produces this ""In :"" message loop. I think this bug could be fixed by adding ""if self._is_run_from_ipython():"" before the ""try: import IPython"": . ```. def set_figure_params(. ......etc..... if self._is_run_from_ipython():. try:. import IPython. if isinstance(ipython_format, str):. ipython_format = [ipython_format]. IPython.display.set_matplotlib_formats(*ipython_format). except Exception:. pass. ```. The ""try:"" . ```. >>> import IPython. ```. doesn't throw an exception, as IPython is installed:. ```. $ pip show IPython. Name: ipython. Version: 7.18.1. Summary: IPython: Productive Interactive Computing. Home-page: https://ipython.org. Author: The IPython Development Team. Author-email: ipython-dev@python.org. License: BSD. Location: /slipstream/home/sbridgett/miniconda3/lib/python3.8/site-packages. Requires: pygments, jedi, prompt-toolkit, backcall, pexpect, setuptools, decorator, traitlets, pickleshare. Required-by: ipywidgets, ipykernel. ```. whereas the _is_run_from_ipython() will correctly ``return False``, as ``__IPYTHON__`` gives an exception:. ```. def _is_run_from_ipython():. """"""Determines whether run from Ipython. Only affects progress bars. """""". try:. __IPYTHON__. return True. except NameError:. return False. ```. #### Versions. <details>. scanpy.logging.print_versions(). -----. anndata 0.7.4. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.0. anndata 0.7.4. cairo 1.20.0. cffi 1.14.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. h5py 2.10.0. igraph 0.8.3. joblib 0.17.0. kiwisolve",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1477
https://github.com/scverse/scanpy/issues/1477:2622,deployability,Version,Versions,2622,"t_figure_params(. ......etc..... if self._is_run_from_ipython():. try:. import IPython. if isinstance(ipython_format, str):. ipython_format = [ipython_format]. IPython.display.set_matplotlib_formats(*ipython_format). except Exception:. pass. ```. The ""try:"" . ```. >>> import IPython. ```. doesn't throw an exception, as IPython is installed:. ```. $ pip show IPython. Name: ipython. Version: 7.18.1. Summary: IPython: Productive Interactive Computing. Home-page: https://ipython.org. Author: The IPython Development Team. Author-email: ipython-dev@python.org. License: BSD. Location: /slipstream/home/sbridgett/miniconda3/lib/python3.8/site-packages. Requires: pygments, jedi, prompt-toolkit, backcall, pexpect, setuptools, decorator, traitlets, pickleshare. Required-by: ipywidgets, ipykernel. ```. whereas the _is_run_from_ipython() will correctly ``return False``, as ``__IPYTHON__`` gives an exception:. ```. def _is_run_from_ipython():. """"""Determines whether run from Ipython. Only affects progress bars. """""". try:. __IPYTHON__. return True. except NameError:. return False. ```. #### Versions. <details>. scanpy.logging.print_versions(). -----. anndata 0.7.4. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.0. anndata 0.7.4. cairo 1.20.0. cffi 1.14.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. h5py 2.10.0. igraph 0.8.3. joblib 0.17.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. leidenalg 0.8.2. llvmlite 0.34.0. matplotlib 3.3.2. mkl 2.3.0. mpl_toolkits NA. natsort 7.0.1. numba 0.51.2. numexpr 2.7.1. numpy 1.19.2. packaging 20.4. pandas 1.1.3. pkg_resources NA. pyparsing 2.4.7. pytz 2020.1. scanpy 1.6.0. scipy 1.5.2. setuptools_scm NA. sinfo 0.3.1. six 1.14.0. sklearn 0.23.2. tables 3.6.1. texttable 1.6.3. typing_extensions NA. wcwidth 0.2.5. -----. Python 3.8.3 (default, May 19 2020, 18:47:26) [GCC 7.3.0]. Linux-3.13.0-143-generic-x86_64-with-glibc2.10. 32 logical CPU cores, x86_64. -----. Session information updated at 2020-11-01 11:37. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1477
https://github.com/scverse/scanpy/issues/1477:2650,deployability,log,logging,2650,"t_figure_params(. ......etc..... if self._is_run_from_ipython():. try:. import IPython. if isinstance(ipython_format, str):. ipython_format = [ipython_format]. IPython.display.set_matplotlib_formats(*ipython_format). except Exception:. pass. ```. The ""try:"" . ```. >>> import IPython. ```. doesn't throw an exception, as IPython is installed:. ```. $ pip show IPython. Name: ipython. Version: 7.18.1. Summary: IPython: Productive Interactive Computing. Home-page: https://ipython.org. Author: The IPython Development Team. Author-email: ipython-dev@python.org. License: BSD. Location: /slipstream/home/sbridgett/miniconda3/lib/python3.8/site-packages. Requires: pygments, jedi, prompt-toolkit, backcall, pexpect, setuptools, decorator, traitlets, pickleshare. Required-by: ipywidgets, ipykernel. ```. whereas the _is_run_from_ipython() will correctly ``return False``, as ``__IPYTHON__`` gives an exception:. ```. def _is_run_from_ipython():. """"""Determines whether run from Ipython. Only affects progress bars. """""". try:. __IPYTHON__. return True. except NameError:. return False. ```. #### Versions. <details>. scanpy.logging.print_versions(). -----. anndata 0.7.4. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.0. anndata 0.7.4. cairo 1.20.0. cffi 1.14.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. h5py 2.10.0. igraph 0.8.3. joblib 0.17.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. leidenalg 0.8.2. llvmlite 0.34.0. matplotlib 3.3.2. mkl 2.3.0. mpl_toolkits NA. natsort 7.0.1. numba 0.51.2. numexpr 2.7.1. numpy 1.19.2. packaging 20.4. pandas 1.1.3. pkg_resources NA. pyparsing 2.4.7. pytz 2020.1. scanpy 1.6.0. scipy 1.5.2. setuptools_scm NA. sinfo 0.3.1. six 1.14.0. sklearn 0.23.2. tables 3.6.1. texttable 1.6.3. typing_extensions NA. wcwidth 0.2.5. -----. Python 3.8.3 (default, May 19 2020, 18:47:26) [GCC 7.3.0]. Linux-3.13.0-143-generic-x86_64-with-glibc2.10. 32 logical CPU cores, x86_64. -----. Session information updated at 2020-11-01 11:37. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1477
https://github.com/scverse/scanpy/issues/1477:3437,deployability,log,logical,3437,"t_figure_params(. ......etc..... if self._is_run_from_ipython():. try:. import IPython. if isinstance(ipython_format, str):. ipython_format = [ipython_format]. IPython.display.set_matplotlib_formats(*ipython_format). except Exception:. pass. ```. The ""try:"" . ```. >>> import IPython. ```. doesn't throw an exception, as IPython is installed:. ```. $ pip show IPython. Name: ipython. Version: 7.18.1. Summary: IPython: Productive Interactive Computing. Home-page: https://ipython.org. Author: The IPython Development Team. Author-email: ipython-dev@python.org. License: BSD. Location: /slipstream/home/sbridgett/miniconda3/lib/python3.8/site-packages. Requires: pygments, jedi, prompt-toolkit, backcall, pexpect, setuptools, decorator, traitlets, pickleshare. Required-by: ipywidgets, ipykernel. ```. whereas the _is_run_from_ipython() will correctly ``return False``, as ``__IPYTHON__`` gives an exception:. ```. def _is_run_from_ipython():. """"""Determines whether run from Ipython. Only affects progress bars. """""". try:. __IPYTHON__. return True. except NameError:. return False. ```. #### Versions. <details>. scanpy.logging.print_versions(). -----. anndata 0.7.4. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.0. anndata 0.7.4. cairo 1.20.0. cffi 1.14.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. h5py 2.10.0. igraph 0.8.3. joblib 0.17.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. leidenalg 0.8.2. llvmlite 0.34.0. matplotlib 3.3.2. mkl 2.3.0. mpl_toolkits NA. natsort 7.0.1. numba 0.51.2. numexpr 2.7.1. numpy 1.19.2. packaging 20.4. pandas 1.1.3. pkg_resources NA. pyparsing 2.4.7. pytz 2020.1. scanpy 1.6.0. scipy 1.5.2. setuptools_scm NA. sinfo 0.3.1. six 1.14.0. sklearn 0.23.2. tables 3.6.1. texttable 1.6.3. typing_extensions NA. wcwidth 0.2.5. -----. Python 3.8.3 (default, May 19 2020, 18:47:26) [GCC 7.3.0]. Linux-3.13.0-143-generic-x86_64-with-glibc2.10. 32 logical CPU cores, x86_64. -----. Session information updated at 2020-11-01 11:37. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1477
https://github.com/scverse/scanpy/issues/1477:3491,deployability,updat,updated,3491,"t_figure_params(. ......etc..... if self._is_run_from_ipython():. try:. import IPython. if isinstance(ipython_format, str):. ipython_format = [ipython_format]. IPython.display.set_matplotlib_formats(*ipython_format). except Exception:. pass. ```. The ""try:"" . ```. >>> import IPython. ```. doesn't throw an exception, as IPython is installed:. ```. $ pip show IPython. Name: ipython. Version: 7.18.1. Summary: IPython: Productive Interactive Computing. Home-page: https://ipython.org. Author: The IPython Development Team. Author-email: ipython-dev@python.org. License: BSD. Location: /slipstream/home/sbridgett/miniconda3/lib/python3.8/site-packages. Requires: pygments, jedi, prompt-toolkit, backcall, pexpect, setuptools, decorator, traitlets, pickleshare. Required-by: ipywidgets, ipykernel. ```. whereas the _is_run_from_ipython() will correctly ``return False``, as ``__IPYTHON__`` gives an exception:. ```. def _is_run_from_ipython():. """"""Determines whether run from Ipython. Only affects progress bars. """""". try:. __IPYTHON__. return True. except NameError:. return False. ```. #### Versions. <details>. scanpy.logging.print_versions(). -----. anndata 0.7.4. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.0. anndata 0.7.4. cairo 1.20.0. cffi 1.14.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. h5py 2.10.0. igraph 0.8.3. joblib 0.17.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. leidenalg 0.8.2. llvmlite 0.34.0. matplotlib 3.3.2. mkl 2.3.0. mpl_toolkits NA. natsort 7.0.1. numba 0.51.2. numexpr 2.7.1. numpy 1.19.2. packaging 20.4. pandas 1.1.3. pkg_resources NA. pyparsing 2.4.7. pytz 2020.1. scanpy 1.6.0. scipy 1.5.2. setuptools_scm NA. sinfo 0.3.1. six 1.14.0. sklearn 0.23.2. tables 3.6.1. texttable 1.6.3. typing_extensions NA. wcwidth 0.2.5. -----. Python 3.8.3 (default, May 19 2020, 18:47:26) [GCC 7.3.0]. Linux-3.13.0-143-generic-x86_64-with-glibc2.10. 32 logical CPU cores, x86_64. -----. Session information updated at 2020-11-01 11:37. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1477
https://github.com/scverse/scanpy/issues/1477:3445,energy efficiency,CPU,CPU,3445,"t_figure_params(. ......etc..... if self._is_run_from_ipython():. try:. import IPython. if isinstance(ipython_format, str):. ipython_format = [ipython_format]. IPython.display.set_matplotlib_formats(*ipython_format). except Exception:. pass. ```. The ""try:"" . ```. >>> import IPython. ```. doesn't throw an exception, as IPython is installed:. ```. $ pip show IPython. Name: ipython. Version: 7.18.1. Summary: IPython: Productive Interactive Computing. Home-page: https://ipython.org. Author: The IPython Development Team. Author-email: ipython-dev@python.org. License: BSD. Location: /slipstream/home/sbridgett/miniconda3/lib/python3.8/site-packages. Requires: pygments, jedi, prompt-toolkit, backcall, pexpect, setuptools, decorator, traitlets, pickleshare. Required-by: ipywidgets, ipykernel. ```. whereas the _is_run_from_ipython() will correctly ``return False``, as ``__IPYTHON__`` gives an exception:. ```. def _is_run_from_ipython():. """"""Determines whether run from Ipython. Only affects progress bars. """""". try:. __IPYTHON__. return True. except NameError:. return False. ```. #### Versions. <details>. scanpy.logging.print_versions(). -----. anndata 0.7.4. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.0. anndata 0.7.4. cairo 1.20.0. cffi 1.14.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. h5py 2.10.0. igraph 0.8.3. joblib 0.17.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. leidenalg 0.8.2. llvmlite 0.34.0. matplotlib 3.3.2. mkl 2.3.0. mpl_toolkits NA. natsort 7.0.1. numba 0.51.2. numexpr 2.7.1. numpy 1.19.2. packaging 20.4. pandas 1.1.3. pkg_resources NA. pyparsing 2.4.7. pytz 2020.1. scanpy 1.6.0. scipy 1.5.2. setuptools_scm NA. sinfo 0.3.1. six 1.14.0. sklearn 0.23.2. tables 3.6.1. texttable 1.6.3. typing_extensions NA. wcwidth 0.2.5. -----. Python 3.8.3 (default, May 19 2020, 18:47:26) [GCC 7.3.0]. Linux-3.13.0-143-generic-x86_64-with-glibc2.10. 32 logical CPU cores, x86_64. -----. Session information updated at 2020-11-01 11:37. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1477
https://github.com/scverse/scanpy/issues/1477:3449,energy efficiency,core,cores,3449,"t_figure_params(. ......etc..... if self._is_run_from_ipython():. try:. import IPython. if isinstance(ipython_format, str):. ipython_format = [ipython_format]. IPython.display.set_matplotlib_formats(*ipython_format). except Exception:. pass. ```. The ""try:"" . ```. >>> import IPython. ```. doesn't throw an exception, as IPython is installed:. ```. $ pip show IPython. Name: ipython. Version: 7.18.1. Summary: IPython: Productive Interactive Computing. Home-page: https://ipython.org. Author: The IPython Development Team. Author-email: ipython-dev@python.org. License: BSD. Location: /slipstream/home/sbridgett/miniconda3/lib/python3.8/site-packages. Requires: pygments, jedi, prompt-toolkit, backcall, pexpect, setuptools, decorator, traitlets, pickleshare. Required-by: ipywidgets, ipykernel. ```. whereas the _is_run_from_ipython() will correctly ``return False``, as ``__IPYTHON__`` gives an exception:. ```. def _is_run_from_ipython():. """"""Determines whether run from Ipython. Only affects progress bars. """""". try:. __IPYTHON__. return True. except NameError:. return False. ```. #### Versions. <details>. scanpy.logging.print_versions(). -----. anndata 0.7.4. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.0. anndata 0.7.4. cairo 1.20.0. cffi 1.14.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. h5py 2.10.0. igraph 0.8.3. joblib 0.17.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. leidenalg 0.8.2. llvmlite 0.34.0. matplotlib 3.3.2. mkl 2.3.0. mpl_toolkits NA. natsort 7.0.1. numba 0.51.2. numexpr 2.7.1. numpy 1.19.2. packaging 20.4. pandas 1.1.3. pkg_resources NA. pyparsing 2.4.7. pytz 2020.1. scanpy 1.6.0. scipy 1.5.2. setuptools_scm NA. sinfo 0.3.1. six 1.14.0. sklearn 0.23.2. tables 3.6.1. texttable 1.6.3. typing_extensions NA. wcwidth 0.2.5. -----. Python 3.8.3 (default, May 19 2020, 18:47:26) [GCC 7.3.0]. Linux-3.13.0-143-generic-x86_64-with-glibc2.10. 32 logical CPU cores, x86_64. -----. Session information updated at 2020-11-01 11:37. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1477
https://github.com/scverse/scanpy/issues/1477:177,integrability,version,version,177,"set_figure_params() bug when running at command-line; - [X ] I have checked that this issue has not already been reported. - [X ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. When I run scanpy over an ssh connection to a remote Ubuntu Linux server (so not using the IPython notebooks), the scanpy ""set_figure_params(...)"" command just outputs an ""In :"", and I need to exit using [Ctrl][D]: . ### Minimal code sample (that we can copy&paste without having any data). ```. import scanpy as sc. sc.set_figure_params(figsize=(4, 4)). ```. The output in console is:. ```. In :. In :. ```. and need to press [Crtrl][D] to exit, as otherwise this just loops ""In :"" repeatedly. If I add ""ipython_format=None"":. ```. sc.set_figure_params(figsize=(4, 4), ipython_format=None). ```. then this continues without any ""In :"", and I can continue with script. . I think the reason for this is in the scanpy ""_settings.py"" file:. ```. def set_figure_params(. ......etc..... try:. import IPython. if isinstance(ipython_format, str):. ipython_format = [ipython_format]. IPython.display.set_matplotlib_formats(*ipython_format). except Exception:. pass. from matplotlib import rcParams. .....etc...... ```. where the:. ```. IPython.display.set_matplotlib_formats(*ipython_format). ```. produces this ""In :"" message loop. I think this bug could be fixed by adding ""if self._is_run_from_ipython():"" before the ""try: import IPython"": . ```. def set_figure_params(. ......etc..... if self._is_run_from_ipython():. try:. import IPython. if isinstance(ipython_format, str):. ipython_format = [ipython_format]. IPython.display.set_matplotlib_formats(*ipython_format). except Exception:. pass. ```. The ""try:"" . ```. >>> import IPython. ```. doesn't throw an exception, as IPython is installed:. ```. $ pip show IPython. Name: ipython. Version: 7.18.1. Summary: IPython: Productive Interactive Computing. Home-page: https",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1477
https://github.com/scverse/scanpy/issues/1477:1394,integrability,messag,message,1394,"scanpy ""set_figure_params(...)"" command just outputs an ""In :"", and I need to exit using [Ctrl][D]: . ### Minimal code sample (that we can copy&paste without having any data). ```. import scanpy as sc. sc.set_figure_params(figsize=(4, 4)). ```. The output in console is:. ```. In :. In :. ```. and need to press [Crtrl][D] to exit, as otherwise this just loops ""In :"" repeatedly. If I add ""ipython_format=None"":. ```. sc.set_figure_params(figsize=(4, 4), ipython_format=None). ```. then this continues without any ""In :"", and I can continue with script. . I think the reason for this is in the scanpy ""_settings.py"" file:. ```. def set_figure_params(. ......etc..... try:. import IPython. if isinstance(ipython_format, str):. ipython_format = [ipython_format]. IPython.display.set_matplotlib_formats(*ipython_format). except Exception:. pass. from matplotlib import rcParams. .....etc...... ```. where the:. ```. IPython.display.set_matplotlib_formats(*ipython_format). ```. produces this ""In :"" message loop. I think this bug could be fixed by adding ""if self._is_run_from_ipython():"" before the ""try: import IPython"": . ```. def set_figure_params(. ......etc..... if self._is_run_from_ipython():. try:. import IPython. if isinstance(ipython_format, str):. ipython_format = [ipython_format]. IPython.display.set_matplotlib_formats(*ipython_format). except Exception:. pass. ```. The ""try:"" . ```. >>> import IPython. ```. doesn't throw an exception, as IPython is installed:. ```. $ pip show IPython. Name: ipython. Version: 7.18.1. Summary: IPython: Productive Interactive Computing. Home-page: https://ipython.org. Author: The IPython Development Team. Author-email: ipython-dev@python.org. License: BSD. Location: /slipstream/home/sbridgett/miniconda3/lib/python3.8/site-packages. Requires: pygments, jedi, prompt-toolkit, backcall, pexpect, setuptools, decorator, traitlets, pickleshare. Required-by: ipywidgets, ipykernel. ```. whereas the _is_run_from_ipython() will correctly ``return False``",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1477
https://github.com/scverse/scanpy/issues/1477:1915,integrability,Version,Version,1915," and I can continue with script. . I think the reason for this is in the scanpy ""_settings.py"" file:. ```. def set_figure_params(. ......etc..... try:. import IPython. if isinstance(ipython_format, str):. ipython_format = [ipython_format]. IPython.display.set_matplotlib_formats(*ipython_format). except Exception:. pass. from matplotlib import rcParams. .....etc...... ```. where the:. ```. IPython.display.set_matplotlib_formats(*ipython_format). ```. produces this ""In :"" message loop. I think this bug could be fixed by adding ""if self._is_run_from_ipython():"" before the ""try: import IPython"": . ```. def set_figure_params(. ......etc..... if self._is_run_from_ipython():. try:. import IPython. if isinstance(ipython_format, str):. ipython_format = [ipython_format]. IPython.display.set_matplotlib_formats(*ipython_format). except Exception:. pass. ```. The ""try:"" . ```. >>> import IPython. ```. doesn't throw an exception, as IPython is installed:. ```. $ pip show IPython. Name: ipython. Version: 7.18.1. Summary: IPython: Productive Interactive Computing. Home-page: https://ipython.org. Author: The IPython Development Team. Author-email: ipython-dev@python.org. License: BSD. Location: /slipstream/home/sbridgett/miniconda3/lib/python3.8/site-packages. Requires: pygments, jedi, prompt-toolkit, backcall, pexpect, setuptools, decorator, traitlets, pickleshare. Required-by: ipywidgets, ipykernel. ```. whereas the _is_run_from_ipython() will correctly ``return False``, as ``__IPYTHON__`` gives an exception:. ```. def _is_run_from_ipython():. """"""Determines whether run from Ipython. Only affects progress bars. """""". try:. __IPYTHON__. return True. except NameError:. return False. ```. #### Versions. <details>. scanpy.logging.print_versions(). -----. anndata 0.7.4. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.0. anndata 0.7.4. cairo 1.20.0. cffi 1.14.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. h5py 2.10.0. igraph 0.8.3. joblib 0.17.0. kiwisolve",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1477
https://github.com/scverse/scanpy/issues/1477:2622,integrability,Version,Versions,2622,"t_figure_params(. ......etc..... if self._is_run_from_ipython():. try:. import IPython. if isinstance(ipython_format, str):. ipython_format = [ipython_format]. IPython.display.set_matplotlib_formats(*ipython_format). except Exception:. pass. ```. The ""try:"" . ```. >>> import IPython. ```. doesn't throw an exception, as IPython is installed:. ```. $ pip show IPython. Name: ipython. Version: 7.18.1. Summary: IPython: Productive Interactive Computing. Home-page: https://ipython.org. Author: The IPython Development Team. Author-email: ipython-dev@python.org. License: BSD. Location: /slipstream/home/sbridgett/miniconda3/lib/python3.8/site-packages. Requires: pygments, jedi, prompt-toolkit, backcall, pexpect, setuptools, decorator, traitlets, pickleshare. Required-by: ipywidgets, ipykernel. ```. whereas the _is_run_from_ipython() will correctly ``return False``, as ``__IPYTHON__`` gives an exception:. ```. def _is_run_from_ipython():. """"""Determines whether run from Ipython. Only affects progress bars. """""". try:. __IPYTHON__. return True. except NameError:. return False. ```. #### Versions. <details>. scanpy.logging.print_versions(). -----. anndata 0.7.4. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.0. anndata 0.7.4. cairo 1.20.0. cffi 1.14.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. h5py 2.10.0. igraph 0.8.3. joblib 0.17.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. leidenalg 0.8.2. llvmlite 0.34.0. matplotlib 3.3.2. mkl 2.3.0. mpl_toolkits NA. natsort 7.0.1. numba 0.51.2. numexpr 2.7.1. numpy 1.19.2. packaging 20.4. pandas 1.1.3. pkg_resources NA. pyparsing 2.4.7. pytz 2020.1. scanpy 1.6.0. scipy 1.5.2. setuptools_scm NA. sinfo 0.3.1. six 1.14.0. sklearn 0.23.2. tables 3.6.1. texttable 1.6.3. typing_extensions NA. wcwidth 0.2.5. -----. Python 3.8.3 (default, May 19 2020, 18:47:26) [GCC 7.3.0]. Linux-3.13.0-143-generic-x86_64-with-glibc2.10. 32 logical CPU cores, x86_64. -----. Session information updated at 2020-11-01 11:37. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1477
https://github.com/scverse/scanpy/issues/1477:1394,interoperability,messag,message,1394,"scanpy ""set_figure_params(...)"" command just outputs an ""In :"", and I need to exit using [Ctrl][D]: . ### Minimal code sample (that we can copy&paste without having any data). ```. import scanpy as sc. sc.set_figure_params(figsize=(4, 4)). ```. The output in console is:. ```. In :. In :. ```. and need to press [Crtrl][D] to exit, as otherwise this just loops ""In :"" repeatedly. If I add ""ipython_format=None"":. ```. sc.set_figure_params(figsize=(4, 4), ipython_format=None). ```. then this continues without any ""In :"", and I can continue with script. . I think the reason for this is in the scanpy ""_settings.py"" file:. ```. def set_figure_params(. ......etc..... try:. import IPython. if isinstance(ipython_format, str):. ipython_format = [ipython_format]. IPython.display.set_matplotlib_formats(*ipython_format). except Exception:. pass. from matplotlib import rcParams. .....etc...... ```. where the:. ```. IPython.display.set_matplotlib_formats(*ipython_format). ```. produces this ""In :"" message loop. I think this bug could be fixed by adding ""if self._is_run_from_ipython():"" before the ""try: import IPython"": . ```. def set_figure_params(. ......etc..... if self._is_run_from_ipython():. try:. import IPython. if isinstance(ipython_format, str):. ipython_format = [ipython_format]. IPython.display.set_matplotlib_formats(*ipython_format). except Exception:. pass. ```. The ""try:"" . ```. >>> import IPython. ```. doesn't throw an exception, as IPython is installed:. ```. $ pip show IPython. Name: ipython. Version: 7.18.1. Summary: IPython: Productive Interactive Computing. Home-page: https://ipython.org. Author: The IPython Development Team. Author-email: ipython-dev@python.org. License: BSD. Location: /slipstream/home/sbridgett/miniconda3/lib/python3.8/site-packages. Requires: pygments, jedi, prompt-toolkit, backcall, pexpect, setuptools, decorator, traitlets, pickleshare. Required-by: ipywidgets, ipykernel. ```. whereas the _is_run_from_ipython() will correctly ``return False``",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1477
https://github.com/scverse/scanpy/issues/1477:177,modifiability,version,version,177,"set_figure_params() bug when running at command-line; - [X ] I have checked that this issue has not already been reported. - [X ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. When I run scanpy over an ssh connection to a remote Ubuntu Linux server (so not using the IPython notebooks), the scanpy ""set_figure_params(...)"" command just outputs an ""In :"", and I need to exit using [Ctrl][D]: . ### Minimal code sample (that we can copy&paste without having any data). ```. import scanpy as sc. sc.set_figure_params(figsize=(4, 4)). ```. The output in console is:. ```. In :. In :. ```. and need to press [Crtrl][D] to exit, as otherwise this just loops ""In :"" repeatedly. If I add ""ipython_format=None"":. ```. sc.set_figure_params(figsize=(4, 4), ipython_format=None). ```. then this continues without any ""In :"", and I can continue with script. . I think the reason for this is in the scanpy ""_settings.py"" file:. ```. def set_figure_params(. ......etc..... try:. import IPython. if isinstance(ipython_format, str):. ipython_format = [ipython_format]. IPython.display.set_matplotlib_formats(*ipython_format). except Exception:. pass. from matplotlib import rcParams. .....etc...... ```. where the:. ```. IPython.display.set_matplotlib_formats(*ipython_format). ```. produces this ""In :"" message loop. I think this bug could be fixed by adding ""if self._is_run_from_ipython():"" before the ""try: import IPython"": . ```. def set_figure_params(. ......etc..... if self._is_run_from_ipython():. try:. import IPython. if isinstance(ipython_format, str):. ipython_format = [ipython_format]. IPython.display.set_matplotlib_formats(*ipython_format). except Exception:. pass. ```. The ""try:"" . ```. >>> import IPython. ```. doesn't throw an exception, as IPython is installed:. ```. $ pip show IPython. Name: ipython. Version: 7.18.1. Summary: IPython: Productive Interactive Computing. Home-page: https",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1477
https://github.com/scverse/scanpy/issues/1477:1915,modifiability,Version,Version,1915," and I can continue with script. . I think the reason for this is in the scanpy ""_settings.py"" file:. ```. def set_figure_params(. ......etc..... try:. import IPython. if isinstance(ipython_format, str):. ipython_format = [ipython_format]. IPython.display.set_matplotlib_formats(*ipython_format). except Exception:. pass. from matplotlib import rcParams. .....etc...... ```. where the:. ```. IPython.display.set_matplotlib_formats(*ipython_format). ```. produces this ""In :"" message loop. I think this bug could be fixed by adding ""if self._is_run_from_ipython():"" before the ""try: import IPython"": . ```. def set_figure_params(. ......etc..... if self._is_run_from_ipython():. try:. import IPython. if isinstance(ipython_format, str):. ipython_format = [ipython_format]. IPython.display.set_matplotlib_formats(*ipython_format). except Exception:. pass. ```. The ""try:"" . ```. >>> import IPython. ```. doesn't throw an exception, as IPython is installed:. ```. $ pip show IPython. Name: ipython. Version: 7.18.1. Summary: IPython: Productive Interactive Computing. Home-page: https://ipython.org. Author: The IPython Development Team. Author-email: ipython-dev@python.org. License: BSD. Location: /slipstream/home/sbridgett/miniconda3/lib/python3.8/site-packages. Requires: pygments, jedi, prompt-toolkit, backcall, pexpect, setuptools, decorator, traitlets, pickleshare. Required-by: ipywidgets, ipykernel. ```. whereas the _is_run_from_ipython() will correctly ``return False``, as ``__IPYTHON__`` gives an exception:. ```. def _is_run_from_ipython():. """"""Determines whether run from Ipython. Only affects progress bars. """""". try:. __IPYTHON__. return True. except NameError:. return False. ```. #### Versions. <details>. scanpy.logging.print_versions(). -----. anndata 0.7.4. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.0. anndata 0.7.4. cairo 1.20.0. cffi 1.14.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. h5py 2.10.0. igraph 0.8.3. joblib 0.17.0. kiwisolve",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1477
https://github.com/scverse/scanpy/issues/1477:2173,modifiability,pac,packages,2173,"t_matplotlib_formats(*ipython_format). except Exception:. pass. from matplotlib import rcParams. .....etc...... ```. where the:. ```. IPython.display.set_matplotlib_formats(*ipython_format). ```. produces this ""In :"" message loop. I think this bug could be fixed by adding ""if self._is_run_from_ipython():"" before the ""try: import IPython"": . ```. def set_figure_params(. ......etc..... if self._is_run_from_ipython():. try:. import IPython. if isinstance(ipython_format, str):. ipython_format = [ipython_format]. IPython.display.set_matplotlib_formats(*ipython_format). except Exception:. pass. ```. The ""try:"" . ```. >>> import IPython. ```. doesn't throw an exception, as IPython is installed:. ```. $ pip show IPython. Name: ipython. Version: 7.18.1. Summary: IPython: Productive Interactive Computing. Home-page: https://ipython.org. Author: The IPython Development Team. Author-email: ipython-dev@python.org. License: BSD. Location: /slipstream/home/sbridgett/miniconda3/lib/python3.8/site-packages. Requires: pygments, jedi, prompt-toolkit, backcall, pexpect, setuptools, decorator, traitlets, pickleshare. Required-by: ipywidgets, ipykernel. ```. whereas the _is_run_from_ipython() will correctly ``return False``, as ``__IPYTHON__`` gives an exception:. ```. def _is_run_from_ipython():. """"""Determines whether run from Ipython. Only affects progress bars. """""". try:. __IPYTHON__. return True. except NameError:. return False. ```. #### Versions. <details>. scanpy.logging.print_versions(). -----. anndata 0.7.4. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.0. anndata 0.7.4. cairo 1.20.0. cffi 1.14.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. h5py 2.10.0. igraph 0.8.3. joblib 0.17.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. leidenalg 0.8.2. llvmlite 0.34.0. matplotlib 3.3.2. mkl 2.3.0. mpl_toolkits NA. natsort 7.0.1. numba 0.51.2. numexpr 2.7.1. numpy 1.19.2. packaging 20.4. pandas 1.1.3. pkg_resources NA. pyparsing 2.4.7. pytz 2020.1. scanpy 1.6.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1477
https://github.com/scverse/scanpy/issues/1477:2256,modifiability,deco,decorator,2256,"rt rcParams. .....etc...... ```. where the:. ```. IPython.display.set_matplotlib_formats(*ipython_format). ```. produces this ""In :"" message loop. I think this bug could be fixed by adding ""if self._is_run_from_ipython():"" before the ""try: import IPython"": . ```. def set_figure_params(. ......etc..... if self._is_run_from_ipython():. try:. import IPython. if isinstance(ipython_format, str):. ipython_format = [ipython_format]. IPython.display.set_matplotlib_formats(*ipython_format). except Exception:. pass. ```. The ""try:"" . ```. >>> import IPython. ```. doesn't throw an exception, as IPython is installed:. ```. $ pip show IPython. Name: ipython. Version: 7.18.1. Summary: IPython: Productive Interactive Computing. Home-page: https://ipython.org. Author: The IPython Development Team. Author-email: ipython-dev@python.org. License: BSD. Location: /slipstream/home/sbridgett/miniconda3/lib/python3.8/site-packages. Requires: pygments, jedi, prompt-toolkit, backcall, pexpect, setuptools, decorator, traitlets, pickleshare. Required-by: ipywidgets, ipykernel. ```. whereas the _is_run_from_ipython() will correctly ``return False``, as ``__IPYTHON__`` gives an exception:. ```. def _is_run_from_ipython():. """"""Determines whether run from Ipython. Only affects progress bars. """""". try:. __IPYTHON__. return True. except NameError:. return False. ```. #### Versions. <details>. scanpy.logging.print_versions(). -----. anndata 0.7.4. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.0. anndata 0.7.4. cairo 1.20.0. cffi 1.14.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. h5py 2.10.0. igraph 0.8.3. joblib 0.17.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. leidenalg 0.8.2. llvmlite 0.34.0. matplotlib 3.3.2. mkl 2.3.0. mpl_toolkits NA. natsort 7.0.1. numba 0.51.2. numexpr 2.7.1. numpy 1.19.2. packaging 20.4. pandas 1.1.3. pkg_resources NA. pyparsing 2.4.7. pytz 2020.1. scanpy 1.6.0. scipy 1.5.2. setuptools_scm NA. sinfo 0.3.1. six 1.14.0. sklearn 0.23.2. tables 3.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1477
https://github.com/scverse/scanpy/issues/1477:2622,modifiability,Version,Versions,2622,"t_figure_params(. ......etc..... if self._is_run_from_ipython():. try:. import IPython. if isinstance(ipython_format, str):. ipython_format = [ipython_format]. IPython.display.set_matplotlib_formats(*ipython_format). except Exception:. pass. ```. The ""try:"" . ```. >>> import IPython. ```. doesn't throw an exception, as IPython is installed:. ```. $ pip show IPython. Name: ipython. Version: 7.18.1. Summary: IPython: Productive Interactive Computing. Home-page: https://ipython.org. Author: The IPython Development Team. Author-email: ipython-dev@python.org. License: BSD. Location: /slipstream/home/sbridgett/miniconda3/lib/python3.8/site-packages. Requires: pygments, jedi, prompt-toolkit, backcall, pexpect, setuptools, decorator, traitlets, pickleshare. Required-by: ipywidgets, ipykernel. ```. whereas the _is_run_from_ipython() will correctly ``return False``, as ``__IPYTHON__`` gives an exception:. ```. def _is_run_from_ipython():. """"""Determines whether run from Ipython. Only affects progress bars. """""". try:. __IPYTHON__. return True. except NameError:. return False. ```. #### Versions. <details>. scanpy.logging.print_versions(). -----. anndata 0.7.4. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.0. anndata 0.7.4. cairo 1.20.0. cffi 1.14.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. h5py 2.10.0. igraph 0.8.3. joblib 0.17.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. leidenalg 0.8.2. llvmlite 0.34.0. matplotlib 3.3.2. mkl 2.3.0. mpl_toolkits NA. natsort 7.0.1. numba 0.51.2. numexpr 2.7.1. numpy 1.19.2. packaging 20.4. pandas 1.1.3. pkg_resources NA. pyparsing 2.4.7. pytz 2020.1. scanpy 1.6.0. scipy 1.5.2. setuptools_scm NA. sinfo 0.3.1. six 1.14.0. sklearn 0.23.2. tables 3.6.1. texttable 1.6.3. typing_extensions NA. wcwidth 0.2.5. -----. Python 3.8.3 (default, May 19 2020, 18:47:26) [GCC 7.3.0]. Linux-3.13.0-143-generic-x86_64-with-glibc2.10. 32 logical CPU cores, x86_64. -----. Session information updated at 2020-11-01 11:37. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1477
https://github.com/scverse/scanpy/issues/1477:3087,modifiability,pac,packaging,3087,"t_figure_params(. ......etc..... if self._is_run_from_ipython():. try:. import IPython. if isinstance(ipython_format, str):. ipython_format = [ipython_format]. IPython.display.set_matplotlib_formats(*ipython_format). except Exception:. pass. ```. The ""try:"" . ```. >>> import IPython. ```. doesn't throw an exception, as IPython is installed:. ```. $ pip show IPython. Name: ipython. Version: 7.18.1. Summary: IPython: Productive Interactive Computing. Home-page: https://ipython.org. Author: The IPython Development Team. Author-email: ipython-dev@python.org. License: BSD. Location: /slipstream/home/sbridgett/miniconda3/lib/python3.8/site-packages. Requires: pygments, jedi, prompt-toolkit, backcall, pexpect, setuptools, decorator, traitlets, pickleshare. Required-by: ipywidgets, ipykernel. ```. whereas the _is_run_from_ipython() will correctly ``return False``, as ``__IPYTHON__`` gives an exception:. ```. def _is_run_from_ipython():. """"""Determines whether run from Ipython. Only affects progress bars. """""". try:. __IPYTHON__. return True. except NameError:. return False. ```. #### Versions. <details>. scanpy.logging.print_versions(). -----. anndata 0.7.4. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.0. anndata 0.7.4. cairo 1.20.0. cffi 1.14.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. h5py 2.10.0. igraph 0.8.3. joblib 0.17.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. leidenalg 0.8.2. llvmlite 0.34.0. matplotlib 3.3.2. mkl 2.3.0. mpl_toolkits NA. natsort 7.0.1. numba 0.51.2. numexpr 2.7.1. numpy 1.19.2. packaging 20.4. pandas 1.1.3. pkg_resources NA. pyparsing 2.4.7. pytz 2020.1. scanpy 1.6.0. scipy 1.5.2. setuptools_scm NA. sinfo 0.3.1. six 1.14.0. sklearn 0.23.2. tables 3.6.1. texttable 1.6.3. typing_extensions NA. wcwidth 0.2.5. -----. Python 3.8.3 (default, May 19 2020, 18:47:26) [GCC 7.3.0]. Linux-3.13.0-143-generic-x86_64-with-glibc2.10. 32 logical CPU cores, x86_64. -----. Session information updated at 2020-11-01 11:37. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1477
https://github.com/scverse/scanpy/issues/1477:3445,performance,CPU,CPU,3445,"t_figure_params(. ......etc..... if self._is_run_from_ipython():. try:. import IPython. if isinstance(ipython_format, str):. ipython_format = [ipython_format]. IPython.display.set_matplotlib_formats(*ipython_format). except Exception:. pass. ```. The ""try:"" . ```. >>> import IPython. ```. doesn't throw an exception, as IPython is installed:. ```. $ pip show IPython. Name: ipython. Version: 7.18.1. Summary: IPython: Productive Interactive Computing. Home-page: https://ipython.org. Author: The IPython Development Team. Author-email: ipython-dev@python.org. License: BSD. Location: /slipstream/home/sbridgett/miniconda3/lib/python3.8/site-packages. Requires: pygments, jedi, prompt-toolkit, backcall, pexpect, setuptools, decorator, traitlets, pickleshare. Required-by: ipywidgets, ipykernel. ```. whereas the _is_run_from_ipython() will correctly ``return False``, as ``__IPYTHON__`` gives an exception:. ```. def _is_run_from_ipython():. """"""Determines whether run from Ipython. Only affects progress bars. """""". try:. __IPYTHON__. return True. except NameError:. return False. ```. #### Versions. <details>. scanpy.logging.print_versions(). -----. anndata 0.7.4. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.0. anndata 0.7.4. cairo 1.20.0. cffi 1.14.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. h5py 2.10.0. igraph 0.8.3. joblib 0.17.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. leidenalg 0.8.2. llvmlite 0.34.0. matplotlib 3.3.2. mkl 2.3.0. mpl_toolkits NA. natsort 7.0.1. numba 0.51.2. numexpr 2.7.1. numpy 1.19.2. packaging 20.4. pandas 1.1.3. pkg_resources NA. pyparsing 2.4.7. pytz 2020.1. scanpy 1.6.0. scipy 1.5.2. setuptools_scm NA. sinfo 0.3.1. six 1.14.0. sklearn 0.23.2. tables 3.6.1. texttable 1.6.3. typing_extensions NA. wcwidth 0.2.5. -----. Python 3.8.3 (default, May 19 2020, 18:47:26) [GCC 7.3.0]. Linux-3.13.0-143-generic-x86_64-with-glibc2.10. 32 logical CPU cores, x86_64. -----. Session information updated at 2020-11-01 11:37. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1477
https://github.com/scverse/scanpy/issues/1477:1821,reliability,doe,doesn,1821,"igure_params(figsize=(4, 4), ipython_format=None). ```. then this continues without any ""In :"", and I can continue with script. . I think the reason for this is in the scanpy ""_settings.py"" file:. ```. def set_figure_params(. ......etc..... try:. import IPython. if isinstance(ipython_format, str):. ipython_format = [ipython_format]. IPython.display.set_matplotlib_formats(*ipython_format). except Exception:. pass. from matplotlib import rcParams. .....etc...... ```. where the:. ```. IPython.display.set_matplotlib_formats(*ipython_format). ```. produces this ""In :"" message loop. I think this bug could be fixed by adding ""if self._is_run_from_ipython():"" before the ""try: import IPython"": . ```. def set_figure_params(. ......etc..... if self._is_run_from_ipython():. try:. import IPython. if isinstance(ipython_format, str):. ipython_format = [ipython_format]. IPython.display.set_matplotlib_formats(*ipython_format). except Exception:. pass. ```. The ""try:"" . ```. >>> import IPython. ```. doesn't throw an exception, as IPython is installed:. ```. $ pip show IPython. Name: ipython. Version: 7.18.1. Summary: IPython: Productive Interactive Computing. Home-page: https://ipython.org. Author: The IPython Development Team. Author-email: ipython-dev@python.org. License: BSD. Location: /slipstream/home/sbridgett/miniconda3/lib/python3.8/site-packages. Requires: pygments, jedi, prompt-toolkit, backcall, pexpect, setuptools, decorator, traitlets, pickleshare. Required-by: ipywidgets, ipykernel. ```. whereas the _is_run_from_ipython() will correctly ``return False``, as ``__IPYTHON__`` gives an exception:. ```. def _is_run_from_ipython():. """"""Determines whether run from Ipython. Only affects progress bars. """""". try:. __IPYTHON__. return True. except NameError:. return False. ```. #### Versions. <details>. scanpy.logging.print_versions(). -----. anndata 0.7.4. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.0. anndata 0.7.4. cairo 1.20.0. cffi 1.14.0. colorama 0.4.4. cycler 0.10.0. cython_r",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1477
https://github.com/scverse/scanpy/issues/1477:2117,reliability,sli,slipstream,2117,". ipython_format = [ipython_format]. IPython.display.set_matplotlib_formats(*ipython_format). except Exception:. pass. from matplotlib import rcParams. .....etc...... ```. where the:. ```. IPython.display.set_matplotlib_formats(*ipython_format). ```. produces this ""In :"" message loop. I think this bug could be fixed by adding ""if self._is_run_from_ipython():"" before the ""try: import IPython"": . ```. def set_figure_params(. ......etc..... if self._is_run_from_ipython():. try:. import IPython. if isinstance(ipython_format, str):. ipython_format = [ipython_format]. IPython.display.set_matplotlib_formats(*ipython_format). except Exception:. pass. ```. The ""try:"" . ```. >>> import IPython. ```. doesn't throw an exception, as IPython is installed:. ```. $ pip show IPython. Name: ipython. Version: 7.18.1. Summary: IPython: Productive Interactive Computing. Home-page: https://ipython.org. Author: The IPython Development Team. Author-email: ipython-dev@python.org. License: BSD. Location: /slipstream/home/sbridgett/miniconda3/lib/python3.8/site-packages. Requires: pygments, jedi, prompt-toolkit, backcall, pexpect, setuptools, decorator, traitlets, pickleshare. Required-by: ipywidgets, ipykernel. ```. whereas the _is_run_from_ipython() will correctly ``return False``, as ``__IPYTHON__`` gives an exception:. ```. def _is_run_from_ipython():. """"""Determines whether run from Ipython. Only affects progress bars. """""". try:. __IPYTHON__. return True. except NameError:. return False. ```. #### Versions. <details>. scanpy.logging.print_versions(). -----. anndata 0.7.4. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.0. anndata 0.7.4. cairo 1.20.0. cffi 1.14.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. h5py 2.10.0. igraph 0.8.3. joblib 0.17.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. leidenalg 0.8.2. llvmlite 0.34.0. matplotlib 3.3.2. mkl 2.3.0. mpl_toolkits NA. natsort 7.0.1. numba 0.51.2. numexpr 2.7.1. numpy 1.19.2. packaging 20.4. pandas 1.1.3. pkg_r",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1477
https://github.com/scverse/scanpy/issues/1477:1216,safety,except,except,1216," confirmed this bug exists on the master branch of scanpy. ---. When I run scanpy over an ssh connection to a remote Ubuntu Linux server (so not using the IPython notebooks), the scanpy ""set_figure_params(...)"" command just outputs an ""In :"", and I need to exit using [Ctrl][D]: . ### Minimal code sample (that we can copy&paste without having any data). ```. import scanpy as sc. sc.set_figure_params(figsize=(4, 4)). ```. The output in console is:. ```. In :. In :. ```. and need to press [Crtrl][D] to exit, as otherwise this just loops ""In :"" repeatedly. If I add ""ipython_format=None"":. ```. sc.set_figure_params(figsize=(4, 4), ipython_format=None). ```. then this continues without any ""In :"", and I can continue with script. . I think the reason for this is in the scanpy ""_settings.py"" file:. ```. def set_figure_params(. ......etc..... try:. import IPython. if isinstance(ipython_format, str):. ipython_format = [ipython_format]. IPython.display.set_matplotlib_formats(*ipython_format). except Exception:. pass. from matplotlib import rcParams. .....etc...... ```. where the:. ```. IPython.display.set_matplotlib_formats(*ipython_format). ```. produces this ""In :"" message loop. I think this bug could be fixed by adding ""if self._is_run_from_ipython():"" before the ""try: import IPython"": . ```. def set_figure_params(. ......etc..... if self._is_run_from_ipython():. try:. import IPython. if isinstance(ipython_format, str):. ipython_format = [ipython_format]. IPython.display.set_matplotlib_formats(*ipython_format). except Exception:. pass. ```. The ""try:"" . ```. >>> import IPython. ```. doesn't throw an exception, as IPython is installed:. ```. $ pip show IPython. Name: ipython. Version: 7.18.1. Summary: IPython: Productive Interactive Computing. Home-page: https://ipython.org. Author: The IPython Development Team. Author-email: ipython-dev@python.org. License: BSD. Location: /slipstream/home/sbridgett/miniconda3/lib/python3.8/site-packages. Requires: pygments, jedi, prompt-too",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1477
https://github.com/scverse/scanpy/issues/1477:1223,safety,Except,Exception,1223,"d this bug exists on the master branch of scanpy. ---. When I run scanpy over an ssh connection to a remote Ubuntu Linux server (so not using the IPython notebooks), the scanpy ""set_figure_params(...)"" command just outputs an ""In :"", and I need to exit using [Ctrl][D]: . ### Minimal code sample (that we can copy&paste without having any data). ```. import scanpy as sc. sc.set_figure_params(figsize=(4, 4)). ```. The output in console is:. ```. In :. In :. ```. and need to press [Crtrl][D] to exit, as otherwise this just loops ""In :"" repeatedly. If I add ""ipython_format=None"":. ```. sc.set_figure_params(figsize=(4, 4), ipython_format=None). ```. then this continues without any ""In :"", and I can continue with script. . I think the reason for this is in the scanpy ""_settings.py"" file:. ```. def set_figure_params(. ......etc..... try:. import IPython. if isinstance(ipython_format, str):. ipython_format = [ipython_format]. IPython.display.set_matplotlib_formats(*ipython_format). except Exception:. pass. from matplotlib import rcParams. .....etc...... ```. where the:. ```. IPython.display.set_matplotlib_formats(*ipython_format). ```. produces this ""In :"" message loop. I think this bug could be fixed by adding ""if self._is_run_from_ipython():"" before the ""try: import IPython"": . ```. def set_figure_params(. ......etc..... if self._is_run_from_ipython():. try:. import IPython. if isinstance(ipython_format, str):. ipython_format = [ipython_format]. IPython.display.set_matplotlib_formats(*ipython_format). except Exception:. pass. ```. The ""try:"" . ```. >>> import IPython. ```. doesn't throw an exception, as IPython is installed:. ```. $ pip show IPython. Name: ipython. Version: 7.18.1. Summary: IPython: Productive Interactive Computing. Home-page: https://ipython.org. Author: The IPython Development Team. Author-email: ipython-dev@python.org. License: BSD. Location: /slipstream/home/sbridgett/miniconda3/lib/python3.8/site-packages. Requires: pygments, jedi, prompt-toolkit, bac",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1477
https://github.com/scverse/scanpy/issues/1477:1748,safety,except,except,1748,"t loops ""In :"" repeatedly. If I add ""ipython_format=None"":. ```. sc.set_figure_params(figsize=(4, 4), ipython_format=None). ```. then this continues without any ""In :"", and I can continue with script. . I think the reason for this is in the scanpy ""_settings.py"" file:. ```. def set_figure_params(. ......etc..... try:. import IPython. if isinstance(ipython_format, str):. ipython_format = [ipython_format]. IPython.display.set_matplotlib_formats(*ipython_format). except Exception:. pass. from matplotlib import rcParams. .....etc...... ```. where the:. ```. IPython.display.set_matplotlib_formats(*ipython_format). ```. produces this ""In :"" message loop. I think this bug could be fixed by adding ""if self._is_run_from_ipython():"" before the ""try: import IPython"": . ```. def set_figure_params(. ......etc..... if self._is_run_from_ipython():. try:. import IPython. if isinstance(ipython_format, str):. ipython_format = [ipython_format]. IPython.display.set_matplotlib_formats(*ipython_format). except Exception:. pass. ```. The ""try:"" . ```. >>> import IPython. ```. doesn't throw an exception, as IPython is installed:. ```. $ pip show IPython. Name: ipython. Version: 7.18.1. Summary: IPython: Productive Interactive Computing. Home-page: https://ipython.org. Author: The IPython Development Team. Author-email: ipython-dev@python.org. License: BSD. Location: /slipstream/home/sbridgett/miniconda3/lib/python3.8/site-packages. Requires: pygments, jedi, prompt-toolkit, backcall, pexpect, setuptools, decorator, traitlets, pickleshare. Required-by: ipywidgets, ipykernel. ```. whereas the _is_run_from_ipython() will correctly ``return False``, as ``__IPYTHON__`` gives an exception:. ```. def _is_run_from_ipython():. """"""Determines whether run from Ipython. Only affects progress bars. """""". try:. __IPYTHON__. return True. except NameError:. return False. ```. #### Versions. <details>. scanpy.logging.print_versions(). -----. anndata 0.7.4. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.0. anndata ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1477
https://github.com/scverse/scanpy/issues/1477:1755,safety,Except,Exception,1755,"In :"" repeatedly. If I add ""ipython_format=None"":. ```. sc.set_figure_params(figsize=(4, 4), ipython_format=None). ```. then this continues without any ""In :"", and I can continue with script. . I think the reason for this is in the scanpy ""_settings.py"" file:. ```. def set_figure_params(. ......etc..... try:. import IPython. if isinstance(ipython_format, str):. ipython_format = [ipython_format]. IPython.display.set_matplotlib_formats(*ipython_format). except Exception:. pass. from matplotlib import rcParams. .....etc...... ```. where the:. ```. IPython.display.set_matplotlib_formats(*ipython_format). ```. produces this ""In :"" message loop. I think this bug could be fixed by adding ""if self._is_run_from_ipython():"" before the ""try: import IPython"": . ```. def set_figure_params(. ......etc..... if self._is_run_from_ipython():. try:. import IPython. if isinstance(ipython_format, str):. ipython_format = [ipython_format]. IPython.display.set_matplotlib_formats(*ipython_format). except Exception:. pass. ```. The ""try:"" . ```. >>> import IPython. ```. doesn't throw an exception, as IPython is installed:. ```. $ pip show IPython. Name: ipython. Version: 7.18.1. Summary: IPython: Productive Interactive Computing. Home-page: https://ipython.org. Author: The IPython Development Team. Author-email: ipython-dev@python.org. License: BSD. Location: /slipstream/home/sbridgett/miniconda3/lib/python3.8/site-packages. Requires: pygments, jedi, prompt-toolkit, backcall, pexpect, setuptools, decorator, traitlets, pickleshare. Required-by: ipywidgets, ipykernel. ```. whereas the _is_run_from_ipython() will correctly ``return False``, as ``__IPYTHON__`` gives an exception:. ```. def _is_run_from_ipython():. """"""Determines whether run from Ipython. Only affects progress bars. """""". try:. __IPYTHON__. return True. except NameError:. return False. ```. #### Versions. <details>. scanpy.logging.print_versions(). -----. anndata 0.7.4. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.0. anndata 0.7.4. ca",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1477
https://github.com/scverse/scanpy/issues/1477:1838,safety,except,exception,1838,"e=(4, 4), ipython_format=None). ```. then this continues without any ""In :"", and I can continue with script. . I think the reason for this is in the scanpy ""_settings.py"" file:. ```. def set_figure_params(. ......etc..... try:. import IPython. if isinstance(ipython_format, str):. ipython_format = [ipython_format]. IPython.display.set_matplotlib_formats(*ipython_format). except Exception:. pass. from matplotlib import rcParams. .....etc...... ```. where the:. ```. IPython.display.set_matplotlib_formats(*ipython_format). ```. produces this ""In :"" message loop. I think this bug could be fixed by adding ""if self._is_run_from_ipython():"" before the ""try: import IPython"": . ```. def set_figure_params(. ......etc..... if self._is_run_from_ipython():. try:. import IPython. if isinstance(ipython_format, str):. ipython_format = [ipython_format]. IPython.display.set_matplotlib_formats(*ipython_format). except Exception:. pass. ```. The ""try:"" . ```. >>> import IPython. ```. doesn't throw an exception, as IPython is installed:. ```. $ pip show IPython. Name: ipython. Version: 7.18.1. Summary: IPython: Productive Interactive Computing. Home-page: https://ipython.org. Author: The IPython Development Team. Author-email: ipython-dev@python.org. License: BSD. Location: /slipstream/home/sbridgett/miniconda3/lib/python3.8/site-packages. Requires: pygments, jedi, prompt-toolkit, backcall, pexpect, setuptools, decorator, traitlets, pickleshare. Required-by: ipywidgets, ipykernel. ```. whereas the _is_run_from_ipython() will correctly ``return False``, as ``__IPYTHON__`` gives an exception:. ```. def _is_run_from_ipython():. """"""Determines whether run from Ipython. Only affects progress bars. """""". try:. __IPYTHON__. return True. except NameError:. return False. ```. #### Versions. <details>. scanpy.logging.print_versions(). -----. anndata 0.7.4. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.0. anndata 0.7.4. cairo 1.20.0. cffi 1.14.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1477
https://github.com/scverse/scanpy/issues/1477:2428,safety,except,exception,2428," fixed by adding ""if self._is_run_from_ipython():"" before the ""try: import IPython"": . ```. def set_figure_params(. ......etc..... if self._is_run_from_ipython():. try:. import IPython. if isinstance(ipython_format, str):. ipython_format = [ipython_format]. IPython.display.set_matplotlib_formats(*ipython_format). except Exception:. pass. ```. The ""try:"" . ```. >>> import IPython. ```. doesn't throw an exception, as IPython is installed:. ```. $ pip show IPython. Name: ipython. Version: 7.18.1. Summary: IPython: Productive Interactive Computing. Home-page: https://ipython.org. Author: The IPython Development Team. Author-email: ipython-dev@python.org. License: BSD. Location: /slipstream/home/sbridgett/miniconda3/lib/python3.8/site-packages. Requires: pygments, jedi, prompt-toolkit, backcall, pexpect, setuptools, decorator, traitlets, pickleshare. Required-by: ipywidgets, ipykernel. ```. whereas the _is_run_from_ipython() will correctly ``return False``, as ``__IPYTHON__`` gives an exception:. ```. def _is_run_from_ipython():. """"""Determines whether run from Ipython. Only affects progress bars. """""". try:. __IPYTHON__. return True. except NameError:. return False. ```. #### Versions. <details>. scanpy.logging.print_versions(). -----. anndata 0.7.4. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.0. anndata 0.7.4. cairo 1.20.0. cffi 1.14.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. h5py 2.10.0. igraph 0.8.3. joblib 0.17.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. leidenalg 0.8.2. llvmlite 0.34.0. matplotlib 3.3.2. mkl 2.3.0. mpl_toolkits NA. natsort 7.0.1. numba 0.51.2. numexpr 2.7.1. numpy 1.19.2. packaging 20.4. pandas 1.1.3. pkg_resources NA. pyparsing 2.4.7. pytz 2020.1. scanpy 1.6.0. scipy 1.5.2. setuptools_scm NA. sinfo 0.3.1. six 1.14.0. sklearn 0.23.2. tables 3.6.1. texttable 1.6.3. typing_extensions NA. wcwidth 0.2.5. -----. Python 3.8.3 (default, May 19 2020, 18:47:26) [GCC 7.3.0]. Linux-3.13.0-143-generic-x86_64-with-glibc2.10.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1477
https://github.com/scverse/scanpy/issues/1477:2579,safety,except,except,2579,"t_figure_params(. ......etc..... if self._is_run_from_ipython():. try:. import IPython. if isinstance(ipython_format, str):. ipython_format = [ipython_format]. IPython.display.set_matplotlib_formats(*ipython_format). except Exception:. pass. ```. The ""try:"" . ```. >>> import IPython. ```. doesn't throw an exception, as IPython is installed:. ```. $ pip show IPython. Name: ipython. Version: 7.18.1. Summary: IPython: Productive Interactive Computing. Home-page: https://ipython.org. Author: The IPython Development Team. Author-email: ipython-dev@python.org. License: BSD. Location: /slipstream/home/sbridgett/miniconda3/lib/python3.8/site-packages. Requires: pygments, jedi, prompt-toolkit, backcall, pexpect, setuptools, decorator, traitlets, pickleshare. Required-by: ipywidgets, ipykernel. ```. whereas the _is_run_from_ipython() will correctly ``return False``, as ``__IPYTHON__`` gives an exception:. ```. def _is_run_from_ipython():. """"""Determines whether run from Ipython. Only affects progress bars. """""". try:. __IPYTHON__. return True. except NameError:. return False. ```. #### Versions. <details>. scanpy.logging.print_versions(). -----. anndata 0.7.4. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.0. anndata 0.7.4. cairo 1.20.0. cffi 1.14.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. h5py 2.10.0. igraph 0.8.3. joblib 0.17.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. leidenalg 0.8.2. llvmlite 0.34.0. matplotlib 3.3.2. mkl 2.3.0. mpl_toolkits NA. natsort 7.0.1. numba 0.51.2. numexpr 2.7.1. numpy 1.19.2. packaging 20.4. pandas 1.1.3. pkg_resources NA. pyparsing 2.4.7. pytz 2020.1. scanpy 1.6.0. scipy 1.5.2. setuptools_scm NA. sinfo 0.3.1. six 1.14.0. sklearn 0.23.2. tables 3.6.1. texttable 1.6.3. typing_extensions NA. wcwidth 0.2.5. -----. Python 3.8.3 (default, May 19 2020, 18:47:26) [GCC 7.3.0]. Linux-3.13.0-143-generic-x86_64-with-glibc2.10. 32 logical CPU cores, x86_64. -----. Session information updated at 2020-11-01 11:37. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1477
https://github.com/scverse/scanpy/issues/1477:2650,safety,log,logging,2650,"t_figure_params(. ......etc..... if self._is_run_from_ipython():. try:. import IPython. if isinstance(ipython_format, str):. ipython_format = [ipython_format]. IPython.display.set_matplotlib_formats(*ipython_format). except Exception:. pass. ```. The ""try:"" . ```. >>> import IPython. ```. doesn't throw an exception, as IPython is installed:. ```. $ pip show IPython. Name: ipython. Version: 7.18.1. Summary: IPython: Productive Interactive Computing. Home-page: https://ipython.org. Author: The IPython Development Team. Author-email: ipython-dev@python.org. License: BSD. Location: /slipstream/home/sbridgett/miniconda3/lib/python3.8/site-packages. Requires: pygments, jedi, prompt-toolkit, backcall, pexpect, setuptools, decorator, traitlets, pickleshare. Required-by: ipywidgets, ipykernel. ```. whereas the _is_run_from_ipython() will correctly ``return False``, as ``__IPYTHON__`` gives an exception:. ```. def _is_run_from_ipython():. """"""Determines whether run from Ipython. Only affects progress bars. """""". try:. __IPYTHON__. return True. except NameError:. return False. ```. #### Versions. <details>. scanpy.logging.print_versions(). -----. anndata 0.7.4. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.0. anndata 0.7.4. cairo 1.20.0. cffi 1.14.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. h5py 2.10.0. igraph 0.8.3. joblib 0.17.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. leidenalg 0.8.2. llvmlite 0.34.0. matplotlib 3.3.2. mkl 2.3.0. mpl_toolkits NA. natsort 7.0.1. numba 0.51.2. numexpr 2.7.1. numpy 1.19.2. packaging 20.4. pandas 1.1.3. pkg_resources NA. pyparsing 2.4.7. pytz 2020.1. scanpy 1.6.0. scipy 1.5.2. setuptools_scm NA. sinfo 0.3.1. six 1.14.0. sklearn 0.23.2. tables 3.6.1. texttable 1.6.3. typing_extensions NA. wcwidth 0.2.5. -----. Python 3.8.3 (default, May 19 2020, 18:47:26) [GCC 7.3.0]. Linux-3.13.0-143-generic-x86_64-with-glibc2.10. 32 logical CPU cores, x86_64. -----. Session information updated at 2020-11-01 11:37. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1477
https://github.com/scverse/scanpy/issues/1477:3437,safety,log,logical,3437,"t_figure_params(. ......etc..... if self._is_run_from_ipython():. try:. import IPython. if isinstance(ipython_format, str):. ipython_format = [ipython_format]. IPython.display.set_matplotlib_formats(*ipython_format). except Exception:. pass. ```. The ""try:"" . ```. >>> import IPython. ```. doesn't throw an exception, as IPython is installed:. ```. $ pip show IPython. Name: ipython. Version: 7.18.1. Summary: IPython: Productive Interactive Computing. Home-page: https://ipython.org. Author: The IPython Development Team. Author-email: ipython-dev@python.org. License: BSD. Location: /slipstream/home/sbridgett/miniconda3/lib/python3.8/site-packages. Requires: pygments, jedi, prompt-toolkit, backcall, pexpect, setuptools, decorator, traitlets, pickleshare. Required-by: ipywidgets, ipykernel. ```. whereas the _is_run_from_ipython() will correctly ``return False``, as ``__IPYTHON__`` gives an exception:. ```. def _is_run_from_ipython():. """"""Determines whether run from Ipython. Only affects progress bars. """""". try:. __IPYTHON__. return True. except NameError:. return False. ```. #### Versions. <details>. scanpy.logging.print_versions(). -----. anndata 0.7.4. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.0. anndata 0.7.4. cairo 1.20.0. cffi 1.14.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. h5py 2.10.0. igraph 0.8.3. joblib 0.17.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. leidenalg 0.8.2. llvmlite 0.34.0. matplotlib 3.3.2. mkl 2.3.0. mpl_toolkits NA. natsort 7.0.1. numba 0.51.2. numexpr 2.7.1. numpy 1.19.2. packaging 20.4. pandas 1.1.3. pkg_resources NA. pyparsing 2.4.7. pytz 2020.1. scanpy 1.6.0. scipy 1.5.2. setuptools_scm NA. sinfo 0.3.1. six 1.14.0. sklearn 0.23.2. tables 3.6.1. texttable 1.6.3. typing_extensions NA. wcwidth 0.2.5. -----. Python 3.8.3 (default, May 19 2020, 18:47:26) [GCC 7.3.0]. Linux-3.13.0-143-generic-x86_64-with-glibc2.10. 32 logical CPU cores, x86_64. -----. Session information updated at 2020-11-01 11:37. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1477
https://github.com/scverse/scanpy/issues/1477:3491,safety,updat,updated,3491,"t_figure_params(. ......etc..... if self._is_run_from_ipython():. try:. import IPython. if isinstance(ipython_format, str):. ipython_format = [ipython_format]. IPython.display.set_matplotlib_formats(*ipython_format). except Exception:. pass. ```. The ""try:"" . ```. >>> import IPython. ```. doesn't throw an exception, as IPython is installed:. ```. $ pip show IPython. Name: ipython. Version: 7.18.1. Summary: IPython: Productive Interactive Computing. Home-page: https://ipython.org. Author: The IPython Development Team. Author-email: ipython-dev@python.org. License: BSD. Location: /slipstream/home/sbridgett/miniconda3/lib/python3.8/site-packages. Requires: pygments, jedi, prompt-toolkit, backcall, pexpect, setuptools, decorator, traitlets, pickleshare. Required-by: ipywidgets, ipykernel. ```. whereas the _is_run_from_ipython() will correctly ``return False``, as ``__IPYTHON__`` gives an exception:. ```. def _is_run_from_ipython():. """"""Determines whether run from Ipython. Only affects progress bars. """""". try:. __IPYTHON__. return True. except NameError:. return False. ```. #### Versions. <details>. scanpy.logging.print_versions(). -----. anndata 0.7.4. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.0. anndata 0.7.4. cairo 1.20.0. cffi 1.14.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. h5py 2.10.0. igraph 0.8.3. joblib 0.17.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. leidenalg 0.8.2. llvmlite 0.34.0. matplotlib 3.3.2. mkl 2.3.0. mpl_toolkits NA. natsort 7.0.1. numba 0.51.2. numexpr 2.7.1. numpy 1.19.2. packaging 20.4. pandas 1.1.3. pkg_resources NA. pyparsing 2.4.7. pytz 2020.1. scanpy 1.6.0. scipy 1.5.2. setuptools_scm NA. sinfo 0.3.1. six 1.14.0. sklearn 0.23.2. tables 3.6.1. texttable 1.6.3. typing_extensions NA. wcwidth 0.2.5. -----. Python 3.8.3 (default, May 19 2020, 18:47:26) [GCC 7.3.0]. Linux-3.13.0-143-generic-x86_64-with-glibc2.10. 32 logical CPU cores, x86_64. -----. Session information updated at 2020-11-01 11:37. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1477
https://github.com/scverse/scanpy/issues/1477:40,security,command-lin,command-line,40,"set_figure_params() bug when running at command-line; - [X ] I have checked that this issue has not already been reported. - [X ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. When I run scanpy over an ssh connection to a remote Ubuntu Linux server (so not using the IPython notebooks), the scanpy ""set_figure_params(...)"" command just outputs an ""In :"", and I need to exit using [Ctrl][D]: . ### Minimal code sample (that we can copy&paste without having any data). ```. import scanpy as sc. sc.set_figure_params(figsize=(4, 4)). ```. The output in console is:. ```. In :. In :. ```. and need to press [Crtrl][D] to exit, as otherwise this just loops ""In :"" repeatedly. If I add ""ipython_format=None"":. ```. sc.set_figure_params(figsize=(4, 4), ipython_format=None). ```. then this continues without any ""In :"", and I can continue with script. . I think the reason for this is in the scanpy ""_settings.py"" file:. ```. def set_figure_params(. ......etc..... try:. import IPython. if isinstance(ipython_format, str):. ipython_format = [ipython_format]. IPython.display.set_matplotlib_formats(*ipython_format). except Exception:. pass. from matplotlib import rcParams. .....etc...... ```. where the:. ```. IPython.display.set_matplotlib_formats(*ipython_format). ```. produces this ""In :"" message loop. I think this bug could be fixed by adding ""if self._is_run_from_ipython():"" before the ""try: import IPython"": . ```. def set_figure_params(. ......etc..... if self._is_run_from_ipython():. try:. import IPython. if isinstance(ipython_format, str):. ipython_format = [ipython_format]. IPython.display.set_matplotlib_formats(*ipython_format). except Exception:. pass. ```. The ""try:"" . ```. >>> import IPython. ```. doesn't throw an exception, as IPython is installed:. ```. $ pip show IPython. Name: ipython. Version: 7.18.1. Summary: IPython: Productive Interactive Computing. Home-page: https",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1477
https://github.com/scverse/scanpy/issues/1477:309,security,ssh,ssh,309,"set_figure_params() bug when running at command-line; - [X ] I have checked that this issue has not already been reported. - [X ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. When I run scanpy over an ssh connection to a remote Ubuntu Linux server (so not using the IPython notebooks), the scanpy ""set_figure_params(...)"" command just outputs an ""In :"", and I need to exit using [Ctrl][D]: . ### Minimal code sample (that we can copy&paste without having any data). ```. import scanpy as sc. sc.set_figure_params(figsize=(4, 4)). ```. The output in console is:. ```. In :. In :. ```. and need to press [Crtrl][D] to exit, as otherwise this just loops ""In :"" repeatedly. If I add ""ipython_format=None"":. ```. sc.set_figure_params(figsize=(4, 4), ipython_format=None). ```. then this continues without any ""In :"", and I can continue with script. . I think the reason for this is in the scanpy ""_settings.py"" file:. ```. def set_figure_params(. ......etc..... try:. import IPython. if isinstance(ipython_format, str):. ipython_format = [ipython_format]. IPython.display.set_matplotlib_formats(*ipython_format). except Exception:. pass. from matplotlib import rcParams. .....etc...... ```. where the:. ```. IPython.display.set_matplotlib_formats(*ipython_format). ```. produces this ""In :"" message loop. I think this bug could be fixed by adding ""if self._is_run_from_ipython():"" before the ""try: import IPython"": . ```. def set_figure_params(. ......etc..... if self._is_run_from_ipython():. try:. import IPython. if isinstance(ipython_format, str):. ipython_format = [ipython_format]. IPython.display.set_matplotlib_formats(*ipython_format). except Exception:. pass. ```. The ""try:"" . ```. >>> import IPython. ```. doesn't throw an exception, as IPython is installed:. ```. $ pip show IPython. Name: ipython. Version: 7.18.1. Summary: IPython: Productive Interactive Computing. Home-page: https",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1477
https://github.com/scverse/scanpy/issues/1477:2016,security,Auth,Author,2016,". ```. def set_figure_params(. ......etc..... try:. import IPython. if isinstance(ipython_format, str):. ipython_format = [ipython_format]. IPython.display.set_matplotlib_formats(*ipython_format). except Exception:. pass. from matplotlib import rcParams. .....etc...... ```. where the:. ```. IPython.display.set_matplotlib_formats(*ipython_format). ```. produces this ""In :"" message loop. I think this bug could be fixed by adding ""if self._is_run_from_ipython():"" before the ""try: import IPython"": . ```. def set_figure_params(. ......etc..... if self._is_run_from_ipython():. try:. import IPython. if isinstance(ipython_format, str):. ipython_format = [ipython_format]. IPython.display.set_matplotlib_formats(*ipython_format). except Exception:. pass. ```. The ""try:"" . ```. >>> import IPython. ```. doesn't throw an exception, as IPython is installed:. ```. $ pip show IPython. Name: ipython. Version: 7.18.1. Summary: IPython: Productive Interactive Computing. Home-page: https://ipython.org. Author: The IPython Development Team. Author-email: ipython-dev@python.org. License: BSD. Location: /slipstream/home/sbridgett/miniconda3/lib/python3.8/site-packages. Requires: pygments, jedi, prompt-toolkit, backcall, pexpect, setuptools, decorator, traitlets, pickleshare. Required-by: ipywidgets, ipykernel. ```. whereas the _is_run_from_ipython() will correctly ``return False``, as ``__IPYTHON__`` gives an exception:. ```. def _is_run_from_ipython():. """"""Determines whether run from Ipython. Only affects progress bars. """""". try:. __IPYTHON__. return True. except NameError:. return False. ```. #### Versions. <details>. scanpy.logging.print_versions(). -----. anndata 0.7.4. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.0. anndata 0.7.4. cairo 1.20.0. cffi 1.14.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. h5py 2.10.0. igraph 0.8.3. joblib 0.17.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. leidenalg 0.8.2. llvmlite 0.34.0. matplotlib 3.3.2. mkl 2.3.0. mpl_too",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1477
https://github.com/scverse/scanpy/issues/1477:2048,security,Team,Team,2048,"......etc..... try:. import IPython. if isinstance(ipython_format, str):. ipython_format = [ipython_format]. IPython.display.set_matplotlib_formats(*ipython_format). except Exception:. pass. from matplotlib import rcParams. .....etc...... ```. where the:. ```. IPython.display.set_matplotlib_formats(*ipython_format). ```. produces this ""In :"" message loop. I think this bug could be fixed by adding ""if self._is_run_from_ipython():"" before the ""try: import IPython"": . ```. def set_figure_params(. ......etc..... if self._is_run_from_ipython():. try:. import IPython. if isinstance(ipython_format, str):. ipython_format = [ipython_format]. IPython.display.set_matplotlib_formats(*ipython_format). except Exception:. pass. ```. The ""try:"" . ```. >>> import IPython. ```. doesn't throw an exception, as IPython is installed:. ```. $ pip show IPython. Name: ipython. Version: 7.18.1. Summary: IPython: Productive Interactive Computing. Home-page: https://ipython.org. Author: The IPython Development Team. Author-email: ipython-dev@python.org. License: BSD. Location: /slipstream/home/sbridgett/miniconda3/lib/python3.8/site-packages. Requires: pygments, jedi, prompt-toolkit, backcall, pexpect, setuptools, decorator, traitlets, pickleshare. Required-by: ipywidgets, ipykernel. ```. whereas the _is_run_from_ipython() will correctly ``return False``, as ``__IPYTHON__`` gives an exception:. ```. def _is_run_from_ipython():. """"""Determines whether run from Ipython. Only affects progress bars. """""". try:. __IPYTHON__. return True. except NameError:. return False. ```. #### Versions. <details>. scanpy.logging.print_versions(). -----. anndata 0.7.4. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.0. anndata 0.7.4. cairo 1.20.0. cffi 1.14.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. h5py 2.10.0. igraph 0.8.3. joblib 0.17.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. leidenalg 0.8.2. llvmlite 0.34.0. matplotlib 3.3.2. mkl 2.3.0. mpl_toolkits NA. natsort 7.0.1. numba ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1477
https://github.com/scverse/scanpy/issues/1477:2054,security,Auth,Author-email,2054,".... try:. import IPython. if isinstance(ipython_format, str):. ipython_format = [ipython_format]. IPython.display.set_matplotlib_formats(*ipython_format). except Exception:. pass. from matplotlib import rcParams. .....etc...... ```. where the:. ```. IPython.display.set_matplotlib_formats(*ipython_format). ```. produces this ""In :"" message loop. I think this bug could be fixed by adding ""if self._is_run_from_ipython():"" before the ""try: import IPython"": . ```. def set_figure_params(. ......etc..... if self._is_run_from_ipython():. try:. import IPython. if isinstance(ipython_format, str):. ipython_format = [ipython_format]. IPython.display.set_matplotlib_formats(*ipython_format). except Exception:. pass. ```. The ""try:"" . ```. >>> import IPython. ```. doesn't throw an exception, as IPython is installed:. ```. $ pip show IPython. Name: ipython. Version: 7.18.1. Summary: IPython: Productive Interactive Computing. Home-page: https://ipython.org. Author: The IPython Development Team. Author-email: ipython-dev@python.org. License: BSD. Location: /slipstream/home/sbridgett/miniconda3/lib/python3.8/site-packages. Requires: pygments, jedi, prompt-toolkit, backcall, pexpect, setuptools, decorator, traitlets, pickleshare. Required-by: ipywidgets, ipykernel. ```. whereas the _is_run_from_ipython() will correctly ``return False``, as ``__IPYTHON__`` gives an exception:. ```. def _is_run_from_ipython():. """"""Determines whether run from Ipython. Only affects progress bars. """""". try:. __IPYTHON__. return True. except NameError:. return False. ```. #### Versions. <details>. scanpy.logging.print_versions(). -----. anndata 0.7.4. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.0. anndata 0.7.4. cairo 1.20.0. cffi 1.14.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. h5py 2.10.0. igraph 0.8.3. joblib 0.17.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. leidenalg 0.8.2. llvmlite 0.34.0. matplotlib 3.3.2. mkl 2.3.0. mpl_toolkits NA. natsort 7.0.1. numba 0.51.2. nu",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1477
https://github.com/scverse/scanpy/issues/1477:2650,security,log,logging,2650,"t_figure_params(. ......etc..... if self._is_run_from_ipython():. try:. import IPython. if isinstance(ipython_format, str):. ipython_format = [ipython_format]. IPython.display.set_matplotlib_formats(*ipython_format). except Exception:. pass. ```. The ""try:"" . ```. >>> import IPython. ```. doesn't throw an exception, as IPython is installed:. ```. $ pip show IPython. Name: ipython. Version: 7.18.1. Summary: IPython: Productive Interactive Computing. Home-page: https://ipython.org. Author: The IPython Development Team. Author-email: ipython-dev@python.org. License: BSD. Location: /slipstream/home/sbridgett/miniconda3/lib/python3.8/site-packages. Requires: pygments, jedi, prompt-toolkit, backcall, pexpect, setuptools, decorator, traitlets, pickleshare. Required-by: ipywidgets, ipykernel. ```. whereas the _is_run_from_ipython() will correctly ``return False``, as ``__IPYTHON__`` gives an exception:. ```. def _is_run_from_ipython():. """"""Determines whether run from Ipython. Only affects progress bars. """""". try:. __IPYTHON__. return True. except NameError:. return False. ```. #### Versions. <details>. scanpy.logging.print_versions(). -----. anndata 0.7.4. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.0. anndata 0.7.4. cairo 1.20.0. cffi 1.14.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. h5py 2.10.0. igraph 0.8.3. joblib 0.17.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. leidenalg 0.8.2. llvmlite 0.34.0. matplotlib 3.3.2. mkl 2.3.0. mpl_toolkits NA. natsort 7.0.1. numba 0.51.2. numexpr 2.7.1. numpy 1.19.2. packaging 20.4. pandas 1.1.3. pkg_resources NA. pyparsing 2.4.7. pytz 2020.1. scanpy 1.6.0. scipy 1.5.2. setuptools_scm NA. sinfo 0.3.1. six 1.14.0. sklearn 0.23.2. tables 3.6.1. texttable 1.6.3. typing_extensions NA. wcwidth 0.2.5. -----. Python 3.8.3 (default, May 19 2020, 18:47:26) [GCC 7.3.0]. Linux-3.13.0-143-generic-x86_64-with-glibc2.10. 32 logical CPU cores, x86_64. -----. Session information updated at 2020-11-01 11:37. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1477
https://github.com/scverse/scanpy/issues/1477:3437,security,log,logical,3437,"t_figure_params(. ......etc..... if self._is_run_from_ipython():. try:. import IPython. if isinstance(ipython_format, str):. ipython_format = [ipython_format]. IPython.display.set_matplotlib_formats(*ipython_format). except Exception:. pass. ```. The ""try:"" . ```. >>> import IPython. ```. doesn't throw an exception, as IPython is installed:. ```. $ pip show IPython. Name: ipython. Version: 7.18.1. Summary: IPython: Productive Interactive Computing. Home-page: https://ipython.org. Author: The IPython Development Team. Author-email: ipython-dev@python.org. License: BSD. Location: /slipstream/home/sbridgett/miniconda3/lib/python3.8/site-packages. Requires: pygments, jedi, prompt-toolkit, backcall, pexpect, setuptools, decorator, traitlets, pickleshare. Required-by: ipywidgets, ipykernel. ```. whereas the _is_run_from_ipython() will correctly ``return False``, as ``__IPYTHON__`` gives an exception:. ```. def _is_run_from_ipython():. """"""Determines whether run from Ipython. Only affects progress bars. """""". try:. __IPYTHON__. return True. except NameError:. return False. ```. #### Versions. <details>. scanpy.logging.print_versions(). -----. anndata 0.7.4. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.0. anndata 0.7.4. cairo 1.20.0. cffi 1.14.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. h5py 2.10.0. igraph 0.8.3. joblib 0.17.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. leidenalg 0.8.2. llvmlite 0.34.0. matplotlib 3.3.2. mkl 2.3.0. mpl_toolkits NA. natsort 7.0.1. numba 0.51.2. numexpr 2.7.1. numpy 1.19.2. packaging 20.4. pandas 1.1.3. pkg_resources NA. pyparsing 2.4.7. pytz 2020.1. scanpy 1.6.0. scipy 1.5.2. setuptools_scm NA. sinfo 0.3.1. six 1.14.0. sklearn 0.23.2. tables 3.6.1. texttable 1.6.3. typing_extensions NA. wcwidth 0.2.5. -----. Python 3.8.3 (default, May 19 2020, 18:47:26) [GCC 7.3.0]. Linux-3.13.0-143-generic-x86_64-with-glibc2.10. 32 logical CPU cores, x86_64. -----. Session information updated at 2020-11-01 11:37. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1477
https://github.com/scverse/scanpy/issues/1477:3471,security,Session,Session,3471,"t_figure_params(. ......etc..... if self._is_run_from_ipython():. try:. import IPython. if isinstance(ipython_format, str):. ipython_format = [ipython_format]. IPython.display.set_matplotlib_formats(*ipython_format). except Exception:. pass. ```. The ""try:"" . ```. >>> import IPython. ```. doesn't throw an exception, as IPython is installed:. ```. $ pip show IPython. Name: ipython. Version: 7.18.1. Summary: IPython: Productive Interactive Computing. Home-page: https://ipython.org. Author: The IPython Development Team. Author-email: ipython-dev@python.org. License: BSD. Location: /slipstream/home/sbridgett/miniconda3/lib/python3.8/site-packages. Requires: pygments, jedi, prompt-toolkit, backcall, pexpect, setuptools, decorator, traitlets, pickleshare. Required-by: ipywidgets, ipykernel. ```. whereas the _is_run_from_ipython() will correctly ``return False``, as ``__IPYTHON__`` gives an exception:. ```. def _is_run_from_ipython():. """"""Determines whether run from Ipython. Only affects progress bars. """""". try:. __IPYTHON__. return True. except NameError:. return False. ```. #### Versions. <details>. scanpy.logging.print_versions(). -----. anndata 0.7.4. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.0. anndata 0.7.4. cairo 1.20.0. cffi 1.14.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. h5py 2.10.0. igraph 0.8.3. joblib 0.17.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. leidenalg 0.8.2. llvmlite 0.34.0. matplotlib 3.3.2. mkl 2.3.0. mpl_toolkits NA. natsort 7.0.1. numba 0.51.2. numexpr 2.7.1. numpy 1.19.2. packaging 20.4. pandas 1.1.3. pkg_resources NA. pyparsing 2.4.7. pytz 2020.1. scanpy 1.6.0. scipy 1.5.2. setuptools_scm NA. sinfo 0.3.1. six 1.14.0. sklearn 0.23.2. tables 3.6.1. texttable 1.6.3. typing_extensions NA. wcwidth 0.2.5. -----. Python 3.8.3 (default, May 19 2020, 18:47:26) [GCC 7.3.0]. Linux-3.13.0-143-generic-x86_64-with-glibc2.10. 32 logical CPU cores, x86_64. -----. Session information updated at 2020-11-01 11:37. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1477
https://github.com/scverse/scanpy/issues/1477:3491,security,updat,updated,3491,"t_figure_params(. ......etc..... if self._is_run_from_ipython():. try:. import IPython. if isinstance(ipython_format, str):. ipython_format = [ipython_format]. IPython.display.set_matplotlib_formats(*ipython_format). except Exception:. pass. ```. The ""try:"" . ```. >>> import IPython. ```. doesn't throw an exception, as IPython is installed:. ```. $ pip show IPython. Name: ipython. Version: 7.18.1. Summary: IPython: Productive Interactive Computing. Home-page: https://ipython.org. Author: The IPython Development Team. Author-email: ipython-dev@python.org. License: BSD. Location: /slipstream/home/sbridgett/miniconda3/lib/python3.8/site-packages. Requires: pygments, jedi, prompt-toolkit, backcall, pexpect, setuptools, decorator, traitlets, pickleshare. Required-by: ipywidgets, ipykernel. ```. whereas the _is_run_from_ipython() will correctly ``return False``, as ``__IPYTHON__`` gives an exception:. ```. def _is_run_from_ipython():. """"""Determines whether run from Ipython. Only affects progress bars. """""". try:. __IPYTHON__. return True. except NameError:. return False. ```. #### Versions. <details>. scanpy.logging.print_versions(). -----. anndata 0.7.4. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.0. anndata 0.7.4. cairo 1.20.0. cffi 1.14.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. h5py 2.10.0. igraph 0.8.3. joblib 0.17.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. leidenalg 0.8.2. llvmlite 0.34.0. matplotlib 3.3.2. mkl 2.3.0. mpl_toolkits NA. natsort 7.0.1. numba 0.51.2. numexpr 2.7.1. numpy 1.19.2. packaging 20.4. pandas 1.1.3. pkg_resources NA. pyparsing 2.4.7. pytz 2020.1. scanpy 1.6.0. scipy 1.5.2. setuptools_scm NA. sinfo 0.3.1. six 1.14.0. sklearn 0.23.2. tables 3.6.1. texttable 1.6.3. typing_extensions NA. wcwidth 0.2.5. -----. Python 3.8.3 (default, May 19 2020, 18:47:26) [GCC 7.3.0]. Linux-3.13.0-143-generic-x86_64-with-glibc2.10. 32 logical CPU cores, x86_64. -----. Session information updated at 2020-11-01 11:37. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1477
https://github.com/scverse/scanpy/issues/1477:2650,testability,log,logging,2650,"t_figure_params(. ......etc..... if self._is_run_from_ipython():. try:. import IPython. if isinstance(ipython_format, str):. ipython_format = [ipython_format]. IPython.display.set_matplotlib_formats(*ipython_format). except Exception:. pass. ```. The ""try:"" . ```. >>> import IPython. ```. doesn't throw an exception, as IPython is installed:. ```. $ pip show IPython. Name: ipython. Version: 7.18.1. Summary: IPython: Productive Interactive Computing. Home-page: https://ipython.org. Author: The IPython Development Team. Author-email: ipython-dev@python.org. License: BSD. Location: /slipstream/home/sbridgett/miniconda3/lib/python3.8/site-packages. Requires: pygments, jedi, prompt-toolkit, backcall, pexpect, setuptools, decorator, traitlets, pickleshare. Required-by: ipywidgets, ipykernel. ```. whereas the _is_run_from_ipython() will correctly ``return False``, as ``__IPYTHON__`` gives an exception:. ```. def _is_run_from_ipython():. """"""Determines whether run from Ipython. Only affects progress bars. """""". try:. __IPYTHON__. return True. except NameError:. return False. ```. #### Versions. <details>. scanpy.logging.print_versions(). -----. anndata 0.7.4. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.0. anndata 0.7.4. cairo 1.20.0. cffi 1.14.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. h5py 2.10.0. igraph 0.8.3. joblib 0.17.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. leidenalg 0.8.2. llvmlite 0.34.0. matplotlib 3.3.2. mkl 2.3.0. mpl_toolkits NA. natsort 7.0.1. numba 0.51.2. numexpr 2.7.1. numpy 1.19.2. packaging 20.4. pandas 1.1.3. pkg_resources NA. pyparsing 2.4.7. pytz 2020.1. scanpy 1.6.0. scipy 1.5.2. setuptools_scm NA. sinfo 0.3.1. six 1.14.0. sklearn 0.23.2. tables 3.6.1. texttable 1.6.3. typing_extensions NA. wcwidth 0.2.5. -----. Python 3.8.3 (default, May 19 2020, 18:47:26) [GCC 7.3.0]. Linux-3.13.0-143-generic-x86_64-with-glibc2.10. 32 logical CPU cores, x86_64. -----. Session information updated at 2020-11-01 11:37. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1477
https://github.com/scverse/scanpy/issues/1477:3437,testability,log,logical,3437,"t_figure_params(. ......etc..... if self._is_run_from_ipython():. try:. import IPython. if isinstance(ipython_format, str):. ipython_format = [ipython_format]. IPython.display.set_matplotlib_formats(*ipython_format). except Exception:. pass. ```. The ""try:"" . ```. >>> import IPython. ```. doesn't throw an exception, as IPython is installed:. ```. $ pip show IPython. Name: ipython. Version: 7.18.1. Summary: IPython: Productive Interactive Computing. Home-page: https://ipython.org. Author: The IPython Development Team. Author-email: ipython-dev@python.org. License: BSD. Location: /slipstream/home/sbridgett/miniconda3/lib/python3.8/site-packages. Requires: pygments, jedi, prompt-toolkit, backcall, pexpect, setuptools, decorator, traitlets, pickleshare. Required-by: ipywidgets, ipykernel. ```. whereas the _is_run_from_ipython() will correctly ``return False``, as ``__IPYTHON__`` gives an exception:. ```. def _is_run_from_ipython():. """"""Determines whether run from Ipython. Only affects progress bars. """""". try:. __IPYTHON__. return True. except NameError:. return False. ```. #### Versions. <details>. scanpy.logging.print_versions(). -----. anndata 0.7.4. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.0. anndata 0.7.4. cairo 1.20.0. cffi 1.14.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. h5py 2.10.0. igraph 0.8.3. joblib 0.17.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. leidenalg 0.8.2. llvmlite 0.34.0. matplotlib 3.3.2. mkl 2.3.0. mpl_toolkits NA. natsort 7.0.1. numba 0.51.2. numexpr 2.7.1. numpy 1.19.2. packaging 20.4. pandas 1.1.3. pkg_resources NA. pyparsing 2.4.7. pytz 2020.1. scanpy 1.6.0. scipy 1.5.2. setuptools_scm NA. sinfo 0.3.1. six 1.14.0. sklearn 0.23.2. tables 3.6.1. texttable 1.6.3. typing_extensions NA. wcwidth 0.2.5. -----. Python 3.8.3 (default, May 19 2020, 18:47:26) [GCC 7.3.0]. Linux-3.13.0-143-generic-x86_64-with-glibc2.10. 32 logical CPU cores, x86_64. -----. Session information updated at 2020-11-01 11:37. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1477
https://github.com/scverse/scanpy/issues/1477:40,usability,command,command-line,40,"set_figure_params() bug when running at command-line; - [X ] I have checked that this issue has not already been reported. - [X ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. When I run scanpy over an ssh connection to a remote Ubuntu Linux server (so not using the IPython notebooks), the scanpy ""set_figure_params(...)"" command just outputs an ""In :"", and I need to exit using [Ctrl][D]: . ### Minimal code sample (that we can copy&paste without having any data). ```. import scanpy as sc. sc.set_figure_params(figsize=(4, 4)). ```. The output in console is:. ```. In :. In :. ```. and need to press [Crtrl][D] to exit, as otherwise this just loops ""In :"" repeatedly. If I add ""ipython_format=None"":. ```. sc.set_figure_params(figsize=(4, 4), ipython_format=None). ```. then this continues without any ""In :"", and I can continue with script. . I think the reason for this is in the scanpy ""_settings.py"" file:. ```. def set_figure_params(. ......etc..... try:. import IPython. if isinstance(ipython_format, str):. ipython_format = [ipython_format]. IPython.display.set_matplotlib_formats(*ipython_format). except Exception:. pass. from matplotlib import rcParams. .....etc...... ```. where the:. ```. IPython.display.set_matplotlib_formats(*ipython_format). ```. produces this ""In :"" message loop. I think this bug could be fixed by adding ""if self._is_run_from_ipython():"" before the ""try: import IPython"": . ```. def set_figure_params(. ......etc..... if self._is_run_from_ipython():. try:. import IPython. if isinstance(ipython_format, str):. ipython_format = [ipython_format]. IPython.display.set_matplotlib_formats(*ipython_format). except Exception:. pass. ```. The ""try:"" . ```. >>> import IPython. ```. doesn't throw an exception, as IPython is installed:. ```. $ pip show IPython. Name: ipython. Version: 7.18.1. Summary: IPython: Productive Interactive Computing. Home-page: https",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1477
https://github.com/scverse/scanpy/issues/1477:137,usability,confirm,confirmed,137,"set_figure_params() bug when running at command-line; - [X ] I have checked that this issue has not already been reported. - [X ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. When I run scanpy over an ssh connection to a remote Ubuntu Linux server (so not using the IPython notebooks), the scanpy ""set_figure_params(...)"" command just outputs an ""In :"", and I need to exit using [Ctrl][D]: . ### Minimal code sample (that we can copy&paste without having any data). ```. import scanpy as sc. sc.set_figure_params(figsize=(4, 4)). ```. The output in console is:. ```. In :. In :. ```. and need to press [Crtrl][D] to exit, as otherwise this just loops ""In :"" repeatedly. If I add ""ipython_format=None"":. ```. sc.set_figure_params(figsize=(4, 4), ipython_format=None). ```. then this continues without any ""In :"", and I can continue with script. . I think the reason for this is in the scanpy ""_settings.py"" file:. ```. def set_figure_params(. ......etc..... try:. import IPython. if isinstance(ipython_format, str):. ipython_format = [ipython_format]. IPython.display.set_matplotlib_formats(*ipython_format). except Exception:. pass. from matplotlib import rcParams. .....etc...... ```. where the:. ```. IPython.display.set_matplotlib_formats(*ipython_format). ```. produces this ""In :"" message loop. I think this bug could be fixed by adding ""if self._is_run_from_ipython():"" before the ""try: import IPython"": . ```. def set_figure_params(. ......etc..... if self._is_run_from_ipython():. try:. import IPython. if isinstance(ipython_format, str):. ipython_format = [ipython_format]. IPython.display.set_matplotlib_formats(*ipython_format). except Exception:. pass. ```. The ""try:"" . ```. >>> import IPython. ```. doesn't throw an exception, as IPython is installed:. ```. $ pip show IPython. Name: ipython. Version: 7.18.1. Summary: IPython: Productive Interactive Computing. Home-page: https",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1477
https://github.com/scverse/scanpy/issues/1477:220,usability,confirm,confirmed,220,"set_figure_params() bug when running at command-line; - [X ] I have checked that this issue has not already been reported. - [X ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. When I run scanpy over an ssh connection to a remote Ubuntu Linux server (so not using the IPython notebooks), the scanpy ""set_figure_params(...)"" command just outputs an ""In :"", and I need to exit using [Ctrl][D]: . ### Minimal code sample (that we can copy&paste without having any data). ```. import scanpy as sc. sc.set_figure_params(figsize=(4, 4)). ```. The output in console is:. ```. In :. In :. ```. and need to press [Crtrl][D] to exit, as otherwise this just loops ""In :"" repeatedly. If I add ""ipython_format=None"":. ```. sc.set_figure_params(figsize=(4, 4), ipython_format=None). ```. then this continues without any ""In :"", and I can continue with script. . I think the reason for this is in the scanpy ""_settings.py"" file:. ```. def set_figure_params(. ......etc..... try:. import IPython. if isinstance(ipython_format, str):. ipython_format = [ipython_format]. IPython.display.set_matplotlib_formats(*ipython_format). except Exception:. pass. from matplotlib import rcParams. .....etc...... ```. where the:. ```. IPython.display.set_matplotlib_formats(*ipython_format). ```. produces this ""In :"" message loop. I think this bug could be fixed by adding ""if self._is_run_from_ipython():"" before the ""try: import IPython"": . ```. def set_figure_params(. ......etc..... if self._is_run_from_ipython():. try:. import IPython. if isinstance(ipython_format, str):. ipython_format = [ipython_format]. IPython.display.set_matplotlib_formats(*ipython_format). except Exception:. pass. ```. The ""try:"" . ```. >>> import IPython. ```. doesn't throw an exception, as IPython is installed:. ```. $ pip show IPython. Name: ipython. Version: 7.18.1. Summary: IPython: Productive Interactive Computing. Home-page: https",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1477
https://github.com/scverse/scanpy/issues/1477:430,usability,command,command,430,"set_figure_params() bug when running at command-line; - [X ] I have checked that this issue has not already been reported. - [X ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. When I run scanpy over an ssh connection to a remote Ubuntu Linux server (so not using the IPython notebooks), the scanpy ""set_figure_params(...)"" command just outputs an ""In :"", and I need to exit using [Ctrl][D]: . ### Minimal code sample (that we can copy&paste without having any data). ```. import scanpy as sc. sc.set_figure_params(figsize=(4, 4)). ```. The output in console is:. ```. In :. In :. ```. and need to press [Crtrl][D] to exit, as otherwise this just loops ""In :"" repeatedly. If I add ""ipython_format=None"":. ```. sc.set_figure_params(figsize=(4, 4), ipython_format=None). ```. then this continues without any ""In :"", and I can continue with script. . I think the reason for this is in the scanpy ""_settings.py"" file:. ```. def set_figure_params(. ......etc..... try:. import IPython. if isinstance(ipython_format, str):. ipython_format = [ipython_format]. IPython.display.set_matplotlib_formats(*ipython_format). except Exception:. pass. from matplotlib import rcParams. .....etc...... ```. where the:. ```. IPython.display.set_matplotlib_formats(*ipython_format). ```. produces this ""In :"" message loop. I think this bug could be fixed by adding ""if self._is_run_from_ipython():"" before the ""try: import IPython"": . ```. def set_figure_params(. ......etc..... if self._is_run_from_ipython():. try:. import IPython. if isinstance(ipython_format, str):. ipython_format = [ipython_format]. IPython.display.set_matplotlib_formats(*ipython_format). except Exception:. pass. ```. The ""try:"" . ```. >>> import IPython. ```. doesn't throw an exception, as IPython is installed:. ```. $ pip show IPython. Name: ipython. Version: 7.18.1. Summary: IPython: Productive Interactive Computing. Home-page: https",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1477
https://github.com/scverse/scanpy/issues/1477:504,usability,Minim,Minimal,504,"set_figure_params() bug when running at command-line; - [X ] I have checked that this issue has not already been reported. - [X ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. When I run scanpy over an ssh connection to a remote Ubuntu Linux server (so not using the IPython notebooks), the scanpy ""set_figure_params(...)"" command just outputs an ""In :"", and I need to exit using [Ctrl][D]: . ### Minimal code sample (that we can copy&paste without having any data). ```. import scanpy as sc. sc.set_figure_params(figsize=(4, 4)). ```. The output in console is:. ```. In :. In :. ```. and need to press [Crtrl][D] to exit, as otherwise this just loops ""In :"" repeatedly. If I add ""ipython_format=None"":. ```. sc.set_figure_params(figsize=(4, 4), ipython_format=None). ```. then this continues without any ""In :"", and I can continue with script. . I think the reason for this is in the scanpy ""_settings.py"" file:. ```. def set_figure_params(. ......etc..... try:. import IPython. if isinstance(ipython_format, str):. ipython_format = [ipython_format]. IPython.display.set_matplotlib_formats(*ipython_format). except Exception:. pass. from matplotlib import rcParams. .....etc...... ```. where the:. ```. IPython.display.set_matplotlib_formats(*ipython_format). ```. produces this ""In :"" message loop. I think this bug could be fixed by adding ""if self._is_run_from_ipython():"" before the ""try: import IPython"": . ```. def set_figure_params(. ......etc..... if self._is_run_from_ipython():. try:. import IPython. if isinstance(ipython_format, str):. ipython_format = [ipython_format]. IPython.display.set_matplotlib_formats(*ipython_format). except Exception:. pass. ```. The ""try:"" . ```. >>> import IPython. ```. doesn't throw an exception, as IPython is installed:. ```. $ pip show IPython. Name: ipython. Version: 7.18.1. Summary: IPython: Productive Interactive Computing. Home-page: https",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1477
https://github.com/scverse/scanpy/issues/1477:1961,usability,Interact,Interactive,1961,"eason for this is in the scanpy ""_settings.py"" file:. ```. def set_figure_params(. ......etc..... try:. import IPython. if isinstance(ipython_format, str):. ipython_format = [ipython_format]. IPython.display.set_matplotlib_formats(*ipython_format). except Exception:. pass. from matplotlib import rcParams. .....etc...... ```. where the:. ```. IPython.display.set_matplotlib_formats(*ipython_format). ```. produces this ""In :"" message loop. I think this bug could be fixed by adding ""if self._is_run_from_ipython():"" before the ""try: import IPython"": . ```. def set_figure_params(. ......etc..... if self._is_run_from_ipython():. try:. import IPython. if isinstance(ipython_format, str):. ipython_format = [ipython_format]. IPython.display.set_matplotlib_formats(*ipython_format). except Exception:. pass. ```. The ""try:"" . ```. >>> import IPython. ```. doesn't throw an exception, as IPython is installed:. ```. $ pip show IPython. Name: ipython. Version: 7.18.1. Summary: IPython: Productive Interactive Computing. Home-page: https://ipython.org. Author: The IPython Development Team. Author-email: ipython-dev@python.org. License: BSD. Location: /slipstream/home/sbridgett/miniconda3/lib/python3.8/site-packages. Requires: pygments, jedi, prompt-toolkit, backcall, pexpect, setuptools, decorator, traitlets, pickleshare. Required-by: ipywidgets, ipykernel. ```. whereas the _is_run_from_ipython() will correctly ``return False``, as ``__IPYTHON__`` gives an exception:. ```. def _is_run_from_ipython():. """"""Determines whether run from Ipython. Only affects progress bars. """""". try:. __IPYTHON__. return True. except NameError:. return False. ```. #### Versions. <details>. scanpy.logging.print_versions(). -----. anndata 0.7.4. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.0. anndata 0.7.4. cairo 1.20.0. cffi 1.14.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. h5py 2.10.0. igraph 0.8.3. joblib 0.17.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. leidenalg 0.8.2. l",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1477
https://github.com/scverse/scanpy/issues/1477:2216,usability,tool,toolkit,2216,"pt Exception:. pass. from matplotlib import rcParams. .....etc...... ```. where the:. ```. IPython.display.set_matplotlib_formats(*ipython_format). ```. produces this ""In :"" message loop. I think this bug could be fixed by adding ""if self._is_run_from_ipython():"" before the ""try: import IPython"": . ```. def set_figure_params(. ......etc..... if self._is_run_from_ipython():. try:. import IPython. if isinstance(ipython_format, str):. ipython_format = [ipython_format]. IPython.display.set_matplotlib_formats(*ipython_format). except Exception:. pass. ```. The ""try:"" . ```. >>> import IPython. ```. doesn't throw an exception, as IPython is installed:. ```. $ pip show IPython. Name: ipython. Version: 7.18.1. Summary: IPython: Productive Interactive Computing. Home-page: https://ipython.org. Author: The IPython Development Team. Author-email: ipython-dev@python.org. License: BSD. Location: /slipstream/home/sbridgett/miniconda3/lib/python3.8/site-packages. Requires: pygments, jedi, prompt-toolkit, backcall, pexpect, setuptools, decorator, traitlets, pickleshare. Required-by: ipywidgets, ipykernel. ```. whereas the _is_run_from_ipython() will correctly ``return False``, as ``__IPYTHON__`` gives an exception:. ```. def _is_run_from_ipython():. """"""Determines whether run from Ipython. Only affects progress bars. """""". try:. __IPYTHON__. return True. except NameError:. return False. ```. #### Versions. <details>. scanpy.logging.print_versions(). -----. anndata 0.7.4. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.0. anndata 0.7.4. cairo 1.20.0. cffi 1.14.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. h5py 2.10.0. igraph 0.8.3. joblib 0.17.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. leidenalg 0.8.2. llvmlite 0.34.0. matplotlib 3.3.2. mkl 2.3.0. mpl_toolkits NA. natsort 7.0.1. numba 0.51.2. numexpr 2.7.1. numpy 1.19.2. packaging 20.4. pandas 1.1.3. pkg_resources NA. pyparsing 2.4.7. pytz 2020.1. scanpy 1.6.0. scipy 1.5.2. setuptools_scm NA. sinfo 0.3",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1477
https://github.com/scverse/scanpy/issues/1477:2527,usability,progress,progress,2527,"t_figure_params(. ......etc..... if self._is_run_from_ipython():. try:. import IPython. if isinstance(ipython_format, str):. ipython_format = [ipython_format]. IPython.display.set_matplotlib_formats(*ipython_format). except Exception:. pass. ```. The ""try:"" . ```. >>> import IPython. ```. doesn't throw an exception, as IPython is installed:. ```. $ pip show IPython. Name: ipython. Version: 7.18.1. Summary: IPython: Productive Interactive Computing. Home-page: https://ipython.org. Author: The IPython Development Team. Author-email: ipython-dev@python.org. License: BSD. Location: /slipstream/home/sbridgett/miniconda3/lib/python3.8/site-packages. Requires: pygments, jedi, prompt-toolkit, backcall, pexpect, setuptools, decorator, traitlets, pickleshare. Required-by: ipywidgets, ipykernel. ```. whereas the _is_run_from_ipython() will correctly ``return False``, as ``__IPYTHON__`` gives an exception:. ```. def _is_run_from_ipython():. """"""Determines whether run from Ipython. Only affects progress bars. """""". try:. __IPYTHON__. return True. except NameError:. return False. ```. #### Versions. <details>. scanpy.logging.print_versions(). -----. anndata 0.7.4. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.0. anndata 0.7.4. cairo 1.20.0. cffi 1.14.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. get_version 2.1. h5py 2.10.0. igraph 0.8.3. joblib 0.17.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. leidenalg 0.8.2. llvmlite 0.34.0. matplotlib 3.3.2. mkl 2.3.0. mpl_toolkits NA. natsort 7.0.1. numba 0.51.2. numexpr 2.7.1. numpy 1.19.2. packaging 20.4. pandas 1.1.3. pkg_resources NA. pyparsing 2.4.7. pytz 2020.1. scanpy 1.6.0. scipy 1.5.2. setuptools_scm NA. sinfo 0.3.1. six 1.14.0. sklearn 0.23.2. tables 3.6.1. texttable 1.6.3. typing_extensions NA. wcwidth 0.2.5. -----. Python 3.8.3 (default, May 19 2020, 18:47:26) [GCC 7.3.0]. Linux-3.13.0-143-generic-x86_64-with-glibc2.10. 32 logical CPU cores, x86_64. -----. Session information updated at 2020-11-01 11:37. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1477
https://github.com/scverse/scanpy/issues/1478:31,availability,error,errors,31,"sc.tl.rank_genes_groups return errors; Hi, I found that using the sc.tl.rank_genes_groups to perform differential gene expression analysis return the following error. ---. ```python. adata = sc.datasets.pbmc68k_reduced(). sc.tl.rank_genes_groups(adata, 'bulk_labels', method='wilcoxon'). ```. ```pytb. ranking genes. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-92-a8f4e965724c> in <module>. 1 adata = sc.datasets.pbmc68k_reduced(). ----> 2 sc.tl.rank_genes_groups(adata, 'bulk_labels', method='wilcoxon'). /mnt/data4/weixu/miniconda3_R_4.0/envs/celloracle_env/lib/python3.6/site-packages/scanpy/tools/_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, tie_correct, layer, **kwds). 607 for col in test_obj.stats.columns.levels[0]:. 608 adata.uns[key_added][col] = test_obj.stats[col].to_records(. --> 609 index=False, column_dtypes=dtypes[col]. 610 ). 611 . TypeError: to_records() got an unexpected keyword argument 'column_dtypes'. ```. I was wondering that its associate with my pandas version? or other issues? my pandas version 0.23.4",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1478
https://github.com/scverse/scanpy/issues/1478:160,availability,error,error,160,"sc.tl.rank_genes_groups return errors; Hi, I found that using the sc.tl.rank_genes_groups to perform differential gene expression analysis return the following error. ---. ```python. adata = sc.datasets.pbmc68k_reduced(). sc.tl.rank_genes_groups(adata, 'bulk_labels', method='wilcoxon'). ```. ```pytb. ranking genes. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-92-a8f4e965724c> in <module>. 1 adata = sc.datasets.pbmc68k_reduced(). ----> 2 sc.tl.rank_genes_groups(adata, 'bulk_labels', method='wilcoxon'). /mnt/data4/weixu/miniconda3_R_4.0/envs/celloracle_env/lib/python3.6/site-packages/scanpy/tools/_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, tie_correct, layer, **kwds). 607 for col in test_obj.stats.columns.levels[0]:. 608 adata.uns[key_added][col] = test_obj.stats[col].to_records(. --> 609 index=False, column_dtypes=dtypes[col]. 610 ). 611 . TypeError: to_records() got an unexpected keyword argument 'column_dtypes'. ```. I was wondering that its associate with my pandas version? or other issues? my pandas version 0.23.4",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1478
https://github.com/scverse/scanpy/issues/1478:475,deployability,modul,module,475,"sc.tl.rank_genes_groups return errors; Hi, I found that using the sc.tl.rank_genes_groups to perform differential gene expression analysis return the following error. ---. ```python. adata = sc.datasets.pbmc68k_reduced(). sc.tl.rank_genes_groups(adata, 'bulk_labels', method='wilcoxon'). ```. ```pytb. ranking genes. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-92-a8f4e965724c> in <module>. 1 adata = sc.datasets.pbmc68k_reduced(). ----> 2 sc.tl.rank_genes_groups(adata, 'bulk_labels', method='wilcoxon'). /mnt/data4/weixu/miniconda3_R_4.0/envs/celloracle_env/lib/python3.6/site-packages/scanpy/tools/_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, tie_correct, layer, **kwds). 607 for col in test_obj.stats.columns.levels[0]:. 608 adata.uns[key_added][col] = test_obj.stats[col].to_records(. --> 609 index=False, column_dtypes=dtypes[col]. 610 ). 611 . TypeError: to_records() got an unexpected keyword argument 'column_dtypes'. ```. I was wondering that its associate with my pandas version? or other issues? my pandas version 0.23.4",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1478
https://github.com/scverse/scanpy/issues/1478:1181,deployability,version,version,1181,"sc.tl.rank_genes_groups return errors; Hi, I found that using the sc.tl.rank_genes_groups to perform differential gene expression analysis return the following error. ---. ```python. adata = sc.datasets.pbmc68k_reduced(). sc.tl.rank_genes_groups(adata, 'bulk_labels', method='wilcoxon'). ```. ```pytb. ranking genes. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-92-a8f4e965724c> in <module>. 1 adata = sc.datasets.pbmc68k_reduced(). ----> 2 sc.tl.rank_genes_groups(adata, 'bulk_labels', method='wilcoxon'). /mnt/data4/weixu/miniconda3_R_4.0/envs/celloracle_env/lib/python3.6/site-packages/scanpy/tools/_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, tie_correct, layer, **kwds). 607 for col in test_obj.stats.columns.levels[0]:. 608 adata.uns[key_added][col] = test_obj.stats[col].to_records(. --> 609 index=False, column_dtypes=dtypes[col]. 610 ). 611 . TypeError: to_records() got an unexpected keyword argument 'column_dtypes'. ```. I was wondering that its associate with my pandas version? or other issues? my pandas version 0.23.4",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1478
https://github.com/scverse/scanpy/issues/1478:1217,deployability,version,version,1217,"sc.tl.rank_genes_groups return errors; Hi, I found that using the sc.tl.rank_genes_groups to perform differential gene expression analysis return the following error. ---. ```python. adata = sc.datasets.pbmc68k_reduced(). sc.tl.rank_genes_groups(adata, 'bulk_labels', method='wilcoxon'). ```. ```pytb. ranking genes. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-92-a8f4e965724c> in <module>. 1 adata = sc.datasets.pbmc68k_reduced(). ----> 2 sc.tl.rank_genes_groups(adata, 'bulk_labels', method='wilcoxon'). /mnt/data4/weixu/miniconda3_R_4.0/envs/celloracle_env/lib/python3.6/site-packages/scanpy/tools/_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, tie_correct, layer, **kwds). 607 for col in test_obj.stats.columns.levels[0]:. 608 adata.uns[key_added][col] = test_obj.stats[col].to_records(. --> 609 index=False, column_dtypes=dtypes[col]. 610 ). 611 . TypeError: to_records() got an unexpected keyword argument 'column_dtypes'. ```. I was wondering that its associate with my pandas version? or other issues? my pandas version 0.23.4",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1478
https://github.com/scverse/scanpy/issues/1478:1181,integrability,version,version,1181,"sc.tl.rank_genes_groups return errors; Hi, I found that using the sc.tl.rank_genes_groups to perform differential gene expression analysis return the following error. ---. ```python. adata = sc.datasets.pbmc68k_reduced(). sc.tl.rank_genes_groups(adata, 'bulk_labels', method='wilcoxon'). ```. ```pytb. ranking genes. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-92-a8f4e965724c> in <module>. 1 adata = sc.datasets.pbmc68k_reduced(). ----> 2 sc.tl.rank_genes_groups(adata, 'bulk_labels', method='wilcoxon'). /mnt/data4/weixu/miniconda3_R_4.0/envs/celloracle_env/lib/python3.6/site-packages/scanpy/tools/_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, tie_correct, layer, **kwds). 607 for col in test_obj.stats.columns.levels[0]:. 608 adata.uns[key_added][col] = test_obj.stats[col].to_records(. --> 609 index=False, column_dtypes=dtypes[col]. 610 ). 611 . TypeError: to_records() got an unexpected keyword argument 'column_dtypes'. ```. I was wondering that its associate with my pandas version? or other issues? my pandas version 0.23.4",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1478
https://github.com/scverse/scanpy/issues/1478:1217,integrability,version,version,1217,"sc.tl.rank_genes_groups return errors; Hi, I found that using the sc.tl.rank_genes_groups to perform differential gene expression analysis return the following error. ---. ```python. adata = sc.datasets.pbmc68k_reduced(). sc.tl.rank_genes_groups(adata, 'bulk_labels', method='wilcoxon'). ```. ```pytb. ranking genes. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-92-a8f4e965724c> in <module>. 1 adata = sc.datasets.pbmc68k_reduced(). ----> 2 sc.tl.rank_genes_groups(adata, 'bulk_labels', method='wilcoxon'). /mnt/data4/weixu/miniconda3_R_4.0/envs/celloracle_env/lib/python3.6/site-packages/scanpy/tools/_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, tie_correct, layer, **kwds). 607 for col in test_obj.stats.columns.levels[0]:. 608 adata.uns[key_added][col] = test_obj.stats[col].to_records(. --> 609 index=False, column_dtypes=dtypes[col]. 610 ). 611 . TypeError: to_records() got an unexpected keyword argument 'column_dtypes'. ```. I was wondering that its associate with my pandas version? or other issues? my pandas version 0.23.4",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1478
https://github.com/scverse/scanpy/issues/1478:475,modifiability,modul,module,475,"sc.tl.rank_genes_groups return errors; Hi, I found that using the sc.tl.rank_genes_groups to perform differential gene expression analysis return the following error. ---. ```python. adata = sc.datasets.pbmc68k_reduced(). sc.tl.rank_genes_groups(adata, 'bulk_labels', method='wilcoxon'). ```. ```pytb. ranking genes. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-92-a8f4e965724c> in <module>. 1 adata = sc.datasets.pbmc68k_reduced(). ----> 2 sc.tl.rank_genes_groups(adata, 'bulk_labels', method='wilcoxon'). /mnt/data4/weixu/miniconda3_R_4.0/envs/celloracle_env/lib/python3.6/site-packages/scanpy/tools/_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, tie_correct, layer, **kwds). 607 for col in test_obj.stats.columns.levels[0]:. 608 adata.uns[key_added][col] = test_obj.stats[col].to_records(. --> 609 index=False, column_dtypes=dtypes[col]. 610 ). 611 . TypeError: to_records() got an unexpected keyword argument 'column_dtypes'. ```. I was wondering that its associate with my pandas version? or other issues? my pandas version 0.23.4",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1478
https://github.com/scverse/scanpy/issues/1478:672,modifiability,pac,packages,672,"sc.tl.rank_genes_groups return errors; Hi, I found that using the sc.tl.rank_genes_groups to perform differential gene expression analysis return the following error. ---. ```python. adata = sc.datasets.pbmc68k_reduced(). sc.tl.rank_genes_groups(adata, 'bulk_labels', method='wilcoxon'). ```. ```pytb. ranking genes. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-92-a8f4e965724c> in <module>. 1 adata = sc.datasets.pbmc68k_reduced(). ----> 2 sc.tl.rank_genes_groups(adata, 'bulk_labels', method='wilcoxon'). /mnt/data4/weixu/miniconda3_R_4.0/envs/celloracle_env/lib/python3.6/site-packages/scanpy/tools/_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, tie_correct, layer, **kwds). 607 for col in test_obj.stats.columns.levels[0]:. 608 adata.uns[key_added][col] = test_obj.stats[col].to_records(. --> 609 index=False, column_dtypes=dtypes[col]. 610 ). 611 . TypeError: to_records() got an unexpected keyword argument 'column_dtypes'. ```. I was wondering that its associate with my pandas version? or other issues? my pandas version 0.23.4",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1478
https://github.com/scverse/scanpy/issues/1478:858,modifiability,layer,layer,858,"sc.tl.rank_genes_groups return errors; Hi, I found that using the sc.tl.rank_genes_groups to perform differential gene expression analysis return the following error. ---. ```python. adata = sc.datasets.pbmc68k_reduced(). sc.tl.rank_genes_groups(adata, 'bulk_labels', method='wilcoxon'). ```. ```pytb. ranking genes. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-92-a8f4e965724c> in <module>. 1 adata = sc.datasets.pbmc68k_reduced(). ----> 2 sc.tl.rank_genes_groups(adata, 'bulk_labels', method='wilcoxon'). /mnt/data4/weixu/miniconda3_R_4.0/envs/celloracle_env/lib/python3.6/site-packages/scanpy/tools/_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, tie_correct, layer, **kwds). 607 for col in test_obj.stats.columns.levels[0]:. 608 adata.uns[key_added][col] = test_obj.stats[col].to_records(. --> 609 index=False, column_dtypes=dtypes[col]. 610 ). 611 . TypeError: to_records() got an unexpected keyword argument 'column_dtypes'. ```. I was wondering that its associate with my pandas version? or other issues? my pandas version 0.23.4",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1478
https://github.com/scverse/scanpy/issues/1478:1181,modifiability,version,version,1181,"sc.tl.rank_genes_groups return errors; Hi, I found that using the sc.tl.rank_genes_groups to perform differential gene expression analysis return the following error. ---. ```python. adata = sc.datasets.pbmc68k_reduced(). sc.tl.rank_genes_groups(adata, 'bulk_labels', method='wilcoxon'). ```. ```pytb. ranking genes. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-92-a8f4e965724c> in <module>. 1 adata = sc.datasets.pbmc68k_reduced(). ----> 2 sc.tl.rank_genes_groups(adata, 'bulk_labels', method='wilcoxon'). /mnt/data4/weixu/miniconda3_R_4.0/envs/celloracle_env/lib/python3.6/site-packages/scanpy/tools/_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, tie_correct, layer, **kwds). 607 for col in test_obj.stats.columns.levels[0]:. 608 adata.uns[key_added][col] = test_obj.stats[col].to_records(. --> 609 index=False, column_dtypes=dtypes[col]. 610 ). 611 . TypeError: to_records() got an unexpected keyword argument 'column_dtypes'. ```. I was wondering that its associate with my pandas version? or other issues? my pandas version 0.23.4",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1478
https://github.com/scverse/scanpy/issues/1478:1217,modifiability,version,version,1217,"sc.tl.rank_genes_groups return errors; Hi, I found that using the sc.tl.rank_genes_groups to perform differential gene expression analysis return the following error. ---. ```python. adata = sc.datasets.pbmc68k_reduced(). sc.tl.rank_genes_groups(adata, 'bulk_labels', method='wilcoxon'). ```. ```pytb. ranking genes. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-92-a8f4e965724c> in <module>. 1 adata = sc.datasets.pbmc68k_reduced(). ----> 2 sc.tl.rank_genes_groups(adata, 'bulk_labels', method='wilcoxon'). /mnt/data4/weixu/miniconda3_R_4.0/envs/celloracle_env/lib/python3.6/site-packages/scanpy/tools/_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, tie_correct, layer, **kwds). 607 for col in test_obj.stats.columns.levels[0]:. 608 adata.uns[key_added][col] = test_obj.stats[col].to_records(. --> 609 index=False, column_dtypes=dtypes[col]. 610 ). 611 . TypeError: to_records() got an unexpected keyword argument 'column_dtypes'. ```. I was wondering that its associate with my pandas version? or other issues? my pandas version 0.23.4",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1478
https://github.com/scverse/scanpy/issues/1478:31,performance,error,errors,31,"sc.tl.rank_genes_groups return errors; Hi, I found that using the sc.tl.rank_genes_groups to perform differential gene expression analysis return the following error. ---. ```python. adata = sc.datasets.pbmc68k_reduced(). sc.tl.rank_genes_groups(adata, 'bulk_labels', method='wilcoxon'). ```. ```pytb. ranking genes. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-92-a8f4e965724c> in <module>. 1 adata = sc.datasets.pbmc68k_reduced(). ----> 2 sc.tl.rank_genes_groups(adata, 'bulk_labels', method='wilcoxon'). /mnt/data4/weixu/miniconda3_R_4.0/envs/celloracle_env/lib/python3.6/site-packages/scanpy/tools/_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, tie_correct, layer, **kwds). 607 for col in test_obj.stats.columns.levels[0]:. 608 adata.uns[key_added][col] = test_obj.stats[col].to_records(. --> 609 index=False, column_dtypes=dtypes[col]. 610 ). 611 . TypeError: to_records() got an unexpected keyword argument 'column_dtypes'. ```. I was wondering that its associate with my pandas version? or other issues? my pandas version 0.23.4",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1478
https://github.com/scverse/scanpy/issues/1478:93,performance,perform,perform,93,"sc.tl.rank_genes_groups return errors; Hi, I found that using the sc.tl.rank_genes_groups to perform differential gene expression analysis return the following error. ---. ```python. adata = sc.datasets.pbmc68k_reduced(). sc.tl.rank_genes_groups(adata, 'bulk_labels', method='wilcoxon'). ```. ```pytb. ranking genes. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-92-a8f4e965724c> in <module>. 1 adata = sc.datasets.pbmc68k_reduced(). ----> 2 sc.tl.rank_genes_groups(adata, 'bulk_labels', method='wilcoxon'). /mnt/data4/weixu/miniconda3_R_4.0/envs/celloracle_env/lib/python3.6/site-packages/scanpy/tools/_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, tie_correct, layer, **kwds). 607 for col in test_obj.stats.columns.levels[0]:. 608 adata.uns[key_added][col] = test_obj.stats[col].to_records(. --> 609 index=False, column_dtypes=dtypes[col]. 610 ). 611 . TypeError: to_records() got an unexpected keyword argument 'column_dtypes'. ```. I was wondering that its associate with my pandas version? or other issues? my pandas version 0.23.4",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1478
https://github.com/scverse/scanpy/issues/1478:160,performance,error,error,160,"sc.tl.rank_genes_groups return errors; Hi, I found that using the sc.tl.rank_genes_groups to perform differential gene expression analysis return the following error. ---. ```python. adata = sc.datasets.pbmc68k_reduced(). sc.tl.rank_genes_groups(adata, 'bulk_labels', method='wilcoxon'). ```. ```pytb. ranking genes. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-92-a8f4e965724c> in <module>. 1 adata = sc.datasets.pbmc68k_reduced(). ----> 2 sc.tl.rank_genes_groups(adata, 'bulk_labels', method='wilcoxon'). /mnt/data4/weixu/miniconda3_R_4.0/envs/celloracle_env/lib/python3.6/site-packages/scanpy/tools/_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, tie_correct, layer, **kwds). 607 for col in test_obj.stats.columns.levels[0]:. 608 adata.uns[key_added][col] = test_obj.stats[col].to_records(. --> 609 index=False, column_dtypes=dtypes[col]. 610 ). 611 . TypeError: to_records() got an unexpected keyword argument 'column_dtypes'. ```. I was wondering that its associate with my pandas version? or other issues? my pandas version 0.23.4",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1478
https://github.com/scverse/scanpy/issues/1478:31,safety,error,errors,31,"sc.tl.rank_genes_groups return errors; Hi, I found that using the sc.tl.rank_genes_groups to perform differential gene expression analysis return the following error. ---. ```python. adata = sc.datasets.pbmc68k_reduced(). sc.tl.rank_genes_groups(adata, 'bulk_labels', method='wilcoxon'). ```. ```pytb. ranking genes. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-92-a8f4e965724c> in <module>. 1 adata = sc.datasets.pbmc68k_reduced(). ----> 2 sc.tl.rank_genes_groups(adata, 'bulk_labels', method='wilcoxon'). /mnt/data4/weixu/miniconda3_R_4.0/envs/celloracle_env/lib/python3.6/site-packages/scanpy/tools/_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, tie_correct, layer, **kwds). 607 for col in test_obj.stats.columns.levels[0]:. 608 adata.uns[key_added][col] = test_obj.stats[col].to_records(. --> 609 index=False, column_dtypes=dtypes[col]. 610 ). 611 . TypeError: to_records() got an unexpected keyword argument 'column_dtypes'. ```. I was wondering that its associate with my pandas version? or other issues? my pandas version 0.23.4",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1478
https://github.com/scverse/scanpy/issues/1478:160,safety,error,error,160,"sc.tl.rank_genes_groups return errors; Hi, I found that using the sc.tl.rank_genes_groups to perform differential gene expression analysis return the following error. ---. ```python. adata = sc.datasets.pbmc68k_reduced(). sc.tl.rank_genes_groups(adata, 'bulk_labels', method='wilcoxon'). ```. ```pytb. ranking genes. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-92-a8f4e965724c> in <module>. 1 adata = sc.datasets.pbmc68k_reduced(). ----> 2 sc.tl.rank_genes_groups(adata, 'bulk_labels', method='wilcoxon'). /mnt/data4/weixu/miniconda3_R_4.0/envs/celloracle_env/lib/python3.6/site-packages/scanpy/tools/_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, tie_correct, layer, **kwds). 607 for col in test_obj.stats.columns.levels[0]:. 608 adata.uns[key_added][col] = test_obj.stats[col].to_records(. --> 609 index=False, column_dtypes=dtypes[col]. 610 ). 611 . TypeError: to_records() got an unexpected keyword argument 'column_dtypes'. ```. I was wondering that its associate with my pandas version? or other issues? my pandas version 0.23.4",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1478
https://github.com/scverse/scanpy/issues/1478:448,safety,input,input-,448,"sc.tl.rank_genes_groups return errors; Hi, I found that using the sc.tl.rank_genes_groups to perform differential gene expression analysis return the following error. ---. ```python. adata = sc.datasets.pbmc68k_reduced(). sc.tl.rank_genes_groups(adata, 'bulk_labels', method='wilcoxon'). ```. ```pytb. ranking genes. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-92-a8f4e965724c> in <module>. 1 adata = sc.datasets.pbmc68k_reduced(). ----> 2 sc.tl.rank_genes_groups(adata, 'bulk_labels', method='wilcoxon'). /mnt/data4/weixu/miniconda3_R_4.0/envs/celloracle_env/lib/python3.6/site-packages/scanpy/tools/_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, tie_correct, layer, **kwds). 607 for col in test_obj.stats.columns.levels[0]:. 608 adata.uns[key_added][col] = test_obj.stats[col].to_records(. --> 609 index=False, column_dtypes=dtypes[col]. 610 ). 611 . TypeError: to_records() got an unexpected keyword argument 'column_dtypes'. ```. I was wondering that its associate with my pandas version? or other issues? my pandas version 0.23.4",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1478
https://github.com/scverse/scanpy/issues/1478:475,safety,modul,module,475,"sc.tl.rank_genes_groups return errors; Hi, I found that using the sc.tl.rank_genes_groups to perform differential gene expression analysis return the following error. ---. ```python. adata = sc.datasets.pbmc68k_reduced(). sc.tl.rank_genes_groups(adata, 'bulk_labels', method='wilcoxon'). ```. ```pytb. ranking genes. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-92-a8f4e965724c> in <module>. 1 adata = sc.datasets.pbmc68k_reduced(). ----> 2 sc.tl.rank_genes_groups(adata, 'bulk_labels', method='wilcoxon'). /mnt/data4/weixu/miniconda3_R_4.0/envs/celloracle_env/lib/python3.6/site-packages/scanpy/tools/_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, tie_correct, layer, **kwds). 607 for col in test_obj.stats.columns.levels[0]:. 608 adata.uns[key_added][col] = test_obj.stats[col].to_records(. --> 609 index=False, column_dtypes=dtypes[col]. 610 ). 611 . TypeError: to_records() got an unexpected keyword argument 'column_dtypes'. ```. I was wondering that its associate with my pandas version? or other issues? my pandas version 0.23.4",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1478
https://github.com/scverse/scanpy/issues/1478:404,testability,Trace,Traceback,404,"sc.tl.rank_genes_groups return errors; Hi, I found that using the sc.tl.rank_genes_groups to perform differential gene expression analysis return the following error. ---. ```python. adata = sc.datasets.pbmc68k_reduced(). sc.tl.rank_genes_groups(adata, 'bulk_labels', method='wilcoxon'). ```. ```pytb. ranking genes. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-92-a8f4e965724c> in <module>. 1 adata = sc.datasets.pbmc68k_reduced(). ----> 2 sc.tl.rank_genes_groups(adata, 'bulk_labels', method='wilcoxon'). /mnt/data4/weixu/miniconda3_R_4.0/envs/celloracle_env/lib/python3.6/site-packages/scanpy/tools/_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, tie_correct, layer, **kwds). 607 for col in test_obj.stats.columns.levels[0]:. 608 adata.uns[key_added][col] = test_obj.stats[col].to_records(. --> 609 index=False, column_dtypes=dtypes[col]. 610 ). 611 . TypeError: to_records() got an unexpected keyword argument 'column_dtypes'. ```. I was wondering that its associate with my pandas version? or other issues? my pandas version 0.23.4",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1478
https://github.com/scverse/scanpy/issues/1478:31,usability,error,errors,31,"sc.tl.rank_genes_groups return errors; Hi, I found that using the sc.tl.rank_genes_groups to perform differential gene expression analysis return the following error. ---. ```python. adata = sc.datasets.pbmc68k_reduced(). sc.tl.rank_genes_groups(adata, 'bulk_labels', method='wilcoxon'). ```. ```pytb. ranking genes. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-92-a8f4e965724c> in <module>. 1 adata = sc.datasets.pbmc68k_reduced(). ----> 2 sc.tl.rank_genes_groups(adata, 'bulk_labels', method='wilcoxon'). /mnt/data4/weixu/miniconda3_R_4.0/envs/celloracle_env/lib/python3.6/site-packages/scanpy/tools/_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, tie_correct, layer, **kwds). 607 for col in test_obj.stats.columns.levels[0]:. 608 adata.uns[key_added][col] = test_obj.stats[col].to_records(. --> 609 index=False, column_dtypes=dtypes[col]. 610 ). 611 . TypeError: to_records() got an unexpected keyword argument 'column_dtypes'. ```. I was wondering that its associate with my pandas version? or other issues? my pandas version 0.23.4",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1478
https://github.com/scverse/scanpy/issues/1478:93,usability,perform,perform,93,"sc.tl.rank_genes_groups return errors; Hi, I found that using the sc.tl.rank_genes_groups to perform differential gene expression analysis return the following error. ---. ```python. adata = sc.datasets.pbmc68k_reduced(). sc.tl.rank_genes_groups(adata, 'bulk_labels', method='wilcoxon'). ```. ```pytb. ranking genes. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-92-a8f4e965724c> in <module>. 1 adata = sc.datasets.pbmc68k_reduced(). ----> 2 sc.tl.rank_genes_groups(adata, 'bulk_labels', method='wilcoxon'). /mnt/data4/weixu/miniconda3_R_4.0/envs/celloracle_env/lib/python3.6/site-packages/scanpy/tools/_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, tie_correct, layer, **kwds). 607 for col in test_obj.stats.columns.levels[0]:. 608 adata.uns[key_added][col] = test_obj.stats[col].to_records(. --> 609 index=False, column_dtypes=dtypes[col]. 610 ). 611 . TypeError: to_records() got an unexpected keyword argument 'column_dtypes'. ```. I was wondering that its associate with my pandas version? or other issues? my pandas version 0.23.4",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1478
https://github.com/scverse/scanpy/issues/1478:160,usability,error,error,160,"sc.tl.rank_genes_groups return errors; Hi, I found that using the sc.tl.rank_genes_groups to perform differential gene expression analysis return the following error. ---. ```python. adata = sc.datasets.pbmc68k_reduced(). sc.tl.rank_genes_groups(adata, 'bulk_labels', method='wilcoxon'). ```. ```pytb. ranking genes. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-92-a8f4e965724c> in <module>. 1 adata = sc.datasets.pbmc68k_reduced(). ----> 2 sc.tl.rank_genes_groups(adata, 'bulk_labels', method='wilcoxon'). /mnt/data4/weixu/miniconda3_R_4.0/envs/celloracle_env/lib/python3.6/site-packages/scanpy/tools/_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, tie_correct, layer, **kwds). 607 for col in test_obj.stats.columns.levels[0]:. 608 adata.uns[key_added][col] = test_obj.stats[col].to_records(. --> 609 index=False, column_dtypes=dtypes[col]. 610 ). 611 . TypeError: to_records() got an unexpected keyword argument 'column_dtypes'. ```. I was wondering that its associate with my pandas version? or other issues? my pandas version 0.23.4",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1478
https://github.com/scverse/scanpy/issues/1478:448,usability,input,input-,448,"sc.tl.rank_genes_groups return errors; Hi, I found that using the sc.tl.rank_genes_groups to perform differential gene expression analysis return the following error. ---. ```python. adata = sc.datasets.pbmc68k_reduced(). sc.tl.rank_genes_groups(adata, 'bulk_labels', method='wilcoxon'). ```. ```pytb. ranking genes. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-92-a8f4e965724c> in <module>. 1 adata = sc.datasets.pbmc68k_reduced(). ----> 2 sc.tl.rank_genes_groups(adata, 'bulk_labels', method='wilcoxon'). /mnt/data4/weixu/miniconda3_R_4.0/envs/celloracle_env/lib/python3.6/site-packages/scanpy/tools/_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, tie_correct, layer, **kwds). 607 for col in test_obj.stats.columns.levels[0]:. 608 adata.uns[key_added][col] = test_obj.stats[col].to_records(. --> 609 index=False, column_dtypes=dtypes[col]. 610 ). 611 . TypeError: to_records() got an unexpected keyword argument 'column_dtypes'. ```. I was wondering that its associate with my pandas version? or other issues? my pandas version 0.23.4",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1478
https://github.com/scverse/scanpy/issues/1478:688,usability,tool,tools,688,"sc.tl.rank_genes_groups return errors; Hi, I found that using the sc.tl.rank_genes_groups to perform differential gene expression analysis return the following error. ---. ```python. adata = sc.datasets.pbmc68k_reduced(). sc.tl.rank_genes_groups(adata, 'bulk_labels', method='wilcoxon'). ```. ```pytb. ranking genes. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-92-a8f4e965724c> in <module>. 1 adata = sc.datasets.pbmc68k_reduced(). ----> 2 sc.tl.rank_genes_groups(adata, 'bulk_labels', method='wilcoxon'). /mnt/data4/weixu/miniconda3_R_4.0/envs/celloracle_env/lib/python3.6/site-packages/scanpy/tools/_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, tie_correct, layer, **kwds). 607 for col in test_obj.stats.columns.levels[0]:. 608 adata.uns[key_added][col] = test_obj.stats[col].to_records(. --> 609 index=False, column_dtypes=dtypes[col]. 610 ). 611 . TypeError: to_records() got an unexpected keyword argument 'column_dtypes'. ```. I was wondering that its associate with my pandas version? or other issues? my pandas version 0.23.4",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1478
https://github.com/scverse/scanpy/issues/1479:12,availability,cluster,cluster,12,"Mismatching cluster color codes in sc.pl.heatmap; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Description. The issue is visible/reproducibe from the [plotting tutorial](https://scanpy-tutorials.readthedocs.io/en/latest/plotting/core.html#Heatmaps) in cell 23. Here, as an example, Cluster 3/NK cells are associated with the marker genes GNLY and NKG7. However, the cluster color code representing the rows and columns of the heatmap are mismatching. Cluster 3 is summarized using violet on the cell level (color bar below the heatmap) and using green for grouping Cluster 3 associated markers GNLY and NKG7 (color bar on the right). I would expect that these color codes match. ### Minimal code sample. Below are a few lines to reproduce this behaviour:. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). sc.tl.leiden(pbmc, key_added='clusters', resolution=0.5). marker_genes_dict = {'NK': ['GNLY', 'NKG7'],. 'T-cell': ['CD3D'],. 'B-cell': ['CD79A', 'MS4A1'],. 'Monocytes': ['FCGR3A'],. 'Dendritic': ['FCER1A']}. sc.pl.heatmap(pbmc, marker_genes_dict, groupby='clusters', vmin=-2, vmax=2, cmap='RdBu_r', dendrogram=True, swap_axes=True). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479
https://github.com/scverse/scanpy/issues/1479:468,availability,Cluster,Cluster,468,"Mismatching cluster color codes in sc.pl.heatmap; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Description. The issue is visible/reproducibe from the [plotting tutorial](https://scanpy-tutorials.readthedocs.io/en/latest/plotting/core.html#Heatmaps) in cell 23. Here, as an example, Cluster 3/NK cells are associated with the marker genes GNLY and NKG7. However, the cluster color code representing the rows and columns of the heatmap are mismatching. Cluster 3 is summarized using violet on the cell level (color bar below the heatmap) and using green for grouping Cluster 3 associated markers GNLY and NKG7 (color bar on the right). I would expect that these color codes match. ### Minimal code sample. Below are a few lines to reproduce this behaviour:. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). sc.tl.leiden(pbmc, key_added='clusters', resolution=0.5). marker_genes_dict = {'NK': ['GNLY', 'NKG7'],. 'T-cell': ['CD3D'],. 'B-cell': ['CD79A', 'MS4A1'],. 'Monocytes': ['FCGR3A'],. 'Dendritic': ['FCER1A']}. sc.pl.heatmap(pbmc, marker_genes_dict, groupby='clusters', vmin=-2, vmax=2, cmap='RdBu_r', dendrogram=True, swap_axes=True). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479
https://github.com/scverse/scanpy/issues/1479:552,availability,cluster,cluster,552,"Mismatching cluster color codes in sc.pl.heatmap; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Description. The issue is visible/reproducibe from the [plotting tutorial](https://scanpy-tutorials.readthedocs.io/en/latest/plotting/core.html#Heatmaps) in cell 23. Here, as an example, Cluster 3/NK cells are associated with the marker genes GNLY and NKG7. However, the cluster color code representing the rows and columns of the heatmap are mismatching. Cluster 3 is summarized using violet on the cell level (color bar below the heatmap) and using green for grouping Cluster 3 associated markers GNLY and NKG7 (color bar on the right). I would expect that these color codes match. ### Minimal code sample. Below are a few lines to reproduce this behaviour:. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). sc.tl.leiden(pbmc, key_added='clusters', resolution=0.5). marker_genes_dict = {'NK': ['GNLY', 'NKG7'],. 'T-cell': ['CD3D'],. 'B-cell': ['CD79A', 'MS4A1'],. 'Monocytes': ['FCGR3A'],. 'Dendritic': ['FCER1A']}. sc.pl.heatmap(pbmc, marker_genes_dict, groupby='clusters', vmin=-2, vmax=2, cmap='RdBu_r', dendrogram=True, swap_axes=True). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479
https://github.com/scverse/scanpy/issues/1479:637,availability,Cluster,Cluster,637,"Mismatching cluster color codes in sc.pl.heatmap; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Description. The issue is visible/reproducibe from the [plotting tutorial](https://scanpy-tutorials.readthedocs.io/en/latest/plotting/core.html#Heatmaps) in cell 23. Here, as an example, Cluster 3/NK cells are associated with the marker genes GNLY and NKG7. However, the cluster color code representing the rows and columns of the heatmap are mismatching. Cluster 3 is summarized using violet on the cell level (color bar below the heatmap) and using green for grouping Cluster 3 associated markers GNLY and NKG7 (color bar on the right). I would expect that these color codes match. ### Minimal code sample. Below are a few lines to reproduce this behaviour:. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). sc.tl.leiden(pbmc, key_added='clusters', resolution=0.5). marker_genes_dict = {'NK': ['GNLY', 'NKG7'],. 'T-cell': ['CD3D'],. 'B-cell': ['CD79A', 'MS4A1'],. 'Monocytes': ['FCGR3A'],. 'Dendritic': ['FCER1A']}. sc.pl.heatmap(pbmc, marker_genes_dict, groupby='clusters', vmin=-2, vmax=2, cmap='RdBu_r', dendrogram=True, swap_axes=True). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479
https://github.com/scverse/scanpy/issues/1479:751,availability,Cluster,Cluster,751,"Mismatching cluster color codes in sc.pl.heatmap; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Description. The issue is visible/reproducibe from the [plotting tutorial](https://scanpy-tutorials.readthedocs.io/en/latest/plotting/core.html#Heatmaps) in cell 23. Here, as an example, Cluster 3/NK cells are associated with the marker genes GNLY and NKG7. However, the cluster color code representing the rows and columns of the heatmap are mismatching. Cluster 3 is summarized using violet on the cell level (color bar below the heatmap) and using green for grouping Cluster 3 associated markers GNLY and NKG7 (color bar on the right). I would expect that these color codes match. ### Minimal code sample. Below are a few lines to reproduce this behaviour:. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). sc.tl.leiden(pbmc, key_added='clusters', resolution=0.5). marker_genes_dict = {'NK': ['GNLY', 'NKG7'],. 'T-cell': ['CD3D'],. 'B-cell': ['CD79A', 'MS4A1'],. 'Monocytes': ['FCGR3A'],. 'Dendritic': ['FCER1A']}. sc.pl.heatmap(pbmc, marker_genes_dict, groupby='clusters', vmin=-2, vmax=2, cmap='RdBu_r', dendrogram=True, swap_axes=True). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479
https://github.com/scverse/scanpy/issues/1479:1042,availability,cluster,clusters,1042,"Mismatching cluster color codes in sc.pl.heatmap; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Description. The issue is visible/reproducibe from the [plotting tutorial](https://scanpy-tutorials.readthedocs.io/en/latest/plotting/core.html#Heatmaps) in cell 23. Here, as an example, Cluster 3/NK cells are associated with the marker genes GNLY and NKG7. However, the cluster color code representing the rows and columns of the heatmap are mismatching. Cluster 3 is summarized using violet on the cell level (color bar below the heatmap) and using green for grouping Cluster 3 associated markers GNLY and NKG7 (color bar on the right). I would expect that these color codes match. ### Minimal code sample. Below are a few lines to reproduce this behaviour:. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). sc.tl.leiden(pbmc, key_added='clusters', resolution=0.5). marker_genes_dict = {'NK': ['GNLY', 'NKG7'],. 'T-cell': ['CD3D'],. 'B-cell': ['CD79A', 'MS4A1'],. 'Monocytes': ['FCGR3A'],. 'Dendritic': ['FCER1A']}. sc.pl.heatmap(pbmc, marker_genes_dict, groupby='clusters', vmin=-2, vmax=2, cmap='RdBu_r', dendrogram=True, swap_axes=True). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479
https://github.com/scverse/scanpy/issues/1479:1268,availability,cluster,clusters,1268,"Mismatching cluster color codes in sc.pl.heatmap; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Description. The issue is visible/reproducibe from the [plotting tutorial](https://scanpy-tutorials.readthedocs.io/en/latest/plotting/core.html#Heatmaps) in cell 23. Here, as an example, Cluster 3/NK cells are associated with the marker genes GNLY and NKG7. However, the cluster color code representing the rows and columns of the heatmap are mismatching. Cluster 3 is summarized using violet on the cell level (color bar below the heatmap) and using green for grouping Cluster 3 associated markers GNLY and NKG7 (color bar on the right). I would expect that these color codes match. ### Minimal code sample. Below are a few lines to reproduce this behaviour:. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). sc.tl.leiden(pbmc, key_added='clusters', resolution=0.5). marker_genes_dict = {'NK': ['GNLY', 'NKG7'],. 'T-cell': ['CD3D'],. 'B-cell': ['CD79A', 'MS4A1'],. 'Monocytes': ['FCGR3A'],. 'Dendritic': ['FCER1A']}. sc.pl.heatmap(pbmc, marker_genes_dict, groupby='clusters', vmin=-2, vmax=2, cmap='RdBu_r', dendrogram=True, swap_axes=True). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479
https://github.com/scverse/scanpy/issues/1479:12,deployability,cluster,cluster,12,"Mismatching cluster color codes in sc.pl.heatmap; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Description. The issue is visible/reproducibe from the [plotting tutorial](https://scanpy-tutorials.readthedocs.io/en/latest/plotting/core.html#Heatmaps) in cell 23. Here, as an example, Cluster 3/NK cells are associated with the marker genes GNLY and NKG7. However, the cluster color code representing the rows and columns of the heatmap are mismatching. Cluster 3 is summarized using violet on the cell level (color bar below the heatmap) and using green for grouping Cluster 3 associated markers GNLY and NKG7 (color bar on the right). I would expect that these color codes match. ### Minimal code sample. Below are a few lines to reproduce this behaviour:. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). sc.tl.leiden(pbmc, key_added='clusters', resolution=0.5). marker_genes_dict = {'NK': ['GNLY', 'NKG7'],. 'T-cell': ['CD3D'],. 'B-cell': ['CD79A', 'MS4A1'],. 'Monocytes': ['FCGR3A'],. 'Dendritic': ['FCER1A']}. sc.pl.heatmap(pbmc, marker_genes_dict, groupby='clusters', vmin=-2, vmax=2, cmap='RdBu_r', dendrogram=True, swap_axes=True). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479
https://github.com/scverse/scanpy/issues/1479:171,deployability,version,version,171,"Mismatching cluster color codes in sc.pl.heatmap; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Description. The issue is visible/reproducibe from the [plotting tutorial](https://scanpy-tutorials.readthedocs.io/en/latest/plotting/core.html#Heatmaps) in cell 23. Here, as an example, Cluster 3/NK cells are associated with the marker genes GNLY and NKG7. However, the cluster color code representing the rows and columns of the heatmap are mismatching. Cluster 3 is summarized using violet on the cell level (color bar below the heatmap) and using green for grouping Cluster 3 associated markers GNLY and NKG7 (color bar on the right). I would expect that these color codes match. ### Minimal code sample. Below are a few lines to reproduce this behaviour:. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). sc.tl.leiden(pbmc, key_added='clusters', resolution=0.5). marker_genes_dict = {'NK': ['GNLY', 'NKG7'],. 'T-cell': ['CD3D'],. 'B-cell': ['CD79A', 'MS4A1'],. 'Monocytes': ['FCGR3A'],. 'Dendritic': ['FCER1A']}. sc.pl.heatmap(pbmc, marker_genes_dict, groupby='clusters', vmin=-2, vmax=2, cmap='RdBu_r', dendrogram=True, swap_axes=True). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479
https://github.com/scverse/scanpy/issues/1479:468,deployability,Cluster,Cluster,468,"Mismatching cluster color codes in sc.pl.heatmap; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Description. The issue is visible/reproducibe from the [plotting tutorial](https://scanpy-tutorials.readthedocs.io/en/latest/plotting/core.html#Heatmaps) in cell 23. Here, as an example, Cluster 3/NK cells are associated with the marker genes GNLY and NKG7. However, the cluster color code representing the rows and columns of the heatmap are mismatching. Cluster 3 is summarized using violet on the cell level (color bar below the heatmap) and using green for grouping Cluster 3 associated markers GNLY and NKG7 (color bar on the right). I would expect that these color codes match. ### Minimal code sample. Below are a few lines to reproduce this behaviour:. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). sc.tl.leiden(pbmc, key_added='clusters', resolution=0.5). marker_genes_dict = {'NK': ['GNLY', 'NKG7'],. 'T-cell': ['CD3D'],. 'B-cell': ['CD79A', 'MS4A1'],. 'Monocytes': ['FCGR3A'],. 'Dendritic': ['FCER1A']}. sc.pl.heatmap(pbmc, marker_genes_dict, groupby='clusters', vmin=-2, vmax=2, cmap='RdBu_r', dendrogram=True, swap_axes=True). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479
https://github.com/scverse/scanpy/issues/1479:552,deployability,cluster,cluster,552,"Mismatching cluster color codes in sc.pl.heatmap; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Description. The issue is visible/reproducibe from the [plotting tutorial](https://scanpy-tutorials.readthedocs.io/en/latest/plotting/core.html#Heatmaps) in cell 23. Here, as an example, Cluster 3/NK cells are associated with the marker genes GNLY and NKG7. However, the cluster color code representing the rows and columns of the heatmap are mismatching. Cluster 3 is summarized using violet on the cell level (color bar below the heatmap) and using green for grouping Cluster 3 associated markers GNLY and NKG7 (color bar on the right). I would expect that these color codes match. ### Minimal code sample. Below are a few lines to reproduce this behaviour:. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). sc.tl.leiden(pbmc, key_added='clusters', resolution=0.5). marker_genes_dict = {'NK': ['GNLY', 'NKG7'],. 'T-cell': ['CD3D'],. 'B-cell': ['CD79A', 'MS4A1'],. 'Monocytes': ['FCGR3A'],. 'Dendritic': ['FCER1A']}. sc.pl.heatmap(pbmc, marker_genes_dict, groupby='clusters', vmin=-2, vmax=2, cmap='RdBu_r', dendrogram=True, swap_axes=True). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479
https://github.com/scverse/scanpy/issues/1479:637,deployability,Cluster,Cluster,637,"Mismatching cluster color codes in sc.pl.heatmap; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Description. The issue is visible/reproducibe from the [plotting tutorial](https://scanpy-tutorials.readthedocs.io/en/latest/plotting/core.html#Heatmaps) in cell 23. Here, as an example, Cluster 3/NK cells are associated with the marker genes GNLY and NKG7. However, the cluster color code representing the rows and columns of the heatmap are mismatching. Cluster 3 is summarized using violet on the cell level (color bar below the heatmap) and using green for grouping Cluster 3 associated markers GNLY and NKG7 (color bar on the right). I would expect that these color codes match. ### Minimal code sample. Below are a few lines to reproduce this behaviour:. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). sc.tl.leiden(pbmc, key_added='clusters', resolution=0.5). marker_genes_dict = {'NK': ['GNLY', 'NKG7'],. 'T-cell': ['CD3D'],. 'B-cell': ['CD79A', 'MS4A1'],. 'Monocytes': ['FCGR3A'],. 'Dendritic': ['FCER1A']}. sc.pl.heatmap(pbmc, marker_genes_dict, groupby='clusters', vmin=-2, vmax=2, cmap='RdBu_r', dendrogram=True, swap_axes=True). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479
https://github.com/scverse/scanpy/issues/1479:751,deployability,Cluster,Cluster,751,"Mismatching cluster color codes in sc.pl.heatmap; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Description. The issue is visible/reproducibe from the [plotting tutorial](https://scanpy-tutorials.readthedocs.io/en/latest/plotting/core.html#Heatmaps) in cell 23. Here, as an example, Cluster 3/NK cells are associated with the marker genes GNLY and NKG7. However, the cluster color code representing the rows and columns of the heatmap are mismatching. Cluster 3 is summarized using violet on the cell level (color bar below the heatmap) and using green for grouping Cluster 3 associated markers GNLY and NKG7 (color bar on the right). I would expect that these color codes match. ### Minimal code sample. Below are a few lines to reproduce this behaviour:. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). sc.tl.leiden(pbmc, key_added='clusters', resolution=0.5). marker_genes_dict = {'NK': ['GNLY', 'NKG7'],. 'T-cell': ['CD3D'],. 'B-cell': ['CD79A', 'MS4A1'],. 'Monocytes': ['FCGR3A'],. 'Dendritic': ['FCER1A']}. sc.pl.heatmap(pbmc, marker_genes_dict, groupby='clusters', vmin=-2, vmax=2, cmap='RdBu_r', dendrogram=True, swap_axes=True). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479
https://github.com/scverse/scanpy/issues/1479:1042,deployability,cluster,clusters,1042,"Mismatching cluster color codes in sc.pl.heatmap; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Description. The issue is visible/reproducibe from the [plotting tutorial](https://scanpy-tutorials.readthedocs.io/en/latest/plotting/core.html#Heatmaps) in cell 23. Here, as an example, Cluster 3/NK cells are associated with the marker genes GNLY and NKG7. However, the cluster color code representing the rows and columns of the heatmap are mismatching. Cluster 3 is summarized using violet on the cell level (color bar below the heatmap) and using green for grouping Cluster 3 associated markers GNLY and NKG7 (color bar on the right). I would expect that these color codes match. ### Minimal code sample. Below are a few lines to reproduce this behaviour:. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). sc.tl.leiden(pbmc, key_added='clusters', resolution=0.5). marker_genes_dict = {'NK': ['GNLY', 'NKG7'],. 'T-cell': ['CD3D'],. 'B-cell': ['CD79A', 'MS4A1'],. 'Monocytes': ['FCGR3A'],. 'Dendritic': ['FCER1A']}. sc.pl.heatmap(pbmc, marker_genes_dict, groupby='clusters', vmin=-2, vmax=2, cmap='RdBu_r', dendrogram=True, swap_axes=True). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479
https://github.com/scverse/scanpy/issues/1479:1268,deployability,cluster,clusters,1268,"Mismatching cluster color codes in sc.pl.heatmap; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Description. The issue is visible/reproducibe from the [plotting tutorial](https://scanpy-tutorials.readthedocs.io/en/latest/plotting/core.html#Heatmaps) in cell 23. Here, as an example, Cluster 3/NK cells are associated with the marker genes GNLY and NKG7. However, the cluster color code representing the rows and columns of the heatmap are mismatching. Cluster 3 is summarized using violet on the cell level (color bar below the heatmap) and using green for grouping Cluster 3 associated markers GNLY and NKG7 (color bar on the right). I would expect that these color codes match. ### Minimal code sample. Below are a few lines to reproduce this behaviour:. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). sc.tl.leiden(pbmc, key_added='clusters', resolution=0.5). marker_genes_dict = {'NK': ['GNLY', 'NKG7'],. 'T-cell': ['CD3D'],. 'B-cell': ['CD79A', 'MS4A1'],. 'Monocytes': ['FCGR3A'],. 'Dendritic': ['FCER1A']}. sc.pl.heatmap(pbmc, marker_genes_dict, groupby='clusters', vmin=-2, vmax=2, cmap='RdBu_r', dendrogram=True, swap_axes=True). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479
https://github.com/scverse/scanpy/issues/1479:41,energy efficiency,heat,heatmap,41,"Mismatching cluster color codes in sc.pl.heatmap; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Description. The issue is visible/reproducibe from the [plotting tutorial](https://scanpy-tutorials.readthedocs.io/en/latest/plotting/core.html#Heatmaps) in cell 23. Here, as an example, Cluster 3/NK cells are associated with the marker genes GNLY and NKG7. However, the cluster color code representing the rows and columns of the heatmap are mismatching. Cluster 3 is summarized using violet on the cell level (color bar below the heatmap) and using green for grouping Cluster 3 associated markers GNLY and NKG7 (color bar on the right). I would expect that these color codes match. ### Minimal code sample. Below are a few lines to reproduce this behaviour:. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). sc.tl.leiden(pbmc, key_added='clusters', resolution=0.5). marker_genes_dict = {'NK': ['GNLY', 'NKG7'],. 'T-cell': ['CD3D'],. 'B-cell': ['CD79A', 'MS4A1'],. 'Monocytes': ['FCGR3A'],. 'Dendritic': ['FCER1A']}. sc.pl.heatmap(pbmc, marker_genes_dict, groupby='clusters', vmin=-2, vmax=2, cmap='RdBu_r', dendrogram=True, swap_axes=True). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479
https://github.com/scverse/scanpy/issues/1479:415,energy efficiency,core,core,415,"Mismatching cluster color codes in sc.pl.heatmap; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Description. The issue is visible/reproducibe from the [plotting tutorial](https://scanpy-tutorials.readthedocs.io/en/latest/plotting/core.html#Heatmaps) in cell 23. Here, as an example, Cluster 3/NK cells are associated with the marker genes GNLY and NKG7. However, the cluster color code representing the rows and columns of the heatmap are mismatching. Cluster 3 is summarized using violet on the cell level (color bar below the heatmap) and using green for grouping Cluster 3 associated markers GNLY and NKG7 (color bar on the right). I would expect that these color codes match. ### Minimal code sample. Below are a few lines to reproduce this behaviour:. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). sc.tl.leiden(pbmc, key_added='clusters', resolution=0.5). marker_genes_dict = {'NK': ['GNLY', 'NKG7'],. 'T-cell': ['CD3D'],. 'B-cell': ['CD79A', 'MS4A1'],. 'Monocytes': ['FCGR3A'],. 'Dendritic': ['FCER1A']}. sc.pl.heatmap(pbmc, marker_genes_dict, groupby='clusters', vmin=-2, vmax=2, cmap='RdBu_r', dendrogram=True, swap_axes=True). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479
https://github.com/scverse/scanpy/issues/1479:425,energy efficiency,Heat,Heatmaps,425,"Mismatching cluster color codes in sc.pl.heatmap; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Description. The issue is visible/reproducibe from the [plotting tutorial](https://scanpy-tutorials.readthedocs.io/en/latest/plotting/core.html#Heatmaps) in cell 23. Here, as an example, Cluster 3/NK cells are associated with the marker genes GNLY and NKG7. However, the cluster color code representing the rows and columns of the heatmap are mismatching. Cluster 3 is summarized using violet on the cell level (color bar below the heatmap) and using green for grouping Cluster 3 associated markers GNLY and NKG7 (color bar on the right). I would expect that these color codes match. ### Minimal code sample. Below are a few lines to reproduce this behaviour:. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). sc.tl.leiden(pbmc, key_added='clusters', resolution=0.5). marker_genes_dict = {'NK': ['GNLY', 'NKG7'],. 'T-cell': ['CD3D'],. 'B-cell': ['CD79A', 'MS4A1'],. 'Monocytes': ['FCGR3A'],. 'Dendritic': ['FCER1A']}. sc.pl.heatmap(pbmc, marker_genes_dict, groupby='clusters', vmin=-2, vmax=2, cmap='RdBu_r', dendrogram=True, swap_axes=True). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479
https://github.com/scverse/scanpy/issues/1479:612,energy efficiency,heat,heatmap,612,"Mismatching cluster color codes in sc.pl.heatmap; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Description. The issue is visible/reproducibe from the [plotting tutorial](https://scanpy-tutorials.readthedocs.io/en/latest/plotting/core.html#Heatmaps) in cell 23. Here, as an example, Cluster 3/NK cells are associated with the marker genes GNLY and NKG7. However, the cluster color code representing the rows and columns of the heatmap are mismatching. Cluster 3 is summarized using violet on the cell level (color bar below the heatmap) and using green for grouping Cluster 3 associated markers GNLY and NKG7 (color bar on the right). I would expect that these color codes match. ### Minimal code sample. Below are a few lines to reproduce this behaviour:. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). sc.tl.leiden(pbmc, key_added='clusters', resolution=0.5). marker_genes_dict = {'NK': ['GNLY', 'NKG7'],. 'T-cell': ['CD3D'],. 'B-cell': ['CD79A', 'MS4A1'],. 'Monocytes': ['FCGR3A'],. 'Dendritic': ['FCER1A']}. sc.pl.heatmap(pbmc, marker_genes_dict, groupby='clusters', vmin=-2, vmax=2, cmap='RdBu_r', dendrogram=True, swap_axes=True). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479
https://github.com/scverse/scanpy/issues/1479:713,energy efficiency,heat,heatmap,713,"Mismatching cluster color codes in sc.pl.heatmap; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Description. The issue is visible/reproducibe from the [plotting tutorial](https://scanpy-tutorials.readthedocs.io/en/latest/plotting/core.html#Heatmaps) in cell 23. Here, as an example, Cluster 3/NK cells are associated with the marker genes GNLY and NKG7. However, the cluster color code representing the rows and columns of the heatmap are mismatching. Cluster 3 is summarized using violet on the cell level (color bar below the heatmap) and using green for grouping Cluster 3 associated markers GNLY and NKG7 (color bar on the right). I would expect that these color codes match. ### Minimal code sample. Below are a few lines to reproduce this behaviour:. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). sc.tl.leiden(pbmc, key_added='clusters', resolution=0.5). marker_genes_dict = {'NK': ['GNLY', 'NKG7'],. 'T-cell': ['CD3D'],. 'B-cell': ['CD79A', 'MS4A1'],. 'Monocytes': ['FCGR3A'],. 'Dendritic': ['FCER1A']}. sc.pl.heatmap(pbmc, marker_genes_dict, groupby='clusters', vmin=-2, vmax=2, cmap='RdBu_r', dendrogram=True, swap_axes=True). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479
https://github.com/scverse/scanpy/issues/1479:732,energy efficiency,green,green,732,"Mismatching cluster color codes in sc.pl.heatmap; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Description. The issue is visible/reproducibe from the [plotting tutorial](https://scanpy-tutorials.readthedocs.io/en/latest/plotting/core.html#Heatmaps) in cell 23. Here, as an example, Cluster 3/NK cells are associated with the marker genes GNLY and NKG7. However, the cluster color code representing the rows and columns of the heatmap are mismatching. Cluster 3 is summarized using violet on the cell level (color bar below the heatmap) and using green for grouping Cluster 3 associated markers GNLY and NKG7 (color bar on the right). I would expect that these color codes match. ### Minimal code sample. Below are a few lines to reproduce this behaviour:. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). sc.tl.leiden(pbmc, key_added='clusters', resolution=0.5). marker_genes_dict = {'NK': ['GNLY', 'NKG7'],. 'T-cell': ['CD3D'],. 'B-cell': ['CD79A', 'MS4A1'],. 'Monocytes': ['FCGR3A'],. 'Dendritic': ['FCER1A']}. sc.pl.heatmap(pbmc, marker_genes_dict, groupby='clusters', vmin=-2, vmax=2, cmap='RdBu_r', dendrogram=True, swap_axes=True). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479
https://github.com/scverse/scanpy/issues/1479:1226,energy efficiency,heat,heatmap,1226,"Mismatching cluster color codes in sc.pl.heatmap; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Description. The issue is visible/reproducibe from the [plotting tutorial](https://scanpy-tutorials.readthedocs.io/en/latest/plotting/core.html#Heatmaps) in cell 23. Here, as an example, Cluster 3/NK cells are associated with the marker genes GNLY and NKG7. However, the cluster color code representing the rows and columns of the heatmap are mismatching. Cluster 3 is summarized using violet on the cell level (color bar below the heatmap) and using green for grouping Cluster 3 associated markers GNLY and NKG7 (color bar on the right). I would expect that these color codes match. ### Minimal code sample. Below are a few lines to reproduce this behaviour:. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). sc.tl.leiden(pbmc, key_added='clusters', resolution=0.5). marker_genes_dict = {'NK': ['GNLY', 'NKG7'],. 'T-cell': ['CD3D'],. 'B-cell': ['CD79A', 'MS4A1'],. 'Monocytes': ['FCGR3A'],. 'Dendritic': ['FCER1A']}. sc.pl.heatmap(pbmc, marker_genes_dict, groupby='clusters', vmin=-2, vmax=2, cmap='RdBu_r', dendrogram=True, swap_axes=True). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479
https://github.com/scverse/scanpy/issues/1479:171,integrability,version,version,171,"Mismatching cluster color codes in sc.pl.heatmap; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Description. The issue is visible/reproducibe from the [plotting tutorial](https://scanpy-tutorials.readthedocs.io/en/latest/plotting/core.html#Heatmaps) in cell 23. Here, as an example, Cluster 3/NK cells are associated with the marker genes GNLY and NKG7. However, the cluster color code representing the rows and columns of the heatmap are mismatching. Cluster 3 is summarized using violet on the cell level (color bar below the heatmap) and using green for grouping Cluster 3 associated markers GNLY and NKG7 (color bar on the right). I would expect that these color codes match. ### Minimal code sample. Below are a few lines to reproduce this behaviour:. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). sc.tl.leiden(pbmc, key_added='clusters', resolution=0.5). marker_genes_dict = {'NK': ['GNLY', 'NKG7'],. 'T-cell': ['CD3D'],. 'B-cell': ['CD79A', 'MS4A1'],. 'Monocytes': ['FCGR3A'],. 'Dendritic': ['FCER1A']}. sc.pl.heatmap(pbmc, marker_genes_dict, groupby='clusters', vmin=-2, vmax=2, cmap='RdBu_r', dendrogram=True, swap_axes=True). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479
https://github.com/scverse/scanpy/issues/1479:0,interoperability,Mismatch,Mismatching,0,"Mismatching cluster color codes in sc.pl.heatmap; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Description. The issue is visible/reproducibe from the [plotting tutorial](https://scanpy-tutorials.readthedocs.io/en/latest/plotting/core.html#Heatmaps) in cell 23. Here, as an example, Cluster 3/NK cells are associated with the marker genes GNLY and NKG7. However, the cluster color code representing the rows and columns of the heatmap are mismatching. Cluster 3 is summarized using violet on the cell level (color bar below the heatmap) and using green for grouping Cluster 3 associated markers GNLY and NKG7 (color bar on the right). I would expect that these color codes match. ### Minimal code sample. Below are a few lines to reproduce this behaviour:. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). sc.tl.leiden(pbmc, key_added='clusters', resolution=0.5). marker_genes_dict = {'NK': ['GNLY', 'NKG7'],. 'T-cell': ['CD3D'],. 'B-cell': ['CD79A', 'MS4A1'],. 'Monocytes': ['FCGR3A'],. 'Dendritic': ['FCER1A']}. sc.pl.heatmap(pbmc, marker_genes_dict, groupby='clusters', vmin=-2, vmax=2, cmap='RdBu_r', dendrogram=True, swap_axes=True). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479
https://github.com/scverse/scanpy/issues/1479:624,interoperability,mismatch,mismatching,624,"Mismatching cluster color codes in sc.pl.heatmap; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Description. The issue is visible/reproducibe from the [plotting tutorial](https://scanpy-tutorials.readthedocs.io/en/latest/plotting/core.html#Heatmaps) in cell 23. Here, as an example, Cluster 3/NK cells are associated with the marker genes GNLY and NKG7. However, the cluster color code representing the rows and columns of the heatmap are mismatching. Cluster 3 is summarized using violet on the cell level (color bar below the heatmap) and using green for grouping Cluster 3 associated markers GNLY and NKG7 (color bar on the right). I would expect that these color codes match. ### Minimal code sample. Below are a few lines to reproduce this behaviour:. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). sc.tl.leiden(pbmc, key_added='clusters', resolution=0.5). marker_genes_dict = {'NK': ['GNLY', 'NKG7'],. 'T-cell': ['CD3D'],. 'B-cell': ['CD79A', 'MS4A1'],. 'Monocytes': ['FCGR3A'],. 'Dendritic': ['FCER1A']}. sc.pl.heatmap(pbmc, marker_genes_dict, groupby='clusters', vmin=-2, vmax=2, cmap='RdBu_r', dendrogram=True, swap_axes=True). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479
https://github.com/scverse/scanpy/issues/1479:171,modifiability,version,version,171,"Mismatching cluster color codes in sc.pl.heatmap; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Description. The issue is visible/reproducibe from the [plotting tutorial](https://scanpy-tutorials.readthedocs.io/en/latest/plotting/core.html#Heatmaps) in cell 23. Here, as an example, Cluster 3/NK cells are associated with the marker genes GNLY and NKG7. However, the cluster color code representing the rows and columns of the heatmap are mismatching. Cluster 3 is summarized using violet on the cell level (color bar below the heatmap) and using green for grouping Cluster 3 associated markers GNLY and NKG7 (color bar on the right). I would expect that these color codes match. ### Minimal code sample. Below are a few lines to reproduce this behaviour:. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). sc.tl.leiden(pbmc, key_added='clusters', resolution=0.5). marker_genes_dict = {'NK': ['GNLY', 'NKG7'],. 'T-cell': ['CD3D'],. 'B-cell': ['CD79A', 'MS4A1'],. 'Monocytes': ['FCGR3A'],. 'Dendritic': ['FCER1A']}. sc.pl.heatmap(pbmc, marker_genes_dict, groupby='clusters', vmin=-2, vmax=2, cmap='RdBu_r', dendrogram=True, swap_axes=True). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479
https://github.com/scverse/scanpy/issues/1479:131,usability,confirm,confirmed,131,"Mismatching cluster color codes in sc.pl.heatmap; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Description. The issue is visible/reproducibe from the [plotting tutorial](https://scanpy-tutorials.readthedocs.io/en/latest/plotting/core.html#Heatmaps) in cell 23. Here, as an example, Cluster 3/NK cells are associated with the marker genes GNLY and NKG7. However, the cluster color code representing the rows and columns of the heatmap are mismatching. Cluster 3 is summarized using violet on the cell level (color bar below the heatmap) and using green for grouping Cluster 3 associated markers GNLY and NKG7 (color bar on the right). I would expect that these color codes match. ### Minimal code sample. Below are a few lines to reproduce this behaviour:. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). sc.tl.leiden(pbmc, key_added='clusters', resolution=0.5). marker_genes_dict = {'NK': ['GNLY', 'NKG7'],. 'T-cell': ['CD3D'],. 'B-cell': ['CD79A', 'MS4A1'],. 'Monocytes': ['FCGR3A'],. 'Dendritic': ['FCER1A']}. sc.pl.heatmap(pbmc, marker_genes_dict, groupby='clusters', vmin=-2, vmax=2, cmap='RdBu_r', dendrogram=True, swap_axes=True). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479
https://github.com/scverse/scanpy/issues/1479:214,usability,confirm,confirmed,214,"Mismatching cluster color codes in sc.pl.heatmap; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Description. The issue is visible/reproducibe from the [plotting tutorial](https://scanpy-tutorials.readthedocs.io/en/latest/plotting/core.html#Heatmaps) in cell 23. Here, as an example, Cluster 3/NK cells are associated with the marker genes GNLY and NKG7. However, the cluster color code representing the rows and columns of the heatmap are mismatching. Cluster 3 is summarized using violet on the cell level (color bar below the heatmap) and using green for grouping Cluster 3 associated markers GNLY and NKG7 (color bar on the right). I would expect that these color codes match. ### Minimal code sample. Below are a few lines to reproduce this behaviour:. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). sc.tl.leiden(pbmc, key_added='clusters', resolution=0.5). marker_genes_dict = {'NK': ['GNLY', 'NKG7'],. 'T-cell': ['CD3D'],. 'B-cell': ['CD79A', 'MS4A1'],. 'Monocytes': ['FCGR3A'],. 'Dendritic': ['FCER1A']}. sc.pl.heatmap(pbmc, marker_genes_dict, groupby='clusters', vmin=-2, vmax=2, cmap='RdBu_r', dendrogram=True, swap_axes=True). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479
https://github.com/scverse/scanpy/issues/1479:869,usability,Minim,Minimal,869,"Mismatching cluster color codes in sc.pl.heatmap; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Description. The issue is visible/reproducibe from the [plotting tutorial](https://scanpy-tutorials.readthedocs.io/en/latest/plotting/core.html#Heatmaps) in cell 23. Here, as an example, Cluster 3/NK cells are associated with the marker genes GNLY and NKG7. However, the cluster color code representing the rows and columns of the heatmap are mismatching. Cluster 3 is summarized using violet on the cell level (color bar below the heatmap) and using green for grouping Cluster 3 associated markers GNLY and NKG7 (color bar on the right). I would expect that these color codes match. ### Minimal code sample. Below are a few lines to reproduce this behaviour:. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). sc.tl.leiden(pbmc, key_added='clusters', resolution=0.5). marker_genes_dict = {'NK': ['GNLY', 'NKG7'],. 'T-cell': ['CD3D'],. 'B-cell': ['CD79A', 'MS4A1'],. 'Monocytes': ['FCGR3A'],. 'Dendritic': ['FCER1A']}. sc.pl.heatmap(pbmc, marker_genes_dict, groupby='clusters', vmin=-2, vmax=2, cmap='RdBu_r', dendrogram=True, swap_axes=True). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479
https://github.com/scverse/scanpy/issues/1479:930,usability,behavi,behaviour,930,"Mismatching cluster color codes in sc.pl.heatmap; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Description. The issue is visible/reproducibe from the [plotting tutorial](https://scanpy-tutorials.readthedocs.io/en/latest/plotting/core.html#Heatmaps) in cell 23. Here, as an example, Cluster 3/NK cells are associated with the marker genes GNLY and NKG7. However, the cluster color code representing the rows and columns of the heatmap are mismatching. Cluster 3 is summarized using violet on the cell level (color bar below the heatmap) and using green for grouping Cluster 3 associated markers GNLY and NKG7 (color bar on the right). I would expect that these color codes match. ### Minimal code sample. Below are a few lines to reproduce this behaviour:. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). sc.tl.leiden(pbmc, key_added='clusters', resolution=0.5). marker_genes_dict = {'NK': ['GNLY', 'NKG7'],. 'T-cell': ['CD3D'],. 'B-cell': ['CD79A', 'MS4A1'],. 'Monocytes': ['FCGR3A'],. 'Dendritic': ['FCER1A']}. sc.pl.heatmap(pbmc, marker_genes_dict, groupby='clusters', vmin=-2, vmax=2, cmap='RdBu_r', dendrogram=True, swap_axes=True). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1479
https://github.com/scverse/scanpy/issues/1480:142,deployability,version,version,142,"Issue with new h5py; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # update to h5py e.g. as: pip install h5py==3.0.0. import scanpy as sc. adata = sc.datasets.blobs(). sc.read(""foo.h5ad"").obs_names # names are bytes, not str. # Index([ b'0', b'1', b'2', b'3', b'4', b'5', b'6', b'7', b'8', ..., dtype='object', length=640). ```. When using `h5py==2.10.0`, it works as expected (i.e. the index type is str). The same happens for `.var_names` (I haven't check further). I'd recommend updating the requirements.txt oto `h5py<=2.10.0` for now. Related h5py issue: https://github.com/h5py/h5py/issues/1732. Also, I've encoutered this bug when coming up with example (seems unrelated):. ```python. import scanpy as sc. adata = sc.datasets.paul15(). sc.read('data/paul15/paul15.h5'). ```. The last line raises:. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-24-3d2f3a02bf09> in <module>. ----> 1 sc.read('data/paul15/paul15.h5'). ~/.miniconda3/envs/cellrank2/lib/python3.8/site-packages/scanpy/readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compression, **kwargs). 110 filename = Path(filename) # allow passing strings. 111 if is_valid_filename(filename):. --> 112 return _read(. 113 filename,. 114 backed=backed,. ~/.miniconda3/envs/cellrank2/lib/python3.8/site-packages/scanpy/readwrite.py in _read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compressi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1480
https://github.com/scverse/scanpy/issues/1480:520,deployability,updat,update,520,"Issue with new h5py; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # update to h5py e.g. as: pip install h5py==3.0.0. import scanpy as sc. adata = sc.datasets.blobs(). sc.read(""foo.h5ad"").obs_names # names are bytes, not str. # Index([ b'0', b'1', b'2', b'3', b'4', b'5', b'6', b'7', b'8', ..., dtype='object', length=640). ```. When using `h5py==2.10.0`, it works as expected (i.e. the index type is str). The same happens for `.var_names` (I haven't check further). I'd recommend updating the requirements.txt oto `h5py<=2.10.0` for now. Related h5py issue: https://github.com/h5py/h5py/issues/1732. Also, I've encoutered this bug when coming up with example (seems unrelated):. ```python. import scanpy as sc. adata = sc.datasets.paul15(). sc.read('data/paul15/paul15.h5'). ```. The last line raises:. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-24-3d2f3a02bf09> in <module>. ----> 1 sc.read('data/paul15/paul15.h5'). ~/.miniconda3/envs/cellrank2/lib/python3.8/site-packages/scanpy/readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compression, **kwargs). 110 filename = Path(filename) # allow passing strings. 111 if is_valid_filename(filename):. --> 112 return _read(. 113 filename,. 114 backed=backed,. ~/.miniconda3/envs/cellrank2/lib/python3.8/site-packages/scanpy/readwrite.py in _read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compressi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1480
https://github.com/scverse/scanpy/issues/1480:548,deployability,instal,install,548,"Issue with new h5py; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # update to h5py e.g. as: pip install h5py==3.0.0. import scanpy as sc. adata = sc.datasets.blobs(). sc.read(""foo.h5ad"").obs_names # names are bytes, not str. # Index([ b'0', b'1', b'2', b'3', b'4', b'5', b'6', b'7', b'8', ..., dtype='object', length=640). ```. When using `h5py==2.10.0`, it works as expected (i.e. the index type is str). The same happens for `.var_names` (I haven't check further). I'd recommend updating the requirements.txt oto `h5py<=2.10.0` for now. Related h5py issue: https://github.com/h5py/h5py/issues/1732. Also, I've encoutered this bug when coming up with example (seems unrelated):. ```python. import scanpy as sc. adata = sc.datasets.paul15(). sc.read('data/paul15/paul15.h5'). ```. The last line raises:. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-24-3d2f3a02bf09> in <module>. ----> 1 sc.read('data/paul15/paul15.h5'). ~/.miniconda3/envs/cellrank2/lib/python3.8/site-packages/scanpy/readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compression, **kwargs). 110 filename = Path(filename) # allow passing strings. 111 if is_valid_filename(filename):. --> 112 return _read(. 113 filename,. 114 backed=backed,. ~/.miniconda3/envs/cellrank2/lib/python3.8/site-packages/scanpy/readwrite.py in _read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compressi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1480
https://github.com/scverse/scanpy/issues/1480:933,deployability,updat,updating,933,"Issue with new h5py; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # update to h5py e.g. as: pip install h5py==3.0.0. import scanpy as sc. adata = sc.datasets.blobs(). sc.read(""foo.h5ad"").obs_names # names are bytes, not str. # Index([ b'0', b'1', b'2', b'3', b'4', b'5', b'6', b'7', b'8', ..., dtype='object', length=640). ```. When using `h5py==2.10.0`, it works as expected (i.e. the index type is str). The same happens for `.var_names` (I haven't check further). I'd recommend updating the requirements.txt oto `h5py<=2.10.0` for now. Related h5py issue: https://github.com/h5py/h5py/issues/1732. Also, I've encoutered this bug when coming up with example (seems unrelated):. ```python. import scanpy as sc. adata = sc.datasets.paul15(). sc.read('data/paul15/paul15.h5'). ```. The last line raises:. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-24-3d2f3a02bf09> in <module>. ----> 1 sc.read('data/paul15/paul15.h5'). ~/.miniconda3/envs/cellrank2/lib/python3.8/site-packages/scanpy/readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compression, **kwargs). 110 filename = Path(filename) # allow passing strings. 111 if is_valid_filename(filename):. --> 112 return _read(. 113 filename,. 114 backed=backed,. ~/.miniconda3/envs/cellrank2/lib/python3.8/site-packages/scanpy/readwrite.py in _read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compressi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1480
https://github.com/scverse/scanpy/issues/1480:1423,deployability,modul,module,1423,"r bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # update to h5py e.g. as: pip install h5py==3.0.0. import scanpy as sc. adata = sc.datasets.blobs(). sc.read(""foo.h5ad"").obs_names # names are bytes, not str. # Index([ b'0', b'1', b'2', b'3', b'4', b'5', b'6', b'7', b'8', ..., dtype='object', length=640). ```. When using `h5py==2.10.0`, it works as expected (i.e. the index type is str). The same happens for `.var_names` (I haven't check further). I'd recommend updating the requirements.txt oto `h5py<=2.10.0` for now. Related h5py issue: https://github.com/h5py/h5py/issues/1732. Also, I've encoutered this bug when coming up with example (seems unrelated):. ```python. import scanpy as sc. adata = sc.datasets.paul15(). sc.read('data/paul15/paul15.h5'). ```. The last line raises:. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-24-3d2f3a02bf09> in <module>. ----> 1 sc.read('data/paul15/paul15.h5'). ~/.miniconda3/envs/cellrank2/lib/python3.8/site-packages/scanpy/readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compression, **kwargs). 110 filename = Path(filename) # allow passing strings. 111 if is_valid_filename(filename):. --> 112 return _read(. 113 filename,. 114 backed=backed,. ~/.miniconda3/envs/cellrank2/lib/python3.8/site-packages/scanpy/readwrite.py in _read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compression, suppress_cache_warning, **kwargs). 698 if ext in {'h5', 'h5ad'}:. 699 if sheet is None:. --> 700 return read_h5ad(filename, backed=backed). 701 else:. 702 logg.debug(f'reading sheet {sheet} from file {filename}'). ~/.miniconda3/envs/cellrank2/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 427 _clean_uns(d) # backwards compat. 428 . --> 429 return An",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1480
https://github.com/scverse/scanpy/issues/1480:2159,deployability,log,logg,2159,"c. adata = sc.datasets.paul15(). sc.read('data/paul15/paul15.h5'). ```. The last line raises:. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-24-3d2f3a02bf09> in <module>. ----> 1 sc.read('data/paul15/paul15.h5'). ~/.miniconda3/envs/cellrank2/lib/python3.8/site-packages/scanpy/readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compression, **kwargs). 110 filename = Path(filename) # allow passing strings. 111 if is_valid_filename(filename):. --> 112 return _read(. 113 filename,. 114 backed=backed,. ~/.miniconda3/envs/cellrank2/lib/python3.8/site-packages/scanpy/readwrite.py in _read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compression, suppress_cache_warning, **kwargs). 698 if ext in {'h5', 'h5ad'}:. 699 if sheet is None:. --> 700 return read_h5ad(filename, backed=backed). 701 else:. 702 logg.debug(f'reading sheet {sheet} from file {filename}'). ~/.miniconda3/envs/cellrank2/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 427 _clean_uns(d) # backwards compat. 428 . --> 429 return AnnData(**d). 430 . 431 . TypeError: __init__() got an unexpected keyword argument 'batch.names'. ```. #### Versions. <details>. -----. anndata 0.7.4. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. absl NA. anndata 0.7.4. autoreload NA. backcall 0.2.0. cellrank 1.0.0. cffi 1.14.3. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. docrep 0.3.1. future_fstrings NA. get_version 2.1. h5py 2.10.0. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. jax 0.2.5. jaxlib 0.1.56. jedi 0.17.2. joblib 0.17.0. kiwisolver 1.3.1. lapack NA. legacy_api_wrap 1.2. leidenalg 0.8.1. llvmlite 0.34.0. louvain 0.7.0. matplotlib 3.3.2. mpl_toolkits NA. natsort 7.0.1. numba 0.51.2. numexpr 2.7.1. numpy 1.19.4. opt_einsum v3.3.0. packag",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1480
https://github.com/scverse/scanpy/issues/1480:2532,deployability,Version,Versions,2532,"y/readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compression, **kwargs). 110 filename = Path(filename) # allow passing strings. 111 if is_valid_filename(filename):. --> 112 return _read(. 113 filename,. 114 backed=backed,. ~/.miniconda3/envs/cellrank2/lib/python3.8/site-packages/scanpy/readwrite.py in _read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compression, suppress_cache_warning, **kwargs). 698 if ext in {'h5', 'h5ad'}:. 699 if sheet is None:. --> 700 return read_h5ad(filename, backed=backed). 701 else:. 702 logg.debug(f'reading sheet {sheet} from file {filename}'). ~/.miniconda3/envs/cellrank2/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 427 _clean_uns(d) # backwards compat. 428 . --> 429 return AnnData(**d). 430 . 431 . TypeError: __init__() got an unexpected keyword argument 'batch.names'. ```. #### Versions. <details>. -----. anndata 0.7.4. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. absl NA. anndata 0.7.4. autoreload NA. backcall 0.2.0. cellrank 1.0.0. cffi 1.14.3. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. docrep 0.3.1. future_fstrings NA. get_version 2.1. h5py 2.10.0. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. jax 0.2.5. jaxlib 0.1.56. jedi 0.17.2. joblib 0.17.0. kiwisolver 1.3.1. lapack NA. legacy_api_wrap 1.2. leidenalg 0.8.1. llvmlite 0.34.0. louvain 0.7.0. matplotlib 3.3.2. mpl_toolkits NA. natsort 7.0.1. numba 0.51.2. numexpr 2.7.1. numpy 1.19.4. opt_einsum v3.3.0. packaging 20.4. pandas 1.1.4. parso 0.7.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. progressbar 3.53.1. prompt_toolkit 3.0.8. psutil 5.7.3. ptyprocess 0.6.0. pygam 0.8.0. pygments 2.7.2. pyparsing 2.4.7. python_utils NA. pytz 2020.4. scanpy 1.6.0. scipy 1.5.3. scvelo 0.2.2. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. sphinxcontrib NA. storemagic NA. ta",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1480
https://github.com/scverse/scanpy/issues/1480:3848,deployability,log,logical,3848," delimiter, first_column_names, backup_url, cache, cache_compression, suppress_cache_warning, **kwargs). 698 if ext in {'h5', 'h5ad'}:. 699 if sheet is None:. --> 700 return read_h5ad(filename, backed=backed). 701 else:. 702 logg.debug(f'reading sheet {sheet} from file {filename}'). ~/.miniconda3/envs/cellrank2/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 427 _clean_uns(d) # backwards compat. 428 . --> 429 return AnnData(**d). 430 . 431 . TypeError: __init__() got an unexpected keyword argument 'batch.names'. ```. #### Versions. <details>. -----. anndata 0.7.4. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. absl NA. anndata 0.7.4. autoreload NA. backcall 0.2.0. cellrank 1.0.0. cffi 1.14.3. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. docrep 0.3.1. future_fstrings NA. get_version 2.1. h5py 2.10.0. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. jax 0.2.5. jaxlib 0.1.56. jedi 0.17.2. joblib 0.17.0. kiwisolver 1.3.1. lapack NA. legacy_api_wrap 1.2. leidenalg 0.8.1. llvmlite 0.34.0. louvain 0.7.0. matplotlib 3.3.2. mpl_toolkits NA. natsort 7.0.1. numba 0.51.2. numexpr 2.7.1. numpy 1.19.4. opt_einsum v3.3.0. packaging 20.4. pandas 1.1.4. parso 0.7.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. progressbar 3.53.1. prompt_toolkit 3.0.8. psutil 5.7.3. ptyprocess 0.6.0. pygam 0.8.0. pygments 2.7.2. pyparsing 2.4.7. python_utils NA. pytz 2020.4. scanpy 1.6.0. scipy 1.5.3. scvelo 0.2.2. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. sphinxcontrib NA. storemagic NA. tables 3.6.1. texttable 1.6.3. threadpoolctl 2.1.0. tornado 6.1. traitlets 5.0.5. wcwidth 0.2.5. wrapt 1.12.1. zmq 19.0.2. -----. IPython 7.19.0. jupyter_client 6.1.7. jupyter_core 4.6.3. notebook 6.1.4. -----. Python 3.8.5 (default, Sep 4 2020, 07:30:14) [GCC 7.3.0]. Linux-5.8.0-3-amd64-x86_64-with-glibc2.10. 8 logical CPU cores. -----. Session information updated at 2020-11-03 13:36. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1480
https://github.com/scverse/scanpy/issues/1480:3894,deployability,updat,updated,3894," delimiter, first_column_names, backup_url, cache, cache_compression, suppress_cache_warning, **kwargs). 698 if ext in {'h5', 'h5ad'}:. 699 if sheet is None:. --> 700 return read_h5ad(filename, backed=backed). 701 else:. 702 logg.debug(f'reading sheet {sheet} from file {filename}'). ~/.miniconda3/envs/cellrank2/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 427 _clean_uns(d) # backwards compat. 428 . --> 429 return AnnData(**d). 430 . 431 . TypeError: __init__() got an unexpected keyword argument 'batch.names'. ```. #### Versions. <details>. -----. anndata 0.7.4. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. absl NA. anndata 0.7.4. autoreload NA. backcall 0.2.0. cellrank 1.0.0. cffi 1.14.3. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. docrep 0.3.1. future_fstrings NA. get_version 2.1. h5py 2.10.0. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. jax 0.2.5. jaxlib 0.1.56. jedi 0.17.2. joblib 0.17.0. kiwisolver 1.3.1. lapack NA. legacy_api_wrap 1.2. leidenalg 0.8.1. llvmlite 0.34.0. louvain 0.7.0. matplotlib 3.3.2. mpl_toolkits NA. natsort 7.0.1. numba 0.51.2. numexpr 2.7.1. numpy 1.19.4. opt_einsum v3.3.0. packaging 20.4. pandas 1.1.4. parso 0.7.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. progressbar 3.53.1. prompt_toolkit 3.0.8. psutil 5.7.3. ptyprocess 0.6.0. pygam 0.8.0. pygments 2.7.2. pyparsing 2.4.7. python_utils NA. pytz 2020.4. scanpy 1.6.0. scipy 1.5.3. scvelo 0.2.2. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. sphinxcontrib NA. storemagic NA. tables 3.6.1. texttable 1.6.3. threadpoolctl 2.1.0. tornado 6.1. traitlets 5.0.5. wcwidth 0.2.5. wrapt 1.12.1. zmq 19.0.2. -----. IPython 7.19.0. jupyter_client 6.1.7. jupyter_core 4.6.3. notebook 6.1.4. -----. Python 3.8.5 (default, Sep 4 2020, 07:30:14) [GCC 7.3.0]. Linux-5.8.0-3-amd64-x86_64-with-glibc2.10. 8 logical CPU cores. -----. Session information updated at 2020-11-03 13:36. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1480
https://github.com/scverse/scanpy/issues/1480:3856,energy efficiency,CPU,CPU,3856," delimiter, first_column_names, backup_url, cache, cache_compression, suppress_cache_warning, **kwargs). 698 if ext in {'h5', 'h5ad'}:. 699 if sheet is None:. --> 700 return read_h5ad(filename, backed=backed). 701 else:. 702 logg.debug(f'reading sheet {sheet} from file {filename}'). ~/.miniconda3/envs/cellrank2/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 427 _clean_uns(d) # backwards compat. 428 . --> 429 return AnnData(**d). 430 . 431 . TypeError: __init__() got an unexpected keyword argument 'batch.names'. ```. #### Versions. <details>. -----. anndata 0.7.4. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. absl NA. anndata 0.7.4. autoreload NA. backcall 0.2.0. cellrank 1.0.0. cffi 1.14.3. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. docrep 0.3.1. future_fstrings NA. get_version 2.1. h5py 2.10.0. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. jax 0.2.5. jaxlib 0.1.56. jedi 0.17.2. joblib 0.17.0. kiwisolver 1.3.1. lapack NA. legacy_api_wrap 1.2. leidenalg 0.8.1. llvmlite 0.34.0. louvain 0.7.0. matplotlib 3.3.2. mpl_toolkits NA. natsort 7.0.1. numba 0.51.2. numexpr 2.7.1. numpy 1.19.4. opt_einsum v3.3.0. packaging 20.4. pandas 1.1.4. parso 0.7.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. progressbar 3.53.1. prompt_toolkit 3.0.8. psutil 5.7.3. ptyprocess 0.6.0. pygam 0.8.0. pygments 2.7.2. pyparsing 2.4.7. python_utils NA. pytz 2020.4. scanpy 1.6.0. scipy 1.5.3. scvelo 0.2.2. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. sphinxcontrib NA. storemagic NA. tables 3.6.1. texttable 1.6.3. threadpoolctl 2.1.0. tornado 6.1. traitlets 5.0.5. wcwidth 0.2.5. wrapt 1.12.1. zmq 19.0.2. -----. IPython 7.19.0. jupyter_client 6.1.7. jupyter_core 4.6.3. notebook 6.1.4. -----. Python 3.8.5 (default, Sep 4 2020, 07:30:14) [GCC 7.3.0]. Linux-5.8.0-3-amd64-x86_64-with-glibc2.10. 8 logical CPU cores. -----. Session information updated at 2020-11-03 13:36. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1480
https://github.com/scverse/scanpy/issues/1480:3860,energy efficiency,core,cores,3860," delimiter, first_column_names, backup_url, cache, cache_compression, suppress_cache_warning, **kwargs). 698 if ext in {'h5', 'h5ad'}:. 699 if sheet is None:. --> 700 return read_h5ad(filename, backed=backed). 701 else:. 702 logg.debug(f'reading sheet {sheet} from file {filename}'). ~/.miniconda3/envs/cellrank2/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 427 _clean_uns(d) # backwards compat. 428 . --> 429 return AnnData(**d). 430 . 431 . TypeError: __init__() got an unexpected keyword argument 'batch.names'. ```. #### Versions. <details>. -----. anndata 0.7.4. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. absl NA. anndata 0.7.4. autoreload NA. backcall 0.2.0. cellrank 1.0.0. cffi 1.14.3. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. docrep 0.3.1. future_fstrings NA. get_version 2.1. h5py 2.10.0. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. jax 0.2.5. jaxlib 0.1.56. jedi 0.17.2. joblib 0.17.0. kiwisolver 1.3.1. lapack NA. legacy_api_wrap 1.2. leidenalg 0.8.1. llvmlite 0.34.0. louvain 0.7.0. matplotlib 3.3.2. mpl_toolkits NA. natsort 7.0.1. numba 0.51.2. numexpr 2.7.1. numpy 1.19.4. opt_einsum v3.3.0. packaging 20.4. pandas 1.1.4. parso 0.7.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. progressbar 3.53.1. prompt_toolkit 3.0.8. psutil 5.7.3. ptyprocess 0.6.0. pygam 0.8.0. pygments 2.7.2. pyparsing 2.4.7. python_utils NA. pytz 2020.4. scanpy 1.6.0. scipy 1.5.3. scvelo 0.2.2. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. sphinxcontrib NA. storemagic NA. tables 3.6.1. texttable 1.6.3. threadpoolctl 2.1.0. tornado 6.1. traitlets 5.0.5. wcwidth 0.2.5. wrapt 1.12.1. zmq 19.0.2. -----. IPython 7.19.0. jupyter_client 6.1.7. jupyter_core 4.6.3. notebook 6.1.4. -----. Python 3.8.5 (default, Sep 4 2020, 07:30:14) [GCC 7.3.0]. Linux-5.8.0-3-amd64-x86_64-with-glibc2.10. 8 logical CPU cores. -----. Session information updated at 2020-11-03 13:36. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1480
https://github.com/scverse/scanpy/issues/1480:142,integrability,version,version,142,"Issue with new h5py; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # update to h5py e.g. as: pip install h5py==3.0.0. import scanpy as sc. adata = sc.datasets.blobs(). sc.read(""foo.h5ad"").obs_names # names are bytes, not str. # Index([ b'0', b'1', b'2', b'3', b'4', b'5', b'6', b'7', b'8', ..., dtype='object', length=640). ```. When using `h5py==2.10.0`, it works as expected (i.e. the index type is str). The same happens for `.var_names` (I haven't check further). I'd recommend updating the requirements.txt oto `h5py<=2.10.0` for now. Related h5py issue: https://github.com/h5py/h5py/issues/1732. Also, I've encoutered this bug when coming up with example (seems unrelated):. ```python. import scanpy as sc. adata = sc.datasets.paul15(). sc.read('data/paul15/paul15.h5'). ```. The last line raises:. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-24-3d2f3a02bf09> in <module>. ----> 1 sc.read('data/paul15/paul15.h5'). ~/.miniconda3/envs/cellrank2/lib/python3.8/site-packages/scanpy/readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compression, **kwargs). 110 filename = Path(filename) # allow passing strings. 111 if is_valid_filename(filename):. --> 112 return _read(. 113 filename,. 114 backed=backed,. ~/.miniconda3/envs/cellrank2/lib/python3.8/site-packages/scanpy/readwrite.py in _read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compressi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1480
https://github.com/scverse/scanpy/issues/1480:2508,integrability,batch,batch,2508,"on3.8/site-packages/scanpy/readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compression, **kwargs). 110 filename = Path(filename) # allow passing strings. 111 if is_valid_filename(filename):. --> 112 return _read(. 113 filename,. 114 backed=backed,. ~/.miniconda3/envs/cellrank2/lib/python3.8/site-packages/scanpy/readwrite.py in _read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compression, suppress_cache_warning, **kwargs). 698 if ext in {'h5', 'h5ad'}:. 699 if sheet is None:. --> 700 return read_h5ad(filename, backed=backed). 701 else:. 702 logg.debug(f'reading sheet {sheet} from file {filename}'). ~/.miniconda3/envs/cellrank2/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 427 _clean_uns(d) # backwards compat. 428 . --> 429 return AnnData(**d). 430 . 431 . TypeError: __init__() got an unexpected keyword argument 'batch.names'. ```. #### Versions. <details>. -----. anndata 0.7.4. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. absl NA. anndata 0.7.4. autoreload NA. backcall 0.2.0. cellrank 1.0.0. cffi 1.14.3. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. docrep 0.3.1. future_fstrings NA. get_version 2.1. h5py 2.10.0. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. jax 0.2.5. jaxlib 0.1.56. jedi 0.17.2. joblib 0.17.0. kiwisolver 1.3.1. lapack NA. legacy_api_wrap 1.2. leidenalg 0.8.1. llvmlite 0.34.0. louvain 0.7.0. matplotlib 3.3.2. mpl_toolkits NA. natsort 7.0.1. numba 0.51.2. numexpr 2.7.1. numpy 1.19.4. opt_einsum v3.3.0. packaging 20.4. pandas 1.1.4. parso 0.7.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. progressbar 3.53.1. prompt_toolkit 3.0.8. psutil 5.7.3. ptyprocess 0.6.0. pygam 0.8.0. pygments 2.7.2. pyparsing 2.4.7. python_utils NA. pytz 2020.4. scanpy 1.6.0. scipy 1.5.3. scvelo 0.2.2. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. sphinxcont",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1480
https://github.com/scverse/scanpy/issues/1480:2532,integrability,Version,Versions,2532,"y/readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compression, **kwargs). 110 filename = Path(filename) # allow passing strings. 111 if is_valid_filename(filename):. --> 112 return _read(. 113 filename,. 114 backed=backed,. ~/.miniconda3/envs/cellrank2/lib/python3.8/site-packages/scanpy/readwrite.py in _read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compression, suppress_cache_warning, **kwargs). 698 if ext in {'h5', 'h5ad'}:. 699 if sheet is None:. --> 700 return read_h5ad(filename, backed=backed). 701 else:. 702 logg.debug(f'reading sheet {sheet} from file {filename}'). ~/.miniconda3/envs/cellrank2/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 427 _clean_uns(d) # backwards compat. 428 . --> 429 return AnnData(**d). 430 . 431 . TypeError: __init__() got an unexpected keyword argument 'batch.names'. ```. #### Versions. <details>. -----. anndata 0.7.4. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. absl NA. anndata 0.7.4. autoreload NA. backcall 0.2.0. cellrank 1.0.0. cffi 1.14.3. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. docrep 0.3.1. future_fstrings NA. get_version 2.1. h5py 2.10.0. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. jax 0.2.5. jaxlib 0.1.56. jedi 0.17.2. joblib 0.17.0. kiwisolver 1.3.1. lapack NA. legacy_api_wrap 1.2. leidenalg 0.8.1. llvmlite 0.34.0. louvain 0.7.0. matplotlib 3.3.2. mpl_toolkits NA. natsort 7.0.1. numba 0.51.2. numexpr 2.7.1. numpy 1.19.4. opt_einsum v3.3.0. packaging 20.4. pandas 1.1.4. parso 0.7.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. progressbar 3.53.1. prompt_toolkit 3.0.8. psutil 5.7.3. ptyprocess 0.6.0. pygam 0.8.0. pygments 2.7.2. pyparsing 2.4.7. python_utils NA. pytz 2020.4. scanpy 1.6.0. scipy 1.5.3. scvelo 0.2.2. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. sphinxcontrib NA. storemagic NA. ta",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1480
https://github.com/scverse/scanpy/issues/1480:3631,integrability,wrap,wrapt,3631," delimiter, first_column_names, backup_url, cache, cache_compression, suppress_cache_warning, **kwargs). 698 if ext in {'h5', 'h5ad'}:. 699 if sheet is None:. --> 700 return read_h5ad(filename, backed=backed). 701 else:. 702 logg.debug(f'reading sheet {sheet} from file {filename}'). ~/.miniconda3/envs/cellrank2/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 427 _clean_uns(d) # backwards compat. 428 . --> 429 return AnnData(**d). 430 . 431 . TypeError: __init__() got an unexpected keyword argument 'batch.names'. ```. #### Versions. <details>. -----. anndata 0.7.4. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. absl NA. anndata 0.7.4. autoreload NA. backcall 0.2.0. cellrank 1.0.0. cffi 1.14.3. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. docrep 0.3.1. future_fstrings NA. get_version 2.1. h5py 2.10.0. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. jax 0.2.5. jaxlib 0.1.56. jedi 0.17.2. joblib 0.17.0. kiwisolver 1.3.1. lapack NA. legacy_api_wrap 1.2. leidenalg 0.8.1. llvmlite 0.34.0. louvain 0.7.0. matplotlib 3.3.2. mpl_toolkits NA. natsort 7.0.1. numba 0.51.2. numexpr 2.7.1. numpy 1.19.4. opt_einsum v3.3.0. packaging 20.4. pandas 1.1.4. parso 0.7.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. progressbar 3.53.1. prompt_toolkit 3.0.8. psutil 5.7.3. ptyprocess 0.6.0. pygam 0.8.0. pygments 2.7.2. pyparsing 2.4.7. python_utils NA. pytz 2020.4. scanpy 1.6.0. scipy 1.5.3. scvelo 0.2.2. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. sphinxcontrib NA. storemagic NA. tables 3.6.1. texttable 1.6.3. threadpoolctl 2.1.0. tornado 6.1. traitlets 5.0.5. wcwidth 0.2.5. wrapt 1.12.1. zmq 19.0.2. -----. IPython 7.19.0. jupyter_client 6.1.7. jupyter_core 4.6.3. notebook 6.1.4. -----. Python 3.8.5 (default, Sep 4 2020, 07:30:14) [GCC 7.3.0]. Linux-5.8.0-3-amd64-x86_64-with-glibc2.10. 8 logical CPU cores. -----. Session information updated at 2020-11-03 13:36. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1480
https://github.com/scverse/scanpy/issues/1480:142,modifiability,version,version,142,"Issue with new h5py; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # update to h5py e.g. as: pip install h5py==3.0.0. import scanpy as sc. adata = sc.datasets.blobs(). sc.read(""foo.h5ad"").obs_names # names are bytes, not str. # Index([ b'0', b'1', b'2', b'3', b'4', b'5', b'6', b'7', b'8', ..., dtype='object', length=640). ```. When using `h5py==2.10.0`, it works as expected (i.e. the index type is str). The same happens for `.var_names` (I haven't check further). I'd recommend updating the requirements.txt oto `h5py<=2.10.0` for now. Related h5py issue: https://github.com/h5py/h5py/issues/1732. Also, I've encoutered this bug when coming up with example (seems unrelated):. ```python. import scanpy as sc. adata = sc.datasets.paul15(). sc.read('data/paul15/paul15.h5'). ```. The last line raises:. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-24-3d2f3a02bf09> in <module>. ----> 1 sc.read('data/paul15/paul15.h5'). ~/.miniconda3/envs/cellrank2/lib/python3.8/site-packages/scanpy/readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compression, **kwargs). 110 filename = Path(filename) # allow passing strings. 111 if is_valid_filename(filename):. --> 112 return _read(. 113 filename,. 114 backed=backed,. ~/.miniconda3/envs/cellrank2/lib/python3.8/site-packages/scanpy/readwrite.py in _read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compressi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1480
https://github.com/scverse/scanpy/issues/1480:1423,modifiability,modul,module,1423,"r bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # update to h5py e.g. as: pip install h5py==3.0.0. import scanpy as sc. adata = sc.datasets.blobs(). sc.read(""foo.h5ad"").obs_names # names are bytes, not str. # Index([ b'0', b'1', b'2', b'3', b'4', b'5', b'6', b'7', b'8', ..., dtype='object', length=640). ```. When using `h5py==2.10.0`, it works as expected (i.e. the index type is str). The same happens for `.var_names` (I haven't check further). I'd recommend updating the requirements.txt oto `h5py<=2.10.0` for now. Related h5py issue: https://github.com/h5py/h5py/issues/1732. Also, I've encoutered this bug when coming up with example (seems unrelated):. ```python. import scanpy as sc. adata = sc.datasets.paul15(). sc.read('data/paul15/paul15.h5'). ```. The last line raises:. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-24-3d2f3a02bf09> in <module>. ----> 1 sc.read('data/paul15/paul15.h5'). ~/.miniconda3/envs/cellrank2/lib/python3.8/site-packages/scanpy/readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compression, **kwargs). 110 filename = Path(filename) # allow passing strings. 111 if is_valid_filename(filename):. --> 112 return _read(. 113 filename,. 114 backed=backed,. ~/.miniconda3/envs/cellrank2/lib/python3.8/site-packages/scanpy/readwrite.py in _read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compression, suppress_cache_warning, **kwargs). 698 if ext in {'h5', 'h5ad'}:. 699 if sheet is None:. --> 700 return read_h5ad(filename, backed=backed). 701 else:. 702 logg.debug(f'reading sheet {sheet} from file {filename}'). ~/.miniconda3/envs/cellrank2/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 427 _clean_uns(d) # backwards compat. 428 . --> 429 return An",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1480
https://github.com/scverse/scanpy/issues/1480:1522,modifiability,pac,packages,1522," to h5py e.g. as: pip install h5py==3.0.0. import scanpy as sc. adata = sc.datasets.blobs(). sc.read(""foo.h5ad"").obs_names # names are bytes, not str. # Index([ b'0', b'1', b'2', b'3', b'4', b'5', b'6', b'7', b'8', ..., dtype='object', length=640). ```. When using `h5py==2.10.0`, it works as expected (i.e. the index type is str). The same happens for `.var_names` (I haven't check further). I'd recommend updating the requirements.txt oto `h5py<=2.10.0` for now. Related h5py issue: https://github.com/h5py/h5py/issues/1732. Also, I've encoutered this bug when coming up with example (seems unrelated):. ```python. import scanpy as sc. adata = sc.datasets.paul15(). sc.read('data/paul15/paul15.h5'). ```. The last line raises:. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-24-3d2f3a02bf09> in <module>. ----> 1 sc.read('data/paul15/paul15.h5'). ~/.miniconda3/envs/cellrank2/lib/python3.8/site-packages/scanpy/readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compression, **kwargs). 110 filename = Path(filename) # allow passing strings. 111 if is_valid_filename(filename):. --> 112 return _read(. 113 filename,. 114 backed=backed,. ~/.miniconda3/envs/cellrank2/lib/python3.8/site-packages/scanpy/readwrite.py in _read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compression, suppress_cache_warning, **kwargs). 698 if ext in {'h5', 'h5ad'}:. 699 if sheet is None:. --> 700 return read_h5ad(filename, backed=backed). 701 else:. 702 logg.debug(f'reading sheet {sheet} from file {filename}'). ~/.miniconda3/envs/cellrank2/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 427 _clean_uns(d) # backwards compat. 428 . --> 429 return AnnData(**d). 430 . 431 . TypeError: __init__() got an unexpected keyword argument 'batch.names'. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1480
https://github.com/scverse/scanpy/issues/1480:1867,modifiability,pac,packages,1867,"ens for `.var_names` (I haven't check further). I'd recommend updating the requirements.txt oto `h5py<=2.10.0` for now. Related h5py issue: https://github.com/h5py/h5py/issues/1732. Also, I've encoutered this bug when coming up with example (seems unrelated):. ```python. import scanpy as sc. adata = sc.datasets.paul15(). sc.read('data/paul15/paul15.h5'). ```. The last line raises:. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-24-3d2f3a02bf09> in <module>. ----> 1 sc.read('data/paul15/paul15.h5'). ~/.miniconda3/envs/cellrank2/lib/python3.8/site-packages/scanpy/readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compression, **kwargs). 110 filename = Path(filename) # allow passing strings. 111 if is_valid_filename(filename):. --> 112 return _read(. 113 filename,. 114 backed=backed,. ~/.miniconda3/envs/cellrank2/lib/python3.8/site-packages/scanpy/readwrite.py in _read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compression, suppress_cache_warning, **kwargs). 698 if ext in {'h5', 'h5ad'}:. 699 if sheet is None:. --> 700 return read_h5ad(filename, backed=backed). 701 else:. 702 logg.debug(f'reading sheet {sheet} from file {filename}'). ~/.miniconda3/envs/cellrank2/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 427 _clean_uns(d) # backwards compat. 428 . --> 429 return AnnData(**d). 430 . 431 . TypeError: __init__() got an unexpected keyword argument 'batch.names'. ```. #### Versions. <details>. -----. anndata 0.7.4. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. absl NA. anndata 0.7.4. autoreload NA. backcall 0.2.0. cellrank 1.0.0. cffi 1.14.3. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. docrep 0.3.1. future_fstrings NA. get_version 2.1. h5py 2.10.0. igraph 0.8.3. ipykernel 5.3.4. ipyth",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1480
https://github.com/scverse/scanpy/issues/1480:2266,modifiability,pac,packages,2266,"----------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-24-3d2f3a02bf09> in <module>. ----> 1 sc.read('data/paul15/paul15.h5'). ~/.miniconda3/envs/cellrank2/lib/python3.8/site-packages/scanpy/readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compression, **kwargs). 110 filename = Path(filename) # allow passing strings. 111 if is_valid_filename(filename):. --> 112 return _read(. 113 filename,. 114 backed=backed,. ~/.miniconda3/envs/cellrank2/lib/python3.8/site-packages/scanpy/readwrite.py in _read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compression, suppress_cache_warning, **kwargs). 698 if ext in {'h5', 'h5ad'}:. 699 if sheet is None:. --> 700 return read_h5ad(filename, backed=backed). 701 else:. 702 logg.debug(f'reading sheet {sheet} from file {filename}'). ~/.miniconda3/envs/cellrank2/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 427 _clean_uns(d) # backwards compat. 428 . --> 429 return AnnData(**d). 430 . 431 . TypeError: __init__() got an unexpected keyword argument 'batch.names'. ```. #### Versions. <details>. -----. anndata 0.7.4. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. absl NA. anndata 0.7.4. autoreload NA. backcall 0.2.0. cellrank 1.0.0. cffi 1.14.3. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. docrep 0.3.1. future_fstrings NA. get_version 2.1. h5py 2.10.0. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. jax 0.2.5. jaxlib 0.1.56. jedi 0.17.2. joblib 0.17.0. kiwisolver 1.3.1. lapack NA. legacy_api_wrap 1.2. leidenalg 0.8.1. llvmlite 0.34.0. louvain 0.7.0. matplotlib 3.3.2. mpl_toolkits NA. natsort 7.0.1. numba 0.51.2. numexpr 2.7.1. numpy 1.19.4. opt_einsum v3.3.0. packaging 20.4. pandas 1.1.4. parso 0.7.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. progressbar 3.53.1. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1480
https://github.com/scverse/scanpy/issues/1480:2532,modifiability,Version,Versions,2532,"y/readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compression, **kwargs). 110 filename = Path(filename) # allow passing strings. 111 if is_valid_filename(filename):. --> 112 return _read(. 113 filename,. 114 backed=backed,. ~/.miniconda3/envs/cellrank2/lib/python3.8/site-packages/scanpy/readwrite.py in _read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compression, suppress_cache_warning, **kwargs). 698 if ext in {'h5', 'h5ad'}:. 699 if sheet is None:. --> 700 return read_h5ad(filename, backed=backed). 701 else:. 702 logg.debug(f'reading sheet {sheet} from file {filename}'). ~/.miniconda3/envs/cellrank2/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 427 _clean_uns(d) # backwards compat. 428 . --> 429 return AnnData(**d). 430 . 431 . TypeError: __init__() got an unexpected keyword argument 'batch.names'. ```. #### Versions. <details>. -----. anndata 0.7.4. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. absl NA. anndata 0.7.4. autoreload NA. backcall 0.2.0. cellrank 1.0.0. cffi 1.14.3. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. docrep 0.3.1. future_fstrings NA. get_version 2.1. h5py 2.10.0. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. jax 0.2.5. jaxlib 0.1.56. jedi 0.17.2. joblib 0.17.0. kiwisolver 1.3.1. lapack NA. legacy_api_wrap 1.2. leidenalg 0.8.1. llvmlite 0.34.0. louvain 0.7.0. matplotlib 3.3.2. mpl_toolkits NA. natsort 7.0.1. numba 0.51.2. numexpr 2.7.1. numpy 1.19.4. opt_einsum v3.3.0. packaging 20.4. pandas 1.1.4. parso 0.7.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. progressbar 3.53.1. prompt_toolkit 3.0.8. psutil 5.7.3. ptyprocess 0.6.0. pygam 0.8.0. pygments 2.7.2. pyparsing 2.4.7. python_utils NA. pytz 2020.4. scanpy 1.6.0. scipy 1.5.3. scvelo 0.2.2. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. sphinxcontrib NA. storemagic NA. ta",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1480
https://github.com/scverse/scanpy/issues/1480:2754,modifiability,deco,decorator,2754,". --> 112 return _read(. 113 filename,. 114 backed=backed,. ~/.miniconda3/envs/cellrank2/lib/python3.8/site-packages/scanpy/readwrite.py in _read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compression, suppress_cache_warning, **kwargs). 698 if ext in {'h5', 'h5ad'}:. 699 if sheet is None:. --> 700 return read_h5ad(filename, backed=backed). 701 else:. 702 logg.debug(f'reading sheet {sheet} from file {filename}'). ~/.miniconda3/envs/cellrank2/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 427 _clean_uns(d) # backwards compat. 428 . --> 429 return AnnData(**d). 430 . 431 . TypeError: __init__() got an unexpected keyword argument 'batch.names'. ```. #### Versions. <details>. -----. anndata 0.7.4. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. absl NA. anndata 0.7.4. autoreload NA. backcall 0.2.0. cellrank 1.0.0. cffi 1.14.3. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. docrep 0.3.1. future_fstrings NA. get_version 2.1. h5py 2.10.0. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. jax 0.2.5. jaxlib 0.1.56. jedi 0.17.2. joblib 0.17.0. kiwisolver 1.3.1. lapack NA. legacy_api_wrap 1.2. leidenalg 0.8.1. llvmlite 0.34.0. louvain 0.7.0. matplotlib 3.3.2. mpl_toolkits NA. natsort 7.0.1. numba 0.51.2. numexpr 2.7.1. numpy 1.19.4. opt_einsum v3.3.0. packaging 20.4. pandas 1.1.4. parso 0.7.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. progressbar 3.53.1. prompt_toolkit 3.0.8. psutil 5.7.3. ptyprocess 0.6.0. pygam 0.8.0. pygments 2.7.2. pyparsing 2.4.7. python_utils NA. pytz 2020.4. scanpy 1.6.0. scipy 1.5.3. scvelo 0.2.2. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. sphinxcontrib NA. storemagic NA. tables 3.6.1. texttable 1.6.3. threadpoolctl 2.1.0. tornado 6.1. traitlets 5.0.5. wcwidth 0.2.5. wrapt 1.12.1. zmq 19.0.2. -----. IPython 7.19.0. jupyter_client 6.1.7. jupyter_core 4.6.3. notebook 6.1.4. -----. Python 3.8.5 (",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1480
https://github.com/scverse/scanpy/issues/1480:3155,modifiability,pac,packaging,3155," delimiter, first_column_names, backup_url, cache, cache_compression, suppress_cache_warning, **kwargs). 698 if ext in {'h5', 'h5ad'}:. 699 if sheet is None:. --> 700 return read_h5ad(filename, backed=backed). 701 else:. 702 logg.debug(f'reading sheet {sheet} from file {filename}'). ~/.miniconda3/envs/cellrank2/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 427 _clean_uns(d) # backwards compat. 428 . --> 429 return AnnData(**d). 430 . 431 . TypeError: __init__() got an unexpected keyword argument 'batch.names'. ```. #### Versions. <details>. -----. anndata 0.7.4. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. absl NA. anndata 0.7.4. autoreload NA. backcall 0.2.0. cellrank 1.0.0. cffi 1.14.3. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. docrep 0.3.1. future_fstrings NA. get_version 2.1. h5py 2.10.0. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. jax 0.2.5. jaxlib 0.1.56. jedi 0.17.2. joblib 0.17.0. kiwisolver 1.3.1. lapack NA. legacy_api_wrap 1.2. leidenalg 0.8.1. llvmlite 0.34.0. louvain 0.7.0. matplotlib 3.3.2. mpl_toolkits NA. natsort 7.0.1. numba 0.51.2. numexpr 2.7.1. numpy 1.19.4. opt_einsum v3.3.0. packaging 20.4. pandas 1.1.4. parso 0.7.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. progressbar 3.53.1. prompt_toolkit 3.0.8. psutil 5.7.3. ptyprocess 0.6.0. pygam 0.8.0. pygments 2.7.2. pyparsing 2.4.7. python_utils NA. pytz 2020.4. scanpy 1.6.0. scipy 1.5.3. scvelo 0.2.2. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. sphinxcontrib NA. storemagic NA. tables 3.6.1. texttable 1.6.3. threadpoolctl 2.1.0. tornado 6.1. traitlets 5.0.5. wcwidth 0.2.5. wrapt 1.12.1. zmq 19.0.2. -----. IPython 7.19.0. jupyter_client 6.1.7. jupyter_core 4.6.3. notebook 6.1.4. -----. Python 3.8.5 (default, Sep 4 2020, 07:30:14) [GCC 7.3.0]. Linux-5.8.0-3-amd64-x86_64-with-glibc2.10. 8 logical CPU cores. -----. Session information updated at 2020-11-03 13:36. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1480
https://github.com/scverse/scanpy/issues/1480:1632,performance,cach,cache,1632,"d"").obs_names # names are bytes, not str. # Index([ b'0', b'1', b'2', b'3', b'4', b'5', b'6', b'7', b'8', ..., dtype='object', length=640). ```. When using `h5py==2.10.0`, it works as expected (i.e. the index type is str). The same happens for `.var_names` (I haven't check further). I'd recommend updating the requirements.txt oto `h5py<=2.10.0` for now. Related h5py issue: https://github.com/h5py/h5py/issues/1732. Also, I've encoutered this bug when coming up with example (seems unrelated):. ```python. import scanpy as sc. adata = sc.datasets.paul15(). sc.read('data/paul15/paul15.h5'). ```. The last line raises:. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-24-3d2f3a02bf09> in <module>. ----> 1 sc.read('data/paul15/paul15.h5'). ~/.miniconda3/envs/cellrank2/lib/python3.8/site-packages/scanpy/readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compression, **kwargs). 110 filename = Path(filename) # allow passing strings. 111 if is_valid_filename(filename):. --> 112 return _read(. 113 filename,. 114 backed=backed,. ~/.miniconda3/envs/cellrank2/lib/python3.8/site-packages/scanpy/readwrite.py in _read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compression, suppress_cache_warning, **kwargs). 698 if ext in {'h5', 'h5ad'}:. 699 if sheet is None:. --> 700 return read_h5ad(filename, backed=backed). 701 else:. 702 logg.debug(f'reading sheet {sheet} from file {filename}'). ~/.miniconda3/envs/cellrank2/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 427 _clean_uns(d) # backwards compat. 428 . --> 429 return AnnData(**d). 430 . 431 . TypeError: __init__() got an unexpected keyword argument 'batch.names'. ```. #### Versions. <details>. -----. anndata 0.7.4. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. absl NA. anndat",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1480
https://github.com/scverse/scanpy/issues/1480:1978,performance,cach,cache,1978," for now. Related h5py issue: https://github.com/h5py/h5py/issues/1732. Also, I've encoutered this bug when coming up with example (seems unrelated):. ```python. import scanpy as sc. adata = sc.datasets.paul15(). sc.read('data/paul15/paul15.h5'). ```. The last line raises:. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-24-3d2f3a02bf09> in <module>. ----> 1 sc.read('data/paul15/paul15.h5'). ~/.miniconda3/envs/cellrank2/lib/python3.8/site-packages/scanpy/readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compression, **kwargs). 110 filename = Path(filename) # allow passing strings. 111 if is_valid_filename(filename):. --> 112 return _read(. 113 filename,. 114 backed=backed,. ~/.miniconda3/envs/cellrank2/lib/python3.8/site-packages/scanpy/readwrite.py in _read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compression, suppress_cache_warning, **kwargs). 698 if ext in {'h5', 'h5ad'}:. 699 if sheet is None:. --> 700 return read_h5ad(filename, backed=backed). 701 else:. 702 logg.debug(f'reading sheet {sheet} from file {filename}'). ~/.miniconda3/envs/cellrank2/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 427 _clean_uns(d) # backwards compat. 428 . --> 429 return AnnData(**d). 430 . 431 . TypeError: __init__() got an unexpected keyword argument 'batch.names'. ```. #### Versions. <details>. -----. anndata 0.7.4. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. absl NA. anndata 0.7.4. autoreload NA. backcall 0.2.0. cellrank 1.0.0. cffi 1.14.3. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. docrep 0.3.1. future_fstrings NA. get_version 2.1. h5py 2.10.0. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. jax 0.2.5. jaxlib 0.1.56. jedi 0.17.2. joblib 0.17.0. kiwisolver 1.3.1. lapack NA. legacy_a",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1480
https://github.com/scverse/scanpy/issues/1480:2508,performance,batch,batch,2508,"on3.8/site-packages/scanpy/readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compression, **kwargs). 110 filename = Path(filename) # allow passing strings. 111 if is_valid_filename(filename):. --> 112 return _read(. 113 filename,. 114 backed=backed,. ~/.miniconda3/envs/cellrank2/lib/python3.8/site-packages/scanpy/readwrite.py in _read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compression, suppress_cache_warning, **kwargs). 698 if ext in {'h5', 'h5ad'}:. 699 if sheet is None:. --> 700 return read_h5ad(filename, backed=backed). 701 else:. 702 logg.debug(f'reading sheet {sheet} from file {filename}'). ~/.miniconda3/envs/cellrank2/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 427 _clean_uns(d) # backwards compat. 428 . --> 429 return AnnData(**d). 430 . 431 . TypeError: __init__() got an unexpected keyword argument 'batch.names'. ```. #### Versions. <details>. -----. anndata 0.7.4. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. absl NA. anndata 0.7.4. autoreload NA. backcall 0.2.0. cellrank 1.0.0. cffi 1.14.3. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. docrep 0.3.1. future_fstrings NA. get_version 2.1. h5py 2.10.0. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. jax 0.2.5. jaxlib 0.1.56. jedi 0.17.2. joblib 0.17.0. kiwisolver 1.3.1. lapack NA. legacy_api_wrap 1.2. leidenalg 0.8.1. llvmlite 0.34.0. louvain 0.7.0. matplotlib 3.3.2. mpl_toolkits NA. natsort 7.0.1. numba 0.51.2. numexpr 2.7.1. numpy 1.19.4. opt_einsum v3.3.0. packaging 20.4. pandas 1.1.4. parso 0.7.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. progressbar 3.53.1. prompt_toolkit 3.0.8. psutil 5.7.3. ptyprocess 0.6.0. pygam 0.8.0. pygments 2.7.2. pyparsing 2.4.7. python_utils NA. pytz 2020.4. scanpy 1.6.0. scipy 1.5.3. scvelo 0.2.2. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. sphinxcont",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1480
https://github.com/scverse/scanpy/issues/1480:3856,performance,CPU,CPU,3856," delimiter, first_column_names, backup_url, cache, cache_compression, suppress_cache_warning, **kwargs). 698 if ext in {'h5', 'h5ad'}:. 699 if sheet is None:. --> 700 return read_h5ad(filename, backed=backed). 701 else:. 702 logg.debug(f'reading sheet {sheet} from file {filename}'). ~/.miniconda3/envs/cellrank2/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 427 _clean_uns(d) # backwards compat. 428 . --> 429 return AnnData(**d). 430 . 431 . TypeError: __init__() got an unexpected keyword argument 'batch.names'. ```. #### Versions. <details>. -----. anndata 0.7.4. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. absl NA. anndata 0.7.4. autoreload NA. backcall 0.2.0. cellrank 1.0.0. cffi 1.14.3. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. docrep 0.3.1. future_fstrings NA. get_version 2.1. h5py 2.10.0. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. jax 0.2.5. jaxlib 0.1.56. jedi 0.17.2. joblib 0.17.0. kiwisolver 1.3.1. lapack NA. legacy_api_wrap 1.2. leidenalg 0.8.1. llvmlite 0.34.0. louvain 0.7.0. matplotlib 3.3.2. mpl_toolkits NA. natsort 7.0.1. numba 0.51.2. numexpr 2.7.1. numpy 1.19.4. opt_einsum v3.3.0. packaging 20.4. pandas 1.1.4. parso 0.7.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. progressbar 3.53.1. prompt_toolkit 3.0.8. psutil 5.7.3. ptyprocess 0.6.0. pygam 0.8.0. pygments 2.7.2. pyparsing 2.4.7. python_utils NA. pytz 2020.4. scanpy 1.6.0. scipy 1.5.3. scvelo 0.2.2. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. sphinxcontrib NA. storemagic NA. tables 3.6.1. texttable 1.6.3. threadpoolctl 2.1.0. tornado 6.1. traitlets 5.0.5. wcwidth 0.2.5. wrapt 1.12.1. zmq 19.0.2. -----. IPython 7.19.0. jupyter_client 6.1.7. jupyter_core 4.6.3. notebook 6.1.4. -----. Python 3.8.5 (default, Sep 4 2020, 07:30:14) [GCC 7.3.0]. Linux-5.8.0-3-amd64-x86_64-with-glibc2.10. 8 logical CPU cores. -----. Session information updated at 2020-11-03 13:36. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1480
https://github.com/scverse/scanpy/issues/1480:520,safety,updat,update,520,"Issue with new h5py; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # update to h5py e.g. as: pip install h5py==3.0.0. import scanpy as sc. adata = sc.datasets.blobs(). sc.read(""foo.h5ad"").obs_names # names are bytes, not str. # Index([ b'0', b'1', b'2', b'3', b'4', b'5', b'6', b'7', b'8', ..., dtype='object', length=640). ```. When using `h5py==2.10.0`, it works as expected (i.e. the index type is str). The same happens for `.var_names` (I haven't check further). I'd recommend updating the requirements.txt oto `h5py<=2.10.0` for now. Related h5py issue: https://github.com/h5py/h5py/issues/1732. Also, I've encoutered this bug when coming up with example (seems unrelated):. ```python. import scanpy as sc. adata = sc.datasets.paul15(). sc.read('data/paul15/paul15.h5'). ```. The last line raises:. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-24-3d2f3a02bf09> in <module>. ----> 1 sc.read('data/paul15/paul15.h5'). ~/.miniconda3/envs/cellrank2/lib/python3.8/site-packages/scanpy/readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compression, **kwargs). 110 filename = Path(filename) # allow passing strings. 111 if is_valid_filename(filename):. --> 112 return _read(. 113 filename,. 114 backed=backed,. ~/.miniconda3/envs/cellrank2/lib/python3.8/site-packages/scanpy/readwrite.py in _read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compressi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1480
https://github.com/scverse/scanpy/issues/1480:933,safety,updat,updating,933,"Issue with new h5py; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # update to h5py e.g. as: pip install h5py==3.0.0. import scanpy as sc. adata = sc.datasets.blobs(). sc.read(""foo.h5ad"").obs_names # names are bytes, not str. # Index([ b'0', b'1', b'2', b'3', b'4', b'5', b'6', b'7', b'8', ..., dtype='object', length=640). ```. When using `h5py==2.10.0`, it works as expected (i.e. the index type is str). The same happens for `.var_names` (I haven't check further). I'd recommend updating the requirements.txt oto `h5py<=2.10.0` for now. Related h5py issue: https://github.com/h5py/h5py/issues/1732. Also, I've encoutered this bug when coming up with example (seems unrelated):. ```python. import scanpy as sc. adata = sc.datasets.paul15(). sc.read('data/paul15/paul15.h5'). ```. The last line raises:. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-24-3d2f3a02bf09> in <module>. ----> 1 sc.read('data/paul15/paul15.h5'). ~/.miniconda3/envs/cellrank2/lib/python3.8/site-packages/scanpy/readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compression, **kwargs). 110 filename = Path(filename) # allow passing strings. 111 if is_valid_filename(filename):. --> 112 return _read(. 113 filename,. 114 backed=backed,. ~/.miniconda3/envs/cellrank2/lib/python3.8/site-packages/scanpy/readwrite.py in _read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compressi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1480
https://github.com/scverse/scanpy/issues/1480:1396,safety,input,input-,1396,"ion for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # update to h5py e.g. as: pip install h5py==3.0.0. import scanpy as sc. adata = sc.datasets.blobs(). sc.read(""foo.h5ad"").obs_names # names are bytes, not str. # Index([ b'0', b'1', b'2', b'3', b'4', b'5', b'6', b'7', b'8', ..., dtype='object', length=640). ```. When using `h5py==2.10.0`, it works as expected (i.e. the index type is str). The same happens for `.var_names` (I haven't check further). I'd recommend updating the requirements.txt oto `h5py<=2.10.0` for now. Related h5py issue: https://github.com/h5py/h5py/issues/1732. Also, I've encoutered this bug when coming up with example (seems unrelated):. ```python. import scanpy as sc. adata = sc.datasets.paul15(). sc.read('data/paul15/paul15.h5'). ```. The last line raises:. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-24-3d2f3a02bf09> in <module>. ----> 1 sc.read('data/paul15/paul15.h5'). ~/.miniconda3/envs/cellrank2/lib/python3.8/site-packages/scanpy/readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compression, **kwargs). 110 filename = Path(filename) # allow passing strings. 111 if is_valid_filename(filename):. --> 112 return _read(. 113 filename,. 114 backed=backed,. ~/.miniconda3/envs/cellrank2/lib/python3.8/site-packages/scanpy/readwrite.py in _read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compression, suppress_cache_warning, **kwargs). 698 if ext in {'h5', 'h5ad'}:. 699 if sheet is None:. --> 700 return read_h5ad(filename, backed=backed). 701 else:. 702 logg.debug(f'reading sheet {sheet} from file {filename}'). ~/.miniconda3/envs/cellrank2/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 427 _clean_uns(d) # backwards comp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1480
https://github.com/scverse/scanpy/issues/1480:1423,safety,modul,module,1423,"r bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # update to h5py e.g. as: pip install h5py==3.0.0. import scanpy as sc. adata = sc.datasets.blobs(). sc.read(""foo.h5ad"").obs_names # names are bytes, not str. # Index([ b'0', b'1', b'2', b'3', b'4', b'5', b'6', b'7', b'8', ..., dtype='object', length=640). ```. When using `h5py==2.10.0`, it works as expected (i.e. the index type is str). The same happens for `.var_names` (I haven't check further). I'd recommend updating the requirements.txt oto `h5py<=2.10.0` for now. Related h5py issue: https://github.com/h5py/h5py/issues/1732. Also, I've encoutered this bug when coming up with example (seems unrelated):. ```python. import scanpy as sc. adata = sc.datasets.paul15(). sc.read('data/paul15/paul15.h5'). ```. The last line raises:. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-24-3d2f3a02bf09> in <module>. ----> 1 sc.read('data/paul15/paul15.h5'). ~/.miniconda3/envs/cellrank2/lib/python3.8/site-packages/scanpy/readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compression, **kwargs). 110 filename = Path(filename) # allow passing strings. 111 if is_valid_filename(filename):. --> 112 return _read(. 113 filename,. 114 backed=backed,. ~/.miniconda3/envs/cellrank2/lib/python3.8/site-packages/scanpy/readwrite.py in _read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compression, suppress_cache_warning, **kwargs). 698 if ext in {'h5', 'h5ad'}:. 699 if sheet is None:. --> 700 return read_h5ad(filename, backed=backed). 701 else:. 702 logg.debug(f'reading sheet {sheet} from file {filename}'). ~/.miniconda3/envs/cellrank2/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 427 _clean_uns(d) # backwards compat. 428 . --> 429 return An",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1480
https://github.com/scverse/scanpy/issues/1480:2159,safety,log,logg,2159,"c. adata = sc.datasets.paul15(). sc.read('data/paul15/paul15.h5'). ```. The last line raises:. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-24-3d2f3a02bf09> in <module>. ----> 1 sc.read('data/paul15/paul15.h5'). ~/.miniconda3/envs/cellrank2/lib/python3.8/site-packages/scanpy/readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compression, **kwargs). 110 filename = Path(filename) # allow passing strings. 111 if is_valid_filename(filename):. --> 112 return _read(. 113 filename,. 114 backed=backed,. ~/.miniconda3/envs/cellrank2/lib/python3.8/site-packages/scanpy/readwrite.py in _read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compression, suppress_cache_warning, **kwargs). 698 if ext in {'h5', 'h5ad'}:. 699 if sheet is None:. --> 700 return read_h5ad(filename, backed=backed). 701 else:. 702 logg.debug(f'reading sheet {sheet} from file {filename}'). ~/.miniconda3/envs/cellrank2/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 427 _clean_uns(d) # backwards compat. 428 . --> 429 return AnnData(**d). 430 . 431 . TypeError: __init__() got an unexpected keyword argument 'batch.names'. ```. #### Versions. <details>. -----. anndata 0.7.4. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. absl NA. anndata 0.7.4. autoreload NA. backcall 0.2.0. cellrank 1.0.0. cffi 1.14.3. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. docrep 0.3.1. future_fstrings NA. get_version 2.1. h5py 2.10.0. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. jax 0.2.5. jaxlib 0.1.56. jedi 0.17.2. joblib 0.17.0. kiwisolver 1.3.1. lapack NA. legacy_api_wrap 1.2. leidenalg 0.8.1. llvmlite 0.34.0. louvain 0.7.0. matplotlib 3.3.2. mpl_toolkits NA. natsort 7.0.1. numba 0.51.2. numexpr 2.7.1. numpy 1.19.4. opt_einsum v3.3.0. packag",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1480
https://github.com/scverse/scanpy/issues/1480:3848,safety,log,logical,3848," delimiter, first_column_names, backup_url, cache, cache_compression, suppress_cache_warning, **kwargs). 698 if ext in {'h5', 'h5ad'}:. 699 if sheet is None:. --> 700 return read_h5ad(filename, backed=backed). 701 else:. 702 logg.debug(f'reading sheet {sheet} from file {filename}'). ~/.miniconda3/envs/cellrank2/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 427 _clean_uns(d) # backwards compat. 428 . --> 429 return AnnData(**d). 430 . 431 . TypeError: __init__() got an unexpected keyword argument 'batch.names'. ```. #### Versions. <details>. -----. anndata 0.7.4. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. absl NA. anndata 0.7.4. autoreload NA. backcall 0.2.0. cellrank 1.0.0. cffi 1.14.3. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. docrep 0.3.1. future_fstrings NA. get_version 2.1. h5py 2.10.0. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. jax 0.2.5. jaxlib 0.1.56. jedi 0.17.2. joblib 0.17.0. kiwisolver 1.3.1. lapack NA. legacy_api_wrap 1.2. leidenalg 0.8.1. llvmlite 0.34.0. louvain 0.7.0. matplotlib 3.3.2. mpl_toolkits NA. natsort 7.0.1. numba 0.51.2. numexpr 2.7.1. numpy 1.19.4. opt_einsum v3.3.0. packaging 20.4. pandas 1.1.4. parso 0.7.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. progressbar 3.53.1. prompt_toolkit 3.0.8. psutil 5.7.3. ptyprocess 0.6.0. pygam 0.8.0. pygments 2.7.2. pyparsing 2.4.7. python_utils NA. pytz 2020.4. scanpy 1.6.0. scipy 1.5.3. scvelo 0.2.2. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. sphinxcontrib NA. storemagic NA. tables 3.6.1. texttable 1.6.3. threadpoolctl 2.1.0. tornado 6.1. traitlets 5.0.5. wcwidth 0.2.5. wrapt 1.12.1. zmq 19.0.2. -----. IPython 7.19.0. jupyter_client 6.1.7. jupyter_core 4.6.3. notebook 6.1.4. -----. Python 3.8.5 (default, Sep 4 2020, 07:30:14) [GCC 7.3.0]. Linux-5.8.0-3-amd64-x86_64-with-glibc2.10. 8 logical CPU cores. -----. Session information updated at 2020-11-03 13:36. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1480
https://github.com/scverse/scanpy/issues/1480:3894,safety,updat,updated,3894," delimiter, first_column_names, backup_url, cache, cache_compression, suppress_cache_warning, **kwargs). 698 if ext in {'h5', 'h5ad'}:. 699 if sheet is None:. --> 700 return read_h5ad(filename, backed=backed). 701 else:. 702 logg.debug(f'reading sheet {sheet} from file {filename}'). ~/.miniconda3/envs/cellrank2/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 427 _clean_uns(d) # backwards compat. 428 . --> 429 return AnnData(**d). 430 . 431 . TypeError: __init__() got an unexpected keyword argument 'batch.names'. ```. #### Versions. <details>. -----. anndata 0.7.4. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. absl NA. anndata 0.7.4. autoreload NA. backcall 0.2.0. cellrank 1.0.0. cffi 1.14.3. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. docrep 0.3.1. future_fstrings NA. get_version 2.1. h5py 2.10.0. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. jax 0.2.5. jaxlib 0.1.56. jedi 0.17.2. joblib 0.17.0. kiwisolver 1.3.1. lapack NA. legacy_api_wrap 1.2. leidenalg 0.8.1. llvmlite 0.34.0. louvain 0.7.0. matplotlib 3.3.2. mpl_toolkits NA. natsort 7.0.1. numba 0.51.2. numexpr 2.7.1. numpy 1.19.4. opt_einsum v3.3.0. packaging 20.4. pandas 1.1.4. parso 0.7.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. progressbar 3.53.1. prompt_toolkit 3.0.8. psutil 5.7.3. ptyprocess 0.6.0. pygam 0.8.0. pygments 2.7.2. pyparsing 2.4.7. python_utils NA. pytz 2020.4. scanpy 1.6.0. scipy 1.5.3. scvelo 0.2.2. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. sphinxcontrib NA. storemagic NA. tables 3.6.1. texttable 1.6.3. threadpoolctl 2.1.0. tornado 6.1. traitlets 5.0.5. wcwidth 0.2.5. wrapt 1.12.1. zmq 19.0.2. -----. IPython 7.19.0. jupyter_client 6.1.7. jupyter_core 4.6.3. notebook 6.1.4. -----. Python 3.8.5 (default, Sep 4 2020, 07:30:14) [GCC 7.3.0]. Linux-5.8.0-3-amd64-x86_64-with-glibc2.10. 8 logical CPU cores. -----. Session information updated at 2020-11-03 13:36. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1480
https://github.com/scverse/scanpy/issues/1480:520,security,updat,update,520,"Issue with new h5py; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # update to h5py e.g. as: pip install h5py==3.0.0. import scanpy as sc. adata = sc.datasets.blobs(). sc.read(""foo.h5ad"").obs_names # names are bytes, not str. # Index([ b'0', b'1', b'2', b'3', b'4', b'5', b'6', b'7', b'8', ..., dtype='object', length=640). ```. When using `h5py==2.10.0`, it works as expected (i.e. the index type is str). The same happens for `.var_names` (I haven't check further). I'd recommend updating the requirements.txt oto `h5py<=2.10.0` for now. Related h5py issue: https://github.com/h5py/h5py/issues/1732. Also, I've encoutered this bug when coming up with example (seems unrelated):. ```python. import scanpy as sc. adata = sc.datasets.paul15(). sc.read('data/paul15/paul15.h5'). ```. The last line raises:. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-24-3d2f3a02bf09> in <module>. ----> 1 sc.read('data/paul15/paul15.h5'). ~/.miniconda3/envs/cellrank2/lib/python3.8/site-packages/scanpy/readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compression, **kwargs). 110 filename = Path(filename) # allow passing strings. 111 if is_valid_filename(filename):. --> 112 return _read(. 113 filename,. 114 backed=backed,. ~/.miniconda3/envs/cellrank2/lib/python3.8/site-packages/scanpy/readwrite.py in _read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compressi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1480
https://github.com/scverse/scanpy/issues/1480:933,security,updat,updating,933,"Issue with new h5py; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # update to h5py e.g. as: pip install h5py==3.0.0. import scanpy as sc. adata = sc.datasets.blobs(). sc.read(""foo.h5ad"").obs_names # names are bytes, not str. # Index([ b'0', b'1', b'2', b'3', b'4', b'5', b'6', b'7', b'8', ..., dtype='object', length=640). ```. When using `h5py==2.10.0`, it works as expected (i.e. the index type is str). The same happens for `.var_names` (I haven't check further). I'd recommend updating the requirements.txt oto `h5py<=2.10.0` for now. Related h5py issue: https://github.com/h5py/h5py/issues/1732. Also, I've encoutered this bug when coming up with example (seems unrelated):. ```python. import scanpy as sc. adata = sc.datasets.paul15(). sc.read('data/paul15/paul15.h5'). ```. The last line raises:. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-24-3d2f3a02bf09> in <module>. ----> 1 sc.read('data/paul15/paul15.h5'). ~/.miniconda3/envs/cellrank2/lib/python3.8/site-packages/scanpy/readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compression, **kwargs). 110 filename = Path(filename) # allow passing strings. 111 if is_valid_filename(filename):. --> 112 return _read(. 113 filename,. 114 backed=backed,. ~/.miniconda3/envs/cellrank2/lib/python3.8/site-packages/scanpy/readwrite.py in _read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compressi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1480
https://github.com/scverse/scanpy/issues/1480:2159,security,log,logg,2159,"c. adata = sc.datasets.paul15(). sc.read('data/paul15/paul15.h5'). ```. The last line raises:. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-24-3d2f3a02bf09> in <module>. ----> 1 sc.read('data/paul15/paul15.h5'). ~/.miniconda3/envs/cellrank2/lib/python3.8/site-packages/scanpy/readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compression, **kwargs). 110 filename = Path(filename) # allow passing strings. 111 if is_valid_filename(filename):. --> 112 return _read(. 113 filename,. 114 backed=backed,. ~/.miniconda3/envs/cellrank2/lib/python3.8/site-packages/scanpy/readwrite.py in _read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compression, suppress_cache_warning, **kwargs). 698 if ext in {'h5', 'h5ad'}:. 699 if sheet is None:. --> 700 return read_h5ad(filename, backed=backed). 701 else:. 702 logg.debug(f'reading sheet {sheet} from file {filename}'). ~/.miniconda3/envs/cellrank2/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 427 _clean_uns(d) # backwards compat. 428 . --> 429 return AnnData(**d). 430 . 431 . TypeError: __init__() got an unexpected keyword argument 'batch.names'. ```. #### Versions. <details>. -----. anndata 0.7.4. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. absl NA. anndata 0.7.4. autoreload NA. backcall 0.2.0. cellrank 1.0.0. cffi 1.14.3. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. docrep 0.3.1. future_fstrings NA. get_version 2.1. h5py 2.10.0. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. jax 0.2.5. jaxlib 0.1.56. jedi 0.17.2. joblib 0.17.0. kiwisolver 1.3.1. lapack NA. legacy_api_wrap 1.2. leidenalg 0.8.1. llvmlite 0.34.0. louvain 0.7.0. matplotlib 3.3.2. mpl_toolkits NA. natsort 7.0.1. numba 0.51.2. numexpr 2.7.1. numpy 1.19.4. opt_einsum v3.3.0. packag",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1480
https://github.com/scverse/scanpy/issues/1480:3848,security,log,logical,3848," delimiter, first_column_names, backup_url, cache, cache_compression, suppress_cache_warning, **kwargs). 698 if ext in {'h5', 'h5ad'}:. 699 if sheet is None:. --> 700 return read_h5ad(filename, backed=backed). 701 else:. 702 logg.debug(f'reading sheet {sheet} from file {filename}'). ~/.miniconda3/envs/cellrank2/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 427 _clean_uns(d) # backwards compat. 428 . --> 429 return AnnData(**d). 430 . 431 . TypeError: __init__() got an unexpected keyword argument 'batch.names'. ```. #### Versions. <details>. -----. anndata 0.7.4. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. absl NA. anndata 0.7.4. autoreload NA. backcall 0.2.0. cellrank 1.0.0. cffi 1.14.3. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. docrep 0.3.1. future_fstrings NA. get_version 2.1. h5py 2.10.0. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. jax 0.2.5. jaxlib 0.1.56. jedi 0.17.2. joblib 0.17.0. kiwisolver 1.3.1. lapack NA. legacy_api_wrap 1.2. leidenalg 0.8.1. llvmlite 0.34.0. louvain 0.7.0. matplotlib 3.3.2. mpl_toolkits NA. natsort 7.0.1. numba 0.51.2. numexpr 2.7.1. numpy 1.19.4. opt_einsum v3.3.0. packaging 20.4. pandas 1.1.4. parso 0.7.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. progressbar 3.53.1. prompt_toolkit 3.0.8. psutil 5.7.3. ptyprocess 0.6.0. pygam 0.8.0. pygments 2.7.2. pyparsing 2.4.7. python_utils NA. pytz 2020.4. scanpy 1.6.0. scipy 1.5.3. scvelo 0.2.2. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. sphinxcontrib NA. storemagic NA. tables 3.6.1. texttable 1.6.3. threadpoolctl 2.1.0. tornado 6.1. traitlets 5.0.5. wcwidth 0.2.5. wrapt 1.12.1. zmq 19.0.2. -----. IPython 7.19.0. jupyter_client 6.1.7. jupyter_core 4.6.3. notebook 6.1.4. -----. Python 3.8.5 (default, Sep 4 2020, 07:30:14) [GCC 7.3.0]. Linux-5.8.0-3-amd64-x86_64-with-glibc2.10. 8 logical CPU cores. -----. Session information updated at 2020-11-03 13:36. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1480
https://github.com/scverse/scanpy/issues/1480:3874,security,Session,Session,3874," delimiter, first_column_names, backup_url, cache, cache_compression, suppress_cache_warning, **kwargs). 698 if ext in {'h5', 'h5ad'}:. 699 if sheet is None:. --> 700 return read_h5ad(filename, backed=backed). 701 else:. 702 logg.debug(f'reading sheet {sheet} from file {filename}'). ~/.miniconda3/envs/cellrank2/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 427 _clean_uns(d) # backwards compat. 428 . --> 429 return AnnData(**d). 430 . 431 . TypeError: __init__() got an unexpected keyword argument 'batch.names'. ```. #### Versions. <details>. -----. anndata 0.7.4. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. absl NA. anndata 0.7.4. autoreload NA. backcall 0.2.0. cellrank 1.0.0. cffi 1.14.3. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. docrep 0.3.1. future_fstrings NA. get_version 2.1. h5py 2.10.0. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. jax 0.2.5. jaxlib 0.1.56. jedi 0.17.2. joblib 0.17.0. kiwisolver 1.3.1. lapack NA. legacy_api_wrap 1.2. leidenalg 0.8.1. llvmlite 0.34.0. louvain 0.7.0. matplotlib 3.3.2. mpl_toolkits NA. natsort 7.0.1. numba 0.51.2. numexpr 2.7.1. numpy 1.19.4. opt_einsum v3.3.0. packaging 20.4. pandas 1.1.4. parso 0.7.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. progressbar 3.53.1. prompt_toolkit 3.0.8. psutil 5.7.3. ptyprocess 0.6.0. pygam 0.8.0. pygments 2.7.2. pyparsing 2.4.7. python_utils NA. pytz 2020.4. scanpy 1.6.0. scipy 1.5.3. scvelo 0.2.2. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. sphinxcontrib NA. storemagic NA. tables 3.6.1. texttable 1.6.3. threadpoolctl 2.1.0. tornado 6.1. traitlets 5.0.5. wcwidth 0.2.5. wrapt 1.12.1. zmq 19.0.2. -----. IPython 7.19.0. jupyter_client 6.1.7. jupyter_core 4.6.3. notebook 6.1.4. -----. Python 3.8.5 (default, Sep 4 2020, 07:30:14) [GCC 7.3.0]. Linux-5.8.0-3-amd64-x86_64-with-glibc2.10. 8 logical CPU cores. -----. Session information updated at 2020-11-03 13:36. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1480
https://github.com/scverse/scanpy/issues/1480:3894,security,updat,updated,3894," delimiter, first_column_names, backup_url, cache, cache_compression, suppress_cache_warning, **kwargs). 698 if ext in {'h5', 'h5ad'}:. 699 if sheet is None:. --> 700 return read_h5ad(filename, backed=backed). 701 else:. 702 logg.debug(f'reading sheet {sheet} from file {filename}'). ~/.miniconda3/envs/cellrank2/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 427 _clean_uns(d) # backwards compat. 428 . --> 429 return AnnData(**d). 430 . 431 . TypeError: __init__() got an unexpected keyword argument 'batch.names'. ```. #### Versions. <details>. -----. anndata 0.7.4. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. absl NA. anndata 0.7.4. autoreload NA. backcall 0.2.0. cellrank 1.0.0. cffi 1.14.3. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. docrep 0.3.1. future_fstrings NA. get_version 2.1. h5py 2.10.0. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. jax 0.2.5. jaxlib 0.1.56. jedi 0.17.2. joblib 0.17.0. kiwisolver 1.3.1. lapack NA. legacy_api_wrap 1.2. leidenalg 0.8.1. llvmlite 0.34.0. louvain 0.7.0. matplotlib 3.3.2. mpl_toolkits NA. natsort 7.0.1. numba 0.51.2. numexpr 2.7.1. numpy 1.19.4. opt_einsum v3.3.0. packaging 20.4. pandas 1.1.4. parso 0.7.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. progressbar 3.53.1. prompt_toolkit 3.0.8. psutil 5.7.3. ptyprocess 0.6.0. pygam 0.8.0. pygments 2.7.2. pyparsing 2.4.7. python_utils NA. pytz 2020.4. scanpy 1.6.0. scipy 1.5.3. scvelo 0.2.2. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. sphinxcontrib NA. storemagic NA. tables 3.6.1. texttable 1.6.3. threadpoolctl 2.1.0. tornado 6.1. traitlets 5.0.5. wcwidth 0.2.5. wrapt 1.12.1. zmq 19.0.2. -----. IPython 7.19.0. jupyter_client 6.1.7. jupyter_core 4.6.3. notebook 6.1.4. -----. Python 3.8.5 (default, Sep 4 2020, 07:30:14) [GCC 7.3.0]. Linux-5.8.0-3-amd64-x86_64-with-glibc2.10. 8 logical CPU cores. -----. Session information updated at 2020-11-03 13:36. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1480
https://github.com/scverse/scanpy/issues/1480:1352,testability,Trace,Traceback,1352,"ling how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # update to h5py e.g. as: pip install h5py==3.0.0. import scanpy as sc. adata = sc.datasets.blobs(). sc.read(""foo.h5ad"").obs_names # names are bytes, not str. # Index([ b'0', b'1', b'2', b'3', b'4', b'5', b'6', b'7', b'8', ..., dtype='object', length=640). ```. When using `h5py==2.10.0`, it works as expected (i.e. the index type is str). The same happens for `.var_names` (I haven't check further). I'd recommend updating the requirements.txt oto `h5py<=2.10.0` for now. Related h5py issue: https://github.com/h5py/h5py/issues/1732. Also, I've encoutered this bug when coming up with example (seems unrelated):. ```python. import scanpy as sc. adata = sc.datasets.paul15(). sc.read('data/paul15/paul15.h5'). ```. The last line raises:. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-24-3d2f3a02bf09> in <module>. ----> 1 sc.read('data/paul15/paul15.h5'). ~/.miniconda3/envs/cellrank2/lib/python3.8/site-packages/scanpy/readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compression, **kwargs). 110 filename = Path(filename) # allow passing strings. 111 if is_valid_filename(filename):. --> 112 return _read(. 113 filename,. 114 backed=backed,. ~/.miniconda3/envs/cellrank2/lib/python3.8/site-packages/scanpy/readwrite.py in _read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compression, suppress_cache_warning, **kwargs). 698 if ext in {'h5', 'h5ad'}:. 699 if sheet is None:. --> 700 return read_h5ad(filename, backed=backed). 701 else:. 702 logg.debug(f'reading sheet {sheet} from file {filename}'). ~/.miniconda3/envs/cellrank2/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1480
https://github.com/scverse/scanpy/issues/1480:2159,testability,log,logg,2159,"c. adata = sc.datasets.paul15(). sc.read('data/paul15/paul15.h5'). ```. The last line raises:. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-24-3d2f3a02bf09> in <module>. ----> 1 sc.read('data/paul15/paul15.h5'). ~/.miniconda3/envs/cellrank2/lib/python3.8/site-packages/scanpy/readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compression, **kwargs). 110 filename = Path(filename) # allow passing strings. 111 if is_valid_filename(filename):. --> 112 return _read(. 113 filename,. 114 backed=backed,. ~/.miniconda3/envs/cellrank2/lib/python3.8/site-packages/scanpy/readwrite.py in _read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compression, suppress_cache_warning, **kwargs). 698 if ext in {'h5', 'h5ad'}:. 699 if sheet is None:. --> 700 return read_h5ad(filename, backed=backed). 701 else:. 702 logg.debug(f'reading sheet {sheet} from file {filename}'). ~/.miniconda3/envs/cellrank2/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 427 _clean_uns(d) # backwards compat. 428 . --> 429 return AnnData(**d). 430 . 431 . TypeError: __init__() got an unexpected keyword argument 'batch.names'. ```. #### Versions. <details>. -----. anndata 0.7.4. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. absl NA. anndata 0.7.4. autoreload NA. backcall 0.2.0. cellrank 1.0.0. cffi 1.14.3. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. docrep 0.3.1. future_fstrings NA. get_version 2.1. h5py 2.10.0. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. jax 0.2.5. jaxlib 0.1.56. jedi 0.17.2. joblib 0.17.0. kiwisolver 1.3.1. lapack NA. legacy_api_wrap 1.2. leidenalg 0.8.1. llvmlite 0.34.0. louvain 0.7.0. matplotlib 3.3.2. mpl_toolkits NA. natsort 7.0.1. numba 0.51.2. numexpr 2.7.1. numpy 1.19.4. opt_einsum v3.3.0. packag",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1480
https://github.com/scverse/scanpy/issues/1480:3848,testability,log,logical,3848," delimiter, first_column_names, backup_url, cache, cache_compression, suppress_cache_warning, **kwargs). 698 if ext in {'h5', 'h5ad'}:. 699 if sheet is None:. --> 700 return read_h5ad(filename, backed=backed). 701 else:. 702 logg.debug(f'reading sheet {sheet} from file {filename}'). ~/.miniconda3/envs/cellrank2/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 427 _clean_uns(d) # backwards compat. 428 . --> 429 return AnnData(**d). 430 . 431 . TypeError: __init__() got an unexpected keyword argument 'batch.names'. ```. #### Versions. <details>. -----. anndata 0.7.4. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. absl NA. anndata 0.7.4. autoreload NA. backcall 0.2.0. cellrank 1.0.0. cffi 1.14.3. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. docrep 0.3.1. future_fstrings NA. get_version 2.1. h5py 2.10.0. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. jax 0.2.5. jaxlib 0.1.56. jedi 0.17.2. joblib 0.17.0. kiwisolver 1.3.1. lapack NA. legacy_api_wrap 1.2. leidenalg 0.8.1. llvmlite 0.34.0. louvain 0.7.0. matplotlib 3.3.2. mpl_toolkits NA. natsort 7.0.1. numba 0.51.2. numexpr 2.7.1. numpy 1.19.4. opt_einsum v3.3.0. packaging 20.4. pandas 1.1.4. parso 0.7.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. progressbar 3.53.1. prompt_toolkit 3.0.8. psutil 5.7.3. ptyprocess 0.6.0. pygam 0.8.0. pygments 2.7.2. pyparsing 2.4.7. python_utils NA. pytz 2020.4. scanpy 1.6.0. scipy 1.5.3. scvelo 0.2.2. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. sphinxcontrib NA. storemagic NA. tables 3.6.1. texttable 1.6.3. threadpoolctl 2.1.0. tornado 6.1. traitlets 5.0.5. wcwidth 0.2.5. wrapt 1.12.1. zmq 19.0.2. -----. IPython 7.19.0. jupyter_client 6.1.7. jupyter_core 4.6.3. notebook 6.1.4. -----. Python 3.8.5 (default, Sep 4 2020, 07:30:14) [GCC 7.3.0]. Linux-5.8.0-3-amd64-x86_64-with-glibc2.10. 8 logical CPU cores. -----. Session information updated at 2020-11-03 13:36. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1480
https://github.com/scverse/scanpy/issues/1480:102,usability,confirm,confirmed,102,"Issue with new h5py; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # update to h5py e.g. as: pip install h5py==3.0.0. import scanpy as sc. adata = sc.datasets.blobs(). sc.read(""foo.h5ad"").obs_names # names are bytes, not str. # Index([ b'0', b'1', b'2', b'3', b'4', b'5', b'6', b'7', b'8', ..., dtype='object', length=640). ```. When using `h5py==2.10.0`, it works as expected (i.e. the index type is str). The same happens for `.var_names` (I haven't check further). I'd recommend updating the requirements.txt oto `h5py<=2.10.0` for now. Related h5py issue: https://github.com/h5py/h5py/issues/1732. Also, I've encoutered this bug when coming up with example (seems unrelated):. ```python. import scanpy as sc. adata = sc.datasets.paul15(). sc.read('data/paul15/paul15.h5'). ```. The last line raises:. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-24-3d2f3a02bf09> in <module>. ----> 1 sc.read('data/paul15/paul15.h5'). ~/.miniconda3/envs/cellrank2/lib/python3.8/site-packages/scanpy/readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compression, **kwargs). 110 filename = Path(filename) # allow passing strings. 111 if is_valid_filename(filename):. --> 112 return _read(. 113 filename,. 114 backed=backed,. ~/.miniconda3/envs/cellrank2/lib/python3.8/site-packages/scanpy/readwrite.py in _read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compressi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1480
https://github.com/scverse/scanpy/issues/1480:185,usability,confirm,confirmed,185,"Issue with new h5py; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # update to h5py e.g. as: pip install h5py==3.0.0. import scanpy as sc. adata = sc.datasets.blobs(). sc.read(""foo.h5ad"").obs_names # names are bytes, not str. # Index([ b'0', b'1', b'2', b'3', b'4', b'5', b'6', b'7', b'8', ..., dtype='object', length=640). ```. When using `h5py==2.10.0`, it works as expected (i.e. the index type is str). The same happens for `.var_names` (I haven't check further). I'd recommend updating the requirements.txt oto `h5py<=2.10.0` for now. Related h5py issue: https://github.com/h5py/h5py/issues/1732. Also, I've encoutered this bug when coming up with example (seems unrelated):. ```python. import scanpy as sc. adata = sc.datasets.paul15(). sc.read('data/paul15/paul15.h5'). ```. The last line raises:. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-24-3d2f3a02bf09> in <module>. ----> 1 sc.read('data/paul15/paul15.h5'). ~/.miniconda3/envs/cellrank2/lib/python3.8/site-packages/scanpy/readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compression, **kwargs). 110 filename = Path(filename) # allow passing strings. 111 if is_valid_filename(filename):. --> 112 return _read(. 113 filename,. 114 backed=backed,. ~/.miniconda3/envs/cellrank2/lib/python3.8/site-packages/scanpy/readwrite.py in _read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compressi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1480
https://github.com/scverse/scanpy/issues/1480:276,usability,guid,guide,276,"Issue with new h5py; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # update to h5py e.g. as: pip install h5py==3.0.0. import scanpy as sc. adata = sc.datasets.blobs(). sc.read(""foo.h5ad"").obs_names # names are bytes, not str. # Index([ b'0', b'1', b'2', b'3', b'4', b'5', b'6', b'7', b'8', ..., dtype='object', length=640). ```. When using `h5py==2.10.0`, it works as expected (i.e. the index type is str). The same happens for `.var_names` (I haven't check further). I'd recommend updating the requirements.txt oto `h5py<=2.10.0` for now. Related h5py issue: https://github.com/h5py/h5py/issues/1732. Also, I've encoutered this bug when coming up with example (seems unrelated):. ```python. import scanpy as sc. adata = sc.datasets.paul15(). sc.read('data/paul15/paul15.h5'). ```. The last line raises:. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-24-3d2f3a02bf09> in <module>. ----> 1 sc.read('data/paul15/paul15.h5'). ~/.miniconda3/envs/cellrank2/lib/python3.8/site-packages/scanpy/readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compression, **kwargs). 110 filename = Path(filename) # allow passing strings. 111 if is_valid_filename(filename):. --> 112 return _read(. 113 filename,. 114 backed=backed,. ~/.miniconda3/envs/cellrank2/lib/python3.8/site-packages/scanpy/readwrite.py in _read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compressi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1480
https://github.com/scverse/scanpy/issues/1480:331,usability,minim,minimal-bug-reports,331,"Issue with new h5py; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # update to h5py e.g. as: pip install h5py==3.0.0. import scanpy as sc. adata = sc.datasets.blobs(). sc.read(""foo.h5ad"").obs_names # names are bytes, not str. # Index([ b'0', b'1', b'2', b'3', b'4', b'5', b'6', b'7', b'8', ..., dtype='object', length=640). ```. When using `h5py==2.10.0`, it works as expected (i.e. the index type is str). The same happens for `.var_names` (I haven't check further). I'd recommend updating the requirements.txt oto `h5py<=2.10.0` for now. Related h5py issue: https://github.com/h5py/h5py/issues/1732. Also, I've encoutered this bug when coming up with example (seems unrelated):. ```python. import scanpy as sc. adata = sc.datasets.paul15(). sc.read('data/paul15/paul15.h5'). ```. The last line raises:. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-24-3d2f3a02bf09> in <module>. ----> 1 sc.read('data/paul15/paul15.h5'). ~/.miniconda3/envs/cellrank2/lib/python3.8/site-packages/scanpy/readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compression, **kwargs). 110 filename = Path(filename) # allow passing strings. 111 if is_valid_filename(filename):. --> 112 return _read(. 113 filename,. 114 backed=backed,. ~/.miniconda3/envs/cellrank2/lib/python3.8/site-packages/scanpy/readwrite.py in _read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compressi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1480
https://github.com/scverse/scanpy/issues/1480:437,usability,Minim,Minimal,437,"Issue with new h5py; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # update to h5py e.g. as: pip install h5py==3.0.0. import scanpy as sc. adata = sc.datasets.blobs(). sc.read(""foo.h5ad"").obs_names # names are bytes, not str. # Index([ b'0', b'1', b'2', b'3', b'4', b'5', b'6', b'7', b'8', ..., dtype='object', length=640). ```. When using `h5py==2.10.0`, it works as expected (i.e. the index type is str). The same happens for `.var_names` (I haven't check further). I'd recommend updating the requirements.txt oto `h5py<=2.10.0` for now. Related h5py issue: https://github.com/h5py/h5py/issues/1732. Also, I've encoutered this bug when coming up with example (seems unrelated):. ```python. import scanpy as sc. adata = sc.datasets.paul15(). sc.read('data/paul15/paul15.h5'). ```. The last line raises:. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-24-3d2f3a02bf09> in <module>. ----> 1 sc.read('data/paul15/paul15.h5'). ~/.miniconda3/envs/cellrank2/lib/python3.8/site-packages/scanpy/readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compression, **kwargs). 110 filename = Path(filename) # allow passing strings. 111 if is_valid_filename(filename):. --> 112 return _read(. 113 filename,. 114 backed=backed,. ~/.miniconda3/envs/cellrank2/lib/python3.8/site-packages/scanpy/readwrite.py in _read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compressi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1480
https://github.com/scverse/scanpy/issues/1480:1396,usability,input,input-,1396,"ion for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # update to h5py e.g. as: pip install h5py==3.0.0. import scanpy as sc. adata = sc.datasets.blobs(). sc.read(""foo.h5ad"").obs_names # names are bytes, not str. # Index([ b'0', b'1', b'2', b'3', b'4', b'5', b'6', b'7', b'8', ..., dtype='object', length=640). ```. When using `h5py==2.10.0`, it works as expected (i.e. the index type is str). The same happens for `.var_names` (I haven't check further). I'd recommend updating the requirements.txt oto `h5py<=2.10.0` for now. Related h5py issue: https://github.com/h5py/h5py/issues/1732. Also, I've encoutered this bug when coming up with example (seems unrelated):. ```python. import scanpy as sc. adata = sc.datasets.paul15(). sc.read('data/paul15/paul15.h5'). ```. The last line raises:. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-24-3d2f3a02bf09> in <module>. ----> 1 sc.read('data/paul15/paul15.h5'). ~/.miniconda3/envs/cellrank2/lib/python3.8/site-packages/scanpy/readwrite.py in read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compression, **kwargs). 110 filename = Path(filename) # allow passing strings. 111 if is_valid_filename(filename):. --> 112 return _read(. 113 filename,. 114 backed=backed,. ~/.miniconda3/envs/cellrank2/lib/python3.8/site-packages/scanpy/readwrite.py in _read(filename, backed, sheet, ext, delimiter, first_column_names, backup_url, cache, cache_compression, suppress_cache_warning, **kwargs). 698 if ext in {'h5', 'h5ad'}:. 699 if sheet is None:. --> 700 return read_h5ad(filename, backed=backed). 701 else:. 702 logg.debug(f'reading sheet {sheet} from file {filename}'). ~/.miniconda3/envs/cellrank2/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 427 _clean_uns(d) # backwards comp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1480
https://github.com/scverse/scanpy/issues/1480:3250,usability,progress,progressbar,3250," delimiter, first_column_names, backup_url, cache, cache_compression, suppress_cache_warning, **kwargs). 698 if ext in {'h5', 'h5ad'}:. 699 if sheet is None:. --> 700 return read_h5ad(filename, backed=backed). 701 else:. 702 logg.debug(f'reading sheet {sheet} from file {filename}'). ~/.miniconda3/envs/cellrank2/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 427 _clean_uns(d) # backwards compat. 428 . --> 429 return AnnData(**d). 430 . 431 . TypeError: __init__() got an unexpected keyword argument 'batch.names'. ```. #### Versions. <details>. -----. anndata 0.7.4. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. absl NA. anndata 0.7.4. autoreload NA. backcall 0.2.0. cellrank 1.0.0. cffi 1.14.3. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. docrep 0.3.1. future_fstrings NA. get_version 2.1. h5py 2.10.0. igraph 0.8.3. ipykernel 5.3.4. ipython_genutils 0.2.0. jax 0.2.5. jaxlib 0.1.56. jedi 0.17.2. joblib 0.17.0. kiwisolver 1.3.1. lapack NA. legacy_api_wrap 1.2. leidenalg 0.8.1. llvmlite 0.34.0. louvain 0.7.0. matplotlib 3.3.2. mpl_toolkits NA. natsort 7.0.1. numba 0.51.2. numexpr 2.7.1. numpy 1.19.4. opt_einsum v3.3.0. packaging 20.4. pandas 1.1.4. parso 0.7.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. progressbar 3.53.1. prompt_toolkit 3.0.8. psutil 5.7.3. ptyprocess 0.6.0. pygam 0.8.0. pygments 2.7.2. pyparsing 2.4.7. python_utils NA. pytz 2020.4. scanpy 1.6.0. scipy 1.5.3. scvelo 0.2.2. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. sphinxcontrib NA. storemagic NA. tables 3.6.1. texttable 1.6.3. threadpoolctl 2.1.0. tornado 6.1. traitlets 5.0.5. wcwidth 0.2.5. wrapt 1.12.1. zmq 19.0.2. -----. IPython 7.19.0. jupyter_client 6.1.7. jupyter_core 4.6.3. notebook 6.1.4. -----. Python 3.8.5 (default, Sep 4 2020, 07:30:14) [GCC 7.3.0]. Linux-5.8.0-3-amd64-x86_64-with-glibc2.10. 8 logical CPU cores. -----. Session information updated at 2020-11-03 13:36. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1480
https://github.com/scverse/scanpy/issues/1481:593,availability,error,error,593,Hashsolo pre_existing_cluster argument doesn't work; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. ```pytb. [Paste the error output produced by the above code here]. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1481
https://github.com/scverse/scanpy/issues/1481:174,deployability,version,version,174,Hashsolo pre_existing_cluster argument doesn't work; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. ```pytb. [Paste the error output produced by the above code here]. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1481
https://github.com/scverse/scanpy/issues/1481:650,deployability,Version,Versions,650,Hashsolo pre_existing_cluster argument doesn't work; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. ```pytb. [Paste the error output produced by the above code here]. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1481
https://github.com/scverse/scanpy/issues/1481:699,deployability,log,logging,699,Hashsolo pre_existing_cluster argument doesn't work; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. ```pytb. [Paste the error output produced by the above code here]. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1481
https://github.com/scverse/scanpy/issues/1481:174,integrability,version,version,174,Hashsolo pre_existing_cluster argument doesn't work; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. ```pytb. [Paste the error output produced by the above code here]. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1481
https://github.com/scverse/scanpy/issues/1481:650,integrability,Version,Versions,650,Hashsolo pre_existing_cluster argument doesn't work; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. ```pytb. [Paste the error output produced by the above code here]. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1481
https://github.com/scverse/scanpy/issues/1481:174,modifiability,version,version,174,Hashsolo pre_existing_cluster argument doesn't work; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. ```pytb. [Paste the error output produced by the above code here]. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1481
https://github.com/scverse/scanpy/issues/1481:650,modifiability,Version,Versions,650,Hashsolo pre_existing_cluster argument doesn't work; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. ```pytb. [Paste the error output produced by the above code here]. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1481
https://github.com/scverse/scanpy/issues/1481:593,performance,error,error,593,Hashsolo pre_existing_cluster argument doesn't work; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. ```pytb. [Paste the error output produced by the above code here]. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1481
https://github.com/scverse/scanpy/issues/1481:39,reliability,doe,doesn,39,Hashsolo pre_existing_cluster argument doesn't work; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. ```pytb. [Paste the error output produced by the above code here]. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1481
https://github.com/scverse/scanpy/issues/1481:593,safety,error,error,593,Hashsolo pre_existing_cluster argument doesn't work; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. ```pytb. [Paste the error output produced by the above code here]. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1481
https://github.com/scverse/scanpy/issues/1481:699,safety,log,logging,699,Hashsolo pre_existing_cluster argument doesn't work; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. ```pytb. [Paste the error output produced by the above code here]. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1481
https://github.com/scverse/scanpy/issues/1481:0,security,Hash,Hashsolo,0,Hashsolo pre_existing_cluster argument doesn't work; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. ```pytb. [Paste the error output produced by the above code here]. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1481
https://github.com/scverse/scanpy/issues/1481:699,security,log,logging,699,Hashsolo pre_existing_cluster argument doesn't work; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. ```pytb. [Paste the error output produced by the above code here]. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1481
https://github.com/scverse/scanpy/issues/1481:699,testability,log,logging,699,Hashsolo pre_existing_cluster argument doesn't work; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. ```pytb. [Paste the error output produced by the above code here]. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1481
https://github.com/scverse/scanpy/issues/1481:134,usability,confirm,confirmed,134,Hashsolo pre_existing_cluster argument doesn't work; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. ```pytb. [Paste the error output produced by the above code here]. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1481
https://github.com/scverse/scanpy/issues/1481:217,usability,confirm,confirmed,217,Hashsolo pre_existing_cluster argument doesn't work; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. ```pytb. [Paste the error output produced by the above code here]. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1481
https://github.com/scverse/scanpy/issues/1481:308,usability,guid,guide,308,Hashsolo pre_existing_cluster argument doesn't work; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. ```pytb. [Paste the error output produced by the above code here]. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1481
https://github.com/scverse/scanpy/issues/1481:363,usability,minim,minimal-bug-reports,363,Hashsolo pre_existing_cluster argument doesn't work; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. ```pytb. [Paste the error output produced by the above code here]. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1481
https://github.com/scverse/scanpy/issues/1481:469,usability,Minim,Minimal,469,Hashsolo pre_existing_cluster argument doesn't work; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. ```pytb. [Paste the error output produced by the above code here]. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1481
https://github.com/scverse/scanpy/issues/1481:593,usability,error,error,593,Hashsolo pre_existing_cluster argument doesn't work; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. ```pytb. [Paste the error output produced by the above code here]. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1481
https://github.com/scverse/scanpy/issues/1482:179,deployability,version,version,179,"pre_existing_clusters argument for hashsolo doesn't work; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. pre_existing_clusters argument doesn't work. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. ```pytb. KeyError Traceback (most recent call last). <ipython-input-207-326a4b3ee327> in <module>(). 1 sce.pp.hashsolo(adata, sample_to_column.keys(),. 2 number_of_noise_barcodes=1, pre_existing_clusters='leiden',. ----> 3 priors = [0.01, 0.6, 0.39],). /home/nicholas/repos/scanpy/scanpy/external/pp/_hashsolo.py in hashsolo(cell_hashing_adata, cell_hashing_columns, priors, pre_existing_clusters, clustering_data, resolutions, number_of_noise_barcodes, inplace). 249 unique_cluster_features = np.unique(cell_hashing_adata.obs[cluster_features]). 250 for cluster_feature in unique_cluster_features:. --> 251 cluster_feature_bool_vector = cell_hashing_adata.obs[cluster_features == cluster_feature]```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1482
https://github.com/scverse/scanpy/issues/1482:713,deployability,modul,module,713,"pre_existing_clusters argument for hashsolo doesn't work; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. pre_existing_clusters argument doesn't work. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. ```pytb. KeyError Traceback (most recent call last). <ipython-input-207-326a4b3ee327> in <module>(). 1 sce.pp.hashsolo(adata, sample_to_column.keys(),. 2 number_of_noise_barcodes=1, pre_existing_clusters='leiden',. ----> 3 priors = [0.01, 0.6, 0.39],). /home/nicholas/repos/scanpy/scanpy/external/pp/_hashsolo.py in hashsolo(cell_hashing_adata, cell_hashing_columns, priors, pre_existing_clusters, clustering_data, resolutions, number_of_noise_barcodes, inplace). 249 unique_cluster_features = np.unique(cell_hashing_adata.obs[cluster_features]). 250 for cluster_feature in unique_cluster_features:. --> 251 cluster_feature_bool_vector = cell_hashing_adata.obs[cluster_features == cluster_feature]```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1482
https://github.com/scverse/scanpy/issues/1482:1330,deployability,Version,Versions,1330,"pre_existing_clusters argument for hashsolo doesn't work; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. pre_existing_clusters argument doesn't work. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. ```pytb. KeyError Traceback (most recent call last). <ipython-input-207-326a4b3ee327> in <module>(). 1 sce.pp.hashsolo(adata, sample_to_column.keys(),. 2 number_of_noise_barcodes=1, pre_existing_clusters='leiden',. ----> 3 priors = [0.01, 0.6, 0.39],). /home/nicholas/repos/scanpy/scanpy/external/pp/_hashsolo.py in hashsolo(cell_hashing_adata, cell_hashing_columns, priors, pre_existing_clusters, clustering_data, resolutions, number_of_noise_barcodes, inplace). 249 unique_cluster_features = np.unique(cell_hashing_adata.obs[cluster_features]). 250 for cluster_feature in unique_cluster_features:. --> 251 cluster_feature_bool_vector = cell_hashing_adata.obs[cluster_features == cluster_feature]```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1482
https://github.com/scverse/scanpy/issues/1482:1379,deployability,log,logging,1379,"pre_existing_clusters argument for hashsolo doesn't work; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. pre_existing_clusters argument doesn't work. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. ```pytb. KeyError Traceback (most recent call last). <ipython-input-207-326a4b3ee327> in <module>(). 1 sce.pp.hashsolo(adata, sample_to_column.keys(),. 2 number_of_noise_barcodes=1, pre_existing_clusters='leiden',. ----> 3 priors = [0.01, 0.6, 0.39],). /home/nicholas/repos/scanpy/scanpy/external/pp/_hashsolo.py in hashsolo(cell_hashing_adata, cell_hashing_columns, priors, pre_existing_clusters, clustering_data, resolutions, number_of_noise_barcodes, inplace). 249 unique_cluster_features = np.unique(cell_hashing_adata.obs[cluster_features]). 250 for cluster_feature in unique_cluster_features:. --> 251 cluster_feature_bool_vector = cell_hashing_adata.obs[cluster_features == cluster_feature]```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1482
https://github.com/scverse/scanpy/issues/1482:179,integrability,version,version,179,"pre_existing_clusters argument for hashsolo doesn't work; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. pre_existing_clusters argument doesn't work. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. ```pytb. KeyError Traceback (most recent call last). <ipython-input-207-326a4b3ee327> in <module>(). 1 sce.pp.hashsolo(adata, sample_to_column.keys(),. 2 number_of_noise_barcodes=1, pre_existing_clusters='leiden',. ----> 3 priors = [0.01, 0.6, 0.39],). /home/nicholas/repos/scanpy/scanpy/external/pp/_hashsolo.py in hashsolo(cell_hashing_adata, cell_hashing_columns, priors, pre_existing_clusters, clustering_data, resolutions, number_of_noise_barcodes, inplace). 249 unique_cluster_features = np.unique(cell_hashing_adata.obs[cluster_features]). 250 for cluster_feature in unique_cluster_features:. --> 251 cluster_feature_bool_vector = cell_hashing_adata.obs[cluster_features == cluster_feature]```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1482
https://github.com/scverse/scanpy/issues/1482:1330,integrability,Version,Versions,1330,"pre_existing_clusters argument for hashsolo doesn't work; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. pre_existing_clusters argument doesn't work. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. ```pytb. KeyError Traceback (most recent call last). <ipython-input-207-326a4b3ee327> in <module>(). 1 sce.pp.hashsolo(adata, sample_to_column.keys(),. 2 number_of_noise_barcodes=1, pre_existing_clusters='leiden',. ----> 3 priors = [0.01, 0.6, 0.39],). /home/nicholas/repos/scanpy/scanpy/external/pp/_hashsolo.py in hashsolo(cell_hashing_adata, cell_hashing_columns, priors, pre_existing_clusters, clustering_data, resolutions, number_of_noise_barcodes, inplace). 249 unique_cluster_features = np.unique(cell_hashing_adata.obs[cluster_features]). 250 for cluster_feature in unique_cluster_features:. --> 251 cluster_feature_bool_vector = cell_hashing_adata.obs[cluster_features == cluster_feature]```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1482
https://github.com/scverse/scanpy/issues/1482:179,modifiability,version,version,179,"pre_existing_clusters argument for hashsolo doesn't work; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. pre_existing_clusters argument doesn't work. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. ```pytb. KeyError Traceback (most recent call last). <ipython-input-207-326a4b3ee327> in <module>(). 1 sce.pp.hashsolo(adata, sample_to_column.keys(),. 2 number_of_noise_barcodes=1, pre_existing_clusters='leiden',. ----> 3 priors = [0.01, 0.6, 0.39],). /home/nicholas/repos/scanpy/scanpy/external/pp/_hashsolo.py in hashsolo(cell_hashing_adata, cell_hashing_columns, priors, pre_existing_clusters, clustering_data, resolutions, number_of_noise_barcodes, inplace). 249 unique_cluster_features = np.unique(cell_hashing_adata.obs[cluster_features]). 250 for cluster_feature in unique_cluster_features:. --> 251 cluster_feature_bool_vector = cell_hashing_adata.obs[cluster_features == cluster_feature]```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1482
https://github.com/scverse/scanpy/issues/1482:713,modifiability,modul,module,713,"pre_existing_clusters argument for hashsolo doesn't work; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. pre_existing_clusters argument doesn't work. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. ```pytb. KeyError Traceback (most recent call last). <ipython-input-207-326a4b3ee327> in <module>(). 1 sce.pp.hashsolo(adata, sample_to_column.keys(),. 2 number_of_noise_barcodes=1, pre_existing_clusters='leiden',. ----> 3 priors = [0.01, 0.6, 0.39],). /home/nicholas/repos/scanpy/scanpy/external/pp/_hashsolo.py in hashsolo(cell_hashing_adata, cell_hashing_columns, priors, pre_existing_clusters, clustering_data, resolutions, number_of_noise_barcodes, inplace). 249 unique_cluster_features = np.unique(cell_hashing_adata.obs[cluster_features]). 250 for cluster_feature in unique_cluster_features:. --> 251 cluster_feature_bool_vector = cell_hashing_adata.obs[cluster_features == cluster_feature]```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1482
https://github.com/scverse/scanpy/issues/1482:1330,modifiability,Version,Versions,1330,"pre_existing_clusters argument for hashsolo doesn't work; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. pre_existing_clusters argument doesn't work. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. ```pytb. KeyError Traceback (most recent call last). <ipython-input-207-326a4b3ee327> in <module>(). 1 sce.pp.hashsolo(adata, sample_to_column.keys(),. 2 number_of_noise_barcodes=1, pre_existing_clusters='leiden',. ----> 3 priors = [0.01, 0.6, 0.39],). /home/nicholas/repos/scanpy/scanpy/external/pp/_hashsolo.py in hashsolo(cell_hashing_adata, cell_hashing_columns, priors, pre_existing_clusters, clustering_data, resolutions, number_of_noise_barcodes, inplace). 249 unique_cluster_features = np.unique(cell_hashing_adata.obs[cluster_features]). 250 for cluster_feature in unique_cluster_features:. --> 251 cluster_feature_bool_vector = cell_hashing_adata.obs[cluster_features == cluster_feature]```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1482
https://github.com/scverse/scanpy/issues/1482:44,reliability,doe,doesn,44,"pre_existing_clusters argument for hashsolo doesn't work; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. pre_existing_clusters argument doesn't work. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. ```pytb. KeyError Traceback (most recent call last). <ipython-input-207-326a4b3ee327> in <module>(). 1 sce.pp.hashsolo(adata, sample_to_column.keys(),. 2 number_of_noise_barcodes=1, pre_existing_clusters='leiden',. ----> 3 priors = [0.01, 0.6, 0.39],). /home/nicholas/repos/scanpy/scanpy/external/pp/_hashsolo.py in hashsolo(cell_hashing_adata, cell_hashing_columns, priors, pre_existing_clusters, clustering_data, resolutions, number_of_noise_barcodes, inplace). 249 unique_cluster_features = np.unique(cell_hashing_adata.obs[cluster_features]). 250 for cluster_feature in unique_cluster_features:. --> 251 cluster_feature_bool_vector = cell_hashing_adata.obs[cluster_features == cluster_feature]```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1482
https://github.com/scverse/scanpy/issues/1482:501,reliability,doe,doesn,501,"pre_existing_clusters argument for hashsolo doesn't work; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. pre_existing_clusters argument doesn't work. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. ```pytb. KeyError Traceback (most recent call last). <ipython-input-207-326a4b3ee327> in <module>(). 1 sce.pp.hashsolo(adata, sample_to_column.keys(),. 2 number_of_noise_barcodes=1, pre_existing_clusters='leiden',. ----> 3 priors = [0.01, 0.6, 0.39],). /home/nicholas/repos/scanpy/scanpy/external/pp/_hashsolo.py in hashsolo(cell_hashing_adata, cell_hashing_columns, priors, pre_existing_clusters, clustering_data, resolutions, number_of_noise_barcodes, inplace). 249 unique_cluster_features = np.unique(cell_hashing_adata.obs[cluster_features]). 250 for cluster_feature in unique_cluster_features:. --> 251 cluster_feature_bool_vector = cell_hashing_adata.obs[cluster_features == cluster_feature]```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1482
https://github.com/scverse/scanpy/issues/1482:685,safety,input,input-,685,"pre_existing_clusters argument for hashsolo doesn't work; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. pre_existing_clusters argument doesn't work. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. ```pytb. KeyError Traceback (most recent call last). <ipython-input-207-326a4b3ee327> in <module>(). 1 sce.pp.hashsolo(adata, sample_to_column.keys(),. 2 number_of_noise_barcodes=1, pre_existing_clusters='leiden',. ----> 3 priors = [0.01, 0.6, 0.39],). /home/nicholas/repos/scanpy/scanpy/external/pp/_hashsolo.py in hashsolo(cell_hashing_adata, cell_hashing_columns, priors, pre_existing_clusters, clustering_data, resolutions, number_of_noise_barcodes, inplace). 249 unique_cluster_features = np.unique(cell_hashing_adata.obs[cluster_features]). 250 for cluster_feature in unique_cluster_features:. --> 251 cluster_feature_bool_vector = cell_hashing_adata.obs[cluster_features == cluster_feature]```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1482
https://github.com/scverse/scanpy/issues/1482:713,safety,modul,module,713,"pre_existing_clusters argument for hashsolo doesn't work; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. pre_existing_clusters argument doesn't work. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. ```pytb. KeyError Traceback (most recent call last). <ipython-input-207-326a4b3ee327> in <module>(). 1 sce.pp.hashsolo(adata, sample_to_column.keys(),. 2 number_of_noise_barcodes=1, pre_existing_clusters='leiden',. ----> 3 priors = [0.01, 0.6, 0.39],). /home/nicholas/repos/scanpy/scanpy/external/pp/_hashsolo.py in hashsolo(cell_hashing_adata, cell_hashing_columns, priors, pre_existing_clusters, clustering_data, resolutions, number_of_noise_barcodes, inplace). 249 unique_cluster_features = np.unique(cell_hashing_adata.obs[cluster_features]). 250 for cluster_feature in unique_cluster_features:. --> 251 cluster_feature_bool_vector = cell_hashing_adata.obs[cluster_features == cluster_feature]```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1482
https://github.com/scverse/scanpy/issues/1482:1379,safety,log,logging,1379,"pre_existing_clusters argument for hashsolo doesn't work; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. pre_existing_clusters argument doesn't work. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. ```pytb. KeyError Traceback (most recent call last). <ipython-input-207-326a4b3ee327> in <module>(). 1 sce.pp.hashsolo(adata, sample_to_column.keys(),. 2 number_of_noise_barcodes=1, pre_existing_clusters='leiden',. ----> 3 priors = [0.01, 0.6, 0.39],). /home/nicholas/repos/scanpy/scanpy/external/pp/_hashsolo.py in hashsolo(cell_hashing_adata, cell_hashing_columns, priors, pre_existing_clusters, clustering_data, resolutions, number_of_noise_barcodes, inplace). 249 unique_cluster_features = np.unique(cell_hashing_adata.obs[cluster_features]). 250 for cluster_feature in unique_cluster_features:. --> 251 cluster_feature_bool_vector = cell_hashing_adata.obs[cluster_features == cluster_feature]```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1482
https://github.com/scverse/scanpy/issues/1482:35,security,hash,hashsolo,35,"pre_existing_clusters argument for hashsolo doesn't work; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. pre_existing_clusters argument doesn't work. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. ```pytb. KeyError Traceback (most recent call last). <ipython-input-207-326a4b3ee327> in <module>(). 1 sce.pp.hashsolo(adata, sample_to_column.keys(),. 2 number_of_noise_barcodes=1, pre_existing_clusters='leiden',. ----> 3 priors = [0.01, 0.6, 0.39],). /home/nicholas/repos/scanpy/scanpy/external/pp/_hashsolo.py in hashsolo(cell_hashing_adata, cell_hashing_columns, priors, pre_existing_clusters, clustering_data, resolutions, number_of_noise_barcodes, inplace). 249 unique_cluster_features = np.unique(cell_hashing_adata.obs[cluster_features]). 250 for cluster_feature in unique_cluster_features:. --> 251 cluster_feature_bool_vector = cell_hashing_adata.obs[cluster_features == cluster_feature]```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1482
https://github.com/scverse/scanpy/issues/1482:733,security,hash,hashsolo,733,"pre_existing_clusters argument for hashsolo doesn't work; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. pre_existing_clusters argument doesn't work. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. ```pytb. KeyError Traceback (most recent call last). <ipython-input-207-326a4b3ee327> in <module>(). 1 sce.pp.hashsolo(adata, sample_to_column.keys(),. 2 number_of_noise_barcodes=1, pre_existing_clusters='leiden',. ----> 3 priors = [0.01, 0.6, 0.39],). /home/nicholas/repos/scanpy/scanpy/external/pp/_hashsolo.py in hashsolo(cell_hashing_adata, cell_hashing_columns, priors, pre_existing_clusters, clustering_data, resolutions, number_of_noise_barcodes, inplace). 249 unique_cluster_features = np.unique(cell_hashing_adata.obs[cluster_features]). 250 for cluster_feature in unique_cluster_features:. --> 251 cluster_feature_bool_vector = cell_hashing_adata.obs[cluster_features == cluster_feature]```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1482
https://github.com/scverse/scanpy/issues/1482:939,security,hash,hashsolo,939,"pre_existing_clusters argument for hashsolo doesn't work; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. pre_existing_clusters argument doesn't work. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. ```pytb. KeyError Traceback (most recent call last). <ipython-input-207-326a4b3ee327> in <module>(). 1 sce.pp.hashsolo(adata, sample_to_column.keys(),. 2 number_of_noise_barcodes=1, pre_existing_clusters='leiden',. ----> 3 priors = [0.01, 0.6, 0.39],). /home/nicholas/repos/scanpy/scanpy/external/pp/_hashsolo.py in hashsolo(cell_hashing_adata, cell_hashing_columns, priors, pre_existing_clusters, clustering_data, resolutions, number_of_noise_barcodes, inplace). 249 unique_cluster_features = np.unique(cell_hashing_adata.obs[cluster_features]). 250 for cluster_feature in unique_cluster_features:. --> 251 cluster_feature_bool_vector = cell_hashing_adata.obs[cluster_features == cluster_feature]```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1482
https://github.com/scverse/scanpy/issues/1482:1379,security,log,logging,1379,"pre_existing_clusters argument for hashsolo doesn't work; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. pre_existing_clusters argument doesn't work. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. ```pytb. KeyError Traceback (most recent call last). <ipython-input-207-326a4b3ee327> in <module>(). 1 sce.pp.hashsolo(adata, sample_to_column.keys(),. 2 number_of_noise_barcodes=1, pre_existing_clusters='leiden',. ----> 3 priors = [0.01, 0.6, 0.39],). /home/nicholas/repos/scanpy/scanpy/external/pp/_hashsolo.py in hashsolo(cell_hashing_adata, cell_hashing_columns, priors, pre_existing_clusters, clustering_data, resolutions, number_of_noise_barcodes, inplace). 249 unique_cluster_features = np.unique(cell_hashing_adata.obs[cluster_features]). 250 for cluster_feature in unique_cluster_features:. --> 251 cluster_feature_bool_vector = cell_hashing_adata.obs[cluster_features == cluster_feature]```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1482
https://github.com/scverse/scanpy/issues/1482:641,testability,Trace,Traceback,641,"pre_existing_clusters argument for hashsolo doesn't work; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. pre_existing_clusters argument doesn't work. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. ```pytb. KeyError Traceback (most recent call last). <ipython-input-207-326a4b3ee327> in <module>(). 1 sce.pp.hashsolo(adata, sample_to_column.keys(),. 2 number_of_noise_barcodes=1, pre_existing_clusters='leiden',. ----> 3 priors = [0.01, 0.6, 0.39],). /home/nicholas/repos/scanpy/scanpy/external/pp/_hashsolo.py in hashsolo(cell_hashing_adata, cell_hashing_columns, priors, pre_existing_clusters, clustering_data, resolutions, number_of_noise_barcodes, inplace). 249 unique_cluster_features = np.unique(cell_hashing_adata.obs[cluster_features]). 250 for cluster_feature in unique_cluster_features:. --> 251 cluster_feature_bool_vector = cell_hashing_adata.obs[cluster_features == cluster_feature]```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1482
https://github.com/scverse/scanpy/issues/1482:1379,testability,log,logging,1379,"pre_existing_clusters argument for hashsolo doesn't work; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. pre_existing_clusters argument doesn't work. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. ```pytb. KeyError Traceback (most recent call last). <ipython-input-207-326a4b3ee327> in <module>(). 1 sce.pp.hashsolo(adata, sample_to_column.keys(),. 2 number_of_noise_barcodes=1, pre_existing_clusters='leiden',. ----> 3 priors = [0.01, 0.6, 0.39],). /home/nicholas/repos/scanpy/scanpy/external/pp/_hashsolo.py in hashsolo(cell_hashing_adata, cell_hashing_columns, priors, pre_existing_clusters, clustering_data, resolutions, number_of_noise_barcodes, inplace). 249 unique_cluster_features = np.unique(cell_hashing_adata.obs[cluster_features]). 250 for cluster_feature in unique_cluster_features:. --> 251 cluster_feature_bool_vector = cell_hashing_adata.obs[cluster_features == cluster_feature]```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1482
https://github.com/scverse/scanpy/issues/1482:139,usability,confirm,confirmed,139,"pre_existing_clusters argument for hashsolo doesn't work; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. pre_existing_clusters argument doesn't work. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. ```pytb. KeyError Traceback (most recent call last). <ipython-input-207-326a4b3ee327> in <module>(). 1 sce.pp.hashsolo(adata, sample_to_column.keys(),. 2 number_of_noise_barcodes=1, pre_existing_clusters='leiden',. ----> 3 priors = [0.01, 0.6, 0.39],). /home/nicholas/repos/scanpy/scanpy/external/pp/_hashsolo.py in hashsolo(cell_hashing_adata, cell_hashing_columns, priors, pre_existing_clusters, clustering_data, resolutions, number_of_noise_barcodes, inplace). 249 unique_cluster_features = np.unique(cell_hashing_adata.obs[cluster_features]). 250 for cluster_feature in unique_cluster_features:. --> 251 cluster_feature_bool_vector = cell_hashing_adata.obs[cluster_features == cluster_feature]```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1482
https://github.com/scverse/scanpy/issues/1482:222,usability,confirm,confirmed,222,"pre_existing_clusters argument for hashsolo doesn't work; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. pre_existing_clusters argument doesn't work. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. ```pytb. KeyError Traceback (most recent call last). <ipython-input-207-326a4b3ee327> in <module>(). 1 sce.pp.hashsolo(adata, sample_to_column.keys(),. 2 number_of_noise_barcodes=1, pre_existing_clusters='leiden',. ----> 3 priors = [0.01, 0.6, 0.39],). /home/nicholas/repos/scanpy/scanpy/external/pp/_hashsolo.py in hashsolo(cell_hashing_adata, cell_hashing_columns, priors, pre_existing_clusters, clustering_data, resolutions, number_of_noise_barcodes, inplace). 249 unique_cluster_features = np.unique(cell_hashing_adata.obs[cluster_features]). 250 for cluster_feature in unique_cluster_features:. --> 251 cluster_feature_bool_vector = cell_hashing_adata.obs[cluster_features == cluster_feature]```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1482
https://github.com/scverse/scanpy/issues/1482:313,usability,guid,guide,313,"pre_existing_clusters argument for hashsolo doesn't work; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. pre_existing_clusters argument doesn't work. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. ```pytb. KeyError Traceback (most recent call last). <ipython-input-207-326a4b3ee327> in <module>(). 1 sce.pp.hashsolo(adata, sample_to_column.keys(),. 2 number_of_noise_barcodes=1, pre_existing_clusters='leiden',. ----> 3 priors = [0.01, 0.6, 0.39],). /home/nicholas/repos/scanpy/scanpy/external/pp/_hashsolo.py in hashsolo(cell_hashing_adata, cell_hashing_columns, priors, pre_existing_clusters, clustering_data, resolutions, number_of_noise_barcodes, inplace). 249 unique_cluster_features = np.unique(cell_hashing_adata.obs[cluster_features]). 250 for cluster_feature in unique_cluster_features:. --> 251 cluster_feature_bool_vector = cell_hashing_adata.obs[cluster_features == cluster_feature]```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1482
https://github.com/scverse/scanpy/issues/1482:368,usability,minim,minimal-bug-reports,368,"pre_existing_clusters argument for hashsolo doesn't work; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. pre_existing_clusters argument doesn't work. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. ```pytb. KeyError Traceback (most recent call last). <ipython-input-207-326a4b3ee327> in <module>(). 1 sce.pp.hashsolo(adata, sample_to_column.keys(),. 2 number_of_noise_barcodes=1, pre_existing_clusters='leiden',. ----> 3 priors = [0.01, 0.6, 0.39],). /home/nicholas/repos/scanpy/scanpy/external/pp/_hashsolo.py in hashsolo(cell_hashing_adata, cell_hashing_columns, priors, pre_existing_clusters, clustering_data, resolutions, number_of_noise_barcodes, inplace). 249 unique_cluster_features = np.unique(cell_hashing_adata.obs[cluster_features]). 250 for cluster_feature in unique_cluster_features:. --> 251 cluster_feature_bool_vector = cell_hashing_adata.obs[cluster_features == cluster_feature]```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1482
https://github.com/scverse/scanpy/issues/1482:519,usability,Minim,Minimal,519,"pre_existing_clusters argument for hashsolo doesn't work; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. pre_existing_clusters argument doesn't work. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. ```pytb. KeyError Traceback (most recent call last). <ipython-input-207-326a4b3ee327> in <module>(). 1 sce.pp.hashsolo(adata, sample_to_column.keys(),. 2 number_of_noise_barcodes=1, pre_existing_clusters='leiden',. ----> 3 priors = [0.01, 0.6, 0.39],). /home/nicholas/repos/scanpy/scanpy/external/pp/_hashsolo.py in hashsolo(cell_hashing_adata, cell_hashing_columns, priors, pre_existing_clusters, clustering_data, resolutions, number_of_noise_barcodes, inplace). 249 unique_cluster_features = np.unique(cell_hashing_adata.obs[cluster_features]). 250 for cluster_feature in unique_cluster_features:. --> 251 cluster_feature_bool_vector = cell_hashing_adata.obs[cluster_features == cluster_feature]```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1482
https://github.com/scverse/scanpy/issues/1482:685,usability,input,input-,685,"pre_existing_clusters argument for hashsolo doesn't work; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. pre_existing_clusters argument doesn't work. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. ```pytb. KeyError Traceback (most recent call last). <ipython-input-207-326a4b3ee327> in <module>(). 1 sce.pp.hashsolo(adata, sample_to_column.keys(),. 2 number_of_noise_barcodes=1, pre_existing_clusters='leiden',. ----> 3 priors = [0.01, 0.6, 0.39],). /home/nicholas/repos/scanpy/scanpy/external/pp/_hashsolo.py in hashsolo(cell_hashing_adata, cell_hashing_columns, priors, pre_existing_clusters, clustering_data, resolutions, number_of_noise_barcodes, inplace). 249 unique_cluster_features = np.unique(cell_hashing_adata.obs[cluster_features]). 250 for cluster_feature in unique_cluster_features:. --> 251 cluster_feature_bool_vector = cell_hashing_adata.obs[cluster_features == cluster_feature]```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1482
https://github.com/scverse/scanpy/pull/1483:10,security,hash,hashsolo,10,Addresses hashsolo pre_existing_cluster bugs; Also added a check to make sure the number of noise barcodes is less than the number of sample barcodes. Fixed the example in the doc string to include the cell_hashing_columns argument,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1483
https://github.com/scverse/scanpy/issues/1484:22,availability,error,error,22,"PR problem: docstring error; Hi! I'm having trouble getting the CI to pass on this PR: https://github.com/theislab/scanpy/pull/1476. This seems to be the issue:. ```. > raise SyntaxError(msg, (filename, lineno, 2, text)). E File ""/home/travis/build/theislab/scanpy/scanpy/external/pp/_scrublet.py"", line 9. E > <. E ^. E SyntaxError: Header of function `scanpy.external.pp._scrublet.scrub_doublets`s docstring should start with one-line description:. E . E """"""\. E My one-linedescription. E . E . E """""". scanpy/tests/test_docs.py:38: SyntaxError. ```. ... but the function does have that one-line description. . Would you be able to suggest to me what I'm doing wrong?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1484
https://github.com/scverse/scanpy/issues/1484:243,deployability,build,build,243,"PR problem: docstring error; Hi! I'm having trouble getting the CI to pass on this PR: https://github.com/theislab/scanpy/pull/1476. This seems to be the issue:. ```. > raise SyntaxError(msg, (filename, lineno, 2, text)). E File ""/home/travis/build/theislab/scanpy/scanpy/external/pp/_scrublet.py"", line 9. E > <. E ^. E SyntaxError: Header of function `scanpy.external.pp._scrublet.scrub_doublets`s docstring should start with one-line description:. E . E """"""\. E My one-linedescription. E . E . E """""". scanpy/tests/test_docs.py:38: SyntaxError. ```. ... but the function does have that one-line description. . Would you be able to suggest to me what I'm doing wrong?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1484
https://github.com/scverse/scanpy/issues/1484:22,performance,error,error,22,"PR problem: docstring error; Hi! I'm having trouble getting the CI to pass on this PR: https://github.com/theislab/scanpy/pull/1476. This seems to be the issue:. ```. > raise SyntaxError(msg, (filename, lineno, 2, text)). E File ""/home/travis/build/theislab/scanpy/scanpy/external/pp/_scrublet.py"", line 9. E > <. E ^. E SyntaxError: Header of function `scanpy.external.pp._scrublet.scrub_doublets`s docstring should start with one-line description:. E . E """"""\. E My one-linedescription. E . E . E """""". scanpy/tests/test_docs.py:38: SyntaxError. ```. ... but the function does have that one-line description. . Would you be able to suggest to me what I'm doing wrong?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1484
https://github.com/scverse/scanpy/issues/1484:592,reliability,doe,does,592,"PR problem: docstring error; Hi! I'm having trouble getting the CI to pass on this PR: https://github.com/theislab/scanpy/pull/1476. This seems to be the issue:. ```. > raise SyntaxError(msg, (filename, lineno, 2, text)). E File ""/home/travis/build/theislab/scanpy/scanpy/external/pp/_scrublet.py"", line 9. E > <. E ^. E SyntaxError: Header of function `scanpy.external.pp._scrublet.scrub_doublets`s docstring should start with one-line description:. E . E """"""\. E My one-linedescription. E . E . E """""". scanpy/tests/test_docs.py:38: SyntaxError. ```. ... but the function does have that one-line description. . Would you be able to suggest to me what I'm doing wrong?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1484
https://github.com/scverse/scanpy/issues/1484:22,safety,error,error,22,"PR problem: docstring error; Hi! I'm having trouble getting the CI to pass on this PR: https://github.com/theislab/scanpy/pull/1476. This seems to be the issue:. ```. > raise SyntaxError(msg, (filename, lineno, 2, text)). E File ""/home/travis/build/theislab/scanpy/scanpy/external/pp/_scrublet.py"", line 9. E > <. E ^. E SyntaxError: Header of function `scanpy.external.pp._scrublet.scrub_doublets`s docstring should start with one-line description:. E . E """"""\. E My one-linedescription. E . E . E """""". scanpy/tests/test_docs.py:38: SyntaxError. ```. ... but the function does have that one-line description. . Would you be able to suggest to me what I'm doing wrong?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1484
https://github.com/scverse/scanpy/issues/1484:530,safety,test,tests,530,"PR problem: docstring error; Hi! I'm having trouble getting the CI to pass on this PR: https://github.com/theislab/scanpy/pull/1476. This seems to be the issue:. ```. > raise SyntaxError(msg, (filename, lineno, 2, text)). E File ""/home/travis/build/theislab/scanpy/scanpy/external/pp/_scrublet.py"", line 9. E > <. E ^. E SyntaxError: Header of function `scanpy.external.pp._scrublet.scrub_doublets`s docstring should start with one-line description:. E . E """"""\. E My one-linedescription. E . E . E """""". scanpy/tests/test_docs.py:38: SyntaxError. ```. ... but the function does have that one-line description. . Would you be able to suggest to me what I'm doing wrong?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1484
https://github.com/scverse/scanpy/issues/1484:530,testability,test,tests,530,"PR problem: docstring error; Hi! I'm having trouble getting the CI to pass on this PR: https://github.com/theislab/scanpy/pull/1476. This seems to be the issue:. ```. > raise SyntaxError(msg, (filename, lineno, 2, text)). E File ""/home/travis/build/theislab/scanpy/scanpy/external/pp/_scrublet.py"", line 9. E > <. E ^. E SyntaxError: Header of function `scanpy.external.pp._scrublet.scrub_doublets`s docstring should start with one-line description:. E . E """"""\. E My one-linedescription. E . E . E """""". scanpy/tests/test_docs.py:38: SyntaxError. ```. ... but the function does have that one-line description. . Would you be able to suggest to me what I'm doing wrong?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1484
https://github.com/scverse/scanpy/issues/1484:22,usability,error,error,22,"PR problem: docstring error; Hi! I'm having trouble getting the CI to pass on this PR: https://github.com/theislab/scanpy/pull/1476. This seems to be the issue:. ```. > raise SyntaxError(msg, (filename, lineno, 2, text)). E File ""/home/travis/build/theislab/scanpy/scanpy/external/pp/_scrublet.py"", line 9. E > <. E ^. E SyntaxError: Header of function `scanpy.external.pp._scrublet.scrub_doublets`s docstring should start with one-line description:. E . E """"""\. E My one-linedescription. E . E . E """""". scanpy/tests/test_docs.py:38: SyntaxError. ```. ... but the function does have that one-line description. . Would you be able to suggest to me what I'm doing wrong?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1484
https://github.com/scverse/scanpy/issues/1485:178,deployability,version,version,178,"sc.tl.rank_genes_groups: reference argument is ignored; - [ x] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello,. I am having problems with the ```sc.tl.rank_genes_groups``` function. Specifically, I specify a reference level with ```reference = ``` argument but it is ignored. The table that this function produces in the ```.uns``` object indicates the reference as ```rest``` (the default) when I have indicated otherwise. . ```python. print(set(noncycling_adult.obs.class_1)). #{'krt', 'dendritic', 'eccrine', 'T-cell', 'mel'}. sc.tl.rank_genes_groups(noncycling_adult, groupby = 'class_1', groups = ['eccrine', 'krt', 'T-cell', 'dendritic'], reference = 'mel', method = 'wilcoxon'). print(full_adata.uns['rank_genes_groups']). """"""{'params': {'groupby': 'class_1', 'reference': 'rest', 'method': 'wilcoxon', 'use_raw': True, 'corr_method': 'benjamini-hochberg'}, 'scores': rec.array([(8.494621 ,), (8.326364 ,), (8.24139 ,), (7.382108 ,),. (7.340947 ,), (7.25889 ,), (7.2148457,), (7.0626616,),. (6.991276 ,), (6.952865 ,)],. dtype=[('T-cell', '<f4')]), 'names': rec.array([('IL32',), ('CD52',), ('CORO1A',), ('CD3D',), ('IL2RG',),. ('PTPRCAP',), ('RAC2',), ('CD2',), ('LTB',), ('S100A4',)],. dtype=[('T-cell', '<U50')]), 'logfoldchanges': rec.array([(10.175177 ,), (12.354224 ,), (11.05518 ,), (14.337216 ,),. (11.3317585,), ( 9.758805 ,), ( 8.825092 ,), (14.170704 ,),. (10.144425 ,), ( 5.6517367,)],. dtype=[('T-cell', '<f4')]), 'pvals': rec.array([(1.98579427e-17,), (8.33632215e-17,), (1.70221006e-16,),. (1.55802204e-13,), (2.12087430e-13,), (3.90279912e-13,),. (5.39952731e-13,), (1.63343167e-12,), (2.72397796e-12,),. (3.57940624e-12,)],. dtype=[('T-cell', '<f8')]), 'pvals_adj': rec.array([(4.86400449e-13,), (1.02094937e-12,), (1.38979777e-12,),. (9.54054799e-10,), (1.03897390e-09,), (1.59325269e-09,),. (1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1485
https://github.com/scverse/scanpy/issues/1485:1405,deployability,log,logfoldchanges,1405,"ps``` function. Specifically, I specify a reference level with ```reference = ``` argument but it is ignored. The table that this function produces in the ```.uns``` object indicates the reference as ```rest``` (the default) when I have indicated otherwise. . ```python. print(set(noncycling_adult.obs.class_1)). #{'krt', 'dendritic', 'eccrine', 'T-cell', 'mel'}. sc.tl.rank_genes_groups(noncycling_adult, groupby = 'class_1', groups = ['eccrine', 'krt', 'T-cell', 'dendritic'], reference = 'mel', method = 'wilcoxon'). print(full_adata.uns['rank_genes_groups']). """"""{'params': {'groupby': 'class_1', 'reference': 'rest', 'method': 'wilcoxon', 'use_raw': True, 'corr_method': 'benjamini-hochberg'}, 'scores': rec.array([(8.494621 ,), (8.326364 ,), (8.24139 ,), (7.382108 ,),. (7.340947 ,), (7.25889 ,), (7.2148457,), (7.0626616,),. (6.991276 ,), (6.952865 ,)],. dtype=[('T-cell', '<f4')]), 'names': rec.array([('IL32',), ('CD52',), ('CORO1A',), ('CD3D',), ('IL2RG',),. ('PTPRCAP',), ('RAC2',), ('CD2',), ('LTB',), ('S100A4',)],. dtype=[('T-cell', '<U50')]), 'logfoldchanges': rec.array([(10.175177 ,), (12.354224 ,), (11.05518 ,), (14.337216 ,),. (11.3317585,), ( 9.758805 ,), ( 8.825092 ,), (14.170704 ,),. (10.144425 ,), ( 5.6517367,)],. dtype=[('T-cell', '<f4')]), 'pvals': rec.array([(1.98579427e-17,), (8.33632215e-17,), (1.70221006e-16,),. (1.55802204e-13,), (2.12087430e-13,), (3.90279912e-13,),. (5.39952731e-13,), (1.63343167e-12,), (2.72397796e-12,),. (3.57940624e-12,)],. dtype=[('T-cell', '<f8')]), 'pvals_adj': rec.array([(4.86400449e-13,), (1.02094937e-12,), (1.38979777e-12,),. (9.54054799e-10,), (1.03897390e-09,), (1.59325269e-09,),. (1.88937174e-09,), (5.00115941e-09,), (7.41345735e-09,),. (8.76739764e-09,)],. dtype=[('T-cell', '<f8')])}. """""". ```. Thanks for your help. #### Versions. <details>. scanpy==1.4.4.post1 anndata==0.6.22.post1 umap==0.3.10 numpy==1.17.4 scipy==1.3.2 pandas==1.1.3 scikit-learn==0.22 statsmodels==0.12.0 python-igraph==0.7.1 louvain==0.6.1. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1485
https://github.com/scverse/scanpy/issues/1485:2142,deployability,Version,Versions,2142,"ps``` function. Specifically, I specify a reference level with ```reference = ``` argument but it is ignored. The table that this function produces in the ```.uns``` object indicates the reference as ```rest``` (the default) when I have indicated otherwise. . ```python. print(set(noncycling_adult.obs.class_1)). #{'krt', 'dendritic', 'eccrine', 'T-cell', 'mel'}. sc.tl.rank_genes_groups(noncycling_adult, groupby = 'class_1', groups = ['eccrine', 'krt', 'T-cell', 'dendritic'], reference = 'mel', method = 'wilcoxon'). print(full_adata.uns['rank_genes_groups']). """"""{'params': {'groupby': 'class_1', 'reference': 'rest', 'method': 'wilcoxon', 'use_raw': True, 'corr_method': 'benjamini-hochberg'}, 'scores': rec.array([(8.494621 ,), (8.326364 ,), (8.24139 ,), (7.382108 ,),. (7.340947 ,), (7.25889 ,), (7.2148457,), (7.0626616,),. (6.991276 ,), (6.952865 ,)],. dtype=[('T-cell', '<f4')]), 'names': rec.array([('IL32',), ('CD52',), ('CORO1A',), ('CD3D',), ('IL2RG',),. ('PTPRCAP',), ('RAC2',), ('CD2',), ('LTB',), ('S100A4',)],. dtype=[('T-cell', '<U50')]), 'logfoldchanges': rec.array([(10.175177 ,), (12.354224 ,), (11.05518 ,), (14.337216 ,),. (11.3317585,), ( 9.758805 ,), ( 8.825092 ,), (14.170704 ,),. (10.144425 ,), ( 5.6517367,)],. dtype=[('T-cell', '<f4')]), 'pvals': rec.array([(1.98579427e-17,), (8.33632215e-17,), (1.70221006e-16,),. (1.55802204e-13,), (2.12087430e-13,), (3.90279912e-13,),. (5.39952731e-13,), (1.63343167e-12,), (2.72397796e-12,),. (3.57940624e-12,)],. dtype=[('T-cell', '<f8')]), 'pvals_adj': rec.array([(4.86400449e-13,), (1.02094937e-12,), (1.38979777e-12,),. (9.54054799e-10,), (1.03897390e-09,), (1.59325269e-09,),. (1.88937174e-09,), (5.00115941e-09,), (7.41345735e-09,),. (8.76739764e-09,)],. dtype=[('T-cell', '<f8')])}. """""". ```. Thanks for your help. #### Versions. <details>. scanpy==1.4.4.post1 anndata==0.6.22.post1 umap==0.3.10 numpy==1.17.4 scipy==1.3.2 pandas==1.1.3 scikit-learn==0.22 statsmodels==0.12.0 python-igraph==0.7.1 louvain==0.6.1. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1485
https://github.com/scverse/scanpy/issues/1485:178,integrability,version,version,178,"sc.tl.rank_genes_groups: reference argument is ignored; - [ x] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello,. I am having problems with the ```sc.tl.rank_genes_groups``` function. Specifically, I specify a reference level with ```reference = ``` argument but it is ignored. The table that this function produces in the ```.uns``` object indicates the reference as ```rest``` (the default) when I have indicated otherwise. . ```python. print(set(noncycling_adult.obs.class_1)). #{'krt', 'dendritic', 'eccrine', 'T-cell', 'mel'}. sc.tl.rank_genes_groups(noncycling_adult, groupby = 'class_1', groups = ['eccrine', 'krt', 'T-cell', 'dendritic'], reference = 'mel', method = 'wilcoxon'). print(full_adata.uns['rank_genes_groups']). """"""{'params': {'groupby': 'class_1', 'reference': 'rest', 'method': 'wilcoxon', 'use_raw': True, 'corr_method': 'benjamini-hochberg'}, 'scores': rec.array([(8.494621 ,), (8.326364 ,), (8.24139 ,), (7.382108 ,),. (7.340947 ,), (7.25889 ,), (7.2148457,), (7.0626616,),. (6.991276 ,), (6.952865 ,)],. dtype=[('T-cell', '<f4')]), 'names': rec.array([('IL32',), ('CD52',), ('CORO1A',), ('CD3D',), ('IL2RG',),. ('PTPRCAP',), ('RAC2',), ('CD2',), ('LTB',), ('S100A4',)],. dtype=[('T-cell', '<U50')]), 'logfoldchanges': rec.array([(10.175177 ,), (12.354224 ,), (11.05518 ,), (14.337216 ,),. (11.3317585,), ( 9.758805 ,), ( 8.825092 ,), (14.170704 ,),. (10.144425 ,), ( 5.6517367,)],. dtype=[('T-cell', '<f4')]), 'pvals': rec.array([(1.98579427e-17,), (8.33632215e-17,), (1.70221006e-16,),. (1.55802204e-13,), (2.12087430e-13,), (3.90279912e-13,),. (5.39952731e-13,), (1.63343167e-12,), (2.72397796e-12,),. (3.57940624e-12,)],. dtype=[('T-cell', '<f8')]), 'pvals_adj': rec.array([(4.86400449e-13,), (1.02094937e-12,), (1.38979777e-12,),. (9.54054799e-10,), (1.03897390e-09,), (1.59325269e-09,),. (1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1485
https://github.com/scverse/scanpy/issues/1485:2142,integrability,Version,Versions,2142,"ps``` function. Specifically, I specify a reference level with ```reference = ``` argument but it is ignored. The table that this function produces in the ```.uns``` object indicates the reference as ```rest``` (the default) when I have indicated otherwise. . ```python. print(set(noncycling_adult.obs.class_1)). #{'krt', 'dendritic', 'eccrine', 'T-cell', 'mel'}. sc.tl.rank_genes_groups(noncycling_adult, groupby = 'class_1', groups = ['eccrine', 'krt', 'T-cell', 'dendritic'], reference = 'mel', method = 'wilcoxon'). print(full_adata.uns['rank_genes_groups']). """"""{'params': {'groupby': 'class_1', 'reference': 'rest', 'method': 'wilcoxon', 'use_raw': True, 'corr_method': 'benjamini-hochberg'}, 'scores': rec.array([(8.494621 ,), (8.326364 ,), (8.24139 ,), (7.382108 ,),. (7.340947 ,), (7.25889 ,), (7.2148457,), (7.0626616,),. (6.991276 ,), (6.952865 ,)],. dtype=[('T-cell', '<f4')]), 'names': rec.array([('IL32',), ('CD52',), ('CORO1A',), ('CD3D',), ('IL2RG',),. ('PTPRCAP',), ('RAC2',), ('CD2',), ('LTB',), ('S100A4',)],. dtype=[('T-cell', '<U50')]), 'logfoldchanges': rec.array([(10.175177 ,), (12.354224 ,), (11.05518 ,), (14.337216 ,),. (11.3317585,), ( 9.758805 ,), ( 8.825092 ,), (14.170704 ,),. (10.144425 ,), ( 5.6517367,)],. dtype=[('T-cell', '<f4')]), 'pvals': rec.array([(1.98579427e-17,), (8.33632215e-17,), (1.70221006e-16,),. (1.55802204e-13,), (2.12087430e-13,), (3.90279912e-13,),. (5.39952731e-13,), (1.63343167e-12,), (2.72397796e-12,),. (3.57940624e-12,)],. dtype=[('T-cell', '<f8')]), 'pvals_adj': rec.array([(4.86400449e-13,), (1.02094937e-12,), (1.38979777e-12,),. (9.54054799e-10,), (1.03897390e-09,), (1.59325269e-09,),. (1.88937174e-09,), (5.00115941e-09,), (7.41345735e-09,),. (8.76739764e-09,)],. dtype=[('T-cell', '<f8')])}. """""". ```. Thanks for your help. #### Versions. <details>. scanpy==1.4.4.post1 anndata==0.6.22.post1 umap==0.3.10 numpy==1.17.4 scipy==1.3.2 pandas==1.1.3 scikit-learn==0.22 statsmodels==0.12.0 python-igraph==0.7.1 louvain==0.6.1. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1485
https://github.com/scverse/scanpy/issues/1485:362,interoperability,Specif,Specifically,362,"sc.tl.rank_genes_groups: reference argument is ignored; - [ x] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello,. I am having problems with the ```sc.tl.rank_genes_groups``` function. Specifically, I specify a reference level with ```reference = ``` argument but it is ignored. The table that this function produces in the ```.uns``` object indicates the reference as ```rest``` (the default) when I have indicated otherwise. . ```python. print(set(noncycling_adult.obs.class_1)). #{'krt', 'dendritic', 'eccrine', 'T-cell', 'mel'}. sc.tl.rank_genes_groups(noncycling_adult, groupby = 'class_1', groups = ['eccrine', 'krt', 'T-cell', 'dendritic'], reference = 'mel', method = 'wilcoxon'). print(full_adata.uns['rank_genes_groups']). """"""{'params': {'groupby': 'class_1', 'reference': 'rest', 'method': 'wilcoxon', 'use_raw': True, 'corr_method': 'benjamini-hochberg'}, 'scores': rec.array([(8.494621 ,), (8.326364 ,), (8.24139 ,), (7.382108 ,),. (7.340947 ,), (7.25889 ,), (7.2148457,), (7.0626616,),. (6.991276 ,), (6.952865 ,)],. dtype=[('T-cell', '<f4')]), 'names': rec.array([('IL32',), ('CD52',), ('CORO1A',), ('CD3D',), ('IL2RG',),. ('PTPRCAP',), ('RAC2',), ('CD2',), ('LTB',), ('S100A4',)],. dtype=[('T-cell', '<U50')]), 'logfoldchanges': rec.array([(10.175177 ,), (12.354224 ,), (11.05518 ,), (14.337216 ,),. (11.3317585,), ( 9.758805 ,), ( 8.825092 ,), (14.170704 ,),. (10.144425 ,), ( 5.6517367,)],. dtype=[('T-cell', '<f4')]), 'pvals': rec.array([(1.98579427e-17,), (8.33632215e-17,), (1.70221006e-16,),. (1.55802204e-13,), (2.12087430e-13,), (3.90279912e-13,),. (5.39952731e-13,), (1.63343167e-12,), (2.72397796e-12,),. (3.57940624e-12,)],. dtype=[('T-cell', '<f8')]), 'pvals_adj': rec.array([(4.86400449e-13,), (1.02094937e-12,), (1.38979777e-12,),. (9.54054799e-10,), (1.03897390e-09,), (1.59325269e-09,),. (1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1485
https://github.com/scverse/scanpy/issues/1485:378,interoperability,specif,specify,378,"sc.tl.rank_genes_groups: reference argument is ignored; - [ x] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello,. I am having problems with the ```sc.tl.rank_genes_groups``` function. Specifically, I specify a reference level with ```reference = ``` argument but it is ignored. The table that this function produces in the ```.uns``` object indicates the reference as ```rest``` (the default) when I have indicated otherwise. . ```python. print(set(noncycling_adult.obs.class_1)). #{'krt', 'dendritic', 'eccrine', 'T-cell', 'mel'}. sc.tl.rank_genes_groups(noncycling_adult, groupby = 'class_1', groups = ['eccrine', 'krt', 'T-cell', 'dendritic'], reference = 'mel', method = 'wilcoxon'). print(full_adata.uns['rank_genes_groups']). """"""{'params': {'groupby': 'class_1', 'reference': 'rest', 'method': 'wilcoxon', 'use_raw': True, 'corr_method': 'benjamini-hochberg'}, 'scores': rec.array([(8.494621 ,), (8.326364 ,), (8.24139 ,), (7.382108 ,),. (7.340947 ,), (7.25889 ,), (7.2148457,), (7.0626616,),. (6.991276 ,), (6.952865 ,)],. dtype=[('T-cell', '<f4')]), 'names': rec.array([('IL32',), ('CD52',), ('CORO1A',), ('CD3D',), ('IL2RG',),. ('PTPRCAP',), ('RAC2',), ('CD2',), ('LTB',), ('S100A4',)],. dtype=[('T-cell', '<U50')]), 'logfoldchanges': rec.array([(10.175177 ,), (12.354224 ,), (11.05518 ,), (14.337216 ,),. (11.3317585,), ( 9.758805 ,), ( 8.825092 ,), (14.170704 ,),. (10.144425 ,), ( 5.6517367,)],. dtype=[('T-cell', '<f4')]), 'pvals': rec.array([(1.98579427e-17,), (8.33632215e-17,), (1.70221006e-16,),. (1.55802204e-13,), (2.12087430e-13,), (3.90279912e-13,),. (5.39952731e-13,), (1.63343167e-12,), (2.72397796e-12,),. (3.57940624e-12,)],. dtype=[('T-cell', '<f8')]), 'pvals_adj': rec.array([(4.86400449e-13,), (1.02094937e-12,), (1.38979777e-12,),. (9.54054799e-10,), (1.03897390e-09,), (1.59325269e-09,),. (1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1485
https://github.com/scverse/scanpy/issues/1485:178,modifiability,version,version,178,"sc.tl.rank_genes_groups: reference argument is ignored; - [ x] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello,. I am having problems with the ```sc.tl.rank_genes_groups``` function. Specifically, I specify a reference level with ```reference = ``` argument but it is ignored. The table that this function produces in the ```.uns``` object indicates the reference as ```rest``` (the default) when I have indicated otherwise. . ```python. print(set(noncycling_adult.obs.class_1)). #{'krt', 'dendritic', 'eccrine', 'T-cell', 'mel'}. sc.tl.rank_genes_groups(noncycling_adult, groupby = 'class_1', groups = ['eccrine', 'krt', 'T-cell', 'dendritic'], reference = 'mel', method = 'wilcoxon'). print(full_adata.uns['rank_genes_groups']). """"""{'params': {'groupby': 'class_1', 'reference': 'rest', 'method': 'wilcoxon', 'use_raw': True, 'corr_method': 'benjamini-hochberg'}, 'scores': rec.array([(8.494621 ,), (8.326364 ,), (8.24139 ,), (7.382108 ,),. (7.340947 ,), (7.25889 ,), (7.2148457,), (7.0626616,),. (6.991276 ,), (6.952865 ,)],. dtype=[('T-cell', '<f4')]), 'names': rec.array([('IL32',), ('CD52',), ('CORO1A',), ('CD3D',), ('IL2RG',),. ('PTPRCAP',), ('RAC2',), ('CD2',), ('LTB',), ('S100A4',)],. dtype=[('T-cell', '<U50')]), 'logfoldchanges': rec.array([(10.175177 ,), (12.354224 ,), (11.05518 ,), (14.337216 ,),. (11.3317585,), ( 9.758805 ,), ( 8.825092 ,), (14.170704 ,),. (10.144425 ,), ( 5.6517367,)],. dtype=[('T-cell', '<f4')]), 'pvals': rec.array([(1.98579427e-17,), (8.33632215e-17,), (1.70221006e-16,),. (1.55802204e-13,), (2.12087430e-13,), (3.90279912e-13,),. (5.39952731e-13,), (1.63343167e-12,), (2.72397796e-12,),. (3.57940624e-12,)],. dtype=[('T-cell', '<f8')]), 'pvals_adj': rec.array([(4.86400449e-13,), (1.02094937e-12,), (1.38979777e-12,),. (9.54054799e-10,), (1.03897390e-09,), (1.59325269e-09,),. (1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1485
https://github.com/scverse/scanpy/issues/1485:2142,modifiability,Version,Versions,2142,"ps``` function. Specifically, I specify a reference level with ```reference = ``` argument but it is ignored. The table that this function produces in the ```.uns``` object indicates the reference as ```rest``` (the default) when I have indicated otherwise. . ```python. print(set(noncycling_adult.obs.class_1)). #{'krt', 'dendritic', 'eccrine', 'T-cell', 'mel'}. sc.tl.rank_genes_groups(noncycling_adult, groupby = 'class_1', groups = ['eccrine', 'krt', 'T-cell', 'dendritic'], reference = 'mel', method = 'wilcoxon'). print(full_adata.uns['rank_genes_groups']). """"""{'params': {'groupby': 'class_1', 'reference': 'rest', 'method': 'wilcoxon', 'use_raw': True, 'corr_method': 'benjamini-hochberg'}, 'scores': rec.array([(8.494621 ,), (8.326364 ,), (8.24139 ,), (7.382108 ,),. (7.340947 ,), (7.25889 ,), (7.2148457,), (7.0626616,),. (6.991276 ,), (6.952865 ,)],. dtype=[('T-cell', '<f4')]), 'names': rec.array([('IL32',), ('CD52',), ('CORO1A',), ('CD3D',), ('IL2RG',),. ('PTPRCAP',), ('RAC2',), ('CD2',), ('LTB',), ('S100A4',)],. dtype=[('T-cell', '<U50')]), 'logfoldchanges': rec.array([(10.175177 ,), (12.354224 ,), (11.05518 ,), (14.337216 ,),. (11.3317585,), ( 9.758805 ,), ( 8.825092 ,), (14.170704 ,),. (10.144425 ,), ( 5.6517367,)],. dtype=[('T-cell', '<f4')]), 'pvals': rec.array([(1.98579427e-17,), (8.33632215e-17,), (1.70221006e-16,),. (1.55802204e-13,), (2.12087430e-13,), (3.90279912e-13,),. (5.39952731e-13,), (1.63343167e-12,), (2.72397796e-12,),. (3.57940624e-12,)],. dtype=[('T-cell', '<f8')]), 'pvals_adj': rec.array([(4.86400449e-13,), (1.02094937e-12,), (1.38979777e-12,),. (9.54054799e-10,), (1.03897390e-09,), (1.59325269e-09,),. (1.88937174e-09,), (5.00115941e-09,), (7.41345735e-09,),. (8.76739764e-09,)],. dtype=[('T-cell', '<f8')])}. """""". ```. Thanks for your help. #### Versions. <details>. scanpy==1.4.4.post1 anndata==0.6.22.post1 umap==0.3.10 numpy==1.17.4 scipy==1.3.2 pandas==1.1.3 scikit-learn==0.22 statsmodels==0.12.0 python-igraph==0.7.1 louvain==0.6.1. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1485
https://github.com/scverse/scanpy/issues/1485:1405,safety,log,logfoldchanges,1405,"ps``` function. Specifically, I specify a reference level with ```reference = ``` argument but it is ignored. The table that this function produces in the ```.uns``` object indicates the reference as ```rest``` (the default) when I have indicated otherwise. . ```python. print(set(noncycling_adult.obs.class_1)). #{'krt', 'dendritic', 'eccrine', 'T-cell', 'mel'}. sc.tl.rank_genes_groups(noncycling_adult, groupby = 'class_1', groups = ['eccrine', 'krt', 'T-cell', 'dendritic'], reference = 'mel', method = 'wilcoxon'). print(full_adata.uns['rank_genes_groups']). """"""{'params': {'groupby': 'class_1', 'reference': 'rest', 'method': 'wilcoxon', 'use_raw': True, 'corr_method': 'benjamini-hochberg'}, 'scores': rec.array([(8.494621 ,), (8.326364 ,), (8.24139 ,), (7.382108 ,),. (7.340947 ,), (7.25889 ,), (7.2148457,), (7.0626616,),. (6.991276 ,), (6.952865 ,)],. dtype=[('T-cell', '<f4')]), 'names': rec.array([('IL32',), ('CD52',), ('CORO1A',), ('CD3D',), ('IL2RG',),. ('PTPRCAP',), ('RAC2',), ('CD2',), ('LTB',), ('S100A4',)],. dtype=[('T-cell', '<U50')]), 'logfoldchanges': rec.array([(10.175177 ,), (12.354224 ,), (11.05518 ,), (14.337216 ,),. (11.3317585,), ( 9.758805 ,), ( 8.825092 ,), (14.170704 ,),. (10.144425 ,), ( 5.6517367,)],. dtype=[('T-cell', '<f4')]), 'pvals': rec.array([(1.98579427e-17,), (8.33632215e-17,), (1.70221006e-16,),. (1.55802204e-13,), (2.12087430e-13,), (3.90279912e-13,),. (5.39952731e-13,), (1.63343167e-12,), (2.72397796e-12,),. (3.57940624e-12,)],. dtype=[('T-cell', '<f8')]), 'pvals_adj': rec.array([(4.86400449e-13,), (1.02094937e-12,), (1.38979777e-12,),. (9.54054799e-10,), (1.03897390e-09,), (1.59325269e-09,),. (1.88937174e-09,), (5.00115941e-09,), (7.41345735e-09,),. (8.76739764e-09,)],. dtype=[('T-cell', '<f8')])}. """""". ```. Thanks for your help. #### Versions. <details>. scanpy==1.4.4.post1 anndata==0.6.22.post1 umap==0.3.10 numpy==1.17.4 scipy==1.3.2 pandas==1.1.3 scikit-learn==0.22 statsmodels==0.12.0 python-igraph==0.7.1 louvain==0.6.1. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1485
https://github.com/scverse/scanpy/issues/1485:1405,security,log,logfoldchanges,1405,"ps``` function. Specifically, I specify a reference level with ```reference = ``` argument but it is ignored. The table that this function produces in the ```.uns``` object indicates the reference as ```rest``` (the default) when I have indicated otherwise. . ```python. print(set(noncycling_adult.obs.class_1)). #{'krt', 'dendritic', 'eccrine', 'T-cell', 'mel'}. sc.tl.rank_genes_groups(noncycling_adult, groupby = 'class_1', groups = ['eccrine', 'krt', 'T-cell', 'dendritic'], reference = 'mel', method = 'wilcoxon'). print(full_adata.uns['rank_genes_groups']). """"""{'params': {'groupby': 'class_1', 'reference': 'rest', 'method': 'wilcoxon', 'use_raw': True, 'corr_method': 'benjamini-hochberg'}, 'scores': rec.array([(8.494621 ,), (8.326364 ,), (8.24139 ,), (7.382108 ,),. (7.340947 ,), (7.25889 ,), (7.2148457,), (7.0626616,),. (6.991276 ,), (6.952865 ,)],. dtype=[('T-cell', '<f4')]), 'names': rec.array([('IL32',), ('CD52',), ('CORO1A',), ('CD3D',), ('IL2RG',),. ('PTPRCAP',), ('RAC2',), ('CD2',), ('LTB',), ('S100A4',)],. dtype=[('T-cell', '<U50')]), 'logfoldchanges': rec.array([(10.175177 ,), (12.354224 ,), (11.05518 ,), (14.337216 ,),. (11.3317585,), ( 9.758805 ,), ( 8.825092 ,), (14.170704 ,),. (10.144425 ,), ( 5.6517367,)],. dtype=[('T-cell', '<f4')]), 'pvals': rec.array([(1.98579427e-17,), (8.33632215e-17,), (1.70221006e-16,),. (1.55802204e-13,), (2.12087430e-13,), (3.90279912e-13,),. (5.39952731e-13,), (1.63343167e-12,), (2.72397796e-12,),. (3.57940624e-12,)],. dtype=[('T-cell', '<f8')]), 'pvals_adj': rec.array([(4.86400449e-13,), (1.02094937e-12,), (1.38979777e-12,),. (9.54054799e-10,), (1.03897390e-09,), (1.59325269e-09,),. (1.88937174e-09,), (5.00115941e-09,), (7.41345735e-09,),. (8.76739764e-09,)],. dtype=[('T-cell', '<f8')])}. """""". ```. Thanks for your help. #### Versions. <details>. scanpy==1.4.4.post1 anndata==0.6.22.post1 umap==0.3.10 numpy==1.17.4 scipy==1.3.2 pandas==1.1.3 scikit-learn==0.22 statsmodels==0.12.0 python-igraph==0.7.1 louvain==0.6.1. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1485
https://github.com/scverse/scanpy/issues/1485:1405,testability,log,logfoldchanges,1405,"ps``` function. Specifically, I specify a reference level with ```reference = ``` argument but it is ignored. The table that this function produces in the ```.uns``` object indicates the reference as ```rest``` (the default) when I have indicated otherwise. . ```python. print(set(noncycling_adult.obs.class_1)). #{'krt', 'dendritic', 'eccrine', 'T-cell', 'mel'}. sc.tl.rank_genes_groups(noncycling_adult, groupby = 'class_1', groups = ['eccrine', 'krt', 'T-cell', 'dendritic'], reference = 'mel', method = 'wilcoxon'). print(full_adata.uns['rank_genes_groups']). """"""{'params': {'groupby': 'class_1', 'reference': 'rest', 'method': 'wilcoxon', 'use_raw': True, 'corr_method': 'benjamini-hochberg'}, 'scores': rec.array([(8.494621 ,), (8.326364 ,), (8.24139 ,), (7.382108 ,),. (7.340947 ,), (7.25889 ,), (7.2148457,), (7.0626616,),. (6.991276 ,), (6.952865 ,)],. dtype=[('T-cell', '<f4')]), 'names': rec.array([('IL32',), ('CD52',), ('CORO1A',), ('CD3D',), ('IL2RG',),. ('PTPRCAP',), ('RAC2',), ('CD2',), ('LTB',), ('S100A4',)],. dtype=[('T-cell', '<U50')]), 'logfoldchanges': rec.array([(10.175177 ,), (12.354224 ,), (11.05518 ,), (14.337216 ,),. (11.3317585,), ( 9.758805 ,), ( 8.825092 ,), (14.170704 ,),. (10.144425 ,), ( 5.6517367,)],. dtype=[('T-cell', '<f4')]), 'pvals': rec.array([(1.98579427e-17,), (8.33632215e-17,), (1.70221006e-16,),. (1.55802204e-13,), (2.12087430e-13,), (3.90279912e-13,),. (5.39952731e-13,), (1.63343167e-12,), (2.72397796e-12,),. (3.57940624e-12,)],. dtype=[('T-cell', '<f8')]), 'pvals_adj': rec.array([(4.86400449e-13,), (1.02094937e-12,), (1.38979777e-12,),. (9.54054799e-10,), (1.03897390e-09,), (1.59325269e-09,),. (1.88937174e-09,), (5.00115941e-09,), (7.41345735e-09,),. (8.76739764e-09,)],. dtype=[('T-cell', '<f8')])}. """""". ```. Thanks for your help. #### Versions. <details>. scanpy==1.4.4.post1 anndata==0.6.22.post1 umap==0.3.10 numpy==1.17.4 scipy==1.3.2 pandas==1.1.3 scikit-learn==0.22 statsmodels==0.12.0 python-igraph==0.7.1 louvain==0.6.1. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1485
https://github.com/scverse/scanpy/issues/1485:138,usability,confirm,confirmed,138,"sc.tl.rank_genes_groups: reference argument is ignored; - [ x] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello,. I am having problems with the ```sc.tl.rank_genes_groups``` function. Specifically, I specify a reference level with ```reference = ``` argument but it is ignored. The table that this function produces in the ```.uns``` object indicates the reference as ```rest``` (the default) when I have indicated otherwise. . ```python. print(set(noncycling_adult.obs.class_1)). #{'krt', 'dendritic', 'eccrine', 'T-cell', 'mel'}. sc.tl.rank_genes_groups(noncycling_adult, groupby = 'class_1', groups = ['eccrine', 'krt', 'T-cell', 'dendritic'], reference = 'mel', method = 'wilcoxon'). print(full_adata.uns['rank_genes_groups']). """"""{'params': {'groupby': 'class_1', 'reference': 'rest', 'method': 'wilcoxon', 'use_raw': True, 'corr_method': 'benjamini-hochberg'}, 'scores': rec.array([(8.494621 ,), (8.326364 ,), (8.24139 ,), (7.382108 ,),. (7.340947 ,), (7.25889 ,), (7.2148457,), (7.0626616,),. (6.991276 ,), (6.952865 ,)],. dtype=[('T-cell', '<f4')]), 'names': rec.array([('IL32',), ('CD52',), ('CORO1A',), ('CD3D',), ('IL2RG',),. ('PTPRCAP',), ('RAC2',), ('CD2',), ('LTB',), ('S100A4',)],. dtype=[('T-cell', '<U50')]), 'logfoldchanges': rec.array([(10.175177 ,), (12.354224 ,), (11.05518 ,), (14.337216 ,),. (11.3317585,), ( 9.758805 ,), ( 8.825092 ,), (14.170704 ,),. (10.144425 ,), ( 5.6517367,)],. dtype=[('T-cell', '<f4')]), 'pvals': rec.array([(1.98579427e-17,), (8.33632215e-17,), (1.70221006e-16,),. (1.55802204e-13,), (2.12087430e-13,), (3.90279912e-13,),. (5.39952731e-13,), (1.63343167e-12,), (2.72397796e-12,),. (3.57940624e-12,)],. dtype=[('T-cell', '<f8')]), 'pvals_adj': rec.array([(4.86400449e-13,), (1.02094937e-12,), (1.38979777e-12,),. (9.54054799e-10,), (1.03897390e-09,), (1.59325269e-09,),. (1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1485
https://github.com/scverse/scanpy/issues/1485:221,usability,confirm,confirmed,221,"sc.tl.rank_genes_groups: reference argument is ignored; - [ x] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello,. I am having problems with the ```sc.tl.rank_genes_groups``` function. Specifically, I specify a reference level with ```reference = ``` argument but it is ignored. The table that this function produces in the ```.uns``` object indicates the reference as ```rest``` (the default) when I have indicated otherwise. . ```python. print(set(noncycling_adult.obs.class_1)). #{'krt', 'dendritic', 'eccrine', 'T-cell', 'mel'}. sc.tl.rank_genes_groups(noncycling_adult, groupby = 'class_1', groups = ['eccrine', 'krt', 'T-cell', 'dendritic'], reference = 'mel', method = 'wilcoxon'). print(full_adata.uns['rank_genes_groups']). """"""{'params': {'groupby': 'class_1', 'reference': 'rest', 'method': 'wilcoxon', 'use_raw': True, 'corr_method': 'benjamini-hochberg'}, 'scores': rec.array([(8.494621 ,), (8.326364 ,), (8.24139 ,), (7.382108 ,),. (7.340947 ,), (7.25889 ,), (7.2148457,), (7.0626616,),. (6.991276 ,), (6.952865 ,)],. dtype=[('T-cell', '<f4')]), 'names': rec.array([('IL32',), ('CD52',), ('CORO1A',), ('CD3D',), ('IL2RG',),. ('PTPRCAP',), ('RAC2',), ('CD2',), ('LTB',), ('S100A4',)],. dtype=[('T-cell', '<U50')]), 'logfoldchanges': rec.array([(10.175177 ,), (12.354224 ,), (11.05518 ,), (14.337216 ,),. (11.3317585,), ( 9.758805 ,), ( 8.825092 ,), (14.170704 ,),. (10.144425 ,), ( 5.6517367,)],. dtype=[('T-cell', '<f4')]), 'pvals': rec.array([(1.98579427e-17,), (8.33632215e-17,), (1.70221006e-16,),. (1.55802204e-13,), (2.12087430e-13,), (3.90279912e-13,),. (5.39952731e-13,), (1.63343167e-12,), (2.72397796e-12,),. (3.57940624e-12,)],. dtype=[('T-cell', '<f8')]), 'pvals_adj': rec.array([(4.86400449e-13,), (1.02094937e-12,), (1.38979777e-12,),. (9.54054799e-10,), (1.03897390e-09,), (1.59325269e-09,),. (1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1485
https://github.com/scverse/scanpy/issues/1485:519,usability,indicat,indicates,519,"sc.tl.rank_genes_groups: reference argument is ignored; - [ x] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello,. I am having problems with the ```sc.tl.rank_genes_groups``` function. Specifically, I specify a reference level with ```reference = ``` argument but it is ignored. The table that this function produces in the ```.uns``` object indicates the reference as ```rest``` (the default) when I have indicated otherwise. . ```python. print(set(noncycling_adult.obs.class_1)). #{'krt', 'dendritic', 'eccrine', 'T-cell', 'mel'}. sc.tl.rank_genes_groups(noncycling_adult, groupby = 'class_1', groups = ['eccrine', 'krt', 'T-cell', 'dendritic'], reference = 'mel', method = 'wilcoxon'). print(full_adata.uns['rank_genes_groups']). """"""{'params': {'groupby': 'class_1', 'reference': 'rest', 'method': 'wilcoxon', 'use_raw': True, 'corr_method': 'benjamini-hochberg'}, 'scores': rec.array([(8.494621 ,), (8.326364 ,), (8.24139 ,), (7.382108 ,),. (7.340947 ,), (7.25889 ,), (7.2148457,), (7.0626616,),. (6.991276 ,), (6.952865 ,)],. dtype=[('T-cell', '<f4')]), 'names': rec.array([('IL32',), ('CD52',), ('CORO1A',), ('CD3D',), ('IL2RG',),. ('PTPRCAP',), ('RAC2',), ('CD2',), ('LTB',), ('S100A4',)],. dtype=[('T-cell', '<U50')]), 'logfoldchanges': rec.array([(10.175177 ,), (12.354224 ,), (11.05518 ,), (14.337216 ,),. (11.3317585,), ( 9.758805 ,), ( 8.825092 ,), (14.170704 ,),. (10.144425 ,), ( 5.6517367,)],. dtype=[('T-cell', '<f4')]), 'pvals': rec.array([(1.98579427e-17,), (8.33632215e-17,), (1.70221006e-16,),. (1.55802204e-13,), (2.12087430e-13,), (3.90279912e-13,),. (5.39952731e-13,), (1.63343167e-12,), (2.72397796e-12,),. (3.57940624e-12,)],. dtype=[('T-cell', '<f8')]), 'pvals_adj': rec.array([(4.86400449e-13,), (1.02094937e-12,), (1.38979777e-12,),. (9.54054799e-10,), (1.03897390e-09,), (1.59325269e-09,),. (1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1485
https://github.com/scverse/scanpy/issues/1485:583,usability,indicat,indicated,583,"sc.tl.rank_genes_groups: reference argument is ignored; - [ x] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello,. I am having problems with the ```sc.tl.rank_genes_groups``` function. Specifically, I specify a reference level with ```reference = ``` argument but it is ignored. The table that this function produces in the ```.uns``` object indicates the reference as ```rest``` (the default) when I have indicated otherwise. . ```python. print(set(noncycling_adult.obs.class_1)). #{'krt', 'dendritic', 'eccrine', 'T-cell', 'mel'}. sc.tl.rank_genes_groups(noncycling_adult, groupby = 'class_1', groups = ['eccrine', 'krt', 'T-cell', 'dendritic'], reference = 'mel', method = 'wilcoxon'). print(full_adata.uns['rank_genes_groups']). """"""{'params': {'groupby': 'class_1', 'reference': 'rest', 'method': 'wilcoxon', 'use_raw': True, 'corr_method': 'benjamini-hochberg'}, 'scores': rec.array([(8.494621 ,), (8.326364 ,), (8.24139 ,), (7.382108 ,),. (7.340947 ,), (7.25889 ,), (7.2148457,), (7.0626616,),. (6.991276 ,), (6.952865 ,)],. dtype=[('T-cell', '<f4')]), 'names': rec.array([('IL32',), ('CD52',), ('CORO1A',), ('CD3D',), ('IL2RG',),. ('PTPRCAP',), ('RAC2',), ('CD2',), ('LTB',), ('S100A4',)],. dtype=[('T-cell', '<U50')]), 'logfoldchanges': rec.array([(10.175177 ,), (12.354224 ,), (11.05518 ,), (14.337216 ,),. (11.3317585,), ( 9.758805 ,), ( 8.825092 ,), (14.170704 ,),. (10.144425 ,), ( 5.6517367,)],. dtype=[('T-cell', '<f4')]), 'pvals': rec.array([(1.98579427e-17,), (8.33632215e-17,), (1.70221006e-16,),. (1.55802204e-13,), (2.12087430e-13,), (3.90279912e-13,),. (5.39952731e-13,), (1.63343167e-12,), (2.72397796e-12,),. (3.57940624e-12,)],. dtype=[('T-cell', '<f8')]), 'pvals_adj': rec.array([(4.86400449e-13,), (1.02094937e-12,), (1.38979777e-12,),. (9.54054799e-10,), (1.03897390e-09,), (1.59325269e-09,),. (1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1485
https://github.com/scverse/scanpy/issues/1485:2131,usability,help,help,2131,"ps``` function. Specifically, I specify a reference level with ```reference = ``` argument but it is ignored. The table that this function produces in the ```.uns``` object indicates the reference as ```rest``` (the default) when I have indicated otherwise. . ```python. print(set(noncycling_adult.obs.class_1)). #{'krt', 'dendritic', 'eccrine', 'T-cell', 'mel'}. sc.tl.rank_genes_groups(noncycling_adult, groupby = 'class_1', groups = ['eccrine', 'krt', 'T-cell', 'dendritic'], reference = 'mel', method = 'wilcoxon'). print(full_adata.uns['rank_genes_groups']). """"""{'params': {'groupby': 'class_1', 'reference': 'rest', 'method': 'wilcoxon', 'use_raw': True, 'corr_method': 'benjamini-hochberg'}, 'scores': rec.array([(8.494621 ,), (8.326364 ,), (8.24139 ,), (7.382108 ,),. (7.340947 ,), (7.25889 ,), (7.2148457,), (7.0626616,),. (6.991276 ,), (6.952865 ,)],. dtype=[('T-cell', '<f4')]), 'names': rec.array([('IL32',), ('CD52',), ('CORO1A',), ('CD3D',), ('IL2RG',),. ('PTPRCAP',), ('RAC2',), ('CD2',), ('LTB',), ('S100A4',)],. dtype=[('T-cell', '<U50')]), 'logfoldchanges': rec.array([(10.175177 ,), (12.354224 ,), (11.05518 ,), (14.337216 ,),. (11.3317585,), ( 9.758805 ,), ( 8.825092 ,), (14.170704 ,),. (10.144425 ,), ( 5.6517367,)],. dtype=[('T-cell', '<f4')]), 'pvals': rec.array([(1.98579427e-17,), (8.33632215e-17,), (1.70221006e-16,),. (1.55802204e-13,), (2.12087430e-13,), (3.90279912e-13,),. (5.39952731e-13,), (1.63343167e-12,), (2.72397796e-12,),. (3.57940624e-12,)],. dtype=[('T-cell', '<f8')]), 'pvals_adj': rec.array([(4.86400449e-13,), (1.02094937e-12,), (1.38979777e-12,),. (9.54054799e-10,), (1.03897390e-09,), (1.59325269e-09,),. (1.88937174e-09,), (5.00115941e-09,), (7.41345735e-09,),. (8.76739764e-09,)],. dtype=[('T-cell', '<f8')])}. """""". ```. Thanks for your help. #### Versions. <details>. scanpy==1.4.4.post1 anndata==0.6.22.post1 umap==0.3.10 numpy==1.17.4 scipy==1.3.2 pandas==1.1.3 scikit-learn==0.22 statsmodels==0.12.0 python-igraph==0.7.1 louvain==0.6.1. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1485
https://github.com/scverse/scanpy/issues/1485:2266,usability,learn,learn,2266,"ps``` function. Specifically, I specify a reference level with ```reference = ``` argument but it is ignored. The table that this function produces in the ```.uns``` object indicates the reference as ```rest``` (the default) when I have indicated otherwise. . ```python. print(set(noncycling_adult.obs.class_1)). #{'krt', 'dendritic', 'eccrine', 'T-cell', 'mel'}. sc.tl.rank_genes_groups(noncycling_adult, groupby = 'class_1', groups = ['eccrine', 'krt', 'T-cell', 'dendritic'], reference = 'mel', method = 'wilcoxon'). print(full_adata.uns['rank_genes_groups']). """"""{'params': {'groupby': 'class_1', 'reference': 'rest', 'method': 'wilcoxon', 'use_raw': True, 'corr_method': 'benjamini-hochberg'}, 'scores': rec.array([(8.494621 ,), (8.326364 ,), (8.24139 ,), (7.382108 ,),. (7.340947 ,), (7.25889 ,), (7.2148457,), (7.0626616,),. (6.991276 ,), (6.952865 ,)],. dtype=[('T-cell', '<f4')]), 'names': rec.array([('IL32',), ('CD52',), ('CORO1A',), ('CD3D',), ('IL2RG',),. ('PTPRCAP',), ('RAC2',), ('CD2',), ('LTB',), ('S100A4',)],. dtype=[('T-cell', '<U50')]), 'logfoldchanges': rec.array([(10.175177 ,), (12.354224 ,), (11.05518 ,), (14.337216 ,),. (11.3317585,), ( 9.758805 ,), ( 8.825092 ,), (14.170704 ,),. (10.144425 ,), ( 5.6517367,)],. dtype=[('T-cell', '<f4')]), 'pvals': rec.array([(1.98579427e-17,), (8.33632215e-17,), (1.70221006e-16,),. (1.55802204e-13,), (2.12087430e-13,), (3.90279912e-13,),. (5.39952731e-13,), (1.63343167e-12,), (2.72397796e-12,),. (3.57940624e-12,)],. dtype=[('T-cell', '<f8')]), 'pvals_adj': rec.array([(4.86400449e-13,), (1.02094937e-12,), (1.38979777e-12,),. (9.54054799e-10,), (1.03897390e-09,), (1.59325269e-09,),. (1.88937174e-09,), (5.00115941e-09,), (7.41345735e-09,),. (8.76739764e-09,)],. dtype=[('T-cell', '<f8')])}. """""". ```. Thanks for your help. #### Versions. <details>. scanpy==1.4.4.post1 anndata==0.6.22.post1 umap==0.3.10 numpy==1.17.4 scipy==1.3.2 pandas==1.1.3 scikit-learn==0.22 statsmodels==0.12.0 python-igraph==0.7.1 louvain==0.6.1. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1485
https://github.com/scverse/scanpy/issues/1486:574,availability,error,error,574,"plotting data horizontal plots with shared axis; - [x ] I have checked that this issue has not already been reported. - [ x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. The problem here is that the violin plots are horizontal rather than vertical and that they share the same x-axis scale. Plotting two sets of numbers 10s vs 10,000s the 10s data are not observable. . This looks like a change in the way that seaborn wants violin plots called, based solely on the error below. . **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_house'],. jitter=0.4, multi_panel=True). ```. ```pytb. /Users/banana/opt/miniconda3/lib/python3.8/site-packages/anndata/_core/anndata.py:1192: FutureWarning:. is_categorical is deprecated and will be removed in a future version. Use is_categorical_dtype instead. /Users/banana/opt/miniconda3/lib/python3.8/site-packages/seaborn/_core.py:1303: UserWarning:. Vertical orientation ignored with only `x` specified. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.4. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. anndata 0.7.4. appnope 0.1.0. attr 20.2.0. backcall 0.2.0. cffi 1.14.0. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 2.10.0. idna 2.9. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. joblib 0.17.0. jsonschema 3.2.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. llvmlite 0.34.0. matplotlib 3.3.2. mpl_toolkits NA. natsort 7.0.1. nbformat 5.0.8. numba 0.51.2. numexpr 2.7.1. numpy 1.19.1. packaging 20.4. pandas 1.1.2. parso 0.7.1. pexpec",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1486
https://github.com/scverse/scanpy/issues/1486:172,deployability,version,version,172,"plotting data horizontal plots with shared axis; - [x ] I have checked that this issue has not already been reported. - [ x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. The problem here is that the violin plots are horizontal rather than vertical and that they share the same x-axis scale. Plotting two sets of numbers 10s vs 10,000s the 10s data are not observable. . This looks like a change in the way that seaborn wants violin plots called, based solely on the error below. . **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_house'],. jitter=0.4, multi_panel=True). ```. ```pytb. /Users/banana/opt/miniconda3/lib/python3.8/site-packages/anndata/_core/anndata.py:1192: FutureWarning:. is_categorical is deprecated and will be removed in a future version. Use is_categorical_dtype instead. /Users/banana/opt/miniconda3/lib/python3.8/site-packages/seaborn/_core.py:1303: UserWarning:. Vertical orientation ignored with only `x` specified. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.4. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. anndata 0.7.4. appnope 0.1.0. attr 20.2.0. backcall 0.2.0. cffi 1.14.0. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 2.10.0. idna 2.9. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. joblib 0.17.0. jsonschema 3.2.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. llvmlite 0.34.0. matplotlib 3.3.2. mpl_toolkits NA. natsort 7.0.1. nbformat 5.0.8. numba 0.51.2. numexpr 2.7.1. numpy 1.19.1. packaging 20.4. pandas 1.1.2. parso 0.7.1. pexpec",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1486
https://github.com/scverse/scanpy/issues/1486:392,deployability,scale,scale,392,"plotting data horizontal plots with shared axis; - [x ] I have checked that this issue has not already been reported. - [ x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. The problem here is that the violin plots are horizontal rather than vertical and that they share the same x-axis scale. Plotting two sets of numbers 10s vs 10,000s the 10s data are not observable. . This looks like a change in the way that seaborn wants violin plots called, based solely on the error below. . **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_house'],. jitter=0.4, multi_panel=True). ```. ```pytb. /Users/banana/opt/miniconda3/lib/python3.8/site-packages/anndata/_core/anndata.py:1192: FutureWarning:. is_categorical is deprecated and will be removed in a future version. Use is_categorical_dtype instead. /Users/banana/opt/miniconda3/lib/python3.8/site-packages/seaborn/_core.py:1303: UserWarning:. Vertical orientation ignored with only `x` specified. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.4. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. anndata 0.7.4. appnope 0.1.0. attr 20.2.0. backcall 0.2.0. cffi 1.14.0. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 2.10.0. idna 2.9. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. joblib 0.17.0. jsonschema 3.2.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. llvmlite 0.34.0. matplotlib 3.3.2. mpl_toolkits NA. natsort 7.0.1. nbformat 5.0.8. numba 0.51.2. numexpr 2.7.1. numpy 1.19.1. packaging 20.4. pandas 1.1.2. parso 0.7.1. pexpec",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1486
https://github.com/scverse/scanpy/issues/1486:464,deployability,observ,observable,464,"plotting data horizontal plots with shared axis; - [x ] I have checked that this issue has not already been reported. - [ x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. The problem here is that the violin plots are horizontal rather than vertical and that they share the same x-axis scale. Plotting two sets of numbers 10s vs 10,000s the 10s data are not observable. . This looks like a change in the way that seaborn wants violin plots called, based solely on the error below. . **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_house'],. jitter=0.4, multi_panel=True). ```. ```pytb. /Users/banana/opt/miniconda3/lib/python3.8/site-packages/anndata/_core/anndata.py:1192: FutureWarning:. is_categorical is deprecated and will be removed in a future version. Use is_categorical_dtype instead. /Users/banana/opt/miniconda3/lib/python3.8/site-packages/seaborn/_core.py:1303: UserWarning:. Vertical orientation ignored with only `x` specified. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.4. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. anndata 0.7.4. appnope 0.1.0. attr 20.2.0. backcall 0.2.0. cffi 1.14.0. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 2.10.0. idna 2.9. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. joblib 0.17.0. jsonschema 3.2.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. llvmlite 0.34.0. matplotlib 3.3.2. mpl_toolkits NA. natsort 7.0.1. nbformat 5.0.8. numba 0.51.2. numexpr 2.7.1. numpy 1.19.1. packaging 20.4. pandas 1.1.2. parso 0.7.1. pexpec",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1486
https://github.com/scverse/scanpy/issues/1486:1149,deployability,version,version,1149,"ists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. The problem here is that the violin plots are horizontal rather than vertical and that they share the same x-axis scale. Plotting two sets of numbers 10s vs 10,000s the 10s data are not observable. . This looks like a change in the way that seaborn wants violin plots called, based solely on the error below. . **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_house'],. jitter=0.4, multi_panel=True). ```. ```pytb. /Users/banana/opt/miniconda3/lib/python3.8/site-packages/anndata/_core/anndata.py:1192: FutureWarning:. is_categorical is deprecated and will be removed in a future version. Use is_categorical_dtype instead. /Users/banana/opt/miniconda3/lib/python3.8/site-packages/seaborn/_core.py:1303: UserWarning:. Vertical orientation ignored with only `x` specified. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.4. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. anndata 0.7.4. appnope 0.1.0. attr 20.2.0. backcall 0.2.0. cffi 1.14.0. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 2.10.0. idna 2.9. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. joblib 0.17.0. jsonschema 3.2.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. llvmlite 0.34.0. matplotlib 3.3.2. mpl_toolkits NA. natsort 7.0.1. nbformat 5.0.8. numba 0.51.2. numexpr 2.7.1. numpy 1.19.1. packaging 20.4. pandas 1.1.2. parso 0.7.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotly 4.12.0. prompt_toolkit 3.0.8. ptyprocess 0.6.0. pvectorc NA. pygments 2.7.1. pyparsing 2.4.7. pyrsis",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1486
https://github.com/scverse/scanpy/issues/1486:1350,deployability,Version,Versions,1350,"l and that they share the same x-axis scale. Plotting two sets of numbers 10s vs 10,000s the 10s data are not observable. . This looks like a change in the way that seaborn wants violin plots called, based solely on the error below. . **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_house'],. jitter=0.4, multi_panel=True). ```. ```pytb. /Users/banana/opt/miniconda3/lib/python3.8/site-packages/anndata/_core/anndata.py:1192: FutureWarning:. is_categorical is deprecated and will be removed in a future version. Use is_categorical_dtype instead. /Users/banana/opt/miniconda3/lib/python3.8/site-packages/seaborn/_core.py:1303: UserWarning:. Vertical orientation ignored with only `x` specified. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.4. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. anndata 0.7.4. appnope 0.1.0. attr 20.2.0. backcall 0.2.0. cffi 1.14.0. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 2.10.0. idna 2.9. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. joblib 0.17.0. jsonschema 3.2.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. llvmlite 0.34.0. matplotlib 3.3.2. mpl_toolkits NA. natsort 7.0.1. nbformat 5.0.8. numba 0.51.2. numexpr 2.7.1. numpy 1.19.1. packaging 20.4. pandas 1.1.2. parso 0.7.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotly 4.12.0. prompt_toolkit 3.0.8. ptyprocess 0.6.0. pvectorc NA. pygments 2.7.1. pyparsing 2.4.7. pyrsistent NA. pytz 2020.1. retrying NA. scanpy 1.6.0. scipy 1.5.2. seaborn 0.11.0. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. statsmodels 0.12.1. storemagic NA. tables 3.6.1. tornado 6.0.4.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1486
https://github.com/scverse/scanpy/issues/1486:2585,deployability,log,logical,2585,"al-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_house'],. jitter=0.4, multi_panel=True). ```. ```pytb. /Users/banana/opt/miniconda3/lib/python3.8/site-packages/anndata/_core/anndata.py:1192: FutureWarning:. is_categorical is deprecated and will be removed in a future version. Use is_categorical_dtype instead. /Users/banana/opt/miniconda3/lib/python3.8/site-packages/seaborn/_core.py:1303: UserWarning:. Vertical orientation ignored with only `x` specified. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.4. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. anndata 0.7.4. appnope 0.1.0. attr 20.2.0. backcall 0.2.0. cffi 1.14.0. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 2.10.0. idna 2.9. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. joblib 0.17.0. jsonschema 3.2.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. llvmlite 0.34.0. matplotlib 3.3.2. mpl_toolkits NA. natsort 7.0.1. nbformat 5.0.8. numba 0.51.2. numexpr 2.7.1. numpy 1.19.1. packaging 20.4. pandas 1.1.2. parso 0.7.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotly 4.12.0. prompt_toolkit 3.0.8. ptyprocess 0.6.0. pvectorc NA. pygments 2.7.1. pyparsing 2.4.7. pyrsistent NA. pytz 2020.1. retrying NA. scanpy 1.6.0. scipy 1.5.2. seaborn 0.11.0. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. statsmodels 0.12.1. storemagic NA. tables 3.6.1. tornado 6.0.4. traitlets 5.0.5. wcwidth 0.2.5. zmq 19.0.2. -----. IPython 7.18.1. jupyter_client 6.1.7. jupyter_core 4.6.3. notebook 6.1.4. -----. Python 3.8.3 (default, May 19 2020, 13:54:14) [Clang 10.0.0 ]. macOS-10.15.7-x86_64-i386-64bit. 4 logical CPU cores, i386. -----. Session information updated at 2020-11-05 17:47. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1486
https://github.com/scverse/scanpy/issues/1486:2637,deployability,updat,updated,2637,"al-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_house'],. jitter=0.4, multi_panel=True). ```. ```pytb. /Users/banana/opt/miniconda3/lib/python3.8/site-packages/anndata/_core/anndata.py:1192: FutureWarning:. is_categorical is deprecated and will be removed in a future version. Use is_categorical_dtype instead. /Users/banana/opt/miniconda3/lib/python3.8/site-packages/seaborn/_core.py:1303: UserWarning:. Vertical orientation ignored with only `x` specified. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.4. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. anndata 0.7.4. appnope 0.1.0. attr 20.2.0. backcall 0.2.0. cffi 1.14.0. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 2.10.0. idna 2.9. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. joblib 0.17.0. jsonschema 3.2.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. llvmlite 0.34.0. matplotlib 3.3.2. mpl_toolkits NA. natsort 7.0.1. nbformat 5.0.8. numba 0.51.2. numexpr 2.7.1. numpy 1.19.1. packaging 20.4. pandas 1.1.2. parso 0.7.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotly 4.12.0. prompt_toolkit 3.0.8. ptyprocess 0.6.0. pvectorc NA. pygments 2.7.1. pyparsing 2.4.7. pyrsistent NA. pytz 2020.1. retrying NA. scanpy 1.6.0. scipy 1.5.2. seaborn 0.11.0. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. statsmodels 0.12.1. storemagic NA. tables 3.6.1. tornado 6.0.4. traitlets 5.0.5. wcwidth 0.2.5. zmq 19.0.2. -----. IPython 7.18.1. jupyter_client 6.1.7. jupyter_core 4.6.3. notebook 6.1.4. -----. Python 3.8.3 (default, May 19 2020, 13:54:14) [Clang 10.0.0 ]. macOS-10.15.7-x86_64-i386-64bit. 4 logical CPU cores, i386. -----. Session information updated at 2020-11-05 17:47. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1486
https://github.com/scverse/scanpy/issues/1486:392,energy efficiency,scale,scale,392,"plotting data horizontal plots with shared axis; - [x ] I have checked that this issue has not already been reported. - [ x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. The problem here is that the violin plots are horizontal rather than vertical and that they share the same x-axis scale. Plotting two sets of numbers 10s vs 10,000s the 10s data are not observable. . This looks like a change in the way that seaborn wants violin plots called, based solely on the error below. . **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_house'],. jitter=0.4, multi_panel=True). ```. ```pytb. /Users/banana/opt/miniconda3/lib/python3.8/site-packages/anndata/_core/anndata.py:1192: FutureWarning:. is_categorical is deprecated and will be removed in a future version. Use is_categorical_dtype instead. /Users/banana/opt/miniconda3/lib/python3.8/site-packages/seaborn/_core.py:1303: UserWarning:. Vertical orientation ignored with only `x` specified. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.4. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. anndata 0.7.4. appnope 0.1.0. attr 20.2.0. backcall 0.2.0. cffi 1.14.0. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 2.10.0. idna 2.9. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. joblib 0.17.0. jsonschema 3.2.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. llvmlite 0.34.0. matplotlib 3.3.2. mpl_toolkits NA. natsort 7.0.1. nbformat 5.0.8. numba 0.51.2. numexpr 2.7.1. numpy 1.19.1. packaging 20.4. pandas 1.1.2. parso 0.7.1. pexpec",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1486
https://github.com/scverse/scanpy/issues/1486:2593,energy efficiency,CPU,CPU,2593,"al-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_house'],. jitter=0.4, multi_panel=True). ```. ```pytb. /Users/banana/opt/miniconda3/lib/python3.8/site-packages/anndata/_core/anndata.py:1192: FutureWarning:. is_categorical is deprecated and will be removed in a future version. Use is_categorical_dtype instead. /Users/banana/opt/miniconda3/lib/python3.8/site-packages/seaborn/_core.py:1303: UserWarning:. Vertical orientation ignored with only `x` specified. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.4. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. anndata 0.7.4. appnope 0.1.0. attr 20.2.0. backcall 0.2.0. cffi 1.14.0. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 2.10.0. idna 2.9. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. joblib 0.17.0. jsonschema 3.2.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. llvmlite 0.34.0. matplotlib 3.3.2. mpl_toolkits NA. natsort 7.0.1. nbformat 5.0.8. numba 0.51.2. numexpr 2.7.1. numpy 1.19.1. packaging 20.4. pandas 1.1.2. parso 0.7.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotly 4.12.0. prompt_toolkit 3.0.8. ptyprocess 0.6.0. pvectorc NA. pygments 2.7.1. pyparsing 2.4.7. pyrsistent NA. pytz 2020.1. retrying NA. scanpy 1.6.0. scipy 1.5.2. seaborn 0.11.0. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. statsmodels 0.12.1. storemagic NA. tables 3.6.1. tornado 6.0.4. traitlets 5.0.5. wcwidth 0.2.5. zmq 19.0.2. -----. IPython 7.18.1. jupyter_client 6.1.7. jupyter_core 4.6.3. notebook 6.1.4. -----. Python 3.8.3 (default, May 19 2020, 13:54:14) [Clang 10.0.0 ]. macOS-10.15.7-x86_64-i386-64bit. 4 logical CPU cores, i386. -----. Session information updated at 2020-11-05 17:47. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1486
https://github.com/scverse/scanpy/issues/1486:2597,energy efficiency,core,cores,2597,"al-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_house'],. jitter=0.4, multi_panel=True). ```. ```pytb. /Users/banana/opt/miniconda3/lib/python3.8/site-packages/anndata/_core/anndata.py:1192: FutureWarning:. is_categorical is deprecated and will be removed in a future version. Use is_categorical_dtype instead. /Users/banana/opt/miniconda3/lib/python3.8/site-packages/seaborn/_core.py:1303: UserWarning:. Vertical orientation ignored with only `x` specified. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.4. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. anndata 0.7.4. appnope 0.1.0. attr 20.2.0. backcall 0.2.0. cffi 1.14.0. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 2.10.0. idna 2.9. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. joblib 0.17.0. jsonschema 3.2.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. llvmlite 0.34.0. matplotlib 3.3.2. mpl_toolkits NA. natsort 7.0.1. nbformat 5.0.8. numba 0.51.2. numexpr 2.7.1. numpy 1.19.1. packaging 20.4. pandas 1.1.2. parso 0.7.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotly 4.12.0. prompt_toolkit 3.0.8. ptyprocess 0.6.0. pvectorc NA. pygments 2.7.1. pyparsing 2.4.7. pyrsistent NA. pytz 2020.1. retrying NA. scanpy 1.6.0. scipy 1.5.2. seaborn 0.11.0. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. statsmodels 0.12.1. storemagic NA. tables 3.6.1. tornado 6.0.4. traitlets 5.0.5. wcwidth 0.2.5. zmq 19.0.2. -----. IPython 7.18.1. jupyter_client 6.1.7. jupyter_core 4.6.3. notebook 6.1.4. -----. Python 3.8.3 (default, May 19 2020, 13:54:14) [Clang 10.0.0 ]. macOS-10.15.7-x86_64-i386-64bit. 4 logical CPU cores, i386. -----. Session information updated at 2020-11-05 17:47. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1486
https://github.com/scverse/scanpy/issues/1486:172,integrability,version,version,172,"plotting data horizontal plots with shared axis; - [x ] I have checked that this issue has not already been reported. - [ x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. The problem here is that the violin plots are horizontal rather than vertical and that they share the same x-axis scale. Plotting two sets of numbers 10s vs 10,000s the 10s data are not observable. . This looks like a change in the way that seaborn wants violin plots called, based solely on the error below. . **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_house'],. jitter=0.4, multi_panel=True). ```. ```pytb. /Users/banana/opt/miniconda3/lib/python3.8/site-packages/anndata/_core/anndata.py:1192: FutureWarning:. is_categorical is deprecated and will be removed in a future version. Use is_categorical_dtype instead. /Users/banana/opt/miniconda3/lib/python3.8/site-packages/seaborn/_core.py:1303: UserWarning:. Vertical orientation ignored with only `x` specified. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.4. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. anndata 0.7.4. appnope 0.1.0. attr 20.2.0. backcall 0.2.0. cffi 1.14.0. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 2.10.0. idna 2.9. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. joblib 0.17.0. jsonschema 3.2.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. llvmlite 0.34.0. matplotlib 3.3.2. mpl_toolkits NA. natsort 7.0.1. nbformat 5.0.8. numba 0.51.2. numexpr 2.7.1. numpy 1.19.1. packaging 20.4. pandas 1.1.2. parso 0.7.1. pexpec",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1486
https://github.com/scverse/scanpy/issues/1486:1149,integrability,version,version,1149,"ists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. The problem here is that the violin plots are horizontal rather than vertical and that they share the same x-axis scale. Plotting two sets of numbers 10s vs 10,000s the 10s data are not observable. . This looks like a change in the way that seaborn wants violin plots called, based solely on the error below. . **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_house'],. jitter=0.4, multi_panel=True). ```. ```pytb. /Users/banana/opt/miniconda3/lib/python3.8/site-packages/anndata/_core/anndata.py:1192: FutureWarning:. is_categorical is deprecated and will be removed in a future version. Use is_categorical_dtype instead. /Users/banana/opt/miniconda3/lib/python3.8/site-packages/seaborn/_core.py:1303: UserWarning:. Vertical orientation ignored with only `x` specified. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.4. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. anndata 0.7.4. appnope 0.1.0. attr 20.2.0. backcall 0.2.0. cffi 1.14.0. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 2.10.0. idna 2.9. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. joblib 0.17.0. jsonschema 3.2.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. llvmlite 0.34.0. matplotlib 3.3.2. mpl_toolkits NA. natsort 7.0.1. nbformat 5.0.8. numba 0.51.2. numexpr 2.7.1. numpy 1.19.1. packaging 20.4. pandas 1.1.2. parso 0.7.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotly 4.12.0. prompt_toolkit 3.0.8. ptyprocess 0.6.0. pvectorc NA. pygments 2.7.1. pyparsing 2.4.7. pyrsis",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1486
https://github.com/scverse/scanpy/issues/1486:1350,integrability,Version,Versions,1350,"l and that they share the same x-axis scale. Plotting two sets of numbers 10s vs 10,000s the 10s data are not observable. . This looks like a change in the way that seaborn wants violin plots called, based solely on the error below. . **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_house'],. jitter=0.4, multi_panel=True). ```. ```pytb. /Users/banana/opt/miniconda3/lib/python3.8/site-packages/anndata/_core/anndata.py:1192: FutureWarning:. is_categorical is deprecated and will be removed in a future version. Use is_categorical_dtype instead. /Users/banana/opt/miniconda3/lib/python3.8/site-packages/seaborn/_core.py:1303: UserWarning:. Vertical orientation ignored with only `x` specified. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.4. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. anndata 0.7.4. appnope 0.1.0. attr 20.2.0. backcall 0.2.0. cffi 1.14.0. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 2.10.0. idna 2.9. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. joblib 0.17.0. jsonschema 3.2.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. llvmlite 0.34.0. matplotlib 3.3.2. mpl_toolkits NA. natsort 7.0.1. nbformat 5.0.8. numba 0.51.2. numexpr 2.7.1. numpy 1.19.1. packaging 20.4. pandas 1.1.2. parso 0.7.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotly 4.12.0. prompt_toolkit 3.0.8. ptyprocess 0.6.0. pvectorc NA. pygments 2.7.1. pyparsing 2.4.7. pyrsistent NA. pytz 2020.1. retrying NA. scanpy 1.6.0. scipy 1.5.2. seaborn 0.11.0. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. statsmodels 0.12.1. storemagic NA. tables 3.6.1. tornado 6.0.4.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1486
https://github.com/scverse/scanpy/issues/1486:36,interoperability,share,shared,36,"plotting data horizontal plots with shared axis; - [x ] I have checked that this issue has not already been reported. - [ x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. The problem here is that the violin plots are horizontal rather than vertical and that they share the same x-axis scale. Plotting two sets of numbers 10s vs 10,000s the 10s data are not observable. . This looks like a change in the way that seaborn wants violin plots called, based solely on the error below. . **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_house'],. jitter=0.4, multi_panel=True). ```. ```pytb. /Users/banana/opt/miniconda3/lib/python3.8/site-packages/anndata/_core/anndata.py:1192: FutureWarning:. is_categorical is deprecated and will be removed in a future version. Use is_categorical_dtype instead. /Users/banana/opt/miniconda3/lib/python3.8/site-packages/seaborn/_core.py:1303: UserWarning:. Vertical orientation ignored with only `x` specified. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.4. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. anndata 0.7.4. appnope 0.1.0. attr 20.2.0. backcall 0.2.0. cffi 1.14.0. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 2.10.0. idna 2.9. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. joblib 0.17.0. jsonschema 3.2.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. llvmlite 0.34.0. matplotlib 3.3.2. mpl_toolkits NA. natsort 7.0.1. nbformat 5.0.8. numba 0.51.2. numexpr 2.7.1. numpy 1.19.1. packaging 20.4. pandas 1.1.2. parso 0.7.1. pexpec",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1486
https://github.com/scverse/scanpy/issues/1486:370,interoperability,share,share,370,"plotting data horizontal plots with shared axis; - [x ] I have checked that this issue has not already been reported. - [ x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. The problem here is that the violin plots are horizontal rather than vertical and that they share the same x-axis scale. Plotting two sets of numbers 10s vs 10,000s the 10s data are not observable. . This looks like a change in the way that seaborn wants violin plots called, based solely on the error below. . **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_house'],. jitter=0.4, multi_panel=True). ```. ```pytb. /Users/banana/opt/miniconda3/lib/python3.8/site-packages/anndata/_core/anndata.py:1192: FutureWarning:. is_categorical is deprecated and will be removed in a future version. Use is_categorical_dtype instead. /Users/banana/opt/miniconda3/lib/python3.8/site-packages/seaborn/_core.py:1303: UserWarning:. Vertical orientation ignored with only `x` specified. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.4. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. anndata 0.7.4. appnope 0.1.0. attr 20.2.0. backcall 0.2.0. cffi 1.14.0. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 2.10.0. idna 2.9. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. joblib 0.17.0. jsonschema 3.2.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. llvmlite 0.34.0. matplotlib 3.3.2. mpl_toolkits NA. natsort 7.0.1. nbformat 5.0.8. numba 0.51.2. numexpr 2.7.1. numpy 1.19.1. packaging 20.4. pandas 1.1.2. parso 0.7.1. pexpec",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1486
https://github.com/scverse/scanpy/issues/1486:1329,interoperability,specif,specified,1329," rather than vertical and that they share the same x-axis scale. Plotting two sets of numbers 10s vs 10,000s the 10s data are not observable. . This looks like a change in the way that seaborn wants violin plots called, based solely on the error below. . **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_house'],. jitter=0.4, multi_panel=True). ```. ```pytb. /Users/banana/opt/miniconda3/lib/python3.8/site-packages/anndata/_core/anndata.py:1192: FutureWarning:. is_categorical is deprecated and will be removed in a future version. Use is_categorical_dtype instead. /Users/banana/opt/miniconda3/lib/python3.8/site-packages/seaborn/_core.py:1303: UserWarning:. Vertical orientation ignored with only `x` specified. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.4. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. anndata 0.7.4. appnope 0.1.0. attr 20.2.0. backcall 0.2.0. cffi 1.14.0. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 2.10.0. idna 2.9. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. joblib 0.17.0. jsonschema 3.2.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. llvmlite 0.34.0. matplotlib 3.3.2. mpl_toolkits NA. natsort 7.0.1. nbformat 5.0.8. numba 0.51.2. numexpr 2.7.1. numpy 1.19.1. packaging 20.4. pandas 1.1.2. parso 0.7.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotly 4.12.0. prompt_toolkit 3.0.8. ptyprocess 0.6.0. pvectorc NA. pygments 2.7.1. pyparsing 2.4.7. pyrsistent NA. pytz 2020.1. retrying NA. scanpy 1.6.0. scipy 1.5.2. seaborn 0.11.0. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. statsmodels 0.12.1. storemagic NA. tables 3",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1486
https://github.com/scverse/scanpy/issues/1486:172,modifiability,version,version,172,"plotting data horizontal plots with shared axis; - [x ] I have checked that this issue has not already been reported. - [ x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. The problem here is that the violin plots are horizontal rather than vertical and that they share the same x-axis scale. Plotting two sets of numbers 10s vs 10,000s the 10s data are not observable. . This looks like a change in the way that seaborn wants violin plots called, based solely on the error below. . **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_house'],. jitter=0.4, multi_panel=True). ```. ```pytb. /Users/banana/opt/miniconda3/lib/python3.8/site-packages/anndata/_core/anndata.py:1192: FutureWarning:. is_categorical is deprecated and will be removed in a future version. Use is_categorical_dtype instead. /Users/banana/opt/miniconda3/lib/python3.8/site-packages/seaborn/_core.py:1303: UserWarning:. Vertical orientation ignored with only `x` specified. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.4. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. anndata 0.7.4. appnope 0.1.0. attr 20.2.0. backcall 0.2.0. cffi 1.14.0. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 2.10.0. idna 2.9. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. joblib 0.17.0. jsonschema 3.2.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. llvmlite 0.34.0. matplotlib 3.3.2. mpl_toolkits NA. natsort 7.0.1. nbformat 5.0.8. numba 0.51.2. numexpr 2.7.1. numpy 1.19.1. packaging 20.4. pandas 1.1.2. parso 0.7.1. pexpec",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1486
https://github.com/scverse/scanpy/issues/1486:392,modifiability,scal,scale,392,"plotting data horizontal plots with shared axis; - [x ] I have checked that this issue has not already been reported. - [ x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. The problem here is that the violin plots are horizontal rather than vertical and that they share the same x-axis scale. Plotting two sets of numbers 10s vs 10,000s the 10s data are not observable. . This looks like a change in the way that seaborn wants violin plots called, based solely on the error below. . **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_house'],. jitter=0.4, multi_panel=True). ```. ```pytb. /Users/banana/opt/miniconda3/lib/python3.8/site-packages/anndata/_core/anndata.py:1192: FutureWarning:. is_categorical is deprecated and will be removed in a future version. Use is_categorical_dtype instead. /Users/banana/opt/miniconda3/lib/python3.8/site-packages/seaborn/_core.py:1303: UserWarning:. Vertical orientation ignored with only `x` specified. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.4. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. anndata 0.7.4. appnope 0.1.0. attr 20.2.0. backcall 0.2.0. cffi 1.14.0. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 2.10.0. idna 2.9. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. joblib 0.17.0. jsonschema 3.2.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. llvmlite 0.34.0. matplotlib 3.3.2. mpl_toolkits NA. natsort 7.0.1. nbformat 5.0.8. numba 0.51.2. numexpr 2.7.1. numpy 1.19.1. packaging 20.4. pandas 1.1.2. parso 0.7.1. pexpec",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1486
https://github.com/scverse/scanpy/issues/1486:1032,modifiability,pac,packages,1032,"shared axis; - [x ] I have checked that this issue has not already been reported. - [ x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. The problem here is that the violin plots are horizontal rather than vertical and that they share the same x-axis scale. Plotting two sets of numbers 10s vs 10,000s the 10s data are not observable. . This looks like a change in the way that seaborn wants violin plots called, based solely on the error below. . **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_house'],. jitter=0.4, multi_panel=True). ```. ```pytb. /Users/banana/opt/miniconda3/lib/python3.8/site-packages/anndata/_core/anndata.py:1192: FutureWarning:. is_categorical is deprecated and will be removed in a future version. Use is_categorical_dtype instead. /Users/banana/opt/miniconda3/lib/python3.8/site-packages/seaborn/_core.py:1303: UserWarning:. Vertical orientation ignored with only `x` specified. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.4. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. anndata 0.7.4. appnope 0.1.0. attr 20.2.0. backcall 0.2.0. cffi 1.14.0. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 2.10.0. idna 2.9. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. joblib 0.17.0. jsonschema 3.2.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. llvmlite 0.34.0. matplotlib 3.3.2. mpl_toolkits NA. natsort 7.0.1. nbformat 5.0.8. numba 0.51.2. numexpr 2.7.1. numpy 1.19.1. packaging 20.4. pandas 1.1.2. parso 0.7.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_reso",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1486
https://github.com/scverse/scanpy/issues/1486:1149,modifiability,version,version,1149,"ists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. The problem here is that the violin plots are horizontal rather than vertical and that they share the same x-axis scale. Plotting two sets of numbers 10s vs 10,000s the 10s data are not observable. . This looks like a change in the way that seaborn wants violin plots called, based solely on the error below. . **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_house'],. jitter=0.4, multi_panel=True). ```. ```pytb. /Users/banana/opt/miniconda3/lib/python3.8/site-packages/anndata/_core/anndata.py:1192: FutureWarning:. is_categorical is deprecated and will be removed in a future version. Use is_categorical_dtype instead. /Users/banana/opt/miniconda3/lib/python3.8/site-packages/seaborn/_core.py:1303: UserWarning:. Vertical orientation ignored with only `x` specified. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.4. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. anndata 0.7.4. appnope 0.1.0. attr 20.2.0. backcall 0.2.0. cffi 1.14.0. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 2.10.0. idna 2.9. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. joblib 0.17.0. jsonschema 3.2.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. llvmlite 0.34.0. matplotlib 3.3.2. mpl_toolkits NA. natsort 7.0.1. nbformat 5.0.8. numba 0.51.2. numexpr 2.7.1. numpy 1.19.1. packaging 20.4. pandas 1.1.2. parso 0.7.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotly 4.12.0. prompt_toolkit 3.0.8. ptyprocess 0.6.0. pvectorc NA. pygments 2.7.1. pyparsing 2.4.7. pyrsis",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1486
https://github.com/scverse/scanpy/issues/1486:1240,modifiability,pac,packages,1240,"the master branch of scanpy. ---. The problem here is that the violin plots are horizontal rather than vertical and that they share the same x-axis scale. Plotting two sets of numbers 10s vs 10,000s the 10s data are not observable. . This looks like a change in the way that seaborn wants violin plots called, based solely on the error below. . **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_house'],. jitter=0.4, multi_panel=True). ```. ```pytb. /Users/banana/opt/miniconda3/lib/python3.8/site-packages/anndata/_core/anndata.py:1192: FutureWarning:. is_categorical is deprecated and will be removed in a future version. Use is_categorical_dtype instead. /Users/banana/opt/miniconda3/lib/python3.8/site-packages/seaborn/_core.py:1303: UserWarning:. Vertical orientation ignored with only `x` specified. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.4. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. anndata 0.7.4. appnope 0.1.0. attr 20.2.0. backcall 0.2.0. cffi 1.14.0. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 2.10.0. idna 2.9. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. joblib 0.17.0. jsonschema 3.2.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. llvmlite 0.34.0. matplotlib 3.3.2. mpl_toolkits NA. natsort 7.0.1. nbformat 5.0.8. numba 0.51.2. numexpr 2.7.1. numpy 1.19.1. packaging 20.4. pandas 1.1.2. parso 0.7.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotly 4.12.0. prompt_toolkit 3.0.8. ptyprocess 0.6.0. pvectorc NA. pygments 2.7.1. pyparsing 2.4.7. pyrsistent NA. pytz 2020.1. retrying NA. scanpy 1.6.0. scipy 1.5.2. seaborn 0.11.0. setuptools_sc",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1486
https://github.com/scverse/scanpy/issues/1486:1350,modifiability,Version,Versions,1350,"l and that they share the same x-axis scale. Plotting two sets of numbers 10s vs 10,000s the 10s data are not observable. . This looks like a change in the way that seaborn wants violin plots called, based solely on the error below. . **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_house'],. jitter=0.4, multi_panel=True). ```. ```pytb. /Users/banana/opt/miniconda3/lib/python3.8/site-packages/anndata/_core/anndata.py:1192: FutureWarning:. is_categorical is deprecated and will be removed in a future version. Use is_categorical_dtype instead. /Users/banana/opt/miniconda3/lib/python3.8/site-packages/seaborn/_core.py:1303: UserWarning:. Vertical orientation ignored with only `x` specified. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.4. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. anndata 0.7.4. appnope 0.1.0. attr 20.2.0. backcall 0.2.0. cffi 1.14.0. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 2.10.0. idna 2.9. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. joblib 0.17.0. jsonschema 3.2.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. llvmlite 0.34.0. matplotlib 3.3.2. mpl_toolkits NA. natsort 7.0.1. nbformat 5.0.8. numba 0.51.2. numexpr 2.7.1. numpy 1.19.1. packaging 20.4. pandas 1.1.2. parso 0.7.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotly 4.12.0. prompt_toolkit 3.0.8. ptyprocess 0.6.0. pvectorc NA. pygments 2.7.1. pyparsing 2.4.7. pyrsistent NA. pytz 2020.1. retrying NA. scanpy 1.6.0. scipy 1.5.2. seaborn 0.11.0. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. statsmodels 0.12.1. storemagic NA. tables 3.6.1. tornado 6.0.4.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1486
https://github.com/scverse/scanpy/issues/1486:1624,modifiability,deco,decorator,1624,"://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_house'],. jitter=0.4, multi_panel=True). ```. ```pytb. /Users/banana/opt/miniconda3/lib/python3.8/site-packages/anndata/_core/anndata.py:1192: FutureWarning:. is_categorical is deprecated and will be removed in a future version. Use is_categorical_dtype instead. /Users/banana/opt/miniconda3/lib/python3.8/site-packages/seaborn/_core.py:1303: UserWarning:. Vertical orientation ignored with only `x` specified. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.4. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. anndata 0.7.4. appnope 0.1.0. attr 20.2.0. backcall 0.2.0. cffi 1.14.0. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 2.10.0. idna 2.9. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. joblib 0.17.0. jsonschema 3.2.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. llvmlite 0.34.0. matplotlib 3.3.2. mpl_toolkits NA. natsort 7.0.1. nbformat 5.0.8. numba 0.51.2. numexpr 2.7.1. numpy 1.19.1. packaging 20.4. pandas 1.1.2. parso 0.7.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotly 4.12.0. prompt_toolkit 3.0.8. ptyprocess 0.6.0. pvectorc NA. pygments 2.7.1. pyparsing 2.4.7. pyrsistent NA. pytz 2020.1. retrying NA. scanpy 1.6.0. scipy 1.5.2. seaborn 0.11.0. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. statsmodels 0.12.1. storemagic NA. tables 3.6.1. tornado 6.0.4. traitlets 5.0.5. wcwidth 0.2.5. zmq 19.0.2. -----. IPython 7.18.1. jupyter_client 6.1.7. jupyter_core 4.6.3. notebook 6.1.4. -----. Python 3.8.3 (default, May 19 2020, 13:54:14) [Clang 10.0.0 ]. macOS-10.15.7-x86_64-i386-64bit. 4 logical CPU cores, i386. -----. Session info",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1486
https://github.com/scverse/scanpy/issues/1486:1951,modifiability,pac,packaging,1951,"al-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_house'],. jitter=0.4, multi_panel=True). ```. ```pytb. /Users/banana/opt/miniconda3/lib/python3.8/site-packages/anndata/_core/anndata.py:1192: FutureWarning:. is_categorical is deprecated and will be removed in a future version. Use is_categorical_dtype instead. /Users/banana/opt/miniconda3/lib/python3.8/site-packages/seaborn/_core.py:1303: UserWarning:. Vertical orientation ignored with only `x` specified. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.4. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. anndata 0.7.4. appnope 0.1.0. attr 20.2.0. backcall 0.2.0. cffi 1.14.0. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 2.10.0. idna 2.9. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. joblib 0.17.0. jsonschema 3.2.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. llvmlite 0.34.0. matplotlib 3.3.2. mpl_toolkits NA. natsort 7.0.1. nbformat 5.0.8. numba 0.51.2. numexpr 2.7.1. numpy 1.19.1. packaging 20.4. pandas 1.1.2. parso 0.7.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotly 4.12.0. prompt_toolkit 3.0.8. ptyprocess 0.6.0. pvectorc NA. pygments 2.7.1. pyparsing 2.4.7. pyrsistent NA. pytz 2020.1. retrying NA. scanpy 1.6.0. scipy 1.5.2. seaborn 0.11.0. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. statsmodels 0.12.1. storemagic NA. tables 3.6.1. tornado 6.0.4. traitlets 5.0.5. wcwidth 0.2.5. zmq 19.0.2. -----. IPython 7.18.1. jupyter_client 6.1.7. jupyter_core 4.6.3. notebook 6.1.4. -----. Python 3.8.3 (default, May 19 2020, 13:54:14) [Clang 10.0.0 ]. macOS-10.15.7-x86_64-i386-64bit. 4 logical CPU cores, i386. -----. Session information updated at 2020-11-05 17:47. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1486
https://github.com/scverse/scanpy/issues/1486:392,performance,scale,scale,392,"plotting data horizontal plots with shared axis; - [x ] I have checked that this issue has not already been reported. - [ x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. The problem here is that the violin plots are horizontal rather than vertical and that they share the same x-axis scale. Plotting two sets of numbers 10s vs 10,000s the 10s data are not observable. . This looks like a change in the way that seaborn wants violin plots called, based solely on the error below. . **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_house'],. jitter=0.4, multi_panel=True). ```. ```pytb. /Users/banana/opt/miniconda3/lib/python3.8/site-packages/anndata/_core/anndata.py:1192: FutureWarning:. is_categorical is deprecated and will be removed in a future version. Use is_categorical_dtype instead. /Users/banana/opt/miniconda3/lib/python3.8/site-packages/seaborn/_core.py:1303: UserWarning:. Vertical orientation ignored with only `x` specified. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.4. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. anndata 0.7.4. appnope 0.1.0. attr 20.2.0. backcall 0.2.0. cffi 1.14.0. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 2.10.0. idna 2.9. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. joblib 0.17.0. jsonschema 3.2.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. llvmlite 0.34.0. matplotlib 3.3.2. mpl_toolkits NA. natsort 7.0.1. nbformat 5.0.8. numba 0.51.2. numexpr 2.7.1. numpy 1.19.1. packaging 20.4. pandas 1.1.2. parso 0.7.1. pexpec",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1486
https://github.com/scverse/scanpy/issues/1486:574,performance,error,error,574,"plotting data horizontal plots with shared axis; - [x ] I have checked that this issue has not already been reported. - [ x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. The problem here is that the violin plots are horizontal rather than vertical and that they share the same x-axis scale. Plotting two sets of numbers 10s vs 10,000s the 10s data are not observable. . This looks like a change in the way that seaborn wants violin plots called, based solely on the error below. . **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_house'],. jitter=0.4, multi_panel=True). ```. ```pytb. /Users/banana/opt/miniconda3/lib/python3.8/site-packages/anndata/_core/anndata.py:1192: FutureWarning:. is_categorical is deprecated and will be removed in a future version. Use is_categorical_dtype instead. /Users/banana/opt/miniconda3/lib/python3.8/site-packages/seaborn/_core.py:1303: UserWarning:. Vertical orientation ignored with only `x` specified. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.4. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. anndata 0.7.4. appnope 0.1.0. attr 20.2.0. backcall 0.2.0. cffi 1.14.0. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 2.10.0. idna 2.9. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. joblib 0.17.0. jsonschema 3.2.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. llvmlite 0.34.0. matplotlib 3.3.2. mpl_toolkits NA. natsort 7.0.1. nbformat 5.0.8. numba 0.51.2. numexpr 2.7.1. numpy 1.19.1. packaging 20.4. pandas 1.1.2. parso 0.7.1. pexpec",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1486
https://github.com/scverse/scanpy/issues/1486:2593,performance,CPU,CPU,2593,"al-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_house'],. jitter=0.4, multi_panel=True). ```. ```pytb. /Users/banana/opt/miniconda3/lib/python3.8/site-packages/anndata/_core/anndata.py:1192: FutureWarning:. is_categorical is deprecated and will be removed in a future version. Use is_categorical_dtype instead. /Users/banana/opt/miniconda3/lib/python3.8/site-packages/seaborn/_core.py:1303: UserWarning:. Vertical orientation ignored with only `x` specified. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.4. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. anndata 0.7.4. appnope 0.1.0. attr 20.2.0. backcall 0.2.0. cffi 1.14.0. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 2.10.0. idna 2.9. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. joblib 0.17.0. jsonschema 3.2.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. llvmlite 0.34.0. matplotlib 3.3.2. mpl_toolkits NA. natsort 7.0.1. nbformat 5.0.8. numba 0.51.2. numexpr 2.7.1. numpy 1.19.1. packaging 20.4. pandas 1.1.2. parso 0.7.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotly 4.12.0. prompt_toolkit 3.0.8. ptyprocess 0.6.0. pvectorc NA. pygments 2.7.1. pyparsing 2.4.7. pyrsistent NA. pytz 2020.1. retrying NA. scanpy 1.6.0. scipy 1.5.2. seaborn 0.11.0. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. statsmodels 0.12.1. storemagic NA. tables 3.6.1. tornado 6.0.4. traitlets 5.0.5. wcwidth 0.2.5. zmq 19.0.2. -----. IPython 7.18.1. jupyter_client 6.1.7. jupyter_core 4.6.3. notebook 6.1.4. -----. Python 3.8.3 (default, May 19 2020, 13:54:14) [Clang 10.0.0 ]. macOS-10.15.7-x86_64-i386-64bit. 4 logical CPU cores, i386. -----. Session information updated at 2020-11-05 17:47. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1486
https://github.com/scverse/scanpy/issues/1486:574,safety,error,error,574,"plotting data horizontal plots with shared axis; - [x ] I have checked that this issue has not already been reported. - [ x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. The problem here is that the violin plots are horizontal rather than vertical and that they share the same x-axis scale. Plotting two sets of numbers 10s vs 10,000s the 10s data are not observable. . This looks like a change in the way that seaborn wants violin plots called, based solely on the error below. . **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_house'],. jitter=0.4, multi_panel=True). ```. ```pytb. /Users/banana/opt/miniconda3/lib/python3.8/site-packages/anndata/_core/anndata.py:1192: FutureWarning:. is_categorical is deprecated and will be removed in a future version. Use is_categorical_dtype instead. /Users/banana/opt/miniconda3/lib/python3.8/site-packages/seaborn/_core.py:1303: UserWarning:. Vertical orientation ignored with only `x` specified. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.4. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. anndata 0.7.4. appnope 0.1.0. attr 20.2.0. backcall 0.2.0. cffi 1.14.0. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 2.10.0. idna 2.9. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. joblib 0.17.0. jsonschema 3.2.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. llvmlite 0.34.0. matplotlib 3.3.2. mpl_toolkits NA. natsort 7.0.1. nbformat 5.0.8. numba 0.51.2. numexpr 2.7.1. numpy 1.19.1. packaging 20.4. pandas 1.1.2. parso 0.7.1. pexpec",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1486
https://github.com/scverse/scanpy/issues/1486:2585,safety,log,logical,2585,"al-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_house'],. jitter=0.4, multi_panel=True). ```. ```pytb. /Users/banana/opt/miniconda3/lib/python3.8/site-packages/anndata/_core/anndata.py:1192: FutureWarning:. is_categorical is deprecated and will be removed in a future version. Use is_categorical_dtype instead. /Users/banana/opt/miniconda3/lib/python3.8/site-packages/seaborn/_core.py:1303: UserWarning:. Vertical orientation ignored with only `x` specified. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.4. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. anndata 0.7.4. appnope 0.1.0. attr 20.2.0. backcall 0.2.0. cffi 1.14.0. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 2.10.0. idna 2.9. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. joblib 0.17.0. jsonschema 3.2.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. llvmlite 0.34.0. matplotlib 3.3.2. mpl_toolkits NA. natsort 7.0.1. nbformat 5.0.8. numba 0.51.2. numexpr 2.7.1. numpy 1.19.1. packaging 20.4. pandas 1.1.2. parso 0.7.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotly 4.12.0. prompt_toolkit 3.0.8. ptyprocess 0.6.0. pvectorc NA. pygments 2.7.1. pyparsing 2.4.7. pyrsistent NA. pytz 2020.1. retrying NA. scanpy 1.6.0. scipy 1.5.2. seaborn 0.11.0. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. statsmodels 0.12.1. storemagic NA. tables 3.6.1. tornado 6.0.4. traitlets 5.0.5. wcwidth 0.2.5. zmq 19.0.2. -----. IPython 7.18.1. jupyter_client 6.1.7. jupyter_core 4.6.3. notebook 6.1.4. -----. Python 3.8.3 (default, May 19 2020, 13:54:14) [Clang 10.0.0 ]. macOS-10.15.7-x86_64-i386-64bit. 4 logical CPU cores, i386. -----. Session information updated at 2020-11-05 17:47. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1486
https://github.com/scverse/scanpy/issues/1486:2637,safety,updat,updated,2637,"al-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_house'],. jitter=0.4, multi_panel=True). ```. ```pytb. /Users/banana/opt/miniconda3/lib/python3.8/site-packages/anndata/_core/anndata.py:1192: FutureWarning:. is_categorical is deprecated and will be removed in a future version. Use is_categorical_dtype instead. /Users/banana/opt/miniconda3/lib/python3.8/site-packages/seaborn/_core.py:1303: UserWarning:. Vertical orientation ignored with only `x` specified. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.4. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. anndata 0.7.4. appnope 0.1.0. attr 20.2.0. backcall 0.2.0. cffi 1.14.0. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 2.10.0. idna 2.9. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. joblib 0.17.0. jsonschema 3.2.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. llvmlite 0.34.0. matplotlib 3.3.2. mpl_toolkits NA. natsort 7.0.1. nbformat 5.0.8. numba 0.51.2. numexpr 2.7.1. numpy 1.19.1. packaging 20.4. pandas 1.1.2. parso 0.7.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotly 4.12.0. prompt_toolkit 3.0.8. ptyprocess 0.6.0. pvectorc NA. pygments 2.7.1. pyparsing 2.4.7. pyrsistent NA. pytz 2020.1. retrying NA. scanpy 1.6.0. scipy 1.5.2. seaborn 0.11.0. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. statsmodels 0.12.1. storemagic NA. tables 3.6.1. tornado 6.0.4. traitlets 5.0.5. wcwidth 0.2.5. zmq 19.0.2. -----. IPython 7.18.1. jupyter_client 6.1.7. jupyter_core 4.6.3. notebook 6.1.4. -----. Python 3.8.3 (default, May 19 2020, 13:54:14) [Clang 10.0.0 ]. macOS-10.15.7-x86_64-i386-64bit. 4 logical CPU cores, i386. -----. Session information updated at 2020-11-05 17:47. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1486
https://github.com/scverse/scanpy/issues/1486:2585,security,log,logical,2585,"al-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_house'],. jitter=0.4, multi_panel=True). ```. ```pytb. /Users/banana/opt/miniconda3/lib/python3.8/site-packages/anndata/_core/anndata.py:1192: FutureWarning:. is_categorical is deprecated and will be removed in a future version. Use is_categorical_dtype instead. /Users/banana/opt/miniconda3/lib/python3.8/site-packages/seaborn/_core.py:1303: UserWarning:. Vertical orientation ignored with only `x` specified. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.4. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. anndata 0.7.4. appnope 0.1.0. attr 20.2.0. backcall 0.2.0. cffi 1.14.0. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 2.10.0. idna 2.9. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. joblib 0.17.0. jsonschema 3.2.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. llvmlite 0.34.0. matplotlib 3.3.2. mpl_toolkits NA. natsort 7.0.1. nbformat 5.0.8. numba 0.51.2. numexpr 2.7.1. numpy 1.19.1. packaging 20.4. pandas 1.1.2. parso 0.7.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotly 4.12.0. prompt_toolkit 3.0.8. ptyprocess 0.6.0. pvectorc NA. pygments 2.7.1. pyparsing 2.4.7. pyrsistent NA. pytz 2020.1. retrying NA. scanpy 1.6.0. scipy 1.5.2. seaborn 0.11.0. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. statsmodels 0.12.1. storemagic NA. tables 3.6.1. tornado 6.0.4. traitlets 5.0.5. wcwidth 0.2.5. zmq 19.0.2. -----. IPython 7.18.1. jupyter_client 6.1.7. jupyter_core 4.6.3. notebook 6.1.4. -----. Python 3.8.3 (default, May 19 2020, 13:54:14) [Clang 10.0.0 ]. macOS-10.15.7-x86_64-i386-64bit. 4 logical CPU cores, i386. -----. Session information updated at 2020-11-05 17:47. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1486
https://github.com/scverse/scanpy/issues/1486:2617,security,Session,Session,2617,"al-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_house'],. jitter=0.4, multi_panel=True). ```. ```pytb. /Users/banana/opt/miniconda3/lib/python3.8/site-packages/anndata/_core/anndata.py:1192: FutureWarning:. is_categorical is deprecated and will be removed in a future version. Use is_categorical_dtype instead. /Users/banana/opt/miniconda3/lib/python3.8/site-packages/seaborn/_core.py:1303: UserWarning:. Vertical orientation ignored with only `x` specified. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.4. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. anndata 0.7.4. appnope 0.1.0. attr 20.2.0. backcall 0.2.0. cffi 1.14.0. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 2.10.0. idna 2.9. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. joblib 0.17.0. jsonschema 3.2.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. llvmlite 0.34.0. matplotlib 3.3.2. mpl_toolkits NA. natsort 7.0.1. nbformat 5.0.8. numba 0.51.2. numexpr 2.7.1. numpy 1.19.1. packaging 20.4. pandas 1.1.2. parso 0.7.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotly 4.12.0. prompt_toolkit 3.0.8. ptyprocess 0.6.0. pvectorc NA. pygments 2.7.1. pyparsing 2.4.7. pyrsistent NA. pytz 2020.1. retrying NA. scanpy 1.6.0. scipy 1.5.2. seaborn 0.11.0. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. statsmodels 0.12.1. storemagic NA. tables 3.6.1. tornado 6.0.4. traitlets 5.0.5. wcwidth 0.2.5. zmq 19.0.2. -----. IPython 7.18.1. jupyter_client 6.1.7. jupyter_core 4.6.3. notebook 6.1.4. -----. Python 3.8.3 (default, May 19 2020, 13:54:14) [Clang 10.0.0 ]. macOS-10.15.7-x86_64-i386-64bit. 4 logical CPU cores, i386. -----. Session information updated at 2020-11-05 17:47. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1486
https://github.com/scverse/scanpy/issues/1486:2637,security,updat,updated,2637,"al-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_house'],. jitter=0.4, multi_panel=True). ```. ```pytb. /Users/banana/opt/miniconda3/lib/python3.8/site-packages/anndata/_core/anndata.py:1192: FutureWarning:. is_categorical is deprecated and will be removed in a future version. Use is_categorical_dtype instead. /Users/banana/opt/miniconda3/lib/python3.8/site-packages/seaborn/_core.py:1303: UserWarning:. Vertical orientation ignored with only `x` specified. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.4. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. anndata 0.7.4. appnope 0.1.0. attr 20.2.0. backcall 0.2.0. cffi 1.14.0. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 2.10.0. idna 2.9. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. joblib 0.17.0. jsonschema 3.2.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. llvmlite 0.34.0. matplotlib 3.3.2. mpl_toolkits NA. natsort 7.0.1. nbformat 5.0.8. numba 0.51.2. numexpr 2.7.1. numpy 1.19.1. packaging 20.4. pandas 1.1.2. parso 0.7.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotly 4.12.0. prompt_toolkit 3.0.8. ptyprocess 0.6.0. pvectorc NA. pygments 2.7.1. pyparsing 2.4.7. pyrsistent NA. pytz 2020.1. retrying NA. scanpy 1.6.0. scipy 1.5.2. seaborn 0.11.0. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. statsmodels 0.12.1. storemagic NA. tables 3.6.1. tornado 6.0.4. traitlets 5.0.5. wcwidth 0.2.5. zmq 19.0.2. -----. IPython 7.18.1. jupyter_client 6.1.7. jupyter_core 4.6.3. notebook 6.1.4. -----. Python 3.8.3 (default, May 19 2020, 13:54:14) [Clang 10.0.0 ]. macOS-10.15.7-x86_64-i386-64bit. 4 logical CPU cores, i386. -----. Session information updated at 2020-11-05 17:47. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1486
https://github.com/scverse/scanpy/issues/1486:464,testability,observ,observable,464,"plotting data horizontal plots with shared axis; - [x ] I have checked that this issue has not already been reported. - [ x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. The problem here is that the violin plots are horizontal rather than vertical and that they share the same x-axis scale. Plotting two sets of numbers 10s vs 10,000s the 10s data are not observable. . This looks like a change in the way that seaborn wants violin plots called, based solely on the error below. . **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_house'],. jitter=0.4, multi_panel=True). ```. ```pytb. /Users/banana/opt/miniconda3/lib/python3.8/site-packages/anndata/_core/anndata.py:1192: FutureWarning:. is_categorical is deprecated and will be removed in a future version. Use is_categorical_dtype instead. /Users/banana/opt/miniconda3/lib/python3.8/site-packages/seaborn/_core.py:1303: UserWarning:. Vertical orientation ignored with only `x` specified. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.4. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. anndata 0.7.4. appnope 0.1.0. attr 20.2.0. backcall 0.2.0. cffi 1.14.0. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 2.10.0. idna 2.9. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. joblib 0.17.0. jsonschema 3.2.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. llvmlite 0.34.0. matplotlib 3.3.2. mpl_toolkits NA. natsort 7.0.1. nbformat 5.0.8. numba 0.51.2. numexpr 2.7.1. numpy 1.19.1. packaging 20.4. pandas 1.1.2. parso 0.7.1. pexpec",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1486
https://github.com/scverse/scanpy/issues/1486:2585,testability,log,logical,2585,"al-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_house'],. jitter=0.4, multi_panel=True). ```. ```pytb. /Users/banana/opt/miniconda3/lib/python3.8/site-packages/anndata/_core/anndata.py:1192: FutureWarning:. is_categorical is deprecated and will be removed in a future version. Use is_categorical_dtype instead. /Users/banana/opt/miniconda3/lib/python3.8/site-packages/seaborn/_core.py:1303: UserWarning:. Vertical orientation ignored with only `x` specified. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.4. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. anndata 0.7.4. appnope 0.1.0. attr 20.2.0. backcall 0.2.0. cffi 1.14.0. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 2.10.0. idna 2.9. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. joblib 0.17.0. jsonschema 3.2.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. llvmlite 0.34.0. matplotlib 3.3.2. mpl_toolkits NA. natsort 7.0.1. nbformat 5.0.8. numba 0.51.2. numexpr 2.7.1. numpy 1.19.1. packaging 20.4. pandas 1.1.2. parso 0.7.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotly 4.12.0. prompt_toolkit 3.0.8. ptyprocess 0.6.0. pvectorc NA. pygments 2.7.1. pyparsing 2.4.7. pyrsistent NA. pytz 2020.1. retrying NA. scanpy 1.6.0. scipy 1.5.2. seaborn 0.11.0. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. statsmodels 0.12.1. storemagic NA. tables 3.6.1. tornado 6.0.4. traitlets 5.0.5. wcwidth 0.2.5. zmq 19.0.2. -----. IPython 7.18.1. jupyter_client 6.1.7. jupyter_core 4.6.3. notebook 6.1.4. -----. Python 3.8.3 (default, May 19 2020, 13:54:14) [Clang 10.0.0 ]. macOS-10.15.7-x86_64-i386-64bit. 4 logical CPU cores, i386. -----. Session information updated at 2020-11-05 17:47. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1486
https://github.com/scverse/scanpy/issues/1486:132,usability,confirm,confirmed,132,"plotting data horizontal plots with shared axis; - [x ] I have checked that this issue has not already been reported. - [ x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. The problem here is that the violin plots are horizontal rather than vertical and that they share the same x-axis scale. Plotting two sets of numbers 10s vs 10,000s the 10s data are not observable. . This looks like a change in the way that seaborn wants violin plots called, based solely on the error below. . **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_house'],. jitter=0.4, multi_panel=True). ```. ```pytb. /Users/banana/opt/miniconda3/lib/python3.8/site-packages/anndata/_core/anndata.py:1192: FutureWarning:. is_categorical is deprecated and will be removed in a future version. Use is_categorical_dtype instead. /Users/banana/opt/miniconda3/lib/python3.8/site-packages/seaborn/_core.py:1303: UserWarning:. Vertical orientation ignored with only `x` specified. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.4. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. anndata 0.7.4. appnope 0.1.0. attr 20.2.0. backcall 0.2.0. cffi 1.14.0. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 2.10.0. idna 2.9. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. joblib 0.17.0. jsonschema 3.2.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. llvmlite 0.34.0. matplotlib 3.3.2. mpl_toolkits NA. natsort 7.0.1. nbformat 5.0.8. numba 0.51.2. numexpr 2.7.1. numpy 1.19.1. packaging 20.4. pandas 1.1.2. parso 0.7.1. pexpec",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1486
https://github.com/scverse/scanpy/issues/1486:215,usability,confirm,confirmed,215,"plotting data horizontal plots with shared axis; - [x ] I have checked that this issue has not already been reported. - [ x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. The problem here is that the violin plots are horizontal rather than vertical and that they share the same x-axis scale. Plotting two sets of numbers 10s vs 10,000s the 10s data are not observable. . This looks like a change in the way that seaborn wants violin plots called, based solely on the error below. . **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_house'],. jitter=0.4, multi_panel=True). ```. ```pytb. /Users/banana/opt/miniconda3/lib/python3.8/site-packages/anndata/_core/anndata.py:1192: FutureWarning:. is_categorical is deprecated and will be removed in a future version. Use is_categorical_dtype instead. /Users/banana/opt/miniconda3/lib/python3.8/site-packages/seaborn/_core.py:1303: UserWarning:. Vertical orientation ignored with only `x` specified. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.4. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. anndata 0.7.4. appnope 0.1.0. attr 20.2.0. backcall 0.2.0. cffi 1.14.0. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 2.10.0. idna 2.9. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. joblib 0.17.0. jsonschema 3.2.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. llvmlite 0.34.0. matplotlib 3.3.2. mpl_toolkits NA. natsort 7.0.1. nbformat 5.0.8. numba 0.51.2. numexpr 2.7.1. numpy 1.19.1. packaging 20.4. pandas 1.1.2. parso 0.7.1. pexpec",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1486
https://github.com/scverse/scanpy/issues/1486:574,usability,error,error,574,"plotting data horizontal plots with shared axis; - [x ] I have checked that this issue has not already been reported. - [ x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. The problem here is that the violin plots are horizontal rather than vertical and that they share the same x-axis scale. Plotting two sets of numbers 10s vs 10,000s the 10s data are not observable. . This looks like a change in the way that seaborn wants violin plots called, based solely on the error below. . **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_house'],. jitter=0.4, multi_panel=True). ```. ```pytb. /Users/banana/opt/miniconda3/lib/python3.8/site-packages/anndata/_core/anndata.py:1192: FutureWarning:. is_categorical is deprecated and will be removed in a future version. Use is_categorical_dtype instead. /Users/banana/opt/miniconda3/lib/python3.8/site-packages/seaborn/_core.py:1303: UserWarning:. Vertical orientation ignored with only `x` specified. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.4. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. anndata 0.7.4. appnope 0.1.0. attr 20.2.0. backcall 0.2.0. cffi 1.14.0. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 2.10.0. idna 2.9. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. joblib 0.17.0. jsonschema 3.2.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. llvmlite 0.34.0. matplotlib 3.3.2. mpl_toolkits NA. natsort 7.0.1. nbformat 5.0.8. numba 0.51.2. numexpr 2.7.1. numpy 1.19.1. packaging 20.4. pandas 1.1.2. parso 0.7.1. pexpec",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1486
https://github.com/scverse/scanpy/issues/1486:617,usability,guid,guide,617,"plotting data horizontal plots with shared axis; - [x ] I have checked that this issue has not already been reported. - [ x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. The problem here is that the violin plots are horizontal rather than vertical and that they share the same x-axis scale. Plotting two sets of numbers 10s vs 10,000s the 10s data are not observable. . This looks like a change in the way that seaborn wants violin plots called, based solely on the error below. . **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_house'],. jitter=0.4, multi_panel=True). ```. ```pytb. /Users/banana/opt/miniconda3/lib/python3.8/site-packages/anndata/_core/anndata.py:1192: FutureWarning:. is_categorical is deprecated and will be removed in a future version. Use is_categorical_dtype instead. /Users/banana/opt/miniconda3/lib/python3.8/site-packages/seaborn/_core.py:1303: UserWarning:. Vertical orientation ignored with only `x` specified. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.4. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. anndata 0.7.4. appnope 0.1.0. attr 20.2.0. backcall 0.2.0. cffi 1.14.0. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 2.10.0. idna 2.9. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. joblib 0.17.0. jsonschema 3.2.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. llvmlite 0.34.0. matplotlib 3.3.2. mpl_toolkits NA. natsort 7.0.1. nbformat 5.0.8. numba 0.51.2. numexpr 2.7.1. numpy 1.19.1. packaging 20.4. pandas 1.1.2. parso 0.7.1. pexpec",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1486
https://github.com/scverse/scanpy/issues/1486:672,usability,minim,minimal-bug-reports,672,"plotting data horizontal plots with shared axis; - [x ] I have checked that this issue has not already been reported. - [ x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. The problem here is that the violin plots are horizontal rather than vertical and that they share the same x-axis scale. Plotting two sets of numbers 10s vs 10,000s the 10s data are not observable. . This looks like a change in the way that seaborn wants violin plots called, based solely on the error below. . **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_house'],. jitter=0.4, multi_panel=True). ```. ```pytb. /Users/banana/opt/miniconda3/lib/python3.8/site-packages/anndata/_core/anndata.py:1192: FutureWarning:. is_categorical is deprecated and will be removed in a future version. Use is_categorical_dtype instead. /Users/banana/opt/miniconda3/lib/python3.8/site-packages/seaborn/_core.py:1303: UserWarning:. Vertical orientation ignored with only `x` specified. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.4. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. anndata 0.7.4. appnope 0.1.0. attr 20.2.0. backcall 0.2.0. cffi 1.14.0. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 2.10.0. idna 2.9. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. joblib 0.17.0. jsonschema 3.2.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. llvmlite 0.34.0. matplotlib 3.3.2. mpl_toolkits NA. natsort 7.0.1. nbformat 5.0.8. numba 0.51.2. numexpr 2.7.1. numpy 1.19.1. packaging 20.4. pandas 1.1.2. parso 0.7.1. pexpec",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1486
https://github.com/scverse/scanpy/issues/1486:778,usability,Minim,Minimal,778,"plotting data horizontal plots with shared axis; - [x ] I have checked that this issue has not already been reported. - [ x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. The problem here is that the violin plots are horizontal rather than vertical and that they share the same x-axis scale. Plotting two sets of numbers 10s vs 10,000s the 10s data are not observable. . This looks like a change in the way that seaborn wants violin plots called, based solely on the error below. . **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_house'],. jitter=0.4, multi_panel=True). ```. ```pytb. /Users/banana/opt/miniconda3/lib/python3.8/site-packages/anndata/_core/anndata.py:1192: FutureWarning:. is_categorical is deprecated and will be removed in a future version. Use is_categorical_dtype instead. /Users/banana/opt/miniconda3/lib/python3.8/site-packages/seaborn/_core.py:1303: UserWarning:. Vertical orientation ignored with only `x` specified. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.4. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. anndata 0.7.4. appnope 0.1.0. attr 20.2.0. backcall 0.2.0. cffi 1.14.0. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 2.10.0. idna 2.9. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. joblib 0.17.0. jsonschema 3.2.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. llvmlite 0.34.0. matplotlib 3.3.2. mpl_toolkits NA. natsort 7.0.1. nbformat 5.0.8. numba 0.51.2. numexpr 2.7.1. numpy 1.19.1. packaging 20.4. pandas 1.1.2. parso 0.7.1. pexpec",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1486
https://github.com/scverse/scanpy/issues/1486:985,usability,User,Users,985,"plotting data horizontal plots with shared axis; - [x ] I have checked that this issue has not already been reported. - [ x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. The problem here is that the violin plots are horizontal rather than vertical and that they share the same x-axis scale. Plotting two sets of numbers 10s vs 10,000s the 10s data are not observable. . This looks like a change in the way that seaborn wants violin plots called, based solely on the error below. . **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_house'],. jitter=0.4, multi_panel=True). ```. ```pytb. /Users/banana/opt/miniconda3/lib/python3.8/site-packages/anndata/_core/anndata.py:1192: FutureWarning:. is_categorical is deprecated and will be removed in a future version. Use is_categorical_dtype instead. /Users/banana/opt/miniconda3/lib/python3.8/site-packages/seaborn/_core.py:1303: UserWarning:. Vertical orientation ignored with only `x` specified. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.4. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. anndata 0.7.4. appnope 0.1.0. attr 20.2.0. backcall 0.2.0. cffi 1.14.0. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 2.10.0. idna 2.9. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. joblib 0.17.0. jsonschema 3.2.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. llvmlite 0.34.0. matplotlib 3.3.2. mpl_toolkits NA. natsort 7.0.1. nbformat 5.0.8. numba 0.51.2. numexpr 2.7.1. numpy 1.19.1. packaging 20.4. pandas 1.1.2. parso 0.7.1. pexpec",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1486
https://github.com/scverse/scanpy/issues/1486:1193,usability,User,Users,1193," (optional) I have confirmed this bug exists on the master branch of scanpy. ---. The problem here is that the violin plots are horizontal rather than vertical and that they share the same x-axis scale. Plotting two sets of numbers 10s vs 10,000s the 10s data are not observable. . This looks like a change in the way that seaborn wants violin plots called, based solely on the error below. . **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_house'],. jitter=0.4, multi_panel=True). ```. ```pytb. /Users/banana/opt/miniconda3/lib/python3.8/site-packages/anndata/_core/anndata.py:1192: FutureWarning:. is_categorical is deprecated and will be removed in a future version. Use is_categorical_dtype instead. /Users/banana/opt/miniconda3/lib/python3.8/site-packages/seaborn/_core.py:1303: UserWarning:. Vertical orientation ignored with only `x` specified. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.4. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. anndata 0.7.4. appnope 0.1.0. attr 20.2.0. backcall 0.2.0. cffi 1.14.0. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 2.10.0. idna 2.9. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. joblib 0.17.0. jsonschema 3.2.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. llvmlite 0.34.0. matplotlib 3.3.2. mpl_toolkits NA. natsort 7.0.1. nbformat 5.0.8. numba 0.51.2. numexpr 2.7.1. numpy 1.19.1. packaging 20.4. pandas 1.1.2. parso 0.7.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotly 4.12.0. prompt_toolkit 3.0.8. ptyprocess 0.6.0. pvectorc NA. pygments 2.7.1. pyparsing 2.4.7. pyrsistent NA. pytz 2020.1. retrying NA. scanpy 1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1486
https://github.com/scverse/scanpy/issues/1486:1272,usability,User,UserWarning,1272,"The problem here is that the violin plots are horizontal rather than vertical and that they share the same x-axis scale. Plotting two sets of numbers 10s vs 10,000s the 10s data are not observable. . This looks like a change in the way that seaborn wants violin plots called, based solely on the error below. . **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_house'],. jitter=0.4, multi_panel=True). ```. ```pytb. /Users/banana/opt/miniconda3/lib/python3.8/site-packages/anndata/_core/anndata.py:1192: FutureWarning:. is_categorical is deprecated and will be removed in a future version. Use is_categorical_dtype instead. /Users/banana/opt/miniconda3/lib/python3.8/site-packages/seaborn/_core.py:1303: UserWarning:. Vertical orientation ignored with only `x` specified. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.4. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. anndata 0.7.4. appnope 0.1.0. attr 20.2.0. backcall 0.2.0. cffi 1.14.0. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. get_version 2.1. h5py 2.10.0. idna 2.9. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. joblib 0.17.0. jsonschema 3.2.0. kiwisolver 1.2.0. legacy_api_wrap 1.2. llvmlite 0.34.0. matplotlib 3.3.2. mpl_toolkits NA. natsort 7.0.1. nbformat 5.0.8. numba 0.51.2. numexpr 2.7.1. numpy 1.19.1. packaging 20.4. pandas 1.1.2. parso 0.7.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotly 4.12.0. prompt_toolkit 3.0.8. ptyprocess 0.6.0. pvectorc NA. pygments 2.7.1. pyparsing 2.4.7. pyrsistent NA. pytz 2020.1. retrying NA. scanpy 1.6.0. scipy 1.5.2. seaborn 0.11.0. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. skl",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1486
https://github.com/scverse/scanpy/issues/1487:382,availability,error,error,382,"f""Values {list(not_found)}, from {list(indexer)}, "" ""are not valid obs/ var names or indices.""; This bug only occurred in 1.6.0 but not 1.5.0. I was running `scanpy 1.6.0` this:. `sc.tl.filter_rank_genes_groups(adata, groupby=obs,\. max_out_group_fraction=max_out_group_fraction,. min_fold_change=min_fold_change,use_raw=use_raw,. min_in_group_fraction=0.25,log=log)`. But got this error:. ```. Filtering genes using: min_in_group_fraction: 0.25 min_fold_change: 2, max_out_group_fraction: 0.25. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-91-d477dca208af> in <module>. 2 max_out_group_fraction=max_out_group_fraction,. 3 min_fold_change=min_fold_change,use_raw=use_raw,. ----> 4 min_in_group_fraction=0.25,log=log). /usr/local/lib/python3.6/dist-packages/scanpy/tools/_rank_genes_groups.py in filter_rank_genes_groups(adata, key, groupby, use_raw, log, key_added, min_in_group_fraction, min_fold_change, max_out_group_fraction). 725 var_names,. 726 groupby='__is_in_cluster__',. --> 727 use_raw=use_raw,. 728 ). 729 . /usr/local/lib/python3.6/dist-packages/scanpy/plotting/_anndata.py in _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer, gene_symbols). 1808 matrix = adata.raw[:, var_names].X. 1809 else:. -> 1810 matrix = adata[:, var_names].X. 1811 . 1812 if issparse(matrix):. /usr/local/lib/python3.6/dist-packages/anndata/_core/anndata.py in __getitem__(self, index). 1085 def __getitem__(self, index: Index) -> ""AnnData"":. 1086 """"""Returns a sliced view of the object."""""". -> 1087 oidx, vidx = self._normalize_indices(index). 1088 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1089 . /usr/local/lib/python3.6/dist-packages/anndata/_core/anndata.py in _normalize_indices(self, index). 1066 . 1067 def _normalize_indices(self, index: Optional[Index]) -> Tuple[slice, slice]:. -> 1068 return _normalize_indices(index, self.obs_names, self.var_names). 1069 . 107",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1487
https://github.com/scverse/scanpy/issues/1487:1573,availability,sli,sliced,1573,"Error Traceback (most recent call last). <ipython-input-91-d477dca208af> in <module>. 2 max_out_group_fraction=max_out_group_fraction,. 3 min_fold_change=min_fold_change,use_raw=use_raw,. ----> 4 min_in_group_fraction=0.25,log=log). /usr/local/lib/python3.6/dist-packages/scanpy/tools/_rank_genes_groups.py in filter_rank_genes_groups(adata, key, groupby, use_raw, log, key_added, min_in_group_fraction, min_fold_change, max_out_group_fraction). 725 var_names,. 726 groupby='__is_in_cluster__',. --> 727 use_raw=use_raw,. 728 ). 729 . /usr/local/lib/python3.6/dist-packages/scanpy/plotting/_anndata.py in _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer, gene_symbols). 1808 matrix = adata.raw[:, var_names].X. 1809 else:. -> 1810 matrix = adata[:, var_names].X. 1811 . 1812 if issparse(matrix):. /usr/local/lib/python3.6/dist-packages/anndata/_core/anndata.py in __getitem__(self, index). 1085 def __getitem__(self, index: Index) -> ""AnnData"":. 1086 """"""Returns a sliced view of the object."""""". -> 1087 oidx, vidx = self._normalize_indices(index). 1088 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1089 . /usr/local/lib/python3.6/dist-packages/anndata/_core/anndata.py in _normalize_indices(self, index). 1066 . 1067 def _normalize_indices(self, index: Optional[Index]) -> Tuple[slice, slice]:. -> 1068 return _normalize_indices(index, self.obs_names, self.var_names). 1069 . 1070 # TODO: this is not quite complete... /usr/local/lib/python3.6/dist-packages/anndata/_core/index.py in _normalize_indices(index, names0, names1). 33 ax0, ax1 = unpack_index(index). 34 ax0 = _normalize_index(ax0, names0). ---> 35 ax1 = _normalize_index(ax1, names1). 36 return ax0, ax1. 37 . /usr/local/lib/python3.6/dist-packages/anndata/_core/index.py in _normalize_index(indexer, index). 99 not_found = indexer[positions < 0]. 100 raise KeyError(. --> 101 f""Values {list(not_found)}, from {list(indexer)}, "". 102 ""are not valid obs/ var names or indices."". 103 ). KeyError",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1487
https://github.com/scverse/scanpy/issues/1487:1900,availability,sli,slice,1900,"in_fold_change,use_raw=use_raw,. ----> 4 min_in_group_fraction=0.25,log=log). /usr/local/lib/python3.6/dist-packages/scanpy/tools/_rank_genes_groups.py in filter_rank_genes_groups(adata, key, groupby, use_raw, log, key_added, min_in_group_fraction, min_fold_change, max_out_group_fraction). 725 var_names,. 726 groupby='__is_in_cluster__',. --> 727 use_raw=use_raw,. 728 ). 729 . /usr/local/lib/python3.6/dist-packages/scanpy/plotting/_anndata.py in _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer, gene_symbols). 1808 matrix = adata.raw[:, var_names].X. 1809 else:. -> 1810 matrix = adata[:, var_names].X. 1811 . 1812 if issparse(matrix):. /usr/local/lib/python3.6/dist-packages/anndata/_core/anndata.py in __getitem__(self, index). 1085 def __getitem__(self, index: Index) -> ""AnnData"":. 1086 """"""Returns a sliced view of the object."""""". -> 1087 oidx, vidx = self._normalize_indices(index). 1088 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1089 . /usr/local/lib/python3.6/dist-packages/anndata/_core/anndata.py in _normalize_indices(self, index). 1066 . 1067 def _normalize_indices(self, index: Optional[Index]) -> Tuple[slice, slice]:. -> 1068 return _normalize_indices(index, self.obs_names, self.var_names). 1069 . 1070 # TODO: this is not quite complete... /usr/local/lib/python3.6/dist-packages/anndata/_core/index.py in _normalize_indices(index, names0, names1). 33 ax0, ax1 = unpack_index(index). 34 ax0 = _normalize_index(ax0, names0). ---> 35 ax1 = _normalize_index(ax1, names1). 36 return ax0, ax1. 37 . /usr/local/lib/python3.6/dist-packages/anndata/_core/index.py in _normalize_index(indexer, index). 99 not_found = indexer[positions < 0]. 100 raise KeyError(. --> 101 f""Values {list(not_found)}, from {list(indexer)}, "". 102 ""are not valid obs/ var names or indices."". 103 ). KeyError: ""Values ['LINC00601', 'DPYS', 'AC136604.2', 'AC023137.1', 'MATN3', 'AL359921.1' . ... 'FAM129C', 'TCL1A'], are not valid obs/ var names or indices."". ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1487
https://github.com/scverse/scanpy/issues/1487:1907,availability,sli,slice,1907,"in_fold_change,use_raw=use_raw,. ----> 4 min_in_group_fraction=0.25,log=log). /usr/local/lib/python3.6/dist-packages/scanpy/tools/_rank_genes_groups.py in filter_rank_genes_groups(adata, key, groupby, use_raw, log, key_added, min_in_group_fraction, min_fold_change, max_out_group_fraction). 725 var_names,. 726 groupby='__is_in_cluster__',. --> 727 use_raw=use_raw,. 728 ). 729 . /usr/local/lib/python3.6/dist-packages/scanpy/plotting/_anndata.py in _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer, gene_symbols). 1808 matrix = adata.raw[:, var_names].X. 1809 else:. -> 1810 matrix = adata[:, var_names].X. 1811 . 1812 if issparse(matrix):. /usr/local/lib/python3.6/dist-packages/anndata/_core/anndata.py in __getitem__(self, index). 1085 def __getitem__(self, index: Index) -> ""AnnData"":. 1086 """"""Returns a sliced view of the object."""""". -> 1087 oidx, vidx = self._normalize_indices(index). 1088 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1089 . /usr/local/lib/python3.6/dist-packages/anndata/_core/anndata.py in _normalize_indices(self, index). 1066 . 1067 def _normalize_indices(self, index: Optional[Index]) -> Tuple[slice, slice]:. -> 1068 return _normalize_indices(index, self.obs_names, self.var_names). 1069 . 1070 # TODO: this is not quite complete... /usr/local/lib/python3.6/dist-packages/anndata/_core/index.py in _normalize_indices(index, names0, names1). 33 ax0, ax1 = unpack_index(index). 34 ax0 = _normalize_index(ax0, names0). ---> 35 ax1 = _normalize_index(ax1, names1). 36 return ax0, ax1. 37 . /usr/local/lib/python3.6/dist-packages/anndata/_core/index.py in _normalize_index(indexer, index). 99 not_found = indexer[positions < 0]. 100 raise KeyError(. --> 101 f""Values {list(not_found)}, from {list(indexer)}, "". 102 ""are not valid obs/ var names or indices."". 103 ). KeyError: ""Values ['LINC00601', 'DPYS', 'AC136604.2', 'AC023137.1', 'MATN3', 'AL359921.1' . ... 'FAM129C', 'TCL1A'], are not valid obs/ var names or indices."". ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1487
https://github.com/scverse/scanpy/issues/1487:358,deployability,log,log,358,"f""Values {list(not_found)}, from {list(indexer)}, "" ""are not valid obs/ var names or indices.""; This bug only occurred in 1.6.0 but not 1.5.0. I was running `scanpy 1.6.0` this:. `sc.tl.filter_rank_genes_groups(adata, groupby=obs,\. max_out_group_fraction=max_out_group_fraction,. min_fold_change=min_fold_change,use_raw=use_raw,. min_in_group_fraction=0.25,log=log)`. But got this error:. ```. Filtering genes using: min_in_group_fraction: 0.25 min_fold_change: 2, max_out_group_fraction: 0.25. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-91-d477dca208af> in <module>. 2 max_out_group_fraction=max_out_group_fraction,. 3 min_fold_change=min_fold_change,use_raw=use_raw,. ----> 4 min_in_group_fraction=0.25,log=log). /usr/local/lib/python3.6/dist-packages/scanpy/tools/_rank_genes_groups.py in filter_rank_genes_groups(adata, key, groupby, use_raw, log, key_added, min_in_group_fraction, min_fold_change, max_out_group_fraction). 725 var_names,. 726 groupby='__is_in_cluster__',. --> 727 use_raw=use_raw,. 728 ). 729 . /usr/local/lib/python3.6/dist-packages/scanpy/plotting/_anndata.py in _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer, gene_symbols). 1808 matrix = adata.raw[:, var_names].X. 1809 else:. -> 1810 matrix = adata[:, var_names].X. 1811 . 1812 if issparse(matrix):. /usr/local/lib/python3.6/dist-packages/anndata/_core/anndata.py in __getitem__(self, index). 1085 def __getitem__(self, index: Index) -> ""AnnData"":. 1086 """"""Returns a sliced view of the object."""""". -> 1087 oidx, vidx = self._normalize_indices(index). 1088 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1089 . /usr/local/lib/python3.6/dist-packages/anndata/_core/anndata.py in _normalize_indices(self, index). 1066 . 1067 def _normalize_indices(self, index: Optional[Index]) -> Tuple[slice, slice]:. -> 1068 return _normalize_indices(index, self.obs_names, self.var_names). 1069 . 107",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1487
https://github.com/scverse/scanpy/issues/1487:362,deployability,log,log,362,"f""Values {list(not_found)}, from {list(indexer)}, "" ""are not valid obs/ var names or indices.""; This bug only occurred in 1.6.0 but not 1.5.0. I was running `scanpy 1.6.0` this:. `sc.tl.filter_rank_genes_groups(adata, groupby=obs,\. max_out_group_fraction=max_out_group_fraction,. min_fold_change=min_fold_change,use_raw=use_raw,. min_in_group_fraction=0.25,log=log)`. But got this error:. ```. Filtering genes using: min_in_group_fraction: 0.25 min_fold_change: 2, max_out_group_fraction: 0.25. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-91-d477dca208af> in <module>. 2 max_out_group_fraction=max_out_group_fraction,. 3 min_fold_change=min_fold_change,use_raw=use_raw,. ----> 4 min_in_group_fraction=0.25,log=log). /usr/local/lib/python3.6/dist-packages/scanpy/tools/_rank_genes_groups.py in filter_rank_genes_groups(adata, key, groupby, use_raw, log, key_added, min_in_group_fraction, min_fold_change, max_out_group_fraction). 725 var_names,. 726 groupby='__is_in_cluster__',. --> 727 use_raw=use_raw,. 728 ). 729 . /usr/local/lib/python3.6/dist-packages/scanpy/plotting/_anndata.py in _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer, gene_symbols). 1808 matrix = adata.raw[:, var_names].X. 1809 else:. -> 1810 matrix = adata[:, var_names].X. 1811 . 1812 if issparse(matrix):. /usr/local/lib/python3.6/dist-packages/anndata/_core/anndata.py in __getitem__(self, index). 1085 def __getitem__(self, index: Index) -> ""AnnData"":. 1086 """"""Returns a sliced view of the object."""""". -> 1087 oidx, vidx = self._normalize_indices(index). 1088 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1089 . /usr/local/lib/python3.6/dist-packages/anndata/_core/anndata.py in _normalize_indices(self, index). 1066 . 1067 def _normalize_indices(self, index: Optional[Index]) -> Tuple[slice, slice]:. -> 1068 return _normalize_indices(index, self.obs_names, self.var_names). 1069 . 107",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1487
https://github.com/scverse/scanpy/issues/1487:653,deployability,modul,module,653,"f""Values {list(not_found)}, from {list(indexer)}, "" ""are not valid obs/ var names or indices.""; This bug only occurred in 1.6.0 but not 1.5.0. I was running `scanpy 1.6.0` this:. `sc.tl.filter_rank_genes_groups(adata, groupby=obs,\. max_out_group_fraction=max_out_group_fraction,. min_fold_change=min_fold_change,use_raw=use_raw,. min_in_group_fraction=0.25,log=log)`. But got this error:. ```. Filtering genes using: min_in_group_fraction: 0.25 min_fold_change: 2, max_out_group_fraction: 0.25. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-91-d477dca208af> in <module>. 2 max_out_group_fraction=max_out_group_fraction,. 3 min_fold_change=min_fold_change,use_raw=use_raw,. ----> 4 min_in_group_fraction=0.25,log=log). /usr/local/lib/python3.6/dist-packages/scanpy/tools/_rank_genes_groups.py in filter_rank_genes_groups(adata, key, groupby, use_raw, log, key_added, min_in_group_fraction, min_fold_change, max_out_group_fraction). 725 var_names,. 726 groupby='__is_in_cluster__',. --> 727 use_raw=use_raw,. 728 ). 729 . /usr/local/lib/python3.6/dist-packages/scanpy/plotting/_anndata.py in _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer, gene_symbols). 1808 matrix = adata.raw[:, var_names].X. 1809 else:. -> 1810 matrix = adata[:, var_names].X. 1811 . 1812 if issparse(matrix):. /usr/local/lib/python3.6/dist-packages/anndata/_core/anndata.py in __getitem__(self, index). 1085 def __getitem__(self, index: Index) -> ""AnnData"":. 1086 """"""Returns a sliced view of the object."""""". -> 1087 oidx, vidx = self._normalize_indices(index). 1088 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1089 . /usr/local/lib/python3.6/dist-packages/anndata/_core/anndata.py in _normalize_indices(self, index). 1066 . 1067 def _normalize_indices(self, index: Optional[Index]) -> Tuple[slice, slice]:. -> 1068 return _normalize_indices(index, self.obs_names, self.var_names). 1069 . 107",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1487
https://github.com/scverse/scanpy/issues/1487:799,deployability,log,log,799,"f""Values {list(not_found)}, from {list(indexer)}, "" ""are not valid obs/ var names or indices.""; This bug only occurred in 1.6.0 but not 1.5.0. I was running `scanpy 1.6.0` this:. `sc.tl.filter_rank_genes_groups(adata, groupby=obs,\. max_out_group_fraction=max_out_group_fraction,. min_fold_change=min_fold_change,use_raw=use_raw,. min_in_group_fraction=0.25,log=log)`. But got this error:. ```. Filtering genes using: min_in_group_fraction: 0.25 min_fold_change: 2, max_out_group_fraction: 0.25. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-91-d477dca208af> in <module>. 2 max_out_group_fraction=max_out_group_fraction,. 3 min_fold_change=min_fold_change,use_raw=use_raw,. ----> 4 min_in_group_fraction=0.25,log=log). /usr/local/lib/python3.6/dist-packages/scanpy/tools/_rank_genes_groups.py in filter_rank_genes_groups(adata, key, groupby, use_raw, log, key_added, min_in_group_fraction, min_fold_change, max_out_group_fraction). 725 var_names,. 726 groupby='__is_in_cluster__',. --> 727 use_raw=use_raw,. 728 ). 729 . /usr/local/lib/python3.6/dist-packages/scanpy/plotting/_anndata.py in _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer, gene_symbols). 1808 matrix = adata.raw[:, var_names].X. 1809 else:. -> 1810 matrix = adata[:, var_names].X. 1811 . 1812 if issparse(matrix):. /usr/local/lib/python3.6/dist-packages/anndata/_core/anndata.py in __getitem__(self, index). 1085 def __getitem__(self, index: Index) -> ""AnnData"":. 1086 """"""Returns a sliced view of the object."""""". -> 1087 oidx, vidx = self._normalize_indices(index). 1088 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1089 . /usr/local/lib/python3.6/dist-packages/anndata/_core/anndata.py in _normalize_indices(self, index). 1066 . 1067 def _normalize_indices(self, index: Optional[Index]) -> Tuple[slice, slice]:. -> 1068 return _normalize_indices(index, self.obs_names, self.var_names). 1069 . 107",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1487
https://github.com/scverse/scanpy/issues/1487:803,deployability,log,log,803,"f""Values {list(not_found)}, from {list(indexer)}, "" ""are not valid obs/ var names or indices.""; This bug only occurred in 1.6.0 but not 1.5.0. I was running `scanpy 1.6.0` this:. `sc.tl.filter_rank_genes_groups(adata, groupby=obs,\. max_out_group_fraction=max_out_group_fraction,. min_fold_change=min_fold_change,use_raw=use_raw,. min_in_group_fraction=0.25,log=log)`. But got this error:. ```. Filtering genes using: min_in_group_fraction: 0.25 min_fold_change: 2, max_out_group_fraction: 0.25. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-91-d477dca208af> in <module>. 2 max_out_group_fraction=max_out_group_fraction,. 3 min_fold_change=min_fold_change,use_raw=use_raw,. ----> 4 min_in_group_fraction=0.25,log=log). /usr/local/lib/python3.6/dist-packages/scanpy/tools/_rank_genes_groups.py in filter_rank_genes_groups(adata, key, groupby, use_raw, log, key_added, min_in_group_fraction, min_fold_change, max_out_group_fraction). 725 var_names,. 726 groupby='__is_in_cluster__',. --> 727 use_raw=use_raw,. 728 ). 729 . /usr/local/lib/python3.6/dist-packages/scanpy/plotting/_anndata.py in _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer, gene_symbols). 1808 matrix = adata.raw[:, var_names].X. 1809 else:. -> 1810 matrix = adata[:, var_names].X. 1811 . 1812 if issparse(matrix):. /usr/local/lib/python3.6/dist-packages/anndata/_core/anndata.py in __getitem__(self, index). 1085 def __getitem__(self, index: Index) -> ""AnnData"":. 1086 """"""Returns a sliced view of the object."""""". -> 1087 oidx, vidx = self._normalize_indices(index). 1088 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1089 . /usr/local/lib/python3.6/dist-packages/anndata/_core/anndata.py in _normalize_indices(self, index). 1066 . 1067 def _normalize_indices(self, index: Optional[Index]) -> Tuple[slice, slice]:. -> 1068 return _normalize_indices(index, self.obs_names, self.var_names). 1069 . 107",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1487
https://github.com/scverse/scanpy/issues/1487:941,deployability,log,log,941,"f""Values {list(not_found)}, from {list(indexer)}, "" ""are not valid obs/ var names or indices.""; This bug only occurred in 1.6.0 but not 1.5.0. I was running `scanpy 1.6.0` this:. `sc.tl.filter_rank_genes_groups(adata, groupby=obs,\. max_out_group_fraction=max_out_group_fraction,. min_fold_change=min_fold_change,use_raw=use_raw,. min_in_group_fraction=0.25,log=log)`. But got this error:. ```. Filtering genes using: min_in_group_fraction: 0.25 min_fold_change: 2, max_out_group_fraction: 0.25. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-91-d477dca208af> in <module>. 2 max_out_group_fraction=max_out_group_fraction,. 3 min_fold_change=min_fold_change,use_raw=use_raw,. ----> 4 min_in_group_fraction=0.25,log=log). /usr/local/lib/python3.6/dist-packages/scanpy/tools/_rank_genes_groups.py in filter_rank_genes_groups(adata, key, groupby, use_raw, log, key_added, min_in_group_fraction, min_fold_change, max_out_group_fraction). 725 var_names,. 726 groupby='__is_in_cluster__',. --> 727 use_raw=use_raw,. 728 ). 729 . /usr/local/lib/python3.6/dist-packages/scanpy/plotting/_anndata.py in _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer, gene_symbols). 1808 matrix = adata.raw[:, var_names].X. 1809 else:. -> 1810 matrix = adata[:, var_names].X. 1811 . 1812 if issparse(matrix):. /usr/local/lib/python3.6/dist-packages/anndata/_core/anndata.py in __getitem__(self, index). 1085 def __getitem__(self, index: Index) -> ""AnnData"":. 1086 """"""Returns a sliced view of the object."""""". -> 1087 oidx, vidx = self._normalize_indices(index). 1088 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1089 . /usr/local/lib/python3.6/dist-packages/anndata/_core/anndata.py in _normalize_indices(self, index). 1066 . 1067 def _normalize_indices(self, index: Optional[Index]) -> Tuple[slice, slice]:. -> 1068 return _normalize_indices(index, self.obs_names, self.var_names). 1069 . 107",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1487
https://github.com/scverse/scanpy/issues/1487:1236,deployability,log,log,1236,"ut_group_fraction=max_out_group_fraction,. min_fold_change=min_fold_change,use_raw=use_raw,. min_in_group_fraction=0.25,log=log)`. But got this error:. ```. Filtering genes using: min_in_group_fraction: 0.25 min_fold_change: 2, max_out_group_fraction: 0.25. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-91-d477dca208af> in <module>. 2 max_out_group_fraction=max_out_group_fraction,. 3 min_fold_change=min_fold_change,use_raw=use_raw,. ----> 4 min_in_group_fraction=0.25,log=log). /usr/local/lib/python3.6/dist-packages/scanpy/tools/_rank_genes_groups.py in filter_rank_genes_groups(adata, key, groupby, use_raw, log, key_added, min_in_group_fraction, min_fold_change, max_out_group_fraction). 725 var_names,. 726 groupby='__is_in_cluster__',. --> 727 use_raw=use_raw,. 728 ). 729 . /usr/local/lib/python3.6/dist-packages/scanpy/plotting/_anndata.py in _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer, gene_symbols). 1808 matrix = adata.raw[:, var_names].X. 1809 else:. -> 1810 matrix = adata[:, var_names].X. 1811 . 1812 if issparse(matrix):. /usr/local/lib/python3.6/dist-packages/anndata/_core/anndata.py in __getitem__(self, index). 1085 def __getitem__(self, index: Index) -> ""AnnData"":. 1086 """"""Returns a sliced view of the object."""""". -> 1087 oidx, vidx = self._normalize_indices(index). 1088 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1089 . /usr/local/lib/python3.6/dist-packages/anndata/_core/anndata.py in _normalize_indices(self, index). 1066 . 1067 def _normalize_indices(self, index: Optional[Index]) -> Tuple[slice, slice]:. -> 1068 return _normalize_indices(index, self.obs_names, self.var_names). 1069 . 1070 # TODO: this is not quite complete... /usr/local/lib/python3.6/dist-packages/anndata/_core/index.py in _normalize_indices(index, names0, names1). 33 ax0, ax1 = unpack_index(index). 34 ax0 = _normalize_index(ax0, names0). ---> 35 ax1 = _",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1487
https://github.com/scverse/scanpy/issues/1487:395,integrability,Filter,Filtering,395,"f""Values {list(not_found)}, from {list(indexer)}, "" ""are not valid obs/ var names or indices.""; This bug only occurred in 1.6.0 but not 1.5.0. I was running `scanpy 1.6.0` this:. `sc.tl.filter_rank_genes_groups(adata, groupby=obs,\. max_out_group_fraction=max_out_group_fraction,. min_fold_change=min_fold_change,use_raw=use_raw,. min_in_group_fraction=0.25,log=log)`. But got this error:. ```. Filtering genes using: min_in_group_fraction: 0.25 min_fold_change: 2, max_out_group_fraction: 0.25. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-91-d477dca208af> in <module>. 2 max_out_group_fraction=max_out_group_fraction,. 3 min_fold_change=min_fold_change,use_raw=use_raw,. ----> 4 min_in_group_fraction=0.25,log=log). /usr/local/lib/python3.6/dist-packages/scanpy/tools/_rank_genes_groups.py in filter_rank_genes_groups(adata, key, groupby, use_raw, log, key_added, min_in_group_fraction, min_fold_change, max_out_group_fraction). 725 var_names,. 726 groupby='__is_in_cluster__',. --> 727 use_raw=use_raw,. 728 ). 729 . /usr/local/lib/python3.6/dist-packages/scanpy/plotting/_anndata.py in _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer, gene_symbols). 1808 matrix = adata.raw[:, var_names].X. 1809 else:. -> 1810 matrix = adata[:, var_names].X. 1811 . 1812 if issparse(matrix):. /usr/local/lib/python3.6/dist-packages/anndata/_core/anndata.py in __getitem__(self, index). 1085 def __getitem__(self, index: Index) -> ""AnnData"":. 1086 """"""Returns a sliced view of the object."""""". -> 1087 oidx, vidx = self._normalize_indices(index). 1088 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1089 . /usr/local/lib/python3.6/dist-packages/anndata/_core/anndata.py in _normalize_indices(self, index). 1066 . 1067 def _normalize_indices(self, index: Optional[Index]) -> Tuple[slice, slice]:. -> 1068 return _normalize_indices(index, self.obs_names, self.var_names). 1069 . 107",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1487
https://github.com/scverse/scanpy/issues/1487:653,modifiability,modul,module,653,"f""Values {list(not_found)}, from {list(indexer)}, "" ""are not valid obs/ var names or indices.""; This bug only occurred in 1.6.0 but not 1.5.0. I was running `scanpy 1.6.0` this:. `sc.tl.filter_rank_genes_groups(adata, groupby=obs,\. max_out_group_fraction=max_out_group_fraction,. min_fold_change=min_fold_change,use_raw=use_raw,. min_in_group_fraction=0.25,log=log)`. But got this error:. ```. Filtering genes using: min_in_group_fraction: 0.25 min_fold_change: 2, max_out_group_fraction: 0.25. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-91-d477dca208af> in <module>. 2 max_out_group_fraction=max_out_group_fraction,. 3 min_fold_change=min_fold_change,use_raw=use_raw,. ----> 4 min_in_group_fraction=0.25,log=log). /usr/local/lib/python3.6/dist-packages/scanpy/tools/_rank_genes_groups.py in filter_rank_genes_groups(adata, key, groupby, use_raw, log, key_added, min_in_group_fraction, min_fold_change, max_out_group_fraction). 725 var_names,. 726 groupby='__is_in_cluster__',. --> 727 use_raw=use_raw,. 728 ). 729 . /usr/local/lib/python3.6/dist-packages/scanpy/plotting/_anndata.py in _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer, gene_symbols). 1808 matrix = adata.raw[:, var_names].X. 1809 else:. -> 1810 matrix = adata[:, var_names].X. 1811 . 1812 if issparse(matrix):. /usr/local/lib/python3.6/dist-packages/anndata/_core/anndata.py in __getitem__(self, index). 1085 def __getitem__(self, index: Index) -> ""AnnData"":. 1086 """"""Returns a sliced view of the object."""""". -> 1087 oidx, vidx = self._normalize_indices(index). 1088 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1089 . /usr/local/lib/python3.6/dist-packages/anndata/_core/anndata.py in _normalize_indices(self, index). 1066 . 1067 def _normalize_indices(self, index: Optional[Index]) -> Tuple[slice, slice]:. -> 1068 return _normalize_indices(index, self.obs_names, self.var_names). 1069 . 107",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1487
https://github.com/scverse/scanpy/issues/1487:839,modifiability,pac,packages,839,"f""Values {list(not_found)}, from {list(indexer)}, "" ""are not valid obs/ var names or indices.""; This bug only occurred in 1.6.0 but not 1.5.0. I was running `scanpy 1.6.0` this:. `sc.tl.filter_rank_genes_groups(adata, groupby=obs,\. max_out_group_fraction=max_out_group_fraction,. min_fold_change=min_fold_change,use_raw=use_raw,. min_in_group_fraction=0.25,log=log)`. But got this error:. ```. Filtering genes using: min_in_group_fraction: 0.25 min_fold_change: 2, max_out_group_fraction: 0.25. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-91-d477dca208af> in <module>. 2 max_out_group_fraction=max_out_group_fraction,. 3 min_fold_change=min_fold_change,use_raw=use_raw,. ----> 4 min_in_group_fraction=0.25,log=log). /usr/local/lib/python3.6/dist-packages/scanpy/tools/_rank_genes_groups.py in filter_rank_genes_groups(adata, key, groupby, use_raw, log, key_added, min_in_group_fraction, min_fold_change, max_out_group_fraction). 725 var_names,. 726 groupby='__is_in_cluster__',. --> 727 use_raw=use_raw,. 728 ). 729 . /usr/local/lib/python3.6/dist-packages/scanpy/plotting/_anndata.py in _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer, gene_symbols). 1808 matrix = adata.raw[:, var_names].X. 1809 else:. -> 1810 matrix = adata[:, var_names].X. 1811 . 1812 if issparse(matrix):. /usr/local/lib/python3.6/dist-packages/anndata/_core/anndata.py in __getitem__(self, index). 1085 def __getitem__(self, index: Index) -> ""AnnData"":. 1086 """"""Returns a sliced view of the object."""""". -> 1087 oidx, vidx = self._normalize_indices(index). 1088 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1089 . /usr/local/lib/python3.6/dist-packages/anndata/_core/anndata.py in _normalize_indices(self, index). 1066 . 1067 def _normalize_indices(self, index: Optional[Index]) -> Tuple[slice, slice]:. -> 1068 return _normalize_indices(index, self.obs_names, self.var_names). 1069 . 107",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1487
https://github.com/scverse/scanpy/issues/1487:1141,modifiability,pac,packages,1141,"was running `scanpy 1.6.0` this:. `sc.tl.filter_rank_genes_groups(adata, groupby=obs,\. max_out_group_fraction=max_out_group_fraction,. min_fold_change=min_fold_change,use_raw=use_raw,. min_in_group_fraction=0.25,log=log)`. But got this error:. ```. Filtering genes using: min_in_group_fraction: 0.25 min_fold_change: 2, max_out_group_fraction: 0.25. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-91-d477dca208af> in <module>. 2 max_out_group_fraction=max_out_group_fraction,. 3 min_fold_change=min_fold_change,use_raw=use_raw,. ----> 4 min_in_group_fraction=0.25,log=log). /usr/local/lib/python3.6/dist-packages/scanpy/tools/_rank_genes_groups.py in filter_rank_genes_groups(adata, key, groupby, use_raw, log, key_added, min_in_group_fraction, min_fold_change, max_out_group_fraction). 725 var_names,. 726 groupby='__is_in_cluster__',. --> 727 use_raw=use_raw,. 728 ). 729 . /usr/local/lib/python3.6/dist-packages/scanpy/plotting/_anndata.py in _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer, gene_symbols). 1808 matrix = adata.raw[:, var_names].X. 1809 else:. -> 1810 matrix = adata[:, var_names].X. 1811 . 1812 if issparse(matrix):. /usr/local/lib/python3.6/dist-packages/anndata/_core/anndata.py in __getitem__(self, index). 1085 def __getitem__(self, index: Index) -> ""AnnData"":. 1086 """"""Returns a sliced view of the object."""""". -> 1087 oidx, vidx = self._normalize_indices(index). 1088 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1089 . /usr/local/lib/python3.6/dist-packages/anndata/_core/anndata.py in _normalize_indices(self, index). 1066 . 1067 def _normalize_indices(self, index: Optional[Index]) -> Tuple[slice, slice]:. -> 1068 return _normalize_indices(index, self.obs_names, self.var_names). 1069 . 1070 # TODO: this is not quite complete... /usr/local/lib/python3.6/dist-packages/anndata/_core/index.py in _normalize_indices(index, names0, names1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1487
https://github.com/scverse/scanpy/issues/1487:1257,modifiability,layer,layer,1257,"out_group_fraction,. min_fold_change=min_fold_change,use_raw=use_raw,. min_in_group_fraction=0.25,log=log)`. But got this error:. ```. Filtering genes using: min_in_group_fraction: 0.25 min_fold_change: 2, max_out_group_fraction: 0.25. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-91-d477dca208af> in <module>. 2 max_out_group_fraction=max_out_group_fraction,. 3 min_fold_change=min_fold_change,use_raw=use_raw,. ----> 4 min_in_group_fraction=0.25,log=log). /usr/local/lib/python3.6/dist-packages/scanpy/tools/_rank_genes_groups.py in filter_rank_genes_groups(adata, key, groupby, use_raw, log, key_added, min_in_group_fraction, min_fold_change, max_out_group_fraction). 725 var_names,. 726 groupby='__is_in_cluster__',. --> 727 use_raw=use_raw,. 728 ). 729 . /usr/local/lib/python3.6/dist-packages/scanpy/plotting/_anndata.py in _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer, gene_symbols). 1808 matrix = adata.raw[:, var_names].X. 1809 else:. -> 1810 matrix = adata[:, var_names].X. 1811 . 1812 if issparse(matrix):. /usr/local/lib/python3.6/dist-packages/anndata/_core/anndata.py in __getitem__(self, index). 1085 def __getitem__(self, index: Index) -> ""AnnData"":. 1086 """"""Returns a sliced view of the object."""""". -> 1087 oidx, vidx = self._normalize_indices(index). 1088 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1089 . /usr/local/lib/python3.6/dist-packages/anndata/_core/anndata.py in _normalize_indices(self, index). 1066 . 1067 def _normalize_indices(self, index: Optional[Index]) -> Tuple[slice, slice]:. -> 1068 return _normalize_indices(index, self.obs_names, self.var_names). 1069 . 1070 # TODO: this is not quite complete... /usr/local/lib/python3.6/dist-packages/anndata/_core/index.py in _normalize_indices(index, names0, names1). 33 ax0, ax1 = unpack_index(index). 34 ax0 = _normalize_index(ax0, names0). ---> 35 ax1 = _normalize_index(ax1, n",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1487
https://github.com/scverse/scanpy/issues/1487:1436,modifiability,pac,packages,1436," 0.25 min_fold_change: 2, max_out_group_fraction: 0.25. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-91-d477dca208af> in <module>. 2 max_out_group_fraction=max_out_group_fraction,. 3 min_fold_change=min_fold_change,use_raw=use_raw,. ----> 4 min_in_group_fraction=0.25,log=log). /usr/local/lib/python3.6/dist-packages/scanpy/tools/_rank_genes_groups.py in filter_rank_genes_groups(adata, key, groupby, use_raw, log, key_added, min_in_group_fraction, min_fold_change, max_out_group_fraction). 725 var_names,. 726 groupby='__is_in_cluster__',. --> 727 use_raw=use_raw,. 728 ). 729 . /usr/local/lib/python3.6/dist-packages/scanpy/plotting/_anndata.py in _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer, gene_symbols). 1808 matrix = adata.raw[:, var_names].X. 1809 else:. -> 1810 matrix = adata[:, var_names].X. 1811 . 1812 if issparse(matrix):. /usr/local/lib/python3.6/dist-packages/anndata/_core/anndata.py in __getitem__(self, index). 1085 def __getitem__(self, index: Index) -> ""AnnData"":. 1086 """"""Returns a sliced view of the object."""""". -> 1087 oidx, vidx = self._normalize_indices(index). 1088 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1089 . /usr/local/lib/python3.6/dist-packages/anndata/_core/anndata.py in _normalize_indices(self, index). 1066 . 1067 def _normalize_indices(self, index: Optional[Index]) -> Tuple[slice, slice]:. -> 1068 return _normalize_indices(index, self.obs_names, self.var_names). 1069 . 1070 # TODO: this is not quite complete... /usr/local/lib/python3.6/dist-packages/anndata/_core/index.py in _normalize_indices(index, names0, names1). 33 ax0, ax1 = unpack_index(index). 34 ax0 = _normalize_index(ax0, names0). ---> 35 ax1 = _normalize_index(ax1, names1). 36 return ax0, ax1. 37 . /usr/local/lib/python3.6/dist-packages/anndata/_core/index.py in _normalize_index(indexer, index). 99 not_found = indexer[positions < 0]. 100 raise",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1487
https://github.com/scverse/scanpy/issues/1487:1756,modifiability,pac,packages,1756,"in_fold_change,use_raw=use_raw,. ----> 4 min_in_group_fraction=0.25,log=log). /usr/local/lib/python3.6/dist-packages/scanpy/tools/_rank_genes_groups.py in filter_rank_genes_groups(adata, key, groupby, use_raw, log, key_added, min_in_group_fraction, min_fold_change, max_out_group_fraction). 725 var_names,. 726 groupby='__is_in_cluster__',. --> 727 use_raw=use_raw,. 728 ). 729 . /usr/local/lib/python3.6/dist-packages/scanpy/plotting/_anndata.py in _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer, gene_symbols). 1808 matrix = adata.raw[:, var_names].X. 1809 else:. -> 1810 matrix = adata[:, var_names].X. 1811 . 1812 if issparse(matrix):. /usr/local/lib/python3.6/dist-packages/anndata/_core/anndata.py in __getitem__(self, index). 1085 def __getitem__(self, index: Index) -> ""AnnData"":. 1086 """"""Returns a sliced view of the object."""""". -> 1087 oidx, vidx = self._normalize_indices(index). 1088 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1089 . /usr/local/lib/python3.6/dist-packages/anndata/_core/anndata.py in _normalize_indices(self, index). 1066 . 1067 def _normalize_indices(self, index: Optional[Index]) -> Tuple[slice, slice]:. -> 1068 return _normalize_indices(index, self.obs_names, self.var_names). 1069 . 1070 # TODO: this is not quite complete... /usr/local/lib/python3.6/dist-packages/anndata/_core/index.py in _normalize_indices(index, names0, names1). 33 ax0, ax1 = unpack_index(index). 34 ax0 = _normalize_index(ax0, names0). ---> 35 ax1 = _normalize_index(ax1, names1). 36 return ax0, ax1. 37 . /usr/local/lib/python3.6/dist-packages/anndata/_core/index.py in _normalize_index(indexer, index). 99 not_found = indexer[positions < 0]. 100 raise KeyError(. --> 101 f""Values {list(not_found)}, from {list(indexer)}, "". 102 ""are not valid obs/ var names or indices."". 103 ). KeyError: ""Values ['LINC00601', 'DPYS', 'AC136604.2', 'AC023137.1', 'MATN3', 'AL359921.1' . ... 'FAM129C', 'TCL1A'], are not valid obs/ var names or indices."". ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1487
https://github.com/scverse/scanpy/issues/1487:2070,modifiability,pac,packages,2070,"in_fold_change,use_raw=use_raw,. ----> 4 min_in_group_fraction=0.25,log=log). /usr/local/lib/python3.6/dist-packages/scanpy/tools/_rank_genes_groups.py in filter_rank_genes_groups(adata, key, groupby, use_raw, log, key_added, min_in_group_fraction, min_fold_change, max_out_group_fraction). 725 var_names,. 726 groupby='__is_in_cluster__',. --> 727 use_raw=use_raw,. 728 ). 729 . /usr/local/lib/python3.6/dist-packages/scanpy/plotting/_anndata.py in _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer, gene_symbols). 1808 matrix = adata.raw[:, var_names].X. 1809 else:. -> 1810 matrix = adata[:, var_names].X. 1811 . 1812 if issparse(matrix):. /usr/local/lib/python3.6/dist-packages/anndata/_core/anndata.py in __getitem__(self, index). 1085 def __getitem__(self, index: Index) -> ""AnnData"":. 1086 """"""Returns a sliced view of the object."""""". -> 1087 oidx, vidx = self._normalize_indices(index). 1088 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1089 . /usr/local/lib/python3.6/dist-packages/anndata/_core/anndata.py in _normalize_indices(self, index). 1066 . 1067 def _normalize_indices(self, index: Optional[Index]) -> Tuple[slice, slice]:. -> 1068 return _normalize_indices(index, self.obs_names, self.var_names). 1069 . 1070 # TODO: this is not quite complete... /usr/local/lib/python3.6/dist-packages/anndata/_core/index.py in _normalize_indices(index, names0, names1). 33 ax0, ax1 = unpack_index(index). 34 ax0 = _normalize_index(ax0, names0). ---> 35 ax1 = _normalize_index(ax1, names1). 36 return ax0, ax1. 37 . /usr/local/lib/python3.6/dist-packages/anndata/_core/index.py in _normalize_index(indexer, index). 99 not_found = indexer[positions < 0]. 100 raise KeyError(. --> 101 f""Values {list(not_found)}, from {list(indexer)}, "". 102 ""are not valid obs/ var names or indices."". 103 ). KeyError: ""Values ['LINC00601', 'DPYS', 'AC136604.2', 'AC023137.1', 'MATN3', 'AL359921.1' . ... 'FAM129C', 'TCL1A'], are not valid obs/ var names or indices."". ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1487
https://github.com/scverse/scanpy/issues/1487:2323,modifiability,pac,packages,2323,"in_fold_change,use_raw=use_raw,. ----> 4 min_in_group_fraction=0.25,log=log). /usr/local/lib/python3.6/dist-packages/scanpy/tools/_rank_genes_groups.py in filter_rank_genes_groups(adata, key, groupby, use_raw, log, key_added, min_in_group_fraction, min_fold_change, max_out_group_fraction). 725 var_names,. 726 groupby='__is_in_cluster__',. --> 727 use_raw=use_raw,. 728 ). 729 . /usr/local/lib/python3.6/dist-packages/scanpy/plotting/_anndata.py in _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer, gene_symbols). 1808 matrix = adata.raw[:, var_names].X. 1809 else:. -> 1810 matrix = adata[:, var_names].X. 1811 . 1812 if issparse(matrix):. /usr/local/lib/python3.6/dist-packages/anndata/_core/anndata.py in __getitem__(self, index). 1085 def __getitem__(self, index: Index) -> ""AnnData"":. 1086 """"""Returns a sliced view of the object."""""". -> 1087 oidx, vidx = self._normalize_indices(index). 1088 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1089 . /usr/local/lib/python3.6/dist-packages/anndata/_core/anndata.py in _normalize_indices(self, index). 1066 . 1067 def _normalize_indices(self, index: Optional[Index]) -> Tuple[slice, slice]:. -> 1068 return _normalize_indices(index, self.obs_names, self.var_names). 1069 . 1070 # TODO: this is not quite complete... /usr/local/lib/python3.6/dist-packages/anndata/_core/index.py in _normalize_indices(index, names0, names1). 33 ax0, ax1 = unpack_index(index). 34 ax0 = _normalize_index(ax0, names0). ---> 35 ax1 = _normalize_index(ax1, names1). 36 return ax0, ax1. 37 . /usr/local/lib/python3.6/dist-packages/anndata/_core/index.py in _normalize_index(indexer, index). 99 not_found = indexer[positions < 0]. 100 raise KeyError(. --> 101 f""Values {list(not_found)}, from {list(indexer)}, "". 102 ""are not valid obs/ var names or indices."". 103 ). KeyError: ""Values ['LINC00601', 'DPYS', 'AC136604.2', 'AC023137.1', 'MATN3', 'AL359921.1' . ... 'FAM129C', 'TCL1A'], are not valid obs/ var names or indices."". ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1487
https://github.com/scverse/scanpy/issues/1487:382,performance,error,error,382,"f""Values {list(not_found)}, from {list(indexer)}, "" ""are not valid obs/ var names or indices.""; This bug only occurred in 1.6.0 but not 1.5.0. I was running `scanpy 1.6.0` this:. `sc.tl.filter_rank_genes_groups(adata, groupby=obs,\. max_out_group_fraction=max_out_group_fraction,. min_fold_change=min_fold_change,use_raw=use_raw,. min_in_group_fraction=0.25,log=log)`. But got this error:. ```. Filtering genes using: min_in_group_fraction: 0.25 min_fold_change: 2, max_out_group_fraction: 0.25. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-91-d477dca208af> in <module>. 2 max_out_group_fraction=max_out_group_fraction,. 3 min_fold_change=min_fold_change,use_raw=use_raw,. ----> 4 min_in_group_fraction=0.25,log=log). /usr/local/lib/python3.6/dist-packages/scanpy/tools/_rank_genes_groups.py in filter_rank_genes_groups(adata, key, groupby, use_raw, log, key_added, min_in_group_fraction, min_fold_change, max_out_group_fraction). 725 var_names,. 726 groupby='__is_in_cluster__',. --> 727 use_raw=use_raw,. 728 ). 729 . /usr/local/lib/python3.6/dist-packages/scanpy/plotting/_anndata.py in _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer, gene_symbols). 1808 matrix = adata.raw[:, var_names].X. 1809 else:. -> 1810 matrix = adata[:, var_names].X. 1811 . 1812 if issparse(matrix):. /usr/local/lib/python3.6/dist-packages/anndata/_core/anndata.py in __getitem__(self, index). 1085 def __getitem__(self, index: Index) -> ""AnnData"":. 1086 """"""Returns a sliced view of the object."""""". -> 1087 oidx, vidx = self._normalize_indices(index). 1088 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1089 . /usr/local/lib/python3.6/dist-packages/anndata/_core/anndata.py in _normalize_indices(self, index). 1066 . 1067 def _normalize_indices(self, index: Optional[Index]) -> Tuple[slice, slice]:. -> 1068 return _normalize_indices(index, self.obs_names, self.var_names). 1069 . 107",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1487
https://github.com/scverse/scanpy/issues/1487:1573,reliability,sli,sliced,1573,"Error Traceback (most recent call last). <ipython-input-91-d477dca208af> in <module>. 2 max_out_group_fraction=max_out_group_fraction,. 3 min_fold_change=min_fold_change,use_raw=use_raw,. ----> 4 min_in_group_fraction=0.25,log=log). /usr/local/lib/python3.6/dist-packages/scanpy/tools/_rank_genes_groups.py in filter_rank_genes_groups(adata, key, groupby, use_raw, log, key_added, min_in_group_fraction, min_fold_change, max_out_group_fraction). 725 var_names,. 726 groupby='__is_in_cluster__',. --> 727 use_raw=use_raw,. 728 ). 729 . /usr/local/lib/python3.6/dist-packages/scanpy/plotting/_anndata.py in _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer, gene_symbols). 1808 matrix = adata.raw[:, var_names].X. 1809 else:. -> 1810 matrix = adata[:, var_names].X. 1811 . 1812 if issparse(matrix):. /usr/local/lib/python3.6/dist-packages/anndata/_core/anndata.py in __getitem__(self, index). 1085 def __getitem__(self, index: Index) -> ""AnnData"":. 1086 """"""Returns a sliced view of the object."""""". -> 1087 oidx, vidx = self._normalize_indices(index). 1088 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1089 . /usr/local/lib/python3.6/dist-packages/anndata/_core/anndata.py in _normalize_indices(self, index). 1066 . 1067 def _normalize_indices(self, index: Optional[Index]) -> Tuple[slice, slice]:. -> 1068 return _normalize_indices(index, self.obs_names, self.var_names). 1069 . 1070 # TODO: this is not quite complete... /usr/local/lib/python3.6/dist-packages/anndata/_core/index.py in _normalize_indices(index, names0, names1). 33 ax0, ax1 = unpack_index(index). 34 ax0 = _normalize_index(ax0, names0). ---> 35 ax1 = _normalize_index(ax1, names1). 36 return ax0, ax1. 37 . /usr/local/lib/python3.6/dist-packages/anndata/_core/index.py in _normalize_index(indexer, index). 99 not_found = indexer[positions < 0]. 100 raise KeyError(. --> 101 f""Values {list(not_found)}, from {list(indexer)}, "". 102 ""are not valid obs/ var names or indices."". 103 ). KeyError",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1487
https://github.com/scverse/scanpy/issues/1487:1900,reliability,sli,slice,1900,"in_fold_change,use_raw=use_raw,. ----> 4 min_in_group_fraction=0.25,log=log). /usr/local/lib/python3.6/dist-packages/scanpy/tools/_rank_genes_groups.py in filter_rank_genes_groups(adata, key, groupby, use_raw, log, key_added, min_in_group_fraction, min_fold_change, max_out_group_fraction). 725 var_names,. 726 groupby='__is_in_cluster__',. --> 727 use_raw=use_raw,. 728 ). 729 . /usr/local/lib/python3.6/dist-packages/scanpy/plotting/_anndata.py in _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer, gene_symbols). 1808 matrix = adata.raw[:, var_names].X. 1809 else:. -> 1810 matrix = adata[:, var_names].X. 1811 . 1812 if issparse(matrix):. /usr/local/lib/python3.6/dist-packages/anndata/_core/anndata.py in __getitem__(self, index). 1085 def __getitem__(self, index: Index) -> ""AnnData"":. 1086 """"""Returns a sliced view of the object."""""". -> 1087 oidx, vidx = self._normalize_indices(index). 1088 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1089 . /usr/local/lib/python3.6/dist-packages/anndata/_core/anndata.py in _normalize_indices(self, index). 1066 . 1067 def _normalize_indices(self, index: Optional[Index]) -> Tuple[slice, slice]:. -> 1068 return _normalize_indices(index, self.obs_names, self.var_names). 1069 . 1070 # TODO: this is not quite complete... /usr/local/lib/python3.6/dist-packages/anndata/_core/index.py in _normalize_indices(index, names0, names1). 33 ax0, ax1 = unpack_index(index). 34 ax0 = _normalize_index(ax0, names0). ---> 35 ax1 = _normalize_index(ax1, names1). 36 return ax0, ax1. 37 . /usr/local/lib/python3.6/dist-packages/anndata/_core/index.py in _normalize_index(indexer, index). 99 not_found = indexer[positions < 0]. 100 raise KeyError(. --> 101 f""Values {list(not_found)}, from {list(indexer)}, "". 102 ""are not valid obs/ var names or indices."". 103 ). KeyError: ""Values ['LINC00601', 'DPYS', 'AC136604.2', 'AC023137.1', 'MATN3', 'AL359921.1' . ... 'FAM129C', 'TCL1A'], are not valid obs/ var names or indices."". ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1487
https://github.com/scverse/scanpy/issues/1487:1907,reliability,sli,slice,1907,"in_fold_change,use_raw=use_raw,. ----> 4 min_in_group_fraction=0.25,log=log). /usr/local/lib/python3.6/dist-packages/scanpy/tools/_rank_genes_groups.py in filter_rank_genes_groups(adata, key, groupby, use_raw, log, key_added, min_in_group_fraction, min_fold_change, max_out_group_fraction). 725 var_names,. 726 groupby='__is_in_cluster__',. --> 727 use_raw=use_raw,. 728 ). 729 . /usr/local/lib/python3.6/dist-packages/scanpy/plotting/_anndata.py in _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer, gene_symbols). 1808 matrix = adata.raw[:, var_names].X. 1809 else:. -> 1810 matrix = adata[:, var_names].X. 1811 . 1812 if issparse(matrix):. /usr/local/lib/python3.6/dist-packages/anndata/_core/anndata.py in __getitem__(self, index). 1085 def __getitem__(self, index: Index) -> ""AnnData"":. 1086 """"""Returns a sliced view of the object."""""". -> 1087 oidx, vidx = self._normalize_indices(index). 1088 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1089 . /usr/local/lib/python3.6/dist-packages/anndata/_core/anndata.py in _normalize_indices(self, index). 1066 . 1067 def _normalize_indices(self, index: Optional[Index]) -> Tuple[slice, slice]:. -> 1068 return _normalize_indices(index, self.obs_names, self.var_names). 1069 . 1070 # TODO: this is not quite complete... /usr/local/lib/python3.6/dist-packages/anndata/_core/index.py in _normalize_indices(index, names0, names1). 33 ax0, ax1 = unpack_index(index). 34 ax0 = _normalize_index(ax0, names0). ---> 35 ax1 = _normalize_index(ax1, names1). 36 return ax0, ax1. 37 . /usr/local/lib/python3.6/dist-packages/anndata/_core/index.py in _normalize_index(indexer, index). 99 not_found = indexer[positions < 0]. 100 raise KeyError(. --> 101 f""Values {list(not_found)}, from {list(indexer)}, "". 102 ""are not valid obs/ var names or indices."". 103 ). KeyError: ""Values ['LINC00601', 'DPYS', 'AC136604.2', 'AC023137.1', 'MATN3', 'AL359921.1' . ... 'FAM129C', 'TCL1A'], are not valid obs/ var names or indices."". ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1487
https://github.com/scverse/scanpy/issues/1487:61,safety,valid,valid,61,"f""Values {list(not_found)}, from {list(indexer)}, "" ""are not valid obs/ var names or indices.""; This bug only occurred in 1.6.0 but not 1.5.0. I was running `scanpy 1.6.0` this:. `sc.tl.filter_rank_genes_groups(adata, groupby=obs,\. max_out_group_fraction=max_out_group_fraction,. min_fold_change=min_fold_change,use_raw=use_raw,. min_in_group_fraction=0.25,log=log)`. But got this error:. ```. Filtering genes using: min_in_group_fraction: 0.25 min_fold_change: 2, max_out_group_fraction: 0.25. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-91-d477dca208af> in <module>. 2 max_out_group_fraction=max_out_group_fraction,. 3 min_fold_change=min_fold_change,use_raw=use_raw,. ----> 4 min_in_group_fraction=0.25,log=log). /usr/local/lib/python3.6/dist-packages/scanpy/tools/_rank_genes_groups.py in filter_rank_genes_groups(adata, key, groupby, use_raw, log, key_added, min_in_group_fraction, min_fold_change, max_out_group_fraction). 725 var_names,. 726 groupby='__is_in_cluster__',. --> 727 use_raw=use_raw,. 728 ). 729 . /usr/local/lib/python3.6/dist-packages/scanpy/plotting/_anndata.py in _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer, gene_symbols). 1808 matrix = adata.raw[:, var_names].X. 1809 else:. -> 1810 matrix = adata[:, var_names].X. 1811 . 1812 if issparse(matrix):. /usr/local/lib/python3.6/dist-packages/anndata/_core/anndata.py in __getitem__(self, index). 1085 def __getitem__(self, index: Index) -> ""AnnData"":. 1086 """"""Returns a sliced view of the object."""""". -> 1087 oidx, vidx = self._normalize_indices(index). 1088 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1089 . /usr/local/lib/python3.6/dist-packages/anndata/_core/anndata.py in _normalize_indices(self, index). 1066 . 1067 def _normalize_indices(self, index: Optional[Index]) -> Tuple[slice, slice]:. -> 1068 return _normalize_indices(index, self.obs_names, self.var_names). 1069 . 107",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1487
https://github.com/scverse/scanpy/issues/1487:358,safety,log,log,358,"f""Values {list(not_found)}, from {list(indexer)}, "" ""are not valid obs/ var names or indices.""; This bug only occurred in 1.6.0 but not 1.5.0. I was running `scanpy 1.6.0` this:. `sc.tl.filter_rank_genes_groups(adata, groupby=obs,\. max_out_group_fraction=max_out_group_fraction,. min_fold_change=min_fold_change,use_raw=use_raw,. min_in_group_fraction=0.25,log=log)`. But got this error:. ```. Filtering genes using: min_in_group_fraction: 0.25 min_fold_change: 2, max_out_group_fraction: 0.25. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-91-d477dca208af> in <module>. 2 max_out_group_fraction=max_out_group_fraction,. 3 min_fold_change=min_fold_change,use_raw=use_raw,. ----> 4 min_in_group_fraction=0.25,log=log). /usr/local/lib/python3.6/dist-packages/scanpy/tools/_rank_genes_groups.py in filter_rank_genes_groups(adata, key, groupby, use_raw, log, key_added, min_in_group_fraction, min_fold_change, max_out_group_fraction). 725 var_names,. 726 groupby='__is_in_cluster__',. --> 727 use_raw=use_raw,. 728 ). 729 . /usr/local/lib/python3.6/dist-packages/scanpy/plotting/_anndata.py in _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer, gene_symbols). 1808 matrix = adata.raw[:, var_names].X. 1809 else:. -> 1810 matrix = adata[:, var_names].X. 1811 . 1812 if issparse(matrix):. /usr/local/lib/python3.6/dist-packages/anndata/_core/anndata.py in __getitem__(self, index). 1085 def __getitem__(self, index: Index) -> ""AnnData"":. 1086 """"""Returns a sliced view of the object."""""". -> 1087 oidx, vidx = self._normalize_indices(index). 1088 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1089 . /usr/local/lib/python3.6/dist-packages/anndata/_core/anndata.py in _normalize_indices(self, index). 1066 . 1067 def _normalize_indices(self, index: Optional[Index]) -> Tuple[slice, slice]:. -> 1068 return _normalize_indices(index, self.obs_names, self.var_names). 1069 . 107",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1487
https://github.com/scverse/scanpy/issues/1487:362,safety,log,log,362,"f""Values {list(not_found)}, from {list(indexer)}, "" ""are not valid obs/ var names or indices.""; This bug only occurred in 1.6.0 but not 1.5.0. I was running `scanpy 1.6.0` this:. `sc.tl.filter_rank_genes_groups(adata, groupby=obs,\. max_out_group_fraction=max_out_group_fraction,. min_fold_change=min_fold_change,use_raw=use_raw,. min_in_group_fraction=0.25,log=log)`. But got this error:. ```. Filtering genes using: min_in_group_fraction: 0.25 min_fold_change: 2, max_out_group_fraction: 0.25. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-91-d477dca208af> in <module>. 2 max_out_group_fraction=max_out_group_fraction,. 3 min_fold_change=min_fold_change,use_raw=use_raw,. ----> 4 min_in_group_fraction=0.25,log=log). /usr/local/lib/python3.6/dist-packages/scanpy/tools/_rank_genes_groups.py in filter_rank_genes_groups(adata, key, groupby, use_raw, log, key_added, min_in_group_fraction, min_fold_change, max_out_group_fraction). 725 var_names,. 726 groupby='__is_in_cluster__',. --> 727 use_raw=use_raw,. 728 ). 729 . /usr/local/lib/python3.6/dist-packages/scanpy/plotting/_anndata.py in _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer, gene_symbols). 1808 matrix = adata.raw[:, var_names].X. 1809 else:. -> 1810 matrix = adata[:, var_names].X. 1811 . 1812 if issparse(matrix):. /usr/local/lib/python3.6/dist-packages/anndata/_core/anndata.py in __getitem__(self, index). 1085 def __getitem__(self, index: Index) -> ""AnnData"":. 1086 """"""Returns a sliced view of the object."""""". -> 1087 oidx, vidx = self._normalize_indices(index). 1088 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1089 . /usr/local/lib/python3.6/dist-packages/anndata/_core/anndata.py in _normalize_indices(self, index). 1066 . 1067 def _normalize_indices(self, index: Optional[Index]) -> Tuple[slice, slice]:. -> 1068 return _normalize_indices(index, self.obs_names, self.var_names). 1069 . 107",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1487
https://github.com/scverse/scanpy/issues/1487:382,safety,error,error,382,"f""Values {list(not_found)}, from {list(indexer)}, "" ""are not valid obs/ var names or indices.""; This bug only occurred in 1.6.0 but not 1.5.0. I was running `scanpy 1.6.0` this:. `sc.tl.filter_rank_genes_groups(adata, groupby=obs,\. max_out_group_fraction=max_out_group_fraction,. min_fold_change=min_fold_change,use_raw=use_raw,. min_in_group_fraction=0.25,log=log)`. But got this error:. ```. Filtering genes using: min_in_group_fraction: 0.25 min_fold_change: 2, max_out_group_fraction: 0.25. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-91-d477dca208af> in <module>. 2 max_out_group_fraction=max_out_group_fraction,. 3 min_fold_change=min_fold_change,use_raw=use_raw,. ----> 4 min_in_group_fraction=0.25,log=log). /usr/local/lib/python3.6/dist-packages/scanpy/tools/_rank_genes_groups.py in filter_rank_genes_groups(adata, key, groupby, use_raw, log, key_added, min_in_group_fraction, min_fold_change, max_out_group_fraction). 725 var_names,. 726 groupby='__is_in_cluster__',. --> 727 use_raw=use_raw,. 728 ). 729 . /usr/local/lib/python3.6/dist-packages/scanpy/plotting/_anndata.py in _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer, gene_symbols). 1808 matrix = adata.raw[:, var_names].X. 1809 else:. -> 1810 matrix = adata[:, var_names].X. 1811 . 1812 if issparse(matrix):. /usr/local/lib/python3.6/dist-packages/anndata/_core/anndata.py in __getitem__(self, index). 1085 def __getitem__(self, index: Index) -> ""AnnData"":. 1086 """"""Returns a sliced view of the object."""""". -> 1087 oidx, vidx = self._normalize_indices(index). 1088 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1089 . /usr/local/lib/python3.6/dist-packages/anndata/_core/anndata.py in _normalize_indices(self, index). 1066 . 1067 def _normalize_indices(self, index: Optional[Index]) -> Tuple[slice, slice]:. -> 1068 return _normalize_indices(index, self.obs_names, self.var_names). 1069 . 107",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1487
https://github.com/scverse/scanpy/issues/1487:626,safety,input,input-,626,"f""Values {list(not_found)}, from {list(indexer)}, "" ""are not valid obs/ var names or indices.""; This bug only occurred in 1.6.0 but not 1.5.0. I was running `scanpy 1.6.0` this:. `sc.tl.filter_rank_genes_groups(adata, groupby=obs,\. max_out_group_fraction=max_out_group_fraction,. min_fold_change=min_fold_change,use_raw=use_raw,. min_in_group_fraction=0.25,log=log)`. But got this error:. ```. Filtering genes using: min_in_group_fraction: 0.25 min_fold_change: 2, max_out_group_fraction: 0.25. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-91-d477dca208af> in <module>. 2 max_out_group_fraction=max_out_group_fraction,. 3 min_fold_change=min_fold_change,use_raw=use_raw,. ----> 4 min_in_group_fraction=0.25,log=log). /usr/local/lib/python3.6/dist-packages/scanpy/tools/_rank_genes_groups.py in filter_rank_genes_groups(adata, key, groupby, use_raw, log, key_added, min_in_group_fraction, min_fold_change, max_out_group_fraction). 725 var_names,. 726 groupby='__is_in_cluster__',. --> 727 use_raw=use_raw,. 728 ). 729 . /usr/local/lib/python3.6/dist-packages/scanpy/plotting/_anndata.py in _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer, gene_symbols). 1808 matrix = adata.raw[:, var_names].X. 1809 else:. -> 1810 matrix = adata[:, var_names].X. 1811 . 1812 if issparse(matrix):. /usr/local/lib/python3.6/dist-packages/anndata/_core/anndata.py in __getitem__(self, index). 1085 def __getitem__(self, index: Index) -> ""AnnData"":. 1086 """"""Returns a sliced view of the object."""""". -> 1087 oidx, vidx = self._normalize_indices(index). 1088 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1089 . /usr/local/lib/python3.6/dist-packages/anndata/_core/anndata.py in _normalize_indices(self, index). 1066 . 1067 def _normalize_indices(self, index: Optional[Index]) -> Tuple[slice, slice]:. -> 1068 return _normalize_indices(index, self.obs_names, self.var_names). 1069 . 107",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1487
https://github.com/scverse/scanpy/issues/1487:653,safety,modul,module,653,"f""Values {list(not_found)}, from {list(indexer)}, "" ""are not valid obs/ var names or indices.""; This bug only occurred in 1.6.0 but not 1.5.0. I was running `scanpy 1.6.0` this:. `sc.tl.filter_rank_genes_groups(adata, groupby=obs,\. max_out_group_fraction=max_out_group_fraction,. min_fold_change=min_fold_change,use_raw=use_raw,. min_in_group_fraction=0.25,log=log)`. But got this error:. ```. Filtering genes using: min_in_group_fraction: 0.25 min_fold_change: 2, max_out_group_fraction: 0.25. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-91-d477dca208af> in <module>. 2 max_out_group_fraction=max_out_group_fraction,. 3 min_fold_change=min_fold_change,use_raw=use_raw,. ----> 4 min_in_group_fraction=0.25,log=log). /usr/local/lib/python3.6/dist-packages/scanpy/tools/_rank_genes_groups.py in filter_rank_genes_groups(adata, key, groupby, use_raw, log, key_added, min_in_group_fraction, min_fold_change, max_out_group_fraction). 725 var_names,. 726 groupby='__is_in_cluster__',. --> 727 use_raw=use_raw,. 728 ). 729 . /usr/local/lib/python3.6/dist-packages/scanpy/plotting/_anndata.py in _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer, gene_symbols). 1808 matrix = adata.raw[:, var_names].X. 1809 else:. -> 1810 matrix = adata[:, var_names].X. 1811 . 1812 if issparse(matrix):. /usr/local/lib/python3.6/dist-packages/anndata/_core/anndata.py in __getitem__(self, index). 1085 def __getitem__(self, index: Index) -> ""AnnData"":. 1086 """"""Returns a sliced view of the object."""""". -> 1087 oidx, vidx = self._normalize_indices(index). 1088 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1089 . /usr/local/lib/python3.6/dist-packages/anndata/_core/anndata.py in _normalize_indices(self, index). 1066 . 1067 def _normalize_indices(self, index: Optional[Index]) -> Tuple[slice, slice]:. -> 1068 return _normalize_indices(index, self.obs_names, self.var_names). 1069 . 107",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1487
https://github.com/scverse/scanpy/issues/1487:799,safety,log,log,799,"f""Values {list(not_found)}, from {list(indexer)}, "" ""are not valid obs/ var names or indices.""; This bug only occurred in 1.6.0 but not 1.5.0. I was running `scanpy 1.6.0` this:. `sc.tl.filter_rank_genes_groups(adata, groupby=obs,\. max_out_group_fraction=max_out_group_fraction,. min_fold_change=min_fold_change,use_raw=use_raw,. min_in_group_fraction=0.25,log=log)`. But got this error:. ```. Filtering genes using: min_in_group_fraction: 0.25 min_fold_change: 2, max_out_group_fraction: 0.25. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-91-d477dca208af> in <module>. 2 max_out_group_fraction=max_out_group_fraction,. 3 min_fold_change=min_fold_change,use_raw=use_raw,. ----> 4 min_in_group_fraction=0.25,log=log). /usr/local/lib/python3.6/dist-packages/scanpy/tools/_rank_genes_groups.py in filter_rank_genes_groups(adata, key, groupby, use_raw, log, key_added, min_in_group_fraction, min_fold_change, max_out_group_fraction). 725 var_names,. 726 groupby='__is_in_cluster__',. --> 727 use_raw=use_raw,. 728 ). 729 . /usr/local/lib/python3.6/dist-packages/scanpy/plotting/_anndata.py in _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer, gene_symbols). 1808 matrix = adata.raw[:, var_names].X. 1809 else:. -> 1810 matrix = adata[:, var_names].X. 1811 . 1812 if issparse(matrix):. /usr/local/lib/python3.6/dist-packages/anndata/_core/anndata.py in __getitem__(self, index). 1085 def __getitem__(self, index: Index) -> ""AnnData"":. 1086 """"""Returns a sliced view of the object."""""". -> 1087 oidx, vidx = self._normalize_indices(index). 1088 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1089 . /usr/local/lib/python3.6/dist-packages/anndata/_core/anndata.py in _normalize_indices(self, index). 1066 . 1067 def _normalize_indices(self, index: Optional[Index]) -> Tuple[slice, slice]:. -> 1068 return _normalize_indices(index, self.obs_names, self.var_names). 1069 . 107",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1487
https://github.com/scverse/scanpy/issues/1487:803,safety,log,log,803,"f""Values {list(not_found)}, from {list(indexer)}, "" ""are not valid obs/ var names or indices.""; This bug only occurred in 1.6.0 but not 1.5.0. I was running `scanpy 1.6.0` this:. `sc.tl.filter_rank_genes_groups(adata, groupby=obs,\. max_out_group_fraction=max_out_group_fraction,. min_fold_change=min_fold_change,use_raw=use_raw,. min_in_group_fraction=0.25,log=log)`. But got this error:. ```. Filtering genes using: min_in_group_fraction: 0.25 min_fold_change: 2, max_out_group_fraction: 0.25. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-91-d477dca208af> in <module>. 2 max_out_group_fraction=max_out_group_fraction,. 3 min_fold_change=min_fold_change,use_raw=use_raw,. ----> 4 min_in_group_fraction=0.25,log=log). /usr/local/lib/python3.6/dist-packages/scanpy/tools/_rank_genes_groups.py in filter_rank_genes_groups(adata, key, groupby, use_raw, log, key_added, min_in_group_fraction, min_fold_change, max_out_group_fraction). 725 var_names,. 726 groupby='__is_in_cluster__',. --> 727 use_raw=use_raw,. 728 ). 729 . /usr/local/lib/python3.6/dist-packages/scanpy/plotting/_anndata.py in _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer, gene_symbols). 1808 matrix = adata.raw[:, var_names].X. 1809 else:. -> 1810 matrix = adata[:, var_names].X. 1811 . 1812 if issparse(matrix):. /usr/local/lib/python3.6/dist-packages/anndata/_core/anndata.py in __getitem__(self, index). 1085 def __getitem__(self, index: Index) -> ""AnnData"":. 1086 """"""Returns a sliced view of the object."""""". -> 1087 oidx, vidx = self._normalize_indices(index). 1088 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1089 . /usr/local/lib/python3.6/dist-packages/anndata/_core/anndata.py in _normalize_indices(self, index). 1066 . 1067 def _normalize_indices(self, index: Optional[Index]) -> Tuple[slice, slice]:. -> 1068 return _normalize_indices(index, self.obs_names, self.var_names). 1069 . 107",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1487
https://github.com/scverse/scanpy/issues/1487:941,safety,log,log,941,"f""Values {list(not_found)}, from {list(indexer)}, "" ""are not valid obs/ var names or indices.""; This bug only occurred in 1.6.0 but not 1.5.0. I was running `scanpy 1.6.0` this:. `sc.tl.filter_rank_genes_groups(adata, groupby=obs,\. max_out_group_fraction=max_out_group_fraction,. min_fold_change=min_fold_change,use_raw=use_raw,. min_in_group_fraction=0.25,log=log)`. But got this error:. ```. Filtering genes using: min_in_group_fraction: 0.25 min_fold_change: 2, max_out_group_fraction: 0.25. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-91-d477dca208af> in <module>. 2 max_out_group_fraction=max_out_group_fraction,. 3 min_fold_change=min_fold_change,use_raw=use_raw,. ----> 4 min_in_group_fraction=0.25,log=log). /usr/local/lib/python3.6/dist-packages/scanpy/tools/_rank_genes_groups.py in filter_rank_genes_groups(adata, key, groupby, use_raw, log, key_added, min_in_group_fraction, min_fold_change, max_out_group_fraction). 725 var_names,. 726 groupby='__is_in_cluster__',. --> 727 use_raw=use_raw,. 728 ). 729 . /usr/local/lib/python3.6/dist-packages/scanpy/plotting/_anndata.py in _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer, gene_symbols). 1808 matrix = adata.raw[:, var_names].X. 1809 else:. -> 1810 matrix = adata[:, var_names].X. 1811 . 1812 if issparse(matrix):. /usr/local/lib/python3.6/dist-packages/anndata/_core/anndata.py in __getitem__(self, index). 1085 def __getitem__(self, index: Index) -> ""AnnData"":. 1086 """"""Returns a sliced view of the object."""""". -> 1087 oidx, vidx = self._normalize_indices(index). 1088 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1089 . /usr/local/lib/python3.6/dist-packages/anndata/_core/anndata.py in _normalize_indices(self, index). 1066 . 1067 def _normalize_indices(self, index: Optional[Index]) -> Tuple[slice, slice]:. -> 1068 return _normalize_indices(index, self.obs_names, self.var_names). 1069 . 107",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1487
https://github.com/scverse/scanpy/issues/1487:1236,safety,log,log,1236,"ut_group_fraction=max_out_group_fraction,. min_fold_change=min_fold_change,use_raw=use_raw,. min_in_group_fraction=0.25,log=log)`. But got this error:. ```. Filtering genes using: min_in_group_fraction: 0.25 min_fold_change: 2, max_out_group_fraction: 0.25. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-91-d477dca208af> in <module>. 2 max_out_group_fraction=max_out_group_fraction,. 3 min_fold_change=min_fold_change,use_raw=use_raw,. ----> 4 min_in_group_fraction=0.25,log=log). /usr/local/lib/python3.6/dist-packages/scanpy/tools/_rank_genes_groups.py in filter_rank_genes_groups(adata, key, groupby, use_raw, log, key_added, min_in_group_fraction, min_fold_change, max_out_group_fraction). 725 var_names,. 726 groupby='__is_in_cluster__',. --> 727 use_raw=use_raw,. 728 ). 729 . /usr/local/lib/python3.6/dist-packages/scanpy/plotting/_anndata.py in _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer, gene_symbols). 1808 matrix = adata.raw[:, var_names].X. 1809 else:. -> 1810 matrix = adata[:, var_names].X. 1811 . 1812 if issparse(matrix):. /usr/local/lib/python3.6/dist-packages/anndata/_core/anndata.py in __getitem__(self, index). 1085 def __getitem__(self, index: Index) -> ""AnnData"":. 1086 """"""Returns a sliced view of the object."""""". -> 1087 oidx, vidx = self._normalize_indices(index). 1088 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1089 . /usr/local/lib/python3.6/dist-packages/anndata/_core/anndata.py in _normalize_indices(self, index). 1066 . 1067 def _normalize_indices(self, index: Optional[Index]) -> Tuple[slice, slice]:. -> 1068 return _normalize_indices(index, self.obs_names, self.var_names). 1069 . 1070 # TODO: this is not quite complete... /usr/local/lib/python3.6/dist-packages/anndata/_core/index.py in _normalize_indices(index, names0, names1). 33 ax0, ax1 = unpack_index(index). 34 ax0 = _normalize_index(ax0, names0). ---> 35 ax1 = _",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1487
https://github.com/scverse/scanpy/issues/1487:2028,safety,compl,complete,2028,"in_fold_change,use_raw=use_raw,. ----> 4 min_in_group_fraction=0.25,log=log). /usr/local/lib/python3.6/dist-packages/scanpy/tools/_rank_genes_groups.py in filter_rank_genes_groups(adata, key, groupby, use_raw, log, key_added, min_in_group_fraction, min_fold_change, max_out_group_fraction). 725 var_names,. 726 groupby='__is_in_cluster__',. --> 727 use_raw=use_raw,. 728 ). 729 . /usr/local/lib/python3.6/dist-packages/scanpy/plotting/_anndata.py in _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer, gene_symbols). 1808 matrix = adata.raw[:, var_names].X. 1809 else:. -> 1810 matrix = adata[:, var_names].X. 1811 . 1812 if issparse(matrix):. /usr/local/lib/python3.6/dist-packages/anndata/_core/anndata.py in __getitem__(self, index). 1085 def __getitem__(self, index: Index) -> ""AnnData"":. 1086 """"""Returns a sliced view of the object."""""". -> 1087 oidx, vidx = self._normalize_indices(index). 1088 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1089 . /usr/local/lib/python3.6/dist-packages/anndata/_core/anndata.py in _normalize_indices(self, index). 1066 . 1067 def _normalize_indices(self, index: Optional[Index]) -> Tuple[slice, slice]:. -> 1068 return _normalize_indices(index, self.obs_names, self.var_names). 1069 . 1070 # TODO: this is not quite complete... /usr/local/lib/python3.6/dist-packages/anndata/_core/index.py in _normalize_indices(index, names0, names1). 33 ax0, ax1 = unpack_index(index). 34 ax0 = _normalize_index(ax0, names0). ---> 35 ax1 = _normalize_index(ax1, names1). 36 return ax0, ax1. 37 . /usr/local/lib/python3.6/dist-packages/anndata/_core/index.py in _normalize_index(indexer, index). 99 not_found = indexer[positions < 0]. 100 raise KeyError(. --> 101 f""Values {list(not_found)}, from {list(indexer)}, "". 102 ""are not valid obs/ var names or indices."". 103 ). KeyError: ""Values ['LINC00601', 'DPYS', 'AC136604.2', 'AC023137.1', 'MATN3', 'AL359921.1' . ... 'FAM129C', 'TCL1A'], are not valid obs/ var names or indices."". ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1487
https://github.com/scverse/scanpy/issues/1487:2526,safety,valid,valid,2526,"in_fold_change,use_raw=use_raw,. ----> 4 min_in_group_fraction=0.25,log=log). /usr/local/lib/python3.6/dist-packages/scanpy/tools/_rank_genes_groups.py in filter_rank_genes_groups(adata, key, groupby, use_raw, log, key_added, min_in_group_fraction, min_fold_change, max_out_group_fraction). 725 var_names,. 726 groupby='__is_in_cluster__',. --> 727 use_raw=use_raw,. 728 ). 729 . /usr/local/lib/python3.6/dist-packages/scanpy/plotting/_anndata.py in _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer, gene_symbols). 1808 matrix = adata.raw[:, var_names].X. 1809 else:. -> 1810 matrix = adata[:, var_names].X. 1811 . 1812 if issparse(matrix):. /usr/local/lib/python3.6/dist-packages/anndata/_core/anndata.py in __getitem__(self, index). 1085 def __getitem__(self, index: Index) -> ""AnnData"":. 1086 """"""Returns a sliced view of the object."""""". -> 1087 oidx, vidx = self._normalize_indices(index). 1088 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1089 . /usr/local/lib/python3.6/dist-packages/anndata/_core/anndata.py in _normalize_indices(self, index). 1066 . 1067 def _normalize_indices(self, index: Optional[Index]) -> Tuple[slice, slice]:. -> 1068 return _normalize_indices(index, self.obs_names, self.var_names). 1069 . 1070 # TODO: this is not quite complete... /usr/local/lib/python3.6/dist-packages/anndata/_core/index.py in _normalize_indices(index, names0, names1). 33 ax0, ax1 = unpack_index(index). 34 ax0 = _normalize_index(ax0, names0). ---> 35 ax1 = _normalize_index(ax1, names1). 36 return ax0, ax1. 37 . /usr/local/lib/python3.6/dist-packages/anndata/_core/index.py in _normalize_index(indexer, index). 99 not_found = indexer[positions < 0]. 100 raise KeyError(. --> 101 f""Values {list(not_found)}, from {list(indexer)}, "". 102 ""are not valid obs/ var names or indices."". 103 ). KeyError: ""Values ['LINC00601', 'DPYS', 'AC136604.2', 'AC023137.1', 'MATN3', 'AL359921.1' . ... 'FAM129C', 'TCL1A'], are not valid obs/ var names or indices."". ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1487
https://github.com/scverse/scanpy/issues/1487:2693,safety,valid,valid,2693,"in_fold_change,use_raw=use_raw,. ----> 4 min_in_group_fraction=0.25,log=log). /usr/local/lib/python3.6/dist-packages/scanpy/tools/_rank_genes_groups.py in filter_rank_genes_groups(adata, key, groupby, use_raw, log, key_added, min_in_group_fraction, min_fold_change, max_out_group_fraction). 725 var_names,. 726 groupby='__is_in_cluster__',. --> 727 use_raw=use_raw,. 728 ). 729 . /usr/local/lib/python3.6/dist-packages/scanpy/plotting/_anndata.py in _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer, gene_symbols). 1808 matrix = adata.raw[:, var_names].X. 1809 else:. -> 1810 matrix = adata[:, var_names].X. 1811 . 1812 if issparse(matrix):. /usr/local/lib/python3.6/dist-packages/anndata/_core/anndata.py in __getitem__(self, index). 1085 def __getitem__(self, index: Index) -> ""AnnData"":. 1086 """"""Returns a sliced view of the object."""""". -> 1087 oidx, vidx = self._normalize_indices(index). 1088 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1089 . /usr/local/lib/python3.6/dist-packages/anndata/_core/anndata.py in _normalize_indices(self, index). 1066 . 1067 def _normalize_indices(self, index: Optional[Index]) -> Tuple[slice, slice]:. -> 1068 return _normalize_indices(index, self.obs_names, self.var_names). 1069 . 1070 # TODO: this is not quite complete... /usr/local/lib/python3.6/dist-packages/anndata/_core/index.py in _normalize_indices(index, names0, names1). 33 ax0, ax1 = unpack_index(index). 34 ax0 = _normalize_index(ax0, names0). ---> 35 ax1 = _normalize_index(ax1, names1). 36 return ax0, ax1. 37 . /usr/local/lib/python3.6/dist-packages/anndata/_core/index.py in _normalize_index(indexer, index). 99 not_found = indexer[positions < 0]. 100 raise KeyError(. --> 101 f""Values {list(not_found)}, from {list(indexer)}, "". 102 ""are not valid obs/ var names or indices."". 103 ). KeyError: ""Values ['LINC00601', 'DPYS', 'AC136604.2', 'AC023137.1', 'MATN3', 'AL359921.1' . ... 'FAM129C', 'TCL1A'], are not valid obs/ var names or indices."". ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1487
https://github.com/scverse/scanpy/issues/1487:358,security,log,log,358,"f""Values {list(not_found)}, from {list(indexer)}, "" ""are not valid obs/ var names or indices.""; This bug only occurred in 1.6.0 but not 1.5.0. I was running `scanpy 1.6.0` this:. `sc.tl.filter_rank_genes_groups(adata, groupby=obs,\. max_out_group_fraction=max_out_group_fraction,. min_fold_change=min_fold_change,use_raw=use_raw,. min_in_group_fraction=0.25,log=log)`. But got this error:. ```. Filtering genes using: min_in_group_fraction: 0.25 min_fold_change: 2, max_out_group_fraction: 0.25. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-91-d477dca208af> in <module>. 2 max_out_group_fraction=max_out_group_fraction,. 3 min_fold_change=min_fold_change,use_raw=use_raw,. ----> 4 min_in_group_fraction=0.25,log=log). /usr/local/lib/python3.6/dist-packages/scanpy/tools/_rank_genes_groups.py in filter_rank_genes_groups(adata, key, groupby, use_raw, log, key_added, min_in_group_fraction, min_fold_change, max_out_group_fraction). 725 var_names,. 726 groupby='__is_in_cluster__',. --> 727 use_raw=use_raw,. 728 ). 729 . /usr/local/lib/python3.6/dist-packages/scanpy/plotting/_anndata.py in _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer, gene_symbols). 1808 matrix = adata.raw[:, var_names].X. 1809 else:. -> 1810 matrix = adata[:, var_names].X. 1811 . 1812 if issparse(matrix):. /usr/local/lib/python3.6/dist-packages/anndata/_core/anndata.py in __getitem__(self, index). 1085 def __getitem__(self, index: Index) -> ""AnnData"":. 1086 """"""Returns a sliced view of the object."""""". -> 1087 oidx, vidx = self._normalize_indices(index). 1088 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1089 . /usr/local/lib/python3.6/dist-packages/anndata/_core/anndata.py in _normalize_indices(self, index). 1066 . 1067 def _normalize_indices(self, index: Optional[Index]) -> Tuple[slice, slice]:. -> 1068 return _normalize_indices(index, self.obs_names, self.var_names). 1069 . 107",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1487
https://github.com/scverse/scanpy/issues/1487:362,security,log,log,362,"f""Values {list(not_found)}, from {list(indexer)}, "" ""are not valid obs/ var names or indices.""; This bug only occurred in 1.6.0 but not 1.5.0. I was running `scanpy 1.6.0` this:. `sc.tl.filter_rank_genes_groups(adata, groupby=obs,\. max_out_group_fraction=max_out_group_fraction,. min_fold_change=min_fold_change,use_raw=use_raw,. min_in_group_fraction=0.25,log=log)`. But got this error:. ```. Filtering genes using: min_in_group_fraction: 0.25 min_fold_change: 2, max_out_group_fraction: 0.25. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-91-d477dca208af> in <module>. 2 max_out_group_fraction=max_out_group_fraction,. 3 min_fold_change=min_fold_change,use_raw=use_raw,. ----> 4 min_in_group_fraction=0.25,log=log). /usr/local/lib/python3.6/dist-packages/scanpy/tools/_rank_genes_groups.py in filter_rank_genes_groups(adata, key, groupby, use_raw, log, key_added, min_in_group_fraction, min_fold_change, max_out_group_fraction). 725 var_names,. 726 groupby='__is_in_cluster__',. --> 727 use_raw=use_raw,. 728 ). 729 . /usr/local/lib/python3.6/dist-packages/scanpy/plotting/_anndata.py in _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer, gene_symbols). 1808 matrix = adata.raw[:, var_names].X. 1809 else:. -> 1810 matrix = adata[:, var_names].X. 1811 . 1812 if issparse(matrix):. /usr/local/lib/python3.6/dist-packages/anndata/_core/anndata.py in __getitem__(self, index). 1085 def __getitem__(self, index: Index) -> ""AnnData"":. 1086 """"""Returns a sliced view of the object."""""". -> 1087 oidx, vidx = self._normalize_indices(index). 1088 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1089 . /usr/local/lib/python3.6/dist-packages/anndata/_core/anndata.py in _normalize_indices(self, index). 1066 . 1067 def _normalize_indices(self, index: Optional[Index]) -> Tuple[slice, slice]:. -> 1068 return _normalize_indices(index, self.obs_names, self.var_names). 1069 . 107",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1487
https://github.com/scverse/scanpy/issues/1487:799,security,log,log,799,"f""Values {list(not_found)}, from {list(indexer)}, "" ""are not valid obs/ var names or indices.""; This bug only occurred in 1.6.0 but not 1.5.0. I was running `scanpy 1.6.0` this:. `sc.tl.filter_rank_genes_groups(adata, groupby=obs,\. max_out_group_fraction=max_out_group_fraction,. min_fold_change=min_fold_change,use_raw=use_raw,. min_in_group_fraction=0.25,log=log)`. But got this error:. ```. Filtering genes using: min_in_group_fraction: 0.25 min_fold_change: 2, max_out_group_fraction: 0.25. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-91-d477dca208af> in <module>. 2 max_out_group_fraction=max_out_group_fraction,. 3 min_fold_change=min_fold_change,use_raw=use_raw,. ----> 4 min_in_group_fraction=0.25,log=log). /usr/local/lib/python3.6/dist-packages/scanpy/tools/_rank_genes_groups.py in filter_rank_genes_groups(adata, key, groupby, use_raw, log, key_added, min_in_group_fraction, min_fold_change, max_out_group_fraction). 725 var_names,. 726 groupby='__is_in_cluster__',. --> 727 use_raw=use_raw,. 728 ). 729 . /usr/local/lib/python3.6/dist-packages/scanpy/plotting/_anndata.py in _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer, gene_symbols). 1808 matrix = adata.raw[:, var_names].X. 1809 else:. -> 1810 matrix = adata[:, var_names].X. 1811 . 1812 if issparse(matrix):. /usr/local/lib/python3.6/dist-packages/anndata/_core/anndata.py in __getitem__(self, index). 1085 def __getitem__(self, index: Index) -> ""AnnData"":. 1086 """"""Returns a sliced view of the object."""""". -> 1087 oidx, vidx = self._normalize_indices(index). 1088 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1089 . /usr/local/lib/python3.6/dist-packages/anndata/_core/anndata.py in _normalize_indices(self, index). 1066 . 1067 def _normalize_indices(self, index: Optional[Index]) -> Tuple[slice, slice]:. -> 1068 return _normalize_indices(index, self.obs_names, self.var_names). 1069 . 107",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1487
https://github.com/scverse/scanpy/issues/1487:803,security,log,log,803,"f""Values {list(not_found)}, from {list(indexer)}, "" ""are not valid obs/ var names or indices.""; This bug only occurred in 1.6.0 but not 1.5.0. I was running `scanpy 1.6.0` this:. `sc.tl.filter_rank_genes_groups(adata, groupby=obs,\. max_out_group_fraction=max_out_group_fraction,. min_fold_change=min_fold_change,use_raw=use_raw,. min_in_group_fraction=0.25,log=log)`. But got this error:. ```. Filtering genes using: min_in_group_fraction: 0.25 min_fold_change: 2, max_out_group_fraction: 0.25. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-91-d477dca208af> in <module>. 2 max_out_group_fraction=max_out_group_fraction,. 3 min_fold_change=min_fold_change,use_raw=use_raw,. ----> 4 min_in_group_fraction=0.25,log=log). /usr/local/lib/python3.6/dist-packages/scanpy/tools/_rank_genes_groups.py in filter_rank_genes_groups(adata, key, groupby, use_raw, log, key_added, min_in_group_fraction, min_fold_change, max_out_group_fraction). 725 var_names,. 726 groupby='__is_in_cluster__',. --> 727 use_raw=use_raw,. 728 ). 729 . /usr/local/lib/python3.6/dist-packages/scanpy/plotting/_anndata.py in _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer, gene_symbols). 1808 matrix = adata.raw[:, var_names].X. 1809 else:. -> 1810 matrix = adata[:, var_names].X. 1811 . 1812 if issparse(matrix):. /usr/local/lib/python3.6/dist-packages/anndata/_core/anndata.py in __getitem__(self, index). 1085 def __getitem__(self, index: Index) -> ""AnnData"":. 1086 """"""Returns a sliced view of the object."""""". -> 1087 oidx, vidx = self._normalize_indices(index). 1088 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1089 . /usr/local/lib/python3.6/dist-packages/anndata/_core/anndata.py in _normalize_indices(self, index). 1066 . 1067 def _normalize_indices(self, index: Optional[Index]) -> Tuple[slice, slice]:. -> 1068 return _normalize_indices(index, self.obs_names, self.var_names). 1069 . 107",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1487
https://github.com/scverse/scanpy/issues/1487:941,security,log,log,941,"f""Values {list(not_found)}, from {list(indexer)}, "" ""are not valid obs/ var names or indices.""; This bug only occurred in 1.6.0 but not 1.5.0. I was running `scanpy 1.6.0` this:. `sc.tl.filter_rank_genes_groups(adata, groupby=obs,\. max_out_group_fraction=max_out_group_fraction,. min_fold_change=min_fold_change,use_raw=use_raw,. min_in_group_fraction=0.25,log=log)`. But got this error:. ```. Filtering genes using: min_in_group_fraction: 0.25 min_fold_change: 2, max_out_group_fraction: 0.25. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-91-d477dca208af> in <module>. 2 max_out_group_fraction=max_out_group_fraction,. 3 min_fold_change=min_fold_change,use_raw=use_raw,. ----> 4 min_in_group_fraction=0.25,log=log). /usr/local/lib/python3.6/dist-packages/scanpy/tools/_rank_genes_groups.py in filter_rank_genes_groups(adata, key, groupby, use_raw, log, key_added, min_in_group_fraction, min_fold_change, max_out_group_fraction). 725 var_names,. 726 groupby='__is_in_cluster__',. --> 727 use_raw=use_raw,. 728 ). 729 . /usr/local/lib/python3.6/dist-packages/scanpy/plotting/_anndata.py in _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer, gene_symbols). 1808 matrix = adata.raw[:, var_names].X. 1809 else:. -> 1810 matrix = adata[:, var_names].X. 1811 . 1812 if issparse(matrix):. /usr/local/lib/python3.6/dist-packages/anndata/_core/anndata.py in __getitem__(self, index). 1085 def __getitem__(self, index: Index) -> ""AnnData"":. 1086 """"""Returns a sliced view of the object."""""". -> 1087 oidx, vidx = self._normalize_indices(index). 1088 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1089 . /usr/local/lib/python3.6/dist-packages/anndata/_core/anndata.py in _normalize_indices(self, index). 1066 . 1067 def _normalize_indices(self, index: Optional[Index]) -> Tuple[slice, slice]:. -> 1068 return _normalize_indices(index, self.obs_names, self.var_names). 1069 . 107",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1487
https://github.com/scverse/scanpy/issues/1487:1236,security,log,log,1236,"ut_group_fraction=max_out_group_fraction,. min_fold_change=min_fold_change,use_raw=use_raw,. min_in_group_fraction=0.25,log=log)`. But got this error:. ```. Filtering genes using: min_in_group_fraction: 0.25 min_fold_change: 2, max_out_group_fraction: 0.25. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-91-d477dca208af> in <module>. 2 max_out_group_fraction=max_out_group_fraction,. 3 min_fold_change=min_fold_change,use_raw=use_raw,. ----> 4 min_in_group_fraction=0.25,log=log). /usr/local/lib/python3.6/dist-packages/scanpy/tools/_rank_genes_groups.py in filter_rank_genes_groups(adata, key, groupby, use_raw, log, key_added, min_in_group_fraction, min_fold_change, max_out_group_fraction). 725 var_names,. 726 groupby='__is_in_cluster__',. --> 727 use_raw=use_raw,. 728 ). 729 . /usr/local/lib/python3.6/dist-packages/scanpy/plotting/_anndata.py in _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer, gene_symbols). 1808 matrix = adata.raw[:, var_names].X. 1809 else:. -> 1810 matrix = adata[:, var_names].X. 1811 . 1812 if issparse(matrix):. /usr/local/lib/python3.6/dist-packages/anndata/_core/anndata.py in __getitem__(self, index). 1085 def __getitem__(self, index: Index) -> ""AnnData"":. 1086 """"""Returns a sliced view of the object."""""". -> 1087 oidx, vidx = self._normalize_indices(index). 1088 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1089 . /usr/local/lib/python3.6/dist-packages/anndata/_core/anndata.py in _normalize_indices(self, index). 1066 . 1067 def _normalize_indices(self, index: Optional[Index]) -> Tuple[slice, slice]:. -> 1068 return _normalize_indices(index, self.obs_names, self.var_names). 1069 . 1070 # TODO: this is not quite complete... /usr/local/lib/python3.6/dist-packages/anndata/_core/index.py in _normalize_indices(index, names0, names1). 33 ax0, ax1 = unpack_index(index). 34 ax0 = _normalize_index(ax0, names0). ---> 35 ax1 = _",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1487
https://github.com/scverse/scanpy/issues/1487:2028,security,compl,complete,2028,"in_fold_change,use_raw=use_raw,. ----> 4 min_in_group_fraction=0.25,log=log). /usr/local/lib/python3.6/dist-packages/scanpy/tools/_rank_genes_groups.py in filter_rank_genes_groups(adata, key, groupby, use_raw, log, key_added, min_in_group_fraction, min_fold_change, max_out_group_fraction). 725 var_names,. 726 groupby='__is_in_cluster__',. --> 727 use_raw=use_raw,. 728 ). 729 . /usr/local/lib/python3.6/dist-packages/scanpy/plotting/_anndata.py in _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer, gene_symbols). 1808 matrix = adata.raw[:, var_names].X. 1809 else:. -> 1810 matrix = adata[:, var_names].X. 1811 . 1812 if issparse(matrix):. /usr/local/lib/python3.6/dist-packages/anndata/_core/anndata.py in __getitem__(self, index). 1085 def __getitem__(self, index: Index) -> ""AnnData"":. 1086 """"""Returns a sliced view of the object."""""". -> 1087 oidx, vidx = self._normalize_indices(index). 1088 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1089 . /usr/local/lib/python3.6/dist-packages/anndata/_core/anndata.py in _normalize_indices(self, index). 1066 . 1067 def _normalize_indices(self, index: Optional[Index]) -> Tuple[slice, slice]:. -> 1068 return _normalize_indices(index, self.obs_names, self.var_names). 1069 . 1070 # TODO: this is not quite complete... /usr/local/lib/python3.6/dist-packages/anndata/_core/index.py in _normalize_indices(index, names0, names1). 33 ax0, ax1 = unpack_index(index). 34 ax0 = _normalize_index(ax0, names0). ---> 35 ax1 = _normalize_index(ax1, names1). 36 return ax0, ax1. 37 . /usr/local/lib/python3.6/dist-packages/anndata/_core/index.py in _normalize_index(indexer, index). 99 not_found = indexer[positions < 0]. 100 raise KeyError(. --> 101 f""Values {list(not_found)}, from {list(indexer)}, "". 102 ""are not valid obs/ var names or indices."". 103 ). KeyError: ""Values ['LINC00601', 'DPYS', 'AC136604.2', 'AC023137.1', 'MATN3', 'AL359921.1' . ... 'FAM129C', 'TCL1A'], are not valid obs/ var names or indices."". ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1487
https://github.com/scverse/scanpy/issues/1487:358,testability,log,log,358,"f""Values {list(not_found)}, from {list(indexer)}, "" ""are not valid obs/ var names or indices.""; This bug only occurred in 1.6.0 but not 1.5.0. I was running `scanpy 1.6.0` this:. `sc.tl.filter_rank_genes_groups(adata, groupby=obs,\. max_out_group_fraction=max_out_group_fraction,. min_fold_change=min_fold_change,use_raw=use_raw,. min_in_group_fraction=0.25,log=log)`. But got this error:. ```. Filtering genes using: min_in_group_fraction: 0.25 min_fold_change: 2, max_out_group_fraction: 0.25. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-91-d477dca208af> in <module>. 2 max_out_group_fraction=max_out_group_fraction,. 3 min_fold_change=min_fold_change,use_raw=use_raw,. ----> 4 min_in_group_fraction=0.25,log=log). /usr/local/lib/python3.6/dist-packages/scanpy/tools/_rank_genes_groups.py in filter_rank_genes_groups(adata, key, groupby, use_raw, log, key_added, min_in_group_fraction, min_fold_change, max_out_group_fraction). 725 var_names,. 726 groupby='__is_in_cluster__',. --> 727 use_raw=use_raw,. 728 ). 729 . /usr/local/lib/python3.6/dist-packages/scanpy/plotting/_anndata.py in _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer, gene_symbols). 1808 matrix = adata.raw[:, var_names].X. 1809 else:. -> 1810 matrix = adata[:, var_names].X. 1811 . 1812 if issparse(matrix):. /usr/local/lib/python3.6/dist-packages/anndata/_core/anndata.py in __getitem__(self, index). 1085 def __getitem__(self, index: Index) -> ""AnnData"":. 1086 """"""Returns a sliced view of the object."""""". -> 1087 oidx, vidx = self._normalize_indices(index). 1088 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1089 . /usr/local/lib/python3.6/dist-packages/anndata/_core/anndata.py in _normalize_indices(self, index). 1066 . 1067 def _normalize_indices(self, index: Optional[Index]) -> Tuple[slice, slice]:. -> 1068 return _normalize_indices(index, self.obs_names, self.var_names). 1069 . 107",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1487
https://github.com/scverse/scanpy/issues/1487:362,testability,log,log,362,"f""Values {list(not_found)}, from {list(indexer)}, "" ""are not valid obs/ var names or indices.""; This bug only occurred in 1.6.0 but not 1.5.0. I was running `scanpy 1.6.0` this:. `sc.tl.filter_rank_genes_groups(adata, groupby=obs,\. max_out_group_fraction=max_out_group_fraction,. min_fold_change=min_fold_change,use_raw=use_raw,. min_in_group_fraction=0.25,log=log)`. But got this error:. ```. Filtering genes using: min_in_group_fraction: 0.25 min_fold_change: 2, max_out_group_fraction: 0.25. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-91-d477dca208af> in <module>. 2 max_out_group_fraction=max_out_group_fraction,. 3 min_fold_change=min_fold_change,use_raw=use_raw,. ----> 4 min_in_group_fraction=0.25,log=log). /usr/local/lib/python3.6/dist-packages/scanpy/tools/_rank_genes_groups.py in filter_rank_genes_groups(adata, key, groupby, use_raw, log, key_added, min_in_group_fraction, min_fold_change, max_out_group_fraction). 725 var_names,. 726 groupby='__is_in_cluster__',. --> 727 use_raw=use_raw,. 728 ). 729 . /usr/local/lib/python3.6/dist-packages/scanpy/plotting/_anndata.py in _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer, gene_symbols). 1808 matrix = adata.raw[:, var_names].X. 1809 else:. -> 1810 matrix = adata[:, var_names].X. 1811 . 1812 if issparse(matrix):. /usr/local/lib/python3.6/dist-packages/anndata/_core/anndata.py in __getitem__(self, index). 1085 def __getitem__(self, index: Index) -> ""AnnData"":. 1086 """"""Returns a sliced view of the object."""""". -> 1087 oidx, vidx = self._normalize_indices(index). 1088 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1089 . /usr/local/lib/python3.6/dist-packages/anndata/_core/anndata.py in _normalize_indices(self, index). 1066 . 1067 def _normalize_indices(self, index: Optional[Index]) -> Tuple[slice, slice]:. -> 1068 return _normalize_indices(index, self.obs_names, self.var_names). 1069 . 107",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1487
https://github.com/scverse/scanpy/issues/1487:582,testability,Trace,Traceback,582,"f""Values {list(not_found)}, from {list(indexer)}, "" ""are not valid obs/ var names or indices.""; This bug only occurred in 1.6.0 but not 1.5.0. I was running `scanpy 1.6.0` this:. `sc.tl.filter_rank_genes_groups(adata, groupby=obs,\. max_out_group_fraction=max_out_group_fraction,. min_fold_change=min_fold_change,use_raw=use_raw,. min_in_group_fraction=0.25,log=log)`. But got this error:. ```. Filtering genes using: min_in_group_fraction: 0.25 min_fold_change: 2, max_out_group_fraction: 0.25. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-91-d477dca208af> in <module>. 2 max_out_group_fraction=max_out_group_fraction,. 3 min_fold_change=min_fold_change,use_raw=use_raw,. ----> 4 min_in_group_fraction=0.25,log=log). /usr/local/lib/python3.6/dist-packages/scanpy/tools/_rank_genes_groups.py in filter_rank_genes_groups(adata, key, groupby, use_raw, log, key_added, min_in_group_fraction, min_fold_change, max_out_group_fraction). 725 var_names,. 726 groupby='__is_in_cluster__',. --> 727 use_raw=use_raw,. 728 ). 729 . /usr/local/lib/python3.6/dist-packages/scanpy/plotting/_anndata.py in _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer, gene_symbols). 1808 matrix = adata.raw[:, var_names].X. 1809 else:. -> 1810 matrix = adata[:, var_names].X. 1811 . 1812 if issparse(matrix):. /usr/local/lib/python3.6/dist-packages/anndata/_core/anndata.py in __getitem__(self, index). 1085 def __getitem__(self, index: Index) -> ""AnnData"":. 1086 """"""Returns a sliced view of the object."""""". -> 1087 oidx, vidx = self._normalize_indices(index). 1088 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1089 . /usr/local/lib/python3.6/dist-packages/anndata/_core/anndata.py in _normalize_indices(self, index). 1066 . 1067 def _normalize_indices(self, index: Optional[Index]) -> Tuple[slice, slice]:. -> 1068 return _normalize_indices(index, self.obs_names, self.var_names). 1069 . 107",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1487
https://github.com/scverse/scanpy/issues/1487:799,testability,log,log,799,"f""Values {list(not_found)}, from {list(indexer)}, "" ""are not valid obs/ var names or indices.""; This bug only occurred in 1.6.0 but not 1.5.0. I was running `scanpy 1.6.0` this:. `sc.tl.filter_rank_genes_groups(adata, groupby=obs,\. max_out_group_fraction=max_out_group_fraction,. min_fold_change=min_fold_change,use_raw=use_raw,. min_in_group_fraction=0.25,log=log)`. But got this error:. ```. Filtering genes using: min_in_group_fraction: 0.25 min_fold_change: 2, max_out_group_fraction: 0.25. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-91-d477dca208af> in <module>. 2 max_out_group_fraction=max_out_group_fraction,. 3 min_fold_change=min_fold_change,use_raw=use_raw,. ----> 4 min_in_group_fraction=0.25,log=log). /usr/local/lib/python3.6/dist-packages/scanpy/tools/_rank_genes_groups.py in filter_rank_genes_groups(adata, key, groupby, use_raw, log, key_added, min_in_group_fraction, min_fold_change, max_out_group_fraction). 725 var_names,. 726 groupby='__is_in_cluster__',. --> 727 use_raw=use_raw,. 728 ). 729 . /usr/local/lib/python3.6/dist-packages/scanpy/plotting/_anndata.py in _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer, gene_symbols). 1808 matrix = adata.raw[:, var_names].X. 1809 else:. -> 1810 matrix = adata[:, var_names].X. 1811 . 1812 if issparse(matrix):. /usr/local/lib/python3.6/dist-packages/anndata/_core/anndata.py in __getitem__(self, index). 1085 def __getitem__(self, index: Index) -> ""AnnData"":. 1086 """"""Returns a sliced view of the object."""""". -> 1087 oidx, vidx = self._normalize_indices(index). 1088 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1089 . /usr/local/lib/python3.6/dist-packages/anndata/_core/anndata.py in _normalize_indices(self, index). 1066 . 1067 def _normalize_indices(self, index: Optional[Index]) -> Tuple[slice, slice]:. -> 1068 return _normalize_indices(index, self.obs_names, self.var_names). 1069 . 107",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1487
https://github.com/scverse/scanpy/issues/1487:803,testability,log,log,803,"f""Values {list(not_found)}, from {list(indexer)}, "" ""are not valid obs/ var names or indices.""; This bug only occurred in 1.6.0 but not 1.5.0. I was running `scanpy 1.6.0` this:. `sc.tl.filter_rank_genes_groups(adata, groupby=obs,\. max_out_group_fraction=max_out_group_fraction,. min_fold_change=min_fold_change,use_raw=use_raw,. min_in_group_fraction=0.25,log=log)`. But got this error:. ```. Filtering genes using: min_in_group_fraction: 0.25 min_fold_change: 2, max_out_group_fraction: 0.25. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-91-d477dca208af> in <module>. 2 max_out_group_fraction=max_out_group_fraction,. 3 min_fold_change=min_fold_change,use_raw=use_raw,. ----> 4 min_in_group_fraction=0.25,log=log). /usr/local/lib/python3.6/dist-packages/scanpy/tools/_rank_genes_groups.py in filter_rank_genes_groups(adata, key, groupby, use_raw, log, key_added, min_in_group_fraction, min_fold_change, max_out_group_fraction). 725 var_names,. 726 groupby='__is_in_cluster__',. --> 727 use_raw=use_raw,. 728 ). 729 . /usr/local/lib/python3.6/dist-packages/scanpy/plotting/_anndata.py in _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer, gene_symbols). 1808 matrix = adata.raw[:, var_names].X. 1809 else:. -> 1810 matrix = adata[:, var_names].X. 1811 . 1812 if issparse(matrix):. /usr/local/lib/python3.6/dist-packages/anndata/_core/anndata.py in __getitem__(self, index). 1085 def __getitem__(self, index: Index) -> ""AnnData"":. 1086 """"""Returns a sliced view of the object."""""". -> 1087 oidx, vidx = self._normalize_indices(index). 1088 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1089 . /usr/local/lib/python3.6/dist-packages/anndata/_core/anndata.py in _normalize_indices(self, index). 1066 . 1067 def _normalize_indices(self, index: Optional[Index]) -> Tuple[slice, slice]:. -> 1068 return _normalize_indices(index, self.obs_names, self.var_names). 1069 . 107",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1487
https://github.com/scverse/scanpy/issues/1487:941,testability,log,log,941,"f""Values {list(not_found)}, from {list(indexer)}, "" ""are not valid obs/ var names or indices.""; This bug only occurred in 1.6.0 but not 1.5.0. I was running `scanpy 1.6.0` this:. `sc.tl.filter_rank_genes_groups(adata, groupby=obs,\. max_out_group_fraction=max_out_group_fraction,. min_fold_change=min_fold_change,use_raw=use_raw,. min_in_group_fraction=0.25,log=log)`. But got this error:. ```. Filtering genes using: min_in_group_fraction: 0.25 min_fold_change: 2, max_out_group_fraction: 0.25. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-91-d477dca208af> in <module>. 2 max_out_group_fraction=max_out_group_fraction,. 3 min_fold_change=min_fold_change,use_raw=use_raw,. ----> 4 min_in_group_fraction=0.25,log=log). /usr/local/lib/python3.6/dist-packages/scanpy/tools/_rank_genes_groups.py in filter_rank_genes_groups(adata, key, groupby, use_raw, log, key_added, min_in_group_fraction, min_fold_change, max_out_group_fraction). 725 var_names,. 726 groupby='__is_in_cluster__',. --> 727 use_raw=use_raw,. 728 ). 729 . /usr/local/lib/python3.6/dist-packages/scanpy/plotting/_anndata.py in _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer, gene_symbols). 1808 matrix = adata.raw[:, var_names].X. 1809 else:. -> 1810 matrix = adata[:, var_names].X. 1811 . 1812 if issparse(matrix):. /usr/local/lib/python3.6/dist-packages/anndata/_core/anndata.py in __getitem__(self, index). 1085 def __getitem__(self, index: Index) -> ""AnnData"":. 1086 """"""Returns a sliced view of the object."""""". -> 1087 oidx, vidx = self._normalize_indices(index). 1088 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1089 . /usr/local/lib/python3.6/dist-packages/anndata/_core/anndata.py in _normalize_indices(self, index). 1066 . 1067 def _normalize_indices(self, index: Optional[Index]) -> Tuple[slice, slice]:. -> 1068 return _normalize_indices(index, self.obs_names, self.var_names). 1069 . 107",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1487
https://github.com/scverse/scanpy/issues/1487:1236,testability,log,log,1236,"ut_group_fraction=max_out_group_fraction,. min_fold_change=min_fold_change,use_raw=use_raw,. min_in_group_fraction=0.25,log=log)`. But got this error:. ```. Filtering genes using: min_in_group_fraction: 0.25 min_fold_change: 2, max_out_group_fraction: 0.25. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-91-d477dca208af> in <module>. 2 max_out_group_fraction=max_out_group_fraction,. 3 min_fold_change=min_fold_change,use_raw=use_raw,. ----> 4 min_in_group_fraction=0.25,log=log). /usr/local/lib/python3.6/dist-packages/scanpy/tools/_rank_genes_groups.py in filter_rank_genes_groups(adata, key, groupby, use_raw, log, key_added, min_in_group_fraction, min_fold_change, max_out_group_fraction). 725 var_names,. 726 groupby='__is_in_cluster__',. --> 727 use_raw=use_raw,. 728 ). 729 . /usr/local/lib/python3.6/dist-packages/scanpy/plotting/_anndata.py in _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer, gene_symbols). 1808 matrix = adata.raw[:, var_names].X. 1809 else:. -> 1810 matrix = adata[:, var_names].X. 1811 . 1812 if issparse(matrix):. /usr/local/lib/python3.6/dist-packages/anndata/_core/anndata.py in __getitem__(self, index). 1085 def __getitem__(self, index: Index) -> ""AnnData"":. 1086 """"""Returns a sliced view of the object."""""". -> 1087 oidx, vidx = self._normalize_indices(index). 1088 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1089 . /usr/local/lib/python3.6/dist-packages/anndata/_core/anndata.py in _normalize_indices(self, index). 1066 . 1067 def _normalize_indices(self, index: Optional[Index]) -> Tuple[slice, slice]:. -> 1068 return _normalize_indices(index, self.obs_names, self.var_names). 1069 . 1070 # TODO: this is not quite complete... /usr/local/lib/python3.6/dist-packages/anndata/_core/index.py in _normalize_indices(index, names0, names1). 33 ax0, ax1 = unpack_index(index). 34 ax0 = _normalize_index(ax0, names0). ---> 35 ax1 = _",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1487
https://github.com/scverse/scanpy/issues/1487:382,usability,error,error,382,"f""Values {list(not_found)}, from {list(indexer)}, "" ""are not valid obs/ var names or indices.""; This bug only occurred in 1.6.0 but not 1.5.0. I was running `scanpy 1.6.0` this:. `sc.tl.filter_rank_genes_groups(adata, groupby=obs,\. max_out_group_fraction=max_out_group_fraction,. min_fold_change=min_fold_change,use_raw=use_raw,. min_in_group_fraction=0.25,log=log)`. But got this error:. ```. Filtering genes using: min_in_group_fraction: 0.25 min_fold_change: 2, max_out_group_fraction: 0.25. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-91-d477dca208af> in <module>. 2 max_out_group_fraction=max_out_group_fraction,. 3 min_fold_change=min_fold_change,use_raw=use_raw,. ----> 4 min_in_group_fraction=0.25,log=log). /usr/local/lib/python3.6/dist-packages/scanpy/tools/_rank_genes_groups.py in filter_rank_genes_groups(adata, key, groupby, use_raw, log, key_added, min_in_group_fraction, min_fold_change, max_out_group_fraction). 725 var_names,. 726 groupby='__is_in_cluster__',. --> 727 use_raw=use_raw,. 728 ). 729 . /usr/local/lib/python3.6/dist-packages/scanpy/plotting/_anndata.py in _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer, gene_symbols). 1808 matrix = adata.raw[:, var_names].X. 1809 else:. -> 1810 matrix = adata[:, var_names].X. 1811 . 1812 if issparse(matrix):. /usr/local/lib/python3.6/dist-packages/anndata/_core/anndata.py in __getitem__(self, index). 1085 def __getitem__(self, index: Index) -> ""AnnData"":. 1086 """"""Returns a sliced view of the object."""""". -> 1087 oidx, vidx = self._normalize_indices(index). 1088 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1089 . /usr/local/lib/python3.6/dist-packages/anndata/_core/anndata.py in _normalize_indices(self, index). 1066 . 1067 def _normalize_indices(self, index: Optional[Index]) -> Tuple[slice, slice]:. -> 1068 return _normalize_indices(index, self.obs_names, self.var_names). 1069 . 107",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1487
https://github.com/scverse/scanpy/issues/1487:626,usability,input,input-,626,"f""Values {list(not_found)}, from {list(indexer)}, "" ""are not valid obs/ var names or indices.""; This bug only occurred in 1.6.0 but not 1.5.0. I was running `scanpy 1.6.0` this:. `sc.tl.filter_rank_genes_groups(adata, groupby=obs,\. max_out_group_fraction=max_out_group_fraction,. min_fold_change=min_fold_change,use_raw=use_raw,. min_in_group_fraction=0.25,log=log)`. But got this error:. ```. Filtering genes using: min_in_group_fraction: 0.25 min_fold_change: 2, max_out_group_fraction: 0.25. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-91-d477dca208af> in <module>. 2 max_out_group_fraction=max_out_group_fraction,. 3 min_fold_change=min_fold_change,use_raw=use_raw,. ----> 4 min_in_group_fraction=0.25,log=log). /usr/local/lib/python3.6/dist-packages/scanpy/tools/_rank_genes_groups.py in filter_rank_genes_groups(adata, key, groupby, use_raw, log, key_added, min_in_group_fraction, min_fold_change, max_out_group_fraction). 725 var_names,. 726 groupby='__is_in_cluster__',. --> 727 use_raw=use_raw,. 728 ). 729 . /usr/local/lib/python3.6/dist-packages/scanpy/plotting/_anndata.py in _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer, gene_symbols). 1808 matrix = adata.raw[:, var_names].X. 1809 else:. -> 1810 matrix = adata[:, var_names].X. 1811 . 1812 if issparse(matrix):. /usr/local/lib/python3.6/dist-packages/anndata/_core/anndata.py in __getitem__(self, index). 1085 def __getitem__(self, index: Index) -> ""AnnData"":. 1086 """"""Returns a sliced view of the object."""""". -> 1087 oidx, vidx = self._normalize_indices(index). 1088 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1089 . /usr/local/lib/python3.6/dist-packages/anndata/_core/anndata.py in _normalize_indices(self, index). 1066 . 1067 def _normalize_indices(self, index: Optional[Index]) -> Tuple[slice, slice]:. -> 1068 return _normalize_indices(index, self.obs_names, self.var_names). 1069 . 107",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1487
https://github.com/scverse/scanpy/issues/1487:855,usability,tool,tools,855,"f""Values {list(not_found)}, from {list(indexer)}, "" ""are not valid obs/ var names or indices.""; This bug only occurred in 1.6.0 but not 1.5.0. I was running `scanpy 1.6.0` this:. `sc.tl.filter_rank_genes_groups(adata, groupby=obs,\. max_out_group_fraction=max_out_group_fraction,. min_fold_change=min_fold_change,use_raw=use_raw,. min_in_group_fraction=0.25,log=log)`. But got this error:. ```. Filtering genes using: min_in_group_fraction: 0.25 min_fold_change: 2, max_out_group_fraction: 0.25. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-91-d477dca208af> in <module>. 2 max_out_group_fraction=max_out_group_fraction,. 3 min_fold_change=min_fold_change,use_raw=use_raw,. ----> 4 min_in_group_fraction=0.25,log=log). /usr/local/lib/python3.6/dist-packages/scanpy/tools/_rank_genes_groups.py in filter_rank_genes_groups(adata, key, groupby, use_raw, log, key_added, min_in_group_fraction, min_fold_change, max_out_group_fraction). 725 var_names,. 726 groupby='__is_in_cluster__',. --> 727 use_raw=use_raw,. 728 ). 729 . /usr/local/lib/python3.6/dist-packages/scanpy/plotting/_anndata.py in _prepare_dataframe(adata, var_names, groupby, use_raw, log, num_categories, layer, gene_symbols). 1808 matrix = adata.raw[:, var_names].X. 1809 else:. -> 1810 matrix = adata[:, var_names].X. 1811 . 1812 if issparse(matrix):. /usr/local/lib/python3.6/dist-packages/anndata/_core/anndata.py in __getitem__(self, index). 1085 def __getitem__(self, index: Index) -> ""AnnData"":. 1086 """"""Returns a sliced view of the object."""""". -> 1087 oidx, vidx = self._normalize_indices(index). 1088 return AnnData(self, oidx=oidx, vidx=vidx, asview=True). 1089 . /usr/local/lib/python3.6/dist-packages/anndata/_core/anndata.py in _normalize_indices(self, index). 1066 . 1067 def _normalize_indices(self, index: Optional[Index]) -> Tuple[slice, slice]:. -> 1068 return _normalize_indices(index, self.obs_names, self.var_names). 1069 . 107",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1487
https://github.com/scverse/scanpy/pull/1488:467,interoperability,convers,conversion,467,"Add dict input support to sc.queries.enrich; Adds support for using dictionary inputs to sc.queries.enrich to make bulk queries:. So instead of. ```python. df1 = sc.queries.enrich(['KLF4', 'PAX5']). df2 = sc.queries.enrich(['SOX2', 'NANOG']). ...concat... ```. we can now do. ```python. df = sc.queries.enrich({'set1':['KLF4', 'PAX5'], 'set2':['SOX2', 'NANOG']}). ```. (I mean this was already supported by gprofiler, but it was simply broken due to an explicit list conversion).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1488
https://github.com/scverse/scanpy/pull/1488:9,safety,input,input,9,"Add dict input support to sc.queries.enrich; Adds support for using dictionary inputs to sc.queries.enrich to make bulk queries:. So instead of. ```python. df1 = sc.queries.enrich(['KLF4', 'PAX5']). df2 = sc.queries.enrich(['SOX2', 'NANOG']). ...concat... ```. we can now do. ```python. df = sc.queries.enrich({'set1':['KLF4', 'PAX5'], 'set2':['SOX2', 'NANOG']}). ```. (I mean this was already supported by gprofiler, but it was simply broken due to an explicit list conversion).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1488
https://github.com/scverse/scanpy/pull/1488:79,safety,input,inputs,79,"Add dict input support to sc.queries.enrich; Adds support for using dictionary inputs to sc.queries.enrich to make bulk queries:. So instead of. ```python. df1 = sc.queries.enrich(['KLF4', 'PAX5']). df2 = sc.queries.enrich(['SOX2', 'NANOG']). ...concat... ```. we can now do. ```python. df = sc.queries.enrich({'set1':['KLF4', 'PAX5'], 'set2':['SOX2', 'NANOG']}). ```. (I mean this was already supported by gprofiler, but it was simply broken due to an explicit list conversion).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1488
https://github.com/scverse/scanpy/pull/1488:429,testability,simpl,simply,429,"Add dict input support to sc.queries.enrich; Adds support for using dictionary inputs to sc.queries.enrich to make bulk queries:. So instead of. ```python. df1 = sc.queries.enrich(['KLF4', 'PAX5']). df2 = sc.queries.enrich(['SOX2', 'NANOG']). ...concat... ```. we can now do. ```python. df = sc.queries.enrich({'set1':['KLF4', 'PAX5'], 'set2':['SOX2', 'NANOG']}). ```. (I mean this was already supported by gprofiler, but it was simply broken due to an explicit list conversion).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1488
https://github.com/scverse/scanpy/pull/1488:9,usability,input,input,9,"Add dict input support to sc.queries.enrich; Adds support for using dictionary inputs to sc.queries.enrich to make bulk queries:. So instead of. ```python. df1 = sc.queries.enrich(['KLF4', 'PAX5']). df2 = sc.queries.enrich(['SOX2', 'NANOG']). ...concat... ```. we can now do. ```python. df = sc.queries.enrich({'set1':['KLF4', 'PAX5'], 'set2':['SOX2', 'NANOG']}). ```. (I mean this was already supported by gprofiler, but it was simply broken due to an explicit list conversion).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1488
https://github.com/scverse/scanpy/pull/1488:15,usability,support,support,15,"Add dict input support to sc.queries.enrich; Adds support for using dictionary inputs to sc.queries.enrich to make bulk queries:. So instead of. ```python. df1 = sc.queries.enrich(['KLF4', 'PAX5']). df2 = sc.queries.enrich(['SOX2', 'NANOG']). ...concat... ```. we can now do. ```python. df = sc.queries.enrich({'set1':['KLF4', 'PAX5'], 'set2':['SOX2', 'NANOG']}). ```. (I mean this was already supported by gprofiler, but it was simply broken due to an explicit list conversion).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1488
https://github.com/scverse/scanpy/pull/1488:50,usability,support,support,50,"Add dict input support to sc.queries.enrich; Adds support for using dictionary inputs to sc.queries.enrich to make bulk queries:. So instead of. ```python. df1 = sc.queries.enrich(['KLF4', 'PAX5']). df2 = sc.queries.enrich(['SOX2', 'NANOG']). ...concat... ```. we can now do. ```python. df = sc.queries.enrich({'set1':['KLF4', 'PAX5'], 'set2':['SOX2', 'NANOG']}). ```. (I mean this was already supported by gprofiler, but it was simply broken due to an explicit list conversion).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1488
https://github.com/scverse/scanpy/pull/1488:79,usability,input,inputs,79,"Add dict input support to sc.queries.enrich; Adds support for using dictionary inputs to sc.queries.enrich to make bulk queries:. So instead of. ```python. df1 = sc.queries.enrich(['KLF4', 'PAX5']). df2 = sc.queries.enrich(['SOX2', 'NANOG']). ...concat... ```. we can now do. ```python. df = sc.queries.enrich({'set1':['KLF4', 'PAX5'], 'set2':['SOX2', 'NANOG']}). ```. (I mean this was already supported by gprofiler, but it was simply broken due to an explicit list conversion).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1488
https://github.com/scverse/scanpy/pull/1488:394,usability,support,supported,394,"Add dict input support to sc.queries.enrich; Adds support for using dictionary inputs to sc.queries.enrich to make bulk queries:. So instead of. ```python. df1 = sc.queries.enrich(['KLF4', 'PAX5']). df2 = sc.queries.enrich(['SOX2', 'NANOG']). ...concat... ```. we can now do. ```python. df = sc.queries.enrich({'set1':['KLF4', 'PAX5'], 'set2':['SOX2', 'NANOG']}). ```. (I mean this was already supported by gprofiler, but it was simply broken due to an explicit list conversion).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1488
https://github.com/scverse/scanpy/pull/1488:429,usability,simpl,simply,429,"Add dict input support to sc.queries.enrich; Adds support for using dictionary inputs to sc.queries.enrich to make bulk queries:. So instead of. ```python. df1 = sc.queries.enrich(['KLF4', 'PAX5']). df2 = sc.queries.enrich(['SOX2', 'NANOG']). ...concat... ```. we can now do. ```python. df = sc.queries.enrich({'set1':['KLF4', 'PAX5'], 'set2':['SOX2', 'NANOG']}). ```. (I mean this was already supported by gprofiler, but it was simply broken due to an explicit list conversion).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1488
https://github.com/scverse/scanpy/pull/1489:49,modifiability,variab,variables,49,"added support for individual cmaps for continous variables; As explained in plotting docs. > The color map can also be set individually for each value in adata.obs and adata.var, by setting `adata.uns[""{var}_cmap""]`. The individual values overwrite `color_map`. I think it's very useful when plotting multiple .obs or .var variables using ""color"", as the cmaps can then be defined for each embedding individually.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1489
https://github.com/scverse/scanpy/pull/1489:323,modifiability,variab,variables,323,"added support for individual cmaps for continous variables; As explained in plotting docs. > The color map can also be set individually for each value in adata.obs and adata.var, by setting `adata.uns[""{var}_cmap""]`. The individual values overwrite `color_map`. I think it's very useful when plotting multiple .obs or .var variables using ""color"", as the cmaps can then be defined for each embedding individually.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1489
https://github.com/scverse/scanpy/pull/1489:6,usability,support,support,6,"added support for individual cmaps for continous variables; As explained in plotting docs. > The color map can also be set individually for each value in adata.obs and adata.var, by setting `adata.uns[""{var}_cmap""]`. The individual values overwrite `color_map`. I think it's very useful when plotting multiple .obs or .var variables using ""color"", as the cmaps can then be defined for each embedding individually.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1489
https://github.com/scverse/scanpy/pull/1490:77,availability,error,errors,77,"Require a minimum groupsize for marker detection to prevent division by zero errors; . Currently, if a set of cell groups has any groups with only one cell, attempting to run rank_genes_groups() gets you an error like:. ```. >>> sc.tl.rank_genes_groups(ad, 'louvain_resolution_3.0'). WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'. ranking genes. consider 'louvain_resolution_3.0' groups:. with sizes: [28 13 13 11 10 9 9 8 8 8 8 7 6 6 6 4 3 3 1 1 1]. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/path/to/scanpy/tools/_rank_genes_groups.py"", line 584, in rank_genes_groups. method, corr_method, n_genes_user, rankby_abs, tie_correct, **kwds. File ""/path/to/scanpy/tools/_rank_genes_groups.py"", line 365, in compute_statistics. for group_index, scores, pvals in generate_test_results:. File ""/path/to/scanpy/tools/_rank_genes_groups.py"", line 187, in t_test. self._basic_stats(). File ""/path/to/scanpy/tools/_rank_genes_groups.py"", line 172, in _basic_stats. self.means[imask], self.vars[imask] = _get_mean_var(X_mask). File ""/path/to/scanpy/preprocessing/_utils.py"", line 14, in _get_mean_var. var *= X.shape[axis] / (X.shape[axis] - 1). ZeroDivisionError: division by zero. ```. The fix I've come up with is to filter groups by size when calling select_groups(), happy to help on alternate approaches if required.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1490
https://github.com/scverse/scanpy/pull/1490:207,availability,error,error,207,"Require a minimum groupsize for marker detection to prevent division by zero errors; . Currently, if a set of cell groups has any groups with only one cell, attempting to run rank_genes_groups() gets you an error like:. ```. >>> sc.tl.rank_genes_groups(ad, 'louvain_resolution_3.0'). WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'. ranking genes. consider 'louvain_resolution_3.0' groups:. with sizes: [28 13 13 11 10 9 9 8 8 8 8 7 6 6 6 4 3 3 1 1 1]. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/path/to/scanpy/tools/_rank_genes_groups.py"", line 584, in rank_genes_groups. method, corr_method, n_genes_user, rankby_abs, tie_correct, **kwds. File ""/path/to/scanpy/tools/_rank_genes_groups.py"", line 365, in compute_statistics. for group_index, scores, pvals in generate_test_results:. File ""/path/to/scanpy/tools/_rank_genes_groups.py"", line 187, in t_test. self._basic_stats(). File ""/path/to/scanpy/tools/_rank_genes_groups.py"", line 172, in _basic_stats. self.means[imask], self.vars[imask] = _get_mean_var(X_mask). File ""/path/to/scanpy/preprocessing/_utils.py"", line 14, in _get_mean_var. var *= X.shape[axis] / (X.shape[axis] - 1). ZeroDivisionError: division by zero. ```. The fix I've come up with is to filter groups by size when calling select_groups(), happy to help on alternate approaches if required.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1490
https://github.com/scverse/scanpy/pull/1490:557,deployability,modul,module,557,"Require a minimum groupsize for marker detection to prevent division by zero errors; . Currently, if a set of cell groups has any groups with only one cell, attempting to run rank_genes_groups() gets you an error like:. ```. >>> sc.tl.rank_genes_groups(ad, 'louvain_resolution_3.0'). WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'. ranking genes. consider 'louvain_resolution_3.0' groups:. with sizes: [28 13 13 11 10 9 9 8 8 8 8 7 6 6 6 4 3 3 1 1 1]. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/path/to/scanpy/tools/_rank_genes_groups.py"", line 584, in rank_genes_groups. method, corr_method, n_genes_user, rankby_abs, tie_correct, **kwds. File ""/path/to/scanpy/tools/_rank_genes_groups.py"", line 365, in compute_statistics. for group_index, scores, pvals in generate_test_results:. File ""/path/to/scanpy/tools/_rank_genes_groups.py"", line 187, in t_test. self._basic_stats(). File ""/path/to/scanpy/tools/_rank_genes_groups.py"", line 172, in _basic_stats. self.means[imask], self.vars[imask] = _get_mean_var(X_mask). File ""/path/to/scanpy/preprocessing/_utils.py"", line 14, in _get_mean_var. var *= X.shape[axis] / (X.shape[axis] - 1). ZeroDivisionError: division by zero. ```. The fix I've come up with is to filter groups by size when calling select_groups(), happy to help on alternate approaches if required.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1490
https://github.com/scverse/scanpy/pull/1490:87,energy efficiency,Current,Currently,87,"Require a minimum groupsize for marker detection to prevent division by zero errors; . Currently, if a set of cell groups has any groups with only one cell, attempting to run rank_genes_groups() gets you an error like:. ```. >>> sc.tl.rank_genes_groups(ad, 'louvain_resolution_3.0'). WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'. ranking genes. consider 'louvain_resolution_3.0' groups:. with sizes: [28 13 13 11 10 9 9 8 8 8 8 7 6 6 6 4 3 3 1 1 1]. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/path/to/scanpy/tools/_rank_genes_groups.py"", line 584, in rank_genes_groups. method, corr_method, n_genes_user, rankby_abs, tie_correct, **kwds. File ""/path/to/scanpy/tools/_rank_genes_groups.py"", line 365, in compute_statistics. for group_index, scores, pvals in generate_test_results:. File ""/path/to/scanpy/tools/_rank_genes_groups.py"", line 187, in t_test. self._basic_stats(). File ""/path/to/scanpy/tools/_rank_genes_groups.py"", line 172, in _basic_stats. self.means[imask], self.vars[imask] = _get_mean_var(X_mask). File ""/path/to/scanpy/preprocessing/_utils.py"", line 14, in _get_mean_var. var *= X.shape[axis] / (X.shape[axis] - 1). ZeroDivisionError: division by zero. ```. The fix I've come up with is to filter groups by size when calling select_groups(), happy to help on alternate approaches if required.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1490
https://github.com/scverse/scanpy/pull/1490:1288,integrability,filter,filter,1288,"Require a minimum groupsize for marker detection to prevent division by zero errors; . Currently, if a set of cell groups has any groups with only one cell, attempting to run rank_genes_groups() gets you an error like:. ```. >>> sc.tl.rank_genes_groups(ad, 'louvain_resolution_3.0'). WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'. ranking genes. consider 'louvain_resolution_3.0' groups:. with sizes: [28 13 13 11 10 9 9 8 8 8 8 7 6 6 6 4 3 3 1 1 1]. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/path/to/scanpy/tools/_rank_genes_groups.py"", line 584, in rank_genes_groups. method, corr_method, n_genes_user, rankby_abs, tie_correct, **kwds. File ""/path/to/scanpy/tools/_rank_genes_groups.py"", line 365, in compute_statistics. for group_index, scores, pvals in generate_test_results:. File ""/path/to/scanpy/tools/_rank_genes_groups.py"", line 187, in t_test. self._basic_stats(). File ""/path/to/scanpy/tools/_rank_genes_groups.py"", line 172, in _basic_stats. self.means[imask], self.vars[imask] = _get_mean_var(X_mask). File ""/path/to/scanpy/preprocessing/_utils.py"", line 14, in _get_mean_var. var *= X.shape[axis] / (X.shape[axis] - 1). ZeroDivisionError: division by zero. ```. The fix I've come up with is to filter groups by size when calling select_groups(), happy to help on alternate approaches if required.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1490
https://github.com/scverse/scanpy/pull/1490:557,modifiability,modul,module,557,"Require a minimum groupsize for marker detection to prevent division by zero errors; . Currently, if a set of cell groups has any groups with only one cell, attempting to run rank_genes_groups() gets you an error like:. ```. >>> sc.tl.rank_genes_groups(ad, 'louvain_resolution_3.0'). WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'. ranking genes. consider 'louvain_resolution_3.0' groups:. with sizes: [28 13 13 11 10 9 9 8 8 8 8 7 6 6 6 4 3 3 1 1 1]. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/path/to/scanpy/tools/_rank_genes_groups.py"", line 584, in rank_genes_groups. method, corr_method, n_genes_user, rankby_abs, tie_correct, **kwds. File ""/path/to/scanpy/tools/_rank_genes_groups.py"", line 365, in compute_statistics. for group_index, scores, pvals in generate_test_results:. File ""/path/to/scanpy/tools/_rank_genes_groups.py"", line 187, in t_test. self._basic_stats(). File ""/path/to/scanpy/tools/_rank_genes_groups.py"", line 172, in _basic_stats. self.means[imask], self.vars[imask] = _get_mean_var(X_mask). File ""/path/to/scanpy/preprocessing/_utils.py"", line 14, in _get_mean_var. var *= X.shape[axis] / (X.shape[axis] - 1). ZeroDivisionError: division by zero. ```. The fix I've come up with is to filter groups by size when calling select_groups(), happy to help on alternate approaches if required.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1490
https://github.com/scverse/scanpy/pull/1490:77,performance,error,errors,77,"Require a minimum groupsize for marker detection to prevent division by zero errors; . Currently, if a set of cell groups has any groups with only one cell, attempting to run rank_genes_groups() gets you an error like:. ```. >>> sc.tl.rank_genes_groups(ad, 'louvain_resolution_3.0'). WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'. ranking genes. consider 'louvain_resolution_3.0' groups:. with sizes: [28 13 13 11 10 9 9 8 8 8 8 7 6 6 6 4 3 3 1 1 1]. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/path/to/scanpy/tools/_rank_genes_groups.py"", line 584, in rank_genes_groups. method, corr_method, n_genes_user, rankby_abs, tie_correct, **kwds. File ""/path/to/scanpy/tools/_rank_genes_groups.py"", line 365, in compute_statistics. for group_index, scores, pvals in generate_test_results:. File ""/path/to/scanpy/tools/_rank_genes_groups.py"", line 187, in t_test. self._basic_stats(). File ""/path/to/scanpy/tools/_rank_genes_groups.py"", line 172, in _basic_stats. self.means[imask], self.vars[imask] = _get_mean_var(X_mask). File ""/path/to/scanpy/preprocessing/_utils.py"", line 14, in _get_mean_var. var *= X.shape[axis] / (X.shape[axis] - 1). ZeroDivisionError: division by zero. ```. The fix I've come up with is to filter groups by size when calling select_groups(), happy to help on alternate approaches if required.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1490
https://github.com/scverse/scanpy/pull/1490:207,performance,error,error,207,"Require a minimum groupsize for marker detection to prevent division by zero errors; . Currently, if a set of cell groups has any groups with only one cell, attempting to run rank_genes_groups() gets you an error like:. ```. >>> sc.tl.rank_genes_groups(ad, 'louvain_resolution_3.0'). WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'. ranking genes. consider 'louvain_resolution_3.0' groups:. with sizes: [28 13 13 11 10 9 9 8 8 8 8 7 6 6 6 4 3 3 1 1 1]. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/path/to/scanpy/tools/_rank_genes_groups.py"", line 584, in rank_genes_groups. method, corr_method, n_genes_user, rankby_abs, tie_correct, **kwds. File ""/path/to/scanpy/tools/_rank_genes_groups.py"", line 365, in compute_statistics. for group_index, scores, pvals in generate_test_results:. File ""/path/to/scanpy/tools/_rank_genes_groups.py"", line 187, in t_test. self._basic_stats(). File ""/path/to/scanpy/tools/_rank_genes_groups.py"", line 172, in _basic_stats. self.means[imask], self.vars[imask] = _get_mean_var(X_mask). File ""/path/to/scanpy/preprocessing/_utils.py"", line 14, in _get_mean_var. var *= X.shape[axis] / (X.shape[axis] - 1). ZeroDivisionError: division by zero. ```. The fix I've come up with is to filter groups by size when calling select_groups(), happy to help on alternate approaches if required.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1490
https://github.com/scverse/scanpy/pull/1490:39,safety,detect,detection,39,"Require a minimum groupsize for marker detection to prevent division by zero errors; . Currently, if a set of cell groups has any groups with only one cell, attempting to run rank_genes_groups() gets you an error like:. ```. >>> sc.tl.rank_genes_groups(ad, 'louvain_resolution_3.0'). WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'. ranking genes. consider 'louvain_resolution_3.0' groups:. with sizes: [28 13 13 11 10 9 9 8 8 8 8 7 6 6 6 4 3 3 1 1 1]. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/path/to/scanpy/tools/_rank_genes_groups.py"", line 584, in rank_genes_groups. method, corr_method, n_genes_user, rankby_abs, tie_correct, **kwds. File ""/path/to/scanpy/tools/_rank_genes_groups.py"", line 365, in compute_statistics. for group_index, scores, pvals in generate_test_results:. File ""/path/to/scanpy/tools/_rank_genes_groups.py"", line 187, in t_test. self._basic_stats(). File ""/path/to/scanpy/tools/_rank_genes_groups.py"", line 172, in _basic_stats. self.means[imask], self.vars[imask] = _get_mean_var(X_mask). File ""/path/to/scanpy/preprocessing/_utils.py"", line 14, in _get_mean_var. var *= X.shape[axis] / (X.shape[axis] - 1). ZeroDivisionError: division by zero. ```. The fix I've come up with is to filter groups by size when calling select_groups(), happy to help on alternate approaches if required.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1490
https://github.com/scverse/scanpy/pull/1490:52,safety,prevent,prevent,52,"Require a minimum groupsize for marker detection to prevent division by zero errors; . Currently, if a set of cell groups has any groups with only one cell, attempting to run rank_genes_groups() gets you an error like:. ```. >>> sc.tl.rank_genes_groups(ad, 'louvain_resolution_3.0'). WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'. ranking genes. consider 'louvain_resolution_3.0' groups:. with sizes: [28 13 13 11 10 9 9 8 8 8 8 7 6 6 6 4 3 3 1 1 1]. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/path/to/scanpy/tools/_rank_genes_groups.py"", line 584, in rank_genes_groups. method, corr_method, n_genes_user, rankby_abs, tie_correct, **kwds. File ""/path/to/scanpy/tools/_rank_genes_groups.py"", line 365, in compute_statistics. for group_index, scores, pvals in generate_test_results:. File ""/path/to/scanpy/tools/_rank_genes_groups.py"", line 187, in t_test. self._basic_stats(). File ""/path/to/scanpy/tools/_rank_genes_groups.py"", line 172, in _basic_stats. self.means[imask], self.vars[imask] = _get_mean_var(X_mask). File ""/path/to/scanpy/preprocessing/_utils.py"", line 14, in _get_mean_var. var *= X.shape[axis] / (X.shape[axis] - 1). ZeroDivisionError: division by zero. ```. The fix I've come up with is to filter groups by size when calling select_groups(), happy to help on alternate approaches if required.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1490
https://github.com/scverse/scanpy/pull/1490:77,safety,error,errors,77,"Require a minimum groupsize for marker detection to prevent division by zero errors; . Currently, if a set of cell groups has any groups with only one cell, attempting to run rank_genes_groups() gets you an error like:. ```. >>> sc.tl.rank_genes_groups(ad, 'louvain_resolution_3.0'). WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'. ranking genes. consider 'louvain_resolution_3.0' groups:. with sizes: [28 13 13 11 10 9 9 8 8 8 8 7 6 6 6 4 3 3 1 1 1]. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/path/to/scanpy/tools/_rank_genes_groups.py"", line 584, in rank_genes_groups. method, corr_method, n_genes_user, rankby_abs, tie_correct, **kwds. File ""/path/to/scanpy/tools/_rank_genes_groups.py"", line 365, in compute_statistics. for group_index, scores, pvals in generate_test_results:. File ""/path/to/scanpy/tools/_rank_genes_groups.py"", line 187, in t_test. self._basic_stats(). File ""/path/to/scanpy/tools/_rank_genes_groups.py"", line 172, in _basic_stats. self.means[imask], self.vars[imask] = _get_mean_var(X_mask). File ""/path/to/scanpy/preprocessing/_utils.py"", line 14, in _get_mean_var. var *= X.shape[axis] / (X.shape[axis] - 1). ZeroDivisionError: division by zero. ```. The fix I've come up with is to filter groups by size when calling select_groups(), happy to help on alternate approaches if required.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1490
https://github.com/scverse/scanpy/pull/1490:207,safety,error,error,207,"Require a minimum groupsize for marker detection to prevent division by zero errors; . Currently, if a set of cell groups has any groups with only one cell, attempting to run rank_genes_groups() gets you an error like:. ```. >>> sc.tl.rank_genes_groups(ad, 'louvain_resolution_3.0'). WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'. ranking genes. consider 'louvain_resolution_3.0' groups:. with sizes: [28 13 13 11 10 9 9 8 8 8 8 7 6 6 6 4 3 3 1 1 1]. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/path/to/scanpy/tools/_rank_genes_groups.py"", line 584, in rank_genes_groups. method, corr_method, n_genes_user, rankby_abs, tie_correct, **kwds. File ""/path/to/scanpy/tools/_rank_genes_groups.py"", line 365, in compute_statistics. for group_index, scores, pvals in generate_test_results:. File ""/path/to/scanpy/tools/_rank_genes_groups.py"", line 187, in t_test. self._basic_stats(). File ""/path/to/scanpy/tools/_rank_genes_groups.py"", line 172, in _basic_stats. self.means[imask], self.vars[imask] = _get_mean_var(X_mask). File ""/path/to/scanpy/preprocessing/_utils.py"", line 14, in _get_mean_var. var *= X.shape[axis] / (X.shape[axis] - 1). ZeroDivisionError: division by zero. ```. The fix I've come up with is to filter groups by size when calling select_groups(), happy to help on alternate approaches if required.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1490
https://github.com/scverse/scanpy/pull/1490:338,safety,test,test,338,"Require a minimum groupsize for marker detection to prevent division by zero errors; . Currently, if a set of cell groups has any groups with only one cell, attempting to run rank_genes_groups() gets you an error like:. ```. >>> sc.tl.rank_genes_groups(ad, 'louvain_resolution_3.0'). WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'. ranking genes. consider 'louvain_resolution_3.0' groups:. with sizes: [28 13 13 11 10 9 9 8 8 8 8 7 6 6 6 4 3 3 1 1 1]. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/path/to/scanpy/tools/_rank_genes_groups.py"", line 584, in rank_genes_groups. method, corr_method, n_genes_user, rankby_abs, tie_correct, **kwds. File ""/path/to/scanpy/tools/_rank_genes_groups.py"", line 365, in compute_statistics. for group_index, scores, pvals in generate_test_results:. File ""/path/to/scanpy/tools/_rank_genes_groups.py"", line 187, in t_test. self._basic_stats(). File ""/path/to/scanpy/tools/_rank_genes_groups.py"", line 172, in _basic_stats. self.means[imask], self.vars[imask] = _get_mean_var(X_mask). File ""/path/to/scanpy/preprocessing/_utils.py"", line 14, in _get_mean_var. var *= X.shape[axis] / (X.shape[axis] - 1). ZeroDivisionError: division by zero. ```. The fix I've come up with is to filter groups by size when calling select_groups(), happy to help on alternate approaches if required.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1490
https://github.com/scverse/scanpy/pull/1490:557,safety,modul,module,557,"Require a minimum groupsize for marker detection to prevent division by zero errors; . Currently, if a set of cell groups has any groups with only one cell, attempting to run rank_genes_groups() gets you an error like:. ```. >>> sc.tl.rank_genes_groups(ad, 'louvain_resolution_3.0'). WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'. ranking genes. consider 'louvain_resolution_3.0' groups:. with sizes: [28 13 13 11 10 9 9 8 8 8 8 7 6 6 6 4 3 3 1 1 1]. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/path/to/scanpy/tools/_rank_genes_groups.py"", line 584, in rank_genes_groups. method, corr_method, n_genes_user, rankby_abs, tie_correct, **kwds. File ""/path/to/scanpy/tools/_rank_genes_groups.py"", line 365, in compute_statistics. for group_index, scores, pvals in generate_test_results:. File ""/path/to/scanpy/tools/_rank_genes_groups.py"", line 187, in t_test. self._basic_stats(). File ""/path/to/scanpy/tools/_rank_genes_groups.py"", line 172, in _basic_stats. self.means[imask], self.vars[imask] = _get_mean_var(X_mask). File ""/path/to/scanpy/preprocessing/_utils.py"", line 14, in _get_mean_var. var *= X.shape[axis] / (X.shape[axis] - 1). ZeroDivisionError: division by zero. ```. The fix I've come up with is to filter groups by size when calling select_groups(), happy to help on alternate approaches if required.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1490
https://github.com/scverse/scanpy/pull/1490:39,security,detect,detection,39,"Require a minimum groupsize for marker detection to prevent division by zero errors; . Currently, if a set of cell groups has any groups with only one cell, attempting to run rank_genes_groups() gets you an error like:. ```. >>> sc.tl.rank_genes_groups(ad, 'louvain_resolution_3.0'). WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'. ranking genes. consider 'louvain_resolution_3.0' groups:. with sizes: [28 13 13 11 10 9 9 8 8 8 8 7 6 6 6 4 3 3 1 1 1]. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/path/to/scanpy/tools/_rank_genes_groups.py"", line 584, in rank_genes_groups. method, corr_method, n_genes_user, rankby_abs, tie_correct, **kwds. File ""/path/to/scanpy/tools/_rank_genes_groups.py"", line 365, in compute_statistics. for group_index, scores, pvals in generate_test_results:. File ""/path/to/scanpy/tools/_rank_genes_groups.py"", line 187, in t_test. self._basic_stats(). File ""/path/to/scanpy/tools/_rank_genes_groups.py"", line 172, in _basic_stats. self.means[imask], self.vars[imask] = _get_mean_var(X_mask). File ""/path/to/scanpy/preprocessing/_utils.py"", line 14, in _get_mean_var. var *= X.shape[axis] / (X.shape[axis] - 1). ZeroDivisionError: division by zero. ```. The fix I've come up with is to filter groups by size when calling select_groups(), happy to help on alternate approaches if required.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1490
https://github.com/scverse/scanpy/pull/1490:52,security,preven,prevent,52,"Require a minimum groupsize for marker detection to prevent division by zero errors; . Currently, if a set of cell groups has any groups with only one cell, attempting to run rank_genes_groups() gets you an error like:. ```. >>> sc.tl.rank_genes_groups(ad, 'louvain_resolution_3.0'). WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'. ranking genes. consider 'louvain_resolution_3.0' groups:. with sizes: [28 13 13 11 10 9 9 8 8 8 8 7 6 6 6 4 3 3 1 1 1]. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/path/to/scanpy/tools/_rank_genes_groups.py"", line 584, in rank_genes_groups. method, corr_method, n_genes_user, rankby_abs, tie_correct, **kwds. File ""/path/to/scanpy/tools/_rank_genes_groups.py"", line 365, in compute_statistics. for group_index, scores, pvals in generate_test_results:. File ""/path/to/scanpy/tools/_rank_genes_groups.py"", line 187, in t_test. self._basic_stats(). File ""/path/to/scanpy/tools/_rank_genes_groups.py"", line 172, in _basic_stats. self.means[imask], self.vars[imask] = _get_mean_var(X_mask). File ""/path/to/scanpy/preprocessing/_utils.py"", line 14, in _get_mean_var. var *= X.shape[axis] / (X.shape[axis] - 1). ZeroDivisionError: division by zero. ```. The fix I've come up with is to filter groups by size when calling select_groups(), happy to help on alternate approaches if required.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1490
https://github.com/scverse/scanpy/pull/1490:338,testability,test,test,338,"Require a minimum groupsize for marker detection to prevent division by zero errors; . Currently, if a set of cell groups has any groups with only one cell, attempting to run rank_genes_groups() gets you an error like:. ```. >>> sc.tl.rank_genes_groups(ad, 'louvain_resolution_3.0'). WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'. ranking genes. consider 'louvain_resolution_3.0' groups:. with sizes: [28 13 13 11 10 9 9 8 8 8 8 7 6 6 6 4 3 3 1 1 1]. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/path/to/scanpy/tools/_rank_genes_groups.py"", line 584, in rank_genes_groups. method, corr_method, n_genes_user, rankby_abs, tie_correct, **kwds. File ""/path/to/scanpy/tools/_rank_genes_groups.py"", line 365, in compute_statistics. for group_index, scores, pvals in generate_test_results:. File ""/path/to/scanpy/tools/_rank_genes_groups.py"", line 187, in t_test. self._basic_stats(). File ""/path/to/scanpy/tools/_rank_genes_groups.py"", line 172, in _basic_stats. self.means[imask], self.vars[imask] = _get_mean_var(X_mask). File ""/path/to/scanpy/preprocessing/_utils.py"", line 14, in _get_mean_var. var *= X.shape[axis] / (X.shape[axis] - 1). ZeroDivisionError: division by zero. ```. The fix I've come up with is to filter groups by size when calling select_groups(), happy to help on alternate approaches if required.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1490
https://github.com/scverse/scanpy/pull/1490:493,testability,Trace,Traceback,493,"Require a minimum groupsize for marker detection to prevent division by zero errors; . Currently, if a set of cell groups has any groups with only one cell, attempting to run rank_genes_groups() gets you an error like:. ```. >>> sc.tl.rank_genes_groups(ad, 'louvain_resolution_3.0'). WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'. ranking genes. consider 'louvain_resolution_3.0' groups:. with sizes: [28 13 13 11 10 9 9 8 8 8 8 7 6 6 6 4 3 3 1 1 1]. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/path/to/scanpy/tools/_rank_genes_groups.py"", line 584, in rank_genes_groups. method, corr_method, n_genes_user, rankby_abs, tie_correct, **kwds. File ""/path/to/scanpy/tools/_rank_genes_groups.py"", line 365, in compute_statistics. for group_index, scores, pvals in generate_test_results:. File ""/path/to/scanpy/tools/_rank_genes_groups.py"", line 187, in t_test. self._basic_stats(). File ""/path/to/scanpy/tools/_rank_genes_groups.py"", line 172, in _basic_stats. self.means[imask], self.vars[imask] = _get_mean_var(X_mask). File ""/path/to/scanpy/preprocessing/_utils.py"", line 14, in _get_mean_var. var *= X.shape[axis] / (X.shape[axis] - 1). ZeroDivisionError: division by zero. ```. The fix I've come up with is to filter groups by size when calling select_groups(), happy to help on alternate approaches if required.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1490
https://github.com/scverse/scanpy/pull/1490:10,usability,minim,minimum,10,"Require a minimum groupsize for marker detection to prevent division by zero errors; . Currently, if a set of cell groups has any groups with only one cell, attempting to run rank_genes_groups() gets you an error like:. ```. >>> sc.tl.rank_genes_groups(ad, 'louvain_resolution_3.0'). WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'. ranking genes. consider 'louvain_resolution_3.0' groups:. with sizes: [28 13 13 11 10 9 9 8 8 8 8 7 6 6 6 4 3 3 1 1 1]. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/path/to/scanpy/tools/_rank_genes_groups.py"", line 584, in rank_genes_groups. method, corr_method, n_genes_user, rankby_abs, tie_correct, **kwds. File ""/path/to/scanpy/tools/_rank_genes_groups.py"", line 365, in compute_statistics. for group_index, scores, pvals in generate_test_results:. File ""/path/to/scanpy/tools/_rank_genes_groups.py"", line 187, in t_test. self._basic_stats(). File ""/path/to/scanpy/tools/_rank_genes_groups.py"", line 172, in _basic_stats. self.means[imask], self.vars[imask] = _get_mean_var(X_mask). File ""/path/to/scanpy/preprocessing/_utils.py"", line 14, in _get_mean_var. var *= X.shape[axis] / (X.shape[axis] - 1). ZeroDivisionError: division by zero. ```. The fix I've come up with is to filter groups by size when calling select_groups(), happy to help on alternate approaches if required.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1490
https://github.com/scverse/scanpy/pull/1490:77,usability,error,errors,77,"Require a minimum groupsize for marker detection to prevent division by zero errors; . Currently, if a set of cell groups has any groups with only one cell, attempting to run rank_genes_groups() gets you an error like:. ```. >>> sc.tl.rank_genes_groups(ad, 'louvain_resolution_3.0'). WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'. ranking genes. consider 'louvain_resolution_3.0' groups:. with sizes: [28 13 13 11 10 9 9 8 8 8 8 7 6 6 6 4 3 3 1 1 1]. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/path/to/scanpy/tools/_rank_genes_groups.py"", line 584, in rank_genes_groups. method, corr_method, n_genes_user, rankby_abs, tie_correct, **kwds. File ""/path/to/scanpy/tools/_rank_genes_groups.py"", line 365, in compute_statistics. for group_index, scores, pvals in generate_test_results:. File ""/path/to/scanpy/tools/_rank_genes_groups.py"", line 187, in t_test. self._basic_stats(). File ""/path/to/scanpy/tools/_rank_genes_groups.py"", line 172, in _basic_stats. self.means[imask], self.vars[imask] = _get_mean_var(X_mask). File ""/path/to/scanpy/preprocessing/_utils.py"", line 14, in _get_mean_var. var *= X.shape[axis] / (X.shape[axis] - 1). ZeroDivisionError: division by zero. ```. The fix I've come up with is to filter groups by size when calling select_groups(), happy to help on alternate approaches if required.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1490
https://github.com/scverse/scanpy/pull/1490:207,usability,error,error,207,"Require a minimum groupsize for marker detection to prevent division by zero errors; . Currently, if a set of cell groups has any groups with only one cell, attempting to run rank_genes_groups() gets you an error like:. ```. >>> sc.tl.rank_genes_groups(ad, 'louvain_resolution_3.0'). WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'. ranking genes. consider 'louvain_resolution_3.0' groups:. with sizes: [28 13 13 11 10 9 9 8 8 8 8 7 6 6 6 4 3 3 1 1 1]. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/path/to/scanpy/tools/_rank_genes_groups.py"", line 584, in rank_genes_groups. method, corr_method, n_genes_user, rankby_abs, tie_correct, **kwds. File ""/path/to/scanpy/tools/_rank_genes_groups.py"", line 365, in compute_statistics. for group_index, scores, pvals in generate_test_results:. File ""/path/to/scanpy/tools/_rank_genes_groups.py"", line 187, in t_test. self._basic_stats(). File ""/path/to/scanpy/tools/_rank_genes_groups.py"", line 172, in _basic_stats. self.means[imask], self.vars[imask] = _get_mean_var(X_mask). File ""/path/to/scanpy/preprocessing/_utils.py"", line 14, in _get_mean_var. var *= X.shape[axis] / (X.shape[axis] - 1). ZeroDivisionError: division by zero. ```. The fix I've come up with is to filter groups by size when calling select_groups(), happy to help on alternate approaches if required.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1490
https://github.com/scverse/scanpy/pull/1490:588,usability,tool,tools,588,"Require a minimum groupsize for marker detection to prevent division by zero errors; . Currently, if a set of cell groups has any groups with only one cell, attempting to run rank_genes_groups() gets you an error like:. ```. >>> sc.tl.rank_genes_groups(ad, 'louvain_resolution_3.0'). WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'. ranking genes. consider 'louvain_resolution_3.0' groups:. with sizes: [28 13 13 11 10 9 9 8 8 8 8 7 6 6 6 4 3 3 1 1 1]. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/path/to/scanpy/tools/_rank_genes_groups.py"", line 584, in rank_genes_groups. method, corr_method, n_genes_user, rankby_abs, tie_correct, **kwds. File ""/path/to/scanpy/tools/_rank_genes_groups.py"", line 365, in compute_statistics. for group_index, scores, pvals in generate_test_results:. File ""/path/to/scanpy/tools/_rank_genes_groups.py"", line 187, in t_test. self._basic_stats(). File ""/path/to/scanpy/tools/_rank_genes_groups.py"", line 172, in _basic_stats. self.means[imask], self.vars[imask] = _get_mean_var(X_mask). File ""/path/to/scanpy/preprocessing/_utils.py"", line 14, in _get_mean_var. var *= X.shape[axis] / (X.shape[axis] - 1). ZeroDivisionError: division by zero. ```. The fix I've come up with is to filter groups by size when calling select_groups(), happy to help on alternate approaches if required.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1490
https://github.com/scverse/scanpy/pull/1490:740,usability,tool,tools,740,"Require a minimum groupsize for marker detection to prevent division by zero errors; . Currently, if a set of cell groups has any groups with only one cell, attempting to run rank_genes_groups() gets you an error like:. ```. >>> sc.tl.rank_genes_groups(ad, 'louvain_resolution_3.0'). WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'. ranking genes. consider 'louvain_resolution_3.0' groups:. with sizes: [28 13 13 11 10 9 9 8 8 8 8 7 6 6 6 4 3 3 1 1 1]. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/path/to/scanpy/tools/_rank_genes_groups.py"", line 584, in rank_genes_groups. method, corr_method, n_genes_user, rankby_abs, tie_correct, **kwds. File ""/path/to/scanpy/tools/_rank_genes_groups.py"", line 365, in compute_statistics. for group_index, scores, pvals in generate_test_results:. File ""/path/to/scanpy/tools/_rank_genes_groups.py"", line 187, in t_test. self._basic_stats(). File ""/path/to/scanpy/tools/_rank_genes_groups.py"", line 172, in _basic_stats. self.means[imask], self.vars[imask] = _get_mean_var(X_mask). File ""/path/to/scanpy/preprocessing/_utils.py"", line 14, in _get_mean_var. var *= X.shape[axis] / (X.shape[axis] - 1). ZeroDivisionError: division by zero. ```. The fix I've come up with is to filter groups by size when calling select_groups(), happy to help on alternate approaches if required.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1490
https://github.com/scverse/scanpy/pull/1490:883,usability,tool,tools,883,"Require a minimum groupsize for marker detection to prevent division by zero errors; . Currently, if a set of cell groups has any groups with only one cell, attempting to run rank_genes_groups() gets you an error like:. ```. >>> sc.tl.rank_genes_groups(ad, 'louvain_resolution_3.0'). WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'. ranking genes. consider 'louvain_resolution_3.0' groups:. with sizes: [28 13 13 11 10 9 9 8 8 8 8 7 6 6 6 4 3 3 1 1 1]. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/path/to/scanpy/tools/_rank_genes_groups.py"", line 584, in rank_genes_groups. method, corr_method, n_genes_user, rankby_abs, tie_correct, **kwds. File ""/path/to/scanpy/tools/_rank_genes_groups.py"", line 365, in compute_statistics. for group_index, scores, pvals in generate_test_results:. File ""/path/to/scanpy/tools/_rank_genes_groups.py"", line 187, in t_test. self._basic_stats(). File ""/path/to/scanpy/tools/_rank_genes_groups.py"", line 172, in _basic_stats. self.means[imask], self.vars[imask] = _get_mean_var(X_mask). File ""/path/to/scanpy/preprocessing/_utils.py"", line 14, in _get_mean_var. var *= X.shape[axis] / (X.shape[axis] - 1). ZeroDivisionError: division by zero. ```. The fix I've come up with is to filter groups by size when calling select_groups(), happy to help on alternate approaches if required.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1490
https://github.com/scverse/scanpy/pull/1490:977,usability,tool,tools,977,"Require a minimum groupsize for marker detection to prevent division by zero errors; . Currently, if a set of cell groups has any groups with only one cell, attempting to run rank_genes_groups() gets you an error like:. ```. >>> sc.tl.rank_genes_groups(ad, 'louvain_resolution_3.0'). WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'. ranking genes. consider 'louvain_resolution_3.0' groups:. with sizes: [28 13 13 11 10 9 9 8 8 8 8 7 6 6 6 4 3 3 1 1 1]. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/path/to/scanpy/tools/_rank_genes_groups.py"", line 584, in rank_genes_groups. method, corr_method, n_genes_user, rankby_abs, tie_correct, **kwds. File ""/path/to/scanpy/tools/_rank_genes_groups.py"", line 365, in compute_statistics. for group_index, scores, pvals in generate_test_results:. File ""/path/to/scanpy/tools/_rank_genes_groups.py"", line 187, in t_test. self._basic_stats(). File ""/path/to/scanpy/tools/_rank_genes_groups.py"", line 172, in _basic_stats. self.means[imask], self.vars[imask] = _get_mean_var(X_mask). File ""/path/to/scanpy/preprocessing/_utils.py"", line 14, in _get_mean_var. var *= X.shape[axis] / (X.shape[axis] - 1). ZeroDivisionError: division by zero. ```. The fix I've come up with is to filter groups by size when calling select_groups(), happy to help on alternate approaches if required.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1490
https://github.com/scverse/scanpy/pull/1490:1349,usability,help,help,1349,"Require a minimum groupsize for marker detection to prevent division by zero errors; . Currently, if a set of cell groups has any groups with only one cell, attempting to run rank_genes_groups() gets you an error like:. ```. >>> sc.tl.rank_genes_groups(ad, 'louvain_resolution_3.0'). WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'. ranking genes. consider 'louvain_resolution_3.0' groups:. with sizes: [28 13 13 11 10 9 9 8 8 8 8 7 6 6 6 4 3 3 1 1 1]. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/path/to/scanpy/tools/_rank_genes_groups.py"", line 584, in rank_genes_groups. method, corr_method, n_genes_user, rankby_abs, tie_correct, **kwds. File ""/path/to/scanpy/tools/_rank_genes_groups.py"", line 365, in compute_statistics. for group_index, scores, pvals in generate_test_results:. File ""/path/to/scanpy/tools/_rank_genes_groups.py"", line 187, in t_test. self._basic_stats(). File ""/path/to/scanpy/tools/_rank_genes_groups.py"", line 172, in _basic_stats. self.means[imask], self.vars[imask] = _get_mean_var(X_mask). File ""/path/to/scanpy/preprocessing/_utils.py"", line 14, in _get_mean_var. var *= X.shape[axis] / (X.shape[axis] - 1). ZeroDivisionError: division by zero. ```. The fix I've come up with is to filter groups by size when calling select_groups(), happy to help on alternate approaches if required.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1490
https://github.com/scverse/scanpy/pull/1491:22,deployability,version,version,22,Bump anndata required version for `anndata.concat`; Fixes #1439,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1491
https://github.com/scverse/scanpy/pull/1491:22,integrability,version,version,22,Bump anndata required version for `anndata.concat`; Fixes #1439,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1491
https://github.com/scverse/scanpy/pull/1491:22,modifiability,version,version,22,Bump anndata required version for `anndata.concat`; Fixes #1439,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1491
https://github.com/scverse/scanpy/pull/1492:32,safety,test,test,32,Ignore blank lines in docstring test; Fixes #1484,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1492
https://github.com/scverse/scanpy/pull/1492:32,testability,test,test,32,Ignore blank lines in docstring test; Fixes #1484,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1492
https://github.com/scverse/scanpy/pull/1493:0,deployability,Updat,Update,0,"Update tests now that 3d plots work; Fixes #849. This PR updates our tests so that they expect 3d plots to work if matplotlib 3.3.3 is installed. The plots also look a bit different than they used to:. Old:. ![master_3dprojection](https://user-images.githubusercontent.com/8238804/98928524-fb038500-252d-11eb-82b8-cfb84b28f821.png). New:. ![master_3dprojection](https://user-images.githubusercontent.com/8238804/98928485-f212b380-252d-11eb-8a17-0e2d7683e51a.png). It would be nice if the legend was even more visible, but I think I'll leave it for now.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1493
https://github.com/scverse/scanpy/pull/1493:57,deployability,updat,updates,57,"Update tests now that 3d plots work; Fixes #849. This PR updates our tests so that they expect 3d plots to work if matplotlib 3.3.3 is installed. The plots also look a bit different than they used to:. Old:. ![master_3dprojection](https://user-images.githubusercontent.com/8238804/98928524-fb038500-252d-11eb-82b8-cfb84b28f821.png). New:. ![master_3dprojection](https://user-images.githubusercontent.com/8238804/98928485-f212b380-252d-11eb-8a17-0e2d7683e51a.png). It would be nice if the legend was even more visible, but I think I'll leave it for now.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1493
https://github.com/scverse/scanpy/pull/1493:135,deployability,instal,installed,135,"Update tests now that 3d plots work; Fixes #849. This PR updates our tests so that they expect 3d plots to work if matplotlib 3.3.3 is installed. The plots also look a bit different than they used to:. Old:. ![master_3dprojection](https://user-images.githubusercontent.com/8238804/98928524-fb038500-252d-11eb-82b8-cfb84b28f821.png). New:. ![master_3dprojection](https://user-images.githubusercontent.com/8238804/98928485-f212b380-252d-11eb-8a17-0e2d7683e51a.png). It would be nice if the legend was even more visible, but I think I'll leave it for now.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1493
https://github.com/scverse/scanpy/pull/1493:0,safety,Updat,Update,0,"Update tests now that 3d plots work; Fixes #849. This PR updates our tests so that they expect 3d plots to work if matplotlib 3.3.3 is installed. The plots also look a bit different than they used to:. Old:. ![master_3dprojection](https://user-images.githubusercontent.com/8238804/98928524-fb038500-252d-11eb-82b8-cfb84b28f821.png). New:. ![master_3dprojection](https://user-images.githubusercontent.com/8238804/98928485-f212b380-252d-11eb-8a17-0e2d7683e51a.png). It would be nice if the legend was even more visible, but I think I'll leave it for now.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1493
https://github.com/scverse/scanpy/pull/1493:7,safety,test,tests,7,"Update tests now that 3d plots work; Fixes #849. This PR updates our tests so that they expect 3d plots to work if matplotlib 3.3.3 is installed. The plots also look a bit different than they used to:. Old:. ![master_3dprojection](https://user-images.githubusercontent.com/8238804/98928524-fb038500-252d-11eb-82b8-cfb84b28f821.png). New:. ![master_3dprojection](https://user-images.githubusercontent.com/8238804/98928485-f212b380-252d-11eb-8a17-0e2d7683e51a.png). It would be nice if the legend was even more visible, but I think I'll leave it for now.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1493
https://github.com/scverse/scanpy/pull/1493:57,safety,updat,updates,57,"Update tests now that 3d plots work; Fixes #849. This PR updates our tests so that they expect 3d plots to work if matplotlib 3.3.3 is installed. The plots also look a bit different than they used to:. Old:. ![master_3dprojection](https://user-images.githubusercontent.com/8238804/98928524-fb038500-252d-11eb-82b8-cfb84b28f821.png). New:. ![master_3dprojection](https://user-images.githubusercontent.com/8238804/98928485-f212b380-252d-11eb-8a17-0e2d7683e51a.png). It would be nice if the legend was even more visible, but I think I'll leave it for now.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1493
https://github.com/scverse/scanpy/pull/1493:69,safety,test,tests,69,"Update tests now that 3d plots work; Fixes #849. This PR updates our tests so that they expect 3d plots to work if matplotlib 3.3.3 is installed. The plots also look a bit different than they used to:. Old:. ![master_3dprojection](https://user-images.githubusercontent.com/8238804/98928524-fb038500-252d-11eb-82b8-cfb84b28f821.png). New:. ![master_3dprojection](https://user-images.githubusercontent.com/8238804/98928485-f212b380-252d-11eb-8a17-0e2d7683e51a.png). It would be nice if the legend was even more visible, but I think I'll leave it for now.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1493
https://github.com/scverse/scanpy/pull/1493:0,security,Updat,Update,0,"Update tests now that 3d plots work; Fixes #849. This PR updates our tests so that they expect 3d plots to work if matplotlib 3.3.3 is installed. The plots also look a bit different than they used to:. Old:. ![master_3dprojection](https://user-images.githubusercontent.com/8238804/98928524-fb038500-252d-11eb-82b8-cfb84b28f821.png). New:. ![master_3dprojection](https://user-images.githubusercontent.com/8238804/98928485-f212b380-252d-11eb-8a17-0e2d7683e51a.png). It would be nice if the legend was even more visible, but I think I'll leave it for now.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1493
https://github.com/scverse/scanpy/pull/1493:57,security,updat,updates,57,"Update tests now that 3d plots work; Fixes #849. This PR updates our tests so that they expect 3d plots to work if matplotlib 3.3.3 is installed. The plots also look a bit different than they used to:. Old:. ![master_3dprojection](https://user-images.githubusercontent.com/8238804/98928524-fb038500-252d-11eb-82b8-cfb84b28f821.png). New:. ![master_3dprojection](https://user-images.githubusercontent.com/8238804/98928485-f212b380-252d-11eb-8a17-0e2d7683e51a.png). It would be nice if the legend was even more visible, but I think I'll leave it for now.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1493
https://github.com/scverse/scanpy/pull/1493:7,testability,test,tests,7,"Update tests now that 3d plots work; Fixes #849. This PR updates our tests so that they expect 3d plots to work if matplotlib 3.3.3 is installed. The plots also look a bit different than they used to:. Old:. ![master_3dprojection](https://user-images.githubusercontent.com/8238804/98928524-fb038500-252d-11eb-82b8-cfb84b28f821.png). New:. ![master_3dprojection](https://user-images.githubusercontent.com/8238804/98928485-f212b380-252d-11eb-8a17-0e2d7683e51a.png). It would be nice if the legend was even more visible, but I think I'll leave it for now.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1493
https://github.com/scverse/scanpy/pull/1493:69,testability,test,tests,69,"Update tests now that 3d plots work; Fixes #849. This PR updates our tests so that they expect 3d plots to work if matplotlib 3.3.3 is installed. The plots also look a bit different than they used to:. Old:. ![master_3dprojection](https://user-images.githubusercontent.com/8238804/98928524-fb038500-252d-11eb-82b8-cfb84b28f821.png). New:. ![master_3dprojection](https://user-images.githubusercontent.com/8238804/98928485-f212b380-252d-11eb-8a17-0e2d7683e51a.png). It would be nice if the legend was even more visible, but I think I'll leave it for now.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1493
https://github.com/scverse/scanpy/pull/1493:239,usability,user,user-images,239,"Update tests now that 3d plots work; Fixes #849. This PR updates our tests so that they expect 3d plots to work if matplotlib 3.3.3 is installed. The plots also look a bit different than they used to:. Old:. ![master_3dprojection](https://user-images.githubusercontent.com/8238804/98928524-fb038500-252d-11eb-82b8-cfb84b28f821.png). New:. ![master_3dprojection](https://user-images.githubusercontent.com/8238804/98928485-f212b380-252d-11eb-8a17-0e2d7683e51a.png). It would be nice if the legend was even more visible, but I think I'll leave it for now.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1493
https://github.com/scverse/scanpy/pull/1493:370,usability,user,user-images,370,"Update tests now that 3d plots work; Fixes #849. This PR updates our tests so that they expect 3d plots to work if matplotlib 3.3.3 is installed. The plots also look a bit different than they used to:. Old:. ![master_3dprojection](https://user-images.githubusercontent.com/8238804/98928524-fb038500-252d-11eb-82b8-cfb84b28f821.png). New:. ![master_3dprojection](https://user-images.githubusercontent.com/8238804/98928485-f212b380-252d-11eb-8a17-0e2d7683e51a.png). It would be nice if the legend was even more visible, but I think I'll leave it for now.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1493
https://github.com/scverse/scanpy/pull/1494:8,availability,Failur,Failure,8,Bugfix: Failure due to cugraph api change in v0.16...; Method cugraph.add_adj_list is replaced in RAPIDS v0.16 with from_cudf_adjlist. This patch will check for existence of 'add_adj_list' in the object before. calling it.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1494
https://github.com/scverse/scanpy/pull/1494:8,deployability,Fail,Failure,8,Bugfix: Failure due to cugraph api change in v0.16...; Method cugraph.add_adj_list is replaced in RAPIDS v0.16 with from_cudf_adjlist. This patch will check for existence of 'add_adj_list' in the object before. calling it.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1494
https://github.com/scverse/scanpy/pull/1494:31,deployability,api,api,31,Bugfix: Failure due to cugraph api change in v0.16...; Method cugraph.add_adj_list is replaced in RAPIDS v0.16 with from_cudf_adjlist. This patch will check for existence of 'add_adj_list' in the object before. calling it.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1494
https://github.com/scverse/scanpy/pull/1494:140,deployability,patch,patch,140,Bugfix: Failure due to cugraph api change in v0.16...; Method cugraph.add_adj_list is replaced in RAPIDS v0.16 with from_cudf_adjlist. This patch will check for existence of 'add_adj_list' in the object before. calling it.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1494
https://github.com/scverse/scanpy/pull/1494:31,integrability,api,api,31,Bugfix: Failure due to cugraph api change in v0.16...; Method cugraph.add_adj_list is replaced in RAPIDS v0.16 with from_cudf_adjlist. This patch will check for existence of 'add_adj_list' in the object before. calling it.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1494
https://github.com/scverse/scanpy/pull/1494:31,interoperability,api,api,31,Bugfix: Failure due to cugraph api change in v0.16...; Method cugraph.add_adj_list is replaced in RAPIDS v0.16 with from_cudf_adjlist. This patch will check for existence of 'add_adj_list' in the object before. calling it.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1494
https://github.com/scverse/scanpy/pull/1494:8,performance,Failur,Failure,8,Bugfix: Failure due to cugraph api change in v0.16...; Method cugraph.add_adj_list is replaced in RAPIDS v0.16 with from_cudf_adjlist. This patch will check for existence of 'add_adj_list' in the object before. calling it.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1494
https://github.com/scverse/scanpy/pull/1494:8,reliability,Fail,Failure,8,Bugfix: Failure due to cugraph api change in v0.16...; Method cugraph.add_adj_list is replaced in RAPIDS v0.16 with from_cudf_adjlist. This patch will check for existence of 'add_adj_list' in the object before. calling it.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1494
https://github.com/scverse/scanpy/pull/1494:140,safety,patch,patch,140,Bugfix: Failure due to cugraph api change in v0.16...; Method cugraph.add_adj_list is replaced in RAPIDS v0.16 with from_cudf_adjlist. This patch will check for existence of 'add_adj_list' in the object before. calling it.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1494
https://github.com/scverse/scanpy/pull/1494:140,security,patch,patch,140,Bugfix: Failure due to cugraph api change in v0.16...; Method cugraph.add_adj_list is replaced in RAPIDS v0.16 with from_cudf_adjlist. This patch will check for existence of 'add_adj_list' in the object before. calling it.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1494
https://github.com/scverse/scanpy/issues/1495:150,integrability,filter,filter,150,"min_in_group_fraction in filter_rank_genes_groups doesn't work as expected; the default value of min_in_group_fraction is 0.25, which I understand is filter those genes that has less than 25 percent present in the group. . I use min_in_group_fraction = 0, max_in_group_fraction=1.01 to try to filter everything just by foldchange and adj_p value, but it doesn't add any gene when comparing to min_in_group_franction=0.25, . in my test, if I filter on rank_gene_groups by foldchange and adj_p, I got 87 genes back. but if I try mini_in_group_franction=0 in filter_ranK_gene_groups, I only get 25 back. . I notice an issue https://github.com/theislab/scanpy/issues/863 that mentionthat rank_gene_groups and filter_rank_gene_groups calculate fold change differently, was wondering. 1. why. 2. this doesn't explain the huge difference between numbers of gene returned by different filter method.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1495
https://github.com/scverse/scanpy/issues/1495:293,integrability,filter,filter,293,"min_in_group_fraction in filter_rank_genes_groups doesn't work as expected; the default value of min_in_group_fraction is 0.25, which I understand is filter those genes that has less than 25 percent present in the group. . I use min_in_group_fraction = 0, max_in_group_fraction=1.01 to try to filter everything just by foldchange and adj_p value, but it doesn't add any gene when comparing to min_in_group_franction=0.25, . in my test, if I filter on rank_gene_groups by foldchange and adj_p, I got 87 genes back. but if I try mini_in_group_franction=0 in filter_ranK_gene_groups, I only get 25 back. . I notice an issue https://github.com/theislab/scanpy/issues/863 that mentionthat rank_gene_groups and filter_rank_gene_groups calculate fold change differently, was wondering. 1. why. 2. this doesn't explain the huge difference between numbers of gene returned by different filter method.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1495
https://github.com/scverse/scanpy/issues/1495:441,integrability,filter,filter,441,"min_in_group_fraction in filter_rank_genes_groups doesn't work as expected; the default value of min_in_group_fraction is 0.25, which I understand is filter those genes that has less than 25 percent present in the group. . I use min_in_group_fraction = 0, max_in_group_fraction=1.01 to try to filter everything just by foldchange and adj_p value, but it doesn't add any gene when comparing to min_in_group_franction=0.25, . in my test, if I filter on rank_gene_groups by foldchange and adj_p, I got 87 genes back. but if I try mini_in_group_franction=0 in filter_ranK_gene_groups, I only get 25 back. . I notice an issue https://github.com/theislab/scanpy/issues/863 that mentionthat rank_gene_groups and filter_rank_gene_groups calculate fold change differently, was wondering. 1. why. 2. this doesn't explain the huge difference between numbers of gene returned by different filter method.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1495
https://github.com/scverse/scanpy/issues/1495:877,integrability,filter,filter,877,"min_in_group_fraction in filter_rank_genes_groups doesn't work as expected; the default value of min_in_group_fraction is 0.25, which I understand is filter those genes that has less than 25 percent present in the group. . I use min_in_group_fraction = 0, max_in_group_fraction=1.01 to try to filter everything just by foldchange and adj_p value, but it doesn't add any gene when comparing to min_in_group_franction=0.25, . in my test, if I filter on rank_gene_groups by foldchange and adj_p, I got 87 genes back. but if I try mini_in_group_franction=0 in filter_ranK_gene_groups, I only get 25 back. . I notice an issue https://github.com/theislab/scanpy/issues/863 that mentionthat rank_gene_groups and filter_rank_gene_groups calculate fold change differently, was wondering. 1. why. 2. this doesn't explain the huge difference between numbers of gene returned by different filter method.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1495
https://github.com/scverse/scanpy/issues/1495:50,reliability,doe,doesn,50,"min_in_group_fraction in filter_rank_genes_groups doesn't work as expected; the default value of min_in_group_fraction is 0.25, which I understand is filter those genes that has less than 25 percent present in the group. . I use min_in_group_fraction = 0, max_in_group_fraction=1.01 to try to filter everything just by foldchange and adj_p value, but it doesn't add any gene when comparing to min_in_group_franction=0.25, . in my test, if I filter on rank_gene_groups by foldchange and adj_p, I got 87 genes back. but if I try mini_in_group_franction=0 in filter_ranK_gene_groups, I only get 25 back. . I notice an issue https://github.com/theislab/scanpy/issues/863 that mentionthat rank_gene_groups and filter_rank_gene_groups calculate fold change differently, was wondering. 1. why. 2. this doesn't explain the huge difference between numbers of gene returned by different filter method.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1495
https://github.com/scverse/scanpy/issues/1495:354,reliability,doe,doesn,354,"min_in_group_fraction in filter_rank_genes_groups doesn't work as expected; the default value of min_in_group_fraction is 0.25, which I understand is filter those genes that has less than 25 percent present in the group. . I use min_in_group_fraction = 0, max_in_group_fraction=1.01 to try to filter everything just by foldchange and adj_p value, but it doesn't add any gene when comparing to min_in_group_franction=0.25, . in my test, if I filter on rank_gene_groups by foldchange and adj_p, I got 87 genes back. but if I try mini_in_group_franction=0 in filter_ranK_gene_groups, I only get 25 back. . I notice an issue https://github.com/theislab/scanpy/issues/863 that mentionthat rank_gene_groups and filter_rank_gene_groups calculate fold change differently, was wondering. 1. why. 2. this doesn't explain the huge difference between numbers of gene returned by different filter method.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1495
https://github.com/scverse/scanpy/issues/1495:795,reliability,doe,doesn,795,"min_in_group_fraction in filter_rank_genes_groups doesn't work as expected; the default value of min_in_group_fraction is 0.25, which I understand is filter those genes that has less than 25 percent present in the group. . I use min_in_group_fraction = 0, max_in_group_fraction=1.01 to try to filter everything just by foldchange and adj_p value, but it doesn't add any gene when comparing to min_in_group_franction=0.25, . in my test, if I filter on rank_gene_groups by foldchange and adj_p, I got 87 genes back. but if I try mini_in_group_franction=0 in filter_ranK_gene_groups, I only get 25 back. . I notice an issue https://github.com/theislab/scanpy/issues/863 that mentionthat rank_gene_groups and filter_rank_gene_groups calculate fold change differently, was wondering. 1. why. 2. this doesn't explain the huge difference between numbers of gene returned by different filter method.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1495
https://github.com/scverse/scanpy/issues/1495:430,safety,test,test,430,"min_in_group_fraction in filter_rank_genes_groups doesn't work as expected; the default value of min_in_group_fraction is 0.25, which I understand is filter those genes that has less than 25 percent present in the group. . I use min_in_group_fraction = 0, max_in_group_fraction=1.01 to try to filter everything just by foldchange and adj_p value, but it doesn't add any gene when comparing to min_in_group_franction=0.25, . in my test, if I filter on rank_gene_groups by foldchange and adj_p, I got 87 genes back. but if I try mini_in_group_franction=0 in filter_ranK_gene_groups, I only get 25 back. . I notice an issue https://github.com/theislab/scanpy/issues/863 that mentionthat rank_gene_groups and filter_rank_gene_groups calculate fold change differently, was wondering. 1. why. 2. this doesn't explain the huge difference between numbers of gene returned by different filter method.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1495
https://github.com/scverse/scanpy/issues/1495:136,testability,understand,understand,136,"min_in_group_fraction in filter_rank_genes_groups doesn't work as expected; the default value of min_in_group_fraction is 0.25, which I understand is filter those genes that has less than 25 percent present in the group. . I use min_in_group_fraction = 0, max_in_group_fraction=1.01 to try to filter everything just by foldchange and adj_p value, but it doesn't add any gene when comparing to min_in_group_franction=0.25, . in my test, if I filter on rank_gene_groups by foldchange and adj_p, I got 87 genes back. but if I try mini_in_group_franction=0 in filter_ranK_gene_groups, I only get 25 back. . I notice an issue https://github.com/theislab/scanpy/issues/863 that mentionthat rank_gene_groups and filter_rank_gene_groups calculate fold change differently, was wondering. 1. why. 2. this doesn't explain the huge difference between numbers of gene returned by different filter method.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1495
https://github.com/scverse/scanpy/issues/1495:430,testability,test,test,430,"min_in_group_fraction in filter_rank_genes_groups doesn't work as expected; the default value of min_in_group_fraction is 0.25, which I understand is filter those genes that has less than 25 percent present in the group. . I use min_in_group_fraction = 0, max_in_group_fraction=1.01 to try to filter everything just by foldchange and adj_p value, but it doesn't add any gene when comparing to min_in_group_franction=0.25, . in my test, if I filter on rank_gene_groups by foldchange and adj_p, I got 87 genes back. but if I try mini_in_group_franction=0 in filter_ranK_gene_groups, I only get 25 back. . I notice an issue https://github.com/theislab/scanpy/issues/863 that mentionthat rank_gene_groups and filter_rank_gene_groups calculate fold change differently, was wondering. 1. why. 2. this doesn't explain the huge difference between numbers of gene returned by different filter method.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1495
https://github.com/scverse/scanpy/issues/1496:6909,availability,watchdog,watchdog,6909,ite 0.34.0 . markdown-it-py 0.5.6 . MarkupSafe 1.1.1 . matplotlib 3.3.3 . mccabe 0.6.1 . mistune 0.8.4 . mypy-extensions 0.4.3 . natsort 7.0.1 . nbclient 0.5.1 . nbconvert 6.0.7 . nbdime 2.1.0 . nbformat 5.0.8 . nbresuse 0.3.6 . nest-asyncio 1.4.3 . networkx 2.5 . notebook 6.1.5 . numba 0.51.2 . numexpr 2.7.1 . numpy 1.19.4 . packaging 20.4 . pandas 1.1.4 . pandocfilters 1.4.3 . parso 0.7.1 . path 15.0.0 . pathspec 0.8.1 . pathtools 0.1.2 . patsy 0.5.1 . peepdis 0.1.13 . pexpect 4.8.0 . pickleshare 0.7.5 . Pillow 8.0.1 . pip 20.0.2 . plotly 4.12.0 . pluggy 0.13.1 . prometheus-client 0.8.0 . prompt-toolkit 3.0.8 . psutil 5.7.3 . ptvsd 4.3.2 . ptyprocess 0.6.0 . py 1.9.0 . pycodestyle 2.6.0 . pycparser 2.20 . pydocstyle 5.1.1 . pyflakes 2.2.0 . Pygments 2.7.2 . PyGObject 3.36.0 . pylint 2.6.0 . pymongo 3.11.0 . pyparsing 2.4.7 . pyrsistent 0.17.3 . pytest 6.1.2 . python-apt 2.0.0+ubuntu0.20.4.1 . python-dateutil 2.8.1 . python-debian 0.1.36ubuntu1 . python-jsonrpc-server 0.4.0 . python-language-server 0.36.1 . pytoml 0.1.21 . pytz 2020.4 . PyYAML 5.3.1 . pyzmq 20.0.0 . regex 2020.11.13 . requests 2.22.0 . requests-unixsocket 0.2.0 . retrying 1.3.3 . rich 9.2.0 . rope 0.18.0 . scikit-learn 0.23.2 . scikit-misc 0.1.3 . scipy 1.5.4 . scriptedforms 0.10.1 . scvi-tools 0.7.1 . seaborn 0.11.0 . Send2Trash 1.5.0 . setuptools 50.3.2 . setuptools-scm 4.1.2 . sinfo 0.3.1 . six 1.14.0 . smmap 3.0.4 . snowballstemmer 2.0.0 . SQLAlchemy 1.3.20 . statsmodels 0.12.1 . stdlib-list 0.7.0 . tables 3.6.1 . termcolor 1.1.0 . terminado 0.9.1 . testpath 0.4.4 . threadpoolctl 2.1.0 . toml 0.10.2 . torch 1.7.0 . tornado 6.1 . tqdm 4.51.0 . traitlets 5.0.5 . typed-ast 1.4.1 . typeguard 2.10.0 . typing-extensions 3.7.4.3 . ujson 4.0.1 . umap-learn 0.4.6 . unattended-upgrades 0.1 . urllib3 1.25.8 . watchdog 0.10.3 . wcwidth 0.2.5 . webencodings 0.5.1 . Werkzeug 1.0.1 . wheel 0.35.1 . widgetsnbextension 3.5.1 . wrapt 1.12.1 . xeus-python 0.8.3 . xlrd 1.2.0 . yapf 0.30.0 . zipp 3.4.0. </details>.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1496
https://github.com/scverse/scanpy/issues/1496:5,deployability,instal,install,5,"`pip install -e .` raises LookupError: setuptools-scm was unable to detect version for '/home/ubuntu/code/scanpy'.; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. setuptools-scm can't find the package version when running `pip install -e` or `pip install .`. I stepped through `scanpy/_metadata.py`, and it does appear to be able to get `__version__` via `setuptools_scm.get_version` as opposed to using `._compat`. It seems like it may either be an issue with `setuptools_scm` itself or the combination of my environment and `pyproject.toml`. Any ideas? ### Minimal code sample (that we can copy&paste without having any data). ```bash. pip install -e . ```. ```pytb. File ""/tmp/tmp7fu14tjf"", line 280, in <module>. main(). File ""/tmp/tmp7fu14tjf"", line 263, in main. json_out['return_val'] = hook(**hook_input['kwargs']). File ""/tmp/tmp7fu14tjf"", line 133, in prepare_metadata_for_build_wheel. return hook(metadata_directory, config_settings). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/build_meta.py"", line 161, in prepare_metadata_for_build_wheel self.run_setup(). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/build_meta.py"", line 145, in run_setup. exec(compile(code, __file__, 'exec'), locals()) File ""setup.py"", line 17, in <module>. setup(. File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/__init__.py"", line 153, in setup. return distutils.core.setup(**attrs). File ""/usr/lib/python3.8/distutils/core.py"", line 108, in setup. _setup_distribution = dist = klass(attrs). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 423, in __init__. _Distribution.__init__(self, {. File ""/usr/lib/python3.8/distutils/dist.py"", line 292, in __init__. self.finalize_options(",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1496
https://github.com/scverse/scanpy/issues/1496:75,deployability,version,version,75,"`pip install -e .` raises LookupError: setuptools-scm was unable to detect version for '/home/ubuntu/code/scanpy'.; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. setuptools-scm can't find the package version when running `pip install -e` or `pip install .`. I stepped through `scanpy/_metadata.py`, and it does appear to be able to get `__version__` via `setuptools_scm.get_version` as opposed to using `._compat`. It seems like it may either be an issue with `setuptools_scm` itself or the combination of my environment and `pyproject.toml`. Any ideas? ### Minimal code sample (that we can copy&paste without having any data). ```bash. pip install -e . ```. ```pytb. File ""/tmp/tmp7fu14tjf"", line 280, in <module>. main(). File ""/tmp/tmp7fu14tjf"", line 263, in main. json_out['return_val'] = hook(**hook_input['kwargs']). File ""/tmp/tmp7fu14tjf"", line 133, in prepare_metadata_for_build_wheel. return hook(metadata_directory, config_settings). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/build_meta.py"", line 161, in prepare_metadata_for_build_wheel self.run_setup(). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/build_meta.py"", line 145, in run_setup. exec(compile(code, __file__, 'exec'), locals()) File ""setup.py"", line 17, in <module>. setup(. File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/__init__.py"", line 153, in setup. return distutils.core.setup(**attrs). File ""/usr/lib/python3.8/distutils/core.py"", line 108, in setup. _setup_distribution = dist = klass(attrs). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 423, in __init__. _Distribution.__init__(self, {. File ""/usr/lib/python3.8/distutils/dist.py"", line 292, in __init__. self.finalize_options(",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1496
https://github.com/scverse/scanpy/issues/1496:237,deployability,version,version,237,"`pip install -e .` raises LookupError: setuptools-scm was unable to detect version for '/home/ubuntu/code/scanpy'.; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. setuptools-scm can't find the package version when running `pip install -e` or `pip install .`. I stepped through `scanpy/_metadata.py`, and it does appear to be able to get `__version__` via `setuptools_scm.get_version` as opposed to using `._compat`. It seems like it may either be an issue with `setuptools_scm` itself or the combination of my environment and `pyproject.toml`. Any ideas? ### Minimal code sample (that we can copy&paste without having any data). ```bash. pip install -e . ```. ```pytb. File ""/tmp/tmp7fu14tjf"", line 280, in <module>. main(). File ""/tmp/tmp7fu14tjf"", line 263, in main. json_out['return_val'] = hook(**hook_input['kwargs']). File ""/tmp/tmp7fu14tjf"", line 133, in prepare_metadata_for_build_wheel. return hook(metadata_directory, config_settings). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/build_meta.py"", line 161, in prepare_metadata_for_build_wheel self.run_setup(). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/build_meta.py"", line 145, in run_setup. exec(compile(code, __file__, 'exec'), locals()) File ""setup.py"", line 17, in <module>. setup(. File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/__init__.py"", line 153, in setup. return distutils.core.setup(**attrs). File ""/usr/lib/python3.8/distutils/core.py"", line 108, in setup. _setup_distribution = dist = klass(attrs). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 423, in __init__. _Distribution.__init__(self, {. File ""/usr/lib/python3.8/distutils/dist.py"", line 292, in __init__. self.finalize_options(",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1496
https://github.com/scverse/scanpy/issues/1496:381,deployability,version,version,381,"`pip install -e .` raises LookupError: setuptools-scm was unable to detect version for '/home/ubuntu/code/scanpy'.; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. setuptools-scm can't find the package version when running `pip install -e` or `pip install .`. I stepped through `scanpy/_metadata.py`, and it does appear to be able to get `__version__` via `setuptools_scm.get_version` as opposed to using `._compat`. It seems like it may either be an issue with `setuptools_scm` itself or the combination of my environment and `pyproject.toml`. Any ideas? ### Minimal code sample (that we can copy&paste without having any data). ```bash. pip install -e . ```. ```pytb. File ""/tmp/tmp7fu14tjf"", line 280, in <module>. main(). File ""/tmp/tmp7fu14tjf"", line 263, in main. json_out['return_val'] = hook(**hook_input['kwargs']). File ""/tmp/tmp7fu14tjf"", line 133, in prepare_metadata_for_build_wheel. return hook(metadata_directory, config_settings). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/build_meta.py"", line 161, in prepare_metadata_for_build_wheel self.run_setup(). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/build_meta.py"", line 145, in run_setup. exec(compile(code, __file__, 'exec'), locals()) File ""setup.py"", line 17, in <module>. setup(. File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/__init__.py"", line 153, in setup. return distutils.core.setup(**attrs). File ""/usr/lib/python3.8/distutils/core.py"", line 108, in setup. _setup_distribution = dist = klass(attrs). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 423, in __init__. _Distribution.__init__(self, {. File ""/usr/lib/python3.8/distutils/dist.py"", line 292, in __init__. self.finalize_options(",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1496
https://github.com/scverse/scanpy/issues/1496:407,deployability,instal,install,407,"`pip install -e .` raises LookupError: setuptools-scm was unable to detect version for '/home/ubuntu/code/scanpy'.; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. setuptools-scm can't find the package version when running `pip install -e` or `pip install .`. I stepped through `scanpy/_metadata.py`, and it does appear to be able to get `__version__` via `setuptools_scm.get_version` as opposed to using `._compat`. It seems like it may either be an issue with `setuptools_scm` itself or the combination of my environment and `pyproject.toml`. Any ideas? ### Minimal code sample (that we can copy&paste without having any data). ```bash. pip install -e . ```. ```pytb. File ""/tmp/tmp7fu14tjf"", line 280, in <module>. main(). File ""/tmp/tmp7fu14tjf"", line 263, in main. json_out['return_val'] = hook(**hook_input['kwargs']). File ""/tmp/tmp7fu14tjf"", line 133, in prepare_metadata_for_build_wheel. return hook(metadata_directory, config_settings). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/build_meta.py"", line 161, in prepare_metadata_for_build_wheel self.run_setup(). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/build_meta.py"", line 145, in run_setup. exec(compile(code, __file__, 'exec'), locals()) File ""setup.py"", line 17, in <module>. setup(. File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/__init__.py"", line 153, in setup. return distutils.core.setup(**attrs). File ""/usr/lib/python3.8/distutils/core.py"", line 108, in setup. _setup_distribution = dist = klass(attrs). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 423, in __init__. _Distribution.__init__(self, {. File ""/usr/lib/python3.8/distutils/dist.py"", line 292, in __init__. self.finalize_options(",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1496
https://github.com/scverse/scanpy/issues/1496:427,deployability,instal,install,427,"`pip install -e .` raises LookupError: setuptools-scm was unable to detect version for '/home/ubuntu/code/scanpy'.; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. setuptools-scm can't find the package version when running `pip install -e` or `pip install .`. I stepped through `scanpy/_metadata.py`, and it does appear to be able to get `__version__` via `setuptools_scm.get_version` as opposed to using `._compat`. It seems like it may either be an issue with `setuptools_scm` itself or the combination of my environment and `pyproject.toml`. Any ideas? ### Minimal code sample (that we can copy&paste without having any data). ```bash. pip install -e . ```. ```pytb. File ""/tmp/tmp7fu14tjf"", line 280, in <module>. main(). File ""/tmp/tmp7fu14tjf"", line 263, in main. json_out['return_val'] = hook(**hook_input['kwargs']). File ""/tmp/tmp7fu14tjf"", line 133, in prepare_metadata_for_build_wheel. return hook(metadata_directory, config_settings). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/build_meta.py"", line 161, in prepare_metadata_for_build_wheel self.run_setup(). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/build_meta.py"", line 145, in run_setup. exec(compile(code, __file__, 'exec'), locals()) File ""setup.py"", line 17, in <module>. setup(. File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/__init__.py"", line 153, in setup. return distutils.core.setup(**attrs). File ""/usr/lib/python3.8/distutils/core.py"", line 108, in setup. _setup_distribution = dist = klass(attrs). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 423, in __init__. _Distribution.__init__(self, {. File ""/usr/lib/python3.8/distutils/dist.py"", line 292, in __init__. self.finalize_options(",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1496
https://github.com/scverse/scanpy/issues/1496:822,deployability,instal,install,822,"`pip install -e .` raises LookupError: setuptools-scm was unable to detect version for '/home/ubuntu/code/scanpy'.; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. setuptools-scm can't find the package version when running `pip install -e` or `pip install .`. I stepped through `scanpy/_metadata.py`, and it does appear to be able to get `__version__` via `setuptools_scm.get_version` as opposed to using `._compat`. It seems like it may either be an issue with `setuptools_scm` itself or the combination of my environment and `pyproject.toml`. Any ideas? ### Minimal code sample (that we can copy&paste without having any data). ```bash. pip install -e . ```. ```pytb. File ""/tmp/tmp7fu14tjf"", line 280, in <module>. main(). File ""/tmp/tmp7fu14tjf"", line 263, in main. json_out['return_val'] = hook(**hook_input['kwargs']). File ""/tmp/tmp7fu14tjf"", line 133, in prepare_metadata_for_build_wheel. return hook(metadata_directory, config_settings). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/build_meta.py"", line 161, in prepare_metadata_for_build_wheel self.run_setup(). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/build_meta.py"", line 145, in run_setup. exec(compile(code, __file__, 'exec'), locals()) File ""setup.py"", line 17, in <module>. setup(. File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/__init__.py"", line 153, in setup. return distutils.core.setup(**attrs). File ""/usr/lib/python3.8/distutils/core.py"", line 108, in setup. _setup_distribution = dist = klass(attrs). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 423, in __init__. _Distribution.__init__(self, {. File ""/usr/lib/python3.8/distutils/dist.py"", line 292, in __init__. self.finalize_options(",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1496
https://github.com/scverse/scanpy/issues/1496:888,deployability,modul,module,888,"`pip install -e .` raises LookupError: setuptools-scm was unable to detect version for '/home/ubuntu/code/scanpy'.; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. setuptools-scm can't find the package version when running `pip install -e` or `pip install .`. I stepped through `scanpy/_metadata.py`, and it does appear to be able to get `__version__` via `setuptools_scm.get_version` as opposed to using `._compat`. It seems like it may either be an issue with `setuptools_scm` itself or the combination of my environment and `pyproject.toml`. Any ideas? ### Minimal code sample (that we can copy&paste without having any data). ```bash. pip install -e . ```. ```pytb. File ""/tmp/tmp7fu14tjf"", line 280, in <module>. main(). File ""/tmp/tmp7fu14tjf"", line 263, in main. json_out['return_val'] = hook(**hook_input['kwargs']). File ""/tmp/tmp7fu14tjf"", line 133, in prepare_metadata_for_build_wheel. return hook(metadata_directory, config_settings). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/build_meta.py"", line 161, in prepare_metadata_for_build_wheel self.run_setup(). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/build_meta.py"", line 145, in run_setup. exec(compile(code, __file__, 'exec'), locals()) File ""setup.py"", line 17, in <module>. setup(. File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/__init__.py"", line 153, in setup. return distutils.core.setup(**attrs). File ""/usr/lib/python3.8/distutils/core.py"", line 108, in setup. _setup_distribution = dist = klass(attrs). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 423, in __init__. _Distribution.__init__(self, {. File ""/usr/lib/python3.8/distutils/dist.py"", line 292, in __init__. self.finalize_options(",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1496
https://github.com/scverse/scanpy/issues/1496:1141,deployability,build,build-env-,1141," issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. setuptools-scm can't find the package version when running `pip install -e` or `pip install .`. I stepped through `scanpy/_metadata.py`, and it does appear to be able to get `__version__` via `setuptools_scm.get_version` as opposed to using `._compat`. It seems like it may either be an issue with `setuptools_scm` itself or the combination of my environment and `pyproject.toml`. Any ideas? ### Minimal code sample (that we can copy&paste without having any data). ```bash. pip install -e . ```. ```pytb. File ""/tmp/tmp7fu14tjf"", line 280, in <module>. main(). File ""/tmp/tmp7fu14tjf"", line 263, in main. json_out['return_val'] = hook(**hook_input['kwargs']). File ""/tmp/tmp7fu14tjf"", line 133, in prepare_metadata_for_build_wheel. return hook(metadata_directory, config_settings). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/build_meta.py"", line 161, in prepare_metadata_for_build_wheel self.run_setup(). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/build_meta.py"", line 145, in run_setup. exec(compile(code, __file__, 'exec'), locals()) File ""setup.py"", line 17, in <module>. setup(. File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/__init__.py"", line 153, in setup. return distutils.core.setup(**attrs). File ""/usr/lib/python3.8/distutils/core.py"", line 108, in setup. _setup_distribution = dist = klass(attrs). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 423, in __init__. _Distribution.__init__(self, {. File ""/usr/lib/python3.8/distutils/dist.py"", line 292, in __init__. self.finalize_options() File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 695, in finalize_options. ep(self). File ""/tmp/p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1496
https://github.com/scverse/scanpy/issues/1496:1302,deployability,build,build-env-,1302,"n the master branch of scanpy. ---. setuptools-scm can't find the package version when running `pip install -e` or `pip install .`. I stepped through `scanpy/_metadata.py`, and it does appear to be able to get `__version__` via `setuptools_scm.get_version` as opposed to using `._compat`. It seems like it may either be an issue with `setuptools_scm` itself or the combination of my environment and `pyproject.toml`. Any ideas? ### Minimal code sample (that we can copy&paste without having any data). ```bash. pip install -e . ```. ```pytb. File ""/tmp/tmp7fu14tjf"", line 280, in <module>. main(). File ""/tmp/tmp7fu14tjf"", line 263, in main. json_out['return_val'] = hook(**hook_input['kwargs']). File ""/tmp/tmp7fu14tjf"", line 133, in prepare_metadata_for_build_wheel. return hook(metadata_directory, config_settings). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/build_meta.py"", line 161, in prepare_metadata_for_build_wheel self.run_setup(). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/build_meta.py"", line 145, in run_setup. exec(compile(code, __file__, 'exec'), locals()) File ""setup.py"", line 17, in <module>. setup(. File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/__init__.py"", line 153, in setup. return distutils.core.setup(**attrs). File ""/usr/lib/python3.8/distutils/core.py"", line 108, in setup. _setup_distribution = dist = klass(attrs). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 423, in __init__. _Distribution.__init__(self, {. File ""/usr/lib/python3.8/distutils/dist.py"", line 292, in __init__. self.finalize_options() File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 695, in finalize_options. ep(self). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 702, in _finalize_setup_keywords. ep.load()(self, ep.name, value). File ""/usr",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1496
https://github.com/scverse/scanpy/issues/1496:1486,deployability,modul,module,1486,"es appear to be able to get `__version__` via `setuptools_scm.get_version` as opposed to using `._compat`. It seems like it may either be an issue with `setuptools_scm` itself or the combination of my environment and `pyproject.toml`. Any ideas? ### Minimal code sample (that we can copy&paste without having any data). ```bash. pip install -e . ```. ```pytb. File ""/tmp/tmp7fu14tjf"", line 280, in <module>. main(). File ""/tmp/tmp7fu14tjf"", line 263, in main. json_out['return_val'] = hook(**hook_input['kwargs']). File ""/tmp/tmp7fu14tjf"", line 133, in prepare_metadata_for_build_wheel. return hook(metadata_directory, config_settings). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/build_meta.py"", line 161, in prepare_metadata_for_build_wheel self.run_setup(). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/build_meta.py"", line 145, in run_setup. exec(compile(code, __file__, 'exec'), locals()) File ""setup.py"", line 17, in <module>. setup(. File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/__init__.py"", line 153, in setup. return distutils.core.setup(**attrs). File ""/usr/lib/python3.8/distutils/core.py"", line 108, in setup. _setup_distribution = dist = klass(attrs). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 423, in __init__. _Distribution.__init__(self, {. File ""/usr/lib/python3.8/distutils/dist.py"", line 292, in __init__. self.finalize_options() File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 695, in finalize_options. ep(self). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 702, in _finalize_setup_keywords. ep.load()(self, ep.name, value). File ""/usr/local/lib/python3.8/dist-packages/setuptools_scm/integration.py"", line 17, in version_keyword. dist.metadata.version = _get_version(config). File ""/usr/local/lib/python3.8/dist-pack",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1496
https://github.com/scverse/scanpy/issues/1496:1518,deployability,build,build-env-,1518,"sion__` via `setuptools_scm.get_version` as opposed to using `._compat`. It seems like it may either be an issue with `setuptools_scm` itself or the combination of my environment and `pyproject.toml`. Any ideas? ### Minimal code sample (that we can copy&paste without having any data). ```bash. pip install -e . ```. ```pytb. File ""/tmp/tmp7fu14tjf"", line 280, in <module>. main(). File ""/tmp/tmp7fu14tjf"", line 263, in main. json_out['return_val'] = hook(**hook_input['kwargs']). File ""/tmp/tmp7fu14tjf"", line 133, in prepare_metadata_for_build_wheel. return hook(metadata_directory, config_settings). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/build_meta.py"", line 161, in prepare_metadata_for_build_wheel self.run_setup(). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/build_meta.py"", line 145, in run_setup. exec(compile(code, __file__, 'exec'), locals()) File ""setup.py"", line 17, in <module>. setup(. File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/__init__.py"", line 153, in setup. return distutils.core.setup(**attrs). File ""/usr/lib/python3.8/distutils/core.py"", line 108, in setup. _setup_distribution = dist = klass(attrs). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 423, in __init__. _Distribution.__init__(self, {. File ""/usr/lib/python3.8/distutils/dist.py"", line 292, in __init__. self.finalize_options() File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 695, in finalize_options. ep(self). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 702, in _finalize_setup_keywords. ep.load()(self, ep.name, value). File ""/usr/local/lib/python3.8/dist-packages/setuptools_scm/integration.py"", line 17, in version_keyword. dist.metadata.version = _get_version(config). File ""/usr/local/lib/python3.8/dist-packages/setuptools_scm/__init__.py"", ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1496
https://github.com/scverse/scanpy/issues/1496:1779,deployability,build,build-env-,1779,"ithout having any data). ```bash. pip install -e . ```. ```pytb. File ""/tmp/tmp7fu14tjf"", line 280, in <module>. main(). File ""/tmp/tmp7fu14tjf"", line 263, in main. json_out['return_val'] = hook(**hook_input['kwargs']). File ""/tmp/tmp7fu14tjf"", line 133, in prepare_metadata_for_build_wheel. return hook(metadata_directory, config_settings). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/build_meta.py"", line 161, in prepare_metadata_for_build_wheel self.run_setup(). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/build_meta.py"", line 145, in run_setup. exec(compile(code, __file__, 'exec'), locals()) File ""setup.py"", line 17, in <module>. setup(. File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/__init__.py"", line 153, in setup. return distutils.core.setup(**attrs). File ""/usr/lib/python3.8/distutils/core.py"", line 108, in setup. _setup_distribution = dist = klass(attrs). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 423, in __init__. _Distribution.__init__(self, {. File ""/usr/lib/python3.8/distutils/dist.py"", line 292, in __init__. self.finalize_options() File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 695, in finalize_options. ep(self). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 702, in _finalize_setup_keywords. ep.load()(self, ep.name, value). File ""/usr/local/lib/python3.8/dist-packages/setuptools_scm/integration.py"", line 17, in version_keyword. dist.metadata.version = _get_version(config). File ""/usr/local/lib/python3.8/dist-packages/setuptools_scm/__init__.py"", line 148, in _get_version. parsed_version = _do_parse(config). File ""/usr/local/lib/python3.8/dist-packages/setuptools_scm/__init__.py"", line 110, in _do_parse raise LookupError(. LookupError: setuptools-scm was unable to detect version for '/home/ubuntu/code/s",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1496
https://github.com/scverse/scanpy/issues/1496:2017,deployability,build,build-env-,2017,"4tjf"", line 133, in prepare_metadata_for_build_wheel. return hook(metadata_directory, config_settings). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/build_meta.py"", line 161, in prepare_metadata_for_build_wheel self.run_setup(). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/build_meta.py"", line 145, in run_setup. exec(compile(code, __file__, 'exec'), locals()) File ""setup.py"", line 17, in <module>. setup(. File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/__init__.py"", line 153, in setup. return distutils.core.setup(**attrs). File ""/usr/lib/python3.8/distutils/core.py"", line 108, in setup. _setup_distribution = dist = klass(attrs). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 423, in __init__. _Distribution.__init__(self, {. File ""/usr/lib/python3.8/distutils/dist.py"", line 292, in __init__. self.finalize_options() File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 695, in finalize_options. ep(self). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 702, in _finalize_setup_keywords. ep.load()(self, ep.name, value). File ""/usr/local/lib/python3.8/dist-packages/setuptools_scm/integration.py"", line 17, in version_keyword. dist.metadata.version = _get_version(config). File ""/usr/local/lib/python3.8/dist-packages/setuptools_scm/__init__.py"", line 148, in _get_version. parsed_version = _do_parse(config). File ""/usr/local/lib/python3.8/dist-packages/setuptools_scm/__init__.py"", line 110, in _do_parse raise LookupError(. LookupError: setuptools-scm was unable to detect version for '/home/ubuntu/code/scanpy'. Make sure you're either building from a fully intact git repository or PyPI tarballs. Most other sources (such as GitHub's tarballs, a git checkout without the .git folder) don't contain the necessary metadata and will not work. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1496
https://github.com/scverse/scanpy/issues/1496:2149,deployability,build,build-env-,2149,"dh0v3/overlay/lib/python3.8/site-packages/setuptools/build_meta.py"", line 161, in prepare_metadata_for_build_wheel self.run_setup(). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/build_meta.py"", line 145, in run_setup. exec(compile(code, __file__, 'exec'), locals()) File ""setup.py"", line 17, in <module>. setup(. File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/__init__.py"", line 153, in setup. return distutils.core.setup(**attrs). File ""/usr/lib/python3.8/distutils/core.py"", line 108, in setup. _setup_distribution = dist = klass(attrs). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 423, in __init__. _Distribution.__init__(self, {. File ""/usr/lib/python3.8/distutils/dist.py"", line 292, in __init__. self.finalize_options() File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 695, in finalize_options. ep(self). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 702, in _finalize_setup_keywords. ep.load()(self, ep.name, value). File ""/usr/local/lib/python3.8/dist-packages/setuptools_scm/integration.py"", line 17, in version_keyword. dist.metadata.version = _get_version(config). File ""/usr/local/lib/python3.8/dist-packages/setuptools_scm/__init__.py"", line 148, in _get_version. parsed_version = _do_parse(config). File ""/usr/local/lib/python3.8/dist-packages/setuptools_scm/__init__.py"", line 110, in _do_parse raise LookupError(. LookupError: setuptools-scm was unable to detect version for '/home/ubuntu/code/scanpy'. Make sure you're either building from a fully intact git repository or PyPI tarballs. Most other sources (such as GitHub's tarballs, a git checkout without the .git folder) don't contain the necessary metadata and will not work. . For example, if you're using pip, instead of https://github.com/user/proj/archive/master.zip use git+https://github.com/user/proj.g",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1496
https://github.com/scverse/scanpy/issues/1496:2357,deployability,integr,integration,2357,"ools/build_meta.py"", line 145, in run_setup. exec(compile(code, __file__, 'exec'), locals()) File ""setup.py"", line 17, in <module>. setup(. File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/__init__.py"", line 153, in setup. return distutils.core.setup(**attrs). File ""/usr/lib/python3.8/distutils/core.py"", line 108, in setup. _setup_distribution = dist = klass(attrs). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 423, in __init__. _Distribution.__init__(self, {. File ""/usr/lib/python3.8/distutils/dist.py"", line 292, in __init__. self.finalize_options() File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 695, in finalize_options. ep(self). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 702, in _finalize_setup_keywords. ep.load()(self, ep.name, value). File ""/usr/local/lib/python3.8/dist-packages/setuptools_scm/integration.py"", line 17, in version_keyword. dist.metadata.version = _get_version(config). File ""/usr/local/lib/python3.8/dist-packages/setuptools_scm/__init__.py"", line 148, in _get_version. parsed_version = _do_parse(config). File ""/usr/local/lib/python3.8/dist-packages/setuptools_scm/__init__.py"", line 110, in _do_parse raise LookupError(. LookupError: setuptools-scm was unable to detect version for '/home/ubuntu/code/scanpy'. Make sure you're either building from a fully intact git repository or PyPI tarballs. Most other sources (such as GitHub's tarballs, a git checkout without the .git folder) don't contain the necessary metadata and will not work. . For example, if you're using pip, instead of https://github.com/user/proj/archive/master.zip use git+https://github.com/user/proj.git#egg=proj```. ```. #### Versions. <details>. scanpy. problem is with installation, so scanpy.logging.print_versions(). commit: ef5a8ee57c2aef7778a069a49101a8998718e6d5. python. 3.8.5. pip. 20.0.2 . ubuntu. 2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1496
https://github.com/scverse/scanpy/issues/1496:2417,deployability,version,version,2417,"code, __file__, 'exec'), locals()) File ""setup.py"", line 17, in <module>. setup(. File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/__init__.py"", line 153, in setup. return distutils.core.setup(**attrs). File ""/usr/lib/python3.8/distutils/core.py"", line 108, in setup. _setup_distribution = dist = klass(attrs). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 423, in __init__. _Distribution.__init__(self, {. File ""/usr/lib/python3.8/distutils/dist.py"", line 292, in __init__. self.finalize_options() File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 695, in finalize_options. ep(self). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 702, in _finalize_setup_keywords. ep.load()(self, ep.name, value). File ""/usr/local/lib/python3.8/dist-packages/setuptools_scm/integration.py"", line 17, in version_keyword. dist.metadata.version = _get_version(config). File ""/usr/local/lib/python3.8/dist-packages/setuptools_scm/__init__.py"", line 148, in _get_version. parsed_version = _do_parse(config). File ""/usr/local/lib/python3.8/dist-packages/setuptools_scm/__init__.py"", line 110, in _do_parse raise LookupError(. LookupError: setuptools-scm was unable to detect version for '/home/ubuntu/code/scanpy'. Make sure you're either building from a fully intact git repository or PyPI tarballs. Most other sources (such as GitHub's tarballs, a git checkout without the .git folder) don't contain the necessary metadata and will not work. . For example, if you're using pip, instead of https://github.com/user/proj/archive/master.zip use git+https://github.com/user/proj.git#egg=proj```. ```. #### Versions. <details>. scanpy. problem is with installation, so scanpy.logging.print_versions(). commit: ef5a8ee57c2aef7778a069a49101a8998718e6d5. python. 3.8.5. pip. 20.0.2 . ubuntu. 20.04. pip list. Package Version Location . ---------------",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1496
https://github.com/scverse/scanpy/issues/1496:2752,deployability,version,version,2752,"attrs). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 423, in __init__. _Distribution.__init__(self, {. File ""/usr/lib/python3.8/distutils/dist.py"", line 292, in __init__. self.finalize_options() File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 695, in finalize_options. ep(self). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 702, in _finalize_setup_keywords. ep.load()(self, ep.name, value). File ""/usr/local/lib/python3.8/dist-packages/setuptools_scm/integration.py"", line 17, in version_keyword. dist.metadata.version = _get_version(config). File ""/usr/local/lib/python3.8/dist-packages/setuptools_scm/__init__.py"", line 148, in _get_version. parsed_version = _do_parse(config). File ""/usr/local/lib/python3.8/dist-packages/setuptools_scm/__init__.py"", line 110, in _do_parse raise LookupError(. LookupError: setuptools-scm was unable to detect version for '/home/ubuntu/code/scanpy'. Make sure you're either building from a fully intact git repository or PyPI tarballs. Most other sources (such as GitHub's tarballs, a git checkout without the .git folder) don't contain the necessary metadata and will not work. . For example, if you're using pip, instead of https://github.com/user/proj/archive/master.zip use git+https://github.com/user/proj.git#egg=proj```. ```. #### Versions. <details>. scanpy. problem is with installation, so scanpy.logging.print_versions(). commit: ef5a8ee57c2aef7778a069a49101a8998718e6d5. python. 3.8.5. pip. 20.0.2 . ubuntu. 20.04. pip list. Package Version Location . ------------------------- -------------------- -----------------------------. analysaurus 0.0.1 /home/ubuntu/code/analysaurus. anndata 0.7.5 . ansi2html 1.5.2 . appdirs 1.4.4 . argon2-cffi 20.1.0 . astroid 2.4.2 . async-generator 1.10 . attrs 20.3.0 . autopep8 1.5.4 . backcall 0.2.0 . biopython 1.78 . black 20.8b1 . bleach 3.2.1 . bokeh 2.2.3 . bot",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1496
https://github.com/scverse/scanpy/issues/1496:2816,deployability,build,building,2816,"site-packages/setuptools/dist.py"", line 423, in __init__. _Distribution.__init__(self, {. File ""/usr/lib/python3.8/distutils/dist.py"", line 292, in __init__. self.finalize_options() File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 695, in finalize_options. ep(self). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 702, in _finalize_setup_keywords. ep.load()(self, ep.name, value). File ""/usr/local/lib/python3.8/dist-packages/setuptools_scm/integration.py"", line 17, in version_keyword. dist.metadata.version = _get_version(config). File ""/usr/local/lib/python3.8/dist-packages/setuptools_scm/__init__.py"", line 148, in _get_version. parsed_version = _do_parse(config). File ""/usr/local/lib/python3.8/dist-packages/setuptools_scm/__init__.py"", line 110, in _do_parse raise LookupError(. LookupError: setuptools-scm was unable to detect version for '/home/ubuntu/code/scanpy'. Make sure you're either building from a fully intact git repository or PyPI tarballs. Most other sources (such as GitHub's tarballs, a git checkout without the .git folder) don't contain the necessary metadata and will not work. . For example, if you're using pip, instead of https://github.com/user/proj/archive/master.zip use git+https://github.com/user/proj.git#egg=proj```. ```. #### Versions. <details>. scanpy. problem is with installation, so scanpy.logging.print_versions(). commit: ef5a8ee57c2aef7778a069a49101a8998718e6d5. python. 3.8.5. pip. 20.0.2 . ubuntu. 20.04. pip list. Package Version Location . ------------------------- -------------------- -----------------------------. analysaurus 0.0.1 /home/ubuntu/code/analysaurus. anndata 0.7.5 . ansi2html 1.5.2 . appdirs 1.4.4 . argon2-cffi 20.1.0 . astroid 2.4.2 . async-generator 1.10 . attrs 20.3.0 . autopep8 1.5.4 . backcall 0.2.0 . biopython 1.78 . black 20.8b1 . bleach 3.2.1 . bokeh 2.2.3 . botocore 1.19.18 . Brotli 1.0.9 . cellforest 0.0.2 /home/ubuntu/cod",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1496
https://github.com/scverse/scanpy/issues/1496:2971,deployability,contain,contain,2971,"_. self.finalize_options() File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 695, in finalize_options. ep(self). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 702, in _finalize_setup_keywords. ep.load()(self, ep.name, value). File ""/usr/local/lib/python3.8/dist-packages/setuptools_scm/integration.py"", line 17, in version_keyword. dist.metadata.version = _get_version(config). File ""/usr/local/lib/python3.8/dist-packages/setuptools_scm/__init__.py"", line 148, in _get_version. parsed_version = _do_parse(config). File ""/usr/local/lib/python3.8/dist-packages/setuptools_scm/__init__.py"", line 110, in _do_parse raise LookupError(. LookupError: setuptools-scm was unable to detect version for '/home/ubuntu/code/scanpy'. Make sure you're either building from a fully intact git repository or PyPI tarballs. Most other sources (such as GitHub's tarballs, a git checkout without the .git folder) don't contain the necessary metadata and will not work. . For example, if you're using pip, instead of https://github.com/user/proj/archive/master.zip use git+https://github.com/user/proj.git#egg=proj```. ```. #### Versions. <details>. scanpy. problem is with installation, so scanpy.logging.print_versions(). commit: ef5a8ee57c2aef7778a069a49101a8998718e6d5. python. 3.8.5. pip. 20.0.2 . ubuntu. 20.04. pip list. Package Version Location . ------------------------- -------------------- -----------------------------. analysaurus 0.0.1 /home/ubuntu/code/analysaurus. anndata 0.7.5 . ansi2html 1.5.2 . appdirs 1.4.4 . argon2-cffi 20.1.0 . astroid 2.4.2 . async-generator 1.10 . attrs 20.3.0 . autopep8 1.5.4 . backcall 0.2.0 . biopython 1.78 . black 20.8b1 . bleach 3.2.1 . bokeh 2.2.3 . botocore 1.19.18 . Brotli 1.0.9 . cellforest 0.0.2 /home/ubuntu/code/cellforest . certifi 2019.11.28 . cffi 1.14.3 . chardet 3.0.4 . click 7.1.2 . colorama 0.4.4 . commonmark 0.9.1 . cycler 0.10.0 . dash 1.17.0 . dash-buil",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1496
https://github.com/scverse/scanpy/issues/1496:3180,deployability,Version,Versions,3180,"on3.8/site-packages/setuptools/dist.py"", line 702, in _finalize_setup_keywords. ep.load()(self, ep.name, value). File ""/usr/local/lib/python3.8/dist-packages/setuptools_scm/integration.py"", line 17, in version_keyword. dist.metadata.version = _get_version(config). File ""/usr/local/lib/python3.8/dist-packages/setuptools_scm/__init__.py"", line 148, in _get_version. parsed_version = _do_parse(config). File ""/usr/local/lib/python3.8/dist-packages/setuptools_scm/__init__.py"", line 110, in _do_parse raise LookupError(. LookupError: setuptools-scm was unable to detect version for '/home/ubuntu/code/scanpy'. Make sure you're either building from a fully intact git repository or PyPI tarballs. Most other sources (such as GitHub's tarballs, a git checkout without the .git folder) don't contain the necessary metadata and will not work. . For example, if you're using pip, instead of https://github.com/user/proj/archive/master.zip use git+https://github.com/user/proj.git#egg=proj```. ```. #### Versions. <details>. scanpy. problem is with installation, so scanpy.logging.print_versions(). commit: ef5a8ee57c2aef7778a069a49101a8998718e6d5. python. 3.8.5. pip. 20.0.2 . ubuntu. 20.04. pip list. Package Version Location . ------------------------- -------------------- -----------------------------. analysaurus 0.0.1 /home/ubuntu/code/analysaurus. anndata 0.7.5 . ansi2html 1.5.2 . appdirs 1.4.4 . argon2-cffi 20.1.0 . astroid 2.4.2 . async-generator 1.10 . attrs 20.3.0 . autopep8 1.5.4 . backcall 0.2.0 . biopython 1.78 . black 20.8b1 . bleach 3.2.1 . bokeh 2.2.3 . botocore 1.19.18 . Brotli 1.0.9 . cellforest 0.0.2 /home/ubuntu/code/cellforest . certifi 2019.11.28 . cffi 1.14.3 . chardet 3.0.4 . click 7.1.2 . colorama 0.4.4 . commonmark 0.9.1 . cycler 0.10.0 . dash 1.17.0 . dash-building-blocks 0.1.2 . dash-core-components 1.13.0 . dash-html-components 1.1.1 . dash-renderer 1.8.3 . dash-table 4.11.0 . dataclasses 0.6 . dataforest 0.0.2 /home/ubuntu/code/dataforest . dbus-python 1.2.16 . d",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1496
https://github.com/scverse/scanpy/issues/1496:3225,deployability,instal,installation,3225,"02, in _finalize_setup_keywords. ep.load()(self, ep.name, value). File ""/usr/local/lib/python3.8/dist-packages/setuptools_scm/integration.py"", line 17, in version_keyword. dist.metadata.version = _get_version(config). File ""/usr/local/lib/python3.8/dist-packages/setuptools_scm/__init__.py"", line 148, in _get_version. parsed_version = _do_parse(config). File ""/usr/local/lib/python3.8/dist-packages/setuptools_scm/__init__.py"", line 110, in _do_parse raise LookupError(. LookupError: setuptools-scm was unable to detect version for '/home/ubuntu/code/scanpy'. Make sure you're either building from a fully intact git repository or PyPI tarballs. Most other sources (such as GitHub's tarballs, a git checkout without the .git folder) don't contain the necessary metadata and will not work. . For example, if you're using pip, instead of https://github.com/user/proj/archive/master.zip use git+https://github.com/user/proj.git#egg=proj```. ```. #### Versions. <details>. scanpy. problem is with installation, so scanpy.logging.print_versions(). commit: ef5a8ee57c2aef7778a069a49101a8998718e6d5. python. 3.8.5. pip. 20.0.2 . ubuntu. 20.04. pip list. Package Version Location . ------------------------- -------------------- -----------------------------. analysaurus 0.0.1 /home/ubuntu/code/analysaurus. anndata 0.7.5 . ansi2html 1.5.2 . appdirs 1.4.4 . argon2-cffi 20.1.0 . astroid 2.4.2 . async-generator 1.10 . attrs 20.3.0 . autopep8 1.5.4 . backcall 0.2.0 . biopython 1.78 . black 20.8b1 . bleach 3.2.1 . bokeh 2.2.3 . botocore 1.19.18 . Brotli 1.0.9 . cellforest 0.0.2 /home/ubuntu/code/cellforest . certifi 2019.11.28 . cffi 1.14.3 . chardet 3.0.4 . click 7.1.2 . colorama 0.4.4 . commonmark 0.9.1 . cycler 0.10.0 . dash 1.17.0 . dash-building-blocks 0.1.2 . dash-core-components 1.13.0 . dash-html-components 1.1.1 . dash-renderer 1.8.3 . dash-table 4.11.0 . dataclasses 0.6 . dataforest 0.0.2 /home/ubuntu/code/dataforest . dbus-python 1.2.16 . decorator 4.4.2 . defusedxml 0.6.0 . distro-info",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1496
https://github.com/scverse/scanpy/issues/1496:3249,deployability,log,logging,3249,"_keywords. ep.load()(self, ep.name, value). File ""/usr/local/lib/python3.8/dist-packages/setuptools_scm/integration.py"", line 17, in version_keyword. dist.metadata.version = _get_version(config). File ""/usr/local/lib/python3.8/dist-packages/setuptools_scm/__init__.py"", line 148, in _get_version. parsed_version = _do_parse(config). File ""/usr/local/lib/python3.8/dist-packages/setuptools_scm/__init__.py"", line 110, in _do_parse raise LookupError(. LookupError: setuptools-scm was unable to detect version for '/home/ubuntu/code/scanpy'. Make sure you're either building from a fully intact git repository or PyPI tarballs. Most other sources (such as GitHub's tarballs, a git checkout without the .git folder) don't contain the necessary metadata and will not work. . For example, if you're using pip, instead of https://github.com/user/proj/archive/master.zip use git+https://github.com/user/proj.git#egg=proj```. ```. #### Versions. <details>. scanpy. problem is with installation, so scanpy.logging.print_versions(). commit: ef5a8ee57c2aef7778a069a49101a8998718e6d5. python. 3.8.5. pip. 20.0.2 . ubuntu. 20.04. pip list. Package Version Location . ------------------------- -------------------- -----------------------------. analysaurus 0.0.1 /home/ubuntu/code/analysaurus. anndata 0.7.5 . ansi2html 1.5.2 . appdirs 1.4.4 . argon2-cffi 20.1.0 . astroid 2.4.2 . async-generator 1.10 . attrs 20.3.0 . autopep8 1.5.4 . backcall 0.2.0 . biopython 1.78 . black 20.8b1 . bleach 3.2.1 . bokeh 2.2.3 . botocore 1.19.18 . Brotli 1.0.9 . cellforest 0.0.2 /home/ubuntu/code/cellforest . certifi 2019.11.28 . cffi 1.14.3 . chardet 3.0.4 . click 7.1.2 . colorama 0.4.4 . commonmark 0.9.1 . cycler 0.10.0 . dash 1.17.0 . dash-building-blocks 0.1.2 . dash-core-components 1.13.0 . dash-html-components 1.1.1 . dash-renderer 1.8.3 . dash-table 4.11.0 . dataclasses 0.6 . dataforest 0.0.2 /home/ubuntu/code/dataforest . dbus-python 1.2.16 . decorator 4.4.2 . defusedxml 0.6.0 . distro-info 0.23ubuntu1 . entrypo",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1496
https://github.com/scverse/scanpy/issues/1496:3387,deployability,Version,Version,3387,"on_keyword. dist.metadata.version = _get_version(config). File ""/usr/local/lib/python3.8/dist-packages/setuptools_scm/__init__.py"", line 148, in _get_version. parsed_version = _do_parse(config). File ""/usr/local/lib/python3.8/dist-packages/setuptools_scm/__init__.py"", line 110, in _do_parse raise LookupError(. LookupError: setuptools-scm was unable to detect version for '/home/ubuntu/code/scanpy'. Make sure you're either building from a fully intact git repository or PyPI tarballs. Most other sources (such as GitHub's tarballs, a git checkout without the .git folder) don't contain the necessary metadata and will not work. . For example, if you're using pip, instead of https://github.com/user/proj/archive/master.zip use git+https://github.com/user/proj.git#egg=proj```. ```. #### Versions. <details>. scanpy. problem is with installation, so scanpy.logging.print_versions(). commit: ef5a8ee57c2aef7778a069a49101a8998718e6d5. python. 3.8.5. pip. 20.0.2 . ubuntu. 20.04. pip list. Package Version Location . ------------------------- -------------------- -----------------------------. analysaurus 0.0.1 /home/ubuntu/code/analysaurus. anndata 0.7.5 . ansi2html 1.5.2 . appdirs 1.4.4 . argon2-cffi 20.1.0 . astroid 2.4.2 . async-generator 1.10 . attrs 20.3.0 . autopep8 1.5.4 . backcall 0.2.0 . biopython 1.78 . black 20.8b1 . bleach 3.2.1 . bokeh 2.2.3 . botocore 1.19.18 . Brotli 1.0.9 . cellforest 0.0.2 /home/ubuntu/code/cellforest . certifi 2019.11.28 . cffi 1.14.3 . chardet 3.0.4 . click 7.1.2 . colorama 0.4.4 . commonmark 0.9.1 . cycler 0.10.0 . dash 1.17.0 . dash-building-blocks 0.1.2 . dash-core-components 1.13.0 . dash-html-components 1.1.1 . dash-renderer 1.8.3 . dash-table 4.11.0 . dataclasses 0.6 . dataforest 0.0.2 /home/ubuntu/code/dataforest . dbus-python 1.2.16 . decorator 4.4.2 . defusedxml 0.6.0 . distro-info 0.23ubuntu1 . entrypoints 0.3 . fastcore 1.3.5 . flake8 3.8.4 . Flask 1.1.2 . Flask-Compress 1.8.0 . future 0.18.2 . get-version 2.1 . gitdb 4.0.5 . GitPython ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1496
https://github.com/scverse/scanpy/issues/1496:3971,deployability,build,building-blocks,3971,"the necessary metadata and will not work. . For example, if you're using pip, instead of https://github.com/user/proj/archive/master.zip use git+https://github.com/user/proj.git#egg=proj```. ```. #### Versions. <details>. scanpy. problem is with installation, so scanpy.logging.print_versions(). commit: ef5a8ee57c2aef7778a069a49101a8998718e6d5. python. 3.8.5. pip. 20.0.2 . ubuntu. 20.04. pip list. Package Version Location . ------------------------- -------------------- -----------------------------. analysaurus 0.0.1 /home/ubuntu/code/analysaurus. anndata 0.7.5 . ansi2html 1.5.2 . appdirs 1.4.4 . argon2-cffi 20.1.0 . astroid 2.4.2 . async-generator 1.10 . attrs 20.3.0 . autopep8 1.5.4 . backcall 0.2.0 . biopython 1.78 . black 20.8b1 . bleach 3.2.1 . bokeh 2.2.3 . botocore 1.19.18 . Brotli 1.0.9 . cellforest 0.0.2 /home/ubuntu/code/cellforest . certifi 2019.11.28 . cffi 1.14.3 . chardet 3.0.4 . click 7.1.2 . colorama 0.4.4 . commonmark 0.9.1 . cycler 0.10.0 . dash 1.17.0 . dash-building-blocks 0.1.2 . dash-core-components 1.13.0 . dash-html-components 1.1.1 . dash-renderer 1.8.3 . dash-table 4.11.0 . dataclasses 0.6 . dataforest 0.0.2 /home/ubuntu/code/dataforest . dbus-python 1.2.16 . decorator 4.4.2 . defusedxml 0.6.0 . distro-info 0.23ubuntu1 . entrypoints 0.3 . fastcore 1.3.5 . flake8 3.8.4 . Flask 1.1.2 . Flask-Compress 1.8.0 . future 0.18.2 . get-version 2.1 . gitdb 4.0.5 . GitPython 3.1.11 . h5py 3.1.0 . hyperopt 0.1.2 . idna 2.8 . importlib-metadata 2.0.0 . iniconfig 1.1.1 . ipdb 0.13.4 . ipykernel 5.3.4 . ipympl 0.5.8 . ipython 7.19.0 . ipython-genutils 0.2.0 . ipywidgets 7.5.1 . isort 5.6.4 . itsdangerous 1.1.0 . jedi 0.17.2 . Jinja2 2.11.2 . jmespath 0.10.0 . joblib 0.17.0 . json5 0.9.5 . jsonschema 3.2.0 . jupyter-client 6.1.7 . jupyter-core 4.6.3 . jupyter-dash 0.3.1 . jupyter-lsp 0.9.2 . jupyterlab 2.2.9 . jupyterlab-code-formatter 1.3.6 . jupyterlab-git 0.23.1 . jupyterlab-latex 2.0.0 . jupyterlab-pygments 0.1.2 . jupyterlab-server 1.2.0 . jupyterlab-s",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1496
https://github.com/scverse/scanpy/issues/1496:4353,deployability,version,version,4353,ntu. 20.04. pip list. Package Version Location . ------------------------- -------------------- -----------------------------. analysaurus 0.0.1 /home/ubuntu/code/analysaurus. anndata 0.7.5 . ansi2html 1.5.2 . appdirs 1.4.4 . argon2-cffi 20.1.0 . astroid 2.4.2 . async-generator 1.10 . attrs 20.3.0 . autopep8 1.5.4 . backcall 0.2.0 . biopython 1.78 . black 20.8b1 . bleach 3.2.1 . bokeh 2.2.3 . botocore 1.19.18 . Brotli 1.0.9 . cellforest 0.0.2 /home/ubuntu/code/cellforest . certifi 2019.11.28 . cffi 1.14.3 . chardet 3.0.4 . click 7.1.2 . colorama 0.4.4 . commonmark 0.9.1 . cycler 0.10.0 . dash 1.17.0 . dash-building-blocks 0.1.2 . dash-core-components 1.13.0 . dash-html-components 1.1.1 . dash-renderer 1.8.3 . dash-table 4.11.0 . dataclasses 0.6 . dataforest 0.0.2 /home/ubuntu/code/dataforest . dbus-python 1.2.16 . decorator 4.4.2 . defusedxml 0.6.0 . distro-info 0.23ubuntu1 . entrypoints 0.3 . fastcore 1.3.5 . flake8 3.8.4 . Flask 1.1.2 . Flask-Compress 1.8.0 . future 0.18.2 . get-version 2.1 . gitdb 4.0.5 . GitPython 3.1.11 . h5py 3.1.0 . hyperopt 0.1.2 . idna 2.8 . importlib-metadata 2.0.0 . iniconfig 1.1.1 . ipdb 0.13.4 . ipykernel 5.3.4 . ipympl 0.5.8 . ipython 7.19.0 . ipython-genutils 0.2.0 . ipywidgets 7.5.1 . isort 5.6.4 . itsdangerous 1.1.0 . jedi 0.17.2 . Jinja2 2.11.2 . jmespath 0.10.0 . joblib 0.17.0 . json5 0.9.5 . jsonschema 3.2.0 . jupyter-client 6.1.7 . jupyter-core 4.6.3 . jupyter-dash 0.3.1 . jupyter-lsp 0.9.2 . jupyterlab 2.2.9 . jupyterlab-code-formatter 1.3.6 . jupyterlab-git 0.23.1 . jupyterlab-latex 2.0.0 . jupyterlab-pygments 0.1.2 . jupyterlab-server 1.2.0 . jupyterlab-sql 0.3.3 . jupyterlab-templates 0.2.5 . jupytext 1.6.0 . kiwisolver 1.3.1 . lazy-object-proxy 1.4.3 . legacy-api-wrap 1.2 . llvmlite 0.34.0 . markdown-it-py 0.5.6 . MarkupSafe 1.1.1 . matplotlib 3.3.3 . mccabe 0.6.1 . mistune 0.8.4 . mypy-extensions 0.4.3 . natsort 7.0.1 . nbclient 0.5.1 . nbconvert 6.0.7 . nbdime 2.1.0 . nbformat 5.0.8 . nbresuse 0.3.6 . nest-asyncio 1.4.3 .,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1496
https://github.com/scverse/scanpy/issues/1496:5088,deployability,api,api-wrap,5088,0 . dataclasses 0.6 . dataforest 0.0.2 /home/ubuntu/code/dataforest . dbus-python 1.2.16 . decorator 4.4.2 . defusedxml 0.6.0 . distro-info 0.23ubuntu1 . entrypoints 0.3 . fastcore 1.3.5 . flake8 3.8.4 . Flask 1.1.2 . Flask-Compress 1.8.0 . future 0.18.2 . get-version 2.1 . gitdb 4.0.5 . GitPython 3.1.11 . h5py 3.1.0 . hyperopt 0.1.2 . idna 2.8 . importlib-metadata 2.0.0 . iniconfig 1.1.1 . ipdb 0.13.4 . ipykernel 5.3.4 . ipympl 0.5.8 . ipython 7.19.0 . ipython-genutils 0.2.0 . ipywidgets 7.5.1 . isort 5.6.4 . itsdangerous 1.1.0 . jedi 0.17.2 . Jinja2 2.11.2 . jmespath 0.10.0 . joblib 0.17.0 . json5 0.9.5 . jsonschema 3.2.0 . jupyter-client 6.1.7 . jupyter-core 4.6.3 . jupyter-dash 0.3.1 . jupyter-lsp 0.9.2 . jupyterlab 2.2.9 . jupyterlab-code-formatter 1.3.6 . jupyterlab-git 0.23.1 . jupyterlab-latex 2.0.0 . jupyterlab-pygments 0.1.2 . jupyterlab-server 1.2.0 . jupyterlab-sql 0.3.3 . jupyterlab-templates 0.2.5 . jupytext 1.6.0 . kiwisolver 1.3.1 . lazy-object-proxy 1.4.3 . legacy-api-wrap 1.2 . llvmlite 0.34.0 . markdown-it-py 0.5.6 . MarkupSafe 1.1.1 . matplotlib 3.3.3 . mccabe 0.6.1 . mistune 0.8.4 . mypy-extensions 0.4.3 . natsort 7.0.1 . nbclient 0.5.1 . nbconvert 6.0.7 . nbdime 2.1.0 . nbformat 5.0.8 . nbresuse 0.3.6 . nest-asyncio 1.4.3 . networkx 2.5 . notebook 6.1.5 . numba 0.51.2 . numexpr 2.7.1 . numpy 1.19.4 . packaging 20.4 . pandas 1.1.4 . pandocfilters 1.4.3 . parso 0.7.1 . path 15.0.0 . pathspec 0.8.1 . pathtools 0.1.2 . patsy 0.5.1 . peepdis 0.1.13 . pexpect 4.8.0 . pickleshare 0.7.5 . Pillow 8.0.1 . pip 20.0.2 . plotly 4.12.0 . pluggy 0.13.1 . prometheus-client 0.8.0 . prompt-toolkit 3.0.8 . psutil 5.7.3 . ptvsd 4.3.2 . ptyprocess 0.6.0 . py 1.9.0 . pycodestyle 2.6.0 . pycparser 2.20 . pydocstyle 5.1.1 . pyflakes 2.2.0 . Pygments 2.7.2 . PyGObject 3.36.0 . pylint 2.6.0 . pymongo 3.11.0 . pyparsing 2.4.7 . pyrsistent 0.17.3 . pytest 6.1.2 . python-apt 2.0.0+ubuntu0.20.4.1 . python-dateutil 2.8.1 . python-debian 0.1.36ubuntu1 . python-jsonrpc-server ,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1496
https://github.com/scverse/scanpy/issues/1496:6877,deployability,upgrad,upgrades,6877,ite 0.34.0 . markdown-it-py 0.5.6 . MarkupSafe 1.1.1 . matplotlib 3.3.3 . mccabe 0.6.1 . mistune 0.8.4 . mypy-extensions 0.4.3 . natsort 7.0.1 . nbclient 0.5.1 . nbconvert 6.0.7 . nbdime 2.1.0 . nbformat 5.0.8 . nbresuse 0.3.6 . nest-asyncio 1.4.3 . networkx 2.5 . notebook 6.1.5 . numba 0.51.2 . numexpr 2.7.1 . numpy 1.19.4 . packaging 20.4 . pandas 1.1.4 . pandocfilters 1.4.3 . parso 0.7.1 . path 15.0.0 . pathspec 0.8.1 . pathtools 0.1.2 . patsy 0.5.1 . peepdis 0.1.13 . pexpect 4.8.0 . pickleshare 0.7.5 . Pillow 8.0.1 . pip 20.0.2 . plotly 4.12.0 . pluggy 0.13.1 . prometheus-client 0.8.0 . prompt-toolkit 3.0.8 . psutil 5.7.3 . ptvsd 4.3.2 . ptyprocess 0.6.0 . py 1.9.0 . pycodestyle 2.6.0 . pycparser 2.20 . pydocstyle 5.1.1 . pyflakes 2.2.0 . Pygments 2.7.2 . PyGObject 3.36.0 . pylint 2.6.0 . pymongo 3.11.0 . pyparsing 2.4.7 . pyrsistent 0.17.3 . pytest 6.1.2 . python-apt 2.0.0+ubuntu0.20.4.1 . python-dateutil 2.8.1 . python-debian 0.1.36ubuntu1 . python-jsonrpc-server 0.4.0 . python-language-server 0.36.1 . pytoml 0.1.21 . pytz 2020.4 . PyYAML 5.3.1 . pyzmq 20.0.0 . regex 2020.11.13 . requests 2.22.0 . requests-unixsocket 0.2.0 . retrying 1.3.3 . rich 9.2.0 . rope 0.18.0 . scikit-learn 0.23.2 . scikit-misc 0.1.3 . scipy 1.5.4 . scriptedforms 0.10.1 . scvi-tools 0.7.1 . seaborn 0.11.0 . Send2Trash 1.5.0 . setuptools 50.3.2 . setuptools-scm 4.1.2 . sinfo 0.3.1 . six 1.14.0 . smmap 3.0.4 . snowballstemmer 2.0.0 . SQLAlchemy 1.3.20 . statsmodels 0.12.1 . stdlib-list 0.7.0 . tables 3.6.1 . termcolor 1.1.0 . terminado 0.9.1 . testpath 0.4.4 . threadpoolctl 2.1.0 . toml 0.10.2 . torch 1.7.0 . tornado 6.1 . tqdm 4.51.0 . traitlets 5.0.5 . typed-ast 1.4.1 . typeguard 2.10.0 . typing-extensions 3.7.4.3 . ujson 4.0.1 . umap-learn 0.4.6 . unattended-upgrades 0.1 . urllib3 1.25.8 . watchdog 0.10.3 . wcwidth 0.2.5 . webencodings 0.5.1 . Werkzeug 1.0.1 . wheel 0.35.1 . widgetsnbextension 3.5.1 . wrapt 1.12.1 . xeus-python 0.8.3 . xlrd 1.2.0 . yapf 0.30.0 . zipp 3.4.0. </details>.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1496
https://github.com/scverse/scanpy/issues/1496:1635,energy efficiency,core,core,1635,"ith `setuptools_scm` itself or the combination of my environment and `pyproject.toml`. Any ideas? ### Minimal code sample (that we can copy&paste without having any data). ```bash. pip install -e . ```. ```pytb. File ""/tmp/tmp7fu14tjf"", line 280, in <module>. main(). File ""/tmp/tmp7fu14tjf"", line 263, in main. json_out['return_val'] = hook(**hook_input['kwargs']). File ""/tmp/tmp7fu14tjf"", line 133, in prepare_metadata_for_build_wheel. return hook(metadata_directory, config_settings). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/build_meta.py"", line 161, in prepare_metadata_for_build_wheel self.run_setup(). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/build_meta.py"", line 145, in run_setup. exec(compile(code, __file__, 'exec'), locals()) File ""setup.py"", line 17, in <module>. setup(. File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/__init__.py"", line 153, in setup. return distutils.core.setup(**attrs). File ""/usr/lib/python3.8/distutils/core.py"", line 108, in setup. _setup_distribution = dist = klass(attrs). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 423, in __init__. _Distribution.__init__(self, {. File ""/usr/lib/python3.8/distutils/dist.py"", line 292, in __init__. self.finalize_options() File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 695, in finalize_options. ep(self). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 702, in _finalize_setup_keywords. ep.load()(self, ep.name, value). File ""/usr/local/lib/python3.8/dist-packages/setuptools_scm/integration.py"", line 17, in version_keyword. dist.metadata.version = _get_version(config). File ""/usr/local/lib/python3.8/dist-packages/setuptools_scm/__init__.py"", line 148, in _get_version. parsed_version = _do_parse(config). File ""/usr/local/lib/python3.8/dist-packages/setupt",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1496
https://github.com/scverse/scanpy/issues/1496:1691,energy efficiency,core,core,1691,"ironment and `pyproject.toml`. Any ideas? ### Minimal code sample (that we can copy&paste without having any data). ```bash. pip install -e . ```. ```pytb. File ""/tmp/tmp7fu14tjf"", line 280, in <module>. main(). File ""/tmp/tmp7fu14tjf"", line 263, in main. json_out['return_val'] = hook(**hook_input['kwargs']). File ""/tmp/tmp7fu14tjf"", line 133, in prepare_metadata_for_build_wheel. return hook(metadata_directory, config_settings). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/build_meta.py"", line 161, in prepare_metadata_for_build_wheel self.run_setup(). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/build_meta.py"", line 145, in run_setup. exec(compile(code, __file__, 'exec'), locals()) File ""setup.py"", line 17, in <module>. setup(. File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/__init__.py"", line 153, in setup. return distutils.core.setup(**attrs). File ""/usr/lib/python3.8/distutils/core.py"", line 108, in setup. _setup_distribution = dist = klass(attrs). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 423, in __init__. _Distribution.__init__(self, {. File ""/usr/lib/python3.8/distutils/dist.py"", line 292, in __init__. self.finalize_options() File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 695, in finalize_options. ep(self). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 702, in _finalize_setup_keywords. ep.load()(self, ep.name, value). File ""/usr/local/lib/python3.8/dist-packages/setuptools_scm/integration.py"", line 17, in version_keyword. dist.metadata.version = _get_version(config). File ""/usr/local/lib/python3.8/dist-packages/setuptools_scm/__init__.py"", line 148, in _get_version. parsed_version = _do_parse(config). File ""/usr/local/lib/python3.8/dist-packages/setuptools_scm/__init__.py"", line 110, in _do_parse raise Look",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1496
https://github.com/scverse/scanpy/issues/1496:2267,energy efficiency,load,load,2267,"self.run_setup(). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/build_meta.py"", line 145, in run_setup. exec(compile(code, __file__, 'exec'), locals()) File ""setup.py"", line 17, in <module>. setup(. File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/__init__.py"", line 153, in setup. return distutils.core.setup(**attrs). File ""/usr/lib/python3.8/distutils/core.py"", line 108, in setup. _setup_distribution = dist = klass(attrs). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 423, in __init__. _Distribution.__init__(self, {. File ""/usr/lib/python3.8/distutils/dist.py"", line 292, in __init__. self.finalize_options() File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 695, in finalize_options. ep(self). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 702, in _finalize_setup_keywords. ep.load()(self, ep.name, value). File ""/usr/local/lib/python3.8/dist-packages/setuptools_scm/integration.py"", line 17, in version_keyword. dist.metadata.version = _get_version(config). File ""/usr/local/lib/python3.8/dist-packages/setuptools_scm/__init__.py"", line 148, in _get_version. parsed_version = _do_parse(config). File ""/usr/local/lib/python3.8/dist-packages/setuptools_scm/__init__.py"", line 110, in _do_parse raise LookupError(. LookupError: setuptools-scm was unable to detect version for '/home/ubuntu/code/scanpy'. Make sure you're either building from a fully intact git repository or PyPI tarballs. Most other sources (such as GitHub's tarballs, a git checkout without the .git folder) don't contain the necessary metadata and will not work. . For example, if you're using pip, instead of https://github.com/user/proj/archive/master.zip use git+https://github.com/user/proj.git#egg=proj```. ```. #### Versions. <details>. scanpy. problem is with installation, so scanpy.logging.print_versio",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1496
https://github.com/scverse/scanpy/issues/1496:4000,energy efficiency,core,core-components,4000,"ll not work. . For example, if you're using pip, instead of https://github.com/user/proj/archive/master.zip use git+https://github.com/user/proj.git#egg=proj```. ```. #### Versions. <details>. scanpy. problem is with installation, so scanpy.logging.print_versions(). commit: ef5a8ee57c2aef7778a069a49101a8998718e6d5. python. 3.8.5. pip. 20.0.2 . ubuntu. 20.04. pip list. Package Version Location . ------------------------- -------------------- -----------------------------. analysaurus 0.0.1 /home/ubuntu/code/analysaurus. anndata 0.7.5 . ansi2html 1.5.2 . appdirs 1.4.4 . argon2-cffi 20.1.0 . astroid 2.4.2 . async-generator 1.10 . attrs 20.3.0 . autopep8 1.5.4 . backcall 0.2.0 . biopython 1.78 . black 20.8b1 . bleach 3.2.1 . bokeh 2.2.3 . botocore 1.19.18 . Brotli 1.0.9 . cellforest 0.0.2 /home/ubuntu/code/cellforest . certifi 2019.11.28 . cffi 1.14.3 . chardet 3.0.4 . click 7.1.2 . colorama 0.4.4 . commonmark 0.9.1 . cycler 0.10.0 . dash 1.17.0 . dash-building-blocks 0.1.2 . dash-core-components 1.13.0 . dash-html-components 1.1.1 . dash-renderer 1.8.3 . dash-table 4.11.0 . dataclasses 0.6 . dataforest 0.0.2 /home/ubuntu/code/dataforest . dbus-python 1.2.16 . decorator 4.4.2 . defusedxml 0.6.0 . distro-info 0.23ubuntu1 . entrypoints 0.3 . fastcore 1.3.5 . flake8 3.8.4 . Flask 1.1.2 . Flask-Compress 1.8.0 . future 0.18.2 . get-version 2.1 . gitdb 4.0.5 . GitPython 3.1.11 . h5py 3.1.0 . hyperopt 0.1.2 . idna 2.8 . importlib-metadata 2.0.0 . iniconfig 1.1.1 . ipdb 0.13.4 . ipykernel 5.3.4 . ipympl 0.5.8 . ipython 7.19.0 . ipython-genutils 0.2.0 . ipywidgets 7.5.1 . isort 5.6.4 . itsdangerous 1.1.0 . jedi 0.17.2 . Jinja2 2.11.2 . jmespath 0.10.0 . joblib 0.17.0 . json5 0.9.5 . jsonschema 3.2.0 . jupyter-client 6.1.7 . jupyter-core 4.6.3 . jupyter-dash 0.3.1 . jupyter-lsp 0.9.2 . jupyterlab 2.2.9 . jupyterlab-code-formatter 1.3.6 . jupyterlab-git 0.23.1 . jupyterlab-latex 2.0.0 . jupyterlab-pygments 0.1.2 . jupyterlab-server 1.2.0 . jupyterlab-sql 0.3.3 . jupyterlab-templat",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1496
https://github.com/scverse/scanpy/issues/1496:4757,energy efficiency,core,core,4757,re 1.19.18 . Brotli 1.0.9 . cellforest 0.0.2 /home/ubuntu/code/cellforest . certifi 2019.11.28 . cffi 1.14.3 . chardet 3.0.4 . click 7.1.2 . colorama 0.4.4 . commonmark 0.9.1 . cycler 0.10.0 . dash 1.17.0 . dash-building-blocks 0.1.2 . dash-core-components 1.13.0 . dash-html-components 1.1.1 . dash-renderer 1.8.3 . dash-table 4.11.0 . dataclasses 0.6 . dataforest 0.0.2 /home/ubuntu/code/dataforest . dbus-python 1.2.16 . decorator 4.4.2 . defusedxml 0.6.0 . distro-info 0.23ubuntu1 . entrypoints 0.3 . fastcore 1.3.5 . flake8 3.8.4 . Flask 1.1.2 . Flask-Compress 1.8.0 . future 0.18.2 . get-version 2.1 . gitdb 4.0.5 . GitPython 3.1.11 . h5py 3.1.0 . hyperopt 0.1.2 . idna 2.8 . importlib-metadata 2.0.0 . iniconfig 1.1.1 . ipdb 0.13.4 . ipykernel 5.3.4 . ipympl 0.5.8 . ipython 7.19.0 . ipython-genutils 0.2.0 . ipywidgets 7.5.1 . isort 5.6.4 . itsdangerous 1.1.0 . jedi 0.17.2 . Jinja2 2.11.2 . jmespath 0.10.0 . joblib 0.17.0 . json5 0.9.5 . jsonschema 3.2.0 . jupyter-client 6.1.7 . jupyter-core 4.6.3 . jupyter-dash 0.3.1 . jupyter-lsp 0.9.2 . jupyterlab 2.2.9 . jupyterlab-code-formatter 1.3.6 . jupyterlab-git 0.23.1 . jupyterlab-latex 2.0.0 . jupyterlab-pygments 0.1.2 . jupyterlab-server 1.2.0 . jupyterlab-sql 0.3.3 . jupyterlab-templates 0.2.5 . jupytext 1.6.0 . kiwisolver 1.3.1 . lazy-object-proxy 1.4.3 . legacy-api-wrap 1.2 . llvmlite 0.34.0 . markdown-it-py 0.5.6 . MarkupSafe 1.1.1 . matplotlib 3.3.3 . mccabe 0.6.1 . mistune 0.8.4 . mypy-extensions 0.4.3 . natsort 7.0.1 . nbclient 0.5.1 . nbconvert 6.0.7 . nbdime 2.1.0 . nbformat 5.0.8 . nbresuse 0.3.6 . nest-asyncio 1.4.3 . networkx 2.5 . notebook 6.1.5 . numba 0.51.2 . numexpr 2.7.1 . numpy 1.19.4 . packaging 20.4 . pandas 1.1.4 . pandocfilters 1.4.3 . parso 0.7.1 . path 15.0.0 . pathspec 0.8.1 . pathtools 0.1.2 . patsy 0.5.1 . peepdis 0.1.13 . pexpect 4.8.0 . pickleshare 0.7.5 . Pillow 8.0.1 . pip 20.0.2 . plotly 4.12.0 . pluggy 0.13.1 . prometheus-client 0.8.0 . prompt-toolkit 3.0.8 . psutil 5.7.3 . ptvsd 4.3.2 . p,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1496
https://github.com/scverse/scanpy/issues/1496:75,integrability,version,version,75,"`pip install -e .` raises LookupError: setuptools-scm was unable to detect version for '/home/ubuntu/code/scanpy'.; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. setuptools-scm can't find the package version when running `pip install -e` or `pip install .`. I stepped through `scanpy/_metadata.py`, and it does appear to be able to get `__version__` via `setuptools_scm.get_version` as opposed to using `._compat`. It seems like it may either be an issue with `setuptools_scm` itself or the combination of my environment and `pyproject.toml`. Any ideas? ### Minimal code sample (that we can copy&paste without having any data). ```bash. pip install -e . ```. ```pytb. File ""/tmp/tmp7fu14tjf"", line 280, in <module>. main(). File ""/tmp/tmp7fu14tjf"", line 263, in main. json_out['return_val'] = hook(**hook_input['kwargs']). File ""/tmp/tmp7fu14tjf"", line 133, in prepare_metadata_for_build_wheel. return hook(metadata_directory, config_settings). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/build_meta.py"", line 161, in prepare_metadata_for_build_wheel self.run_setup(). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/build_meta.py"", line 145, in run_setup. exec(compile(code, __file__, 'exec'), locals()) File ""setup.py"", line 17, in <module>. setup(. File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/__init__.py"", line 153, in setup. return distutils.core.setup(**attrs). File ""/usr/lib/python3.8/distutils/core.py"", line 108, in setup. _setup_distribution = dist = klass(attrs). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 423, in __init__. _Distribution.__init__(self, {. File ""/usr/lib/python3.8/distutils/dist.py"", line 292, in __init__. self.finalize_options(",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1496
https://github.com/scverse/scanpy/issues/1496:237,integrability,version,version,237,"`pip install -e .` raises LookupError: setuptools-scm was unable to detect version for '/home/ubuntu/code/scanpy'.; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. setuptools-scm can't find the package version when running `pip install -e` or `pip install .`. I stepped through `scanpy/_metadata.py`, and it does appear to be able to get `__version__` via `setuptools_scm.get_version` as opposed to using `._compat`. It seems like it may either be an issue with `setuptools_scm` itself or the combination of my environment and `pyproject.toml`. Any ideas? ### Minimal code sample (that we can copy&paste without having any data). ```bash. pip install -e . ```. ```pytb. File ""/tmp/tmp7fu14tjf"", line 280, in <module>. main(). File ""/tmp/tmp7fu14tjf"", line 263, in main. json_out['return_val'] = hook(**hook_input['kwargs']). File ""/tmp/tmp7fu14tjf"", line 133, in prepare_metadata_for_build_wheel. return hook(metadata_directory, config_settings). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/build_meta.py"", line 161, in prepare_metadata_for_build_wheel self.run_setup(). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/build_meta.py"", line 145, in run_setup. exec(compile(code, __file__, 'exec'), locals()) File ""setup.py"", line 17, in <module>. setup(. File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/__init__.py"", line 153, in setup. return distutils.core.setup(**attrs). File ""/usr/lib/python3.8/distutils/core.py"", line 108, in setup. _setup_distribution = dist = klass(attrs). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 423, in __init__. _Distribution.__init__(self, {. File ""/usr/lib/python3.8/distutils/dist.py"", line 292, in __init__. self.finalize_options(",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1496
https://github.com/scverse/scanpy/issues/1496:381,integrability,version,version,381,"`pip install -e .` raises LookupError: setuptools-scm was unable to detect version for '/home/ubuntu/code/scanpy'.; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. setuptools-scm can't find the package version when running `pip install -e` or `pip install .`. I stepped through `scanpy/_metadata.py`, and it does appear to be able to get `__version__` via `setuptools_scm.get_version` as opposed to using `._compat`. It seems like it may either be an issue with `setuptools_scm` itself or the combination of my environment and `pyproject.toml`. Any ideas? ### Minimal code sample (that we can copy&paste without having any data). ```bash. pip install -e . ```. ```pytb. File ""/tmp/tmp7fu14tjf"", line 280, in <module>. main(). File ""/tmp/tmp7fu14tjf"", line 263, in main. json_out['return_val'] = hook(**hook_input['kwargs']). File ""/tmp/tmp7fu14tjf"", line 133, in prepare_metadata_for_build_wheel. return hook(metadata_directory, config_settings). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/build_meta.py"", line 161, in prepare_metadata_for_build_wheel self.run_setup(). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/build_meta.py"", line 145, in run_setup. exec(compile(code, __file__, 'exec'), locals()) File ""setup.py"", line 17, in <module>. setup(. File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/__init__.py"", line 153, in setup. return distutils.core.setup(**attrs). File ""/usr/lib/python3.8/distutils/core.py"", line 108, in setup. _setup_distribution = dist = klass(attrs). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 423, in __init__. _Distribution.__init__(self, {. File ""/usr/lib/python3.8/distutils/dist.py"", line 292, in __init__. self.finalize_options(",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1496
https://github.com/scverse/scanpy/issues/1496:2357,integrability,integr,integration,2357,"ools/build_meta.py"", line 145, in run_setup. exec(compile(code, __file__, 'exec'), locals()) File ""setup.py"", line 17, in <module>. setup(. File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/__init__.py"", line 153, in setup. return distutils.core.setup(**attrs). File ""/usr/lib/python3.8/distutils/core.py"", line 108, in setup. _setup_distribution = dist = klass(attrs). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 423, in __init__. _Distribution.__init__(self, {. File ""/usr/lib/python3.8/distutils/dist.py"", line 292, in __init__. self.finalize_options() File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 695, in finalize_options. ep(self). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 702, in _finalize_setup_keywords. ep.load()(self, ep.name, value). File ""/usr/local/lib/python3.8/dist-packages/setuptools_scm/integration.py"", line 17, in version_keyword. dist.metadata.version = _get_version(config). File ""/usr/local/lib/python3.8/dist-packages/setuptools_scm/__init__.py"", line 148, in _get_version. parsed_version = _do_parse(config). File ""/usr/local/lib/python3.8/dist-packages/setuptools_scm/__init__.py"", line 110, in _do_parse raise LookupError(. LookupError: setuptools-scm was unable to detect version for '/home/ubuntu/code/scanpy'. Make sure you're either building from a fully intact git repository or PyPI tarballs. Most other sources (such as GitHub's tarballs, a git checkout without the .git folder) don't contain the necessary metadata and will not work. . For example, if you're using pip, instead of https://github.com/user/proj/archive/master.zip use git+https://github.com/user/proj.git#egg=proj```. ```. #### Versions. <details>. scanpy. problem is with installation, so scanpy.logging.print_versions(). commit: ef5a8ee57c2aef7778a069a49101a8998718e6d5. python. 3.8.5. pip. 20.0.2 . ubuntu. 2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1496
https://github.com/scverse/scanpy/issues/1496:2417,integrability,version,version,2417,"code, __file__, 'exec'), locals()) File ""setup.py"", line 17, in <module>. setup(. File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/__init__.py"", line 153, in setup. return distutils.core.setup(**attrs). File ""/usr/lib/python3.8/distutils/core.py"", line 108, in setup. _setup_distribution = dist = klass(attrs). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 423, in __init__. _Distribution.__init__(self, {. File ""/usr/lib/python3.8/distutils/dist.py"", line 292, in __init__. self.finalize_options() File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 695, in finalize_options. ep(self). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 702, in _finalize_setup_keywords. ep.load()(self, ep.name, value). File ""/usr/local/lib/python3.8/dist-packages/setuptools_scm/integration.py"", line 17, in version_keyword. dist.metadata.version = _get_version(config). File ""/usr/local/lib/python3.8/dist-packages/setuptools_scm/__init__.py"", line 148, in _get_version. parsed_version = _do_parse(config). File ""/usr/local/lib/python3.8/dist-packages/setuptools_scm/__init__.py"", line 110, in _do_parse raise LookupError(. LookupError: setuptools-scm was unable to detect version for '/home/ubuntu/code/scanpy'. Make sure you're either building from a fully intact git repository or PyPI tarballs. Most other sources (such as GitHub's tarballs, a git checkout without the .git folder) don't contain the necessary metadata and will not work. . For example, if you're using pip, instead of https://github.com/user/proj/archive/master.zip use git+https://github.com/user/proj.git#egg=proj```. ```. #### Versions. <details>. scanpy. problem is with installation, so scanpy.logging.print_versions(). commit: ef5a8ee57c2aef7778a069a49101a8998718e6d5. python. 3.8.5. pip. 20.0.2 . ubuntu. 20.04. pip list. Package Version Location . ---------------",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1496
https://github.com/scverse/scanpy/issues/1496:2752,integrability,version,version,2752,"attrs). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 423, in __init__. _Distribution.__init__(self, {. File ""/usr/lib/python3.8/distutils/dist.py"", line 292, in __init__. self.finalize_options() File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 695, in finalize_options. ep(self). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 702, in _finalize_setup_keywords. ep.load()(self, ep.name, value). File ""/usr/local/lib/python3.8/dist-packages/setuptools_scm/integration.py"", line 17, in version_keyword. dist.metadata.version = _get_version(config). File ""/usr/local/lib/python3.8/dist-packages/setuptools_scm/__init__.py"", line 148, in _get_version. parsed_version = _do_parse(config). File ""/usr/local/lib/python3.8/dist-packages/setuptools_scm/__init__.py"", line 110, in _do_parse raise LookupError(. LookupError: setuptools-scm was unable to detect version for '/home/ubuntu/code/scanpy'. Make sure you're either building from a fully intact git repository or PyPI tarballs. Most other sources (such as GitHub's tarballs, a git checkout without the .git folder) don't contain the necessary metadata and will not work. . For example, if you're using pip, instead of https://github.com/user/proj/archive/master.zip use git+https://github.com/user/proj.git#egg=proj```. ```. #### Versions. <details>. scanpy. problem is with installation, so scanpy.logging.print_versions(). commit: ef5a8ee57c2aef7778a069a49101a8998718e6d5. python. 3.8.5. pip. 20.0.2 . ubuntu. 20.04. pip list. Package Version Location . ------------------------- -------------------- -----------------------------. analysaurus 0.0.1 /home/ubuntu/code/analysaurus. anndata 0.7.5 . ansi2html 1.5.2 . appdirs 1.4.4 . argon2-cffi 20.1.0 . astroid 2.4.2 . async-generator 1.10 . attrs 20.3.0 . autopep8 1.5.4 . backcall 0.2.0 . biopython 1.78 . black 20.8b1 . bleach 3.2.1 . bokeh 2.2.3 . bot",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1496
https://github.com/scverse/scanpy/issues/1496:2849,integrability,repositor,repository,2849," line 423, in __init__. _Distribution.__init__(self, {. File ""/usr/lib/python3.8/distutils/dist.py"", line 292, in __init__. self.finalize_options() File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 695, in finalize_options. ep(self). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 702, in _finalize_setup_keywords. ep.load()(self, ep.name, value). File ""/usr/local/lib/python3.8/dist-packages/setuptools_scm/integration.py"", line 17, in version_keyword. dist.metadata.version = _get_version(config). File ""/usr/local/lib/python3.8/dist-packages/setuptools_scm/__init__.py"", line 148, in _get_version. parsed_version = _do_parse(config). File ""/usr/local/lib/python3.8/dist-packages/setuptools_scm/__init__.py"", line 110, in _do_parse raise LookupError(. LookupError: setuptools-scm was unable to detect version for '/home/ubuntu/code/scanpy'. Make sure you're either building from a fully intact git repository or PyPI tarballs. Most other sources (such as GitHub's tarballs, a git checkout without the .git folder) don't contain the necessary metadata and will not work. . For example, if you're using pip, instead of https://github.com/user/proj/archive/master.zip use git+https://github.com/user/proj.git#egg=proj```. ```. #### Versions. <details>. scanpy. problem is with installation, so scanpy.logging.print_versions(). commit: ef5a8ee57c2aef7778a069a49101a8998718e6d5. python. 3.8.5. pip. 20.0.2 . ubuntu. 20.04. pip list. Package Version Location . ------------------------- -------------------- -----------------------------. analysaurus 0.0.1 /home/ubuntu/code/analysaurus. anndata 0.7.5 . ansi2html 1.5.2 . appdirs 1.4.4 . argon2-cffi 20.1.0 . astroid 2.4.2 . async-generator 1.10 . attrs 20.3.0 . autopep8 1.5.4 . backcall 0.2.0 . biopython 1.78 . black 20.8b1 . bleach 3.2.1 . bokeh 2.2.3 . botocore 1.19.18 . Brotli 1.0.9 . cellforest 0.0.2 /home/ubuntu/code/cellforest . certifi 2019.11.28 ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1496
https://github.com/scverse/scanpy/issues/1496:3180,integrability,Version,Versions,3180,"on3.8/site-packages/setuptools/dist.py"", line 702, in _finalize_setup_keywords. ep.load()(self, ep.name, value). File ""/usr/local/lib/python3.8/dist-packages/setuptools_scm/integration.py"", line 17, in version_keyword. dist.metadata.version = _get_version(config). File ""/usr/local/lib/python3.8/dist-packages/setuptools_scm/__init__.py"", line 148, in _get_version. parsed_version = _do_parse(config). File ""/usr/local/lib/python3.8/dist-packages/setuptools_scm/__init__.py"", line 110, in _do_parse raise LookupError(. LookupError: setuptools-scm was unable to detect version for '/home/ubuntu/code/scanpy'. Make sure you're either building from a fully intact git repository or PyPI tarballs. Most other sources (such as GitHub's tarballs, a git checkout without the .git folder) don't contain the necessary metadata and will not work. . For example, if you're using pip, instead of https://github.com/user/proj/archive/master.zip use git+https://github.com/user/proj.git#egg=proj```. ```. #### Versions. <details>. scanpy. problem is with installation, so scanpy.logging.print_versions(). commit: ef5a8ee57c2aef7778a069a49101a8998718e6d5. python. 3.8.5. pip. 20.0.2 . ubuntu. 20.04. pip list. Package Version Location . ------------------------- -------------------- -----------------------------. analysaurus 0.0.1 /home/ubuntu/code/analysaurus. anndata 0.7.5 . ansi2html 1.5.2 . appdirs 1.4.4 . argon2-cffi 20.1.0 . astroid 2.4.2 . async-generator 1.10 . attrs 20.3.0 . autopep8 1.5.4 . backcall 0.2.0 . biopython 1.78 . black 20.8b1 . bleach 3.2.1 . bokeh 2.2.3 . botocore 1.19.18 . Brotli 1.0.9 . cellforest 0.0.2 /home/ubuntu/code/cellforest . certifi 2019.11.28 . cffi 1.14.3 . chardet 3.0.4 . click 7.1.2 . colorama 0.4.4 . commonmark 0.9.1 . cycler 0.10.0 . dash 1.17.0 . dash-building-blocks 0.1.2 . dash-core-components 1.13.0 . dash-html-components 1.1.1 . dash-renderer 1.8.3 . dash-table 4.11.0 . dataclasses 0.6 . dataforest 0.0.2 /home/ubuntu/code/dataforest . dbus-python 1.2.16 . d",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1496
https://github.com/scverse/scanpy/issues/1496:3387,integrability,Version,Version,3387,"on_keyword. dist.metadata.version = _get_version(config). File ""/usr/local/lib/python3.8/dist-packages/setuptools_scm/__init__.py"", line 148, in _get_version. parsed_version = _do_parse(config). File ""/usr/local/lib/python3.8/dist-packages/setuptools_scm/__init__.py"", line 110, in _do_parse raise LookupError(. LookupError: setuptools-scm was unable to detect version for '/home/ubuntu/code/scanpy'. Make sure you're either building from a fully intact git repository or PyPI tarballs. Most other sources (such as GitHub's tarballs, a git checkout without the .git folder) don't contain the necessary metadata and will not work. . For example, if you're using pip, instead of https://github.com/user/proj/archive/master.zip use git+https://github.com/user/proj.git#egg=proj```. ```. #### Versions. <details>. scanpy. problem is with installation, so scanpy.logging.print_versions(). commit: ef5a8ee57c2aef7778a069a49101a8998718e6d5. python. 3.8.5. pip. 20.0.2 . ubuntu. 20.04. pip list. Package Version Location . ------------------------- -------------------- -----------------------------. analysaurus 0.0.1 /home/ubuntu/code/analysaurus. anndata 0.7.5 . ansi2html 1.5.2 . appdirs 1.4.4 . argon2-cffi 20.1.0 . astroid 2.4.2 . async-generator 1.10 . attrs 20.3.0 . autopep8 1.5.4 . backcall 0.2.0 . biopython 1.78 . black 20.8b1 . bleach 3.2.1 . bokeh 2.2.3 . botocore 1.19.18 . Brotli 1.0.9 . cellforest 0.0.2 /home/ubuntu/code/cellforest . certifi 2019.11.28 . cffi 1.14.3 . chardet 3.0.4 . click 7.1.2 . colorama 0.4.4 . commonmark 0.9.1 . cycler 0.10.0 . dash 1.17.0 . dash-building-blocks 0.1.2 . dash-core-components 1.13.0 . dash-html-components 1.1.1 . dash-renderer 1.8.3 . dash-table 4.11.0 . dataclasses 0.6 . dataforest 0.0.2 /home/ubuntu/code/dataforest . dbus-python 1.2.16 . decorator 4.4.2 . defusedxml 0.6.0 . distro-info 0.23ubuntu1 . entrypoints 0.3 . fastcore 1.3.5 . flake8 3.8.4 . Flask 1.1.2 . Flask-Compress 1.8.0 . future 0.18.2 . get-version 2.1 . gitdb 4.0.5 . GitPython ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1496
https://github.com/scverse/scanpy/issues/1496:4005,integrability,compon,components,4005," not work. . For example, if you're using pip, instead of https://github.com/user/proj/archive/master.zip use git+https://github.com/user/proj.git#egg=proj```. ```. #### Versions. <details>. scanpy. problem is with installation, so scanpy.logging.print_versions(). commit: ef5a8ee57c2aef7778a069a49101a8998718e6d5. python. 3.8.5. pip. 20.0.2 . ubuntu. 20.04. pip list. Package Version Location . ------------------------- -------------------- -----------------------------. analysaurus 0.0.1 /home/ubuntu/code/analysaurus. anndata 0.7.5 . ansi2html 1.5.2 . appdirs 1.4.4 . argon2-cffi 20.1.0 . astroid 2.4.2 . async-generator 1.10 . attrs 20.3.0 . autopep8 1.5.4 . backcall 0.2.0 . biopython 1.78 . black 20.8b1 . bleach 3.2.1 . bokeh 2.2.3 . botocore 1.19.18 . Brotli 1.0.9 . cellforest 0.0.2 /home/ubuntu/code/cellforest . certifi 2019.11.28 . cffi 1.14.3 . chardet 3.0.4 . click 7.1.2 . colorama 0.4.4 . commonmark 0.9.1 . cycler 0.10.0 . dash 1.17.0 . dash-building-blocks 0.1.2 . dash-core-components 1.13.0 . dash-html-components 1.1.1 . dash-renderer 1.8.3 . dash-table 4.11.0 . dataclasses 0.6 . dataforest 0.0.2 /home/ubuntu/code/dataforest . dbus-python 1.2.16 . decorator 4.4.2 . defusedxml 0.6.0 . distro-info 0.23ubuntu1 . entrypoints 0.3 . fastcore 1.3.5 . flake8 3.8.4 . Flask 1.1.2 . Flask-Compress 1.8.0 . future 0.18.2 . get-version 2.1 . gitdb 4.0.5 . GitPython 3.1.11 . h5py 3.1.0 . hyperopt 0.1.2 . idna 2.8 . importlib-metadata 2.0.0 . iniconfig 1.1.1 . ipdb 0.13.4 . ipykernel 5.3.4 . ipympl 0.5.8 . ipython 7.19.0 . ipython-genutils 0.2.0 . ipywidgets 7.5.1 . isort 5.6.4 . itsdangerous 1.1.0 . jedi 0.17.2 . Jinja2 2.11.2 . jmespath 0.10.0 . joblib 0.17.0 . json5 0.9.5 . jsonschema 3.2.0 . jupyter-client 6.1.7 . jupyter-core 4.6.3 . jupyter-dash 0.3.1 . jupyter-lsp 0.9.2 . jupyterlab 2.2.9 . jupyterlab-code-formatter 1.3.6 . jupyterlab-git 0.23.1 . jupyterlab-latex 2.0.0 . jupyterlab-pygments 0.1.2 . jupyterlab-server 1.2.0 . jupyterlab-sql 0.3.3 . jupyterlab-templates",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1496
https://github.com/scverse/scanpy/issues/1496:4035,integrability,compon,components,4035,"ou're using pip, instead of https://github.com/user/proj/archive/master.zip use git+https://github.com/user/proj.git#egg=proj```. ```. #### Versions. <details>. scanpy. problem is with installation, so scanpy.logging.print_versions(). commit: ef5a8ee57c2aef7778a069a49101a8998718e6d5. python. 3.8.5. pip. 20.0.2 . ubuntu. 20.04. pip list. Package Version Location . ------------------------- -------------------- -----------------------------. analysaurus 0.0.1 /home/ubuntu/code/analysaurus. anndata 0.7.5 . ansi2html 1.5.2 . appdirs 1.4.4 . argon2-cffi 20.1.0 . astroid 2.4.2 . async-generator 1.10 . attrs 20.3.0 . autopep8 1.5.4 . backcall 0.2.0 . biopython 1.78 . black 20.8b1 . bleach 3.2.1 . bokeh 2.2.3 . botocore 1.19.18 . Brotli 1.0.9 . cellforest 0.0.2 /home/ubuntu/code/cellforest . certifi 2019.11.28 . cffi 1.14.3 . chardet 3.0.4 . click 7.1.2 . colorama 0.4.4 . commonmark 0.9.1 . cycler 0.10.0 . dash 1.17.0 . dash-building-blocks 0.1.2 . dash-core-components 1.13.0 . dash-html-components 1.1.1 . dash-renderer 1.8.3 . dash-table 4.11.0 . dataclasses 0.6 . dataforest 0.0.2 /home/ubuntu/code/dataforest . dbus-python 1.2.16 . decorator 4.4.2 . defusedxml 0.6.0 . distro-info 0.23ubuntu1 . entrypoints 0.3 . fastcore 1.3.5 . flake8 3.8.4 . Flask 1.1.2 . Flask-Compress 1.8.0 . future 0.18.2 . get-version 2.1 . gitdb 4.0.5 . GitPython 3.1.11 . h5py 3.1.0 . hyperopt 0.1.2 . idna 2.8 . importlib-metadata 2.0.0 . iniconfig 1.1.1 . ipdb 0.13.4 . ipykernel 5.3.4 . ipympl 0.5.8 . ipython 7.19.0 . ipython-genutils 0.2.0 . ipywidgets 7.5.1 . isort 5.6.4 . itsdangerous 1.1.0 . jedi 0.17.2 . Jinja2 2.11.2 . jmespath 0.10.0 . joblib 0.17.0 . json5 0.9.5 . jsonschema 3.2.0 . jupyter-client 6.1.7 . jupyter-core 4.6.3 . jupyter-dash 0.3.1 . jupyter-lsp 0.9.2 . jupyterlab 2.2.9 . jupyterlab-code-formatter 1.3.6 . jupyterlab-git 0.23.1 . jupyterlab-latex 2.0.0 . jupyterlab-pygments 0.1.2 . jupyterlab-server 1.2.0 . jupyterlab-sql 0.3.3 . jupyterlab-templates 0.2.5 . jupytext 1.6.0 . kiwi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1496
https://github.com/scverse/scanpy/issues/1496:4353,integrability,version,version,4353,ntu. 20.04. pip list. Package Version Location . ------------------------- -------------------- -----------------------------. analysaurus 0.0.1 /home/ubuntu/code/analysaurus. anndata 0.7.5 . ansi2html 1.5.2 . appdirs 1.4.4 . argon2-cffi 20.1.0 . astroid 2.4.2 . async-generator 1.10 . attrs 20.3.0 . autopep8 1.5.4 . backcall 0.2.0 . biopython 1.78 . black 20.8b1 . bleach 3.2.1 . bokeh 2.2.3 . botocore 1.19.18 . Brotli 1.0.9 . cellforest 0.0.2 /home/ubuntu/code/cellforest . certifi 2019.11.28 . cffi 1.14.3 . chardet 3.0.4 . click 7.1.2 . colorama 0.4.4 . commonmark 0.9.1 . cycler 0.10.0 . dash 1.17.0 . dash-building-blocks 0.1.2 . dash-core-components 1.13.0 . dash-html-components 1.1.1 . dash-renderer 1.8.3 . dash-table 4.11.0 . dataclasses 0.6 . dataforest 0.0.2 /home/ubuntu/code/dataforest . dbus-python 1.2.16 . decorator 4.4.2 . defusedxml 0.6.0 . distro-info 0.23ubuntu1 . entrypoints 0.3 . fastcore 1.3.5 . flake8 3.8.4 . Flask 1.1.2 . Flask-Compress 1.8.0 . future 0.18.2 . get-version 2.1 . gitdb 4.0.5 . GitPython 3.1.11 . h5py 3.1.0 . hyperopt 0.1.2 . idna 2.8 . importlib-metadata 2.0.0 . iniconfig 1.1.1 . ipdb 0.13.4 . ipykernel 5.3.4 . ipympl 0.5.8 . ipython 7.19.0 . ipython-genutils 0.2.0 . ipywidgets 7.5.1 . isort 5.6.4 . itsdangerous 1.1.0 . jedi 0.17.2 . Jinja2 2.11.2 . jmespath 0.10.0 . joblib 0.17.0 . json5 0.9.5 . jsonschema 3.2.0 . jupyter-client 6.1.7 . jupyter-core 4.6.3 . jupyter-dash 0.3.1 . jupyter-lsp 0.9.2 . jupyterlab 2.2.9 . jupyterlab-code-formatter 1.3.6 . jupyterlab-git 0.23.1 . jupyterlab-latex 2.0.0 . jupyterlab-pygments 0.1.2 . jupyterlab-server 1.2.0 . jupyterlab-sql 0.3.3 . jupyterlab-templates 0.2.5 . jupytext 1.6.0 . kiwisolver 1.3.1 . lazy-object-proxy 1.4.3 . legacy-api-wrap 1.2 . llvmlite 0.34.0 . markdown-it-py 0.5.6 . MarkupSafe 1.1.1 . matplotlib 3.3.3 . mccabe 0.6.1 . mistune 0.8.4 . mypy-extensions 0.4.3 . natsort 7.0.1 . nbclient 0.5.1 . nbconvert 6.0.7 . nbdime 2.1.0 . nbformat 5.0.8 . nbresuse 0.3.6 . nest-asyncio 1.4.3 .,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1496
https://github.com/scverse/scanpy/issues/1496:5088,integrability,api,api-wrap,5088,0 . dataclasses 0.6 . dataforest 0.0.2 /home/ubuntu/code/dataforest . dbus-python 1.2.16 . decorator 4.4.2 . defusedxml 0.6.0 . distro-info 0.23ubuntu1 . entrypoints 0.3 . fastcore 1.3.5 . flake8 3.8.4 . Flask 1.1.2 . Flask-Compress 1.8.0 . future 0.18.2 . get-version 2.1 . gitdb 4.0.5 . GitPython 3.1.11 . h5py 3.1.0 . hyperopt 0.1.2 . idna 2.8 . importlib-metadata 2.0.0 . iniconfig 1.1.1 . ipdb 0.13.4 . ipykernel 5.3.4 . ipympl 0.5.8 . ipython 7.19.0 . ipython-genutils 0.2.0 . ipywidgets 7.5.1 . isort 5.6.4 . itsdangerous 1.1.0 . jedi 0.17.2 . Jinja2 2.11.2 . jmespath 0.10.0 . joblib 0.17.0 . json5 0.9.5 . jsonschema 3.2.0 . jupyter-client 6.1.7 . jupyter-core 4.6.3 . jupyter-dash 0.3.1 . jupyter-lsp 0.9.2 . jupyterlab 2.2.9 . jupyterlab-code-formatter 1.3.6 . jupyterlab-git 0.23.1 . jupyterlab-latex 2.0.0 . jupyterlab-pygments 0.1.2 . jupyterlab-server 1.2.0 . jupyterlab-sql 0.3.3 . jupyterlab-templates 0.2.5 . jupytext 1.6.0 . kiwisolver 1.3.1 . lazy-object-proxy 1.4.3 . legacy-api-wrap 1.2 . llvmlite 0.34.0 . markdown-it-py 0.5.6 . MarkupSafe 1.1.1 . matplotlib 3.3.3 . mccabe 0.6.1 . mistune 0.8.4 . mypy-extensions 0.4.3 . natsort 7.0.1 . nbclient 0.5.1 . nbconvert 6.0.7 . nbdime 2.1.0 . nbformat 5.0.8 . nbresuse 0.3.6 . nest-asyncio 1.4.3 . networkx 2.5 . notebook 6.1.5 . numba 0.51.2 . numexpr 2.7.1 . numpy 1.19.4 . packaging 20.4 . pandas 1.1.4 . pandocfilters 1.4.3 . parso 0.7.1 . path 15.0.0 . pathspec 0.8.1 . pathtools 0.1.2 . patsy 0.5.1 . peepdis 0.1.13 . pexpect 4.8.0 . pickleshare 0.7.5 . Pillow 8.0.1 . pip 20.0.2 . plotly 4.12.0 . pluggy 0.13.1 . prometheus-client 0.8.0 . prompt-toolkit 3.0.8 . psutil 5.7.3 . ptvsd 4.3.2 . ptyprocess 0.6.0 . py 1.9.0 . pycodestyle 2.6.0 . pycparser 2.20 . pydocstyle 5.1.1 . pyflakes 2.2.0 . Pygments 2.7.2 . PyGObject 3.36.0 . pylint 2.6.0 . pymongo 3.11.0 . pyparsing 2.4.7 . pyrsistent 0.17.3 . pytest 6.1.2 . python-apt 2.0.0+ubuntu0.20.4.1 . python-dateutil 2.8.1 . python-debian 0.1.36ubuntu1 . python-jsonrpc-server ,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1496
https://github.com/scverse/scanpy/issues/1496:7023,integrability,wrap,wrapt,7023,ite 0.34.0 . markdown-it-py 0.5.6 . MarkupSafe 1.1.1 . matplotlib 3.3.3 . mccabe 0.6.1 . mistune 0.8.4 . mypy-extensions 0.4.3 . natsort 7.0.1 . nbclient 0.5.1 . nbconvert 6.0.7 . nbdime 2.1.0 . nbformat 5.0.8 . nbresuse 0.3.6 . nest-asyncio 1.4.3 . networkx 2.5 . notebook 6.1.5 . numba 0.51.2 . numexpr 2.7.1 . numpy 1.19.4 . packaging 20.4 . pandas 1.1.4 . pandocfilters 1.4.3 . parso 0.7.1 . path 15.0.0 . pathspec 0.8.1 . pathtools 0.1.2 . patsy 0.5.1 . peepdis 0.1.13 . pexpect 4.8.0 . pickleshare 0.7.5 . Pillow 8.0.1 . pip 20.0.2 . plotly 4.12.0 . pluggy 0.13.1 . prometheus-client 0.8.0 . prompt-toolkit 3.0.8 . psutil 5.7.3 . ptvsd 4.3.2 . ptyprocess 0.6.0 . py 1.9.0 . pycodestyle 2.6.0 . pycparser 2.20 . pydocstyle 5.1.1 . pyflakes 2.2.0 . Pygments 2.7.2 . PyGObject 3.36.0 . pylint 2.6.0 . pymongo 3.11.0 . pyparsing 2.4.7 . pyrsistent 0.17.3 . pytest 6.1.2 . python-apt 2.0.0+ubuntu0.20.4.1 . python-dateutil 2.8.1 . python-debian 0.1.36ubuntu1 . python-jsonrpc-server 0.4.0 . python-language-server 0.36.1 . pytoml 0.1.21 . pytz 2020.4 . PyYAML 5.3.1 . pyzmq 20.0.0 . regex 2020.11.13 . requests 2.22.0 . requests-unixsocket 0.2.0 . retrying 1.3.3 . rich 9.2.0 . rope 0.18.0 . scikit-learn 0.23.2 . scikit-misc 0.1.3 . scipy 1.5.4 . scriptedforms 0.10.1 . scvi-tools 0.7.1 . seaborn 0.11.0 . Send2Trash 1.5.0 . setuptools 50.3.2 . setuptools-scm 4.1.2 . sinfo 0.3.1 . six 1.14.0 . smmap 3.0.4 . snowballstemmer 2.0.0 . SQLAlchemy 1.3.20 . statsmodels 0.12.1 . stdlib-list 0.7.0 . tables 3.6.1 . termcolor 1.1.0 . terminado 0.9.1 . testpath 0.4.4 . threadpoolctl 2.1.0 . toml 0.10.2 . torch 1.7.0 . tornado 6.1 . tqdm 4.51.0 . traitlets 5.0.5 . typed-ast 1.4.1 . typeguard 2.10.0 . typing-extensions 3.7.4.3 . ujson 4.0.1 . umap-learn 0.4.6 . unattended-upgrades 0.1 . urllib3 1.25.8 . watchdog 0.10.3 . wcwidth 0.2.5 . webencodings 0.5.1 . Werkzeug 1.0.1 . wheel 0.35.1 . widgetsnbextension 3.5.1 . wrapt 1.12.1 . xeus-python 0.8.3 . xlrd 1.2.0 . yapf 0.30.0 . zipp 3.4.0. </details>.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1496
https://github.com/scverse/scanpy/issues/1496:2357,interoperability,integr,integration,2357,"ools/build_meta.py"", line 145, in run_setup. exec(compile(code, __file__, 'exec'), locals()) File ""setup.py"", line 17, in <module>. setup(. File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/__init__.py"", line 153, in setup. return distutils.core.setup(**attrs). File ""/usr/lib/python3.8/distutils/core.py"", line 108, in setup. _setup_distribution = dist = klass(attrs). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 423, in __init__. _Distribution.__init__(self, {. File ""/usr/lib/python3.8/distutils/dist.py"", line 292, in __init__. self.finalize_options() File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 695, in finalize_options. ep(self). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 702, in _finalize_setup_keywords. ep.load()(self, ep.name, value). File ""/usr/local/lib/python3.8/dist-packages/setuptools_scm/integration.py"", line 17, in version_keyword. dist.metadata.version = _get_version(config). File ""/usr/local/lib/python3.8/dist-packages/setuptools_scm/__init__.py"", line 148, in _get_version. parsed_version = _do_parse(config). File ""/usr/local/lib/python3.8/dist-packages/setuptools_scm/__init__.py"", line 110, in _do_parse raise LookupError(. LookupError: setuptools-scm was unable to detect version for '/home/ubuntu/code/scanpy'. Make sure you're either building from a fully intact git repository or PyPI tarballs. Most other sources (such as GitHub's tarballs, a git checkout without the .git folder) don't contain the necessary metadata and will not work. . For example, if you're using pip, instead of https://github.com/user/proj/archive/master.zip use git+https://github.com/user/proj.git#egg=proj```. ```. #### Versions. <details>. scanpy. problem is with installation, so scanpy.logging.print_versions(). commit: ef5a8ee57c2aef7778a069a49101a8998718e6d5. python. 3.8.5. pip. 20.0.2 . ubuntu. 2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1496
https://github.com/scverse/scanpy/issues/1496:2849,interoperability,repositor,repository,2849," line 423, in __init__. _Distribution.__init__(self, {. File ""/usr/lib/python3.8/distutils/dist.py"", line 292, in __init__. self.finalize_options() File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 695, in finalize_options. ep(self). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 702, in _finalize_setup_keywords. ep.load()(self, ep.name, value). File ""/usr/local/lib/python3.8/dist-packages/setuptools_scm/integration.py"", line 17, in version_keyword. dist.metadata.version = _get_version(config). File ""/usr/local/lib/python3.8/dist-packages/setuptools_scm/__init__.py"", line 148, in _get_version. parsed_version = _do_parse(config). File ""/usr/local/lib/python3.8/dist-packages/setuptools_scm/__init__.py"", line 110, in _do_parse raise LookupError(. LookupError: setuptools-scm was unable to detect version for '/home/ubuntu/code/scanpy'. Make sure you're either building from a fully intact git repository or PyPI tarballs. Most other sources (such as GitHub's tarballs, a git checkout without the .git folder) don't contain the necessary metadata and will not work. . For example, if you're using pip, instead of https://github.com/user/proj/archive/master.zip use git+https://github.com/user/proj.git#egg=proj```. ```. #### Versions. <details>. scanpy. problem is with installation, so scanpy.logging.print_versions(). commit: ef5a8ee57c2aef7778a069a49101a8998718e6d5. python. 3.8.5. pip. 20.0.2 . ubuntu. 20.04. pip list. Package Version Location . ------------------------- -------------------- -----------------------------. analysaurus 0.0.1 /home/ubuntu/code/analysaurus. anndata 0.7.5 . ansi2html 1.5.2 . appdirs 1.4.4 . argon2-cffi 20.1.0 . astroid 2.4.2 . async-generator 1.10 . attrs 20.3.0 . autopep8 1.5.4 . backcall 0.2.0 . biopython 1.78 . black 20.8b1 . bleach 3.2.1 . bokeh 2.2.3 . botocore 1.19.18 . Brotli 1.0.9 . cellforest 0.0.2 /home/ubuntu/code/cellforest . certifi 2019.11.28 ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1496
https://github.com/scverse/scanpy/issues/1496:4005,interoperability,compon,components,4005," not work. . For example, if you're using pip, instead of https://github.com/user/proj/archive/master.zip use git+https://github.com/user/proj.git#egg=proj```. ```. #### Versions. <details>. scanpy. problem is with installation, so scanpy.logging.print_versions(). commit: ef5a8ee57c2aef7778a069a49101a8998718e6d5. python. 3.8.5. pip. 20.0.2 . ubuntu. 20.04. pip list. Package Version Location . ------------------------- -------------------- -----------------------------. analysaurus 0.0.1 /home/ubuntu/code/analysaurus. anndata 0.7.5 . ansi2html 1.5.2 . appdirs 1.4.4 . argon2-cffi 20.1.0 . astroid 2.4.2 . async-generator 1.10 . attrs 20.3.0 . autopep8 1.5.4 . backcall 0.2.0 . biopython 1.78 . black 20.8b1 . bleach 3.2.1 . bokeh 2.2.3 . botocore 1.19.18 . Brotli 1.0.9 . cellforest 0.0.2 /home/ubuntu/code/cellforest . certifi 2019.11.28 . cffi 1.14.3 . chardet 3.0.4 . click 7.1.2 . colorama 0.4.4 . commonmark 0.9.1 . cycler 0.10.0 . dash 1.17.0 . dash-building-blocks 0.1.2 . dash-core-components 1.13.0 . dash-html-components 1.1.1 . dash-renderer 1.8.3 . dash-table 4.11.0 . dataclasses 0.6 . dataforest 0.0.2 /home/ubuntu/code/dataforest . dbus-python 1.2.16 . decorator 4.4.2 . defusedxml 0.6.0 . distro-info 0.23ubuntu1 . entrypoints 0.3 . fastcore 1.3.5 . flake8 3.8.4 . Flask 1.1.2 . Flask-Compress 1.8.0 . future 0.18.2 . get-version 2.1 . gitdb 4.0.5 . GitPython 3.1.11 . h5py 3.1.0 . hyperopt 0.1.2 . idna 2.8 . importlib-metadata 2.0.0 . iniconfig 1.1.1 . ipdb 0.13.4 . ipykernel 5.3.4 . ipympl 0.5.8 . ipython 7.19.0 . ipython-genutils 0.2.0 . ipywidgets 7.5.1 . isort 5.6.4 . itsdangerous 1.1.0 . jedi 0.17.2 . Jinja2 2.11.2 . jmespath 0.10.0 . joblib 0.17.0 . json5 0.9.5 . jsonschema 3.2.0 . jupyter-client 6.1.7 . jupyter-core 4.6.3 . jupyter-dash 0.3.1 . jupyter-lsp 0.9.2 . jupyterlab 2.2.9 . jupyterlab-code-formatter 1.3.6 . jupyterlab-git 0.23.1 . jupyterlab-latex 2.0.0 . jupyterlab-pygments 0.1.2 . jupyterlab-server 1.2.0 . jupyterlab-sql 0.3.3 . jupyterlab-templates",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1496
https://github.com/scverse/scanpy/issues/1496:4035,interoperability,compon,components,4035,"ou're using pip, instead of https://github.com/user/proj/archive/master.zip use git+https://github.com/user/proj.git#egg=proj```. ```. #### Versions. <details>. scanpy. problem is with installation, so scanpy.logging.print_versions(). commit: ef5a8ee57c2aef7778a069a49101a8998718e6d5. python. 3.8.5. pip. 20.0.2 . ubuntu. 20.04. pip list. Package Version Location . ------------------------- -------------------- -----------------------------. analysaurus 0.0.1 /home/ubuntu/code/analysaurus. anndata 0.7.5 . ansi2html 1.5.2 . appdirs 1.4.4 . argon2-cffi 20.1.0 . astroid 2.4.2 . async-generator 1.10 . attrs 20.3.0 . autopep8 1.5.4 . backcall 0.2.0 . biopython 1.78 . black 20.8b1 . bleach 3.2.1 . bokeh 2.2.3 . botocore 1.19.18 . Brotli 1.0.9 . cellforest 0.0.2 /home/ubuntu/code/cellforest . certifi 2019.11.28 . cffi 1.14.3 . chardet 3.0.4 . click 7.1.2 . colorama 0.4.4 . commonmark 0.9.1 . cycler 0.10.0 . dash 1.17.0 . dash-building-blocks 0.1.2 . dash-core-components 1.13.0 . dash-html-components 1.1.1 . dash-renderer 1.8.3 . dash-table 4.11.0 . dataclasses 0.6 . dataforest 0.0.2 /home/ubuntu/code/dataforest . dbus-python 1.2.16 . decorator 4.4.2 . defusedxml 0.6.0 . distro-info 0.23ubuntu1 . entrypoints 0.3 . fastcore 1.3.5 . flake8 3.8.4 . Flask 1.1.2 . Flask-Compress 1.8.0 . future 0.18.2 . get-version 2.1 . gitdb 4.0.5 . GitPython 3.1.11 . h5py 3.1.0 . hyperopt 0.1.2 . idna 2.8 . importlib-metadata 2.0.0 . iniconfig 1.1.1 . ipdb 0.13.4 . ipykernel 5.3.4 . ipympl 0.5.8 . ipython 7.19.0 . ipython-genutils 0.2.0 . ipywidgets 7.5.1 . isort 5.6.4 . itsdangerous 1.1.0 . jedi 0.17.2 . Jinja2 2.11.2 . jmespath 0.10.0 . joblib 0.17.0 . json5 0.9.5 . jsonschema 3.2.0 . jupyter-client 6.1.7 . jupyter-core 4.6.3 . jupyter-dash 0.3.1 . jupyter-lsp 0.9.2 . jupyterlab 2.2.9 . jupyterlab-code-formatter 1.3.6 . jupyterlab-git 0.23.1 . jupyterlab-latex 2.0.0 . jupyterlab-pygments 0.1.2 . jupyterlab-server 1.2.0 . jupyterlab-sql 0.3.3 . jupyterlab-templates 0.2.5 . jupytext 1.6.0 . kiwi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1496
https://github.com/scverse/scanpy/issues/1496:4846,interoperability,format,formatter,4846,28 . cffi 1.14.3 . chardet 3.0.4 . click 7.1.2 . colorama 0.4.4 . commonmark 0.9.1 . cycler 0.10.0 . dash 1.17.0 . dash-building-blocks 0.1.2 . dash-core-components 1.13.0 . dash-html-components 1.1.1 . dash-renderer 1.8.3 . dash-table 4.11.0 . dataclasses 0.6 . dataforest 0.0.2 /home/ubuntu/code/dataforest . dbus-python 1.2.16 . decorator 4.4.2 . defusedxml 0.6.0 . distro-info 0.23ubuntu1 . entrypoints 0.3 . fastcore 1.3.5 . flake8 3.8.4 . Flask 1.1.2 . Flask-Compress 1.8.0 . future 0.18.2 . get-version 2.1 . gitdb 4.0.5 . GitPython 3.1.11 . h5py 3.1.0 . hyperopt 0.1.2 . idna 2.8 . importlib-metadata 2.0.0 . iniconfig 1.1.1 . ipdb 0.13.4 . ipykernel 5.3.4 . ipympl 0.5.8 . ipython 7.19.0 . ipython-genutils 0.2.0 . ipywidgets 7.5.1 . isort 5.6.4 . itsdangerous 1.1.0 . jedi 0.17.2 . Jinja2 2.11.2 . jmespath 0.10.0 . joblib 0.17.0 . json5 0.9.5 . jsonschema 3.2.0 . jupyter-client 6.1.7 . jupyter-core 4.6.3 . jupyter-dash 0.3.1 . jupyter-lsp 0.9.2 . jupyterlab 2.2.9 . jupyterlab-code-formatter 1.3.6 . jupyterlab-git 0.23.1 . jupyterlab-latex 2.0.0 . jupyterlab-pygments 0.1.2 . jupyterlab-server 1.2.0 . jupyterlab-sql 0.3.3 . jupyterlab-templates 0.2.5 . jupytext 1.6.0 . kiwisolver 1.3.1 . lazy-object-proxy 1.4.3 . legacy-api-wrap 1.2 . llvmlite 0.34.0 . markdown-it-py 0.5.6 . MarkupSafe 1.1.1 . matplotlib 3.3.3 . mccabe 0.6.1 . mistune 0.8.4 . mypy-extensions 0.4.3 . natsort 7.0.1 . nbclient 0.5.1 . nbconvert 6.0.7 . nbdime 2.1.0 . nbformat 5.0.8 . nbresuse 0.3.6 . nest-asyncio 1.4.3 . networkx 2.5 . notebook 6.1.5 . numba 0.51.2 . numexpr 2.7.1 . numpy 1.19.4 . packaging 20.4 . pandas 1.1.4 . pandocfilters 1.4.3 . parso 0.7.1 . path 15.0.0 . pathspec 0.8.1 . pathtools 0.1.2 . patsy 0.5.1 . peepdis 0.1.13 . pexpect 4.8.0 . pickleshare 0.7.5 . Pillow 8.0.1 . pip 20.0.2 . plotly 4.12.0 . pluggy 0.13.1 . prometheus-client 0.8.0 . prompt-toolkit 3.0.8 . psutil 5.7.3 . ptvsd 4.3.2 . ptyprocess 0.6.0 . py 1.9.0 . pycodestyle 2.6.0 . pycparser 2.20 . pydocstyle 5.1.1 . pyflake,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1496
https://github.com/scverse/scanpy/issues/1496:5067,interoperability,prox,proxy,5067,8.3 . dash-table 4.11.0 . dataclasses 0.6 . dataforest 0.0.2 /home/ubuntu/code/dataforest . dbus-python 1.2.16 . decorator 4.4.2 . defusedxml 0.6.0 . distro-info 0.23ubuntu1 . entrypoints 0.3 . fastcore 1.3.5 . flake8 3.8.4 . Flask 1.1.2 . Flask-Compress 1.8.0 . future 0.18.2 . get-version 2.1 . gitdb 4.0.5 . GitPython 3.1.11 . h5py 3.1.0 . hyperopt 0.1.2 . idna 2.8 . importlib-metadata 2.0.0 . iniconfig 1.1.1 . ipdb 0.13.4 . ipykernel 5.3.4 . ipympl 0.5.8 . ipython 7.19.0 . ipython-genutils 0.2.0 . ipywidgets 7.5.1 . isort 5.6.4 . itsdangerous 1.1.0 . jedi 0.17.2 . Jinja2 2.11.2 . jmespath 0.10.0 . joblib 0.17.0 . json5 0.9.5 . jsonschema 3.2.0 . jupyter-client 6.1.7 . jupyter-core 4.6.3 . jupyter-dash 0.3.1 . jupyter-lsp 0.9.2 . jupyterlab 2.2.9 . jupyterlab-code-formatter 1.3.6 . jupyterlab-git 0.23.1 . jupyterlab-latex 2.0.0 . jupyterlab-pygments 0.1.2 . jupyterlab-server 1.2.0 . jupyterlab-sql 0.3.3 . jupyterlab-templates 0.2.5 . jupytext 1.6.0 . kiwisolver 1.3.1 . lazy-object-proxy 1.4.3 . legacy-api-wrap 1.2 . llvmlite 0.34.0 . markdown-it-py 0.5.6 . MarkupSafe 1.1.1 . matplotlib 3.3.3 . mccabe 0.6.1 . mistune 0.8.4 . mypy-extensions 0.4.3 . natsort 7.0.1 . nbclient 0.5.1 . nbconvert 6.0.7 . nbdime 2.1.0 . nbformat 5.0.8 . nbresuse 0.3.6 . nest-asyncio 1.4.3 . networkx 2.5 . notebook 6.1.5 . numba 0.51.2 . numexpr 2.7.1 . numpy 1.19.4 . packaging 20.4 . pandas 1.1.4 . pandocfilters 1.4.3 . parso 0.7.1 . path 15.0.0 . pathspec 0.8.1 . pathtools 0.1.2 . patsy 0.5.1 . peepdis 0.1.13 . pexpect 4.8.0 . pickleshare 0.7.5 . Pillow 8.0.1 . pip 20.0.2 . plotly 4.12.0 . pluggy 0.13.1 . prometheus-client 0.8.0 . prompt-toolkit 3.0.8 . psutil 5.7.3 . ptvsd 4.3.2 . ptyprocess 0.6.0 . py 1.9.0 . pycodestyle 2.6.0 . pycparser 2.20 . pydocstyle 5.1.1 . pyflakes 2.2.0 . Pygments 2.7.2 . PyGObject 3.36.0 . pylint 2.6.0 . pymongo 3.11.0 . pyparsing 2.4.7 . pyrsistent 0.17.3 . pytest 6.1.2 . python-apt 2.0.0+ubuntu0.20.4.1 . python-dateutil 2.8.1 . python-debian 0.1.36ubuntu1 . ,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1496
https://github.com/scverse/scanpy/issues/1496:5088,interoperability,api,api-wrap,5088,0 . dataclasses 0.6 . dataforest 0.0.2 /home/ubuntu/code/dataforest . dbus-python 1.2.16 . decorator 4.4.2 . defusedxml 0.6.0 . distro-info 0.23ubuntu1 . entrypoints 0.3 . fastcore 1.3.5 . flake8 3.8.4 . Flask 1.1.2 . Flask-Compress 1.8.0 . future 0.18.2 . get-version 2.1 . gitdb 4.0.5 . GitPython 3.1.11 . h5py 3.1.0 . hyperopt 0.1.2 . idna 2.8 . importlib-metadata 2.0.0 . iniconfig 1.1.1 . ipdb 0.13.4 . ipykernel 5.3.4 . ipympl 0.5.8 . ipython 7.19.0 . ipython-genutils 0.2.0 . ipywidgets 7.5.1 . isort 5.6.4 . itsdangerous 1.1.0 . jedi 0.17.2 . Jinja2 2.11.2 . jmespath 0.10.0 . joblib 0.17.0 . json5 0.9.5 . jsonschema 3.2.0 . jupyter-client 6.1.7 . jupyter-core 4.6.3 . jupyter-dash 0.3.1 . jupyter-lsp 0.9.2 . jupyterlab 2.2.9 . jupyterlab-code-formatter 1.3.6 . jupyterlab-git 0.23.1 . jupyterlab-latex 2.0.0 . jupyterlab-pygments 0.1.2 . jupyterlab-server 1.2.0 . jupyterlab-sql 0.3.3 . jupyterlab-templates 0.2.5 . jupytext 1.6.0 . kiwisolver 1.3.1 . lazy-object-proxy 1.4.3 . legacy-api-wrap 1.2 . llvmlite 0.34.0 . markdown-it-py 0.5.6 . MarkupSafe 1.1.1 . matplotlib 3.3.3 . mccabe 0.6.1 . mistune 0.8.4 . mypy-extensions 0.4.3 . natsort 7.0.1 . nbclient 0.5.1 . nbconvert 6.0.7 . nbdime 2.1.0 . nbformat 5.0.8 . nbresuse 0.3.6 . nest-asyncio 1.4.3 . networkx 2.5 . notebook 6.1.5 . numba 0.51.2 . numexpr 2.7.1 . numpy 1.19.4 . packaging 20.4 . pandas 1.1.4 . pandocfilters 1.4.3 . parso 0.7.1 . path 15.0.0 . pathspec 0.8.1 . pathtools 0.1.2 . patsy 0.5.1 . peepdis 0.1.13 . pexpect 4.8.0 . pickleshare 0.7.5 . Pillow 8.0.1 . pip 20.0.2 . plotly 4.12.0 . pluggy 0.13.1 . prometheus-client 0.8.0 . prompt-toolkit 3.0.8 . psutil 5.7.3 . ptvsd 4.3.2 . ptyprocess 0.6.0 . py 1.9.0 . pycodestyle 2.6.0 . pycparser 2.20 . pydocstyle 5.1.1 . pyflakes 2.2.0 . Pygments 2.7.2 . PyGObject 3.36.0 . pylint 2.6.0 . pymongo 3.11.0 . pyparsing 2.4.7 . pyrsistent 0.17.3 . pytest 6.1.2 . python-apt 2.0.0+ubuntu0.20.4.1 . python-dateutil 2.8.1 . python-debian 0.1.36ubuntu1 . python-jsonrpc-server ,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1496
https://github.com/scverse/scanpy/issues/1496:5664,interoperability,plug,pluggy,5664, 0.10.0 . joblib 0.17.0 . json5 0.9.5 . jsonschema 3.2.0 . jupyter-client 6.1.7 . jupyter-core 4.6.3 . jupyter-dash 0.3.1 . jupyter-lsp 0.9.2 . jupyterlab 2.2.9 . jupyterlab-code-formatter 1.3.6 . jupyterlab-git 0.23.1 . jupyterlab-latex 2.0.0 . jupyterlab-pygments 0.1.2 . jupyterlab-server 1.2.0 . jupyterlab-sql 0.3.3 . jupyterlab-templates 0.2.5 . jupytext 1.6.0 . kiwisolver 1.3.1 . lazy-object-proxy 1.4.3 . legacy-api-wrap 1.2 . llvmlite 0.34.0 . markdown-it-py 0.5.6 . MarkupSafe 1.1.1 . matplotlib 3.3.3 . mccabe 0.6.1 . mistune 0.8.4 . mypy-extensions 0.4.3 . natsort 7.0.1 . nbclient 0.5.1 . nbconvert 6.0.7 . nbdime 2.1.0 . nbformat 5.0.8 . nbresuse 0.3.6 . nest-asyncio 1.4.3 . networkx 2.5 . notebook 6.1.5 . numba 0.51.2 . numexpr 2.7.1 . numpy 1.19.4 . packaging 20.4 . pandas 1.1.4 . pandocfilters 1.4.3 . parso 0.7.1 . path 15.0.0 . pathspec 0.8.1 . pathtools 0.1.2 . patsy 0.5.1 . peepdis 0.1.13 . pexpect 4.8.0 . pickleshare 0.7.5 . Pillow 8.0.1 . pip 20.0.2 . plotly 4.12.0 . pluggy 0.13.1 . prometheus-client 0.8.0 . prompt-toolkit 3.0.8 . psutil 5.7.3 . ptvsd 4.3.2 . ptyprocess 0.6.0 . py 1.9.0 . pycodestyle 2.6.0 . pycparser 2.20 . pydocstyle 5.1.1 . pyflakes 2.2.0 . Pygments 2.7.2 . PyGObject 3.36.0 . pylint 2.6.0 . pymongo 3.11.0 . pyparsing 2.4.7 . pyrsistent 0.17.3 . pytest 6.1.2 . python-apt 2.0.0+ubuntu0.20.4.1 . python-dateutil 2.8.1 . python-debian 0.1.36ubuntu1 . python-jsonrpc-server 0.4.0 . python-language-server 0.36.1 . pytoml 0.1.21 . pytz 2020.4 . PyYAML 5.3.1 . pyzmq 20.0.0 . regex 2020.11.13 . requests 2.22.0 . requests-unixsocket 0.2.0 . retrying 1.3.3 . rich 9.2.0 . rope 0.18.0 . scikit-learn 0.23.2 . scikit-misc 0.1.3 . scipy 1.5.4 . scriptedforms 0.10.1 . scvi-tools 0.7.1 . seaborn 0.11.0 . Send2Trash 1.5.0 . setuptools 50.3.2 . setuptools-scm 4.1.2 . sinfo 0.3.1 . six 1.14.0 . smmap 3.0.4 . snowballstemmer 2.0.0 . SQLAlchemy 1.3.20 . statsmodels 0.12.1 . stdlib-list 0.7.0 . tables 3.6.1 . termcolor 1.1.0 . terminado 0.9.1 . testpath 0.4,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1496
https://github.com/scverse/scanpy/issues/1496:75,modifiability,version,version,75,"`pip install -e .` raises LookupError: setuptools-scm was unable to detect version for '/home/ubuntu/code/scanpy'.; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. setuptools-scm can't find the package version when running `pip install -e` or `pip install .`. I stepped through `scanpy/_metadata.py`, and it does appear to be able to get `__version__` via `setuptools_scm.get_version` as opposed to using `._compat`. It seems like it may either be an issue with `setuptools_scm` itself or the combination of my environment and `pyproject.toml`. Any ideas? ### Minimal code sample (that we can copy&paste without having any data). ```bash. pip install -e . ```. ```pytb. File ""/tmp/tmp7fu14tjf"", line 280, in <module>. main(). File ""/tmp/tmp7fu14tjf"", line 263, in main. json_out['return_val'] = hook(**hook_input['kwargs']). File ""/tmp/tmp7fu14tjf"", line 133, in prepare_metadata_for_build_wheel. return hook(metadata_directory, config_settings). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/build_meta.py"", line 161, in prepare_metadata_for_build_wheel self.run_setup(). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/build_meta.py"", line 145, in run_setup. exec(compile(code, __file__, 'exec'), locals()) File ""setup.py"", line 17, in <module>. setup(. File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/__init__.py"", line 153, in setup. return distutils.core.setup(**attrs). File ""/usr/lib/python3.8/distutils/core.py"", line 108, in setup. _setup_distribution = dist = klass(attrs). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 423, in __init__. _Distribution.__init__(self, {. File ""/usr/lib/python3.8/distutils/dist.py"", line 292, in __init__. self.finalize_options(",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1496
https://github.com/scverse/scanpy/issues/1496:237,modifiability,version,version,237,"`pip install -e .` raises LookupError: setuptools-scm was unable to detect version for '/home/ubuntu/code/scanpy'.; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. setuptools-scm can't find the package version when running `pip install -e` or `pip install .`. I stepped through `scanpy/_metadata.py`, and it does appear to be able to get `__version__` via `setuptools_scm.get_version` as opposed to using `._compat`. It seems like it may either be an issue with `setuptools_scm` itself or the combination of my environment and `pyproject.toml`. Any ideas? ### Minimal code sample (that we can copy&paste without having any data). ```bash. pip install -e . ```. ```pytb. File ""/tmp/tmp7fu14tjf"", line 280, in <module>. main(). File ""/tmp/tmp7fu14tjf"", line 263, in main. json_out['return_val'] = hook(**hook_input['kwargs']). File ""/tmp/tmp7fu14tjf"", line 133, in prepare_metadata_for_build_wheel. return hook(metadata_directory, config_settings). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/build_meta.py"", line 161, in prepare_metadata_for_build_wheel self.run_setup(). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/build_meta.py"", line 145, in run_setup. exec(compile(code, __file__, 'exec'), locals()) File ""setup.py"", line 17, in <module>. setup(. File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/__init__.py"", line 153, in setup. return distutils.core.setup(**attrs). File ""/usr/lib/python3.8/distutils/core.py"", line 108, in setup. _setup_distribution = dist = klass(attrs). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 423, in __init__. _Distribution.__init__(self, {. File ""/usr/lib/python3.8/distutils/dist.py"", line 292, in __init__. self.finalize_options(",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1496
https://github.com/scverse/scanpy/issues/1496:373,modifiability,pac,package,373,"`pip install -e .` raises LookupError: setuptools-scm was unable to detect version for '/home/ubuntu/code/scanpy'.; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. setuptools-scm can't find the package version when running `pip install -e` or `pip install .`. I stepped through `scanpy/_metadata.py`, and it does appear to be able to get `__version__` via `setuptools_scm.get_version` as opposed to using `._compat`. It seems like it may either be an issue with `setuptools_scm` itself or the combination of my environment and `pyproject.toml`. Any ideas? ### Minimal code sample (that we can copy&paste without having any data). ```bash. pip install -e . ```. ```pytb. File ""/tmp/tmp7fu14tjf"", line 280, in <module>. main(). File ""/tmp/tmp7fu14tjf"", line 263, in main. json_out['return_val'] = hook(**hook_input['kwargs']). File ""/tmp/tmp7fu14tjf"", line 133, in prepare_metadata_for_build_wheel. return hook(metadata_directory, config_settings). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/build_meta.py"", line 161, in prepare_metadata_for_build_wheel self.run_setup(). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/build_meta.py"", line 145, in run_setup. exec(compile(code, __file__, 'exec'), locals()) File ""setup.py"", line 17, in <module>. setup(. File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/__init__.py"", line 153, in setup. return distutils.core.setup(**attrs). File ""/usr/lib/python3.8/distutils/core.py"", line 108, in setup. _setup_distribution = dist = klass(attrs). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 423, in __init__. _Distribution.__init__(self, {. File ""/usr/lib/python3.8/distutils/dist.py"", line 292, in __init__. self.finalize_options(",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1496
https://github.com/scverse/scanpy/issues/1496:381,modifiability,version,version,381,"`pip install -e .` raises LookupError: setuptools-scm was unable to detect version for '/home/ubuntu/code/scanpy'.; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. setuptools-scm can't find the package version when running `pip install -e` or `pip install .`. I stepped through `scanpy/_metadata.py`, and it does appear to be able to get `__version__` via `setuptools_scm.get_version` as opposed to using `._compat`. It seems like it may either be an issue with `setuptools_scm` itself or the combination of my environment and `pyproject.toml`. Any ideas? ### Minimal code sample (that we can copy&paste without having any data). ```bash. pip install -e . ```. ```pytb. File ""/tmp/tmp7fu14tjf"", line 280, in <module>. main(). File ""/tmp/tmp7fu14tjf"", line 263, in main. json_out['return_val'] = hook(**hook_input['kwargs']). File ""/tmp/tmp7fu14tjf"", line 133, in prepare_metadata_for_build_wheel. return hook(metadata_directory, config_settings). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/build_meta.py"", line 161, in prepare_metadata_for_build_wheel self.run_setup(). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/build_meta.py"", line 145, in run_setup. exec(compile(code, __file__, 'exec'), locals()) File ""setup.py"", line 17, in <module>. setup(. File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/__init__.py"", line 153, in setup. return distutils.core.setup(**attrs). File ""/usr/lib/python3.8/distutils/core.py"", line 108, in setup. _setup_distribution = dist = klass(attrs). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 423, in __init__. _Distribution.__init__(self, {. File ""/usr/lib/python3.8/distutils/dist.py"", line 292, in __init__. self.finalize_options(",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1496
https://github.com/scverse/scanpy/issues/1496:888,modifiability,modul,module,888,"`pip install -e .` raises LookupError: setuptools-scm was unable to detect version for '/home/ubuntu/code/scanpy'.; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. setuptools-scm can't find the package version when running `pip install -e` or `pip install .`. I stepped through `scanpy/_metadata.py`, and it does appear to be able to get `__version__` via `setuptools_scm.get_version` as opposed to using `._compat`. It seems like it may either be an issue with `setuptools_scm` itself or the combination of my environment and `pyproject.toml`. Any ideas? ### Minimal code sample (that we can copy&paste without having any data). ```bash. pip install -e . ```. ```pytb. File ""/tmp/tmp7fu14tjf"", line 280, in <module>. main(). File ""/tmp/tmp7fu14tjf"", line 263, in main. json_out['return_val'] = hook(**hook_input['kwargs']). File ""/tmp/tmp7fu14tjf"", line 133, in prepare_metadata_for_build_wheel. return hook(metadata_directory, config_settings). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/build_meta.py"", line 161, in prepare_metadata_for_build_wheel self.run_setup(). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/build_meta.py"", line 145, in run_setup. exec(compile(code, __file__, 'exec'), locals()) File ""setup.py"", line 17, in <module>. setup(. File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/__init__.py"", line 153, in setup. return distutils.core.setup(**attrs). File ""/usr/lib/python3.8/distutils/core.py"", line 108, in setup. _setup_distribution = dist = klass(attrs). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 423, in __init__. _Distribution.__init__(self, {. File ""/usr/lib/python3.8/distutils/dist.py"", line 292, in __init__. self.finalize_options(",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1496
https://github.com/scverse/scanpy/issues/1496:1187,modifiability,pac,packages,1187," have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. setuptools-scm can't find the package version when running `pip install -e` or `pip install .`. I stepped through `scanpy/_metadata.py`, and it does appear to be able to get `__version__` via `setuptools_scm.get_version` as opposed to using `._compat`. It seems like it may either be an issue with `setuptools_scm` itself or the combination of my environment and `pyproject.toml`. Any ideas? ### Minimal code sample (that we can copy&paste without having any data). ```bash. pip install -e . ```. ```pytb. File ""/tmp/tmp7fu14tjf"", line 280, in <module>. main(). File ""/tmp/tmp7fu14tjf"", line 263, in main. json_out['return_val'] = hook(**hook_input['kwargs']). File ""/tmp/tmp7fu14tjf"", line 133, in prepare_metadata_for_build_wheel. return hook(metadata_directory, config_settings). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/build_meta.py"", line 161, in prepare_metadata_for_build_wheel self.run_setup(). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/build_meta.py"", line 145, in run_setup. exec(compile(code, __file__, 'exec'), locals()) File ""setup.py"", line 17, in <module>. setup(. File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/__init__.py"", line 153, in setup. return distutils.core.setup(**attrs). File ""/usr/lib/python3.8/distutils/core.py"", line 108, in setup. _setup_distribution = dist = klass(attrs). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 423, in __init__. _Distribution.__init__(self, {. File ""/usr/lib/python3.8/distutils/dist.py"", line 292, in __init__. self.finalize_options() File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 695, in finalize_options. ep(self). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/s",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1496
https://github.com/scverse/scanpy/issues/1496:1348,modifiability,pac,packages,1348,"s-scm can't find the package version when running `pip install -e` or `pip install .`. I stepped through `scanpy/_metadata.py`, and it does appear to be able to get `__version__` via `setuptools_scm.get_version` as opposed to using `._compat`. It seems like it may either be an issue with `setuptools_scm` itself or the combination of my environment and `pyproject.toml`. Any ideas? ### Minimal code sample (that we can copy&paste without having any data). ```bash. pip install -e . ```. ```pytb. File ""/tmp/tmp7fu14tjf"", line 280, in <module>. main(). File ""/tmp/tmp7fu14tjf"", line 263, in main. json_out['return_val'] = hook(**hook_input['kwargs']). File ""/tmp/tmp7fu14tjf"", line 133, in prepare_metadata_for_build_wheel. return hook(metadata_directory, config_settings). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/build_meta.py"", line 161, in prepare_metadata_for_build_wheel self.run_setup(). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/build_meta.py"", line 145, in run_setup. exec(compile(code, __file__, 'exec'), locals()) File ""setup.py"", line 17, in <module>. setup(. File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/__init__.py"", line 153, in setup. return distutils.core.setup(**attrs). File ""/usr/lib/python3.8/distutils/core.py"", line 108, in setup. _setup_distribution = dist = klass(attrs). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 423, in __init__. _Distribution.__init__(self, {. File ""/usr/lib/python3.8/distutils/dist.py"", line 292, in __init__. self.finalize_options() File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 695, in finalize_options. ep(self). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 702, in _finalize_setup_keywords. ep.load()(self, ep.name, value). File ""/usr/local/lib/python3.8/dist-packages/setuptools",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1496
https://github.com/scverse/scanpy/issues/1496:1486,modifiability,modul,module,1486,"es appear to be able to get `__version__` via `setuptools_scm.get_version` as opposed to using `._compat`. It seems like it may either be an issue with `setuptools_scm` itself or the combination of my environment and `pyproject.toml`. Any ideas? ### Minimal code sample (that we can copy&paste without having any data). ```bash. pip install -e . ```. ```pytb. File ""/tmp/tmp7fu14tjf"", line 280, in <module>. main(). File ""/tmp/tmp7fu14tjf"", line 263, in main. json_out['return_val'] = hook(**hook_input['kwargs']). File ""/tmp/tmp7fu14tjf"", line 133, in prepare_metadata_for_build_wheel. return hook(metadata_directory, config_settings). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/build_meta.py"", line 161, in prepare_metadata_for_build_wheel self.run_setup(). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/build_meta.py"", line 145, in run_setup. exec(compile(code, __file__, 'exec'), locals()) File ""setup.py"", line 17, in <module>. setup(. File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/__init__.py"", line 153, in setup. return distutils.core.setup(**attrs). File ""/usr/lib/python3.8/distutils/core.py"", line 108, in setup. _setup_distribution = dist = klass(attrs). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 423, in __init__. _Distribution.__init__(self, {. File ""/usr/lib/python3.8/distutils/dist.py"", line 292, in __init__. self.finalize_options() File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 695, in finalize_options. ep(self). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 702, in _finalize_setup_keywords. ep.load()(self, ep.name, value). File ""/usr/local/lib/python3.8/dist-packages/setuptools_scm/integration.py"", line 17, in version_keyword. dist.metadata.version = _get_version(config). File ""/usr/local/lib/python3.8/dist-pack",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1496
https://github.com/scverse/scanpy/issues/1496:1564,modifiability,pac,packages,1564,"pposed to using `._compat`. It seems like it may either be an issue with `setuptools_scm` itself or the combination of my environment and `pyproject.toml`. Any ideas? ### Minimal code sample (that we can copy&paste without having any data). ```bash. pip install -e . ```. ```pytb. File ""/tmp/tmp7fu14tjf"", line 280, in <module>. main(). File ""/tmp/tmp7fu14tjf"", line 263, in main. json_out['return_val'] = hook(**hook_input['kwargs']). File ""/tmp/tmp7fu14tjf"", line 133, in prepare_metadata_for_build_wheel. return hook(metadata_directory, config_settings). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/build_meta.py"", line 161, in prepare_metadata_for_build_wheel self.run_setup(). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/build_meta.py"", line 145, in run_setup. exec(compile(code, __file__, 'exec'), locals()) File ""setup.py"", line 17, in <module>. setup(. File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/__init__.py"", line 153, in setup. return distutils.core.setup(**attrs). File ""/usr/lib/python3.8/distutils/core.py"", line 108, in setup. _setup_distribution = dist = klass(attrs). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 423, in __init__. _Distribution.__init__(self, {. File ""/usr/lib/python3.8/distutils/dist.py"", line 292, in __init__. self.finalize_options() File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 695, in finalize_options. ep(self). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 702, in _finalize_setup_keywords. ep.load()(self, ep.name, value). File ""/usr/local/lib/python3.8/dist-packages/setuptools_scm/integration.py"", line 17, in version_keyword. dist.metadata.version = _get_version(config). File ""/usr/local/lib/python3.8/dist-packages/setuptools_scm/__init__.py"", line 148, in _get_version. parsed_version = _",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1496
https://github.com/scverse/scanpy/issues/1496:1825,modifiability,pac,packages,1825," -e . ```. ```pytb. File ""/tmp/tmp7fu14tjf"", line 280, in <module>. main(). File ""/tmp/tmp7fu14tjf"", line 263, in main. json_out['return_val'] = hook(**hook_input['kwargs']). File ""/tmp/tmp7fu14tjf"", line 133, in prepare_metadata_for_build_wheel. return hook(metadata_directory, config_settings). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/build_meta.py"", line 161, in prepare_metadata_for_build_wheel self.run_setup(). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/build_meta.py"", line 145, in run_setup. exec(compile(code, __file__, 'exec'), locals()) File ""setup.py"", line 17, in <module>. setup(. File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/__init__.py"", line 153, in setup. return distutils.core.setup(**attrs). File ""/usr/lib/python3.8/distutils/core.py"", line 108, in setup. _setup_distribution = dist = klass(attrs). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 423, in __init__. _Distribution.__init__(self, {. File ""/usr/lib/python3.8/distutils/dist.py"", line 292, in __init__. self.finalize_options() File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 695, in finalize_options. ep(self). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 702, in _finalize_setup_keywords. ep.load()(self, ep.name, value). File ""/usr/local/lib/python3.8/dist-packages/setuptools_scm/integration.py"", line 17, in version_keyword. dist.metadata.version = _get_version(config). File ""/usr/local/lib/python3.8/dist-packages/setuptools_scm/__init__.py"", line 148, in _get_version. parsed_version = _do_parse(config). File ""/usr/local/lib/python3.8/dist-packages/setuptools_scm/__init__.py"", line 110, in _do_parse raise LookupError(. LookupError: setuptools-scm was unable to detect version for '/home/ubuntu/code/scanpy'. Make sure you're either building from",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1496
https://github.com/scverse/scanpy/issues/1496:2063,modifiability,pac,packages,2063,"d_wheel. return hook(metadata_directory, config_settings). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/build_meta.py"", line 161, in prepare_metadata_for_build_wheel self.run_setup(). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/build_meta.py"", line 145, in run_setup. exec(compile(code, __file__, 'exec'), locals()) File ""setup.py"", line 17, in <module>. setup(. File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/__init__.py"", line 153, in setup. return distutils.core.setup(**attrs). File ""/usr/lib/python3.8/distutils/core.py"", line 108, in setup. _setup_distribution = dist = klass(attrs). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 423, in __init__. _Distribution.__init__(self, {. File ""/usr/lib/python3.8/distutils/dist.py"", line 292, in __init__. self.finalize_options() File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 695, in finalize_options. ep(self). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 702, in _finalize_setup_keywords. ep.load()(self, ep.name, value). File ""/usr/local/lib/python3.8/dist-packages/setuptools_scm/integration.py"", line 17, in version_keyword. dist.metadata.version = _get_version(config). File ""/usr/local/lib/python3.8/dist-packages/setuptools_scm/__init__.py"", line 148, in _get_version. parsed_version = _do_parse(config). File ""/usr/local/lib/python3.8/dist-packages/setuptools_scm/__init__.py"", line 110, in _do_parse raise LookupError(. LookupError: setuptools-scm was unable to detect version for '/home/ubuntu/code/scanpy'. Make sure you're either building from a fully intact git repository or PyPI tarballs. Most other sources (such as GitHub's tarballs, a git checkout without the .git folder) don't contain the necessary metadata and will not work. . For example, if you're using pip, instead of",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1496
https://github.com/scverse/scanpy/issues/1496:2195,modifiability,pac,packages,2195,"uptools/build_meta.py"", line 161, in prepare_metadata_for_build_wheel self.run_setup(). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/build_meta.py"", line 145, in run_setup. exec(compile(code, __file__, 'exec'), locals()) File ""setup.py"", line 17, in <module>. setup(. File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/__init__.py"", line 153, in setup. return distutils.core.setup(**attrs). File ""/usr/lib/python3.8/distutils/core.py"", line 108, in setup. _setup_distribution = dist = klass(attrs). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 423, in __init__. _Distribution.__init__(self, {. File ""/usr/lib/python3.8/distutils/dist.py"", line 292, in __init__. self.finalize_options() File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 695, in finalize_options. ep(self). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 702, in _finalize_setup_keywords. ep.load()(self, ep.name, value). File ""/usr/local/lib/python3.8/dist-packages/setuptools_scm/integration.py"", line 17, in version_keyword. dist.metadata.version = _get_version(config). File ""/usr/local/lib/python3.8/dist-packages/setuptools_scm/__init__.py"", line 148, in _get_version. parsed_version = _do_parse(config). File ""/usr/local/lib/python3.8/dist-packages/setuptools_scm/__init__.py"", line 110, in _do_parse raise LookupError(. LookupError: setuptools-scm was unable to detect version for '/home/ubuntu/code/scanpy'. Make sure you're either building from a fully intact git repository or PyPI tarballs. Most other sources (such as GitHub's tarballs, a git checkout without the .git folder) don't contain the necessary metadata and will not work. . For example, if you're using pip, instead of https://github.com/user/proj/archive/master.zip use git+https://github.com/user/proj.git#egg=proj```. ```. #### Versions. <details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1496
https://github.com/scverse/scanpy/issues/1496:2333,modifiability,pac,packages,2333,"on3.8/site-packages/setuptools/build_meta.py"", line 145, in run_setup. exec(compile(code, __file__, 'exec'), locals()) File ""setup.py"", line 17, in <module>. setup(. File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/__init__.py"", line 153, in setup. return distutils.core.setup(**attrs). File ""/usr/lib/python3.8/distutils/core.py"", line 108, in setup. _setup_distribution = dist = klass(attrs). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 423, in __init__. _Distribution.__init__(self, {. File ""/usr/lib/python3.8/distutils/dist.py"", line 292, in __init__. self.finalize_options() File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 695, in finalize_options. ep(self). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 702, in _finalize_setup_keywords. ep.load()(self, ep.name, value). File ""/usr/local/lib/python3.8/dist-packages/setuptools_scm/integration.py"", line 17, in version_keyword. dist.metadata.version = _get_version(config). File ""/usr/local/lib/python3.8/dist-packages/setuptools_scm/__init__.py"", line 148, in _get_version. parsed_version = _do_parse(config). File ""/usr/local/lib/python3.8/dist-packages/setuptools_scm/__init__.py"", line 110, in _do_parse raise LookupError(. LookupError: setuptools-scm was unable to detect version for '/home/ubuntu/code/scanpy'. Make sure you're either building from a fully intact git repository or PyPI tarballs. Most other sources (such as GitHub's tarballs, a git checkout without the .git folder) don't contain the necessary metadata and will not work. . For example, if you're using pip, instead of https://github.com/user/proj/archive/master.zip use git+https://github.com/user/proj.git#egg=proj```. ```. #### Versions. <details>. scanpy. problem is with installation, so scanpy.logging.print_versions(). commit: ef5a8ee57c2aef7778a069a49101a8998718e6d5. python. 3.8.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1496
https://github.com/scverse/scanpy/issues/1496:2357,modifiability,integr,integration,2357,"ools/build_meta.py"", line 145, in run_setup. exec(compile(code, __file__, 'exec'), locals()) File ""setup.py"", line 17, in <module>. setup(. File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/__init__.py"", line 153, in setup. return distutils.core.setup(**attrs). File ""/usr/lib/python3.8/distutils/core.py"", line 108, in setup. _setup_distribution = dist = klass(attrs). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 423, in __init__. _Distribution.__init__(self, {. File ""/usr/lib/python3.8/distutils/dist.py"", line 292, in __init__. self.finalize_options() File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 695, in finalize_options. ep(self). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 702, in _finalize_setup_keywords. ep.load()(self, ep.name, value). File ""/usr/local/lib/python3.8/dist-packages/setuptools_scm/integration.py"", line 17, in version_keyword. dist.metadata.version = _get_version(config). File ""/usr/local/lib/python3.8/dist-packages/setuptools_scm/__init__.py"", line 148, in _get_version. parsed_version = _do_parse(config). File ""/usr/local/lib/python3.8/dist-packages/setuptools_scm/__init__.py"", line 110, in _do_parse raise LookupError(. LookupError: setuptools-scm was unable to detect version for '/home/ubuntu/code/scanpy'. Make sure you're either building from a fully intact git repository or PyPI tarballs. Most other sources (such as GitHub's tarballs, a git checkout without the .git folder) don't contain the necessary metadata and will not work. . For example, if you're using pip, instead of https://github.com/user/proj/archive/master.zip use git+https://github.com/user/proj.git#egg=proj```. ```. #### Versions. <details>. scanpy. problem is with installation, so scanpy.logging.print_versions(). commit: ef5a8ee57c2aef7778a069a49101a8998718e6d5. python. 3.8.5. pip. 20.0.2 . ubuntu. 2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1496
https://github.com/scverse/scanpy/issues/1496:2417,modifiability,version,version,2417,"code, __file__, 'exec'), locals()) File ""setup.py"", line 17, in <module>. setup(. File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/__init__.py"", line 153, in setup. return distutils.core.setup(**attrs). File ""/usr/lib/python3.8/distutils/core.py"", line 108, in setup. _setup_distribution = dist = klass(attrs). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 423, in __init__. _Distribution.__init__(self, {. File ""/usr/lib/python3.8/distutils/dist.py"", line 292, in __init__. self.finalize_options() File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 695, in finalize_options. ep(self). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 702, in _finalize_setup_keywords. ep.load()(self, ep.name, value). File ""/usr/local/lib/python3.8/dist-packages/setuptools_scm/integration.py"", line 17, in version_keyword. dist.metadata.version = _get_version(config). File ""/usr/local/lib/python3.8/dist-packages/setuptools_scm/__init__.py"", line 148, in _get_version. parsed_version = _do_parse(config). File ""/usr/local/lib/python3.8/dist-packages/setuptools_scm/__init__.py"", line 110, in _do_parse raise LookupError(. LookupError: setuptools-scm was unable to detect version for '/home/ubuntu/code/scanpy'. Make sure you're either building from a fully intact git repository or PyPI tarballs. Most other sources (such as GitHub's tarballs, a git checkout without the .git folder) don't contain the necessary metadata and will not work. . For example, if you're using pip, instead of https://github.com/user/proj/archive/master.zip use git+https://github.com/user/proj.git#egg=proj```. ```. #### Versions. <details>. scanpy. problem is with installation, so scanpy.logging.print_versions(). commit: ef5a8ee57c2aef7778a069a49101a8998718e6d5. python. 3.8.5. pip. 20.0.2 . ubuntu. 20.04. pip list. Package Version Location . ---------------",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1496
https://github.com/scverse/scanpy/issues/1496:2485,modifiability,pac,packages,2485,"ule>. setup(. File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/__init__.py"", line 153, in setup. return distutils.core.setup(**attrs). File ""/usr/lib/python3.8/distutils/core.py"", line 108, in setup. _setup_distribution = dist = klass(attrs). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 423, in __init__. _Distribution.__init__(self, {. File ""/usr/lib/python3.8/distutils/dist.py"", line 292, in __init__. self.finalize_options() File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 695, in finalize_options. ep(self). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 702, in _finalize_setup_keywords. ep.load()(self, ep.name, value). File ""/usr/local/lib/python3.8/dist-packages/setuptools_scm/integration.py"", line 17, in version_keyword. dist.metadata.version = _get_version(config). File ""/usr/local/lib/python3.8/dist-packages/setuptools_scm/__init__.py"", line 148, in _get_version. parsed_version = _do_parse(config). File ""/usr/local/lib/python3.8/dist-packages/setuptools_scm/__init__.py"", line 110, in _do_parse raise LookupError(. LookupError: setuptools-scm was unable to detect version for '/home/ubuntu/code/scanpy'. Make sure you're either building from a fully intact git repository or PyPI tarballs. Most other sources (such as GitHub's tarballs, a git checkout without the .git folder) don't contain the necessary metadata and will not work. . For example, if you're using pip, instead of https://github.com/user/proj/archive/master.zip use git+https://github.com/user/proj.git#egg=proj```. ```. #### Versions. <details>. scanpy. problem is with installation, so scanpy.logging.print_versions(). commit: ef5a8ee57c2aef7778a069a49101a8998718e6d5. python. 3.8.5. pip. 20.0.2 . ubuntu. 20.04. pip list. Package Version Location . ------------------------- -------------------- -----------------------------. analy",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1496
https://github.com/scverse/scanpy/issues/1496:2622,modifiability,pac,packages,2622,"istutils.core.setup(**attrs). File ""/usr/lib/python3.8/distutils/core.py"", line 108, in setup. _setup_distribution = dist = klass(attrs). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 423, in __init__. _Distribution.__init__(self, {. File ""/usr/lib/python3.8/distutils/dist.py"", line 292, in __init__. self.finalize_options() File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 695, in finalize_options. ep(self). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 702, in _finalize_setup_keywords. ep.load()(self, ep.name, value). File ""/usr/local/lib/python3.8/dist-packages/setuptools_scm/integration.py"", line 17, in version_keyword. dist.metadata.version = _get_version(config). File ""/usr/local/lib/python3.8/dist-packages/setuptools_scm/__init__.py"", line 148, in _get_version. parsed_version = _do_parse(config). File ""/usr/local/lib/python3.8/dist-packages/setuptools_scm/__init__.py"", line 110, in _do_parse raise LookupError(. LookupError: setuptools-scm was unable to detect version for '/home/ubuntu/code/scanpy'. Make sure you're either building from a fully intact git repository or PyPI tarballs. Most other sources (such as GitHub's tarballs, a git checkout without the .git folder) don't contain the necessary metadata and will not work. . For example, if you're using pip, instead of https://github.com/user/proj/archive/master.zip use git+https://github.com/user/proj.git#egg=proj```. ```. #### Versions. <details>. scanpy. problem is with installation, so scanpy.logging.print_versions(). commit: ef5a8ee57c2aef7778a069a49101a8998718e6d5. python. 3.8.5. pip. 20.0.2 . ubuntu. 20.04. pip list. Package Version Location . ------------------------- -------------------- -----------------------------. analysaurus 0.0.1 /home/ubuntu/code/analysaurus. anndata 0.7.5 . ansi2html 1.5.2 . appdirs 1.4.4 . argon2-cffi 20.1.0 . astroid 2.4.2 . async-",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1496
https://github.com/scverse/scanpy/issues/1496:2752,modifiability,version,version,2752,"attrs). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 423, in __init__. _Distribution.__init__(self, {. File ""/usr/lib/python3.8/distutils/dist.py"", line 292, in __init__. self.finalize_options() File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 695, in finalize_options. ep(self). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 702, in _finalize_setup_keywords. ep.load()(self, ep.name, value). File ""/usr/local/lib/python3.8/dist-packages/setuptools_scm/integration.py"", line 17, in version_keyword. dist.metadata.version = _get_version(config). File ""/usr/local/lib/python3.8/dist-packages/setuptools_scm/__init__.py"", line 148, in _get_version. parsed_version = _do_parse(config). File ""/usr/local/lib/python3.8/dist-packages/setuptools_scm/__init__.py"", line 110, in _do_parse raise LookupError(. LookupError: setuptools-scm was unable to detect version for '/home/ubuntu/code/scanpy'. Make sure you're either building from a fully intact git repository or PyPI tarballs. Most other sources (such as GitHub's tarballs, a git checkout without the .git folder) don't contain the necessary metadata and will not work. . For example, if you're using pip, instead of https://github.com/user/proj/archive/master.zip use git+https://github.com/user/proj.git#egg=proj```. ```. #### Versions. <details>. scanpy. problem is with installation, so scanpy.logging.print_versions(). commit: ef5a8ee57c2aef7778a069a49101a8998718e6d5. python. 3.8.5. pip. 20.0.2 . ubuntu. 20.04. pip list. Package Version Location . ------------------------- -------------------- -----------------------------. analysaurus 0.0.1 /home/ubuntu/code/analysaurus. anndata 0.7.5 . ansi2html 1.5.2 . appdirs 1.4.4 . argon2-cffi 20.1.0 . astroid 2.4.2 . async-generator 1.10 . attrs 20.3.0 . autopep8 1.5.4 . backcall 0.2.0 . biopython 1.78 . black 20.8b1 . bleach 3.2.1 . bokeh 2.2.3 . bot",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1496
https://github.com/scverse/scanpy/issues/1496:3180,modifiability,Version,Versions,3180,"on3.8/site-packages/setuptools/dist.py"", line 702, in _finalize_setup_keywords. ep.load()(self, ep.name, value). File ""/usr/local/lib/python3.8/dist-packages/setuptools_scm/integration.py"", line 17, in version_keyword. dist.metadata.version = _get_version(config). File ""/usr/local/lib/python3.8/dist-packages/setuptools_scm/__init__.py"", line 148, in _get_version. parsed_version = _do_parse(config). File ""/usr/local/lib/python3.8/dist-packages/setuptools_scm/__init__.py"", line 110, in _do_parse raise LookupError(. LookupError: setuptools-scm was unable to detect version for '/home/ubuntu/code/scanpy'. Make sure you're either building from a fully intact git repository or PyPI tarballs. Most other sources (such as GitHub's tarballs, a git checkout without the .git folder) don't contain the necessary metadata and will not work. . For example, if you're using pip, instead of https://github.com/user/proj/archive/master.zip use git+https://github.com/user/proj.git#egg=proj```. ```. #### Versions. <details>. scanpy. problem is with installation, so scanpy.logging.print_versions(). commit: ef5a8ee57c2aef7778a069a49101a8998718e6d5. python. 3.8.5. pip. 20.0.2 . ubuntu. 20.04. pip list. Package Version Location . ------------------------- -------------------- -----------------------------. analysaurus 0.0.1 /home/ubuntu/code/analysaurus. anndata 0.7.5 . ansi2html 1.5.2 . appdirs 1.4.4 . argon2-cffi 20.1.0 . astroid 2.4.2 . async-generator 1.10 . attrs 20.3.0 . autopep8 1.5.4 . backcall 0.2.0 . biopython 1.78 . black 20.8b1 . bleach 3.2.1 . bokeh 2.2.3 . botocore 1.19.18 . Brotli 1.0.9 . cellforest 0.0.2 /home/ubuntu/code/cellforest . certifi 2019.11.28 . cffi 1.14.3 . chardet 3.0.4 . click 7.1.2 . colorama 0.4.4 . commonmark 0.9.1 . cycler 0.10.0 . dash 1.17.0 . dash-building-blocks 0.1.2 . dash-core-components 1.13.0 . dash-html-components 1.1.1 . dash-renderer 1.8.3 . dash-table 4.11.0 . dataclasses 0.6 . dataforest 0.0.2 /home/ubuntu/code/dataforest . dbus-python 1.2.16 . d",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1496
https://github.com/scverse/scanpy/issues/1496:3379,modifiability,Pac,Package,3379,"in version_keyword. dist.metadata.version = _get_version(config). File ""/usr/local/lib/python3.8/dist-packages/setuptools_scm/__init__.py"", line 148, in _get_version. parsed_version = _do_parse(config). File ""/usr/local/lib/python3.8/dist-packages/setuptools_scm/__init__.py"", line 110, in _do_parse raise LookupError(. LookupError: setuptools-scm was unable to detect version for '/home/ubuntu/code/scanpy'. Make sure you're either building from a fully intact git repository or PyPI tarballs. Most other sources (such as GitHub's tarballs, a git checkout without the .git folder) don't contain the necessary metadata and will not work. . For example, if you're using pip, instead of https://github.com/user/proj/archive/master.zip use git+https://github.com/user/proj.git#egg=proj```. ```. #### Versions. <details>. scanpy. problem is with installation, so scanpy.logging.print_versions(). commit: ef5a8ee57c2aef7778a069a49101a8998718e6d5. python. 3.8.5. pip. 20.0.2 . ubuntu. 20.04. pip list. Package Version Location . ------------------------- -------------------- -----------------------------. analysaurus 0.0.1 /home/ubuntu/code/analysaurus. anndata 0.7.5 . ansi2html 1.5.2 . appdirs 1.4.4 . argon2-cffi 20.1.0 . astroid 2.4.2 . async-generator 1.10 . attrs 20.3.0 . autopep8 1.5.4 . backcall 0.2.0 . biopython 1.78 . black 20.8b1 . bleach 3.2.1 . bokeh 2.2.3 . botocore 1.19.18 . Brotli 1.0.9 . cellforest 0.0.2 /home/ubuntu/code/cellforest . certifi 2019.11.28 . cffi 1.14.3 . chardet 3.0.4 . click 7.1.2 . colorama 0.4.4 . commonmark 0.9.1 . cycler 0.10.0 . dash 1.17.0 . dash-building-blocks 0.1.2 . dash-core-components 1.13.0 . dash-html-components 1.1.1 . dash-renderer 1.8.3 . dash-table 4.11.0 . dataclasses 0.6 . dataforest 0.0.2 /home/ubuntu/code/dataforest . dbus-python 1.2.16 . decorator 4.4.2 . defusedxml 0.6.0 . distro-info 0.23ubuntu1 . entrypoints 0.3 . fastcore 1.3.5 . flake8 3.8.4 . Flask 1.1.2 . Flask-Compress 1.8.0 . future 0.18.2 . get-version 2.1 . gitdb 4.0.5 . Gi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1496
https://github.com/scverse/scanpy/issues/1496:3387,modifiability,Version,Version,3387,"on_keyword. dist.metadata.version = _get_version(config). File ""/usr/local/lib/python3.8/dist-packages/setuptools_scm/__init__.py"", line 148, in _get_version. parsed_version = _do_parse(config). File ""/usr/local/lib/python3.8/dist-packages/setuptools_scm/__init__.py"", line 110, in _do_parse raise LookupError(. LookupError: setuptools-scm was unable to detect version for '/home/ubuntu/code/scanpy'. Make sure you're either building from a fully intact git repository or PyPI tarballs. Most other sources (such as GitHub's tarballs, a git checkout without the .git folder) don't contain the necessary metadata and will not work. . For example, if you're using pip, instead of https://github.com/user/proj/archive/master.zip use git+https://github.com/user/proj.git#egg=proj```. ```. #### Versions. <details>. scanpy. problem is with installation, so scanpy.logging.print_versions(). commit: ef5a8ee57c2aef7778a069a49101a8998718e6d5. python. 3.8.5. pip. 20.0.2 . ubuntu. 20.04. pip list. Package Version Location . ------------------------- -------------------- -----------------------------. analysaurus 0.0.1 /home/ubuntu/code/analysaurus. anndata 0.7.5 . ansi2html 1.5.2 . appdirs 1.4.4 . argon2-cffi 20.1.0 . astroid 2.4.2 . async-generator 1.10 . attrs 20.3.0 . autopep8 1.5.4 . backcall 0.2.0 . biopython 1.78 . black 20.8b1 . bleach 3.2.1 . bokeh 2.2.3 . botocore 1.19.18 . Brotli 1.0.9 . cellforest 0.0.2 /home/ubuntu/code/cellforest . certifi 2019.11.28 . cffi 1.14.3 . chardet 3.0.4 . click 7.1.2 . colorama 0.4.4 . commonmark 0.9.1 . cycler 0.10.0 . dash 1.17.0 . dash-building-blocks 0.1.2 . dash-core-components 1.13.0 . dash-html-components 1.1.1 . dash-renderer 1.8.3 . dash-table 4.11.0 . dataclasses 0.6 . dataforest 0.0.2 /home/ubuntu/code/dataforest . dbus-python 1.2.16 . decorator 4.4.2 . defusedxml 0.6.0 . distro-info 0.23ubuntu1 . entrypoints 0.3 . fastcore 1.3.5 . flake8 3.8.4 . Flask 1.1.2 . Flask-Compress 1.8.0 . future 0.18.2 . get-version 2.1 . gitdb 4.0.5 . GitPython ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1496
https://github.com/scverse/scanpy/issues/1496:4005,modifiability,compon,components,4005," not work. . For example, if you're using pip, instead of https://github.com/user/proj/archive/master.zip use git+https://github.com/user/proj.git#egg=proj```. ```. #### Versions. <details>. scanpy. problem is with installation, so scanpy.logging.print_versions(). commit: ef5a8ee57c2aef7778a069a49101a8998718e6d5. python. 3.8.5. pip. 20.0.2 . ubuntu. 20.04. pip list. Package Version Location . ------------------------- -------------------- -----------------------------. analysaurus 0.0.1 /home/ubuntu/code/analysaurus. anndata 0.7.5 . ansi2html 1.5.2 . appdirs 1.4.4 . argon2-cffi 20.1.0 . astroid 2.4.2 . async-generator 1.10 . attrs 20.3.0 . autopep8 1.5.4 . backcall 0.2.0 . biopython 1.78 . black 20.8b1 . bleach 3.2.1 . bokeh 2.2.3 . botocore 1.19.18 . Brotli 1.0.9 . cellforest 0.0.2 /home/ubuntu/code/cellforest . certifi 2019.11.28 . cffi 1.14.3 . chardet 3.0.4 . click 7.1.2 . colorama 0.4.4 . commonmark 0.9.1 . cycler 0.10.0 . dash 1.17.0 . dash-building-blocks 0.1.2 . dash-core-components 1.13.0 . dash-html-components 1.1.1 . dash-renderer 1.8.3 . dash-table 4.11.0 . dataclasses 0.6 . dataforest 0.0.2 /home/ubuntu/code/dataforest . dbus-python 1.2.16 . decorator 4.4.2 . defusedxml 0.6.0 . distro-info 0.23ubuntu1 . entrypoints 0.3 . fastcore 1.3.5 . flake8 3.8.4 . Flask 1.1.2 . Flask-Compress 1.8.0 . future 0.18.2 . get-version 2.1 . gitdb 4.0.5 . GitPython 3.1.11 . h5py 3.1.0 . hyperopt 0.1.2 . idna 2.8 . importlib-metadata 2.0.0 . iniconfig 1.1.1 . ipdb 0.13.4 . ipykernel 5.3.4 . ipympl 0.5.8 . ipython 7.19.0 . ipython-genutils 0.2.0 . ipywidgets 7.5.1 . isort 5.6.4 . itsdangerous 1.1.0 . jedi 0.17.2 . Jinja2 2.11.2 . jmespath 0.10.0 . joblib 0.17.0 . json5 0.9.5 . jsonschema 3.2.0 . jupyter-client 6.1.7 . jupyter-core 4.6.3 . jupyter-dash 0.3.1 . jupyter-lsp 0.9.2 . jupyterlab 2.2.9 . jupyterlab-code-formatter 1.3.6 . jupyterlab-git 0.23.1 . jupyterlab-latex 2.0.0 . jupyterlab-pygments 0.1.2 . jupyterlab-server 1.2.0 . jupyterlab-sql 0.3.3 . jupyterlab-templates",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1496
https://github.com/scverse/scanpy/issues/1496:4035,modifiability,compon,components,4035,"ou're using pip, instead of https://github.com/user/proj/archive/master.zip use git+https://github.com/user/proj.git#egg=proj```. ```. #### Versions. <details>. scanpy. problem is with installation, so scanpy.logging.print_versions(). commit: ef5a8ee57c2aef7778a069a49101a8998718e6d5. python. 3.8.5. pip. 20.0.2 . ubuntu. 20.04. pip list. Package Version Location . ------------------------- -------------------- -----------------------------. analysaurus 0.0.1 /home/ubuntu/code/analysaurus. anndata 0.7.5 . ansi2html 1.5.2 . appdirs 1.4.4 . argon2-cffi 20.1.0 . astroid 2.4.2 . async-generator 1.10 . attrs 20.3.0 . autopep8 1.5.4 . backcall 0.2.0 . biopython 1.78 . black 20.8b1 . bleach 3.2.1 . bokeh 2.2.3 . botocore 1.19.18 . Brotli 1.0.9 . cellforest 0.0.2 /home/ubuntu/code/cellforest . certifi 2019.11.28 . cffi 1.14.3 . chardet 3.0.4 . click 7.1.2 . colorama 0.4.4 . commonmark 0.9.1 . cycler 0.10.0 . dash 1.17.0 . dash-building-blocks 0.1.2 . dash-core-components 1.13.0 . dash-html-components 1.1.1 . dash-renderer 1.8.3 . dash-table 4.11.0 . dataclasses 0.6 . dataforest 0.0.2 /home/ubuntu/code/dataforest . dbus-python 1.2.16 . decorator 4.4.2 . defusedxml 0.6.0 . distro-info 0.23ubuntu1 . entrypoints 0.3 . fastcore 1.3.5 . flake8 3.8.4 . Flask 1.1.2 . Flask-Compress 1.8.0 . future 0.18.2 . get-version 2.1 . gitdb 4.0.5 . GitPython 3.1.11 . h5py 3.1.0 . hyperopt 0.1.2 . idna 2.8 . importlib-metadata 2.0.0 . iniconfig 1.1.1 . ipdb 0.13.4 . ipykernel 5.3.4 . ipympl 0.5.8 . ipython 7.19.0 . ipython-genutils 0.2.0 . ipywidgets 7.5.1 . isort 5.6.4 . itsdangerous 1.1.0 . jedi 0.17.2 . Jinja2 2.11.2 . jmespath 0.10.0 . joblib 0.17.0 . json5 0.9.5 . jsonschema 3.2.0 . jupyter-client 6.1.7 . jupyter-core 4.6.3 . jupyter-dash 0.3.1 . jupyter-lsp 0.9.2 . jupyterlab 2.2.9 . jupyterlab-code-formatter 1.3.6 . jupyterlab-git 0.23.1 . jupyterlab-latex 2.0.0 . jupyterlab-pygments 0.1.2 . jupyterlab-server 1.2.0 . jupyterlab-sql 0.3.3 . jupyterlab-templates 0.2.5 . jupytext 1.6.0 . kiwi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1496
https://github.com/scverse/scanpy/issues/1496:4183,modifiability,deco,decorator,4183,". <details>. scanpy. problem is with installation, so scanpy.logging.print_versions(). commit: ef5a8ee57c2aef7778a069a49101a8998718e6d5. python. 3.8.5. pip. 20.0.2 . ubuntu. 20.04. pip list. Package Version Location . ------------------------- -------------------- -----------------------------. analysaurus 0.0.1 /home/ubuntu/code/analysaurus. anndata 0.7.5 . ansi2html 1.5.2 . appdirs 1.4.4 . argon2-cffi 20.1.0 . astroid 2.4.2 . async-generator 1.10 . attrs 20.3.0 . autopep8 1.5.4 . backcall 0.2.0 . biopython 1.78 . black 20.8b1 . bleach 3.2.1 . bokeh 2.2.3 . botocore 1.19.18 . Brotli 1.0.9 . cellforest 0.0.2 /home/ubuntu/code/cellforest . certifi 2019.11.28 . cffi 1.14.3 . chardet 3.0.4 . click 7.1.2 . colorama 0.4.4 . commonmark 0.9.1 . cycler 0.10.0 . dash 1.17.0 . dash-building-blocks 0.1.2 . dash-core-components 1.13.0 . dash-html-components 1.1.1 . dash-renderer 1.8.3 . dash-table 4.11.0 . dataclasses 0.6 . dataforest 0.0.2 /home/ubuntu/code/dataforest . dbus-python 1.2.16 . decorator 4.4.2 . defusedxml 0.6.0 . distro-info 0.23ubuntu1 . entrypoints 0.3 . fastcore 1.3.5 . flake8 3.8.4 . Flask 1.1.2 . Flask-Compress 1.8.0 . future 0.18.2 . get-version 2.1 . gitdb 4.0.5 . GitPython 3.1.11 . h5py 3.1.0 . hyperopt 0.1.2 . idna 2.8 . importlib-metadata 2.0.0 . iniconfig 1.1.1 . ipdb 0.13.4 . ipykernel 5.3.4 . ipympl 0.5.8 . ipython 7.19.0 . ipython-genutils 0.2.0 . ipywidgets 7.5.1 . isort 5.6.4 . itsdangerous 1.1.0 . jedi 0.17.2 . Jinja2 2.11.2 . jmespath 0.10.0 . joblib 0.17.0 . json5 0.9.5 . jsonschema 3.2.0 . jupyter-client 6.1.7 . jupyter-core 4.6.3 . jupyter-dash 0.3.1 . jupyter-lsp 0.9.2 . jupyterlab 2.2.9 . jupyterlab-code-formatter 1.3.6 . jupyterlab-git 0.23.1 . jupyterlab-latex 2.0.0 . jupyterlab-pygments 0.1.2 . jupyterlab-server 1.2.0 . jupyterlab-sql 0.3.3 . jupyterlab-templates 0.2.5 . jupytext 1.6.0 . kiwisolver 1.3.1 . lazy-object-proxy 1.4.3 . legacy-api-wrap 1.2 . llvmlite 0.34.0 . markdown-it-py 0.5.6 . MarkupSafe 1.1.1 . matplotlib 3.3.3 . mccabe",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1496
https://github.com/scverse/scanpy/issues/1496:4353,modifiability,version,version,4353,ntu. 20.04. pip list. Package Version Location . ------------------------- -------------------- -----------------------------. analysaurus 0.0.1 /home/ubuntu/code/analysaurus. anndata 0.7.5 . ansi2html 1.5.2 . appdirs 1.4.4 . argon2-cffi 20.1.0 . astroid 2.4.2 . async-generator 1.10 . attrs 20.3.0 . autopep8 1.5.4 . backcall 0.2.0 . biopython 1.78 . black 20.8b1 . bleach 3.2.1 . bokeh 2.2.3 . botocore 1.19.18 . Brotli 1.0.9 . cellforest 0.0.2 /home/ubuntu/code/cellforest . certifi 2019.11.28 . cffi 1.14.3 . chardet 3.0.4 . click 7.1.2 . colorama 0.4.4 . commonmark 0.9.1 . cycler 0.10.0 . dash 1.17.0 . dash-building-blocks 0.1.2 . dash-core-components 1.13.0 . dash-html-components 1.1.1 . dash-renderer 1.8.3 . dash-table 4.11.0 . dataclasses 0.6 . dataforest 0.0.2 /home/ubuntu/code/dataforest . dbus-python 1.2.16 . decorator 4.4.2 . defusedxml 0.6.0 . distro-info 0.23ubuntu1 . entrypoints 0.3 . fastcore 1.3.5 . flake8 3.8.4 . Flask 1.1.2 . Flask-Compress 1.8.0 . future 0.18.2 . get-version 2.1 . gitdb 4.0.5 . GitPython 3.1.11 . h5py 3.1.0 . hyperopt 0.1.2 . idna 2.8 . importlib-metadata 2.0.0 . iniconfig 1.1.1 . ipdb 0.13.4 . ipykernel 5.3.4 . ipympl 0.5.8 . ipython 7.19.0 . ipython-genutils 0.2.0 . ipywidgets 7.5.1 . isort 5.6.4 . itsdangerous 1.1.0 . jedi 0.17.2 . Jinja2 2.11.2 . jmespath 0.10.0 . joblib 0.17.0 . json5 0.9.5 . jsonschema 3.2.0 . jupyter-client 6.1.7 . jupyter-core 4.6.3 . jupyter-dash 0.3.1 . jupyter-lsp 0.9.2 . jupyterlab 2.2.9 . jupyterlab-code-formatter 1.3.6 . jupyterlab-git 0.23.1 . jupyterlab-latex 2.0.0 . jupyterlab-pygments 0.1.2 . jupyterlab-server 1.2.0 . jupyterlab-sql 0.3.3 . jupyterlab-templates 0.2.5 . jupytext 1.6.0 . kiwisolver 1.3.1 . lazy-object-proxy 1.4.3 . legacy-api-wrap 1.2 . llvmlite 0.34.0 . markdown-it-py 0.5.6 . MarkupSafe 1.1.1 . matplotlib 3.3.3 . mccabe 0.6.1 . mistune 0.8.4 . mypy-extensions 0.4.3 . natsort 7.0.1 . nbclient 0.5.1 . nbconvert 6.0.7 . nbdime 2.1.0 . nbformat 5.0.8 . nbresuse 0.3.6 . nest-asyncio 1.4.3 .,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1496
https://github.com/scverse/scanpy/issues/1496:5218,modifiability,extens,extensions,5218,tro-info 0.23ubuntu1 . entrypoints 0.3 . fastcore 1.3.5 . flake8 3.8.4 . Flask 1.1.2 . Flask-Compress 1.8.0 . future 0.18.2 . get-version 2.1 . gitdb 4.0.5 . GitPython 3.1.11 . h5py 3.1.0 . hyperopt 0.1.2 . idna 2.8 . importlib-metadata 2.0.0 . iniconfig 1.1.1 . ipdb 0.13.4 . ipykernel 5.3.4 . ipympl 0.5.8 . ipython 7.19.0 . ipython-genutils 0.2.0 . ipywidgets 7.5.1 . isort 5.6.4 . itsdangerous 1.1.0 . jedi 0.17.2 . Jinja2 2.11.2 . jmespath 0.10.0 . joblib 0.17.0 . json5 0.9.5 . jsonschema 3.2.0 . jupyter-client 6.1.7 . jupyter-core 4.6.3 . jupyter-dash 0.3.1 . jupyter-lsp 0.9.2 . jupyterlab 2.2.9 . jupyterlab-code-formatter 1.3.6 . jupyterlab-git 0.23.1 . jupyterlab-latex 2.0.0 . jupyterlab-pygments 0.1.2 . jupyterlab-server 1.2.0 . jupyterlab-sql 0.3.3 . jupyterlab-templates 0.2.5 . jupytext 1.6.0 . kiwisolver 1.3.1 . lazy-object-proxy 1.4.3 . legacy-api-wrap 1.2 . llvmlite 0.34.0 . markdown-it-py 0.5.6 . MarkupSafe 1.1.1 . matplotlib 3.3.3 . mccabe 0.6.1 . mistune 0.8.4 . mypy-extensions 0.4.3 . natsort 7.0.1 . nbclient 0.5.1 . nbconvert 6.0.7 . nbdime 2.1.0 . nbformat 5.0.8 . nbresuse 0.3.6 . nest-asyncio 1.4.3 . networkx 2.5 . notebook 6.1.5 . numba 0.51.2 . numexpr 2.7.1 . numpy 1.19.4 . packaging 20.4 . pandas 1.1.4 . pandocfilters 1.4.3 . parso 0.7.1 . path 15.0.0 . pathspec 0.8.1 . pathtools 0.1.2 . patsy 0.5.1 . peepdis 0.1.13 . pexpect 4.8.0 . pickleshare 0.7.5 . Pillow 8.0.1 . pip 20.0.2 . plotly 4.12.0 . pluggy 0.13.1 . prometheus-client 0.8.0 . prompt-toolkit 3.0.8 . psutil 5.7.3 . ptvsd 4.3.2 . ptyprocess 0.6.0 . py 1.9.0 . pycodestyle 2.6.0 . pycparser 2.20 . pydocstyle 5.1.1 . pyflakes 2.2.0 . Pygments 2.7.2 . PyGObject 3.36.0 . pylint 2.6.0 . pymongo 3.11.0 . pyparsing 2.4.7 . pyrsistent 0.17.3 . pytest 6.1.2 . python-apt 2.0.0+ubuntu0.20.4.1 . python-dateutil 2.8.1 . python-debian 0.1.36ubuntu1 . python-jsonrpc-server 0.4.0 . python-language-server 0.36.1 . pytoml 0.1.21 . pytz 2020.4 . PyYAML 5.3.1 . pyzmq 20.0.0 . regex 2020.11.13 . requests 2.2,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1496
https://github.com/scverse/scanpy/issues/1496:5436,modifiability,pac,packaging,5436,importlib-metadata 2.0.0 . iniconfig 1.1.1 . ipdb 0.13.4 . ipykernel 5.3.4 . ipympl 0.5.8 . ipython 7.19.0 . ipython-genutils 0.2.0 . ipywidgets 7.5.1 . isort 5.6.4 . itsdangerous 1.1.0 . jedi 0.17.2 . Jinja2 2.11.2 . jmespath 0.10.0 . joblib 0.17.0 . json5 0.9.5 . jsonschema 3.2.0 . jupyter-client 6.1.7 . jupyter-core 4.6.3 . jupyter-dash 0.3.1 . jupyter-lsp 0.9.2 . jupyterlab 2.2.9 . jupyterlab-code-formatter 1.3.6 . jupyterlab-git 0.23.1 . jupyterlab-latex 2.0.0 . jupyterlab-pygments 0.1.2 . jupyterlab-server 1.2.0 . jupyterlab-sql 0.3.3 . jupyterlab-templates 0.2.5 . jupytext 1.6.0 . kiwisolver 1.3.1 . lazy-object-proxy 1.4.3 . legacy-api-wrap 1.2 . llvmlite 0.34.0 . markdown-it-py 0.5.6 . MarkupSafe 1.1.1 . matplotlib 3.3.3 . mccabe 0.6.1 . mistune 0.8.4 . mypy-extensions 0.4.3 . natsort 7.0.1 . nbclient 0.5.1 . nbconvert 6.0.7 . nbdime 2.1.0 . nbformat 5.0.8 . nbresuse 0.3.6 . nest-asyncio 1.4.3 . networkx 2.5 . notebook 6.1.5 . numba 0.51.2 . numexpr 2.7.1 . numpy 1.19.4 . packaging 20.4 . pandas 1.1.4 . pandocfilters 1.4.3 . parso 0.7.1 . path 15.0.0 . pathspec 0.8.1 . pathtools 0.1.2 . patsy 0.5.1 . peepdis 0.1.13 . pexpect 4.8.0 . pickleshare 0.7.5 . Pillow 8.0.1 . pip 20.0.2 . plotly 4.12.0 . pluggy 0.13.1 . prometheus-client 0.8.0 . prompt-toolkit 3.0.8 . psutil 5.7.3 . ptvsd 4.3.2 . ptyprocess 0.6.0 . py 1.9.0 . pycodestyle 2.6.0 . pycparser 2.20 . pydocstyle 5.1.1 . pyflakes 2.2.0 . Pygments 2.7.2 . PyGObject 3.36.0 . pylint 2.6.0 . pymongo 3.11.0 . pyparsing 2.4.7 . pyrsistent 0.17.3 . pytest 6.1.2 . python-apt 2.0.0+ubuntu0.20.4.1 . python-dateutil 2.8.1 . python-debian 0.1.36ubuntu1 . python-jsonrpc-server 0.4.0 . python-language-server 0.36.1 . pytoml 0.1.21 . pytz 2020.4 . PyYAML 5.3.1 . pyzmq 20.0.0 . regex 2020.11.13 . requests 2.22.0 . requests-unixsocket 0.2.0 . retrying 1.3.3 . rich 9.2.0 . rope 0.18.0 . scikit-learn 0.23.2 . scikit-misc 0.1.3 . scipy 1.5.4 . scriptedforms 0.10.1 . scvi-tools 0.7.1 . seaborn 0.11.0 . Send2Trash 1.5.0 . setupt,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1496
https://github.com/scverse/scanpy/issues/1496:6812,modifiability,extens,extensions,6812,ite 0.34.0 . markdown-it-py 0.5.6 . MarkupSafe 1.1.1 . matplotlib 3.3.3 . mccabe 0.6.1 . mistune 0.8.4 . mypy-extensions 0.4.3 . natsort 7.0.1 . nbclient 0.5.1 . nbconvert 6.0.7 . nbdime 2.1.0 . nbformat 5.0.8 . nbresuse 0.3.6 . nest-asyncio 1.4.3 . networkx 2.5 . notebook 6.1.5 . numba 0.51.2 . numexpr 2.7.1 . numpy 1.19.4 . packaging 20.4 . pandas 1.1.4 . pandocfilters 1.4.3 . parso 0.7.1 . path 15.0.0 . pathspec 0.8.1 . pathtools 0.1.2 . patsy 0.5.1 . peepdis 0.1.13 . pexpect 4.8.0 . pickleshare 0.7.5 . Pillow 8.0.1 . pip 20.0.2 . plotly 4.12.0 . pluggy 0.13.1 . prometheus-client 0.8.0 . prompt-toolkit 3.0.8 . psutil 5.7.3 . ptvsd 4.3.2 . ptyprocess 0.6.0 . py 1.9.0 . pycodestyle 2.6.0 . pycparser 2.20 . pydocstyle 5.1.1 . pyflakes 2.2.0 . Pygments 2.7.2 . PyGObject 3.36.0 . pylint 2.6.0 . pymongo 3.11.0 . pyparsing 2.4.7 . pyrsistent 0.17.3 . pytest 6.1.2 . python-apt 2.0.0+ubuntu0.20.4.1 . python-dateutil 2.8.1 . python-debian 0.1.36ubuntu1 . python-jsonrpc-server 0.4.0 . python-language-server 0.36.1 . pytoml 0.1.21 . pytz 2020.4 . PyYAML 5.3.1 . pyzmq 20.0.0 . regex 2020.11.13 . requests 2.22.0 . requests-unixsocket 0.2.0 . retrying 1.3.3 . rich 9.2.0 . rope 0.18.0 . scikit-learn 0.23.2 . scikit-misc 0.1.3 . scipy 1.5.4 . scriptedforms 0.10.1 . scvi-tools 0.7.1 . seaborn 0.11.0 . Send2Trash 1.5.0 . setuptools 50.3.2 . setuptools-scm 4.1.2 . sinfo 0.3.1 . six 1.14.0 . smmap 3.0.4 . snowballstemmer 2.0.0 . SQLAlchemy 1.3.20 . statsmodels 0.12.1 . stdlib-list 0.7.0 . tables 3.6.1 . termcolor 1.1.0 . terminado 0.9.1 . testpath 0.4.4 . threadpoolctl 2.1.0 . toml 0.10.2 . torch 1.7.0 . tornado 6.1 . tqdm 4.51.0 . traitlets 5.0.5 . typed-ast 1.4.1 . typeguard 2.10.0 . typing-extensions 3.7.4.3 . ujson 4.0.1 . umap-learn 0.4.6 . unattended-upgrades 0.1 . urllib3 1.25.8 . watchdog 0.10.3 . wcwidth 0.2.5 . webencodings 0.5.1 . Werkzeug 1.0.1 . wheel 0.35.1 . widgetsnbextension 3.5.1 . wrapt 1.12.1 . xeus-python 0.8.3 . xlrd 1.2.0 . yapf 0.30.0 . zipp 3.4.0. </details>.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1496
https://github.com/scverse/scanpy/issues/1496:6877,modifiability,upgrad,upgrades,6877,ite 0.34.0 . markdown-it-py 0.5.6 . MarkupSafe 1.1.1 . matplotlib 3.3.3 . mccabe 0.6.1 . mistune 0.8.4 . mypy-extensions 0.4.3 . natsort 7.0.1 . nbclient 0.5.1 . nbconvert 6.0.7 . nbdime 2.1.0 . nbformat 5.0.8 . nbresuse 0.3.6 . nest-asyncio 1.4.3 . networkx 2.5 . notebook 6.1.5 . numba 0.51.2 . numexpr 2.7.1 . numpy 1.19.4 . packaging 20.4 . pandas 1.1.4 . pandocfilters 1.4.3 . parso 0.7.1 . path 15.0.0 . pathspec 0.8.1 . pathtools 0.1.2 . patsy 0.5.1 . peepdis 0.1.13 . pexpect 4.8.0 . pickleshare 0.7.5 . Pillow 8.0.1 . pip 20.0.2 . plotly 4.12.0 . pluggy 0.13.1 . prometheus-client 0.8.0 . prompt-toolkit 3.0.8 . psutil 5.7.3 . ptvsd 4.3.2 . ptyprocess 0.6.0 . py 1.9.0 . pycodestyle 2.6.0 . pycparser 2.20 . pydocstyle 5.1.1 . pyflakes 2.2.0 . Pygments 2.7.2 . PyGObject 3.36.0 . pylint 2.6.0 . pymongo 3.11.0 . pyparsing 2.4.7 . pyrsistent 0.17.3 . pytest 6.1.2 . python-apt 2.0.0+ubuntu0.20.4.1 . python-dateutil 2.8.1 . python-debian 0.1.36ubuntu1 . python-jsonrpc-server 0.4.0 . python-language-server 0.36.1 . pytoml 0.1.21 . pytz 2020.4 . PyYAML 5.3.1 . pyzmq 20.0.0 . regex 2020.11.13 . requests 2.22.0 . requests-unixsocket 0.2.0 . retrying 1.3.3 . rich 9.2.0 . rope 0.18.0 . scikit-learn 0.23.2 . scikit-misc 0.1.3 . scipy 1.5.4 . scriptedforms 0.10.1 . scvi-tools 0.7.1 . seaborn 0.11.0 . Send2Trash 1.5.0 . setuptools 50.3.2 . setuptools-scm 4.1.2 . sinfo 0.3.1 . six 1.14.0 . smmap 3.0.4 . snowballstemmer 2.0.0 . SQLAlchemy 1.3.20 . statsmodels 0.12.1 . stdlib-list 0.7.0 . tables 3.6.1 . termcolor 1.1.0 . terminado 0.9.1 . testpath 0.4.4 . threadpoolctl 2.1.0 . toml 0.10.2 . torch 1.7.0 . tornado 6.1 . tqdm 4.51.0 . traitlets 5.0.5 . typed-ast 1.4.1 . typeguard 2.10.0 . typing-extensions 3.7.4.3 . ujson 4.0.1 . umap-learn 0.4.6 . unattended-upgrades 0.1 . urllib3 1.25.8 . watchdog 0.10.3 . wcwidth 0.2.5 . webencodings 0.5.1 . Werkzeug 1.0.1 . wheel 0.35.1 . widgetsnbextension 3.5.1 . wrapt 1.12.1 . xeus-python 0.8.3 . xlrd 1.2.0 . yapf 0.30.0 . zipp 3.4.0. </details>.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1496
https://github.com/scverse/scanpy/issues/1496:2267,performance,load,load,2267,"self.run_setup(). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/build_meta.py"", line 145, in run_setup. exec(compile(code, __file__, 'exec'), locals()) File ""setup.py"", line 17, in <module>. setup(. File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/__init__.py"", line 153, in setup. return distutils.core.setup(**attrs). File ""/usr/lib/python3.8/distutils/core.py"", line 108, in setup. _setup_distribution = dist = klass(attrs). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 423, in __init__. _Distribution.__init__(self, {. File ""/usr/lib/python3.8/distutils/dist.py"", line 292, in __init__. self.finalize_options() File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 695, in finalize_options. ep(self). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 702, in _finalize_setup_keywords. ep.load()(self, ep.name, value). File ""/usr/local/lib/python3.8/dist-packages/setuptools_scm/integration.py"", line 17, in version_keyword. dist.metadata.version = _get_version(config). File ""/usr/local/lib/python3.8/dist-packages/setuptools_scm/__init__.py"", line 148, in _get_version. parsed_version = _do_parse(config). File ""/usr/local/lib/python3.8/dist-packages/setuptools_scm/__init__.py"", line 110, in _do_parse raise LookupError(. LookupError: setuptools-scm was unable to detect version for '/home/ubuntu/code/scanpy'. Make sure you're either building from a fully intact git repository or PyPI tarballs. Most other sources (such as GitHub's tarballs, a git checkout without the .git folder) don't contain the necessary metadata and will not work. . For example, if you're using pip, instead of https://github.com/user/proj/archive/master.zip use git+https://github.com/user/proj.git#egg=proj```. ```. #### Versions. <details>. scanpy. problem is with installation, so scanpy.logging.print_versio",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1496
https://github.com/scverse/scanpy/issues/1496:5358,performance,network,networkx,5358,.1 . gitdb 4.0.5 . GitPython 3.1.11 . h5py 3.1.0 . hyperopt 0.1.2 . idna 2.8 . importlib-metadata 2.0.0 . iniconfig 1.1.1 . ipdb 0.13.4 . ipykernel 5.3.4 . ipympl 0.5.8 . ipython 7.19.0 . ipython-genutils 0.2.0 . ipywidgets 7.5.1 . isort 5.6.4 . itsdangerous 1.1.0 . jedi 0.17.2 . Jinja2 2.11.2 . jmespath 0.10.0 . joblib 0.17.0 . json5 0.9.5 . jsonschema 3.2.0 . jupyter-client 6.1.7 . jupyter-core 4.6.3 . jupyter-dash 0.3.1 . jupyter-lsp 0.9.2 . jupyterlab 2.2.9 . jupyterlab-code-formatter 1.3.6 . jupyterlab-git 0.23.1 . jupyterlab-latex 2.0.0 . jupyterlab-pygments 0.1.2 . jupyterlab-server 1.2.0 . jupyterlab-sql 0.3.3 . jupyterlab-templates 0.2.5 . jupytext 1.6.0 . kiwisolver 1.3.1 . lazy-object-proxy 1.4.3 . legacy-api-wrap 1.2 . llvmlite 0.34.0 . markdown-it-py 0.5.6 . MarkupSafe 1.1.1 . matplotlib 3.3.3 . mccabe 0.6.1 . mistune 0.8.4 . mypy-extensions 0.4.3 . natsort 7.0.1 . nbclient 0.5.1 . nbconvert 6.0.7 . nbdime 2.1.0 . nbformat 5.0.8 . nbresuse 0.3.6 . nest-asyncio 1.4.3 . networkx 2.5 . notebook 6.1.5 . numba 0.51.2 . numexpr 2.7.1 . numpy 1.19.4 . packaging 20.4 . pandas 1.1.4 . pandocfilters 1.4.3 . parso 0.7.1 . path 15.0.0 . pathspec 0.8.1 . pathtools 0.1.2 . patsy 0.5.1 . peepdis 0.1.13 . pexpect 4.8.0 . pickleshare 0.7.5 . Pillow 8.0.1 . pip 20.0.2 . plotly 4.12.0 . pluggy 0.13.1 . prometheus-client 0.8.0 . prompt-toolkit 3.0.8 . psutil 5.7.3 . ptvsd 4.3.2 . ptyprocess 0.6.0 . py 1.9.0 . pycodestyle 2.6.0 . pycparser 2.20 . pydocstyle 5.1.1 . pyflakes 2.2.0 . Pygments 2.7.2 . PyGObject 3.36.0 . pylint 2.6.0 . pymongo 3.11.0 . pyparsing 2.4.7 . pyrsistent 0.17.3 . pytest 6.1.2 . python-apt 2.0.0+ubuntu0.20.4.1 . python-dateutil 2.8.1 . python-debian 0.1.36ubuntu1 . python-jsonrpc-server 0.4.0 . python-language-server 0.36.1 . pytoml 0.1.21 . pytz 2020.4 . PyYAML 5.3.1 . pyzmq 20.0.0 . regex 2020.11.13 . requests 2.22.0 . requests-unixsocket 0.2.0 . retrying 1.3.3 . rich 9.2.0 . rope 0.18.0 . scikit-learn 0.23.2 . scikit-misc 0.1.3 . scipy 1.5.4 . scrip,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1496
https://github.com/scverse/scanpy/issues/1496:487,reliability,doe,does,487,"`pip install -e .` raises LookupError: setuptools-scm was unable to detect version for '/home/ubuntu/code/scanpy'.; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. setuptools-scm can't find the package version when running `pip install -e` or `pip install .`. I stepped through `scanpy/_metadata.py`, and it does appear to be able to get `__version__` via `setuptools_scm.get_version` as opposed to using `._compat`. It seems like it may either be an issue with `setuptools_scm` itself or the combination of my environment and `pyproject.toml`. Any ideas? ### Minimal code sample (that we can copy&paste without having any data). ```bash. pip install -e . ```. ```pytb. File ""/tmp/tmp7fu14tjf"", line 280, in <module>. main(). File ""/tmp/tmp7fu14tjf"", line 263, in main. json_out['return_val'] = hook(**hook_input['kwargs']). File ""/tmp/tmp7fu14tjf"", line 133, in prepare_metadata_for_build_wheel. return hook(metadata_directory, config_settings). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/build_meta.py"", line 161, in prepare_metadata_for_build_wheel self.run_setup(). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/build_meta.py"", line 145, in run_setup. exec(compile(code, __file__, 'exec'), locals()) File ""setup.py"", line 17, in <module>. setup(. File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/__init__.py"", line 153, in setup. return distutils.core.setup(**attrs). File ""/usr/lib/python3.8/distutils/core.py"", line 108, in setup. _setup_distribution = dist = klass(attrs). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 423, in __init__. _Distribution.__init__(self, {. File ""/usr/lib/python3.8/distutils/dist.py"", line 292, in __init__. self.finalize_options(",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1496
https://github.com/scverse/scanpy/issues/1496:2357,reliability,integr,integration,2357,"ools/build_meta.py"", line 145, in run_setup. exec(compile(code, __file__, 'exec'), locals()) File ""setup.py"", line 17, in <module>. setup(. File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/__init__.py"", line 153, in setup. return distutils.core.setup(**attrs). File ""/usr/lib/python3.8/distutils/core.py"", line 108, in setup. _setup_distribution = dist = klass(attrs). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 423, in __init__. _Distribution.__init__(self, {. File ""/usr/lib/python3.8/distutils/dist.py"", line 292, in __init__. self.finalize_options() File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 695, in finalize_options. ep(self). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 702, in _finalize_setup_keywords. ep.load()(self, ep.name, value). File ""/usr/local/lib/python3.8/dist-packages/setuptools_scm/integration.py"", line 17, in version_keyword. dist.metadata.version = _get_version(config). File ""/usr/local/lib/python3.8/dist-packages/setuptools_scm/__init__.py"", line 148, in _get_version. parsed_version = _do_parse(config). File ""/usr/local/lib/python3.8/dist-packages/setuptools_scm/__init__.py"", line 110, in _do_parse raise LookupError(. LookupError: setuptools-scm was unable to detect version for '/home/ubuntu/code/scanpy'. Make sure you're either building from a fully intact git repository or PyPI tarballs. Most other sources (such as GitHub's tarballs, a git checkout without the .git folder) don't contain the necessary metadata and will not work. . For example, if you're using pip, instead of https://github.com/user/proj/archive/master.zip use git+https://github.com/user/proj.git#egg=proj```. ```. #### Versions. <details>. scanpy. problem is with installation, so scanpy.logging.print_versions(). commit: ef5a8ee57c2aef7778a069a49101a8998718e6d5. python. 3.8.5. pip. 20.0.2 . ubuntu. 2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1496
https://github.com/scverse/scanpy/issues/1496:68,safety,detect,detect,68,"`pip install -e .` raises LookupError: setuptools-scm was unable to detect version for '/home/ubuntu/code/scanpy'.; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. setuptools-scm can't find the package version when running `pip install -e` or `pip install .`. I stepped through `scanpy/_metadata.py`, and it does appear to be able to get `__version__` via `setuptools_scm.get_version` as opposed to using `._compat`. It seems like it may either be an issue with `setuptools_scm` itself or the combination of my environment and `pyproject.toml`. Any ideas? ### Minimal code sample (that we can copy&paste without having any data). ```bash. pip install -e . ```. ```pytb. File ""/tmp/tmp7fu14tjf"", line 280, in <module>. main(). File ""/tmp/tmp7fu14tjf"", line 263, in main. json_out['return_val'] = hook(**hook_input['kwargs']). File ""/tmp/tmp7fu14tjf"", line 133, in prepare_metadata_for_build_wheel. return hook(metadata_directory, config_settings). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/build_meta.py"", line 161, in prepare_metadata_for_build_wheel self.run_setup(). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/build_meta.py"", line 145, in run_setup. exec(compile(code, __file__, 'exec'), locals()) File ""setup.py"", line 17, in <module>. setup(. File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/__init__.py"", line 153, in setup. return distutils.core.setup(**attrs). File ""/usr/lib/python3.8/distutils/core.py"", line 108, in setup. _setup_distribution = dist = klass(attrs). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 423, in __init__. _Distribution.__init__(self, {. File ""/usr/lib/python3.8/distutils/dist.py"", line 292, in __init__. self.finalize_options(",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1496
https://github.com/scverse/scanpy/issues/1496:888,safety,modul,module,888,"`pip install -e .` raises LookupError: setuptools-scm was unable to detect version for '/home/ubuntu/code/scanpy'.; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. setuptools-scm can't find the package version when running `pip install -e` or `pip install .`. I stepped through `scanpy/_metadata.py`, and it does appear to be able to get `__version__` via `setuptools_scm.get_version` as opposed to using `._compat`. It seems like it may either be an issue with `setuptools_scm` itself or the combination of my environment and `pyproject.toml`. Any ideas? ### Minimal code sample (that we can copy&paste without having any data). ```bash. pip install -e . ```. ```pytb. File ""/tmp/tmp7fu14tjf"", line 280, in <module>. main(). File ""/tmp/tmp7fu14tjf"", line 263, in main. json_out['return_val'] = hook(**hook_input['kwargs']). File ""/tmp/tmp7fu14tjf"", line 133, in prepare_metadata_for_build_wheel. return hook(metadata_directory, config_settings). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/build_meta.py"", line 161, in prepare_metadata_for_build_wheel self.run_setup(). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/build_meta.py"", line 145, in run_setup. exec(compile(code, __file__, 'exec'), locals()) File ""setup.py"", line 17, in <module>. setup(. File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/__init__.py"", line 153, in setup. return distutils.core.setup(**attrs). File ""/usr/lib/python3.8/distutils/core.py"", line 108, in setup. _setup_distribution = dist = klass(attrs). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 423, in __init__. _Distribution.__init__(self, {. File ""/usr/lib/python3.8/distutils/dist.py"", line 292, in __init__. self.finalize_options(",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1496
https://github.com/scverse/scanpy/issues/1496:1486,safety,modul,module,1486,"es appear to be able to get `__version__` via `setuptools_scm.get_version` as opposed to using `._compat`. It seems like it may either be an issue with `setuptools_scm` itself or the combination of my environment and `pyproject.toml`. Any ideas? ### Minimal code sample (that we can copy&paste without having any data). ```bash. pip install -e . ```. ```pytb. File ""/tmp/tmp7fu14tjf"", line 280, in <module>. main(). File ""/tmp/tmp7fu14tjf"", line 263, in main. json_out['return_val'] = hook(**hook_input['kwargs']). File ""/tmp/tmp7fu14tjf"", line 133, in prepare_metadata_for_build_wheel. return hook(metadata_directory, config_settings). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/build_meta.py"", line 161, in prepare_metadata_for_build_wheel self.run_setup(). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/build_meta.py"", line 145, in run_setup. exec(compile(code, __file__, 'exec'), locals()) File ""setup.py"", line 17, in <module>. setup(. File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/__init__.py"", line 153, in setup. return distutils.core.setup(**attrs). File ""/usr/lib/python3.8/distutils/core.py"", line 108, in setup. _setup_distribution = dist = klass(attrs). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 423, in __init__. _Distribution.__init__(self, {. File ""/usr/lib/python3.8/distutils/dist.py"", line 292, in __init__. self.finalize_options() File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 695, in finalize_options. ep(self). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 702, in _finalize_setup_keywords. ep.load()(self, ep.name, value). File ""/usr/local/lib/python3.8/dist-packages/setuptools_scm/integration.py"", line 17, in version_keyword. dist.metadata.version = _get_version(config). File ""/usr/local/lib/python3.8/dist-pack",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1496
https://github.com/scverse/scanpy/issues/1496:2745,safety,detect,detect,2745,"= klass(attrs). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 423, in __init__. _Distribution.__init__(self, {. File ""/usr/lib/python3.8/distutils/dist.py"", line 292, in __init__. self.finalize_options() File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 695, in finalize_options. ep(self). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 702, in _finalize_setup_keywords. ep.load()(self, ep.name, value). File ""/usr/local/lib/python3.8/dist-packages/setuptools_scm/integration.py"", line 17, in version_keyword. dist.metadata.version = _get_version(config). File ""/usr/local/lib/python3.8/dist-packages/setuptools_scm/__init__.py"", line 148, in _get_version. parsed_version = _do_parse(config). File ""/usr/local/lib/python3.8/dist-packages/setuptools_scm/__init__.py"", line 110, in _do_parse raise LookupError(. LookupError: setuptools-scm was unable to detect version for '/home/ubuntu/code/scanpy'. Make sure you're either building from a fully intact git repository or PyPI tarballs. Most other sources (such as GitHub's tarballs, a git checkout without the .git folder) don't contain the necessary metadata and will not work. . For example, if you're using pip, instead of https://github.com/user/proj/archive/master.zip use git+https://github.com/user/proj.git#egg=proj```. ```. #### Versions. <details>. scanpy. problem is with installation, so scanpy.logging.print_versions(). commit: ef5a8ee57c2aef7778a069a49101a8998718e6d5. python. 3.8.5. pip. 20.0.2 . ubuntu. 20.04. pip list. Package Version Location . ------------------------- -------------------- -----------------------------. analysaurus 0.0.1 /home/ubuntu/code/analysaurus. anndata 0.7.5 . ansi2html 1.5.2 . appdirs 1.4.4 . argon2-cffi 20.1.0 . astroid 2.4.2 . async-generator 1.10 . attrs 20.3.0 . autopep8 1.5.4 . backcall 0.2.0 . biopython 1.78 . black 20.8b1 . bleach 3.2.1 . bokeh 2.2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1496
https://github.com/scverse/scanpy/issues/1496:3249,safety,log,logging,3249,"_keywords. ep.load()(self, ep.name, value). File ""/usr/local/lib/python3.8/dist-packages/setuptools_scm/integration.py"", line 17, in version_keyword. dist.metadata.version = _get_version(config). File ""/usr/local/lib/python3.8/dist-packages/setuptools_scm/__init__.py"", line 148, in _get_version. parsed_version = _do_parse(config). File ""/usr/local/lib/python3.8/dist-packages/setuptools_scm/__init__.py"", line 110, in _do_parse raise LookupError(. LookupError: setuptools-scm was unable to detect version for '/home/ubuntu/code/scanpy'. Make sure you're either building from a fully intact git repository or PyPI tarballs. Most other sources (such as GitHub's tarballs, a git checkout without the .git folder) don't contain the necessary metadata and will not work. . For example, if you're using pip, instead of https://github.com/user/proj/archive/master.zip use git+https://github.com/user/proj.git#egg=proj```. ```. #### Versions. <details>. scanpy. problem is with installation, so scanpy.logging.print_versions(). commit: ef5a8ee57c2aef7778a069a49101a8998718e6d5. python. 3.8.5. pip. 20.0.2 . ubuntu. 20.04. pip list. Package Version Location . ------------------------- -------------------- -----------------------------. analysaurus 0.0.1 /home/ubuntu/code/analysaurus. anndata 0.7.5 . ansi2html 1.5.2 . appdirs 1.4.4 . argon2-cffi 20.1.0 . astroid 2.4.2 . async-generator 1.10 . attrs 20.3.0 . autopep8 1.5.4 . backcall 0.2.0 . biopython 1.78 . black 20.8b1 . bleach 3.2.1 . bokeh 2.2.3 . botocore 1.19.18 . Brotli 1.0.9 . cellforest 0.0.2 /home/ubuntu/code/cellforest . certifi 2019.11.28 . cffi 1.14.3 . chardet 3.0.4 . click 7.1.2 . colorama 0.4.4 . commonmark 0.9.1 . cycler 0.10.0 . dash 1.17.0 . dash-building-blocks 0.1.2 . dash-core-components 1.13.0 . dash-html-components 1.1.1 . dash-renderer 1.8.3 . dash-table 4.11.0 . dataclasses 0.6 . dataforest 0.0.2 /home/ubuntu/code/dataforest . dbus-python 1.2.16 . decorator 4.4.2 . defusedxml 0.6.0 . distro-info 0.23ubuntu1 . entrypo",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1496
https://github.com/scverse/scanpy/issues/1496:6655,safety,test,testpath,6655,ite 0.34.0 . markdown-it-py 0.5.6 . MarkupSafe 1.1.1 . matplotlib 3.3.3 . mccabe 0.6.1 . mistune 0.8.4 . mypy-extensions 0.4.3 . natsort 7.0.1 . nbclient 0.5.1 . nbconvert 6.0.7 . nbdime 2.1.0 . nbformat 5.0.8 . nbresuse 0.3.6 . nest-asyncio 1.4.3 . networkx 2.5 . notebook 6.1.5 . numba 0.51.2 . numexpr 2.7.1 . numpy 1.19.4 . packaging 20.4 . pandas 1.1.4 . pandocfilters 1.4.3 . parso 0.7.1 . path 15.0.0 . pathspec 0.8.1 . pathtools 0.1.2 . patsy 0.5.1 . peepdis 0.1.13 . pexpect 4.8.0 . pickleshare 0.7.5 . Pillow 8.0.1 . pip 20.0.2 . plotly 4.12.0 . pluggy 0.13.1 . prometheus-client 0.8.0 . prompt-toolkit 3.0.8 . psutil 5.7.3 . ptvsd 4.3.2 . ptyprocess 0.6.0 . py 1.9.0 . pycodestyle 2.6.0 . pycparser 2.20 . pydocstyle 5.1.1 . pyflakes 2.2.0 . Pygments 2.7.2 . PyGObject 3.36.0 . pylint 2.6.0 . pymongo 3.11.0 . pyparsing 2.4.7 . pyrsistent 0.17.3 . pytest 6.1.2 . python-apt 2.0.0+ubuntu0.20.4.1 . python-dateutil 2.8.1 . python-debian 0.1.36ubuntu1 . python-jsonrpc-server 0.4.0 . python-language-server 0.36.1 . pytoml 0.1.21 . pytz 2020.4 . PyYAML 5.3.1 . pyzmq 20.0.0 . regex 2020.11.13 . requests 2.22.0 . requests-unixsocket 0.2.0 . retrying 1.3.3 . rich 9.2.0 . rope 0.18.0 . scikit-learn 0.23.2 . scikit-misc 0.1.3 . scipy 1.5.4 . scriptedforms 0.10.1 . scvi-tools 0.7.1 . seaborn 0.11.0 . Send2Trash 1.5.0 . setuptools 50.3.2 . setuptools-scm 4.1.2 . sinfo 0.3.1 . six 1.14.0 . smmap 3.0.4 . snowballstemmer 2.0.0 . SQLAlchemy 1.3.20 . statsmodels 0.12.1 . stdlib-list 0.7.0 . tables 3.6.1 . termcolor 1.1.0 . terminado 0.9.1 . testpath 0.4.4 . threadpoolctl 2.1.0 . toml 0.10.2 . torch 1.7.0 . tornado 6.1 . tqdm 4.51.0 . traitlets 5.0.5 . typed-ast 1.4.1 . typeguard 2.10.0 . typing-extensions 3.7.4.3 . ujson 4.0.1 . umap-learn 0.4.6 . unattended-upgrades 0.1 . urllib3 1.25.8 . watchdog 0.10.3 . wcwidth 0.2.5 . webencodings 0.5.1 . Werkzeug 1.0.1 . wheel 0.35.1 . widgetsnbextension 3.5.1 . wrapt 1.12.1 . xeus-python 0.8.3 . xlrd 1.2.0 . yapf 0.30.0 . zipp 3.4.0. </details>.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1496
https://github.com/scverse/scanpy/issues/1496:6909,safety,watchdog,watchdog,6909,ite 0.34.0 . markdown-it-py 0.5.6 . MarkupSafe 1.1.1 . matplotlib 3.3.3 . mccabe 0.6.1 . mistune 0.8.4 . mypy-extensions 0.4.3 . natsort 7.0.1 . nbclient 0.5.1 . nbconvert 6.0.7 . nbdime 2.1.0 . nbformat 5.0.8 . nbresuse 0.3.6 . nest-asyncio 1.4.3 . networkx 2.5 . notebook 6.1.5 . numba 0.51.2 . numexpr 2.7.1 . numpy 1.19.4 . packaging 20.4 . pandas 1.1.4 . pandocfilters 1.4.3 . parso 0.7.1 . path 15.0.0 . pathspec 0.8.1 . pathtools 0.1.2 . patsy 0.5.1 . peepdis 0.1.13 . pexpect 4.8.0 . pickleshare 0.7.5 . Pillow 8.0.1 . pip 20.0.2 . plotly 4.12.0 . pluggy 0.13.1 . prometheus-client 0.8.0 . prompt-toolkit 3.0.8 . psutil 5.7.3 . ptvsd 4.3.2 . ptyprocess 0.6.0 . py 1.9.0 . pycodestyle 2.6.0 . pycparser 2.20 . pydocstyle 5.1.1 . pyflakes 2.2.0 . Pygments 2.7.2 . PyGObject 3.36.0 . pylint 2.6.0 . pymongo 3.11.0 . pyparsing 2.4.7 . pyrsistent 0.17.3 . pytest 6.1.2 . python-apt 2.0.0+ubuntu0.20.4.1 . python-dateutil 2.8.1 . python-debian 0.1.36ubuntu1 . python-jsonrpc-server 0.4.0 . python-language-server 0.36.1 . pytoml 0.1.21 . pytz 2020.4 . PyYAML 5.3.1 . pyzmq 20.0.0 . regex 2020.11.13 . requests 2.22.0 . requests-unixsocket 0.2.0 . retrying 1.3.3 . rich 9.2.0 . rope 0.18.0 . scikit-learn 0.23.2 . scikit-misc 0.1.3 . scipy 1.5.4 . scriptedforms 0.10.1 . scvi-tools 0.7.1 . seaborn 0.11.0 . Send2Trash 1.5.0 . setuptools 50.3.2 . setuptools-scm 4.1.2 . sinfo 0.3.1 . six 1.14.0 . smmap 3.0.4 . snowballstemmer 2.0.0 . SQLAlchemy 1.3.20 . statsmodels 0.12.1 . stdlib-list 0.7.0 . tables 3.6.1 . termcolor 1.1.0 . terminado 0.9.1 . testpath 0.4.4 . threadpoolctl 2.1.0 . toml 0.10.2 . torch 1.7.0 . tornado 6.1 . tqdm 4.51.0 . traitlets 5.0.5 . typed-ast 1.4.1 . typeguard 2.10.0 . typing-extensions 3.7.4.3 . ujson 4.0.1 . umap-learn 0.4.6 . unattended-upgrades 0.1 . urllib3 1.25.8 . watchdog 0.10.3 . wcwidth 0.2.5 . webencodings 0.5.1 . Werkzeug 1.0.1 . wheel 0.35.1 . widgetsnbextension 3.5.1 . wrapt 1.12.1 . xeus-python 0.8.3 . xlrd 1.2.0 . yapf 0.30.0 . zipp 3.4.0. </details>.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1496
https://github.com/scverse/scanpy/issues/1496:68,security,detect,detect,68,"`pip install -e .` raises LookupError: setuptools-scm was unable to detect version for '/home/ubuntu/code/scanpy'.; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. setuptools-scm can't find the package version when running `pip install -e` or `pip install .`. I stepped through `scanpy/_metadata.py`, and it does appear to be able to get `__version__` via `setuptools_scm.get_version` as opposed to using `._compat`. It seems like it may either be an issue with `setuptools_scm` itself or the combination of my environment and `pyproject.toml`. Any ideas? ### Minimal code sample (that we can copy&paste without having any data). ```bash. pip install -e . ```. ```pytb. File ""/tmp/tmp7fu14tjf"", line 280, in <module>. main(). File ""/tmp/tmp7fu14tjf"", line 263, in main. json_out['return_val'] = hook(**hook_input['kwargs']). File ""/tmp/tmp7fu14tjf"", line 133, in prepare_metadata_for_build_wheel. return hook(metadata_directory, config_settings). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/build_meta.py"", line 161, in prepare_metadata_for_build_wheel self.run_setup(). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/build_meta.py"", line 145, in run_setup. exec(compile(code, __file__, 'exec'), locals()) File ""setup.py"", line 17, in <module>. setup(. File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/__init__.py"", line 153, in setup. return distutils.core.setup(**attrs). File ""/usr/lib/python3.8/distutils/core.py"", line 108, in setup. _setup_distribution = dist = klass(attrs). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 423, in __init__. _Distribution.__init__(self, {. File ""/usr/lib/python3.8/distutils/dist.py"", line 292, in __init__. self.finalize_options(",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1496
https://github.com/scverse/scanpy/issues/1496:2357,security,integr,integration,2357,"ools/build_meta.py"", line 145, in run_setup. exec(compile(code, __file__, 'exec'), locals()) File ""setup.py"", line 17, in <module>. setup(. File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/__init__.py"", line 153, in setup. return distutils.core.setup(**attrs). File ""/usr/lib/python3.8/distutils/core.py"", line 108, in setup. _setup_distribution = dist = klass(attrs). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 423, in __init__. _Distribution.__init__(self, {. File ""/usr/lib/python3.8/distutils/dist.py"", line 292, in __init__. self.finalize_options() File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 695, in finalize_options. ep(self). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 702, in _finalize_setup_keywords. ep.load()(self, ep.name, value). File ""/usr/local/lib/python3.8/dist-packages/setuptools_scm/integration.py"", line 17, in version_keyword. dist.metadata.version = _get_version(config). File ""/usr/local/lib/python3.8/dist-packages/setuptools_scm/__init__.py"", line 148, in _get_version. parsed_version = _do_parse(config). File ""/usr/local/lib/python3.8/dist-packages/setuptools_scm/__init__.py"", line 110, in _do_parse raise LookupError(. LookupError: setuptools-scm was unable to detect version for '/home/ubuntu/code/scanpy'. Make sure you're either building from a fully intact git repository or PyPI tarballs. Most other sources (such as GitHub's tarballs, a git checkout without the .git folder) don't contain the necessary metadata and will not work. . For example, if you're using pip, instead of https://github.com/user/proj/archive/master.zip use git+https://github.com/user/proj.git#egg=proj```. ```. #### Versions. <details>. scanpy. problem is with installation, so scanpy.logging.print_versions(). commit: ef5a8ee57c2aef7778a069a49101a8998718e6d5. python. 3.8.5. pip. 20.0.2 . ubuntu. 2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1496
https://github.com/scverse/scanpy/issues/1496:2745,security,detect,detect,2745,"= klass(attrs). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 423, in __init__. _Distribution.__init__(self, {. File ""/usr/lib/python3.8/distutils/dist.py"", line 292, in __init__. self.finalize_options() File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 695, in finalize_options. ep(self). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 702, in _finalize_setup_keywords. ep.load()(self, ep.name, value). File ""/usr/local/lib/python3.8/dist-packages/setuptools_scm/integration.py"", line 17, in version_keyword. dist.metadata.version = _get_version(config). File ""/usr/local/lib/python3.8/dist-packages/setuptools_scm/__init__.py"", line 148, in _get_version. parsed_version = _do_parse(config). File ""/usr/local/lib/python3.8/dist-packages/setuptools_scm/__init__.py"", line 110, in _do_parse raise LookupError(. LookupError: setuptools-scm was unable to detect version for '/home/ubuntu/code/scanpy'. Make sure you're either building from a fully intact git repository or PyPI tarballs. Most other sources (such as GitHub's tarballs, a git checkout without the .git folder) don't contain the necessary metadata and will not work. . For example, if you're using pip, instead of https://github.com/user/proj/archive/master.zip use git+https://github.com/user/proj.git#egg=proj```. ```. #### Versions. <details>. scanpy. problem is with installation, so scanpy.logging.print_versions(). commit: ef5a8ee57c2aef7778a069a49101a8998718e6d5. python. 3.8.5. pip. 20.0.2 . ubuntu. 20.04. pip list. Package Version Location . ------------------------- -------------------- -----------------------------. analysaurus 0.0.1 /home/ubuntu/code/analysaurus. anndata 0.7.5 . ansi2html 1.5.2 . appdirs 1.4.4 . argon2-cffi 20.1.0 . astroid 2.4.2 . async-generator 1.10 . attrs 20.3.0 . autopep8 1.5.4 . backcall 0.2.0 . biopython 1.78 . black 20.8b1 . bleach 3.2.1 . bokeh 2.2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1496
https://github.com/scverse/scanpy/issues/1496:3249,security,log,logging,3249,"_keywords. ep.load()(self, ep.name, value). File ""/usr/local/lib/python3.8/dist-packages/setuptools_scm/integration.py"", line 17, in version_keyword. dist.metadata.version = _get_version(config). File ""/usr/local/lib/python3.8/dist-packages/setuptools_scm/__init__.py"", line 148, in _get_version. parsed_version = _do_parse(config). File ""/usr/local/lib/python3.8/dist-packages/setuptools_scm/__init__.py"", line 110, in _do_parse raise LookupError(. LookupError: setuptools-scm was unable to detect version for '/home/ubuntu/code/scanpy'. Make sure you're either building from a fully intact git repository or PyPI tarballs. Most other sources (such as GitHub's tarballs, a git checkout without the .git folder) don't contain the necessary metadata and will not work. . For example, if you're using pip, instead of https://github.com/user/proj/archive/master.zip use git+https://github.com/user/proj.git#egg=proj```. ```. #### Versions. <details>. scanpy. problem is with installation, so scanpy.logging.print_versions(). commit: ef5a8ee57c2aef7778a069a49101a8998718e6d5. python. 3.8.5. pip. 20.0.2 . ubuntu. 20.04. pip list. Package Version Location . ------------------------- -------------------- -----------------------------. analysaurus 0.0.1 /home/ubuntu/code/analysaurus. anndata 0.7.5 . ansi2html 1.5.2 . appdirs 1.4.4 . argon2-cffi 20.1.0 . astroid 2.4.2 . async-generator 1.10 . attrs 20.3.0 . autopep8 1.5.4 . backcall 0.2.0 . biopython 1.78 . black 20.8b1 . bleach 3.2.1 . bokeh 2.2.3 . botocore 1.19.18 . Brotli 1.0.9 . cellforest 0.0.2 /home/ubuntu/code/cellforest . certifi 2019.11.28 . cffi 1.14.3 . chardet 3.0.4 . click 7.1.2 . colorama 0.4.4 . commonmark 0.9.1 . cycler 0.10.0 . dash 1.17.0 . dash-building-blocks 0.1.2 . dash-core-components 1.13.0 . dash-html-components 1.1.1 . dash-renderer 1.8.3 . dash-table 4.11.0 . dataclasses 0.6 . dataforest 0.0.2 /home/ubuntu/code/dataforest . dbus-python 1.2.16 . decorator 4.4.2 . defusedxml 0.6.0 . distro-info 0.23ubuntu1 . entrypo",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1496
https://github.com/scverse/scanpy/issues/1496:3835,security,certif,certifi,3835,"ntact git repository or PyPI tarballs. Most other sources (such as GitHub's tarballs, a git checkout without the .git folder) don't contain the necessary metadata and will not work. . For example, if you're using pip, instead of https://github.com/user/proj/archive/master.zip use git+https://github.com/user/proj.git#egg=proj```. ```. #### Versions. <details>. scanpy. problem is with installation, so scanpy.logging.print_versions(). commit: ef5a8ee57c2aef7778a069a49101a8998718e6d5. python. 3.8.5. pip. 20.0.2 . ubuntu. 20.04. pip list. Package Version Location . ------------------------- -------------------- -----------------------------. analysaurus 0.0.1 /home/ubuntu/code/analysaurus. anndata 0.7.5 . ansi2html 1.5.2 . appdirs 1.4.4 . argon2-cffi 20.1.0 . astroid 2.4.2 . async-generator 1.10 . attrs 20.3.0 . autopep8 1.5.4 . backcall 0.2.0 . biopython 1.78 . black 20.8b1 . bleach 3.2.1 . bokeh 2.2.3 . botocore 1.19.18 . Brotli 1.0.9 . cellforest 0.0.2 /home/ubuntu/code/cellforest . certifi 2019.11.28 . cffi 1.14.3 . chardet 3.0.4 . click 7.1.2 . colorama 0.4.4 . commonmark 0.9.1 . cycler 0.10.0 . dash 1.17.0 . dash-building-blocks 0.1.2 . dash-core-components 1.13.0 . dash-html-components 1.1.1 . dash-renderer 1.8.3 . dash-table 4.11.0 . dataclasses 0.6 . dataforest 0.0.2 /home/ubuntu/code/dataforest . dbus-python 1.2.16 . decorator 4.4.2 . defusedxml 0.6.0 . distro-info 0.23ubuntu1 . entrypoints 0.3 . fastcore 1.3.5 . flake8 3.8.4 . Flask 1.1.2 . Flask-Compress 1.8.0 . future 0.18.2 . get-version 2.1 . gitdb 4.0.5 . GitPython 3.1.11 . h5py 3.1.0 . hyperopt 0.1.2 . idna 2.8 . importlib-metadata 2.0.0 . iniconfig 1.1.1 . ipdb 0.13.4 . ipykernel 5.3.4 . ipympl 0.5.8 . ipython 7.19.0 . ipython-genutils 0.2.0 . ipywidgets 7.5.1 . isort 5.6.4 . itsdangerous 1.1.0 . jedi 0.17.2 . Jinja2 2.11.2 . jmespath 0.10.0 . joblib 0.17.0 . json5 0.9.5 . jsonschema 3.2.0 . jupyter-client 6.1.7 . jupyter-core 4.6.3 . jupyter-dash 0.3.1 . jupyter-lsp 0.9.2 . jupyterlab 2.2.9 . jupyterla",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1496
https://github.com/scverse/scanpy/issues/1496:4594,security,iso,isort,4594,.1.0 . astroid 2.4.2 . async-generator 1.10 . attrs 20.3.0 . autopep8 1.5.4 . backcall 0.2.0 . biopython 1.78 . black 20.8b1 . bleach 3.2.1 . bokeh 2.2.3 . botocore 1.19.18 . Brotli 1.0.9 . cellforest 0.0.2 /home/ubuntu/code/cellforest . certifi 2019.11.28 . cffi 1.14.3 . chardet 3.0.4 . click 7.1.2 . colorama 0.4.4 . commonmark 0.9.1 . cycler 0.10.0 . dash 1.17.0 . dash-building-blocks 0.1.2 . dash-core-components 1.13.0 . dash-html-components 1.1.1 . dash-renderer 1.8.3 . dash-table 4.11.0 . dataclasses 0.6 . dataforest 0.0.2 /home/ubuntu/code/dataforest . dbus-python 1.2.16 . decorator 4.4.2 . defusedxml 0.6.0 . distro-info 0.23ubuntu1 . entrypoints 0.3 . fastcore 1.3.5 . flake8 3.8.4 . Flask 1.1.2 . Flask-Compress 1.8.0 . future 0.18.2 . get-version 2.1 . gitdb 4.0.5 . GitPython 3.1.11 . h5py 3.1.0 . hyperopt 0.1.2 . idna 2.8 . importlib-metadata 2.0.0 . iniconfig 1.1.1 . ipdb 0.13.4 . ipykernel 5.3.4 . ipympl 0.5.8 . ipython 7.19.0 . ipython-genutils 0.2.0 . ipywidgets 7.5.1 . isort 5.6.4 . itsdangerous 1.1.0 . jedi 0.17.2 . Jinja2 2.11.2 . jmespath 0.10.0 . joblib 0.17.0 . json5 0.9.5 . jsonschema 3.2.0 . jupyter-client 6.1.7 . jupyter-core 4.6.3 . jupyter-dash 0.3.1 . jupyter-lsp 0.9.2 . jupyterlab 2.2.9 . jupyterlab-code-formatter 1.3.6 . jupyterlab-git 0.23.1 . jupyterlab-latex 2.0.0 . jupyterlab-pygments 0.1.2 . jupyterlab-server 1.2.0 . jupyterlab-sql 0.3.3 . jupyterlab-templates 0.2.5 . jupytext 1.6.0 . kiwisolver 1.3.1 . lazy-object-proxy 1.4.3 . legacy-api-wrap 1.2 . llvmlite 0.34.0 . markdown-it-py 0.5.6 . MarkupSafe 1.1.1 . matplotlib 3.3.3 . mccabe 0.6.1 . mistune 0.8.4 . mypy-extensions 0.4.3 . natsort 7.0.1 . nbclient 0.5.1 . nbconvert 6.0.7 . nbdime 2.1.0 . nbformat 5.0.8 . nbresuse 0.3.6 . nest-asyncio 1.4.3 . networkx 2.5 . notebook 6.1.5 . numba 0.51.2 . numexpr 2.7.1 . numpy 1.19.4 . packaging 20.4 . pandas 1.1.4 . pandocfilters 1.4.3 . parso 0.7.1 . path 15.0.0 . pathspec 0.8.1 . pathtools 0.1.2 . patsy 0.5.1 . peepdis 0.1.13 . pexpect 4.8.0,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1496
https://github.com/scverse/scanpy/issues/1496:5358,security,network,networkx,5358,.1 . gitdb 4.0.5 . GitPython 3.1.11 . h5py 3.1.0 . hyperopt 0.1.2 . idna 2.8 . importlib-metadata 2.0.0 . iniconfig 1.1.1 . ipdb 0.13.4 . ipykernel 5.3.4 . ipympl 0.5.8 . ipython 7.19.0 . ipython-genutils 0.2.0 . ipywidgets 7.5.1 . isort 5.6.4 . itsdangerous 1.1.0 . jedi 0.17.2 . Jinja2 2.11.2 . jmespath 0.10.0 . joblib 0.17.0 . json5 0.9.5 . jsonschema 3.2.0 . jupyter-client 6.1.7 . jupyter-core 4.6.3 . jupyter-dash 0.3.1 . jupyter-lsp 0.9.2 . jupyterlab 2.2.9 . jupyterlab-code-formatter 1.3.6 . jupyterlab-git 0.23.1 . jupyterlab-latex 2.0.0 . jupyterlab-pygments 0.1.2 . jupyterlab-server 1.2.0 . jupyterlab-sql 0.3.3 . jupyterlab-templates 0.2.5 . jupytext 1.6.0 . kiwisolver 1.3.1 . lazy-object-proxy 1.4.3 . legacy-api-wrap 1.2 . llvmlite 0.34.0 . markdown-it-py 0.5.6 . MarkupSafe 1.1.1 . matplotlib 3.3.3 . mccabe 0.6.1 . mistune 0.8.4 . mypy-extensions 0.4.3 . natsort 7.0.1 . nbclient 0.5.1 . nbconvert 6.0.7 . nbdime 2.1.0 . nbformat 5.0.8 . nbresuse 0.3.6 . nest-asyncio 1.4.3 . networkx 2.5 . notebook 6.1.5 . numba 0.51.2 . numexpr 2.7.1 . numpy 1.19.4 . packaging 20.4 . pandas 1.1.4 . pandocfilters 1.4.3 . parso 0.7.1 . path 15.0.0 . pathspec 0.8.1 . pathtools 0.1.2 . patsy 0.5.1 . peepdis 0.1.13 . pexpect 4.8.0 . pickleshare 0.7.5 . Pillow 8.0.1 . pip 20.0.2 . plotly 4.12.0 . pluggy 0.13.1 . prometheus-client 0.8.0 . prompt-toolkit 3.0.8 . psutil 5.7.3 . ptvsd 4.3.2 . ptyprocess 0.6.0 . py 1.9.0 . pycodestyle 2.6.0 . pycparser 2.20 . pydocstyle 5.1.1 . pyflakes 2.2.0 . Pygments 2.7.2 . PyGObject 3.36.0 . pylint 2.6.0 . pymongo 3.11.0 . pyparsing 2.4.7 . pyrsistent 0.17.3 . pytest 6.1.2 . python-apt 2.0.0+ubuntu0.20.4.1 . python-dateutil 2.8.1 . python-debian 0.1.36ubuntu1 . python-jsonrpc-server 0.4.0 . python-language-server 0.36.1 . pytoml 0.1.21 . pytz 2020.4 . PyYAML 5.3.1 . pyzmq 20.0.0 . regex 2020.11.13 . requests 2.22.0 . requests-unixsocket 0.2.0 . retrying 1.3.3 . rich 9.2.0 . rope 0.18.0 . scikit-learn 0.23.2 . scikit-misc 0.1.3 . scipy 1.5.4 . scrip,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1496
https://github.com/scverse/scanpy/issues/1496:5989,security,apt,apt,5989,upyterlab-templates 0.2.5 . jupytext 1.6.0 . kiwisolver 1.3.1 . lazy-object-proxy 1.4.3 . legacy-api-wrap 1.2 . llvmlite 0.34.0 . markdown-it-py 0.5.6 . MarkupSafe 1.1.1 . matplotlib 3.3.3 . mccabe 0.6.1 . mistune 0.8.4 . mypy-extensions 0.4.3 . natsort 7.0.1 . nbclient 0.5.1 . nbconvert 6.0.7 . nbdime 2.1.0 . nbformat 5.0.8 . nbresuse 0.3.6 . nest-asyncio 1.4.3 . networkx 2.5 . notebook 6.1.5 . numba 0.51.2 . numexpr 2.7.1 . numpy 1.19.4 . packaging 20.4 . pandas 1.1.4 . pandocfilters 1.4.3 . parso 0.7.1 . path 15.0.0 . pathspec 0.8.1 . pathtools 0.1.2 . patsy 0.5.1 . peepdis 0.1.13 . pexpect 4.8.0 . pickleshare 0.7.5 . Pillow 8.0.1 . pip 20.0.2 . plotly 4.12.0 . pluggy 0.13.1 . prometheus-client 0.8.0 . prompt-toolkit 3.0.8 . psutil 5.7.3 . ptvsd 4.3.2 . ptyprocess 0.6.0 . py 1.9.0 . pycodestyle 2.6.0 . pycparser 2.20 . pydocstyle 5.1.1 . pyflakes 2.2.0 . Pygments 2.7.2 . PyGObject 3.36.0 . pylint 2.6.0 . pymongo 3.11.0 . pyparsing 2.4.7 . pyrsistent 0.17.3 . pytest 6.1.2 . python-apt 2.0.0+ubuntu0.20.4.1 . python-dateutil 2.8.1 . python-debian 0.1.36ubuntu1 . python-jsonrpc-server 0.4.0 . python-language-server 0.36.1 . pytoml 0.1.21 . pytz 2020.4 . PyYAML 5.3.1 . pyzmq 20.0.0 . regex 2020.11.13 . requests 2.22.0 . requests-unixsocket 0.2.0 . retrying 1.3.3 . rich 9.2.0 . rope 0.18.0 . scikit-learn 0.23.2 . scikit-misc 0.1.3 . scipy 1.5.4 . scriptedforms 0.10.1 . scvi-tools 0.7.1 . seaborn 0.11.0 . Send2Trash 1.5.0 . setuptools 50.3.2 . setuptools-scm 4.1.2 . sinfo 0.3.1 . six 1.14.0 . smmap 3.0.4 . snowballstemmer 2.0.0 . SQLAlchemy 1.3.20 . statsmodels 0.12.1 . stdlib-list 0.7.0 . tables 3.6.1 . termcolor 1.1.0 . terminado 0.9.1 . testpath 0.4.4 . threadpoolctl 2.1.0 . toml 0.10.2 . torch 1.7.0 . tornado 6.1 . tqdm 4.51.0 . traitlets 5.0.5 . typed-ast 1.4.1 . typeguard 2.10.0 . typing-extensions 3.7.4.3 . ujson 4.0.1 . umap-learn 0.4.6 . unattended-upgrades 0.1 . urllib3 1.25.8 . watchdog 0.10.3 . wcwidth 0.2.5 . webencodings 0.5.1 . Werkzeug 1.0.1 . wheel 0.35,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1496
https://github.com/scverse/scanpy/issues/1496:974,testability,hook,hook,974,"`pip install -e .` raises LookupError: setuptools-scm was unable to detect version for '/home/ubuntu/code/scanpy'.; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. setuptools-scm can't find the package version when running `pip install -e` or `pip install .`. I stepped through `scanpy/_metadata.py`, and it does appear to be able to get `__version__` via `setuptools_scm.get_version` as opposed to using `._compat`. It seems like it may either be an issue with `setuptools_scm` itself or the combination of my environment and `pyproject.toml`. Any ideas? ### Minimal code sample (that we can copy&paste without having any data). ```bash. pip install -e . ```. ```pytb. File ""/tmp/tmp7fu14tjf"", line 280, in <module>. main(). File ""/tmp/tmp7fu14tjf"", line 263, in main. json_out['return_val'] = hook(**hook_input['kwargs']). File ""/tmp/tmp7fu14tjf"", line 133, in prepare_metadata_for_build_wheel. return hook(metadata_directory, config_settings). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/build_meta.py"", line 161, in prepare_metadata_for_build_wheel self.run_setup(). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/build_meta.py"", line 145, in run_setup. exec(compile(code, __file__, 'exec'), locals()) File ""setup.py"", line 17, in <module>. setup(. File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/__init__.py"", line 153, in setup. return distutils.core.setup(**attrs). File ""/usr/lib/python3.8/distutils/core.py"", line 108, in setup. _setup_distribution = dist = klass(attrs). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 423, in __init__. _Distribution.__init__(self, {. File ""/usr/lib/python3.8/distutils/dist.py"", line 292, in __init__. self.finalize_options(",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1496
https://github.com/scverse/scanpy/issues/1496:1083,testability,hook,hook,1083,"r '/home/ubuntu/code/scanpy'.; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. setuptools-scm can't find the package version when running `pip install -e` or `pip install .`. I stepped through `scanpy/_metadata.py`, and it does appear to be able to get `__version__` via `setuptools_scm.get_version` as opposed to using `._compat`. It seems like it may either be an issue with `setuptools_scm` itself or the combination of my environment and `pyproject.toml`. Any ideas? ### Minimal code sample (that we can copy&paste without having any data). ```bash. pip install -e . ```. ```pytb. File ""/tmp/tmp7fu14tjf"", line 280, in <module>. main(). File ""/tmp/tmp7fu14tjf"", line 263, in main. json_out['return_val'] = hook(**hook_input['kwargs']). File ""/tmp/tmp7fu14tjf"", line 133, in prepare_metadata_for_build_wheel. return hook(metadata_directory, config_settings). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/build_meta.py"", line 161, in prepare_metadata_for_build_wheel self.run_setup(). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/build_meta.py"", line 145, in run_setup. exec(compile(code, __file__, 'exec'), locals()) File ""setup.py"", line 17, in <module>. setup(. File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/__init__.py"", line 153, in setup. return distutils.core.setup(**attrs). File ""/usr/lib/python3.8/distutils/core.py"", line 108, in setup. _setup_distribution = dist = klass(attrs). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 423, in __init__. _Distribution.__init__(self, {. File ""/usr/lib/python3.8/distutils/dist.py"", line 292, in __init__. self.finalize_options() File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/di",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1496
https://github.com/scverse/scanpy/issues/1496:2357,testability,integr,integration,2357,"ools/build_meta.py"", line 145, in run_setup. exec(compile(code, __file__, 'exec'), locals()) File ""setup.py"", line 17, in <module>. setup(. File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/__init__.py"", line 153, in setup. return distutils.core.setup(**attrs). File ""/usr/lib/python3.8/distutils/core.py"", line 108, in setup. _setup_distribution = dist = klass(attrs). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 423, in __init__. _Distribution.__init__(self, {. File ""/usr/lib/python3.8/distutils/dist.py"", line 292, in __init__. self.finalize_options() File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 695, in finalize_options. ep(self). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 702, in _finalize_setup_keywords. ep.load()(self, ep.name, value). File ""/usr/local/lib/python3.8/dist-packages/setuptools_scm/integration.py"", line 17, in version_keyword. dist.metadata.version = _get_version(config). File ""/usr/local/lib/python3.8/dist-packages/setuptools_scm/__init__.py"", line 148, in _get_version. parsed_version = _do_parse(config). File ""/usr/local/lib/python3.8/dist-packages/setuptools_scm/__init__.py"", line 110, in _do_parse raise LookupError(. LookupError: setuptools-scm was unable to detect version for '/home/ubuntu/code/scanpy'. Make sure you're either building from a fully intact git repository or PyPI tarballs. Most other sources (such as GitHub's tarballs, a git checkout without the .git folder) don't contain the necessary metadata and will not work. . For example, if you're using pip, instead of https://github.com/user/proj/archive/master.zip use git+https://github.com/user/proj.git#egg=proj```. ```. #### Versions. <details>. scanpy. problem is with installation, so scanpy.logging.print_versions(). commit: ef5a8ee57c2aef7778a069a49101a8998718e6d5. python. 3.8.5. pip. 20.0.2 . ubuntu. 2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1496
https://github.com/scverse/scanpy/issues/1496:3249,testability,log,logging,3249,"_keywords. ep.load()(self, ep.name, value). File ""/usr/local/lib/python3.8/dist-packages/setuptools_scm/integration.py"", line 17, in version_keyword. dist.metadata.version = _get_version(config). File ""/usr/local/lib/python3.8/dist-packages/setuptools_scm/__init__.py"", line 148, in _get_version. parsed_version = _do_parse(config). File ""/usr/local/lib/python3.8/dist-packages/setuptools_scm/__init__.py"", line 110, in _do_parse raise LookupError(. LookupError: setuptools-scm was unable to detect version for '/home/ubuntu/code/scanpy'. Make sure you're either building from a fully intact git repository or PyPI tarballs. Most other sources (such as GitHub's tarballs, a git checkout without the .git folder) don't contain the necessary metadata and will not work. . For example, if you're using pip, instead of https://github.com/user/proj/archive/master.zip use git+https://github.com/user/proj.git#egg=proj```. ```. #### Versions. <details>. scanpy. problem is with installation, so scanpy.logging.print_versions(). commit: ef5a8ee57c2aef7778a069a49101a8998718e6d5. python. 3.8.5. pip. 20.0.2 . ubuntu. 20.04. pip list. Package Version Location . ------------------------- -------------------- -----------------------------. analysaurus 0.0.1 /home/ubuntu/code/analysaurus. anndata 0.7.5 . ansi2html 1.5.2 . appdirs 1.4.4 . argon2-cffi 20.1.0 . astroid 2.4.2 . async-generator 1.10 . attrs 20.3.0 . autopep8 1.5.4 . backcall 0.2.0 . biopython 1.78 . black 20.8b1 . bleach 3.2.1 . bokeh 2.2.3 . botocore 1.19.18 . Brotli 1.0.9 . cellforest 0.0.2 /home/ubuntu/code/cellforest . certifi 2019.11.28 . cffi 1.14.3 . chardet 3.0.4 . click 7.1.2 . colorama 0.4.4 . commonmark 0.9.1 . cycler 0.10.0 . dash 1.17.0 . dash-building-blocks 0.1.2 . dash-core-components 1.13.0 . dash-html-components 1.1.1 . dash-renderer 1.8.3 . dash-table 4.11.0 . dataclasses 0.6 . dataforest 0.0.2 /home/ubuntu/code/dataforest . dbus-python 1.2.16 . decorator 4.4.2 . defusedxml 0.6.0 . distro-info 0.23ubuntu1 . entrypo",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1496
https://github.com/scverse/scanpy/issues/1496:6655,testability,test,testpath,6655,ite 0.34.0 . markdown-it-py 0.5.6 . MarkupSafe 1.1.1 . matplotlib 3.3.3 . mccabe 0.6.1 . mistune 0.8.4 . mypy-extensions 0.4.3 . natsort 7.0.1 . nbclient 0.5.1 . nbconvert 6.0.7 . nbdime 2.1.0 . nbformat 5.0.8 . nbresuse 0.3.6 . nest-asyncio 1.4.3 . networkx 2.5 . notebook 6.1.5 . numba 0.51.2 . numexpr 2.7.1 . numpy 1.19.4 . packaging 20.4 . pandas 1.1.4 . pandocfilters 1.4.3 . parso 0.7.1 . path 15.0.0 . pathspec 0.8.1 . pathtools 0.1.2 . patsy 0.5.1 . peepdis 0.1.13 . pexpect 4.8.0 . pickleshare 0.7.5 . Pillow 8.0.1 . pip 20.0.2 . plotly 4.12.0 . pluggy 0.13.1 . prometheus-client 0.8.0 . prompt-toolkit 3.0.8 . psutil 5.7.3 . ptvsd 4.3.2 . ptyprocess 0.6.0 . py 1.9.0 . pycodestyle 2.6.0 . pycparser 2.20 . pydocstyle 5.1.1 . pyflakes 2.2.0 . Pygments 2.7.2 . PyGObject 3.36.0 . pylint 2.6.0 . pymongo 3.11.0 . pyparsing 2.4.7 . pyrsistent 0.17.3 . pytest 6.1.2 . python-apt 2.0.0+ubuntu0.20.4.1 . python-dateutil 2.8.1 . python-debian 0.1.36ubuntu1 . python-jsonrpc-server 0.4.0 . python-language-server 0.36.1 . pytoml 0.1.21 . pytz 2020.4 . PyYAML 5.3.1 . pyzmq 20.0.0 . regex 2020.11.13 . requests 2.22.0 . requests-unixsocket 0.2.0 . retrying 1.3.3 . rich 9.2.0 . rope 0.18.0 . scikit-learn 0.23.2 . scikit-misc 0.1.3 . scipy 1.5.4 . scriptedforms 0.10.1 . scvi-tools 0.7.1 . seaborn 0.11.0 . Send2Trash 1.5.0 . setuptools 50.3.2 . setuptools-scm 4.1.2 . sinfo 0.3.1 . six 1.14.0 . smmap 3.0.4 . snowballstemmer 2.0.0 . SQLAlchemy 1.3.20 . statsmodels 0.12.1 . stdlib-list 0.7.0 . tables 3.6.1 . termcolor 1.1.0 . terminado 0.9.1 . testpath 0.4.4 . threadpoolctl 2.1.0 . toml 0.10.2 . torch 1.7.0 . tornado 6.1 . tqdm 4.51.0 . traitlets 5.0.5 . typed-ast 1.4.1 . typeguard 2.10.0 . typing-extensions 3.7.4.3 . ujson 4.0.1 . umap-learn 0.4.6 . unattended-upgrades 0.1 . urllib3 1.25.8 . watchdog 0.10.3 . wcwidth 0.2.5 . webencodings 0.5.1 . Werkzeug 1.0.1 . wheel 0.35.1 . widgetsnbextension 3.5.1 . wrapt 1.12.1 . xeus-python 0.8.3 . xlrd 1.2.0 . yapf 0.30.0 . zipp 3.4.0. </details>.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1496
https://github.com/scverse/scanpy/issues/1496:197,usability,confirm,confirmed,197,"`pip install -e .` raises LookupError: setuptools-scm was unable to detect version for '/home/ubuntu/code/scanpy'.; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. setuptools-scm can't find the package version when running `pip install -e` or `pip install .`. I stepped through `scanpy/_metadata.py`, and it does appear to be able to get `__version__` via `setuptools_scm.get_version` as opposed to using `._compat`. It seems like it may either be an issue with `setuptools_scm` itself or the combination of my environment and `pyproject.toml`. Any ideas? ### Minimal code sample (that we can copy&paste without having any data). ```bash. pip install -e . ```. ```pytb. File ""/tmp/tmp7fu14tjf"", line 280, in <module>. main(). File ""/tmp/tmp7fu14tjf"", line 263, in main. json_out['return_val'] = hook(**hook_input['kwargs']). File ""/tmp/tmp7fu14tjf"", line 133, in prepare_metadata_for_build_wheel. return hook(metadata_directory, config_settings). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/build_meta.py"", line 161, in prepare_metadata_for_build_wheel self.run_setup(). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/build_meta.py"", line 145, in run_setup. exec(compile(code, __file__, 'exec'), locals()) File ""setup.py"", line 17, in <module>. setup(. File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/__init__.py"", line 153, in setup. return distutils.core.setup(**attrs). File ""/usr/lib/python3.8/distutils/core.py"", line 108, in setup. _setup_distribution = dist = klass(attrs). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 423, in __init__. _Distribution.__init__(self, {. File ""/usr/lib/python3.8/distutils/dist.py"", line 292, in __init__. self.finalize_options(",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1496
https://github.com/scverse/scanpy/issues/1496:280,usability,confirm,confirmed,280,"`pip install -e .` raises LookupError: setuptools-scm was unable to detect version for '/home/ubuntu/code/scanpy'.; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. setuptools-scm can't find the package version when running `pip install -e` or `pip install .`. I stepped through `scanpy/_metadata.py`, and it does appear to be able to get `__version__` via `setuptools_scm.get_version` as opposed to using `._compat`. It seems like it may either be an issue with `setuptools_scm` itself or the combination of my environment and `pyproject.toml`. Any ideas? ### Minimal code sample (that we can copy&paste without having any data). ```bash. pip install -e . ```. ```pytb. File ""/tmp/tmp7fu14tjf"", line 280, in <module>. main(). File ""/tmp/tmp7fu14tjf"", line 263, in main. json_out['return_val'] = hook(**hook_input['kwargs']). File ""/tmp/tmp7fu14tjf"", line 133, in prepare_metadata_for_build_wheel. return hook(metadata_directory, config_settings). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/build_meta.py"", line 161, in prepare_metadata_for_build_wheel self.run_setup(). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/build_meta.py"", line 145, in run_setup. exec(compile(code, __file__, 'exec'), locals()) File ""setup.py"", line 17, in <module>. setup(. File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/__init__.py"", line 153, in setup. return distutils.core.setup(**attrs). File ""/usr/lib/python3.8/distutils/core.py"", line 108, in setup. _setup_distribution = dist = klass(attrs). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 423, in __init__. _Distribution.__init__(self, {. File ""/usr/lib/python3.8/distutils/dist.py"", line 292, in __init__. self.finalize_options(",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1496
https://github.com/scverse/scanpy/issues/1496:739,usability,Minim,Minimal,739,"`pip install -e .` raises LookupError: setuptools-scm was unable to detect version for '/home/ubuntu/code/scanpy'.; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. setuptools-scm can't find the package version when running `pip install -e` or `pip install .`. I stepped through `scanpy/_metadata.py`, and it does appear to be able to get `__version__` via `setuptools_scm.get_version` as opposed to using `._compat`. It seems like it may either be an issue with `setuptools_scm` itself or the combination of my environment and `pyproject.toml`. Any ideas? ### Minimal code sample (that we can copy&paste without having any data). ```bash. pip install -e . ```. ```pytb. File ""/tmp/tmp7fu14tjf"", line 280, in <module>. main(). File ""/tmp/tmp7fu14tjf"", line 263, in main. json_out['return_val'] = hook(**hook_input['kwargs']). File ""/tmp/tmp7fu14tjf"", line 133, in prepare_metadata_for_build_wheel. return hook(metadata_directory, config_settings). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/build_meta.py"", line 161, in prepare_metadata_for_build_wheel self.run_setup(). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/build_meta.py"", line 145, in run_setup. exec(compile(code, __file__, 'exec'), locals()) File ""setup.py"", line 17, in <module>. setup(. File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/__init__.py"", line 153, in setup. return distutils.core.setup(**attrs). File ""/usr/lib/python3.8/distutils/core.py"", line 108, in setup. _setup_distribution = dist = klass(attrs). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 423, in __init__. _Distribution.__init__(self, {. File ""/usr/lib/python3.8/distutils/dist.py"", line 292, in __init__. self.finalize_options(",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1496
https://github.com/scverse/scanpy/issues/1496:3087,usability,user,user,3087,"y"", line 695, in finalize_options. ep(self). File ""/tmp/pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 702, in _finalize_setup_keywords. ep.load()(self, ep.name, value). File ""/usr/local/lib/python3.8/dist-packages/setuptools_scm/integration.py"", line 17, in version_keyword. dist.metadata.version = _get_version(config). File ""/usr/local/lib/python3.8/dist-packages/setuptools_scm/__init__.py"", line 148, in _get_version. parsed_version = _do_parse(config). File ""/usr/local/lib/python3.8/dist-packages/setuptools_scm/__init__.py"", line 110, in _do_parse raise LookupError(. LookupError: setuptools-scm was unable to detect version for '/home/ubuntu/code/scanpy'. Make sure you're either building from a fully intact git repository or PyPI tarballs. Most other sources (such as GitHub's tarballs, a git checkout without the .git folder) don't contain the necessary metadata and will not work. . For example, if you're using pip, instead of https://github.com/user/proj/archive/master.zip use git+https://github.com/user/proj.git#egg=proj```. ```. #### Versions. <details>. scanpy. problem is with installation, so scanpy.logging.print_versions(). commit: ef5a8ee57c2aef7778a069a49101a8998718e6d5. python. 3.8.5. pip. 20.0.2 . ubuntu. 20.04. pip list. Package Version Location . ------------------------- -------------------- -----------------------------. analysaurus 0.0.1 /home/ubuntu/code/analysaurus. anndata 0.7.5 . ansi2html 1.5.2 . appdirs 1.4.4 . argon2-cffi 20.1.0 . astroid 2.4.2 . async-generator 1.10 . attrs 20.3.0 . autopep8 1.5.4 . backcall 0.2.0 . biopython 1.78 . black 20.8b1 . bleach 3.2.1 . bokeh 2.2.3 . botocore 1.19.18 . Brotli 1.0.9 . cellforest 0.0.2 /home/ubuntu/code/cellforest . certifi 2019.11.28 . cffi 1.14.3 . chardet 3.0.4 . click 7.1.2 . colorama 0.4.4 . commonmark 0.9.1 . cycler 0.10.0 . dash 1.17.0 . dash-building-blocks 0.1.2 . dash-core-components 1.13.0 . dash-html-components 1.1.1 . dash-renderer 1.8.3 . dash-table 4.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1496
https://github.com/scverse/scanpy/issues/1496:3143,usability,user,user,3143,"pip-build-env-wb9dh0v3/overlay/lib/python3.8/site-packages/setuptools/dist.py"", line 702, in _finalize_setup_keywords. ep.load()(self, ep.name, value). File ""/usr/local/lib/python3.8/dist-packages/setuptools_scm/integration.py"", line 17, in version_keyword. dist.metadata.version = _get_version(config). File ""/usr/local/lib/python3.8/dist-packages/setuptools_scm/__init__.py"", line 148, in _get_version. parsed_version = _do_parse(config). File ""/usr/local/lib/python3.8/dist-packages/setuptools_scm/__init__.py"", line 110, in _do_parse raise LookupError(. LookupError: setuptools-scm was unable to detect version for '/home/ubuntu/code/scanpy'. Make sure you're either building from a fully intact git repository or PyPI tarballs. Most other sources (such as GitHub's tarballs, a git checkout without the .git folder) don't contain the necessary metadata and will not work. . For example, if you're using pip, instead of https://github.com/user/proj/archive/master.zip use git+https://github.com/user/proj.git#egg=proj```. ```. #### Versions. <details>. scanpy. problem is with installation, so scanpy.logging.print_versions(). commit: ef5a8ee57c2aef7778a069a49101a8998718e6d5. python. 3.8.5. pip. 20.0.2 . ubuntu. 20.04. pip list. Package Version Location . ------------------------- -------------------- -----------------------------. analysaurus 0.0.1 /home/ubuntu/code/analysaurus. anndata 0.7.5 . ansi2html 1.5.2 . appdirs 1.4.4 . argon2-cffi 20.1.0 . astroid 2.4.2 . async-generator 1.10 . attrs 20.3.0 . autopep8 1.5.4 . backcall 0.2.0 . biopython 1.78 . black 20.8b1 . bleach 3.2.1 . bokeh 2.2.3 . botocore 1.19.18 . Brotli 1.0.9 . cellforest 0.0.2 /home/ubuntu/code/cellforest . certifi 2019.11.28 . cffi 1.14.3 . chardet 3.0.4 . click 7.1.2 . colorama 0.4.4 . commonmark 0.9.1 . cycler 0.10.0 . dash 1.17.0 . dash-building-blocks 0.1.2 . dash-core-components 1.13.0 . dash-html-components 1.1.1 . dash-renderer 1.8.3 . dash-table 4.11.0 . dataclasses 0.6 . dataforest 0.0.2 /home/ubuntu/c",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1496
https://github.com/scverse/scanpy/issues/1496:5713,usability,tool,toolkit,5713, 3.2.0 . jupyter-client 6.1.7 . jupyter-core 4.6.3 . jupyter-dash 0.3.1 . jupyter-lsp 0.9.2 . jupyterlab 2.2.9 . jupyterlab-code-formatter 1.3.6 . jupyterlab-git 0.23.1 . jupyterlab-latex 2.0.0 . jupyterlab-pygments 0.1.2 . jupyterlab-server 1.2.0 . jupyterlab-sql 0.3.3 . jupyterlab-templates 0.2.5 . jupytext 1.6.0 . kiwisolver 1.3.1 . lazy-object-proxy 1.4.3 . legacy-api-wrap 1.2 . llvmlite 0.34.0 . markdown-it-py 0.5.6 . MarkupSafe 1.1.1 . matplotlib 3.3.3 . mccabe 0.6.1 . mistune 0.8.4 . mypy-extensions 0.4.3 . natsort 7.0.1 . nbclient 0.5.1 . nbconvert 6.0.7 . nbdime 2.1.0 . nbformat 5.0.8 . nbresuse 0.3.6 . nest-asyncio 1.4.3 . networkx 2.5 . notebook 6.1.5 . numba 0.51.2 . numexpr 2.7.1 . numpy 1.19.4 . packaging 20.4 . pandas 1.1.4 . pandocfilters 1.4.3 . parso 0.7.1 . path 15.0.0 . pathspec 0.8.1 . pathtools 0.1.2 . patsy 0.5.1 . peepdis 0.1.13 . pexpect 4.8.0 . pickleshare 0.7.5 . Pillow 8.0.1 . pip 20.0.2 . plotly 4.12.0 . pluggy 0.13.1 . prometheus-client 0.8.0 . prompt-toolkit 3.0.8 . psutil 5.7.3 . ptvsd 4.3.2 . ptyprocess 0.6.0 . py 1.9.0 . pycodestyle 2.6.0 . pycparser 2.20 . pydocstyle 5.1.1 . pyflakes 2.2.0 . Pygments 2.7.2 . PyGObject 3.36.0 . pylint 2.6.0 . pymongo 3.11.0 . pyparsing 2.4.7 . pyrsistent 0.17.3 . pytest 6.1.2 . python-apt 2.0.0+ubuntu0.20.4.1 . python-dateutil 2.8.1 . python-debian 0.1.36ubuntu1 . python-jsonrpc-server 0.4.0 . python-language-server 0.36.1 . pytoml 0.1.21 . pytz 2020.4 . PyYAML 5.3.1 . pyzmq 20.0.0 . regex 2020.11.13 . requests 2.22.0 . requests-unixsocket 0.2.0 . retrying 1.3.3 . rich 9.2.0 . rope 0.18.0 . scikit-learn 0.23.2 . scikit-misc 0.1.3 . scipy 1.5.4 . scriptedforms 0.10.1 . scvi-tools 0.7.1 . seaborn 0.11.0 . Send2Trash 1.5.0 . setuptools 50.3.2 . setuptools-scm 4.1.2 . sinfo 0.3.1 . six 1.14.0 . smmap 3.0.4 . snowballstemmer 2.0.0 . SQLAlchemy 1.3.20 . statsmodels 0.12.1 . stdlib-list 0.7.0 . tables 3.6.1 . termcolor 1.1.0 . terminado 0.9.1 . testpath 0.4.4 . threadpoolctl 2.1.0 . toml 0.10.2 . torch 1.7,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1496
https://github.com/scverse/scanpy/issues/1496:6308,usability,learn,learn,6308,ite 0.34.0 . markdown-it-py 0.5.6 . MarkupSafe 1.1.1 . matplotlib 3.3.3 . mccabe 0.6.1 . mistune 0.8.4 . mypy-extensions 0.4.3 . natsort 7.0.1 . nbclient 0.5.1 . nbconvert 6.0.7 . nbdime 2.1.0 . nbformat 5.0.8 . nbresuse 0.3.6 . nest-asyncio 1.4.3 . networkx 2.5 . notebook 6.1.5 . numba 0.51.2 . numexpr 2.7.1 . numpy 1.19.4 . packaging 20.4 . pandas 1.1.4 . pandocfilters 1.4.3 . parso 0.7.1 . path 15.0.0 . pathspec 0.8.1 . pathtools 0.1.2 . patsy 0.5.1 . peepdis 0.1.13 . pexpect 4.8.0 . pickleshare 0.7.5 . Pillow 8.0.1 . pip 20.0.2 . plotly 4.12.0 . pluggy 0.13.1 . prometheus-client 0.8.0 . prompt-toolkit 3.0.8 . psutil 5.7.3 . ptvsd 4.3.2 . ptyprocess 0.6.0 . py 1.9.0 . pycodestyle 2.6.0 . pycparser 2.20 . pydocstyle 5.1.1 . pyflakes 2.2.0 . Pygments 2.7.2 . PyGObject 3.36.0 . pylint 2.6.0 . pymongo 3.11.0 . pyparsing 2.4.7 . pyrsistent 0.17.3 . pytest 6.1.2 . python-apt 2.0.0+ubuntu0.20.4.1 . python-dateutil 2.8.1 . python-debian 0.1.36ubuntu1 . python-jsonrpc-server 0.4.0 . python-language-server 0.36.1 . pytoml 0.1.21 . pytz 2020.4 . PyYAML 5.3.1 . pyzmq 20.0.0 . regex 2020.11.13 . requests 2.22.0 . requests-unixsocket 0.2.0 . retrying 1.3.3 . rich 9.2.0 . rope 0.18.0 . scikit-learn 0.23.2 . scikit-misc 0.1.3 . scipy 1.5.4 . scriptedforms 0.10.1 . scvi-tools 0.7.1 . seaborn 0.11.0 . Send2Trash 1.5.0 . setuptools 50.3.2 . setuptools-scm 4.1.2 . sinfo 0.3.1 . six 1.14.0 . smmap 3.0.4 . snowballstemmer 2.0.0 . SQLAlchemy 1.3.20 . statsmodels 0.12.1 . stdlib-list 0.7.0 . tables 3.6.1 . termcolor 1.1.0 . terminado 0.9.1 . testpath 0.4.4 . threadpoolctl 2.1.0 . toml 0.10.2 . torch 1.7.0 . tornado 6.1 . tqdm 4.51.0 . traitlets 5.0.5 . typed-ast 1.4.1 . typeguard 2.10.0 . typing-extensions 3.7.4.3 . ujson 4.0.1 . umap-learn 0.4.6 . unattended-upgrades 0.1 . urllib3 1.25.8 . watchdog 0.10.3 . wcwidth 0.2.5 . webencodings 0.5.1 . Werkzeug 1.0.1 . wheel 0.35.1 . widgetsnbextension 3.5.1 . wrapt 1.12.1 . xeus-python 0.8.3 . xlrd 1.2.0 . yapf 0.30.0 . zipp 3.4.0. </details>.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1496
https://github.com/scverse/scanpy/issues/1496:6385,usability,tool,tools,6385,ite 0.34.0 . markdown-it-py 0.5.6 . MarkupSafe 1.1.1 . matplotlib 3.3.3 . mccabe 0.6.1 . mistune 0.8.4 . mypy-extensions 0.4.3 . natsort 7.0.1 . nbclient 0.5.1 . nbconvert 6.0.7 . nbdime 2.1.0 . nbformat 5.0.8 . nbresuse 0.3.6 . nest-asyncio 1.4.3 . networkx 2.5 . notebook 6.1.5 . numba 0.51.2 . numexpr 2.7.1 . numpy 1.19.4 . packaging 20.4 . pandas 1.1.4 . pandocfilters 1.4.3 . parso 0.7.1 . path 15.0.0 . pathspec 0.8.1 . pathtools 0.1.2 . patsy 0.5.1 . peepdis 0.1.13 . pexpect 4.8.0 . pickleshare 0.7.5 . Pillow 8.0.1 . pip 20.0.2 . plotly 4.12.0 . pluggy 0.13.1 . prometheus-client 0.8.0 . prompt-toolkit 3.0.8 . psutil 5.7.3 . ptvsd 4.3.2 . ptyprocess 0.6.0 . py 1.9.0 . pycodestyle 2.6.0 . pycparser 2.20 . pydocstyle 5.1.1 . pyflakes 2.2.0 . Pygments 2.7.2 . PyGObject 3.36.0 . pylint 2.6.0 . pymongo 3.11.0 . pyparsing 2.4.7 . pyrsistent 0.17.3 . pytest 6.1.2 . python-apt 2.0.0+ubuntu0.20.4.1 . python-dateutil 2.8.1 . python-debian 0.1.36ubuntu1 . python-jsonrpc-server 0.4.0 . python-language-server 0.36.1 . pytoml 0.1.21 . pytz 2020.4 . PyYAML 5.3.1 . pyzmq 20.0.0 . regex 2020.11.13 . requests 2.22.0 . requests-unixsocket 0.2.0 . retrying 1.3.3 . rich 9.2.0 . rope 0.18.0 . scikit-learn 0.23.2 . scikit-misc 0.1.3 . scipy 1.5.4 . scriptedforms 0.10.1 . scvi-tools 0.7.1 . seaborn 0.11.0 . Send2Trash 1.5.0 . setuptools 50.3.2 . setuptools-scm 4.1.2 . sinfo 0.3.1 . six 1.14.0 . smmap 3.0.4 . snowballstemmer 2.0.0 . SQLAlchemy 1.3.20 . statsmodels 0.12.1 . stdlib-list 0.7.0 . tables 3.6.1 . termcolor 1.1.0 . terminado 0.9.1 . testpath 0.4.4 . threadpoolctl 2.1.0 . toml 0.10.2 . torch 1.7.0 . tornado 6.1 . tqdm 4.51.0 . traitlets 5.0.5 . typed-ast 1.4.1 . typeguard 2.10.0 . typing-extensions 3.7.4.3 . ujson 4.0.1 . umap-learn 0.4.6 . unattended-upgrades 0.1 . urllib3 1.25.8 . watchdog 0.10.3 . wcwidth 0.2.5 . webencodings 0.5.1 . Werkzeug 1.0.1 . wheel 0.35.1 . widgetsnbextension 3.5.1 . wrapt 1.12.1 . xeus-python 0.8.3 . xlrd 1.2.0 . yapf 0.30.0 . zipp 3.4.0. </details>.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1496
https://github.com/scverse/scanpy/issues/1496:6852,usability,learn,learn,6852,ite 0.34.0 . markdown-it-py 0.5.6 . MarkupSafe 1.1.1 . matplotlib 3.3.3 . mccabe 0.6.1 . mistune 0.8.4 . mypy-extensions 0.4.3 . natsort 7.0.1 . nbclient 0.5.1 . nbconvert 6.0.7 . nbdime 2.1.0 . nbformat 5.0.8 . nbresuse 0.3.6 . nest-asyncio 1.4.3 . networkx 2.5 . notebook 6.1.5 . numba 0.51.2 . numexpr 2.7.1 . numpy 1.19.4 . packaging 20.4 . pandas 1.1.4 . pandocfilters 1.4.3 . parso 0.7.1 . path 15.0.0 . pathspec 0.8.1 . pathtools 0.1.2 . patsy 0.5.1 . peepdis 0.1.13 . pexpect 4.8.0 . pickleshare 0.7.5 . Pillow 8.0.1 . pip 20.0.2 . plotly 4.12.0 . pluggy 0.13.1 . prometheus-client 0.8.0 . prompt-toolkit 3.0.8 . psutil 5.7.3 . ptvsd 4.3.2 . ptyprocess 0.6.0 . py 1.9.0 . pycodestyle 2.6.0 . pycparser 2.20 . pydocstyle 5.1.1 . pyflakes 2.2.0 . Pygments 2.7.2 . PyGObject 3.36.0 . pylint 2.6.0 . pymongo 3.11.0 . pyparsing 2.4.7 . pyrsistent 0.17.3 . pytest 6.1.2 . python-apt 2.0.0+ubuntu0.20.4.1 . python-dateutil 2.8.1 . python-debian 0.1.36ubuntu1 . python-jsonrpc-server 0.4.0 . python-language-server 0.36.1 . pytoml 0.1.21 . pytz 2020.4 . PyYAML 5.3.1 . pyzmq 20.0.0 . regex 2020.11.13 . requests 2.22.0 . requests-unixsocket 0.2.0 . retrying 1.3.3 . rich 9.2.0 . rope 0.18.0 . scikit-learn 0.23.2 . scikit-misc 0.1.3 . scipy 1.5.4 . scriptedforms 0.10.1 . scvi-tools 0.7.1 . seaborn 0.11.0 . Send2Trash 1.5.0 . setuptools 50.3.2 . setuptools-scm 4.1.2 . sinfo 0.3.1 . six 1.14.0 . smmap 3.0.4 . snowballstemmer 2.0.0 . SQLAlchemy 1.3.20 . statsmodels 0.12.1 . stdlib-list 0.7.0 . tables 3.6.1 . termcolor 1.1.0 . terminado 0.9.1 . testpath 0.4.4 . threadpoolctl 2.1.0 . toml 0.10.2 . torch 1.7.0 . tornado 6.1 . tqdm 4.51.0 . traitlets 5.0.5 . typed-ast 1.4.1 . typeguard 2.10.0 . typing-extensions 3.7.4.3 . ujson 4.0.1 . umap-learn 0.4.6 . unattended-upgrades 0.1 . urllib3 1.25.8 . watchdog 0.10.3 . wcwidth 0.2.5 . webencodings 0.5.1 . Werkzeug 1.0.1 . wheel 0.35.1 . widgetsnbextension 3.5.1 . wrapt 1.12.1 . xeus-python 0.8.3 . xlrd 1.2.0 . yapf 0.30.0 . zipp 3.4.0. </details>.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1496
https://github.com/scverse/scanpy/issues/1496:6996,usability,widget,widgetsnbextension,6996,ite 0.34.0 . markdown-it-py 0.5.6 . MarkupSafe 1.1.1 . matplotlib 3.3.3 . mccabe 0.6.1 . mistune 0.8.4 . mypy-extensions 0.4.3 . natsort 7.0.1 . nbclient 0.5.1 . nbconvert 6.0.7 . nbdime 2.1.0 . nbformat 5.0.8 . nbresuse 0.3.6 . nest-asyncio 1.4.3 . networkx 2.5 . notebook 6.1.5 . numba 0.51.2 . numexpr 2.7.1 . numpy 1.19.4 . packaging 20.4 . pandas 1.1.4 . pandocfilters 1.4.3 . parso 0.7.1 . path 15.0.0 . pathspec 0.8.1 . pathtools 0.1.2 . patsy 0.5.1 . peepdis 0.1.13 . pexpect 4.8.0 . pickleshare 0.7.5 . Pillow 8.0.1 . pip 20.0.2 . plotly 4.12.0 . pluggy 0.13.1 . prometheus-client 0.8.0 . prompt-toolkit 3.0.8 . psutil 5.7.3 . ptvsd 4.3.2 . ptyprocess 0.6.0 . py 1.9.0 . pycodestyle 2.6.0 . pycparser 2.20 . pydocstyle 5.1.1 . pyflakes 2.2.0 . Pygments 2.7.2 . PyGObject 3.36.0 . pylint 2.6.0 . pymongo 3.11.0 . pyparsing 2.4.7 . pyrsistent 0.17.3 . pytest 6.1.2 . python-apt 2.0.0+ubuntu0.20.4.1 . python-dateutil 2.8.1 . python-debian 0.1.36ubuntu1 . python-jsonrpc-server 0.4.0 . python-language-server 0.36.1 . pytoml 0.1.21 . pytz 2020.4 . PyYAML 5.3.1 . pyzmq 20.0.0 . regex 2020.11.13 . requests 2.22.0 . requests-unixsocket 0.2.0 . retrying 1.3.3 . rich 9.2.0 . rope 0.18.0 . scikit-learn 0.23.2 . scikit-misc 0.1.3 . scipy 1.5.4 . scriptedforms 0.10.1 . scvi-tools 0.7.1 . seaborn 0.11.0 . Send2Trash 1.5.0 . setuptools 50.3.2 . setuptools-scm 4.1.2 . sinfo 0.3.1 . six 1.14.0 . smmap 3.0.4 . snowballstemmer 2.0.0 . SQLAlchemy 1.3.20 . statsmodels 0.12.1 . stdlib-list 0.7.0 . tables 3.6.1 . termcolor 1.1.0 . terminado 0.9.1 . testpath 0.4.4 . threadpoolctl 2.1.0 . toml 0.10.2 . torch 1.7.0 . tornado 6.1 . tqdm 4.51.0 . traitlets 5.0.5 . typed-ast 1.4.1 . typeguard 2.10.0 . typing-extensions 3.7.4.3 . ujson 4.0.1 . umap-learn 0.4.6 . unattended-upgrades 0.1 . urllib3 1.25.8 . watchdog 0.10.3 . wcwidth 0.2.5 . webencodings 0.5.1 . Werkzeug 1.0.1 . wheel 0.35.1 . widgetsnbextension 3.5.1 . wrapt 1.12.1 . xeus-python 0.8.3 . xlrd 1.2.0 . yapf 0.30.0 . zipp 3.4.0. </details>.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1496
https://github.com/scverse/scanpy/issues/1497:260,availability,error,error,260,"Bug with pie colors in sc.pl.scanpy; It works fine when I set the color to 'seurat_clusters'. But I want to show the pie chart for each node so I changed the color parameter according to the format in the documentation. This caused a ""unhashable type: 'dict'"" error. I looked into the paga.py code but couldn't figure out where the problem is. . The 'seurat_clusters' contains 8 clusters:. ```. adata.obs['seurat_clusters'].cat.categories. ```. `Index(['0', '1', '2', '3', '4', '5', '6', '7'], dtype='object')`. My command-line to run pl.paga with pie nodes:. ```. sc.pl.paga(adata,color={'0':{'red':0.2,'blue':0.8},'1':{'red':0.2,'blue':0.8},'2':{'red':0.2,'blue':0.8},'3':{'red':0.2,'blue':0.8},'4':{'red':0.2,'blue':0.8},'5':{'red':0.2,'blue':0.8},'6':{'red':0.2,'blue':0.8},'7':{'red':0.2,'blue':0.8}}, root=3, layout='eq_tree', node_size_scale=2, save='PAGA_tree.pdf'). ```. Error message:. ```. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-327-1f686f2dc40b> in <module>(). ----> 1 sc.pl.paga(adata,color=colors). /nfs/med-bfx-activeprojects/weishwu/common/Anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/_tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax). 474 or (c in var_names). 475 ). --> 476 for c in colors. 477 ]. 478 else:. /nfs/med-bfx-activeprojects/weishwu/common/Anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/_tools/paga.py in <listcomp>(.0). 474 or (c in var_names). 475 ). --> 476 for c in colors. 477 ]. 478 else:. /nfs/med-bfx-activeproje",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1497
https://github.com/scverse/scanpy/issues/1497:379,availability,cluster,clusters,379,"Bug with pie colors in sc.pl.scanpy; It works fine when I set the color to 'seurat_clusters'. But I want to show the pie chart for each node so I changed the color parameter according to the format in the documentation. This caused a ""unhashable type: 'dict'"" error. I looked into the paga.py code but couldn't figure out where the problem is. . The 'seurat_clusters' contains 8 clusters:. ```. adata.obs['seurat_clusters'].cat.categories. ```. `Index(['0', '1', '2', '3', '4', '5', '6', '7'], dtype='object')`. My command-line to run pl.paga with pie nodes:. ```. sc.pl.paga(adata,color={'0':{'red':0.2,'blue':0.8},'1':{'red':0.2,'blue':0.8},'2':{'red':0.2,'blue':0.8},'3':{'red':0.2,'blue':0.8},'4':{'red':0.2,'blue':0.8},'5':{'red':0.2,'blue':0.8},'6':{'red':0.2,'blue':0.8},'7':{'red':0.2,'blue':0.8}}, root=3, layout='eq_tree', node_size_scale=2, save='PAGA_tree.pdf'). ```. Error message:. ```. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-327-1f686f2dc40b> in <module>(). ----> 1 sc.pl.paga(adata,color=colors). /nfs/med-bfx-activeprojects/weishwu/common/Anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/_tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax). 474 or (c in var_names). 475 ). --> 476 for c in colors. 477 ]. 478 else:. /nfs/med-bfx-activeprojects/weishwu/common/Anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/_tools/paga.py in <listcomp>(.0). 474 or (c in var_names). 475 ). --> 476 for c in colors. 477 ]. 478 else:. /nfs/med-bfx-activeproje",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1497
https://github.com/scverse/scanpy/issues/1497:880,availability,Error,Error,880,"Bug with pie colors in sc.pl.scanpy; It works fine when I set the color to 'seurat_clusters'. But I want to show the pie chart for each node so I changed the color parameter according to the format in the documentation. This caused a ""unhashable type: 'dict'"" error. I looked into the paga.py code but couldn't figure out where the problem is. . The 'seurat_clusters' contains 8 clusters:. ```. adata.obs['seurat_clusters'].cat.categories. ```. `Index(['0', '1', '2', '3', '4', '5', '6', '7'], dtype='object')`. My command-line to run pl.paga with pie nodes:. ```. sc.pl.paga(adata,color={'0':{'red':0.2,'blue':0.8},'1':{'red':0.2,'blue':0.8},'2':{'red':0.2,'blue':0.8},'3':{'red':0.2,'blue':0.8},'4':{'red':0.2,'blue':0.8},'5':{'red':0.2,'blue':0.8},'6':{'red':0.2,'blue':0.8},'7':{'red':0.2,'blue':0.8}}, root=3, layout='eq_tree', node_size_scale=2, save='PAGA_tree.pdf'). ```. Error message:. ```. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-327-1f686f2dc40b> in <module>(). ----> 1 sc.pl.paga(adata,color=colors). /nfs/med-bfx-activeprojects/weishwu/common/Anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/_tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax). 474 or (c in var_names). 475 ). --> 476 for c in colors. 477 ]. 478 else:. /nfs/med-bfx-activeprojects/weishwu/common/Anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/_tools/paga.py in <listcomp>(.0). 474 or (c in var_names). 475 ). --> 476 for c in colors. 477 ]. 478 else:. /nfs/med-bfx-activeproje",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1497
https://github.com/scverse/scanpy/issues/1497:368,deployability,contain,contains,368,"Bug with pie colors in sc.pl.scanpy; It works fine when I set the color to 'seurat_clusters'. But I want to show the pie chart for each node so I changed the color parameter according to the format in the documentation. This caused a ""unhashable type: 'dict'"" error. I looked into the paga.py code but couldn't figure out where the problem is. . The 'seurat_clusters' contains 8 clusters:. ```. adata.obs['seurat_clusters'].cat.categories. ```. `Index(['0', '1', '2', '3', '4', '5', '6', '7'], dtype='object')`. My command-line to run pl.paga with pie nodes:. ```. sc.pl.paga(adata,color={'0':{'red':0.2,'blue':0.8},'1':{'red':0.2,'blue':0.8},'2':{'red':0.2,'blue':0.8},'3':{'red':0.2,'blue':0.8},'4':{'red':0.2,'blue':0.8},'5':{'red':0.2,'blue':0.8},'6':{'red':0.2,'blue':0.8},'7':{'red':0.2,'blue':0.8}}, root=3, layout='eq_tree', node_size_scale=2, save='PAGA_tree.pdf'). ```. Error message:. ```. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-327-1f686f2dc40b> in <module>(). ----> 1 sc.pl.paga(adata,color=colors). /nfs/med-bfx-activeprojects/weishwu/common/Anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/_tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax). 474 or (c in var_names). 475 ). --> 476 for c in colors. 477 ]. 478 else:. /nfs/med-bfx-activeprojects/weishwu/common/Anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/_tools/paga.py in <listcomp>(.0). 474 or (c in var_names). 475 ). --> 476 for c in colors. 477 ]. 478 else:. /nfs/med-bfx-activeproje",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1497
https://github.com/scverse/scanpy/issues/1497:379,deployability,cluster,clusters,379,"Bug with pie colors in sc.pl.scanpy; It works fine when I set the color to 'seurat_clusters'. But I want to show the pie chart for each node so I changed the color parameter according to the format in the documentation. This caused a ""unhashable type: 'dict'"" error. I looked into the paga.py code but couldn't figure out where the problem is. . The 'seurat_clusters' contains 8 clusters:. ```. adata.obs['seurat_clusters'].cat.categories. ```. `Index(['0', '1', '2', '3', '4', '5', '6', '7'], dtype='object')`. My command-line to run pl.paga with pie nodes:. ```. sc.pl.paga(adata,color={'0':{'red':0.2,'blue':0.8},'1':{'red':0.2,'blue':0.8},'2':{'red':0.2,'blue':0.8},'3':{'red':0.2,'blue':0.8},'4':{'red':0.2,'blue':0.8},'5':{'red':0.2,'blue':0.8},'6':{'red':0.2,'blue':0.8},'7':{'red':0.2,'blue':0.8}}, root=3, layout='eq_tree', node_size_scale=2, save='PAGA_tree.pdf'). ```. Error message:. ```. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-327-1f686f2dc40b> in <module>(). ----> 1 sc.pl.paga(adata,color=colors). /nfs/med-bfx-activeprojects/weishwu/common/Anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/_tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax). 474 or (c in var_names). 475 ). --> 476 for c in colors. 477 ]. 478 else:. /nfs/med-bfx-activeprojects/weishwu/common/Anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/_tools/paga.py in <listcomp>(.0). 474 or (c in var_names). 475 ). --> 476 for c in colors. 477 ]. 478 else:. /nfs/med-bfx-activeproje",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1497
https://github.com/scverse/scanpy/issues/1497:1060,deployability,modul,module,1060,"he color to 'seurat_clusters'. But I want to show the pie chart for each node so I changed the color parameter according to the format in the documentation. This caused a ""unhashable type: 'dict'"" error. I looked into the paga.py code but couldn't figure out where the problem is. . The 'seurat_clusters' contains 8 clusters:. ```. adata.obs['seurat_clusters'].cat.categories. ```. `Index(['0', '1', '2', '3', '4', '5', '6', '7'], dtype='object')`. My command-line to run pl.paga with pie nodes:. ```. sc.pl.paga(adata,color={'0':{'red':0.2,'blue':0.8},'1':{'red':0.2,'blue':0.8},'2':{'red':0.2,'blue':0.8},'3':{'red':0.2,'blue':0.8},'4':{'red':0.2,'blue':0.8},'5':{'red':0.2,'blue':0.8},'6':{'red':0.2,'blue':0.8},'7':{'red':0.2,'blue':0.8}}, root=3, layout='eq_tree', node_size_scale=2, save='PAGA_tree.pdf'). ```. Error message:. ```. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-327-1f686f2dc40b> in <module>(). ----> 1 sc.pl.paga(adata,color=colors). /nfs/med-bfx-activeprojects/weishwu/common/Anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/_tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax). 474 or (c in var_names). 475 ). --> 476 for c in colors. 477 ]. 478 else:. /nfs/med-bfx-activeprojects/weishwu/common/Anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/_tools/paga.py in <listcomp>(.0). 474 or (c in var_names). 475 ). --> 476 for c in colors. 477 ]. 478 else:. /nfs/med-bfx-activeprojects/weishwu/common/Anaconda3/envs/scanpy/lib/python3.6/site-pac",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1497
https://github.com/scverse/scanpy/issues/1497:2076,energy efficiency,core,core,2076,"e: 'dict'"" error. I looked into the paga.py code but couldn't figure out where the problem is. . The 'seurat_clusters' contains 8 clusters:. ```. adata.obs['seurat_clusters'].cat.categories. ```. `Index(['0', '1', '2', '3', '4', '5', '6', '7'], dtype='object')`. My command-line to run pl.paga with pie nodes:. ```. sc.pl.paga(adata,color={'0':{'red':0.2,'blue':0.8},'1':{'red':0.2,'blue':0.8},'2':{'red':0.2,'blue':0.8},'3':{'red':0.2,'blue':0.8},'4':{'red':0.2,'blue':0.8},'5':{'red':0.2,'blue':0.8},'6':{'red':0.2,'blue':0.8},'7':{'red':0.2,'blue':0.8}}, root=3, layout='eq_tree', node_size_scale=2, save='PAGA_tree.pdf'). ```. Error message:. ```. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-327-1f686f2dc40b> in <module>(). ----> 1 sc.pl.paga(adata,color=colors). /nfs/med-bfx-activeprojects/weishwu/common/Anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/_tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax). 474 or (c in var_names). 475 ). --> 476 for c in colors. 477 ]. 478 else:. /nfs/med-bfx-activeprojects/weishwu/common/Anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/_tools/paga.py in <listcomp>(.0). 474 or (c in var_names). 475 ). --> 476 for c in colors. 477 ]. 478 else:. /nfs/med-bfx-activeprojects/weishwu/common/Anaconda3/envs/scanpy/lib/python3.6/site-packages/pandas/core/indexes/base.py in __contains__(self, key). 4069 False. 4070 """""". -> 4071 hash(key). 4072 try:. 4073 return key in self._engine. TypeError: unhashable type: 'dict'. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1497
https://github.com/scverse/scanpy/issues/1497:886,integrability,messag,message,886,"Bug with pie colors in sc.pl.scanpy; It works fine when I set the color to 'seurat_clusters'. But I want to show the pie chart for each node so I changed the color parameter according to the format in the documentation. This caused a ""unhashable type: 'dict'"" error. I looked into the paga.py code but couldn't figure out where the problem is. . The 'seurat_clusters' contains 8 clusters:. ```. adata.obs['seurat_clusters'].cat.categories. ```. `Index(['0', '1', '2', '3', '4', '5', '6', '7'], dtype='object')`. My command-line to run pl.paga with pie nodes:. ```. sc.pl.paga(adata,color={'0':{'red':0.2,'blue':0.8},'1':{'red':0.2,'blue':0.8},'2':{'red':0.2,'blue':0.8},'3':{'red':0.2,'blue':0.8},'4':{'red':0.2,'blue':0.8},'5':{'red':0.2,'blue':0.8},'6':{'red':0.2,'blue':0.8},'7':{'red':0.2,'blue':0.8}}, root=3, layout='eq_tree', node_size_scale=2, save='PAGA_tree.pdf'). ```. Error message:. ```. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-327-1f686f2dc40b> in <module>(). ----> 1 sc.pl.paga(adata,color=colors). /nfs/med-bfx-activeprojects/weishwu/common/Anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/_tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax). 474 or (c in var_names). 475 ). --> 476 for c in colors. 477 ]. 478 else:. /nfs/med-bfx-activeprojects/weishwu/common/Anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/_tools/paga.py in <listcomp>(.0). 474 or (c in var_names). 475 ). --> 476 for c in colors. 477 ]. 478 else:. /nfs/med-bfx-activeproje",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1497
https://github.com/scverse/scanpy/issues/1497:191,interoperability,format,format,191,"Bug with pie colors in sc.pl.scanpy; It works fine when I set the color to 'seurat_clusters'. But I want to show the pie chart for each node so I changed the color parameter according to the format in the documentation. This caused a ""unhashable type: 'dict'"" error. I looked into the paga.py code but couldn't figure out where the problem is. . The 'seurat_clusters' contains 8 clusters:. ```. adata.obs['seurat_clusters'].cat.categories. ```. `Index(['0', '1', '2', '3', '4', '5', '6', '7'], dtype='object')`. My command-line to run pl.paga with pie nodes:. ```. sc.pl.paga(adata,color={'0':{'red':0.2,'blue':0.8},'1':{'red':0.2,'blue':0.8},'2':{'red':0.2,'blue':0.8},'3':{'red':0.2,'blue':0.8},'4':{'red':0.2,'blue':0.8},'5':{'red':0.2,'blue':0.8},'6':{'red':0.2,'blue':0.8},'7':{'red':0.2,'blue':0.8}}, root=3, layout='eq_tree', node_size_scale=2, save='PAGA_tree.pdf'). ```. Error message:. ```. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-327-1f686f2dc40b> in <module>(). ----> 1 sc.pl.paga(adata,color=colors). /nfs/med-bfx-activeprojects/weishwu/common/Anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/_tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax). 474 or (c in var_names). 475 ). --> 476 for c in colors. 477 ]. 478 else:. /nfs/med-bfx-activeprojects/weishwu/common/Anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/_tools/paga.py in <listcomp>(.0). 474 or (c in var_names). 475 ). --> 476 for c in colors. 477 ]. 478 else:. /nfs/med-bfx-activeproje",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1497
https://github.com/scverse/scanpy/issues/1497:886,interoperability,messag,message,886,"Bug with pie colors in sc.pl.scanpy; It works fine when I set the color to 'seurat_clusters'. But I want to show the pie chart for each node so I changed the color parameter according to the format in the documentation. This caused a ""unhashable type: 'dict'"" error. I looked into the paga.py code but couldn't figure out where the problem is. . The 'seurat_clusters' contains 8 clusters:. ```. adata.obs['seurat_clusters'].cat.categories. ```. `Index(['0', '1', '2', '3', '4', '5', '6', '7'], dtype='object')`. My command-line to run pl.paga with pie nodes:. ```. sc.pl.paga(adata,color={'0':{'red':0.2,'blue':0.8},'1':{'red':0.2,'blue':0.8},'2':{'red':0.2,'blue':0.8},'3':{'red':0.2,'blue':0.8},'4':{'red':0.2,'blue':0.8},'5':{'red':0.2,'blue':0.8},'6':{'red':0.2,'blue':0.8},'7':{'red':0.2,'blue':0.8}}, root=3, layout='eq_tree', node_size_scale=2, save='PAGA_tree.pdf'). ```. Error message:. ```. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-327-1f686f2dc40b> in <module>(). ----> 1 sc.pl.paga(adata,color=colors). /nfs/med-bfx-activeprojects/weishwu/common/Anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/_tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax). 474 or (c in var_names). 475 ). --> 476 for c in colors. 477 ]. 478 else:. /nfs/med-bfx-activeprojects/weishwu/common/Anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/_tools/paga.py in <listcomp>(.0). 474 or (c in var_names). 475 ). --> 476 for c in colors. 477 ]. 478 else:. /nfs/med-bfx-activeproje",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1497
https://github.com/scverse/scanpy/issues/1497:164,modifiability,paramet,parameter,164,"Bug with pie colors in sc.pl.scanpy; It works fine when I set the color to 'seurat_clusters'. But I want to show the pie chart for each node so I changed the color parameter according to the format in the documentation. This caused a ""unhashable type: 'dict'"" error. I looked into the paga.py code but couldn't figure out where the problem is. . The 'seurat_clusters' contains 8 clusters:. ```. adata.obs['seurat_clusters'].cat.categories. ```. `Index(['0', '1', '2', '3', '4', '5', '6', '7'], dtype='object')`. My command-line to run pl.paga with pie nodes:. ```. sc.pl.paga(adata,color={'0':{'red':0.2,'blue':0.8},'1':{'red':0.2,'blue':0.8},'2':{'red':0.2,'blue':0.8},'3':{'red':0.2,'blue':0.8},'4':{'red':0.2,'blue':0.8},'5':{'red':0.2,'blue':0.8},'6':{'red':0.2,'blue':0.8},'7':{'red':0.2,'blue':0.8}}, root=3, layout='eq_tree', node_size_scale=2, save='PAGA_tree.pdf'). ```. Error message:. ```. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-327-1f686f2dc40b> in <module>(). ----> 1 sc.pl.paga(adata,color=colors). /nfs/med-bfx-activeprojects/weishwu/common/Anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/_tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax). 474 or (c in var_names). 475 ). --> 476 for c in colors. 477 ]. 478 else:. /nfs/med-bfx-activeprojects/weishwu/common/Anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/_tools/paga.py in <listcomp>(.0). 474 or (c in var_names). 475 ). --> 476 for c in colors. 477 ]. 478 else:. /nfs/med-bfx-activeproje",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1497
https://github.com/scverse/scanpy/issues/1497:1060,modifiability,modul,module,1060,"he color to 'seurat_clusters'. But I want to show the pie chart for each node so I changed the color parameter according to the format in the documentation. This caused a ""unhashable type: 'dict'"" error. I looked into the paga.py code but couldn't figure out where the problem is. . The 'seurat_clusters' contains 8 clusters:. ```. adata.obs['seurat_clusters'].cat.categories. ```. `Index(['0', '1', '2', '3', '4', '5', '6', '7'], dtype='object')`. My command-line to run pl.paga with pie nodes:. ```. sc.pl.paga(adata,color={'0':{'red':0.2,'blue':0.8},'1':{'red':0.2,'blue':0.8},'2':{'red':0.2,'blue':0.8},'3':{'red':0.2,'blue':0.8},'4':{'red':0.2,'blue':0.8},'5':{'red':0.2,'blue':0.8},'6':{'red':0.2,'blue':0.8},'7':{'red':0.2,'blue':0.8}}, root=3, layout='eq_tree', node_size_scale=2, save='PAGA_tree.pdf'). ```. Error message:. ```. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-327-1f686f2dc40b> in <module>(). ----> 1 sc.pl.paga(adata,color=colors). /nfs/med-bfx-activeprojects/weishwu/common/Anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/_tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax). 474 or (c in var_names). 475 ). --> 476 for c in colors. 477 ]. 478 else:. /nfs/med-bfx-activeprojects/weishwu/common/Anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/_tools/paga.py in <listcomp>(.0). 474 or (c in var_names). 475 ). --> 476 for c in colors. 477 ]. 478 else:. /nfs/med-bfx-activeprojects/weishwu/common/Anaconda3/envs/scanpy/lib/python3.6/site-pac",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1497
https://github.com/scverse/scanpy/issues/1497:1195,modifiability,pac,packages,1195,"n the documentation. This caused a ""unhashable type: 'dict'"" error. I looked into the paga.py code but couldn't figure out where the problem is. . The 'seurat_clusters' contains 8 clusters:. ```. adata.obs['seurat_clusters'].cat.categories. ```. `Index(['0', '1', '2', '3', '4', '5', '6', '7'], dtype='object')`. My command-line to run pl.paga with pie nodes:. ```. sc.pl.paga(adata,color={'0':{'red':0.2,'blue':0.8},'1':{'red':0.2,'blue':0.8},'2':{'red':0.2,'blue':0.8},'3':{'red':0.2,'blue':0.8},'4':{'red':0.2,'blue':0.8},'5':{'red':0.2,'blue':0.8},'6':{'red':0.2,'blue':0.8},'7':{'red':0.2,'blue':0.8}}, root=3, layout='eq_tree', node_size_scale=2, save='PAGA_tree.pdf'). ```. Error message:. ```. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-327-1f686f2dc40b> in <module>(). ----> 1 sc.pl.paga(adata,color=colors). /nfs/med-bfx-activeprojects/weishwu/common/Anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/_tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax). 474 or (c in var_names). 475 ). --> 476 for c in colors. 477 ]. 478 else:. /nfs/med-bfx-activeprojects/weishwu/common/Anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/_tools/paga.py in <listcomp>(.0). 474 or (c in var_names). 475 ). --> 476 for c in colors. 477 ]. 478 else:. /nfs/med-bfx-activeprojects/weishwu/common/Anaconda3/envs/scanpy/lib/python3.6/site-packages/pandas/core/indexes/base.py in __contains__(self, key). 4069 False. 4070 """""". -> 4071 hash(key). 4072 try:. 4073 return key in sel",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1497
https://github.com/scverse/scanpy/issues/1497:1842,modifiability,pac,packages,1842,"e: 'dict'"" error. I looked into the paga.py code but couldn't figure out where the problem is. . The 'seurat_clusters' contains 8 clusters:. ```. adata.obs['seurat_clusters'].cat.categories. ```. `Index(['0', '1', '2', '3', '4', '5', '6', '7'], dtype='object')`. My command-line to run pl.paga with pie nodes:. ```. sc.pl.paga(adata,color={'0':{'red':0.2,'blue':0.8},'1':{'red':0.2,'blue':0.8},'2':{'red':0.2,'blue':0.8},'3':{'red':0.2,'blue':0.8},'4':{'red':0.2,'blue':0.8},'5':{'red':0.2,'blue':0.8},'6':{'red':0.2,'blue':0.8},'7':{'red':0.2,'blue':0.8}}, root=3, layout='eq_tree', node_size_scale=2, save='PAGA_tree.pdf'). ```. Error message:. ```. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-327-1f686f2dc40b> in <module>(). ----> 1 sc.pl.paga(adata,color=colors). /nfs/med-bfx-activeprojects/weishwu/common/Anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/_tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax). 474 or (c in var_names). 475 ). --> 476 for c in colors. 477 ]. 478 else:. /nfs/med-bfx-activeprojects/weishwu/common/Anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/_tools/paga.py in <listcomp>(.0). 474 or (c in var_names). 475 ). --> 476 for c in colors. 477 ]. 478 else:. /nfs/med-bfx-activeprojects/weishwu/common/Anaconda3/envs/scanpy/lib/python3.6/site-packages/pandas/core/indexes/base.py in __contains__(self, key). 4069 False. 4070 """""". -> 4071 hash(key). 4072 try:. 4073 return key in self._engine. TypeError: unhashable type: 'dict'. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1497
https://github.com/scverse/scanpy/issues/1497:2060,modifiability,pac,packages,2060,"e: 'dict'"" error. I looked into the paga.py code but couldn't figure out where the problem is. . The 'seurat_clusters' contains 8 clusters:. ```. adata.obs['seurat_clusters'].cat.categories. ```. `Index(['0', '1', '2', '3', '4', '5', '6', '7'], dtype='object')`. My command-line to run pl.paga with pie nodes:. ```. sc.pl.paga(adata,color={'0':{'red':0.2,'blue':0.8},'1':{'red':0.2,'blue':0.8},'2':{'red':0.2,'blue':0.8},'3':{'red':0.2,'blue':0.8},'4':{'red':0.2,'blue':0.8},'5':{'red':0.2,'blue':0.8},'6':{'red':0.2,'blue':0.8},'7':{'red':0.2,'blue':0.8}}, root=3, layout='eq_tree', node_size_scale=2, save='PAGA_tree.pdf'). ```. Error message:. ```. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-327-1f686f2dc40b> in <module>(). ----> 1 sc.pl.paga(adata,color=colors). /nfs/med-bfx-activeprojects/weishwu/common/Anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/_tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax). 474 or (c in var_names). 475 ). --> 476 for c in colors. 477 ]. 478 else:. /nfs/med-bfx-activeprojects/weishwu/common/Anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/_tools/paga.py in <listcomp>(.0). 474 or (c in var_names). 475 ). --> 476 for c in colors. 477 ]. 478 else:. /nfs/med-bfx-activeprojects/weishwu/common/Anaconda3/envs/scanpy/lib/python3.6/site-packages/pandas/core/indexes/base.py in __contains__(self, key). 4069 False. 4070 """""". -> 4071 hash(key). 4072 try:. 4073 return key in self._engine. TypeError: unhashable type: 'dict'. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1497
https://github.com/scverse/scanpy/issues/1497:260,performance,error,error,260,"Bug with pie colors in sc.pl.scanpy; It works fine when I set the color to 'seurat_clusters'. But I want to show the pie chart for each node so I changed the color parameter according to the format in the documentation. This caused a ""unhashable type: 'dict'"" error. I looked into the paga.py code but couldn't figure out where the problem is. . The 'seurat_clusters' contains 8 clusters:. ```. adata.obs['seurat_clusters'].cat.categories. ```. `Index(['0', '1', '2', '3', '4', '5', '6', '7'], dtype='object')`. My command-line to run pl.paga with pie nodes:. ```. sc.pl.paga(adata,color={'0':{'red':0.2,'blue':0.8},'1':{'red':0.2,'blue':0.8},'2':{'red':0.2,'blue':0.8},'3':{'red':0.2,'blue':0.8},'4':{'red':0.2,'blue':0.8},'5':{'red':0.2,'blue':0.8},'6':{'red':0.2,'blue':0.8},'7':{'red':0.2,'blue':0.8}}, root=3, layout='eq_tree', node_size_scale=2, save='PAGA_tree.pdf'). ```. Error message:. ```. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-327-1f686f2dc40b> in <module>(). ----> 1 sc.pl.paga(adata,color=colors). /nfs/med-bfx-activeprojects/weishwu/common/Anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/_tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax). 474 or (c in var_names). 475 ). --> 476 for c in colors. 477 ]. 478 else:. /nfs/med-bfx-activeprojects/weishwu/common/Anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/_tools/paga.py in <listcomp>(.0). 474 or (c in var_names). 475 ). --> 476 for c in colors. 477 ]. 478 else:. /nfs/med-bfx-activeproje",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1497
https://github.com/scverse/scanpy/issues/1497:880,performance,Error,Error,880,"Bug with pie colors in sc.pl.scanpy; It works fine when I set the color to 'seurat_clusters'. But I want to show the pie chart for each node so I changed the color parameter according to the format in the documentation. This caused a ""unhashable type: 'dict'"" error. I looked into the paga.py code but couldn't figure out where the problem is. . The 'seurat_clusters' contains 8 clusters:. ```. adata.obs['seurat_clusters'].cat.categories. ```. `Index(['0', '1', '2', '3', '4', '5', '6', '7'], dtype='object')`. My command-line to run pl.paga with pie nodes:. ```. sc.pl.paga(adata,color={'0':{'red':0.2,'blue':0.8},'1':{'red':0.2,'blue':0.8},'2':{'red':0.2,'blue':0.8},'3':{'red':0.2,'blue':0.8},'4':{'red':0.2,'blue':0.8},'5':{'red':0.2,'blue':0.8},'6':{'red':0.2,'blue':0.8},'7':{'red':0.2,'blue':0.8}}, root=3, layout='eq_tree', node_size_scale=2, save='PAGA_tree.pdf'). ```. Error message:. ```. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-327-1f686f2dc40b> in <module>(). ----> 1 sc.pl.paga(adata,color=colors). /nfs/med-bfx-activeprojects/weishwu/common/Anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/_tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax). 474 or (c in var_names). 475 ). --> 476 for c in colors. 477 ]. 478 else:. /nfs/med-bfx-activeprojects/weishwu/common/Anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/_tools/paga.py in <listcomp>(.0). 474 or (c in var_names). 475 ). --> 476 for c in colors. 477 ]. 478 else:. /nfs/med-bfx-activeproje",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1497
https://github.com/scverse/scanpy/issues/1497:260,safety,error,error,260,"Bug with pie colors in sc.pl.scanpy; It works fine when I set the color to 'seurat_clusters'. But I want to show the pie chart for each node so I changed the color parameter according to the format in the documentation. This caused a ""unhashable type: 'dict'"" error. I looked into the paga.py code but couldn't figure out where the problem is. . The 'seurat_clusters' contains 8 clusters:. ```. adata.obs['seurat_clusters'].cat.categories. ```. `Index(['0', '1', '2', '3', '4', '5', '6', '7'], dtype='object')`. My command-line to run pl.paga with pie nodes:. ```. sc.pl.paga(adata,color={'0':{'red':0.2,'blue':0.8},'1':{'red':0.2,'blue':0.8},'2':{'red':0.2,'blue':0.8},'3':{'red':0.2,'blue':0.8},'4':{'red':0.2,'blue':0.8},'5':{'red':0.2,'blue':0.8},'6':{'red':0.2,'blue':0.8},'7':{'red':0.2,'blue':0.8}}, root=3, layout='eq_tree', node_size_scale=2, save='PAGA_tree.pdf'). ```. Error message:. ```. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-327-1f686f2dc40b> in <module>(). ----> 1 sc.pl.paga(adata,color=colors). /nfs/med-bfx-activeprojects/weishwu/common/Anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/_tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax). 474 or (c in var_names). 475 ). --> 476 for c in colors. 477 ]. 478 else:. /nfs/med-bfx-activeprojects/weishwu/common/Anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/_tools/paga.py in <listcomp>(.0). 474 or (c in var_names). 475 ). --> 476 for c in colors. 477 ]. 478 else:. /nfs/med-bfx-activeproje",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1497
https://github.com/scverse/scanpy/issues/1497:880,safety,Error,Error,880,"Bug with pie colors in sc.pl.scanpy; It works fine when I set the color to 'seurat_clusters'. But I want to show the pie chart for each node so I changed the color parameter according to the format in the documentation. This caused a ""unhashable type: 'dict'"" error. I looked into the paga.py code but couldn't figure out where the problem is. . The 'seurat_clusters' contains 8 clusters:. ```. adata.obs['seurat_clusters'].cat.categories. ```. `Index(['0', '1', '2', '3', '4', '5', '6', '7'], dtype='object')`. My command-line to run pl.paga with pie nodes:. ```. sc.pl.paga(adata,color={'0':{'red':0.2,'blue':0.8},'1':{'red':0.2,'blue':0.8},'2':{'red':0.2,'blue':0.8},'3':{'red':0.2,'blue':0.8},'4':{'red':0.2,'blue':0.8},'5':{'red':0.2,'blue':0.8},'6':{'red':0.2,'blue':0.8},'7':{'red':0.2,'blue':0.8}}, root=3, layout='eq_tree', node_size_scale=2, save='PAGA_tree.pdf'). ```. Error message:. ```. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-327-1f686f2dc40b> in <module>(). ----> 1 sc.pl.paga(adata,color=colors). /nfs/med-bfx-activeprojects/weishwu/common/Anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/_tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax). 474 or (c in var_names). 475 ). --> 476 for c in colors. 477 ]. 478 else:. /nfs/med-bfx-activeprojects/weishwu/common/Anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/_tools/paga.py in <listcomp>(.0). 474 or (c in var_names). 475 ). --> 476 for c in colors. 477 ]. 478 else:. /nfs/med-bfx-activeproje",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1497
https://github.com/scverse/scanpy/issues/1497:1032,safety,input,input-,1032,"; It works fine when I set the color to 'seurat_clusters'. But I want to show the pie chart for each node so I changed the color parameter according to the format in the documentation. This caused a ""unhashable type: 'dict'"" error. I looked into the paga.py code but couldn't figure out where the problem is. . The 'seurat_clusters' contains 8 clusters:. ```. adata.obs['seurat_clusters'].cat.categories. ```. `Index(['0', '1', '2', '3', '4', '5', '6', '7'], dtype='object')`. My command-line to run pl.paga with pie nodes:. ```. sc.pl.paga(adata,color={'0':{'red':0.2,'blue':0.8},'1':{'red':0.2,'blue':0.8},'2':{'red':0.2,'blue':0.8},'3':{'red':0.2,'blue':0.8},'4':{'red':0.2,'blue':0.8},'5':{'red':0.2,'blue':0.8},'6':{'red':0.2,'blue':0.8},'7':{'red':0.2,'blue':0.8}}, root=3, layout='eq_tree', node_size_scale=2, save='PAGA_tree.pdf'). ```. Error message:. ```. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-327-1f686f2dc40b> in <module>(). ----> 1 sc.pl.paga(adata,color=colors). /nfs/med-bfx-activeprojects/weishwu/common/Anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/_tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax). 474 or (c in var_names). 475 ). --> 476 for c in colors. 477 ]. 478 else:. /nfs/med-bfx-activeprojects/weishwu/common/Anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/_tools/paga.py in <listcomp>(.0). 474 or (c in var_names). 475 ). --> 476 for c in colors. 477 ]. 478 else:. /nfs/med-bfx-activeprojects/weishwu/common/Anaconda3/envs/s",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1497
https://github.com/scverse/scanpy/issues/1497:1060,safety,modul,module,1060,"he color to 'seurat_clusters'. But I want to show the pie chart for each node so I changed the color parameter according to the format in the documentation. This caused a ""unhashable type: 'dict'"" error. I looked into the paga.py code but couldn't figure out where the problem is. . The 'seurat_clusters' contains 8 clusters:. ```. adata.obs['seurat_clusters'].cat.categories. ```. `Index(['0', '1', '2', '3', '4', '5', '6', '7'], dtype='object')`. My command-line to run pl.paga with pie nodes:. ```. sc.pl.paga(adata,color={'0':{'red':0.2,'blue':0.8},'1':{'red':0.2,'blue':0.8},'2':{'red':0.2,'blue':0.8},'3':{'red':0.2,'blue':0.8},'4':{'red':0.2,'blue':0.8},'5':{'red':0.2,'blue':0.8},'6':{'red':0.2,'blue':0.8},'7':{'red':0.2,'blue':0.8}}, root=3, layout='eq_tree', node_size_scale=2, save='PAGA_tree.pdf'). ```. Error message:. ```. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-327-1f686f2dc40b> in <module>(). ----> 1 sc.pl.paga(adata,color=colors). /nfs/med-bfx-activeprojects/weishwu/common/Anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/_tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax). 474 or (c in var_names). 475 ). --> 476 for c in colors. 477 ]. 478 else:. /nfs/med-bfx-activeprojects/weishwu/common/Anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/_tools/paga.py in <listcomp>(.0). 474 or (c in var_names). 475 ). --> 476 for c in colors. 477 ]. 478 else:. /nfs/med-bfx-activeprojects/weishwu/common/Anaconda3/envs/scanpy/lib/python3.6/site-pac",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1497
https://github.com/scverse/scanpy/issues/1497:515,security,command-lin,command-line,515,"Bug with pie colors in sc.pl.scanpy; It works fine when I set the color to 'seurat_clusters'. But I want to show the pie chart for each node so I changed the color parameter according to the format in the documentation. This caused a ""unhashable type: 'dict'"" error. I looked into the paga.py code but couldn't figure out where the problem is. . The 'seurat_clusters' contains 8 clusters:. ```. adata.obs['seurat_clusters'].cat.categories. ```. `Index(['0', '1', '2', '3', '4', '5', '6', '7'], dtype='object')`. My command-line to run pl.paga with pie nodes:. ```. sc.pl.paga(adata,color={'0':{'red':0.2,'blue':0.8},'1':{'red':0.2,'blue':0.8},'2':{'red':0.2,'blue':0.8},'3':{'red':0.2,'blue':0.8},'4':{'red':0.2,'blue':0.8},'5':{'red':0.2,'blue':0.8},'6':{'red':0.2,'blue':0.8},'7':{'red':0.2,'blue':0.8}}, root=3, layout='eq_tree', node_size_scale=2, save='PAGA_tree.pdf'). ```. Error message:. ```. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-327-1f686f2dc40b> in <module>(). ----> 1 sc.pl.paga(adata,color=colors). /nfs/med-bfx-activeprojects/weishwu/common/Anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/_tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax). 474 or (c in var_names). 475 ). --> 476 for c in colors. 477 ]. 478 else:. /nfs/med-bfx-activeprojects/weishwu/common/Anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/_tools/paga.py in <listcomp>(.0). 474 or (c in var_names). 475 ). --> 476 for c in colors. 477 ]. 478 else:. /nfs/med-bfx-activeproje",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1497
https://github.com/scverse/scanpy/issues/1497:2155,security,hash,hash,2155,"e: 'dict'"" error. I looked into the paga.py code but couldn't figure out where the problem is. . The 'seurat_clusters' contains 8 clusters:. ```. adata.obs['seurat_clusters'].cat.categories. ```. `Index(['0', '1', '2', '3', '4', '5', '6', '7'], dtype='object')`. My command-line to run pl.paga with pie nodes:. ```. sc.pl.paga(adata,color={'0':{'red':0.2,'blue':0.8},'1':{'red':0.2,'blue':0.8},'2':{'red':0.2,'blue':0.8},'3':{'red':0.2,'blue':0.8},'4':{'red':0.2,'blue':0.8},'5':{'red':0.2,'blue':0.8},'6':{'red':0.2,'blue':0.8},'7':{'red':0.2,'blue':0.8}}, root=3, layout='eq_tree', node_size_scale=2, save='PAGA_tree.pdf'). ```. Error message:. ```. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-327-1f686f2dc40b> in <module>(). ----> 1 sc.pl.paga(adata,color=colors). /nfs/med-bfx-activeprojects/weishwu/common/Anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/_tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax). 474 or (c in var_names). 475 ). --> 476 for c in colors. 477 ]. 478 else:. /nfs/med-bfx-activeprojects/weishwu/common/Anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/_tools/paga.py in <listcomp>(.0). 474 or (c in var_names). 475 ). --> 476 for c in colors. 477 ]. 478 else:. /nfs/med-bfx-activeprojects/weishwu/common/Anaconda3/envs/scanpy/lib/python3.6/site-packages/pandas/core/indexes/base.py in __contains__(self, key). 4069 False. 4070 """""". -> 4071 hash(key). 4072 try:. 4073 return key in self._engine. TypeError: unhashable type: 'dict'. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1497
https://github.com/scverse/scanpy/issues/1497:988,testability,Trace,Traceback,988,"Bug with pie colors in sc.pl.scanpy; It works fine when I set the color to 'seurat_clusters'. But I want to show the pie chart for each node so I changed the color parameter according to the format in the documentation. This caused a ""unhashable type: 'dict'"" error. I looked into the paga.py code but couldn't figure out where the problem is. . The 'seurat_clusters' contains 8 clusters:. ```. adata.obs['seurat_clusters'].cat.categories. ```. `Index(['0', '1', '2', '3', '4', '5', '6', '7'], dtype='object')`. My command-line to run pl.paga with pie nodes:. ```. sc.pl.paga(adata,color={'0':{'red':0.2,'blue':0.8},'1':{'red':0.2,'blue':0.8},'2':{'red':0.2,'blue':0.8},'3':{'red':0.2,'blue':0.8},'4':{'red':0.2,'blue':0.8},'5':{'red':0.2,'blue':0.8},'6':{'red':0.2,'blue':0.8},'7':{'red':0.2,'blue':0.8}}, root=3, layout='eq_tree', node_size_scale=2, save='PAGA_tree.pdf'). ```. Error message:. ```. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-327-1f686f2dc40b> in <module>(). ----> 1 sc.pl.paga(adata,color=colors). /nfs/med-bfx-activeprojects/weishwu/common/Anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/_tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax). 474 or (c in var_names). 475 ). --> 476 for c in colors. 477 ]. 478 else:. /nfs/med-bfx-activeprojects/weishwu/common/Anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/_tools/paga.py in <listcomp>(.0). 474 or (c in var_names). 475 ). --> 476 for c in colors. 477 ]. 478 else:. /nfs/med-bfx-activeproje",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1497
https://github.com/scverse/scanpy/issues/1497:205,usability,document,documentation,205,"Bug with pie colors in sc.pl.scanpy; It works fine when I set the color to 'seurat_clusters'. But I want to show the pie chart for each node so I changed the color parameter according to the format in the documentation. This caused a ""unhashable type: 'dict'"" error. I looked into the paga.py code but couldn't figure out where the problem is. . The 'seurat_clusters' contains 8 clusters:. ```. adata.obs['seurat_clusters'].cat.categories. ```. `Index(['0', '1', '2', '3', '4', '5', '6', '7'], dtype='object')`. My command-line to run pl.paga with pie nodes:. ```. sc.pl.paga(adata,color={'0':{'red':0.2,'blue':0.8},'1':{'red':0.2,'blue':0.8},'2':{'red':0.2,'blue':0.8},'3':{'red':0.2,'blue':0.8},'4':{'red':0.2,'blue':0.8},'5':{'red':0.2,'blue':0.8},'6':{'red':0.2,'blue':0.8},'7':{'red':0.2,'blue':0.8}}, root=3, layout='eq_tree', node_size_scale=2, save='PAGA_tree.pdf'). ```. Error message:. ```. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-327-1f686f2dc40b> in <module>(). ----> 1 sc.pl.paga(adata,color=colors). /nfs/med-bfx-activeprojects/weishwu/common/Anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/_tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax). 474 or (c in var_names). 475 ). --> 476 for c in colors. 477 ]. 478 else:. /nfs/med-bfx-activeprojects/weishwu/common/Anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/_tools/paga.py in <listcomp>(.0). 474 or (c in var_names). 475 ). --> 476 for c in colors. 477 ]. 478 else:. /nfs/med-bfx-activeproje",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1497
https://github.com/scverse/scanpy/issues/1497:260,usability,error,error,260,"Bug with pie colors in sc.pl.scanpy; It works fine when I set the color to 'seurat_clusters'. But I want to show the pie chart for each node so I changed the color parameter according to the format in the documentation. This caused a ""unhashable type: 'dict'"" error. I looked into the paga.py code but couldn't figure out where the problem is. . The 'seurat_clusters' contains 8 clusters:. ```. adata.obs['seurat_clusters'].cat.categories. ```. `Index(['0', '1', '2', '3', '4', '5', '6', '7'], dtype='object')`. My command-line to run pl.paga with pie nodes:. ```. sc.pl.paga(adata,color={'0':{'red':0.2,'blue':0.8},'1':{'red':0.2,'blue':0.8},'2':{'red':0.2,'blue':0.8},'3':{'red':0.2,'blue':0.8},'4':{'red':0.2,'blue':0.8},'5':{'red':0.2,'blue':0.8},'6':{'red':0.2,'blue':0.8},'7':{'red':0.2,'blue':0.8}}, root=3, layout='eq_tree', node_size_scale=2, save='PAGA_tree.pdf'). ```. Error message:. ```. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-327-1f686f2dc40b> in <module>(). ----> 1 sc.pl.paga(adata,color=colors). /nfs/med-bfx-activeprojects/weishwu/common/Anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/_tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax). 474 or (c in var_names). 475 ). --> 476 for c in colors. 477 ]. 478 else:. /nfs/med-bfx-activeprojects/weishwu/common/Anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/_tools/paga.py in <listcomp>(.0). 474 or (c in var_names). 475 ). --> 476 for c in colors. 477 ]. 478 else:. /nfs/med-bfx-activeproje",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1497
https://github.com/scverse/scanpy/issues/1497:515,usability,command,command-line,515,"Bug with pie colors in sc.pl.scanpy; It works fine when I set the color to 'seurat_clusters'. But I want to show the pie chart for each node so I changed the color parameter according to the format in the documentation. This caused a ""unhashable type: 'dict'"" error. I looked into the paga.py code but couldn't figure out where the problem is. . The 'seurat_clusters' contains 8 clusters:. ```. adata.obs['seurat_clusters'].cat.categories. ```. `Index(['0', '1', '2', '3', '4', '5', '6', '7'], dtype='object')`. My command-line to run pl.paga with pie nodes:. ```. sc.pl.paga(adata,color={'0':{'red':0.2,'blue':0.8},'1':{'red':0.2,'blue':0.8},'2':{'red':0.2,'blue':0.8},'3':{'red':0.2,'blue':0.8},'4':{'red':0.2,'blue':0.8},'5':{'red':0.2,'blue':0.8},'6':{'red':0.2,'blue':0.8},'7':{'red':0.2,'blue':0.8}}, root=3, layout='eq_tree', node_size_scale=2, save='PAGA_tree.pdf'). ```. Error message:. ```. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-327-1f686f2dc40b> in <module>(). ----> 1 sc.pl.paga(adata,color=colors). /nfs/med-bfx-activeprojects/weishwu/common/Anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/_tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax). 474 or (c in var_names). 475 ). --> 476 for c in colors. 477 ]. 478 else:. /nfs/med-bfx-activeprojects/weishwu/common/Anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/_tools/paga.py in <listcomp>(.0). 474 or (c in var_names). 475 ). --> 476 for c in colors. 477 ]. 478 else:. /nfs/med-bfx-activeproje",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1497
https://github.com/scverse/scanpy/issues/1497:880,usability,Error,Error,880,"Bug with pie colors in sc.pl.scanpy; It works fine when I set the color to 'seurat_clusters'. But I want to show the pie chart for each node so I changed the color parameter according to the format in the documentation. This caused a ""unhashable type: 'dict'"" error. I looked into the paga.py code but couldn't figure out where the problem is. . The 'seurat_clusters' contains 8 clusters:. ```. adata.obs['seurat_clusters'].cat.categories. ```. `Index(['0', '1', '2', '3', '4', '5', '6', '7'], dtype='object')`. My command-line to run pl.paga with pie nodes:. ```. sc.pl.paga(adata,color={'0':{'red':0.2,'blue':0.8},'1':{'red':0.2,'blue':0.8},'2':{'red':0.2,'blue':0.8},'3':{'red':0.2,'blue':0.8},'4':{'red':0.2,'blue':0.8},'5':{'red':0.2,'blue':0.8},'6':{'red':0.2,'blue':0.8},'7':{'red':0.2,'blue':0.8}}, root=3, layout='eq_tree', node_size_scale=2, save='PAGA_tree.pdf'). ```. Error message:. ```. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-327-1f686f2dc40b> in <module>(). ----> 1 sc.pl.paga(adata,color=colors). /nfs/med-bfx-activeprojects/weishwu/common/Anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/_tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax). 474 or (c in var_names). 475 ). --> 476 for c in colors. 477 ]. 478 else:. /nfs/med-bfx-activeprojects/weishwu/common/Anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/_tools/paga.py in <listcomp>(.0). 474 or (c in var_names). 475 ). --> 476 for c in colors. 477 ]. 478 else:. /nfs/med-bfx-activeproje",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1497
https://github.com/scverse/scanpy/issues/1497:1032,usability,input,input-,1032,"; It works fine when I set the color to 'seurat_clusters'. But I want to show the pie chart for each node so I changed the color parameter according to the format in the documentation. This caused a ""unhashable type: 'dict'"" error. I looked into the paga.py code but couldn't figure out where the problem is. . The 'seurat_clusters' contains 8 clusters:. ```. adata.obs['seurat_clusters'].cat.categories. ```. `Index(['0', '1', '2', '3', '4', '5', '6', '7'], dtype='object')`. My command-line to run pl.paga with pie nodes:. ```. sc.pl.paga(adata,color={'0':{'red':0.2,'blue':0.8},'1':{'red':0.2,'blue':0.8},'2':{'red':0.2,'blue':0.8},'3':{'red':0.2,'blue':0.8},'4':{'red':0.2,'blue':0.8},'5':{'red':0.2,'blue':0.8},'6':{'red':0.2,'blue':0.8},'7':{'red':0.2,'blue':0.8}}, root=3, layout='eq_tree', node_size_scale=2, save='PAGA_tree.pdf'). ```. Error message:. ```. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-327-1f686f2dc40b> in <module>(). ----> 1 sc.pl.paga(adata,color=colors). /nfs/med-bfx-activeprojects/weishwu/common/Anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/_tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax). 474 or (c in var_names). 475 ). --> 476 for c in colors. 477 ]. 478 else:. /nfs/med-bfx-activeprojects/weishwu/common/Anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/plotting/_tools/paga.py in <listcomp>(.0). 474 or (c in var_names). 475 ). --> 476 for c in colors. 477 ]. 478 else:. /nfs/med-bfx-activeprojects/weishwu/common/Anaconda3/envs/s",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1497
https://github.com/scverse/scanpy/pull/1498:0,deployability,Build,Build,0,Build docs with newer Python;,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1498
https://github.com/scverse/scanpy/pull/1499:38,availability,sli,slicing,38,"Speedup sc.get.obs_df; By using array slicing, this codes improves ~10 fold the speed of `sc.get.obs_df()`. ```PYTHON. %timeit sc.get.obs_df(adata, list(adata.var_names[:100]) + ['louvain']). ````. before:. `40.6 ms  2.38 ms per loop (mean  std. dev. of 7 runs, 10 loops each)`. after:. `4.45 ms  228 s per loop (mean  std. dev. of 7 runs, 100 loops each)`",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1499
https://github.com/scverse/scanpy/pull/1499:120,performance,time,timeit,120,"Speedup sc.get.obs_df; By using array slicing, this codes improves ~10 fold the speed of `sc.get.obs_df()`. ```PYTHON. %timeit sc.get.obs_df(adata, list(adata.var_names[:100]) + ['louvain']). ````. before:. `40.6 ms  2.38 ms per loop (mean  std. dev. of 7 runs, 10 loops each)`. after:. `4.45 ms  228 s per loop (mean  std. dev. of 7 runs, 100 loops each)`",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1499
https://github.com/scverse/scanpy/pull/1499:38,reliability,sli,slicing,38,"Speedup sc.get.obs_df; By using array slicing, this codes improves ~10 fold the speed of `sc.get.obs_df()`. ```PYTHON. %timeit sc.get.obs_df(adata, list(adata.var_names[:100]) + ['louvain']). ````. before:. `40.6 ms  2.38 ms per loop (mean  std. dev. of 7 runs, 10 loops each)`. after:. `4.45 ms  228 s per loop (mean  std. dev. of 7 runs, 100 loops each)`",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1499
https://github.com/scverse/scanpy/issues/1500:744,availability,Cluster,Cluster,744,"Support obsm key to color UMAP; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. Quite often I need to color UMAPs based on features that are not part of `adata.X` but `adata.obsm` for the reason that they are special. E.g. KO data with gRNAs versus endogenes/ target genes, or viral genes versus edogenes. Example use case: . - Cluster cells based on endogenes. - UMAP and color by a bunch of viral genes. Clustering must not include these viral genes -> must be excluded from `X`. . I don't want to store so many additional columns in `obs` and I need to have these features separated in their own matrix for downstream analysis, which is why I want to use `obsm`. Can we have sth. like this:. ```. sc.pl.umap(adata, color='viral_genes') # adata.obsm['viral_genes'] is a pandas.DataFrame ? ```. It shouldn't be overcomplicated I think, since this only involves an additional check: if the elements in the color arg list are not found in `obs.columns` nor `var.columns`, then check the keys in `obsm` and use the entire dataframe behind this key.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1500
https://github.com/scverse/scanpy/issues/1500:822,availability,Cluster,Clustering,822,"Support obsm key to color UMAP; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. Quite often I need to color UMAPs based on features that are not part of `adata.X` but `adata.obsm` for the reason that they are special. E.g. KO data with gRNAs versus endogenes/ target genes, or viral genes versus edogenes. Example use case: . - Cluster cells based on endogenes. - UMAP and color by a bunch of viral genes. Clustering must not include these viral genes -> must be excluded from `X`. . I don't want to store so many additional columns in `obs` and I need to have these features separated in their own matrix for downstream analysis, which is why I want to use `obsm`. Can we have sth. like this:. ```. sc.pl.umap(adata, color='viral_genes') # adata.obsm['viral_genes'] is a pandas.DataFrame ? ```. It shouldn't be overcomplicated I think, since this only involves an additional check: if the elements in the color arg list are not found in `obs.columns` nor `var.columns`, then check the keys in `obsm` and use the entire dataframe behind this key.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1500
https://github.com/scverse/scanpy/issues/1500:1026,availability,down,downstream,1026,"Support obsm key to color UMAP; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. Quite often I need to color UMAPs based on features that are not part of `adata.X` but `adata.obsm` for the reason that they are special. E.g. KO data with gRNAs versus endogenes/ target genes, or viral genes versus edogenes. Example use case: . - Cluster cells based on endogenes. - UMAP and color by a bunch of viral genes. Clustering must not include these viral genes -> must be excluded from `X`. . I don't want to store so many additional columns in `obs` and I need to have these features separated in their own matrix for downstream analysis, which is why I want to use `obsm`. Can we have sth. like this:. ```. sc.pl.umap(adata, color='viral_genes') # adata.obsm['viral_genes'] is a pandas.DataFrame ? ```. It shouldn't be overcomplicated I think, since this only involves an additional check: if the elements in the color arg list are not found in `obs.columns` nor `var.columns`, then check the keys in `obsm` and use the entire dataframe behind this key.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1500
https://github.com/scverse/scanpy/issues/1500:744,deployability,Cluster,Cluster,744,"Support obsm key to color UMAP; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. Quite often I need to color UMAPs based on features that are not part of `adata.X` but `adata.obsm` for the reason that they are special. E.g. KO data with gRNAs versus endogenes/ target genes, or viral genes versus edogenes. Example use case: . - Cluster cells based on endogenes. - UMAP and color by a bunch of viral genes. Clustering must not include these viral genes -> must be excluded from `X`. . I don't want to store so many additional columns in `obs` and I need to have these features separated in their own matrix for downstream analysis, which is why I want to use `obsm`. Can we have sth. like this:. ```. sc.pl.umap(adata, color='viral_genes') # adata.obsm['viral_genes'] is a pandas.DataFrame ? ```. It shouldn't be overcomplicated I think, since this only involves an additional check: if the elements in the color arg list are not found in `obs.columns` nor `var.columns`, then check the keys in `obsm` and use the entire dataframe behind this key.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1500
https://github.com/scverse/scanpy/issues/1500:822,deployability,Cluster,Clustering,822,"Support obsm key to color UMAP; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. Quite often I need to color UMAPs based on features that are not part of `adata.X` but `adata.obsm` for the reason that they are special. E.g. KO data with gRNAs versus endogenes/ target genes, or viral genes versus edogenes. Example use case: . - Cluster cells based on endogenes. - UMAP and color by a bunch of viral genes. Clustering must not include these viral genes -> must be excluded from `X`. . I don't want to store so many additional columns in `obs` and I need to have these features separated in their own matrix for downstream analysis, which is why I want to use `obsm`. Can we have sth. like this:. ```. sc.pl.umap(adata, color='viral_genes') # adata.obsm['viral_genes'] is a pandas.DataFrame ? ```. It shouldn't be overcomplicated I think, since this only involves an additional check: if the elements in the color arg list are not found in `obs.columns` nor `var.columns`, then check the keys in `obsm` and use the entire dataframe behind this key.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1500
https://github.com/scverse/scanpy/issues/1500:116,modifiability,paramet,parameters,116,"Support obsm key to color UMAP; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. Quite often I need to color UMAPs based on features that are not part of `adata.X` but `adata.obsm` for the reason that they are special. E.g. KO data with gRNAs versus endogenes/ target genes, or viral genes versus edogenes. Example use case: . - Cluster cells based on endogenes. - UMAP and color by a bunch of viral genes. Clustering must not include these viral genes -> must be excluded from `X`. . I don't want to store so many additional columns in `obs` and I need to have these features separated in their own matrix for downstream analysis, which is why I want to use `obsm`. Can we have sth. like this:. ```. sc.pl.umap(adata, color='viral_genes') # adata.obsm['viral_genes'] is a pandas.DataFrame ? ```. It shouldn't be overcomplicated I think, since this only involves an additional check: if the elements in the color arg list are not found in `obs.columns` nor `var.columns`, then check the keys in `obsm` and use the entire dataframe behind this key.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1500
https://github.com/scverse/scanpy/issues/1500:393,modifiability,pac,package,393,"Support obsm key to color UMAP; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. Quite often I need to color UMAPs based on features that are not part of `adata.X` but `adata.obsm` for the reason that they are special. E.g. KO data with gRNAs versus endogenes/ target genes, or viral genes versus edogenes. Example use case: . - Cluster cells based on endogenes. - UMAP and color by a bunch of viral genes. Clustering must not include these viral genes -> must be excluded from `X`. . I don't want to store so many additional columns in `obs` and I need to have these features separated in their own matrix for downstream analysis, which is why I want to use `obsm`. Can we have sth. like this:. ```. sc.pl.umap(adata, color='viral_genes') # adata.obsm['viral_genes'] is a pandas.DataFrame ? ```. It shouldn't be overcomplicated I think, since this only involves an additional check: if the elements in the color arg list are not found in `obs.columns` nor `var.columns`, then check the keys in `obsm` and use the entire dataframe behind this key.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1500
https://github.com/scverse/scanpy/issues/1500:198,testability,simpl,simple,198,"Support obsm key to color UMAP; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. Quite often I need to color UMAPs based on features that are not part of `adata.X` but `adata.obsm` for the reason that they are special. E.g. KO data with gRNAs versus endogenes/ target genes, or viral genes versus edogenes. Example use case: . - Cluster cells based on endogenes. - UMAP and color by a bunch of viral genes. Clustering must not include these viral genes -> must be excluded from `X`. . I don't want to store so many additional columns in `obs` and I need to have these features separated in their own matrix for downstream analysis, which is why I want to use `obsm`. Can we have sth. like this:. ```. sc.pl.umap(adata, color='viral_genes') # adata.obsm['viral_genes'] is a pandas.DataFrame ? ```. It shouldn't be overcomplicated I think, since this only involves an additional check: if the elements in the color arg list are not found in `obs.columns` nor `var.columns`, then check the keys in `obsm` and use the entire dataframe behind this key.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1500
https://github.com/scverse/scanpy/issues/1500:0,usability,Support,Support,0,"Support obsm key to color UMAP; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. Quite often I need to color UMAPs based on features that are not part of `adata.X` but `adata.obsm` for the reason that they are special. E.g. KO data with gRNAs versus endogenes/ target genes, or viral genes versus edogenes. Example use case: . - Cluster cells based on endogenes. - UMAP and color by a bunch of viral genes. Clustering must not include these viral genes -> must be excluded from `X`. . I don't want to store so many additional columns in `obs` and I need to have these features separated in their own matrix for downstream analysis, which is why I want to use `obsm`. Can we have sth. like this:. ```. sc.pl.umap(adata, color='viral_genes') # adata.obsm['viral_genes'] is a pandas.DataFrame ? ```. It shouldn't be overcomplicated I think, since this only involves an additional check: if the elements in the color arg list are not found in `obs.columns` nor `var.columns`, then check the keys in `obsm` and use the entire dataframe behind this key.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1500
https://github.com/scverse/scanpy/issues/1500:190,usability,tool,tool,190,"Support obsm key to color UMAP; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. Quite often I need to color UMAPs based on features that are not part of `adata.X` but `adata.obsm` for the reason that they are special. E.g. KO data with gRNAs versus endogenes/ target genes, or viral genes versus edogenes. Example use case: . - Cluster cells based on endogenes. - UMAP and color by a bunch of viral genes. Clustering must not include these viral genes -> must be excluded from `X`. . I don't want to store so many additional columns in `obs` and I need to have these features separated in their own matrix for downstream analysis, which is why I want to use `obsm`. Can we have sth. like this:. ```. sc.pl.umap(adata, color='viral_genes') # adata.obsm['viral_genes'] is a pandas.DataFrame ? ```. It shouldn't be overcomplicated I think, since this only involves an additional check: if the elements in the color arg list are not found in `obs.columns` nor `var.columns`, then check the keys in `obsm` and use the entire dataframe behind this key.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1500
https://github.com/scverse/scanpy/issues/1500:198,usability,simpl,simple,198,"Support obsm key to color UMAP; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. Quite often I need to color UMAPs based on features that are not part of `adata.X` but `adata.obsm` for the reason that they are special. E.g. KO data with gRNAs versus endogenes/ target genes, or viral genes versus edogenes. Example use case: . - Cluster cells based on endogenes. - UMAP and color by a bunch of viral genes. Clustering must not include these viral genes -> must be excluded from `X`. . I don't want to store so many additional columns in `obs` and I need to have these features separated in their own matrix for downstream analysis, which is why I want to use `obsm`. Can we have sth. like this:. ```. sc.pl.umap(adata, color='viral_genes') # adata.obsm['viral_genes'] is a pandas.DataFrame ? ```. It shouldn't be overcomplicated I think, since this only involves an additional check: if the elements in the color arg list are not found in `obs.columns` nor `var.columns`, then check the keys in `obsm` and use the entire dataframe behind this key.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1500
https://github.com/scverse/scanpy/issues/1500:214,usability,tool,tool,214,"Support obsm key to color UMAP; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. Quite often I need to color UMAPs based on features that are not part of `adata.X` but `adata.obsm` for the reason that they are special. E.g. KO data with gRNAs versus endogenes/ target genes, or viral genes versus edogenes. Example use case: . - Cluster cells based on endogenes. - UMAP and color by a bunch of viral genes. Clustering must not include these viral genes -> must be excluded from `X`. . I don't want to store so many additional columns in `obs` and I need to have these features separated in their own matrix for downstream analysis, which is why I want to use `obsm`. Can we have sth. like this:. ```. sc.pl.umap(adata, color='viral_genes') # adata.obsm['viral_genes'] is a pandas.DataFrame ? ```. It shouldn't be overcomplicated I think, since this only involves an additional check: if the elements in the color arg list are not found in `obs.columns` nor `var.columns`, then check the keys in `obsm` and use the entire dataframe behind this key.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1500
https://github.com/scverse/scanpy/issues/1500:262,usability,tool,tools,262,"Support obsm key to color UMAP; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. Quite often I need to color UMAPs based on features that are not part of `adata.X` but `adata.obsm` for the reason that they are special. E.g. KO data with gRNAs versus endogenes/ target genes, or viral genes versus edogenes. Example use case: . - Cluster cells based on endogenes. - UMAP and color by a bunch of viral genes. Clustering must not include these viral genes -> must be excluded from `X`. . I don't want to store so many additional columns in `obs` and I need to have these features separated in their own matrix for downstream analysis, which is why I want to use `obsm`. Can we have sth. like this:. ```. sc.pl.umap(adata, color='viral_genes') # adata.obsm['viral_genes'] is a pandas.DataFrame ? ```. It shouldn't be overcomplicated I think, since this only involves an additional check: if the elements in the color arg list are not found in `obs.columns` nor `var.columns`, then check the keys in `obsm` and use the entire dataframe behind this key.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1500
https://github.com/scverse/scanpy/issues/1500:362,usability,tool,tools,362,"Support obsm key to color UMAP; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. Quite often I need to color UMAPs based on features that are not part of `adata.X` but `adata.obsm` for the reason that they are special. E.g. KO data with gRNAs versus endogenes/ target genes, or viral genes versus edogenes. Example use case: . - Cluster cells based on endogenes. - UMAP and color by a bunch of viral genes. Clustering must not include these viral genes -> must be excluded from `X`. . I don't want to store so many additional columns in `obs` and I need to have these features separated in their own matrix for downstream analysis, which is why I want to use `obsm`. Can we have sth. like this:. ```. sc.pl.umap(adata, color='viral_genes') # adata.obsm['viral_genes'] is a pandas.DataFrame ? ```. It shouldn't be overcomplicated I think, since this only involves an additional check: if the elements in the color arg list are not found in `obs.columns` nor `var.columns`, then check the keys in `obsm` and use the entire dataframe behind this key.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1500
https://github.com/scverse/scanpy/pull/1501:81,integrability,pub,publication,81,"Adjust Combat for control cells; I wrote this adjustment for Combat for a recent publication (Boettcher et al, 2020): https://www.biorxiv.org/content/10.1101/2020.08.12.247585v1. It allows to compute a ComBat for control cells and apply this to a second set of cells.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1501
https://github.com/scverse/scanpy/pull/1501:142,performance,content,content,142,"Adjust Combat for control cells; I wrote this adjustment for Combat for a recent publication (Boettcher et al, 2020): https://www.biorxiv.org/content/10.1101/2020.08.12.247585v1. It allows to compute a ComBat for control cells and apply this to a second set of cells.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1501
https://github.com/scverse/scanpy/pull/1501:18,security,control,control,18,"Adjust Combat for control cells; I wrote this adjustment for Combat for a recent publication (Boettcher et al, 2020): https://www.biorxiv.org/content/10.1101/2020.08.12.247585v1. It allows to compute a ComBat for control cells and apply this to a second set of cells.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1501
https://github.com/scverse/scanpy/pull/1501:213,security,control,control,213,"Adjust Combat for control cells; I wrote this adjustment for Combat for a recent publication (Boettcher et al, 2020): https://www.biorxiv.org/content/10.1101/2020.08.12.247585v1. It allows to compute a ComBat for control cells and apply this to a second set of cells.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1501
https://github.com/scverse/scanpy/pull/1501:18,testability,control,control,18,"Adjust Combat for control cells; I wrote this adjustment for Combat for a recent publication (Boettcher et al, 2020): https://www.biorxiv.org/content/10.1101/2020.08.12.247585v1. It allows to compute a ComBat for control cells and apply this to a second set of cells.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1501
https://github.com/scverse/scanpy/pull/1501:213,testability,control,control,213,"Adjust Combat for control cells; I wrote this adjustment for Combat for a recent publication (Boettcher et al, 2020): https://www.biorxiv.org/content/10.1101/2020.08.12.247585v1. It allows to compute a ComBat for control cells and apply this to a second set of cells.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1501
https://github.com/scverse/scanpy/issues/1502:139,modifiability,paramet,parameters,139,"Better document `legend_loc=None` for embedding plots; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. It is a lovely tool, but it would be great to be able to not plot figure legends in, e.g. sc.pl.umap, so that all plots (regardless of what annotation is being colored) are exactly the same size. Perhaps there is already a way to do this, but I've yet to find it. . Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1502
https://github.com/scverse/scanpy/issues/1502:416,modifiability,pac,package,416,"Better document `legend_loc=None` for embedding plots; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. It is a lovely tool, but it would be great to be able to not plot figure legends in, e.g. sc.pl.umap, so that all plots (regardless of what annotation is being colored) are exactly the same size. Perhaps there is already a way to do this, but I've yet to find it. . Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1502
https://github.com/scverse/scanpy/issues/1502:221,testability,simpl,simple,221,"Better document `legend_loc=None` for embedding plots; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. It is a lovely tool, but it would be great to be able to not plot figure legends in, e.g. sc.pl.umap, so that all plots (regardless of what annotation is being colored) are exactly the same size. Perhaps there is already a way to do this, but I've yet to find it. . Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1502
https://github.com/scverse/scanpy/issues/1502:7,usability,document,document,7,"Better document `legend_loc=None` for embedding plots; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. It is a lovely tool, but it would be great to be able to not plot figure legends in, e.g. sc.pl.umap, so that all plots (regardless of what annotation is being colored) are exactly the same size. Perhaps there is already a way to do this, but I've yet to find it. . Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1502
https://github.com/scverse/scanpy/issues/1502:213,usability,tool,tool,213,"Better document `legend_loc=None` for embedding plots; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. It is a lovely tool, but it would be great to be able to not plot figure legends in, e.g. sc.pl.umap, so that all plots (regardless of what annotation is being colored) are exactly the same size. Perhaps there is already a way to do this, but I've yet to find it. . Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1502
https://github.com/scverse/scanpy/issues/1502:221,usability,simpl,simple,221,"Better document `legend_loc=None` for embedding plots; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. It is a lovely tool, but it would be great to be able to not plot figure legends in, e.g. sc.pl.umap, so that all plots (regardless of what annotation is being colored) are exactly the same size. Perhaps there is already a way to do this, but I've yet to find it. . Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1502
https://github.com/scverse/scanpy/issues/1502:237,usability,tool,tool,237,"Better document `legend_loc=None` for embedding plots; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. It is a lovely tool, but it would be great to be able to not plot figure legends in, e.g. sc.pl.umap, so that all plots (regardless of what annotation is being colored) are exactly the same size. Perhaps there is already a way to do this, but I've yet to find it. . Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1502
https://github.com/scverse/scanpy/issues/1502:285,usability,tool,tools,285,"Better document `legend_loc=None` for embedding plots; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. It is a lovely tool, but it would be great to be able to not plot figure legends in, e.g. sc.pl.umap, so that all plots (regardless of what annotation is being colored) are exactly the same size. Perhaps there is already a way to do this, but I've yet to find it. . Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1502
https://github.com/scverse/scanpy/issues/1502:385,usability,tool,tools,385,"Better document `legend_loc=None` for embedding plots; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. It is a lovely tool, but it would be great to be able to not plot figure legends in, e.g. sc.pl.umap, so that all plots (regardless of what annotation is being colored) are exactly the same size. Perhaps there is already a way to do this, but I've yet to find it. . Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1502
https://github.com/scverse/scanpy/issues/1502:534,usability,tool,tool,534,"Better document `legend_loc=None` for embedding plots; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. It is a lovely tool, but it would be great to be able to not plot figure legends in, e.g. sc.pl.umap, so that all plots (regardless of what annotation is being colored) are exactly the same size. Perhaps there is already a way to do this, but I've yet to find it. . Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1502
https://github.com/scverse/scanpy/issues/1503:185,energy efficiency,predict,prediction,185,"Imaging Mass Cytometry data; Hi everyone,. Thank you for scanpy! I use it very frequently for my research. I am getting started with spatial data, and would like to ask if there is any prediction for when IMC data will be supported? You mention this in the [spatial transcriptomics tutorial](https://scanpy-tutorials.readthedocs.io/en/latest/spatial/basic-analysis.html) so I suppose it's coming soon -- but how soon? If you have started something and need an extra pair of hands to get it done, I would be happy to contribute! . Thanks,. Pedro",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1503
https://github.com/scverse/scanpy/issues/1503:185,safety,predict,prediction,185,"Imaging Mass Cytometry data; Hi everyone,. Thank you for scanpy! I use it very frequently for my research. I am getting started with spatial data, and would like to ask if there is any prediction for when IMC data will be supported? You mention this in the [spatial transcriptomics tutorial](https://scanpy-tutorials.readthedocs.io/en/latest/spatial/basic-analysis.html) so I suppose it's coming soon -- but how soon? If you have started something and need an extra pair of hands to get it done, I would be happy to contribute! . Thanks,. Pedro",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1503
https://github.com/scverse/scanpy/issues/1503:222,usability,support,supported,222,"Imaging Mass Cytometry data; Hi everyone,. Thank you for scanpy! I use it very frequently for my research. I am getting started with spatial data, and would like to ask if there is any prediction for when IMC data will be supported? You mention this in the [spatial transcriptomics tutorial](https://scanpy-tutorials.readthedocs.io/en/latest/spatial/basic-analysis.html) so I suppose it's coming soon -- but how soon? If you have started something and need an extra pair of hands to get it done, I would be happy to contribute! . Thanks,. Pedro",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1503
https://github.com/scverse/scanpy/issues/1504:693,availability,error,error,693,"ValueError: b'There are other near singularities as well. 0.090619\n'; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. ---. Hi, . Trying to run `scVI` to analyse my data using the latest `scanpy+scvi-tools` workflow, as described [here](https://www.scvi-tools.org/en/stable/user_guide/notebooks/harmonization.html). However, I'm running into a weird issue with the new `seurat_v3` flavour to call HVGs. When I run this:. ```python. sc.pp.highly_variable_genes(. adata,. flavor = ""seurat_v3"",. n_top_genes = 7000,. layer = ""counts"",. batch_key = ""combined"",. subset = True. ). ```. I get the following error:. ```pytb. If you pass `n_top_genes`, all cutoffs are ignored. extracting highly variable genes. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-19-3748de5bacdc> in <module>. 5 layer = ""counts"",. 6 batch_key = ""combined"",. ----> 7 subset = True. 8 ). 9 adata. /opt/conda/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key). 420 span=span,. 421 subset=subset,. --> 422 inplace=inplace,. 423 ). 424 . /opt/conda/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, span, subset, inplace). 82 x = np.log10(mean[not_const]). 83 model = loess(x, y, span=span, degree=2). ---> 84 model.fit(). 85 estimat_var[not_const] = model.outputs.fitted_values. 86 reg_std = np.sqrt(10 ** estimat_var). _loess.pyx in _loess.loess.fit(). ValueError: b'There are other near singularities as well. 0.090619\n'. ```. While looking for a solution, I came across [this](https://github.com/YosefLab/scvi-tools/issues/727#issuecomment-718717033) issue that reports a similar p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1504
https://github.com/scverse/scanpy/issues/1504:192,deployability,version,version,192,"ValueError: b'There are other near singularities as well. 0.090619\n'; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. ---. Hi, . Trying to run `scVI` to analyse my data using the latest `scanpy+scvi-tools` workflow, as described [here](https://www.scvi-tools.org/en/stable/user_guide/notebooks/harmonization.html). However, I'm running into a weird issue with the new `seurat_v3` flavour to call HVGs. When I run this:. ```python. sc.pp.highly_variable_genes(. adata,. flavor = ""seurat_v3"",. n_top_genes = 7000,. layer = ""counts"",. batch_key = ""combined"",. subset = True. ). ```. I get the following error:. ```pytb. If you pass `n_top_genes`, all cutoffs are ignored. extracting highly variable genes. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-19-3748de5bacdc> in <module>. 5 layer = ""counts"",. 6 batch_key = ""combined"",. ----> 7 subset = True. 8 ). 9 adata. /opt/conda/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key). 420 span=span,. 421 subset=subset,. --> 422 inplace=inplace,. 423 ). 424 . /opt/conda/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, span, subset, inplace). 82 x = np.log10(mean[not_const]). 83 model = loess(x, y, span=span, degree=2). ---> 84 model.fit(). 85 estimat_var[not_const] = model.outputs.fitted_values. 86 reg_std = np.sqrt(10 ** estimat_var). _loess.pyx in _loess.loess.fit(). ValueError: b'There are other near singularities as well. 0.090619\n'. ```. While looking for a solution, I came across [this](https://github.com/YosefLab/scvi-tools/issues/727#issuecomment-718717033) issue that reports a similar p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1504
https://github.com/scverse/scanpy/issues/1504:955,deployability,modul,module,955,"ValueError: b'There are other near singularities as well. 0.090619\n'; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. ---. Hi, . Trying to run `scVI` to analyse my data using the latest `scanpy+scvi-tools` workflow, as described [here](https://www.scvi-tools.org/en/stable/user_guide/notebooks/harmonization.html). However, I'm running into a weird issue with the new `seurat_v3` flavour to call HVGs. When I run this:. ```python. sc.pp.highly_variable_genes(. adata,. flavor = ""seurat_v3"",. n_top_genes = 7000,. layer = ""counts"",. batch_key = ""combined"",. subset = True. ). ```. I get the following error:. ```pytb. If you pass `n_top_genes`, all cutoffs are ignored. extracting highly variable genes. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-19-3748de5bacdc> in <module>. 5 layer = ""counts"",. 6 batch_key = ""combined"",. ----> 7 subset = True. 8 ). 9 adata. /opt/conda/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key). 420 span=span,. 421 subset=subset,. --> 422 inplace=inplace,. 423 ). 424 . /opt/conda/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, span, subset, inplace). 82 x = np.log10(mean[not_const]). 83 model = loess(x, y, span=span, degree=2). ---> 84 model.fit(). 85 estimat_var[not_const] = model.outputs.fitted_values. 86 reg_std = np.sqrt(10 ** estimat_var). _loess.pyx in _loess.loess.fit(). ValueError: b'There are other near singularities as well. 0.090619\n'. ```. While looking for a solution, I came across [this](https://github.com/YosefLab/scvi-tools/issues/727#issuecomment-718717033) issue that reports a similar p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1504
https://github.com/scverse/scanpy/issues/1504:2055,deployability,Version,Versions,2055,"/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key). 420 span=span,. 421 subset=subset,. --> 422 inplace=inplace,. 423 ). 424 . /opt/conda/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, span, subset, inplace). 82 x = np.log10(mean[not_const]). 83 model = loess(x, y, span=span, degree=2). ---> 84 model.fit(). 85 estimat_var[not_const] = model.outputs.fitted_values. 86 reg_std = np.sqrt(10 ** estimat_var). _loess.pyx in _loess.loess.fit(). ValueError: b'There are other near singularities as well. 0.090619\n'. ```. While looking for a solution, I came across [this](https://github.com/YosefLab/scvi-tools/issues/727#issuecomment-718717033) issue that reports a similar problem. Any ideas of what this may be? . Thanks . #### Versions. <details>. [WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.4. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. SCCAF NA. anndata 0.7.4. backcall 0.1.0. cffi 1.14.3. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.1. get_version 2.1. google NA. h5py 2.10.0. igraph 0.8.0. importlib_metadata 1.7.0. ipykernel 5.1.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.16.0. joblib 0.17.0. kiwisolver 1.1.0. legacy_api_wrap 1.2. leidenalg 0.8.2. llvmlite 0.31.0. louvain 0.6.1. matplotlib 3.1.3. mpl_toolkits NA. natsort 7.0.1. numba 0.48.0. numexpr 2.7.1. numpy 1.19.4. packaging 20.4. pandas 1.1.4. parso 0.6.1. patsy 0.5.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.3. psutil 5.7.2. ptyprocess 0.6.0. pycparser 2.20. pygments 2.7.2. pyparsing 2.4.7. pytz 2020.1. rich NA. ruamel NA. scanpy 1.6.0. scipy 1.5.4. scvi 0.7.1. seaborn 0.10.0. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. statsm",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1504
https://github.com/scverse/scanpy/issues/1504:3528,deployability,log,logical,3528,"4 model.fit(). 85 estimat_var[not_const] = model.outputs.fitted_values. 86 reg_std = np.sqrt(10 ** estimat_var). _loess.pyx in _loess.loess.fit(). ValueError: b'There are other near singularities as well. 0.090619\n'. ```. While looking for a solution, I came across [this](https://github.com/YosefLab/scvi-tools/issues/727#issuecomment-718717033) issue that reports a similar problem. Any ideas of what this may be? . Thanks . #### Versions. <details>. [WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.4. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. SCCAF NA. anndata 0.7.4. backcall 0.1.0. cffi 1.14.3. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.1. get_version 2.1. google NA. h5py 2.10.0. igraph 0.8.0. importlib_metadata 1.7.0. ipykernel 5.1.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.16.0. joblib 0.17.0. kiwisolver 1.1.0. legacy_api_wrap 1.2. leidenalg 0.8.2. llvmlite 0.31.0. louvain 0.6.1. matplotlib 3.1.3. mpl_toolkits NA. natsort 7.0.1. numba 0.48.0. numexpr 2.7.1. numpy 1.19.4. packaging 20.4. pandas 1.1.4. parso 0.6.1. patsy 0.5.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.3. psutil 5.7.2. ptyprocess 0.6.0. pycparser 2.20. pygments 2.7.2. pyparsing 2.4.7. pytz 2020.1. rich NA. ruamel NA. scanpy 1.6.0. scipy 1.5.4. scvi 0.7.1. seaborn 0.10.0. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. statsmodels 0.11.1. storemagic NA. tables 3.6.1. texttable 1.6.2. threadpoolctl 2.1.0. torch 1.6.0. tornado 6.0.3. tqdm 4.32.2. traitlets 4.3.3. typing_extensions NA. umap 0.3.10. wcwidth NA. yaml 5.3.1. zipp NA. zmq 19.0.0. -----. IPython 7.12.0. jupyter_client 6.0.0. jupyter_core 4.6.3. jupyterlab 1.2.5. notebook 6.0.3. -----. Python 3.7.6 | packaged by conda-forge | (default, Jan 7 2020, 22:33:48) [GCC 7.3.0]. Linux-4.4.0-189-generic-x86_64-with-debian-buster-sid. 24 logical CPU cores, x86_64. -----. Session information updated at 2020-11-23 09:17. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1504
https://github.com/scverse/scanpy/issues/1504:3582,deployability,updat,updated,3582,"4 model.fit(). 85 estimat_var[not_const] = model.outputs.fitted_values. 86 reg_std = np.sqrt(10 ** estimat_var). _loess.pyx in _loess.loess.fit(). ValueError: b'There are other near singularities as well. 0.090619\n'. ```. While looking for a solution, I came across [this](https://github.com/YosefLab/scvi-tools/issues/727#issuecomment-718717033) issue that reports a similar problem. Any ideas of what this may be? . Thanks . #### Versions. <details>. [WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.4. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. SCCAF NA. anndata 0.7.4. backcall 0.1.0. cffi 1.14.3. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.1. get_version 2.1. google NA. h5py 2.10.0. igraph 0.8.0. importlib_metadata 1.7.0. ipykernel 5.1.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.16.0. joblib 0.17.0. kiwisolver 1.1.0. legacy_api_wrap 1.2. leidenalg 0.8.2. llvmlite 0.31.0. louvain 0.6.1. matplotlib 3.1.3. mpl_toolkits NA. natsort 7.0.1. numba 0.48.0. numexpr 2.7.1. numpy 1.19.4. packaging 20.4. pandas 1.1.4. parso 0.6.1. patsy 0.5.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.3. psutil 5.7.2. ptyprocess 0.6.0. pycparser 2.20. pygments 2.7.2. pyparsing 2.4.7. pytz 2020.1. rich NA. ruamel NA. scanpy 1.6.0. scipy 1.5.4. scvi 0.7.1. seaborn 0.10.0. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. statsmodels 0.11.1. storemagic NA. tables 3.6.1. texttable 1.6.2. threadpoolctl 2.1.0. torch 1.6.0. tornado 6.0.3. tqdm 4.32.2. traitlets 4.3.3. typing_extensions NA. umap 0.3.10. wcwidth NA. yaml 5.3.1. zipp NA. zmq 19.0.0. -----. IPython 7.12.0. jupyter_client 6.0.0. jupyter_core 4.6.3. jupyterlab 1.2.5. notebook 6.0.3. -----. Python 3.7.6 | packaged by conda-forge | (default, Jan 7 2020, 22:33:48) [GCC 7.3.0]. Linux-4.4.0-189-generic-x86_64-with-debian-buster-sid. 24 logical CPU cores, x86_64. -----. Session information updated at 2020-11-23 09:17. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1504
https://github.com/scverse/scanpy/issues/1504:1574,energy efficiency,model,model,1574,"t_v3"",. n_top_genes = 7000,. layer = ""counts"",. batch_key = ""combined"",. subset = True. ). ```. I get the following error:. ```pytb. If you pass `n_top_genes`, all cutoffs are ignored. extracting highly variable genes. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-19-3748de5bacdc> in <module>. 5 layer = ""counts"",. 6 batch_key = ""combined"",. ----> 7 subset = True. 8 ). 9 adata. /opt/conda/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key). 420 span=span,. 421 subset=subset,. --> 422 inplace=inplace,. 423 ). 424 . /opt/conda/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, span, subset, inplace). 82 x = np.log10(mean[not_const]). 83 model = loess(x, y, span=span, degree=2). ---> 84 model.fit(). 85 estimat_var[not_const] = model.outputs.fitted_values. 86 reg_std = np.sqrt(10 ** estimat_var). _loess.pyx in _loess.loess.fit(). ValueError: b'There are other near singularities as well. 0.090619\n'. ```. While looking for a solution, I came across [this](https://github.com/YosefLab/scvi-tools/issues/727#issuecomment-718717033) issue that reports a similar problem. Any ideas of what this may be? . Thanks . #### Versions. <details>. [WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.4. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. SCCAF NA. anndata 0.7.4. backcall 0.1.0. cffi 1.14.3. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.1. get_version 2.1. google NA. h5py 2.10.0. igraph 0.8.0. importlib_metadata 1.7.0. ipykernel 5.1.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.16.0. joblib 0.17.0. kiwisolver 1.1.0. legacy_api_wrap 1.2. leidenalg 0.8.2. llvmlite",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1504
https://github.com/scverse/scanpy/issues/1504:1624,energy efficiency,model,model,1624,"tch_key = ""combined"",. subset = True. ). ```. I get the following error:. ```pytb. If you pass `n_top_genes`, all cutoffs are ignored. extracting highly variable genes. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-19-3748de5bacdc> in <module>. 5 layer = ""counts"",. 6 batch_key = ""combined"",. ----> 7 subset = True. 8 ). 9 adata. /opt/conda/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key). 420 span=span,. 421 subset=subset,. --> 422 inplace=inplace,. 423 ). 424 . /opt/conda/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, span, subset, inplace). 82 x = np.log10(mean[not_const]). 83 model = loess(x, y, span=span, degree=2). ---> 84 model.fit(). 85 estimat_var[not_const] = model.outputs.fitted_values. 86 reg_std = np.sqrt(10 ** estimat_var). _loess.pyx in _loess.loess.fit(). ValueError: b'There are other near singularities as well. 0.090619\n'. ```. While looking for a solution, I came across [this](https://github.com/YosefLab/scvi-tools/issues/727#issuecomment-718717033) issue that reports a similar problem. Any ideas of what this may be? . Thanks . #### Versions. <details>. [WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.4. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. SCCAF NA. anndata 0.7.4. backcall 0.1.0. cffi 1.14.3. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.1. get_version 2.1. google NA. h5py 2.10.0. igraph 0.8.0. importlib_metadata 1.7.0. ipykernel 5.1.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.16.0. joblib 0.17.0. kiwisolver 1.1.0. legacy_api_wrap 1.2. leidenalg 0.8.2. llvmlite 0.31.0. louvain 0.6.1. matplotlib 3.1.3. mpl_tool",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1504
https://github.com/scverse/scanpy/issues/1504:1665,energy efficiency,model,model,1665,"```. I get the following error:. ```pytb. If you pass `n_top_genes`, all cutoffs are ignored. extracting highly variable genes. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-19-3748de5bacdc> in <module>. 5 layer = ""counts"",. 6 batch_key = ""combined"",. ----> 7 subset = True. 8 ). 9 adata. /opt/conda/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key). 420 span=span,. 421 subset=subset,. --> 422 inplace=inplace,. 423 ). 424 . /opt/conda/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, span, subset, inplace). 82 x = np.log10(mean[not_const]). 83 model = loess(x, y, span=span, degree=2). ---> 84 model.fit(). 85 estimat_var[not_const] = model.outputs.fitted_values. 86 reg_std = np.sqrt(10 ** estimat_var). _loess.pyx in _loess.loess.fit(). ValueError: b'There are other near singularities as well. 0.090619\n'. ```. While looking for a solution, I came across [this](https://github.com/YosefLab/scvi-tools/issues/727#issuecomment-718717033) issue that reports a similar problem. Any ideas of what this may be? . Thanks . #### Versions. <details>. [WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.4. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. SCCAF NA. anndata 0.7.4. backcall 0.1.0. cffi 1.14.3. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.1. get_version 2.1. google NA. h5py 2.10.0. igraph 0.8.0. importlib_metadata 1.7.0. ipykernel 5.1.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.16.0. joblib 0.17.0. kiwisolver 1.1.0. legacy_api_wrap 1.2. leidenalg 0.8.2. llvmlite 0.31.0. louvain 0.6.1. matplotlib 3.1.3. mpl_toolkits NA. natsort 7.0.1. numba 0.48.0. num",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1504
https://github.com/scverse/scanpy/issues/1504:3536,energy efficiency,CPU,CPU,3536,"4 model.fit(). 85 estimat_var[not_const] = model.outputs.fitted_values. 86 reg_std = np.sqrt(10 ** estimat_var). _loess.pyx in _loess.loess.fit(). ValueError: b'There are other near singularities as well. 0.090619\n'. ```. While looking for a solution, I came across [this](https://github.com/YosefLab/scvi-tools/issues/727#issuecomment-718717033) issue that reports a similar problem. Any ideas of what this may be? . Thanks . #### Versions. <details>. [WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.4. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. SCCAF NA. anndata 0.7.4. backcall 0.1.0. cffi 1.14.3. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.1. get_version 2.1. google NA. h5py 2.10.0. igraph 0.8.0. importlib_metadata 1.7.0. ipykernel 5.1.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.16.0. joblib 0.17.0. kiwisolver 1.1.0. legacy_api_wrap 1.2. leidenalg 0.8.2. llvmlite 0.31.0. louvain 0.6.1. matplotlib 3.1.3. mpl_toolkits NA. natsort 7.0.1. numba 0.48.0. numexpr 2.7.1. numpy 1.19.4. packaging 20.4. pandas 1.1.4. parso 0.6.1. patsy 0.5.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.3. psutil 5.7.2. ptyprocess 0.6.0. pycparser 2.20. pygments 2.7.2. pyparsing 2.4.7. pytz 2020.1. rich NA. ruamel NA. scanpy 1.6.0. scipy 1.5.4. scvi 0.7.1. seaborn 0.10.0. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. statsmodels 0.11.1. storemagic NA. tables 3.6.1. texttable 1.6.2. threadpoolctl 2.1.0. torch 1.6.0. tornado 6.0.3. tqdm 4.32.2. traitlets 4.3.3. typing_extensions NA. umap 0.3.10. wcwidth NA. yaml 5.3.1. zipp NA. zmq 19.0.0. -----. IPython 7.12.0. jupyter_client 6.0.0. jupyter_core 4.6.3. jupyterlab 1.2.5. notebook 6.0.3. -----. Python 3.7.6 | packaged by conda-forge | (default, Jan 7 2020, 22:33:48) [GCC 7.3.0]. Linux-4.4.0-189-generic-x86_64-with-debian-buster-sid. 24 logical CPU cores, x86_64. -----. Session information updated at 2020-11-23 09:17. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1504
https://github.com/scverse/scanpy/issues/1504:3540,energy efficiency,core,cores,3540,"4 model.fit(). 85 estimat_var[not_const] = model.outputs.fitted_values. 86 reg_std = np.sqrt(10 ** estimat_var). _loess.pyx in _loess.loess.fit(). ValueError: b'There are other near singularities as well. 0.090619\n'. ```. While looking for a solution, I came across [this](https://github.com/YosefLab/scvi-tools/issues/727#issuecomment-718717033) issue that reports a similar problem. Any ideas of what this may be? . Thanks . #### Versions. <details>. [WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.4. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. SCCAF NA. anndata 0.7.4. backcall 0.1.0. cffi 1.14.3. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.1. get_version 2.1. google NA. h5py 2.10.0. igraph 0.8.0. importlib_metadata 1.7.0. ipykernel 5.1.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.16.0. joblib 0.17.0. kiwisolver 1.1.0. legacy_api_wrap 1.2. leidenalg 0.8.2. llvmlite 0.31.0. louvain 0.6.1. matplotlib 3.1.3. mpl_toolkits NA. natsort 7.0.1. numba 0.48.0. numexpr 2.7.1. numpy 1.19.4. packaging 20.4. pandas 1.1.4. parso 0.6.1. patsy 0.5.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.3. psutil 5.7.2. ptyprocess 0.6.0. pycparser 2.20. pygments 2.7.2. pyparsing 2.4.7. pytz 2020.1. rich NA. ruamel NA. scanpy 1.6.0. scipy 1.5.4. scvi 0.7.1. seaborn 0.10.0. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. statsmodels 0.11.1. storemagic NA. tables 3.6.1. texttable 1.6.2. threadpoolctl 2.1.0. torch 1.6.0. tornado 6.0.3. tqdm 4.32.2. traitlets 4.3.3. typing_extensions NA. umap 0.3.10. wcwidth NA. yaml 5.3.1. zipp NA. zmq 19.0.0. -----. IPython 7.12.0. jupyter_client 6.0.0. jupyter_core 4.6.3. jupyterlab 1.2.5. notebook 6.0.3. -----. Python 3.7.6 | packaged by conda-forge | (default, Jan 7 2020, 22:33:48) [GCC 7.3.0]. Linux-4.4.0-189-generic-x86_64-with-debian-buster-sid. 24 logical CPU cores, x86_64. -----. Session information updated at 2020-11-23 09:17. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1504
https://github.com/scverse/scanpy/issues/1504:192,integrability,version,version,192,"ValueError: b'There are other near singularities as well. 0.090619\n'; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. ---. Hi, . Trying to run `scVI` to analyse my data using the latest `scanpy+scvi-tools` workflow, as described [here](https://www.scvi-tools.org/en/stable/user_guide/notebooks/harmonization.html). However, I'm running into a weird issue with the new `seurat_v3` flavour to call HVGs. When I run this:. ```python. sc.pp.highly_variable_genes(. adata,. flavor = ""seurat_v3"",. n_top_genes = 7000,. layer = ""counts"",. batch_key = ""combined"",. subset = True. ). ```. I get the following error:. ```pytb. If you pass `n_top_genes`, all cutoffs are ignored. extracting highly variable genes. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-19-3748de5bacdc> in <module>. 5 layer = ""counts"",. 6 batch_key = ""combined"",. ----> 7 subset = True. 8 ). 9 adata. /opt/conda/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key). 420 span=span,. 421 subset=subset,. --> 422 inplace=inplace,. 423 ). 424 . /opt/conda/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, span, subset, inplace). 82 x = np.log10(mean[not_const]). 83 model = loess(x, y, span=span, degree=2). ---> 84 model.fit(). 85 estimat_var[not_const] = model.outputs.fitted_values. 86 reg_std = np.sqrt(10 ** estimat_var). _loess.pyx in _loess.loess.fit(). ValueError: b'There are other near singularities as well. 0.090619\n'. ```. While looking for a solution, I came across [this](https://github.com/YosefLab/scvi-tools/issues/727#issuecomment-718717033) issue that reports a similar p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1504
https://github.com/scverse/scanpy/issues/1504:650,integrability,sub,subset,650,"ValueError: b'There are other near singularities as well. 0.090619\n'; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. ---. Hi, . Trying to run `scVI` to analyse my data using the latest `scanpy+scvi-tools` workflow, as described [here](https://www.scvi-tools.org/en/stable/user_guide/notebooks/harmonization.html). However, I'm running into a weird issue with the new `seurat_v3` flavour to call HVGs. When I run this:. ```python. sc.pp.highly_variable_genes(. adata,. flavor = ""seurat_v3"",. n_top_genes = 7000,. layer = ""counts"",. batch_key = ""combined"",. subset = True. ). ```. I get the following error:. ```pytb. If you pass `n_top_genes`, all cutoffs are ignored. extracting highly variable genes. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-19-3748de5bacdc> in <module>. 5 layer = ""counts"",. 6 batch_key = ""combined"",. ----> 7 subset = True. 8 ). 9 adata. /opt/conda/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key). 420 span=span,. 421 subset=subset,. --> 422 inplace=inplace,. 423 ). 424 . /opt/conda/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, span, subset, inplace). 82 x = np.log10(mean[not_const]). 83 model = loess(x, y, span=span, degree=2). ---> 84 model.fit(). 85 estimat_var[not_const] = model.outputs.fitted_values. 86 reg_std = np.sqrt(10 ** estimat_var). _loess.pyx in _loess.loess.fit(). ValueError: b'There are other near singularities as well. 0.090619\n'. ```. While looking for a solution, I came across [this](https://github.com/YosefLab/scvi-tools/issues/727#issuecomment-718717033) issue that reports a similar p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1504
https://github.com/scverse/scanpy/issues/1504:1020,integrability,sub,subset,1020," other near singularities as well. 0.090619\n'; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. ---. Hi, . Trying to run `scVI` to analyse my data using the latest `scanpy+scvi-tools` workflow, as described [here](https://www.scvi-tools.org/en/stable/user_guide/notebooks/harmonization.html). However, I'm running into a weird issue with the new `seurat_v3` flavour to call HVGs. When I run this:. ```python. sc.pp.highly_variable_genes(. adata,. flavor = ""seurat_v3"",. n_top_genes = 7000,. layer = ""counts"",. batch_key = ""combined"",. subset = True. ). ```. I get the following error:. ```pytb. If you pass `n_top_genes`, all cutoffs are ignored. extracting highly variable genes. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-19-3748de5bacdc> in <module>. 5 layer = ""counts"",. 6 batch_key = ""combined"",. ----> 7 subset = True. 8 ). 9 adata. /opt/conda/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key). 420 span=span,. 421 subset=subset,. --> 422 inplace=inplace,. 423 ). 424 . /opt/conda/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, span, subset, inplace). 82 x = np.log10(mean[not_const]). 83 model = loess(x, y, span=span, degree=2). ---> 84 model.fit(). 85 estimat_var[not_const] = model.outputs.fitted_values. 86 reg_std = np.sqrt(10 ** estimat_var). _loess.pyx in _loess.loess.fit(). ValueError: b'There are other near singularities as well. 0.090619\n'. ```. While looking for a solution, I came across [this](https://github.com/YosefLab/scvi-tools/issues/727#issuecomment-718717033) issue that reports a similar problem. Any ideas of wh",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1504
https://github.com/scverse/scanpy/issues/1504:1249,integrability,sub,subset,1249,"e my data using the latest `scanpy+scvi-tools` workflow, as described [here](https://www.scvi-tools.org/en/stable/user_guide/notebooks/harmonization.html). However, I'm running into a weird issue with the new `seurat_v3` flavour to call HVGs. When I run this:. ```python. sc.pp.highly_variable_genes(. adata,. flavor = ""seurat_v3"",. n_top_genes = 7000,. layer = ""counts"",. batch_key = ""combined"",. subset = True. ). ```. I get the following error:. ```pytb. If you pass `n_top_genes`, all cutoffs are ignored. extracting highly variable genes. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-19-3748de5bacdc> in <module>. 5 layer = ""counts"",. 6 batch_key = ""combined"",. ----> 7 subset = True. 8 ). 9 adata. /opt/conda/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key). 420 span=span,. 421 subset=subset,. --> 422 inplace=inplace,. 423 ). 424 . /opt/conda/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, span, subset, inplace). 82 x = np.log10(mean[not_const]). 83 model = loess(x, y, span=span, degree=2). ---> 84 model.fit(). 85 estimat_var[not_const] = model.outputs.fitted_values. 86 reg_std = np.sqrt(10 ** estimat_var). _loess.pyx in _loess.loess.fit(). ValueError: b'There are other near singularities as well. 0.090619\n'. ```. While looking for a solution, I came across [this](https://github.com/YosefLab/scvi-tools/issues/727#issuecomment-718717033) issue that reports a similar problem. Any ideas of what this may be? . Thanks . #### Versions. <details>. [WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.4. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. SCCAF NA. anndata 0.7.4. backcall 0.1.0. cff",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1504
https://github.com/scverse/scanpy/issues/1504:1298,integrability,sub,subset,1298,"rkflow, as described [here](https://www.scvi-tools.org/en/stable/user_guide/notebooks/harmonization.html). However, I'm running into a weird issue with the new `seurat_v3` flavour to call HVGs. When I run this:. ```python. sc.pp.highly_variable_genes(. adata,. flavor = ""seurat_v3"",. n_top_genes = 7000,. layer = ""counts"",. batch_key = ""combined"",. subset = True. ). ```. I get the following error:. ```pytb. If you pass `n_top_genes`, all cutoffs are ignored. extracting highly variable genes. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-19-3748de5bacdc> in <module>. 5 layer = ""counts"",. 6 batch_key = ""combined"",. ----> 7 subset = True. 8 ). 9 adata. /opt/conda/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key). 420 span=span,. 421 subset=subset,. --> 422 inplace=inplace,. 423 ). 424 . /opt/conda/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, span, subset, inplace). 82 x = np.log10(mean[not_const]). 83 model = loess(x, y, span=span, degree=2). ---> 84 model.fit(). 85 estimat_var[not_const] = model.outputs.fitted_values. 86 reg_std = np.sqrt(10 ** estimat_var). _loess.pyx in _loess.loess.fit(). ValueError: b'There are other near singularities as well. 0.090619\n'. ```. While looking for a solution, I came across [this](https://github.com/YosefLab/scvi-tools/issues/727#issuecomment-718717033) issue that reports a similar problem. Any ideas of what this may be? . Thanks . #### Versions. <details>. [WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.4. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. SCCAF NA. anndata 0.7.4. backcall 0.1.0. cffi 1.14.3. colorama 0.4.4. cycler 0.10.0. cython_r",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1504
https://github.com/scverse/scanpy/issues/1504:1305,integrability,sub,subset,1305," as described [here](https://www.scvi-tools.org/en/stable/user_guide/notebooks/harmonization.html). However, I'm running into a weird issue with the new `seurat_v3` flavour to call HVGs. When I run this:. ```python. sc.pp.highly_variable_genes(. adata,. flavor = ""seurat_v3"",. n_top_genes = 7000,. layer = ""counts"",. batch_key = ""combined"",. subset = True. ). ```. I get the following error:. ```pytb. If you pass `n_top_genes`, all cutoffs are ignored. extracting highly variable genes. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-19-3748de5bacdc> in <module>. 5 layer = ""counts"",. 6 batch_key = ""combined"",. ----> 7 subset = True. 8 ). 9 adata. /opt/conda/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key). 420 span=span,. 421 subset=subset,. --> 422 inplace=inplace,. 423 ). 424 . /opt/conda/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, span, subset, inplace). 82 x = np.log10(mean[not_const]). 83 model = loess(x, y, span=span, degree=2). ---> 84 model.fit(). 85 estimat_var[not_const] = model.outputs.fitted_values. 86 reg_std = np.sqrt(10 ** estimat_var). _loess.pyx in _loess.loess.fit(). ValueError: b'There are other near singularities as well. 0.090619\n'. ```. While looking for a solution, I came across [this](https://github.com/YosefLab/scvi-tools/issues/727#issuecomment-718717033) issue that reports a similar problem. Any ideas of what this may be? . Thanks . #### Versions. <details>. [WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.4. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. SCCAF NA. anndata 0.7.4. backcall 0.1.0. cffi 1.14.3. colorama 0.4.4. cycler 0.10.0. cython_runtime ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1504
https://github.com/scverse/scanpy/issues/1504:1519,integrability,sub,subset,1519,". sc.pp.highly_variable_genes(. adata,. flavor = ""seurat_v3"",. n_top_genes = 7000,. layer = ""counts"",. batch_key = ""combined"",. subset = True. ). ```. I get the following error:. ```pytb. If you pass `n_top_genes`, all cutoffs are ignored. extracting highly variable genes. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-19-3748de5bacdc> in <module>. 5 layer = ""counts"",. 6 batch_key = ""combined"",. ----> 7 subset = True. 8 ). 9 adata. /opt/conda/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key). 420 span=span,. 421 subset=subset,. --> 422 inplace=inplace,. 423 ). 424 . /opt/conda/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, span, subset, inplace). 82 x = np.log10(mean[not_const]). 83 model = loess(x, y, span=span, degree=2). ---> 84 model.fit(). 85 estimat_var[not_const] = model.outputs.fitted_values. 86 reg_std = np.sqrt(10 ** estimat_var). _loess.pyx in _loess.loess.fit(). ValueError: b'There are other near singularities as well. 0.090619\n'. ```. While looking for a solution, I came across [this](https://github.com/YosefLab/scvi-tools/issues/727#issuecomment-718717033) issue that reports a similar problem. Any ideas of what this may be? . Thanks . #### Versions. <details>. [WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.4. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. SCCAF NA. anndata 0.7.4. backcall 0.1.0. cffi 1.14.3. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.1. get_version 2.1. google NA. h5py 2.10.0. igraph 0.8.0. importlib_metadata 1.7.0. ipykernel 5.1.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.16.0. joblib 0.17.0. kiwisolve",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1504
https://github.com/scverse/scanpy/issues/1504:2055,integrability,Version,Versions,2055,"/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key). 420 span=span,. 421 subset=subset,. --> 422 inplace=inplace,. 423 ). 424 . /opt/conda/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, span, subset, inplace). 82 x = np.log10(mean[not_const]). 83 model = loess(x, y, span=span, degree=2). ---> 84 model.fit(). 85 estimat_var[not_const] = model.outputs.fitted_values. 86 reg_std = np.sqrt(10 ** estimat_var). _loess.pyx in _loess.loess.fit(). ValueError: b'There are other near singularities as well. 0.090619\n'. ```. While looking for a solution, I came across [this](https://github.com/YosefLab/scvi-tools/issues/727#issuecomment-718717033) issue that reports a similar problem. Any ideas of what this may be? . Thanks . #### Versions. <details>. [WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.4. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. SCCAF NA. anndata 0.7.4. backcall 0.1.0. cffi 1.14.3. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.1. get_version 2.1. google NA. h5py 2.10.0. igraph 0.8.0. importlib_metadata 1.7.0. ipykernel 5.1.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.16.0. joblib 0.17.0. kiwisolver 1.1.0. legacy_api_wrap 1.2. leidenalg 0.8.2. llvmlite 0.31.0. louvain 0.6.1. matplotlib 3.1.3. mpl_toolkits NA. natsort 7.0.1. numba 0.48.0. numexpr 2.7.1. numpy 1.19.4. packaging 20.4. pandas 1.1.4. parso 0.6.1. patsy 0.5.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.3. psutil 5.7.2. ptyprocess 0.6.0. pycparser 2.20. pygments 2.7.2. pyparsing 2.4.7. pytz 2020.1. rich NA. ruamel NA. scanpy 1.6.0. scipy 1.5.4. scvi 0.7.1. seaborn 0.10.0. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. statsm",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1504
https://github.com/scverse/scanpy/issues/1504:192,modifiability,version,version,192,"ValueError: b'There are other near singularities as well. 0.090619\n'; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. ---. Hi, . Trying to run `scVI` to analyse my data using the latest `scanpy+scvi-tools` workflow, as described [here](https://www.scvi-tools.org/en/stable/user_guide/notebooks/harmonization.html). However, I'm running into a weird issue with the new `seurat_v3` flavour to call HVGs. When I run this:. ```python. sc.pp.highly_variable_genes(. adata,. flavor = ""seurat_v3"",. n_top_genes = 7000,. layer = ""counts"",. batch_key = ""combined"",. subset = True. ). ```. I get the following error:. ```pytb. If you pass `n_top_genes`, all cutoffs are ignored. extracting highly variable genes. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-19-3748de5bacdc> in <module>. 5 layer = ""counts"",. 6 batch_key = ""combined"",. ----> 7 subset = True. 8 ). 9 adata. /opt/conda/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key). 420 span=span,. 421 subset=subset,. --> 422 inplace=inplace,. 423 ). 424 . /opt/conda/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, span, subset, inplace). 82 x = np.log10(mean[not_const]). 83 model = loess(x, y, span=span, degree=2). ---> 84 model.fit(). 85 estimat_var[not_const] = model.outputs.fitted_values. 86 reg_std = np.sqrt(10 ** estimat_var). _loess.pyx in _loess.loess.fit(). ValueError: b'There are other near singularities as well. 0.090619\n'. ```. While looking for a solution, I came across [this](https://github.com/YosefLab/scvi-tools/issues/727#issuecomment-718717033) issue that reports a similar p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1504
https://github.com/scverse/scanpy/issues/1504:606,modifiability,layer,layer,606,"ValueError: b'There are other near singularities as well. 0.090619\n'; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. ---. Hi, . Trying to run `scVI` to analyse my data using the latest `scanpy+scvi-tools` workflow, as described [here](https://www.scvi-tools.org/en/stable/user_guide/notebooks/harmonization.html). However, I'm running into a weird issue with the new `seurat_v3` flavour to call HVGs. When I run this:. ```python. sc.pp.highly_variable_genes(. adata,. flavor = ""seurat_v3"",. n_top_genes = 7000,. layer = ""counts"",. batch_key = ""combined"",. subset = True. ). ```. I get the following error:. ```pytb. If you pass `n_top_genes`, all cutoffs are ignored. extracting highly variable genes. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-19-3748de5bacdc> in <module>. 5 layer = ""counts"",. 6 batch_key = ""combined"",. ----> 7 subset = True. 8 ). 9 adata. /opt/conda/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key). 420 span=span,. 421 subset=subset,. --> 422 inplace=inplace,. 423 ). 424 . /opt/conda/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, span, subset, inplace). 82 x = np.log10(mean[not_const]). 83 model = loess(x, y, span=span, degree=2). ---> 84 model.fit(). 85 estimat_var[not_const] = model.outputs.fitted_values. 86 reg_std = np.sqrt(10 ** estimat_var). _loess.pyx in _loess.loess.fit(). ValueError: b'There are other near singularities as well. 0.090619\n'. ```. While looking for a solution, I came across [this](https://github.com/YosefLab/scvi-tools/issues/727#issuecomment-718717033) issue that reports a similar p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1504
https://github.com/scverse/scanpy/issues/1504:780,modifiability,variab,variable,780,"ValueError: b'There are other near singularities as well. 0.090619\n'; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. ---. Hi, . Trying to run `scVI` to analyse my data using the latest `scanpy+scvi-tools` workflow, as described [here](https://www.scvi-tools.org/en/stable/user_guide/notebooks/harmonization.html). However, I'm running into a weird issue with the new `seurat_v3` flavour to call HVGs. When I run this:. ```python. sc.pp.highly_variable_genes(. adata,. flavor = ""seurat_v3"",. n_top_genes = 7000,. layer = ""counts"",. batch_key = ""combined"",. subset = True. ). ```. I get the following error:. ```pytb. If you pass `n_top_genes`, all cutoffs are ignored. extracting highly variable genes. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-19-3748de5bacdc> in <module>. 5 layer = ""counts"",. 6 batch_key = ""combined"",. ----> 7 subset = True. 8 ). 9 adata. /opt/conda/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key). 420 span=span,. 421 subset=subset,. --> 422 inplace=inplace,. 423 ). 424 . /opt/conda/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, span, subset, inplace). 82 x = np.log10(mean[not_const]). 83 model = loess(x, y, span=span, degree=2). ---> 84 model.fit(). 85 estimat_var[not_const] = model.outputs.fitted_values. 86 reg_std = np.sqrt(10 ** estimat_var). _loess.pyx in _loess.loess.fit(). ValueError: b'There are other near singularities as well. 0.090619\n'. ```. While looking for a solution, I came across [this](https://github.com/YosefLab/scvi-tools/issues/727#issuecomment-718717033) issue that reports a similar p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1504
https://github.com/scverse/scanpy/issues/1504:955,modifiability,modul,module,955,"ValueError: b'There are other near singularities as well. 0.090619\n'; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. ---. Hi, . Trying to run `scVI` to analyse my data using the latest `scanpy+scvi-tools` workflow, as described [here](https://www.scvi-tools.org/en/stable/user_guide/notebooks/harmonization.html). However, I'm running into a weird issue with the new `seurat_v3` flavour to call HVGs. When I run this:. ```python. sc.pp.highly_variable_genes(. adata,. flavor = ""seurat_v3"",. n_top_genes = 7000,. layer = ""counts"",. batch_key = ""combined"",. subset = True. ). ```. I get the following error:. ```pytb. If you pass `n_top_genes`, all cutoffs are ignored. extracting highly variable genes. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-19-3748de5bacdc> in <module>. 5 layer = ""counts"",. 6 batch_key = ""combined"",. ----> 7 subset = True. 8 ). 9 adata. /opt/conda/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key). 420 span=span,. 421 subset=subset,. --> 422 inplace=inplace,. 423 ). 424 . /opt/conda/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, span, subset, inplace). 82 x = np.log10(mean[not_const]). 83 model = loess(x, y, span=span, degree=2). ---> 84 model.fit(). 85 estimat_var[not_const] = model.outputs.fitted_values. 86 reg_std = np.sqrt(10 ** estimat_var). _loess.pyx in _loess.loess.fit(). ValueError: b'There are other near singularities as well. 0.090619\n'. ```. While looking for a solution, I came across [this](https://github.com/YosefLab/scvi-tools/issues/727#issuecomment-718717033) issue that reports a similar p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1504
https://github.com/scverse/scanpy/issues/1504:966,modifiability,layer,layer,966,"ValueError: b'There are other near singularities as well. 0.090619\n'; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. ---. Hi, . Trying to run `scVI` to analyse my data using the latest `scanpy+scvi-tools` workflow, as described [here](https://www.scvi-tools.org/en/stable/user_guide/notebooks/harmonization.html). However, I'm running into a weird issue with the new `seurat_v3` flavour to call HVGs. When I run this:. ```python. sc.pp.highly_variable_genes(. adata,. flavor = ""seurat_v3"",. n_top_genes = 7000,. layer = ""counts"",. batch_key = ""combined"",. subset = True. ). ```. I get the following error:. ```pytb. If you pass `n_top_genes`, all cutoffs are ignored. extracting highly variable genes. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-19-3748de5bacdc> in <module>. 5 layer = ""counts"",. 6 batch_key = ""combined"",. ----> 7 subset = True. 8 ). 9 adata. /opt/conda/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key). 420 span=span,. 421 subset=subset,. --> 422 inplace=inplace,. 423 ). 424 . /opt/conda/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, span, subset, inplace). 82 x = np.log10(mean[not_const]). 83 model = loess(x, y, span=span, degree=2). ---> 84 model.fit(). 85 estimat_var[not_const] = model.outputs.fitted_values. 86 reg_std = np.sqrt(10 ** estimat_var). _loess.pyx in _loess.loess.fit(). ValueError: b'There are other near singularities as well. 0.090619\n'. ```. While looking for a solution, I came across [this](https://github.com/YosefLab/scvi-tools/issues/727#issuecomment-718717033) issue that reports a similar p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1504
https://github.com/scverse/scanpy/issues/1504:1079,modifiability,pac,packages,1079," checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. ---. Hi, . Trying to run `scVI` to analyse my data using the latest `scanpy+scvi-tools` workflow, as described [here](https://www.scvi-tools.org/en/stable/user_guide/notebooks/harmonization.html). However, I'm running into a weird issue with the new `seurat_v3` flavour to call HVGs. When I run this:. ```python. sc.pp.highly_variable_genes(. adata,. flavor = ""seurat_v3"",. n_top_genes = 7000,. layer = ""counts"",. batch_key = ""combined"",. subset = True. ). ```. I get the following error:. ```pytb. If you pass `n_top_genes`, all cutoffs are ignored. extracting highly variable genes. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-19-3748de5bacdc> in <module>. 5 layer = ""counts"",. 6 batch_key = ""combined"",. ----> 7 subset = True. 8 ). 9 adata. /opt/conda/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key). 420 span=span,. 421 subset=subset,. --> 422 inplace=inplace,. 423 ). 424 . /opt/conda/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, span, subset, inplace). 82 x = np.log10(mean[not_const]). 83 model = loess(x, y, span=span, degree=2). ---> 84 model.fit(). 85 estimat_var[not_const] = model.outputs.fitted_values. 86 reg_std = np.sqrt(10 ** estimat_var). _loess.pyx in _loess.loess.fit(). ValueError: b'There are other near singularities as well. 0.090619\n'. ```. While looking for a solution, I came across [this](https://github.com/YosefLab/scvi-tools/issues/727#issuecomment-718717033) issue that reports a similar problem. Any ideas of what this may be? . Thanks . #### Versions. <details>. [WARNIN",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1504
https://github.com/scverse/scanpy/issues/1504:1167,modifiability,layer,layer,1167," exists on the latest version of scanpy. ---. Hi, . Trying to run `scVI` to analyse my data using the latest `scanpy+scvi-tools` workflow, as described [here](https://www.scvi-tools.org/en/stable/user_guide/notebooks/harmonization.html). However, I'm running into a weird issue with the new `seurat_v3` flavour to call HVGs. When I run this:. ```python. sc.pp.highly_variable_genes(. adata,. flavor = ""seurat_v3"",. n_top_genes = 7000,. layer = ""counts"",. batch_key = ""combined"",. subset = True. ). ```. I get the following error:. ```pytb. If you pass `n_top_genes`, all cutoffs are ignored. extracting highly variable genes. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-19-3748de5bacdc> in <module>. 5 layer = ""counts"",. 6 batch_key = ""combined"",. ----> 7 subset = True. 8 ). 9 adata. /opt/conda/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key). 420 span=span,. 421 subset=subset,. --> 422 inplace=inplace,. 423 ). 424 . /opt/conda/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, span, subset, inplace). 82 x = np.log10(mean[not_const]). 83 model = loess(x, y, span=span, degree=2). ---> 84 model.fit(). 85 estimat_var[not_const] = model.outputs.fitted_values. 86 reg_std = np.sqrt(10 ** estimat_var). _loess.pyx in _loess.loess.fit(). ValueError: b'There are other near singularities as well. 0.090619\n'. ```. While looking for a solution, I came across [this](https://github.com/YosefLab/scvi-tools/issues/727#issuecomment-718717033) issue that reports a similar problem. Any ideas of what this may be? . Thanks . #### Versions. <details>. [WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.4. scanpy ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1504
https://github.com/scverse/scanpy/issues/1504:1383,modifiability,pac,packages,1383,"harmonization.html). However, I'm running into a weird issue with the new `seurat_v3` flavour to call HVGs. When I run this:. ```python. sc.pp.highly_variable_genes(. adata,. flavor = ""seurat_v3"",. n_top_genes = 7000,. layer = ""counts"",. batch_key = ""combined"",. subset = True. ). ```. I get the following error:. ```pytb. If you pass `n_top_genes`, all cutoffs are ignored. extracting highly variable genes. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-19-3748de5bacdc> in <module>. 5 layer = ""counts"",. 6 batch_key = ""combined"",. ----> 7 subset = True. 8 ). 9 adata. /opt/conda/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key). 420 span=span,. 421 subset=subset,. --> 422 inplace=inplace,. 423 ). 424 . /opt/conda/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, span, subset, inplace). 82 x = np.log10(mean[not_const]). 83 model = loess(x, y, span=span, degree=2). ---> 84 model.fit(). 85 estimat_var[not_const] = model.outputs.fitted_values. 86 reg_std = np.sqrt(10 ** estimat_var). _loess.pyx in _loess.loess.fit(). ValueError: b'There are other near singularities as well. 0.090619\n'. ```. While looking for a solution, I came across [this](https://github.com/YosefLab/scvi-tools/issues/727#issuecomment-718717033) issue that reports a similar problem. Any ideas of what this may be? . Thanks . #### Versions. <details>. [WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.4. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. SCCAF NA. anndata 0.7.4. backcall 0.1.0. cffi 1.14.3. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.1. get_version 2.1. google NA. h5py 2.10.0. i",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1504
https://github.com/scverse/scanpy/issues/1504:1482,modifiability,layer,layer,1482,"all HVGs. When I run this:. ```python. sc.pp.highly_variable_genes(. adata,. flavor = ""seurat_v3"",. n_top_genes = 7000,. layer = ""counts"",. batch_key = ""combined"",. subset = True. ). ```. I get the following error:. ```pytb. If you pass `n_top_genes`, all cutoffs are ignored. extracting highly variable genes. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-19-3748de5bacdc> in <module>. 5 layer = ""counts"",. 6 batch_key = ""combined"",. ----> 7 subset = True. 8 ). 9 adata. /opt/conda/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key). 420 span=span,. 421 subset=subset,. --> 422 inplace=inplace,. 423 ). 424 . /opt/conda/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, span, subset, inplace). 82 x = np.log10(mean[not_const]). 83 model = loess(x, y, span=span, degree=2). ---> 84 model.fit(). 85 estimat_var[not_const] = model.outputs.fitted_values. 86 reg_std = np.sqrt(10 ** estimat_var). _loess.pyx in _loess.loess.fit(). ValueError: b'There are other near singularities as well. 0.090619\n'. ```. While looking for a solution, I came across [this](https://github.com/YosefLab/scvi-tools/issues/727#issuecomment-718717033) issue that reports a similar problem. Any ideas of what this may be? . Thanks . #### Versions. <details>. [WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.4. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. SCCAF NA. anndata 0.7.4. backcall 0.1.0. cffi 1.14.3. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.1. get_version 2.1. google NA. h5py 2.10.0. igraph 0.8.0. importlib_metadata 1.7.0. ipykernel 5.1.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1504
https://github.com/scverse/scanpy/issues/1504:2055,modifiability,Version,Versions,2055,"/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key). 420 span=span,. 421 subset=subset,. --> 422 inplace=inplace,. 423 ). 424 . /opt/conda/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, span, subset, inplace). 82 x = np.log10(mean[not_const]). 83 model = loess(x, y, span=span, degree=2). ---> 84 model.fit(). 85 estimat_var[not_const] = model.outputs.fitted_values. 86 reg_std = np.sqrt(10 ** estimat_var). _loess.pyx in _loess.loess.fit(). ValueError: b'There are other near singularities as well. 0.090619\n'. ```. While looking for a solution, I came across [this](https://github.com/YosefLab/scvi-tools/issues/727#issuecomment-718717033) issue that reports a similar problem. Any ideas of what this may be? . Thanks . #### Versions. <details>. [WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.4. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. SCCAF NA. anndata 0.7.4. backcall 0.1.0. cffi 1.14.3. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.1. get_version 2.1. google NA. h5py 2.10.0. igraph 0.8.0. importlib_metadata 1.7.0. ipykernel 5.1.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.16.0. joblib 0.17.0. kiwisolver 1.1.0. legacy_api_wrap 1.2. leidenalg 0.8.2. llvmlite 0.31.0. louvain 0.6.1. matplotlib 3.1.3. mpl_toolkits NA. natsort 7.0.1. numba 0.48.0. numexpr 2.7.1. numpy 1.19.4. packaging 20.4. pandas 1.1.4. parso 0.6.1. patsy 0.5.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.3. psutil 5.7.2. ptyprocess 0.6.0. pycparser 2.20. pygments 2.7.2. pyparsing 2.4.7. pytz 2020.1. rich NA. ruamel NA. scanpy 1.6.0. scipy 1.5.4. scvi 0.7.1. seaborn 0.10.0. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. statsm",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1504
https://github.com/scverse/scanpy/issues/1504:2328,modifiability,deco,decorator,2328,"lace,. 423 ). 424 . /opt/conda/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, span, subset, inplace). 82 x = np.log10(mean[not_const]). 83 model = loess(x, y, span=span, degree=2). ---> 84 model.fit(). 85 estimat_var[not_const] = model.outputs.fitted_values. 86 reg_std = np.sqrt(10 ** estimat_var). _loess.pyx in _loess.loess.fit(). ValueError: b'There are other near singularities as well. 0.090619\n'. ```. While looking for a solution, I came across [this](https://github.com/YosefLab/scvi-tools/issues/727#issuecomment-718717033) issue that reports a similar problem. Any ideas of what this may be? . Thanks . #### Versions. <details>. [WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.4. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. SCCAF NA. anndata 0.7.4. backcall 0.1.0. cffi 1.14.3. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.1. get_version 2.1. google NA. h5py 2.10.0. igraph 0.8.0. importlib_metadata 1.7.0. ipykernel 5.1.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.16.0. joblib 0.17.0. kiwisolver 1.1.0. legacy_api_wrap 1.2. leidenalg 0.8.2. llvmlite 0.31.0. louvain 0.6.1. matplotlib 3.1.3. mpl_toolkits NA. natsort 7.0.1. numba 0.48.0. numexpr 2.7.1. numpy 1.19.4. packaging 20.4. pandas 1.1.4. parso 0.6.1. patsy 0.5.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.3. psutil 5.7.2. ptyprocess 0.6.0. pycparser 2.20. pygments 2.7.2. pyparsing 2.4.7. pytz 2020.1. rich NA. ruamel NA. scanpy 1.6.0. scipy 1.5.4. scvi 0.7.1. seaborn 0.10.0. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. statsmodels 0.11.1. storemagic NA. tables 3.6.1. texttable 1.6.2. threadpoolctl 2.1.0. torch 1.6.0. tornado 6.0.3. tqdm 4.32.2. traitlets 4.3.3. typing_extensions NA. umap 0.3.10. wcwidth NA. yaml 5.3.1. zipp NA. zmq 19.0.0. -----. IPython 7.12.0. jupyter_client 6.0.0. jupyter_co",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1504
https://github.com/scverse/scanpy/issues/1504:2694,modifiability,pac,packaging,2694,"4 model.fit(). 85 estimat_var[not_const] = model.outputs.fitted_values. 86 reg_std = np.sqrt(10 ** estimat_var). _loess.pyx in _loess.loess.fit(). ValueError: b'There are other near singularities as well. 0.090619\n'. ```. While looking for a solution, I came across [this](https://github.com/YosefLab/scvi-tools/issues/727#issuecomment-718717033) issue that reports a similar problem. Any ideas of what this may be? . Thanks . #### Versions. <details>. [WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.4. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. SCCAF NA. anndata 0.7.4. backcall 0.1.0. cffi 1.14.3. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.1. get_version 2.1. google NA. h5py 2.10.0. igraph 0.8.0. importlib_metadata 1.7.0. ipykernel 5.1.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.16.0. joblib 0.17.0. kiwisolver 1.1.0. legacy_api_wrap 1.2. leidenalg 0.8.2. llvmlite 0.31.0. louvain 0.6.1. matplotlib 3.1.3. mpl_toolkits NA. natsort 7.0.1. numba 0.48.0. numexpr 2.7.1. numpy 1.19.4. packaging 20.4. pandas 1.1.4. parso 0.6.1. patsy 0.5.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.3. psutil 5.7.2. ptyprocess 0.6.0. pycparser 2.20. pygments 2.7.2. pyparsing 2.4.7. pytz 2020.1. rich NA. ruamel NA. scanpy 1.6.0. scipy 1.5.4. scvi 0.7.1. seaborn 0.10.0. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. statsmodels 0.11.1. storemagic NA. tables 3.6.1. texttable 1.6.2. threadpoolctl 2.1.0. torch 1.6.0. tornado 6.0.3. tqdm 4.32.2. traitlets 4.3.3. typing_extensions NA. umap 0.3.10. wcwidth NA. yaml 5.3.1. zipp NA. zmq 19.0.0. -----. IPython 7.12.0. jupyter_client 6.0.0. jupyter_core 4.6.3. jupyterlab 1.2.5. notebook 6.0.3. -----. Python 3.7.6 | packaged by conda-forge | (default, Jan 7 2020, 22:33:48) [GCC 7.3.0]. Linux-4.4.0-189-generic-x86_64-with-debian-buster-sid. 24 logical CPU cores, x86_64. -----. Session information updated at 2020-11-23 09:17. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1504
https://github.com/scverse/scanpy/issues/1504:3399,modifiability,pac,packaged,3399,"4 model.fit(). 85 estimat_var[not_const] = model.outputs.fitted_values. 86 reg_std = np.sqrt(10 ** estimat_var). _loess.pyx in _loess.loess.fit(). ValueError: b'There are other near singularities as well. 0.090619\n'. ```. While looking for a solution, I came across [this](https://github.com/YosefLab/scvi-tools/issues/727#issuecomment-718717033) issue that reports a similar problem. Any ideas of what this may be? . Thanks . #### Versions. <details>. [WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.4. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. SCCAF NA. anndata 0.7.4. backcall 0.1.0. cffi 1.14.3. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.1. get_version 2.1. google NA. h5py 2.10.0. igraph 0.8.0. importlib_metadata 1.7.0. ipykernel 5.1.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.16.0. joblib 0.17.0. kiwisolver 1.1.0. legacy_api_wrap 1.2. leidenalg 0.8.2. llvmlite 0.31.0. louvain 0.6.1. matplotlib 3.1.3. mpl_toolkits NA. natsort 7.0.1. numba 0.48.0. numexpr 2.7.1. numpy 1.19.4. packaging 20.4. pandas 1.1.4. parso 0.6.1. patsy 0.5.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.3. psutil 5.7.2. ptyprocess 0.6.0. pycparser 2.20. pygments 2.7.2. pyparsing 2.4.7. pytz 2020.1. rich NA. ruamel NA. scanpy 1.6.0. scipy 1.5.4. scvi 0.7.1. seaborn 0.10.0. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. statsmodels 0.11.1. storemagic NA. tables 3.6.1. texttable 1.6.2. threadpoolctl 2.1.0. torch 1.6.0. tornado 6.0.3. tqdm 4.32.2. traitlets 4.3.3. typing_extensions NA. umap 0.3.10. wcwidth NA. yaml 5.3.1. zipp NA. zmq 19.0.0. -----. IPython 7.12.0. jupyter_client 6.0.0. jupyter_core 4.6.3. jupyterlab 1.2.5. notebook 6.0.3. -----. Python 3.7.6 | packaged by conda-forge | (default, Jan 7 2020, 22:33:48) [GCC 7.3.0]. Linux-4.4.0-189-generic-x86_64-with-debian-buster-sid. 24 logical CPU cores, x86_64. -----. Session information updated at 2020-11-23 09:17. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1504
https://github.com/scverse/scanpy/issues/1504:693,performance,error,error,693,"ValueError: b'There are other near singularities as well. 0.090619\n'; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. ---. Hi, . Trying to run `scVI` to analyse my data using the latest `scanpy+scvi-tools` workflow, as described [here](https://www.scvi-tools.org/en/stable/user_guide/notebooks/harmonization.html). However, I'm running into a weird issue with the new `seurat_v3` flavour to call HVGs. When I run this:. ```python. sc.pp.highly_variable_genes(. adata,. flavor = ""seurat_v3"",. n_top_genes = 7000,. layer = ""counts"",. batch_key = ""combined"",. subset = True. ). ```. I get the following error:. ```pytb. If you pass `n_top_genes`, all cutoffs are ignored. extracting highly variable genes. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-19-3748de5bacdc> in <module>. 5 layer = ""counts"",. 6 batch_key = ""combined"",. ----> 7 subset = True. 8 ). 9 adata. /opt/conda/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key). 420 span=span,. 421 subset=subset,. --> 422 inplace=inplace,. 423 ). 424 . /opt/conda/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, span, subset, inplace). 82 x = np.log10(mean[not_const]). 83 model = loess(x, y, span=span, degree=2). ---> 84 model.fit(). 85 estimat_var[not_const] = model.outputs.fitted_values. 86 reg_std = np.sqrt(10 ** estimat_var). _loess.pyx in _loess.loess.fit(). ValueError: b'There are other near singularities as well. 0.090619\n'. ```. While looking for a solution, I came across [this](https://github.com/YosefLab/scvi-tools/issues/727#issuecomment-718717033) issue that reports a similar p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1504
https://github.com/scverse/scanpy/issues/1504:3536,performance,CPU,CPU,3536,"4 model.fit(). 85 estimat_var[not_const] = model.outputs.fitted_values. 86 reg_std = np.sqrt(10 ** estimat_var). _loess.pyx in _loess.loess.fit(). ValueError: b'There are other near singularities as well. 0.090619\n'. ```. While looking for a solution, I came across [this](https://github.com/YosefLab/scvi-tools/issues/727#issuecomment-718717033) issue that reports a similar problem. Any ideas of what this may be? . Thanks . #### Versions. <details>. [WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.4. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. SCCAF NA. anndata 0.7.4. backcall 0.1.0. cffi 1.14.3. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.1. get_version 2.1. google NA. h5py 2.10.0. igraph 0.8.0. importlib_metadata 1.7.0. ipykernel 5.1.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.16.0. joblib 0.17.0. kiwisolver 1.1.0. legacy_api_wrap 1.2. leidenalg 0.8.2. llvmlite 0.31.0. louvain 0.6.1. matplotlib 3.1.3. mpl_toolkits NA. natsort 7.0.1. numba 0.48.0. numexpr 2.7.1. numpy 1.19.4. packaging 20.4. pandas 1.1.4. parso 0.6.1. patsy 0.5.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.3. psutil 5.7.2. ptyprocess 0.6.0. pycparser 2.20. pygments 2.7.2. pyparsing 2.4.7. pytz 2020.1. rich NA. ruamel NA. scanpy 1.6.0. scipy 1.5.4. scvi 0.7.1. seaborn 0.10.0. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. statsmodels 0.11.1. storemagic NA. tables 3.6.1. texttable 1.6.2. threadpoolctl 2.1.0. torch 1.6.0. tornado 6.0.3. tqdm 4.32.2. traitlets 4.3.3. typing_extensions NA. umap 0.3.10. wcwidth NA. yaml 5.3.1. zipp NA. zmq 19.0.0. -----. IPython 7.12.0. jupyter_client 6.0.0. jupyter_core 4.6.3. jupyterlab 1.2.5. notebook 6.0.3. -----. Python 3.7.6 | packaged by conda-forge | (default, Jan 7 2020, 22:33:48) [GCC 7.3.0]. Linux-4.4.0-189-generic-x86_64-with-debian-buster-sid. 24 logical CPU cores, x86_64. -----. Session information updated at 2020-11-23 09:17. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1504
https://github.com/scverse/scanpy/issues/1504:693,safety,error,error,693,"ValueError: b'There are other near singularities as well. 0.090619\n'; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. ---. Hi, . Trying to run `scVI` to analyse my data using the latest `scanpy+scvi-tools` workflow, as described [here](https://www.scvi-tools.org/en/stable/user_guide/notebooks/harmonization.html). However, I'm running into a weird issue with the new `seurat_v3` flavour to call HVGs. When I run this:. ```python. sc.pp.highly_variable_genes(. adata,. flavor = ""seurat_v3"",. n_top_genes = 7000,. layer = ""counts"",. batch_key = ""combined"",. subset = True. ). ```. I get the following error:. ```pytb. If you pass `n_top_genes`, all cutoffs are ignored. extracting highly variable genes. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-19-3748de5bacdc> in <module>. 5 layer = ""counts"",. 6 batch_key = ""combined"",. ----> 7 subset = True. 8 ). 9 adata. /opt/conda/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key). 420 span=span,. 421 subset=subset,. --> 422 inplace=inplace,. 423 ). 424 . /opt/conda/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, span, subset, inplace). 82 x = np.log10(mean[not_const]). 83 model = loess(x, y, span=span, degree=2). ---> 84 model.fit(). 85 estimat_var[not_const] = model.outputs.fitted_values. 86 reg_std = np.sqrt(10 ** estimat_var). _loess.pyx in _loess.loess.fit(). ValueError: b'There are other near singularities as well. 0.090619\n'. ```. While looking for a solution, I came across [this](https://github.com/YosefLab/scvi-tools/issues/727#issuecomment-718717033) issue that reports a similar p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1504
https://github.com/scverse/scanpy/issues/1504:928,safety,input,input-,928,"ValueError: b'There are other near singularities as well. 0.090619\n'; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. ---. Hi, . Trying to run `scVI` to analyse my data using the latest `scanpy+scvi-tools` workflow, as described [here](https://www.scvi-tools.org/en/stable/user_guide/notebooks/harmonization.html). However, I'm running into a weird issue with the new `seurat_v3` flavour to call HVGs. When I run this:. ```python. sc.pp.highly_variable_genes(. adata,. flavor = ""seurat_v3"",. n_top_genes = 7000,. layer = ""counts"",. batch_key = ""combined"",. subset = True. ). ```. I get the following error:. ```pytb. If you pass `n_top_genes`, all cutoffs are ignored. extracting highly variable genes. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-19-3748de5bacdc> in <module>. 5 layer = ""counts"",. 6 batch_key = ""combined"",. ----> 7 subset = True. 8 ). 9 adata. /opt/conda/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key). 420 span=span,. 421 subset=subset,. --> 422 inplace=inplace,. 423 ). 424 . /opt/conda/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, span, subset, inplace). 82 x = np.log10(mean[not_const]). 83 model = loess(x, y, span=span, degree=2). ---> 84 model.fit(). 85 estimat_var[not_const] = model.outputs.fitted_values. 86 reg_std = np.sqrt(10 ** estimat_var). _loess.pyx in _loess.loess.fit(). ValueError: b'There are other near singularities as well. 0.090619\n'. ```. While looking for a solution, I came across [this](https://github.com/YosefLab/scvi-tools/issues/727#issuecomment-718717033) issue that reports a similar p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1504
https://github.com/scverse/scanpy/issues/1504:955,safety,modul,module,955,"ValueError: b'There are other near singularities as well. 0.090619\n'; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. ---. Hi, . Trying to run `scVI` to analyse my data using the latest `scanpy+scvi-tools` workflow, as described [here](https://www.scvi-tools.org/en/stable/user_guide/notebooks/harmonization.html). However, I'm running into a weird issue with the new `seurat_v3` flavour to call HVGs. When I run this:. ```python. sc.pp.highly_variable_genes(. adata,. flavor = ""seurat_v3"",. n_top_genes = 7000,. layer = ""counts"",. batch_key = ""combined"",. subset = True. ). ```. I get the following error:. ```pytb. If you pass `n_top_genes`, all cutoffs are ignored. extracting highly variable genes. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-19-3748de5bacdc> in <module>. 5 layer = ""counts"",. 6 batch_key = ""combined"",. ----> 7 subset = True. 8 ). 9 adata. /opt/conda/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key). 420 span=span,. 421 subset=subset,. --> 422 inplace=inplace,. 423 ). 424 . /opt/conda/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, span, subset, inplace). 82 x = np.log10(mean[not_const]). 83 model = loess(x, y, span=span, degree=2). ---> 84 model.fit(). 85 estimat_var[not_const] = model.outputs.fitted_values. 86 reg_std = np.sqrt(10 ** estimat_var). _loess.pyx in _loess.loess.fit(). ValueError: b'There are other near singularities as well. 0.090619\n'. ```. While looking for a solution, I came across [this](https://github.com/YosefLab/scvi-tools/issues/727#issuecomment-718717033) issue that reports a similar p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1504
https://github.com/scverse/scanpy/issues/1504:3528,safety,log,logical,3528,"4 model.fit(). 85 estimat_var[not_const] = model.outputs.fitted_values. 86 reg_std = np.sqrt(10 ** estimat_var). _loess.pyx in _loess.loess.fit(). ValueError: b'There are other near singularities as well. 0.090619\n'. ```. While looking for a solution, I came across [this](https://github.com/YosefLab/scvi-tools/issues/727#issuecomment-718717033) issue that reports a similar problem. Any ideas of what this may be? . Thanks . #### Versions. <details>. [WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.4. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. SCCAF NA. anndata 0.7.4. backcall 0.1.0. cffi 1.14.3. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.1. get_version 2.1. google NA. h5py 2.10.0. igraph 0.8.0. importlib_metadata 1.7.0. ipykernel 5.1.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.16.0. joblib 0.17.0. kiwisolver 1.1.0. legacy_api_wrap 1.2. leidenalg 0.8.2. llvmlite 0.31.0. louvain 0.6.1. matplotlib 3.1.3. mpl_toolkits NA. natsort 7.0.1. numba 0.48.0. numexpr 2.7.1. numpy 1.19.4. packaging 20.4. pandas 1.1.4. parso 0.6.1. patsy 0.5.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.3. psutil 5.7.2. ptyprocess 0.6.0. pycparser 2.20. pygments 2.7.2. pyparsing 2.4.7. pytz 2020.1. rich NA. ruamel NA. scanpy 1.6.0. scipy 1.5.4. scvi 0.7.1. seaborn 0.10.0. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. statsmodels 0.11.1. storemagic NA. tables 3.6.1. texttable 1.6.2. threadpoolctl 2.1.0. torch 1.6.0. tornado 6.0.3. tqdm 4.32.2. traitlets 4.3.3. typing_extensions NA. umap 0.3.10. wcwidth NA. yaml 5.3.1. zipp NA. zmq 19.0.0. -----. IPython 7.12.0. jupyter_client 6.0.0. jupyter_core 4.6.3. jupyterlab 1.2.5. notebook 6.0.3. -----. Python 3.7.6 | packaged by conda-forge | (default, Jan 7 2020, 22:33:48) [GCC 7.3.0]. Linux-4.4.0-189-generic-x86_64-with-debian-buster-sid. 24 logical CPU cores, x86_64. -----. Session information updated at 2020-11-23 09:17. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1504
https://github.com/scverse/scanpy/issues/1504:3582,safety,updat,updated,3582,"4 model.fit(). 85 estimat_var[not_const] = model.outputs.fitted_values. 86 reg_std = np.sqrt(10 ** estimat_var). _loess.pyx in _loess.loess.fit(). ValueError: b'There are other near singularities as well. 0.090619\n'. ```. While looking for a solution, I came across [this](https://github.com/YosefLab/scvi-tools/issues/727#issuecomment-718717033) issue that reports a similar problem. Any ideas of what this may be? . Thanks . #### Versions. <details>. [WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.4. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. SCCAF NA. anndata 0.7.4. backcall 0.1.0. cffi 1.14.3. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.1. get_version 2.1. google NA. h5py 2.10.0. igraph 0.8.0. importlib_metadata 1.7.0. ipykernel 5.1.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.16.0. joblib 0.17.0. kiwisolver 1.1.0. legacy_api_wrap 1.2. leidenalg 0.8.2. llvmlite 0.31.0. louvain 0.6.1. matplotlib 3.1.3. mpl_toolkits NA. natsort 7.0.1. numba 0.48.0. numexpr 2.7.1. numpy 1.19.4. packaging 20.4. pandas 1.1.4. parso 0.6.1. patsy 0.5.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.3. psutil 5.7.2. ptyprocess 0.6.0. pycparser 2.20. pygments 2.7.2. pyparsing 2.4.7. pytz 2020.1. rich NA. ruamel NA. scanpy 1.6.0. scipy 1.5.4. scvi 0.7.1. seaborn 0.10.0. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. statsmodels 0.11.1. storemagic NA. tables 3.6.1. texttable 1.6.2. threadpoolctl 2.1.0. torch 1.6.0. tornado 6.0.3. tqdm 4.32.2. traitlets 4.3.3. typing_extensions NA. umap 0.3.10. wcwidth NA. yaml 5.3.1. zipp NA. zmq 19.0.0. -----. IPython 7.12.0. jupyter_client 6.0.0. jupyter_core 4.6.3. jupyterlab 1.2.5. notebook 6.0.3. -----. Python 3.7.6 | packaged by conda-forge | (default, Jan 7 2020, 22:33:48) [GCC 7.3.0]. Linux-4.4.0-189-generic-x86_64-with-debian-buster-sid. 24 logical CPU cores, x86_64. -----. Session information updated at 2020-11-23 09:17. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1504
https://github.com/scverse/scanpy/issues/1504:1574,security,model,model,1574,"t_v3"",. n_top_genes = 7000,. layer = ""counts"",. batch_key = ""combined"",. subset = True. ). ```. I get the following error:. ```pytb. If you pass `n_top_genes`, all cutoffs are ignored. extracting highly variable genes. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-19-3748de5bacdc> in <module>. 5 layer = ""counts"",. 6 batch_key = ""combined"",. ----> 7 subset = True. 8 ). 9 adata. /opt/conda/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key). 420 span=span,. 421 subset=subset,. --> 422 inplace=inplace,. 423 ). 424 . /opt/conda/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, span, subset, inplace). 82 x = np.log10(mean[not_const]). 83 model = loess(x, y, span=span, degree=2). ---> 84 model.fit(). 85 estimat_var[not_const] = model.outputs.fitted_values. 86 reg_std = np.sqrt(10 ** estimat_var). _loess.pyx in _loess.loess.fit(). ValueError: b'There are other near singularities as well. 0.090619\n'. ```. While looking for a solution, I came across [this](https://github.com/YosefLab/scvi-tools/issues/727#issuecomment-718717033) issue that reports a similar problem. Any ideas of what this may be? . Thanks . #### Versions. <details>. [WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.4. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. SCCAF NA. anndata 0.7.4. backcall 0.1.0. cffi 1.14.3. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.1. get_version 2.1. google NA. h5py 2.10.0. igraph 0.8.0. importlib_metadata 1.7.0. ipykernel 5.1.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.16.0. joblib 0.17.0. kiwisolver 1.1.0. legacy_api_wrap 1.2. leidenalg 0.8.2. llvmlite",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1504
https://github.com/scverse/scanpy/issues/1504:1624,security,model,model,1624,"tch_key = ""combined"",. subset = True. ). ```. I get the following error:. ```pytb. If you pass `n_top_genes`, all cutoffs are ignored. extracting highly variable genes. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-19-3748de5bacdc> in <module>. 5 layer = ""counts"",. 6 batch_key = ""combined"",. ----> 7 subset = True. 8 ). 9 adata. /opt/conda/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key). 420 span=span,. 421 subset=subset,. --> 422 inplace=inplace,. 423 ). 424 . /opt/conda/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, span, subset, inplace). 82 x = np.log10(mean[not_const]). 83 model = loess(x, y, span=span, degree=2). ---> 84 model.fit(). 85 estimat_var[not_const] = model.outputs.fitted_values. 86 reg_std = np.sqrt(10 ** estimat_var). _loess.pyx in _loess.loess.fit(). ValueError: b'There are other near singularities as well. 0.090619\n'. ```. While looking for a solution, I came across [this](https://github.com/YosefLab/scvi-tools/issues/727#issuecomment-718717033) issue that reports a similar problem. Any ideas of what this may be? . Thanks . #### Versions. <details>. [WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.4. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. SCCAF NA. anndata 0.7.4. backcall 0.1.0. cffi 1.14.3. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.1. get_version 2.1. google NA. h5py 2.10.0. igraph 0.8.0. importlib_metadata 1.7.0. ipykernel 5.1.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.16.0. joblib 0.17.0. kiwisolver 1.1.0. legacy_api_wrap 1.2. leidenalg 0.8.2. llvmlite 0.31.0. louvain 0.6.1. matplotlib 3.1.3. mpl_tool",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1504
https://github.com/scverse/scanpy/issues/1504:1665,security,model,model,1665,"```. I get the following error:. ```pytb. If you pass `n_top_genes`, all cutoffs are ignored. extracting highly variable genes. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-19-3748de5bacdc> in <module>. 5 layer = ""counts"",. 6 batch_key = ""combined"",. ----> 7 subset = True. 8 ). 9 adata. /opt/conda/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key). 420 span=span,. 421 subset=subset,. --> 422 inplace=inplace,. 423 ). 424 . /opt/conda/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, span, subset, inplace). 82 x = np.log10(mean[not_const]). 83 model = loess(x, y, span=span, degree=2). ---> 84 model.fit(). 85 estimat_var[not_const] = model.outputs.fitted_values. 86 reg_std = np.sqrt(10 ** estimat_var). _loess.pyx in _loess.loess.fit(). ValueError: b'There are other near singularities as well. 0.090619\n'. ```. While looking for a solution, I came across [this](https://github.com/YosefLab/scvi-tools/issues/727#issuecomment-718717033) issue that reports a similar problem. Any ideas of what this may be? . Thanks . #### Versions. <details>. [WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.4. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. SCCAF NA. anndata 0.7.4. backcall 0.1.0. cffi 1.14.3. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.1. get_version 2.1. google NA. h5py 2.10.0. igraph 0.8.0. importlib_metadata 1.7.0. ipykernel 5.1.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.16.0. joblib 0.17.0. kiwisolver 1.1.0. legacy_api_wrap 1.2. leidenalg 0.8.2. llvmlite 0.31.0. louvain 0.6.1. matplotlib 3.1.3. mpl_toolkits NA. natsort 7.0.1. numba 0.48.0. num",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1504
https://github.com/scverse/scanpy/issues/1504:3528,security,log,logical,3528,"4 model.fit(). 85 estimat_var[not_const] = model.outputs.fitted_values. 86 reg_std = np.sqrt(10 ** estimat_var). _loess.pyx in _loess.loess.fit(). ValueError: b'There are other near singularities as well. 0.090619\n'. ```. While looking for a solution, I came across [this](https://github.com/YosefLab/scvi-tools/issues/727#issuecomment-718717033) issue that reports a similar problem. Any ideas of what this may be? . Thanks . #### Versions. <details>. [WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.4. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. SCCAF NA. anndata 0.7.4. backcall 0.1.0. cffi 1.14.3. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.1. get_version 2.1. google NA. h5py 2.10.0. igraph 0.8.0. importlib_metadata 1.7.0. ipykernel 5.1.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.16.0. joblib 0.17.0. kiwisolver 1.1.0. legacy_api_wrap 1.2. leidenalg 0.8.2. llvmlite 0.31.0. louvain 0.6.1. matplotlib 3.1.3. mpl_toolkits NA. natsort 7.0.1. numba 0.48.0. numexpr 2.7.1. numpy 1.19.4. packaging 20.4. pandas 1.1.4. parso 0.6.1. patsy 0.5.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.3. psutil 5.7.2. ptyprocess 0.6.0. pycparser 2.20. pygments 2.7.2. pyparsing 2.4.7. pytz 2020.1. rich NA. ruamel NA. scanpy 1.6.0. scipy 1.5.4. scvi 0.7.1. seaborn 0.10.0. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. statsmodels 0.11.1. storemagic NA. tables 3.6.1. texttable 1.6.2. threadpoolctl 2.1.0. torch 1.6.0. tornado 6.0.3. tqdm 4.32.2. traitlets 4.3.3. typing_extensions NA. umap 0.3.10. wcwidth NA. yaml 5.3.1. zipp NA. zmq 19.0.0. -----. IPython 7.12.0. jupyter_client 6.0.0. jupyter_core 4.6.3. jupyterlab 1.2.5. notebook 6.0.3. -----. Python 3.7.6 | packaged by conda-forge | (default, Jan 7 2020, 22:33:48) [GCC 7.3.0]. Linux-4.4.0-189-generic-x86_64-with-debian-buster-sid. 24 logical CPU cores, x86_64. -----. Session information updated at 2020-11-23 09:17. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1504
https://github.com/scverse/scanpy/issues/1504:3562,security,Session,Session,3562,"4 model.fit(). 85 estimat_var[not_const] = model.outputs.fitted_values. 86 reg_std = np.sqrt(10 ** estimat_var). _loess.pyx in _loess.loess.fit(). ValueError: b'There are other near singularities as well. 0.090619\n'. ```. While looking for a solution, I came across [this](https://github.com/YosefLab/scvi-tools/issues/727#issuecomment-718717033) issue that reports a similar problem. Any ideas of what this may be? . Thanks . #### Versions. <details>. [WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.4. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. SCCAF NA. anndata 0.7.4. backcall 0.1.0. cffi 1.14.3. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.1. get_version 2.1. google NA. h5py 2.10.0. igraph 0.8.0. importlib_metadata 1.7.0. ipykernel 5.1.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.16.0. joblib 0.17.0. kiwisolver 1.1.0. legacy_api_wrap 1.2. leidenalg 0.8.2. llvmlite 0.31.0. louvain 0.6.1. matplotlib 3.1.3. mpl_toolkits NA. natsort 7.0.1. numba 0.48.0. numexpr 2.7.1. numpy 1.19.4. packaging 20.4. pandas 1.1.4. parso 0.6.1. patsy 0.5.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.3. psutil 5.7.2. ptyprocess 0.6.0. pycparser 2.20. pygments 2.7.2. pyparsing 2.4.7. pytz 2020.1. rich NA. ruamel NA. scanpy 1.6.0. scipy 1.5.4. scvi 0.7.1. seaborn 0.10.0. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. statsmodels 0.11.1. storemagic NA. tables 3.6.1. texttable 1.6.2. threadpoolctl 2.1.0. torch 1.6.0. tornado 6.0.3. tqdm 4.32.2. traitlets 4.3.3. typing_extensions NA. umap 0.3.10. wcwidth NA. yaml 5.3.1. zipp NA. zmq 19.0.0. -----. IPython 7.12.0. jupyter_client 6.0.0. jupyter_core 4.6.3. jupyterlab 1.2.5. notebook 6.0.3. -----. Python 3.7.6 | packaged by conda-forge | (default, Jan 7 2020, 22:33:48) [GCC 7.3.0]. Linux-4.4.0-189-generic-x86_64-with-debian-buster-sid. 24 logical CPU cores, x86_64. -----. Session information updated at 2020-11-23 09:17. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1504
https://github.com/scverse/scanpy/issues/1504:3582,security,updat,updated,3582,"4 model.fit(). 85 estimat_var[not_const] = model.outputs.fitted_values. 86 reg_std = np.sqrt(10 ** estimat_var). _loess.pyx in _loess.loess.fit(). ValueError: b'There are other near singularities as well. 0.090619\n'. ```. While looking for a solution, I came across [this](https://github.com/YosefLab/scvi-tools/issues/727#issuecomment-718717033) issue that reports a similar problem. Any ideas of what this may be? . Thanks . #### Versions. <details>. [WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.4. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. SCCAF NA. anndata 0.7.4. backcall 0.1.0. cffi 1.14.3. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.1. get_version 2.1. google NA. h5py 2.10.0. igraph 0.8.0. importlib_metadata 1.7.0. ipykernel 5.1.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.16.0. joblib 0.17.0. kiwisolver 1.1.0. legacy_api_wrap 1.2. leidenalg 0.8.2. llvmlite 0.31.0. louvain 0.6.1. matplotlib 3.1.3. mpl_toolkits NA. natsort 7.0.1. numba 0.48.0. numexpr 2.7.1. numpy 1.19.4. packaging 20.4. pandas 1.1.4. parso 0.6.1. patsy 0.5.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.3. psutil 5.7.2. ptyprocess 0.6.0. pycparser 2.20. pygments 2.7.2. pyparsing 2.4.7. pytz 2020.1. rich NA. ruamel NA. scanpy 1.6.0. scipy 1.5.4. scvi 0.7.1. seaborn 0.10.0. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. statsmodels 0.11.1. storemagic NA. tables 3.6.1. texttable 1.6.2. threadpoolctl 2.1.0. torch 1.6.0. tornado 6.0.3. tqdm 4.32.2. traitlets 4.3.3. typing_extensions NA. umap 0.3.10. wcwidth NA. yaml 5.3.1. zipp NA. zmq 19.0.0. -----. IPython 7.12.0. jupyter_client 6.0.0. jupyter_core 4.6.3. jupyterlab 1.2.5. notebook 6.0.3. -----. Python 3.7.6 | packaged by conda-forge | (default, Jan 7 2020, 22:33:48) [GCC 7.3.0]. Linux-4.4.0-189-generic-x86_64-with-debian-buster-sid. 24 logical CPU cores, x86_64. -----. Session information updated at 2020-11-23 09:17. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1504
https://github.com/scverse/scanpy/issues/1504:884,testability,Trace,Traceback,884,"ValueError: b'There are other near singularities as well. 0.090619\n'; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. ---. Hi, . Trying to run `scVI` to analyse my data using the latest `scanpy+scvi-tools` workflow, as described [here](https://www.scvi-tools.org/en/stable/user_guide/notebooks/harmonization.html). However, I'm running into a weird issue with the new `seurat_v3` flavour to call HVGs. When I run this:. ```python. sc.pp.highly_variable_genes(. adata,. flavor = ""seurat_v3"",. n_top_genes = 7000,. layer = ""counts"",. batch_key = ""combined"",. subset = True. ). ```. I get the following error:. ```pytb. If you pass `n_top_genes`, all cutoffs are ignored. extracting highly variable genes. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-19-3748de5bacdc> in <module>. 5 layer = ""counts"",. 6 batch_key = ""combined"",. ----> 7 subset = True. 8 ). 9 adata. /opt/conda/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key). 420 span=span,. 421 subset=subset,. --> 422 inplace=inplace,. 423 ). 424 . /opt/conda/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, span, subset, inplace). 82 x = np.log10(mean[not_const]). 83 model = loess(x, y, span=span, degree=2). ---> 84 model.fit(). 85 estimat_var[not_const] = model.outputs.fitted_values. 86 reg_std = np.sqrt(10 ** estimat_var). _loess.pyx in _loess.loess.fit(). ValueError: b'There are other near singularities as well. 0.090619\n'. ```. While looking for a solution, I came across [this](https://github.com/YosefLab/scvi-tools/issues/727#issuecomment-718717033) issue that reports a similar p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1504
https://github.com/scverse/scanpy/issues/1504:3528,testability,log,logical,3528,"4 model.fit(). 85 estimat_var[not_const] = model.outputs.fitted_values. 86 reg_std = np.sqrt(10 ** estimat_var). _loess.pyx in _loess.loess.fit(). ValueError: b'There are other near singularities as well. 0.090619\n'. ```. While looking for a solution, I came across [this](https://github.com/YosefLab/scvi-tools/issues/727#issuecomment-718717033) issue that reports a similar problem. Any ideas of what this may be? . Thanks . #### Versions. <details>. [WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.4. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. SCCAF NA. anndata 0.7.4. backcall 0.1.0. cffi 1.14.3. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.1. get_version 2.1. google NA. h5py 2.10.0. igraph 0.8.0. importlib_metadata 1.7.0. ipykernel 5.1.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.16.0. joblib 0.17.0. kiwisolver 1.1.0. legacy_api_wrap 1.2. leidenalg 0.8.2. llvmlite 0.31.0. louvain 0.6.1. matplotlib 3.1.3. mpl_toolkits NA. natsort 7.0.1. numba 0.48.0. numexpr 2.7.1. numpy 1.19.4. packaging 20.4. pandas 1.1.4. parso 0.6.1. patsy 0.5.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.3. psutil 5.7.2. ptyprocess 0.6.0. pycparser 2.20. pygments 2.7.2. pyparsing 2.4.7. pytz 2020.1. rich NA. ruamel NA. scanpy 1.6.0. scipy 1.5.4. scvi 0.7.1. seaborn 0.10.0. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. statsmodels 0.11.1. storemagic NA. tables 3.6.1. texttable 1.6.2. threadpoolctl 2.1.0. torch 1.6.0. tornado 6.0.3. tqdm 4.32.2. traitlets 4.3.3. typing_extensions NA. umap 0.3.10. wcwidth NA. yaml 5.3.1. zipp NA. zmq 19.0.0. -----. IPython 7.12.0. jupyter_client 6.0.0. jupyter_core 4.6.3. jupyterlab 1.2.5. notebook 6.0.3. -----. Python 3.7.6 | packaged by conda-forge | (default, Jan 7 2020, 22:33:48) [GCC 7.3.0]. Linux-4.4.0-189-generic-x86_64-with-debian-buster-sid. 24 logical CPU cores, x86_64. -----. Session information updated at 2020-11-23 09:17. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1504
https://github.com/scverse/scanpy/issues/1504:152,usability,confirm,confirmed,152,"ValueError: b'There are other near singularities as well. 0.090619\n'; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. ---. Hi, . Trying to run `scVI` to analyse my data using the latest `scanpy+scvi-tools` workflow, as described [here](https://www.scvi-tools.org/en/stable/user_guide/notebooks/harmonization.html). However, I'm running into a weird issue with the new `seurat_v3` flavour to call HVGs. When I run this:. ```python. sc.pp.highly_variable_genes(. adata,. flavor = ""seurat_v3"",. n_top_genes = 7000,. layer = ""counts"",. batch_key = ""combined"",. subset = True. ). ```. I get the following error:. ```pytb. If you pass `n_top_genes`, all cutoffs are ignored. extracting highly variable genes. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-19-3748de5bacdc> in <module>. 5 layer = ""counts"",. 6 batch_key = ""combined"",. ----> 7 subset = True. 8 ). 9 adata. /opt/conda/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key). 420 span=span,. 421 subset=subset,. --> 422 inplace=inplace,. 423 ). 424 . /opt/conda/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, span, subset, inplace). 82 x = np.log10(mean[not_const]). 83 model = loess(x, y, span=span, degree=2). ---> 84 model.fit(). 85 estimat_var[not_const] = model.outputs.fitted_values. 86 reg_std = np.sqrt(10 ** estimat_var). _loess.pyx in _loess.loess.fit(). ValueError: b'There are other near singularities as well. 0.090619\n'. ```. While looking for a solution, I came across [this](https://github.com/YosefLab/scvi-tools/issues/727#issuecomment-718717033) issue that reports a similar p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1504
https://github.com/scverse/scanpy/issues/1504:292,usability,tool,tools,292,"ValueError: b'There are other near singularities as well. 0.090619\n'; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. ---. Hi, . Trying to run `scVI` to analyse my data using the latest `scanpy+scvi-tools` workflow, as described [here](https://www.scvi-tools.org/en/stable/user_guide/notebooks/harmonization.html). However, I'm running into a weird issue with the new `seurat_v3` flavour to call HVGs. When I run this:. ```python. sc.pp.highly_variable_genes(. adata,. flavor = ""seurat_v3"",. n_top_genes = 7000,. layer = ""counts"",. batch_key = ""combined"",. subset = True. ). ```. I get the following error:. ```pytb. If you pass `n_top_genes`, all cutoffs are ignored. extracting highly variable genes. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-19-3748de5bacdc> in <module>. 5 layer = ""counts"",. 6 batch_key = ""combined"",. ----> 7 subset = True. 8 ). 9 adata. /opt/conda/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key). 420 span=span,. 421 subset=subset,. --> 422 inplace=inplace,. 423 ). 424 . /opt/conda/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, span, subset, inplace). 82 x = np.log10(mean[not_const]). 83 model = loess(x, y, span=span, degree=2). ---> 84 model.fit(). 85 estimat_var[not_const] = model.outputs.fitted_values. 86 reg_std = np.sqrt(10 ** estimat_var). _loess.pyx in _loess.loess.fit(). ValueError: b'There are other near singularities as well. 0.090619\n'. ```. While looking for a solution, I came across [this](https://github.com/YosefLab/scvi-tools/issues/727#issuecomment-718717033) issue that reports a similar p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1504
https://github.com/scverse/scanpy/issues/1504:299,usability,workflow,workflow,299,"ValueError: b'There are other near singularities as well. 0.090619\n'; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. ---. Hi, . Trying to run `scVI` to analyse my data using the latest `scanpy+scvi-tools` workflow, as described [here](https://www.scvi-tools.org/en/stable/user_guide/notebooks/harmonization.html). However, I'm running into a weird issue with the new `seurat_v3` flavour to call HVGs. When I run this:. ```python. sc.pp.highly_variable_genes(. adata,. flavor = ""seurat_v3"",. n_top_genes = 7000,. layer = ""counts"",. batch_key = ""combined"",. subset = True. ). ```. I get the following error:. ```pytb. If you pass `n_top_genes`, all cutoffs are ignored. extracting highly variable genes. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-19-3748de5bacdc> in <module>. 5 layer = ""counts"",. 6 batch_key = ""combined"",. ----> 7 subset = True. 8 ). 9 adata. /opt/conda/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key). 420 span=span,. 421 subset=subset,. --> 422 inplace=inplace,. 423 ). 424 . /opt/conda/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, span, subset, inplace). 82 x = np.log10(mean[not_const]). 83 model = loess(x, y, span=span, degree=2). ---> 84 model.fit(). 85 estimat_var[not_const] = model.outputs.fitted_values. 86 reg_std = np.sqrt(10 ** estimat_var). _loess.pyx in _loess.loess.fit(). ValueError: b'There are other near singularities as well. 0.090619\n'. ```. While looking for a solution, I came across [this](https://github.com/YosefLab/scvi-tools/issues/727#issuecomment-718717033) issue that reports a similar p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1504
https://github.com/scverse/scanpy/issues/1504:346,usability,tool,tools,346,"ValueError: b'There are other near singularities as well. 0.090619\n'; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. ---. Hi, . Trying to run `scVI` to analyse my data using the latest `scanpy+scvi-tools` workflow, as described [here](https://www.scvi-tools.org/en/stable/user_guide/notebooks/harmonization.html). However, I'm running into a weird issue with the new `seurat_v3` flavour to call HVGs. When I run this:. ```python. sc.pp.highly_variable_genes(. adata,. flavor = ""seurat_v3"",. n_top_genes = 7000,. layer = ""counts"",. batch_key = ""combined"",. subset = True. ). ```. I get the following error:. ```pytb. If you pass `n_top_genes`, all cutoffs are ignored. extracting highly variable genes. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-19-3748de5bacdc> in <module>. 5 layer = ""counts"",. 6 batch_key = ""combined"",. ----> 7 subset = True. 8 ). 9 adata. /opt/conda/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key). 420 span=span,. 421 subset=subset,. --> 422 inplace=inplace,. 423 ). 424 . /opt/conda/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, span, subset, inplace). 82 x = np.log10(mean[not_const]). 83 model = loess(x, y, span=span, degree=2). ---> 84 model.fit(). 85 estimat_var[not_const] = model.outputs.fitted_values. 86 reg_std = np.sqrt(10 ** estimat_var). _loess.pyx in _loess.loess.fit(). ValueError: b'There are other near singularities as well. 0.090619\n'. ```. While looking for a solution, I came across [this](https://github.com/YosefLab/scvi-tools/issues/727#issuecomment-718717033) issue that reports a similar p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1504
https://github.com/scverse/scanpy/issues/1504:693,usability,error,error,693,"ValueError: b'There are other near singularities as well. 0.090619\n'; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. ---. Hi, . Trying to run `scVI` to analyse my data using the latest `scanpy+scvi-tools` workflow, as described [here](https://www.scvi-tools.org/en/stable/user_guide/notebooks/harmonization.html). However, I'm running into a weird issue with the new `seurat_v3` flavour to call HVGs. When I run this:. ```python. sc.pp.highly_variable_genes(. adata,. flavor = ""seurat_v3"",. n_top_genes = 7000,. layer = ""counts"",. batch_key = ""combined"",. subset = True. ). ```. I get the following error:. ```pytb. If you pass `n_top_genes`, all cutoffs are ignored. extracting highly variable genes. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-19-3748de5bacdc> in <module>. 5 layer = ""counts"",. 6 batch_key = ""combined"",. ----> 7 subset = True. 8 ). 9 adata. /opt/conda/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key). 420 span=span,. 421 subset=subset,. --> 422 inplace=inplace,. 423 ). 424 . /opt/conda/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, span, subset, inplace). 82 x = np.log10(mean[not_const]). 83 model = loess(x, y, span=span, degree=2). ---> 84 model.fit(). 85 estimat_var[not_const] = model.outputs.fitted_values. 86 reg_std = np.sqrt(10 ** estimat_var). _loess.pyx in _loess.loess.fit(). ValueError: b'There are other near singularities as well. 0.090619\n'. ```. While looking for a solution, I came across [this](https://github.com/YosefLab/scvi-tools/issues/727#issuecomment-718717033) issue that reports a similar p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1504
https://github.com/scverse/scanpy/issues/1504:928,usability,input,input-,928,"ValueError: b'There are other near singularities as well. 0.090619\n'; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. ---. Hi, . Trying to run `scVI` to analyse my data using the latest `scanpy+scvi-tools` workflow, as described [here](https://www.scvi-tools.org/en/stable/user_guide/notebooks/harmonization.html). However, I'm running into a weird issue with the new `seurat_v3` flavour to call HVGs. When I run this:. ```python. sc.pp.highly_variable_genes(. adata,. flavor = ""seurat_v3"",. n_top_genes = 7000,. layer = ""counts"",. batch_key = ""combined"",. subset = True. ). ```. I get the following error:. ```pytb. If you pass `n_top_genes`, all cutoffs are ignored. extracting highly variable genes. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-19-3748de5bacdc> in <module>. 5 layer = ""counts"",. 6 batch_key = ""combined"",. ----> 7 subset = True. 8 ). 9 adata. /opt/conda/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key). 420 span=span,. 421 subset=subset,. --> 422 inplace=inplace,. 423 ). 424 . /opt/conda/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, span, subset, inplace). 82 x = np.log10(mean[not_const]). 83 model = loess(x, y, span=span, degree=2). ---> 84 model.fit(). 85 estimat_var[not_const] = model.outputs.fitted_values. 86 reg_std = np.sqrt(10 ** estimat_var). _loess.pyx in _loess.loess.fit(). ValueError: b'There are other near singularities as well. 0.090619\n'. ```. While looking for a solution, I came across [this](https://github.com/YosefLab/scvi-tools/issues/727#issuecomment-718717033) issue that reports a similar p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1504
https://github.com/scverse/scanpy/issues/1504:1929,usability,tool,tools,1929,"t-19-3748de5bacdc> in <module>. 5 layer = ""counts"",. 6 batch_key = ""combined"",. ----> 7 subset = True. 8 ). 9 adata. /opt/conda/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key). 420 span=span,. 421 subset=subset,. --> 422 inplace=inplace,. 423 ). 424 . /opt/conda/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, span, subset, inplace). 82 x = np.log10(mean[not_const]). 83 model = loess(x, y, span=span, degree=2). ---> 84 model.fit(). 85 estimat_var[not_const] = model.outputs.fitted_values. 86 reg_std = np.sqrt(10 ** estimat_var). _loess.pyx in _loess.loess.fit(). ValueError: b'There are other near singularities as well. 0.090619\n'. ```. While looking for a solution, I came across [this](https://github.com/YosefLab/scvi-tools/issues/727#issuecomment-718717033) issue that reports a similar problem. Any ideas of what this may be? . Thanks . #### Versions. <details>. [WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.4. scanpy 1.6.0. sinfo 0.3.1. -----. PIL 8.0.1. SCCAF NA. anndata 0.7.4. backcall 0.1.0. cffi 1.14.3. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.1. get_version 2.1. google NA. h5py 2.10.0. igraph 0.8.0. importlib_metadata 1.7.0. ipykernel 5.1.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.16.0. joblib 0.17.0. kiwisolver 1.1.0. legacy_api_wrap 1.2. leidenalg 0.8.2. llvmlite 0.31.0. louvain 0.6.1. matplotlib 3.1.3. mpl_toolkits NA. natsort 7.0.1. numba 0.48.0. numexpr 2.7.1. numpy 1.19.4. packaging 20.4. pandas 1.1.4. parso 0.6.1. patsy 0.5.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.3. psutil 5.7.2. ptyprocess 0.6.0. pycparser 2.20. pygments 2.7.2. pyparsing 2.4.7. pytz 2020.1. rich NA. ruame",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1504
https://github.com/scverse/scanpy/pull/1505:118,security,team,team,118,"Suggestion on clarifying roles in key contributors panel; As by a discussion with @ivirshup and based off the [Scanpy team meeting in July](https://docs.google.com/document/d/1MPVMsJMJcP6siljdvVJm5IQZUexTe2TO5Rqy_5EVE5w/edit), clarify roles in the key-contributors panel and add Malte and Giovanni.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1505
https://github.com/scverse/scanpy/pull/1505:164,usability,document,document,164,"Suggestion on clarifying roles in key contributors panel; As by a discussion with @ivirshup and based off the [Scanpy team meeting in July](https://docs.google.com/document/d/1MPVMsJMJcP6siljdvVJm5IQZUexTe2TO5Rqy_5EVE5w/edit), clarify roles in the key-contributors panel and add Malte and Giovanni.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1505
https://github.com/scverse/scanpy/pull/1506:11,availability,down,downloading,11,Option for downloading tissue image for spatial visium dataset; Following discussions with @giovp I've extended the `scanpy.datasets.visium_sge` function to optionally return a path to the high-resolution tissue image also available in the visium Spatial Transcriptomics datasets. This makes it easy to leverage `scanpy.datasets` to fully explore visium datasets.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506
https://github.com/scverse/scanpy/pull/1506:223,availability,avail,available,223,Option for downloading tissue image for spatial visium dataset; Following discussions with @giovp I've extended the `scanpy.datasets.visium_sge` function to optionally return a path to the high-resolution tissue image also available in the visium Spatial Transcriptomics datasets. This makes it easy to leverage `scanpy.datasets` to fully explore visium datasets.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506
https://github.com/scverse/scanpy/pull/1506:103,modifiability,exten,extended,103,Option for downloading tissue image for spatial visium dataset; Following discussions with @giovp I've extended the `scanpy.datasets.visium_sge` function to optionally return a path to the high-resolution tissue image also available in the visium Spatial Transcriptomics datasets. This makes it easy to leverage `scanpy.datasets` to fully explore visium datasets.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506
https://github.com/scverse/scanpy/pull/1506:223,reliability,availab,available,223,Option for downloading tissue image for spatial visium dataset; Following discussions with @giovp I've extended the `scanpy.datasets.visium_sge` function to optionally return a path to the high-resolution tissue image also available in the visium Spatial Transcriptomics datasets. This makes it easy to leverage `scanpy.datasets` to fully explore visium datasets.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506
https://github.com/scverse/scanpy/pull/1506:223,safety,avail,available,223,Option for downloading tissue image for spatial visium dataset; Following discussions with @giovp I've extended the `scanpy.datasets.visium_sge` function to optionally return a path to the high-resolution tissue image also available in the visium Spatial Transcriptomics datasets. This makes it easy to leverage `scanpy.datasets` to fully explore visium datasets.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506
https://github.com/scverse/scanpy/pull/1506:223,security,availab,available,223,Option for downloading tissue image for spatial visium dataset; Following discussions with @giovp I've extended the `scanpy.datasets.visium_sge` function to optionally return a path to the high-resolution tissue image also available in the visium Spatial Transcriptomics datasets. This makes it easy to leverage `scanpy.datasets` to fully explore visium datasets.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1506
https://github.com/scverse/scanpy/pull/1507:81,availability,down,downloading,81,"Fix progress bar, use requests, tqdm version; This fixes the small progress when downloading the data as `sc.datasets.paul_15()`, etc.. Also fixes removing the file when `KeyboardInterrupt` occurs (previously, it was just on exceptions and at least for me I sometimes stop a download by interupting the jupyter kernel - now it also correctly removes the partially downloaded file). I've also opted for `requests` library, since it's much cleaner than urllib3 and as a dependency. However, this is completely unrelated to the 2 things I've mentioned above and can be quickly reverted. Relevant PRs I could find:. - tqdm version (I opted for bumping the version [search through open issues, lowest one had 4.32]): https://github.com/theislab/scanpy/issues/1244. Not relevant:. My [reaction](https://www.youtube.com/watch?v=nixR6wVa4HY&t=72) when using the progress bar (slightly NSFW [foul language]).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1507
https://github.com/scverse/scanpy/pull/1507:275,availability,down,download,275,"Fix progress bar, use requests, tqdm version; This fixes the small progress when downloading the data as `sc.datasets.paul_15()`, etc.. Also fixes removing the file when `KeyboardInterrupt` occurs (previously, it was just on exceptions and at least for me I sometimes stop a download by interupting the jupyter kernel - now it also correctly removes the partially downloaded file). I've also opted for `requests` library, since it's much cleaner than urllib3 and as a dependency. However, this is completely unrelated to the 2 things I've mentioned above and can be quickly reverted. Relevant PRs I could find:. - tqdm version (I opted for bumping the version [search through open issues, lowest one had 4.32]): https://github.com/theislab/scanpy/issues/1244. Not relevant:. My [reaction](https://www.youtube.com/watch?v=nixR6wVa4HY&t=72) when using the progress bar (slightly NSFW [foul language]).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1507
https://github.com/scverse/scanpy/pull/1507:364,availability,down,downloaded,364,"Fix progress bar, use requests, tqdm version; This fixes the small progress when downloading the data as `sc.datasets.paul_15()`, etc.. Also fixes removing the file when `KeyboardInterrupt` occurs (previously, it was just on exceptions and at least for me I sometimes stop a download by interupting the jupyter kernel - now it also correctly removes the partially downloaded file). I've also opted for `requests` library, since it's much cleaner than urllib3 and as a dependency. However, this is completely unrelated to the 2 things I've mentioned above and can be quickly reverted. Relevant PRs I could find:. - tqdm version (I opted for bumping the version [search through open issues, lowest one had 4.32]): https://github.com/theislab/scanpy/issues/1244. Not relevant:. My [reaction](https://www.youtube.com/watch?v=nixR6wVa4HY&t=72) when using the progress bar (slightly NSFW [foul language]).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1507
https://github.com/scverse/scanpy/pull/1507:868,availability,sli,slightly,868,"Fix progress bar, use requests, tqdm version; This fixes the small progress when downloading the data as `sc.datasets.paul_15()`, etc.. Also fixes removing the file when `KeyboardInterrupt` occurs (previously, it was just on exceptions and at least for me I sometimes stop a download by interupting the jupyter kernel - now it also correctly removes the partially downloaded file). I've also opted for `requests` library, since it's much cleaner than urllib3 and as a dependency. However, this is completely unrelated to the 2 things I've mentioned above and can be quickly reverted. Relevant PRs I could find:. - tqdm version (I opted for bumping the version [search through open issues, lowest one had 4.32]): https://github.com/theislab/scanpy/issues/1244. Not relevant:. My [reaction](https://www.youtube.com/watch?v=nixR6wVa4HY&t=72) when using the progress bar (slightly NSFW [foul language]).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1507
https://github.com/scverse/scanpy/pull/1507:37,deployability,version,version,37,"Fix progress bar, use requests, tqdm version; This fixes the small progress when downloading the data as `sc.datasets.paul_15()`, etc.. Also fixes removing the file when `KeyboardInterrupt` occurs (previously, it was just on exceptions and at least for me I sometimes stop a download by interupting the jupyter kernel - now it also correctly removes the partially downloaded file). I've also opted for `requests` library, since it's much cleaner than urllib3 and as a dependency. However, this is completely unrelated to the 2 things I've mentioned above and can be quickly reverted. Relevant PRs I could find:. - tqdm version (I opted for bumping the version [search through open issues, lowest one had 4.32]): https://github.com/theislab/scanpy/issues/1244. Not relevant:. My [reaction](https://www.youtube.com/watch?v=nixR6wVa4HY&t=72) when using the progress bar (slightly NSFW [foul language]).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1507
https://github.com/scverse/scanpy/pull/1507:468,deployability,depend,dependency,468,"Fix progress bar, use requests, tqdm version; This fixes the small progress when downloading the data as `sc.datasets.paul_15()`, etc.. Also fixes removing the file when `KeyboardInterrupt` occurs (previously, it was just on exceptions and at least for me I sometimes stop a download by interupting the jupyter kernel - now it also correctly removes the partially downloaded file). I've also opted for `requests` library, since it's much cleaner than urllib3 and as a dependency. However, this is completely unrelated to the 2 things I've mentioned above and can be quickly reverted. Relevant PRs I could find:. - tqdm version (I opted for bumping the version [search through open issues, lowest one had 4.32]): https://github.com/theislab/scanpy/issues/1244. Not relevant:. My [reaction](https://www.youtube.com/watch?v=nixR6wVa4HY&t=72) when using the progress bar (slightly NSFW [foul language]).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1507
https://github.com/scverse/scanpy/pull/1507:619,deployability,version,version,619,"Fix progress bar, use requests, tqdm version; This fixes the small progress when downloading the data as `sc.datasets.paul_15()`, etc.. Also fixes removing the file when `KeyboardInterrupt` occurs (previously, it was just on exceptions and at least for me I sometimes stop a download by interupting the jupyter kernel - now it also correctly removes the partially downloaded file). I've also opted for `requests` library, since it's much cleaner than urllib3 and as a dependency. However, this is completely unrelated to the 2 things I've mentioned above and can be quickly reverted. Relevant PRs I could find:. - tqdm version (I opted for bumping the version [search through open issues, lowest one had 4.32]): https://github.com/theislab/scanpy/issues/1244. Not relevant:. My [reaction](https://www.youtube.com/watch?v=nixR6wVa4HY&t=72) when using the progress bar (slightly NSFW [foul language]).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1507
https://github.com/scverse/scanpy/pull/1507:652,deployability,version,version,652,"Fix progress bar, use requests, tqdm version; This fixes the small progress when downloading the data as `sc.datasets.paul_15()`, etc.. Also fixes removing the file when `KeyboardInterrupt` occurs (previously, it was just on exceptions and at least for me I sometimes stop a download by interupting the jupyter kernel - now it also correctly removes the partially downloaded file). I've also opted for `requests` library, since it's much cleaner than urllib3 and as a dependency. However, this is completely unrelated to the 2 things I've mentioned above and can be quickly reverted. Relevant PRs I could find:. - tqdm version (I opted for bumping the version [search through open issues, lowest one had 4.32]): https://github.com/theislab/scanpy/issues/1244. Not relevant:. My [reaction](https://www.youtube.com/watch?v=nixR6wVa4HY&t=72) when using the progress bar (slightly NSFW [foul language]).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1507
https://github.com/scverse/scanpy/pull/1507:37,integrability,version,version,37,"Fix progress bar, use requests, tqdm version; This fixes the small progress when downloading the data as `sc.datasets.paul_15()`, etc.. Also fixes removing the file when `KeyboardInterrupt` occurs (previously, it was just on exceptions and at least for me I sometimes stop a download by interupting the jupyter kernel - now it also correctly removes the partially downloaded file). I've also opted for `requests` library, since it's much cleaner than urllib3 and as a dependency. However, this is completely unrelated to the 2 things I've mentioned above and can be quickly reverted. Relevant PRs I could find:. - tqdm version (I opted for bumping the version [search through open issues, lowest one had 4.32]): https://github.com/theislab/scanpy/issues/1244. Not relevant:. My [reaction](https://www.youtube.com/watch?v=nixR6wVa4HY&t=72) when using the progress bar (slightly NSFW [foul language]).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1507
https://github.com/scverse/scanpy/pull/1507:468,integrability,depend,dependency,468,"Fix progress bar, use requests, tqdm version; This fixes the small progress when downloading the data as `sc.datasets.paul_15()`, etc.. Also fixes removing the file when `KeyboardInterrupt` occurs (previously, it was just on exceptions and at least for me I sometimes stop a download by interupting the jupyter kernel - now it also correctly removes the partially downloaded file). I've also opted for `requests` library, since it's much cleaner than urllib3 and as a dependency. However, this is completely unrelated to the 2 things I've mentioned above and can be quickly reverted. Relevant PRs I could find:. - tqdm version (I opted for bumping the version [search through open issues, lowest one had 4.32]): https://github.com/theislab/scanpy/issues/1244. Not relevant:. My [reaction](https://www.youtube.com/watch?v=nixR6wVa4HY&t=72) when using the progress bar (slightly NSFW [foul language]).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1507
https://github.com/scverse/scanpy/pull/1507:619,integrability,version,version,619,"Fix progress bar, use requests, tqdm version; This fixes the small progress when downloading the data as `sc.datasets.paul_15()`, etc.. Also fixes removing the file when `KeyboardInterrupt` occurs (previously, it was just on exceptions and at least for me I sometimes stop a download by interupting the jupyter kernel - now it also correctly removes the partially downloaded file). I've also opted for `requests` library, since it's much cleaner than urllib3 and as a dependency. However, this is completely unrelated to the 2 things I've mentioned above and can be quickly reverted. Relevant PRs I could find:. - tqdm version (I opted for bumping the version [search through open issues, lowest one had 4.32]): https://github.com/theislab/scanpy/issues/1244. Not relevant:. My [reaction](https://www.youtube.com/watch?v=nixR6wVa4HY&t=72) when using the progress bar (slightly NSFW [foul language]).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1507
https://github.com/scverse/scanpy/pull/1507:652,integrability,version,version,652,"Fix progress bar, use requests, tqdm version; This fixes the small progress when downloading the data as `sc.datasets.paul_15()`, etc.. Also fixes removing the file when `KeyboardInterrupt` occurs (previously, it was just on exceptions and at least for me I sometimes stop a download by interupting the jupyter kernel - now it also correctly removes the partially downloaded file). I've also opted for `requests` library, since it's much cleaner than urllib3 and as a dependency. However, this is completely unrelated to the 2 things I've mentioned above and can be quickly reverted. Relevant PRs I could find:. - tqdm version (I opted for bumping the version [search through open issues, lowest one had 4.32]): https://github.com/theislab/scanpy/issues/1244. Not relevant:. My [reaction](https://www.youtube.com/watch?v=nixR6wVa4HY&t=72) when using the progress bar (slightly NSFW [foul language]).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1507
https://github.com/scverse/scanpy/pull/1507:37,modifiability,version,version,37,"Fix progress bar, use requests, tqdm version; This fixes the small progress when downloading the data as `sc.datasets.paul_15()`, etc.. Also fixes removing the file when `KeyboardInterrupt` occurs (previously, it was just on exceptions and at least for me I sometimes stop a download by interupting the jupyter kernel - now it also correctly removes the partially downloaded file). I've also opted for `requests` library, since it's much cleaner than urllib3 and as a dependency. However, this is completely unrelated to the 2 things I've mentioned above and can be quickly reverted. Relevant PRs I could find:. - tqdm version (I opted for bumping the version [search through open issues, lowest one had 4.32]): https://github.com/theislab/scanpy/issues/1244. Not relevant:. My [reaction](https://www.youtube.com/watch?v=nixR6wVa4HY&t=72) when using the progress bar (slightly NSFW [foul language]).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1507
https://github.com/scverse/scanpy/pull/1507:468,modifiability,depend,dependency,468,"Fix progress bar, use requests, tqdm version; This fixes the small progress when downloading the data as `sc.datasets.paul_15()`, etc.. Also fixes removing the file when `KeyboardInterrupt` occurs (previously, it was just on exceptions and at least for me I sometimes stop a download by interupting the jupyter kernel - now it also correctly removes the partially downloaded file). I've also opted for `requests` library, since it's much cleaner than urllib3 and as a dependency. However, this is completely unrelated to the 2 things I've mentioned above and can be quickly reverted. Relevant PRs I could find:. - tqdm version (I opted for bumping the version [search through open issues, lowest one had 4.32]): https://github.com/theislab/scanpy/issues/1244. Not relevant:. My [reaction](https://www.youtube.com/watch?v=nixR6wVa4HY&t=72) when using the progress bar (slightly NSFW [foul language]).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1507
https://github.com/scverse/scanpy/pull/1507:619,modifiability,version,version,619,"Fix progress bar, use requests, tqdm version; This fixes the small progress when downloading the data as `sc.datasets.paul_15()`, etc.. Also fixes removing the file when `KeyboardInterrupt` occurs (previously, it was just on exceptions and at least for me I sometimes stop a download by interupting the jupyter kernel - now it also correctly removes the partially downloaded file). I've also opted for `requests` library, since it's much cleaner than urllib3 and as a dependency. However, this is completely unrelated to the 2 things I've mentioned above and can be quickly reverted. Relevant PRs I could find:. - tqdm version (I opted for bumping the version [search through open issues, lowest one had 4.32]): https://github.com/theislab/scanpy/issues/1244. Not relevant:. My [reaction](https://www.youtube.com/watch?v=nixR6wVa4HY&t=72) when using the progress bar (slightly NSFW [foul language]).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1507
https://github.com/scverse/scanpy/pull/1507:652,modifiability,version,version,652,"Fix progress bar, use requests, tqdm version; This fixes the small progress when downloading the data as `sc.datasets.paul_15()`, etc.. Also fixes removing the file when `KeyboardInterrupt` occurs (previously, it was just on exceptions and at least for me I sometimes stop a download by interupting the jupyter kernel - now it also correctly removes the partially downloaded file). I've also opted for `requests` library, since it's much cleaner than urllib3 and as a dependency. However, this is completely unrelated to the 2 things I've mentioned above and can be quickly reverted. Relevant PRs I could find:. - tqdm version (I opted for bumping the version [search through open issues, lowest one had 4.32]): https://github.com/theislab/scanpy/issues/1244. Not relevant:. My [reaction](https://www.youtube.com/watch?v=nixR6wVa4HY&t=72) when using the progress bar (slightly NSFW [foul language]).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1507
https://github.com/scverse/scanpy/pull/1507:868,reliability,sli,slightly,868,"Fix progress bar, use requests, tqdm version; This fixes the small progress when downloading the data as `sc.datasets.paul_15()`, etc.. Also fixes removing the file when `KeyboardInterrupt` occurs (previously, it was just on exceptions and at least for me I sometimes stop a download by interupting the jupyter kernel - now it also correctly removes the partially downloaded file). I've also opted for `requests` library, since it's much cleaner than urllib3 and as a dependency. However, this is completely unrelated to the 2 things I've mentioned above and can be quickly reverted. Relevant PRs I could find:. - tqdm version (I opted for bumping the version [search through open issues, lowest one had 4.32]): https://github.com/theislab/scanpy/issues/1244. Not relevant:. My [reaction](https://www.youtube.com/watch?v=nixR6wVa4HY&t=72) when using the progress bar (slightly NSFW [foul language]).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1507
https://github.com/scverse/scanpy/pull/1507:225,safety,except,exceptions,225,"Fix progress bar, use requests, tqdm version; This fixes the small progress when downloading the data as `sc.datasets.paul_15()`, etc.. Also fixes removing the file when `KeyboardInterrupt` occurs (previously, it was just on exceptions and at least for me I sometimes stop a download by interupting the jupyter kernel - now it also correctly removes the partially downloaded file). I've also opted for `requests` library, since it's much cleaner than urllib3 and as a dependency. However, this is completely unrelated to the 2 things I've mentioned above and can be quickly reverted. Relevant PRs I could find:. - tqdm version (I opted for bumping the version [search through open issues, lowest one had 4.32]): https://github.com/theislab/scanpy/issues/1244. Not relevant:. My [reaction](https://www.youtube.com/watch?v=nixR6wVa4HY&t=72) when using the progress bar (slightly NSFW [foul language]).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1507
https://github.com/scverse/scanpy/pull/1507:468,safety,depend,dependency,468,"Fix progress bar, use requests, tqdm version; This fixes the small progress when downloading the data as `sc.datasets.paul_15()`, etc.. Also fixes removing the file when `KeyboardInterrupt` occurs (previously, it was just on exceptions and at least for me I sometimes stop a download by interupting the jupyter kernel - now it also correctly removes the partially downloaded file). I've also opted for `requests` library, since it's much cleaner than urllib3 and as a dependency. However, this is completely unrelated to the 2 things I've mentioned above and can be quickly reverted. Relevant PRs I could find:. - tqdm version (I opted for bumping the version [search through open issues, lowest one had 4.32]): https://github.com/theislab/scanpy/issues/1244. Not relevant:. My [reaction](https://www.youtube.com/watch?v=nixR6wVa4HY&t=72) when using the progress bar (slightly NSFW [foul language]).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1507
https://github.com/scverse/scanpy/pull/1507:497,safety,compl,completely,497,"Fix progress bar, use requests, tqdm version; This fixes the small progress when downloading the data as `sc.datasets.paul_15()`, etc.. Also fixes removing the file when `KeyboardInterrupt` occurs (previously, it was just on exceptions and at least for me I sometimes stop a download by interupting the jupyter kernel - now it also correctly removes the partially downloaded file). I've also opted for `requests` library, since it's much cleaner than urllib3 and as a dependency. However, this is completely unrelated to the 2 things I've mentioned above and can be quickly reverted. Relevant PRs I could find:. - tqdm version (I opted for bumping the version [search through open issues, lowest one had 4.32]): https://github.com/theislab/scanpy/issues/1244. Not relevant:. My [reaction](https://www.youtube.com/watch?v=nixR6wVa4HY&t=72) when using the progress bar (slightly NSFW [foul language]).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1507
https://github.com/scverse/scanpy/pull/1507:497,security,compl,completely,497,"Fix progress bar, use requests, tqdm version; This fixes the small progress when downloading the data as `sc.datasets.paul_15()`, etc.. Also fixes removing the file when `KeyboardInterrupt` occurs (previously, it was just on exceptions and at least for me I sometimes stop a download by interupting the jupyter kernel - now it also correctly removes the partially downloaded file). I've also opted for `requests` library, since it's much cleaner than urllib3 and as a dependency. However, this is completely unrelated to the 2 things I've mentioned above and can be quickly reverted. Relevant PRs I could find:. - tqdm version (I opted for bumping the version [search through open issues, lowest one had 4.32]): https://github.com/theislab/scanpy/issues/1244. Not relevant:. My [reaction](https://www.youtube.com/watch?v=nixR6wVa4HY&t=72) when using the progress bar (slightly NSFW [foul language]).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1507
https://github.com/scverse/scanpy/pull/1507:468,testability,depend,dependency,468,"Fix progress bar, use requests, tqdm version; This fixes the small progress when downloading the data as `sc.datasets.paul_15()`, etc.. Also fixes removing the file when `KeyboardInterrupt` occurs (previously, it was just on exceptions and at least for me I sometimes stop a download by interupting the jupyter kernel - now it also correctly removes the partially downloaded file). I've also opted for `requests` library, since it's much cleaner than urllib3 and as a dependency. However, this is completely unrelated to the 2 things I've mentioned above and can be quickly reverted. Relevant PRs I could find:. - tqdm version (I opted for bumping the version [search through open issues, lowest one had 4.32]): https://github.com/theislab/scanpy/issues/1244. Not relevant:. My [reaction](https://www.youtube.com/watch?v=nixR6wVa4HY&t=72) when using the progress bar (slightly NSFW [foul language]).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1507
https://github.com/scverse/scanpy/pull/1507:4,usability,progress,progress,4,"Fix progress bar, use requests, tqdm version; This fixes the small progress when downloading the data as `sc.datasets.paul_15()`, etc.. Also fixes removing the file when `KeyboardInterrupt` occurs (previously, it was just on exceptions and at least for me I sometimes stop a download by interupting the jupyter kernel - now it also correctly removes the partially downloaded file). I've also opted for `requests` library, since it's much cleaner than urllib3 and as a dependency. However, this is completely unrelated to the 2 things I've mentioned above and can be quickly reverted. Relevant PRs I could find:. - tqdm version (I opted for bumping the version [search through open issues, lowest one had 4.32]): https://github.com/theislab/scanpy/issues/1244. Not relevant:. My [reaction](https://www.youtube.com/watch?v=nixR6wVa4HY&t=72) when using the progress bar (slightly NSFW [foul language]).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1507
https://github.com/scverse/scanpy/pull/1507:67,usability,progress,progress,67,"Fix progress bar, use requests, tqdm version; This fixes the small progress when downloading the data as `sc.datasets.paul_15()`, etc.. Also fixes removing the file when `KeyboardInterrupt` occurs (previously, it was just on exceptions and at least for me I sometimes stop a download by interupting the jupyter kernel - now it also correctly removes the partially downloaded file). I've also opted for `requests` library, since it's much cleaner than urllib3 and as a dependency. However, this is completely unrelated to the 2 things I've mentioned above and can be quickly reverted. Relevant PRs I could find:. - tqdm version (I opted for bumping the version [search through open issues, lowest one had 4.32]): https://github.com/theislab/scanpy/issues/1244. Not relevant:. My [reaction](https://www.youtube.com/watch?v=nixR6wVa4HY&t=72) when using the progress bar (slightly NSFW [foul language]).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1507
https://github.com/scverse/scanpy/pull/1507:268,usability,stop,stop,268,"Fix progress bar, use requests, tqdm version; This fixes the small progress when downloading the data as `sc.datasets.paul_15()`, etc.. Also fixes removing the file when `KeyboardInterrupt` occurs (previously, it was just on exceptions and at least for me I sometimes stop a download by interupting the jupyter kernel - now it also correctly removes the partially downloaded file). I've also opted for `requests` library, since it's much cleaner than urllib3 and as a dependency. However, this is completely unrelated to the 2 things I've mentioned above and can be quickly reverted. Relevant PRs I could find:. - tqdm version (I opted for bumping the version [search through open issues, lowest one had 4.32]): https://github.com/theislab/scanpy/issues/1244. Not relevant:. My [reaction](https://www.youtube.com/watch?v=nixR6wVa4HY&t=72) when using the progress bar (slightly NSFW [foul language]).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1507
https://github.com/scverse/scanpy/pull/1507:854,usability,progress,progress,854,"Fix progress bar, use requests, tqdm version; This fixes the small progress when downloading the data as `sc.datasets.paul_15()`, etc.. Also fixes removing the file when `KeyboardInterrupt` occurs (previously, it was just on exceptions and at least for me I sometimes stop a download by interupting the jupyter kernel - now it also correctly removes the partially downloaded file). I've also opted for `requests` library, since it's much cleaner than urllib3 and as a dependency. However, this is completely unrelated to the 2 things I've mentioned above and can be quickly reverted. Relevant PRs I could find:. - tqdm version (I opted for bumping the version [search through open issues, lowest one had 4.32]): https://github.com/theislab/scanpy/issues/1244. Not relevant:. My [reaction](https://www.youtube.com/watch?v=nixR6wVa4HY&t=72) when using the progress bar (slightly NSFW [foul language]).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1507
https://github.com/scverse/scanpy/issues/1508:200,deployability,version,version,200,"Saving plots results in a prefixed filename, regardless of sc.settings.figdir; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. As far as I can tell, `sc.pl.violin` always prepends the string ""violin"" to all save filed, regardless of `sc.settings.figdir`. This complicates programatically setting the filename for outputs. I've also confirmed this behaviour for `sc.pl.scatter`, and suspect it holds true for other `sc.pl` methods. As an example: I keep all results from my analysis in a `results/` directory, with each step having its own subdirectory. Currently, this doesn't seem possible. If I set `sc.settings.figdir = ./results`, then try to save to, say ""qcmetrics/total_counts.png"", the code fails as ""violinqcmetrics/total_counts.png"" does not exist. A partial work around is to set `sc.settings.figdir` every time I want to save in a different directory, but this feels quite clunky to me. And it will still result in all my files being prepended with ""violin"" (or ""scatter"", etc.), which I'd like to avoid. Is there any way to disable this prefix on save behaviour? ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.settings.figdir = ""./"". sc.pl.violin(adata, [""total_counts""], save=""results/test_plot.png""). ```. ```pytb. FileNotFoundError: [Errno 2] No such file or directory: 'violinresults/test_plot.png'. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.6.0. sinfo 0.3.1. -----. IPython 7.19.0. PIL 8.0.1. anndata 0.7.5. backcall 0.2.0. cffi 1.14.4. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. flufl NA. get_version 2.1. h5py 3.1.0. igraph 0.8.3. ipython_genutils 0.2.0. jedi 0.17.2. joblib 0.17.0. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.35.0rc3. matplotlib 3.3.3. mpl_toolkits NA. natsor",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1508
https://github.com/scverse/scanpy/issues/1508:878,deployability,fail,fails,878,"Saving plots results in a prefixed filename, regardless of sc.settings.figdir; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. As far as I can tell, `sc.pl.violin` always prepends the string ""violin"" to all save filed, regardless of `sc.settings.figdir`. This complicates programatically setting the filename for outputs. I've also confirmed this behaviour for `sc.pl.scatter`, and suspect it holds true for other `sc.pl` methods. As an example: I keep all results from my analysis in a `results/` directory, with each step having its own subdirectory. Currently, this doesn't seem possible. If I set `sc.settings.figdir = ./results`, then try to save to, say ""qcmetrics/total_counts.png"", the code fails as ""violinqcmetrics/total_counts.png"" does not exist. A partial work around is to set `sc.settings.figdir` every time I want to save in a different directory, but this feels quite clunky to me. And it will still result in all my files being prepended with ""violin"" (or ""scatter"", etc.), which I'd like to avoid. Is there any way to disable this prefix on save behaviour? ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.settings.figdir = ""./"". sc.pl.violin(adata, [""total_counts""], save=""results/test_plot.png""). ```. ```pytb. FileNotFoundError: [Errno 2] No such file or directory: 'violinresults/test_plot.png'. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.6.0. sinfo 0.3.1. -----. IPython 7.19.0. PIL 8.0.1. anndata 0.7.5. backcall 0.2.0. cffi 1.14.4. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. flufl NA. get_version 2.1. h5py 3.1.0. igraph 0.8.3. ipython_genutils 0.2.0. jedi 0.17.2. joblib 0.17.0. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.35.0rc3. matplotlib 3.3.3. mpl_toolkits NA. natsor",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1508
https://github.com/scverse/scanpy/issues/1508:1547,deployability,Version,Versions,1547,"ter`, and suspect it holds true for other `sc.pl` methods. As an example: I keep all results from my analysis in a `results/` directory, with each step having its own subdirectory. Currently, this doesn't seem possible. If I set `sc.settings.figdir = ./results`, then try to save to, say ""qcmetrics/total_counts.png"", the code fails as ""violinqcmetrics/total_counts.png"" does not exist. A partial work around is to set `sc.settings.figdir` every time I want to save in a different directory, but this feels quite clunky to me. And it will still result in all my files being prepended with ""violin"" (or ""scatter"", etc.), which I'd like to avoid. Is there any way to disable this prefix on save behaviour? ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.settings.figdir = ""./"". sc.pl.violin(adata, [""total_counts""], save=""results/test_plot.png""). ```. ```pytb. FileNotFoundError: [Errno 2] No such file or directory: 'violinresults/test_plot.png'. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.6.0. sinfo 0.3.1. -----. IPython 7.19.0. PIL 8.0.1. anndata 0.7.5. backcall 0.2.0. cffi 1.14.4. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. flufl NA. get_version 2.1. h5py 3.1.0. igraph 0.8.3. ipython_genutils 0.2.0. jedi 0.17.2. joblib 0.17.0. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.35.0rc3. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.1.0. numba 0.51.2. numexpr 2.7.1. numpy 1.19.4. packaging 20.4. pandas 1.1.4. parso 0.7.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.8. ptyprocess 0.6.0. pygments 2.7.2. pyparsing 2.4.7. pytz 2020.4. ruamel NA. scanpy 1.6.0. scipy 1.5.4. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. storemagic NA. tables 3.6.1. texttable 1.6.3. traitlets 5.0.5. typing_extensions NA. wcwidth 0.2.5. yaml 5.3.1. zc NA. -----. Python 3.8.4 (default, Jul 16 2020, 19:35:12) [GCC 9.3.0]. Linux-5.4.0-54-generic-x86_64-with-",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1508
https://github.com/scverse/scanpy/issues/1508:2564,deployability,log,logical,2564,"is in a `results/` directory, with each step having its own subdirectory. Currently, this doesn't seem possible. If I set `sc.settings.figdir = ./results`, then try to save to, say ""qcmetrics/total_counts.png"", the code fails as ""violinqcmetrics/total_counts.png"" does not exist. A partial work around is to set `sc.settings.figdir` every time I want to save in a different directory, but this feels quite clunky to me. And it will still result in all my files being prepended with ""violin"" (or ""scatter"", etc.), which I'd like to avoid. Is there any way to disable this prefix on save behaviour? ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.settings.figdir = ""./"". sc.pl.violin(adata, [""total_counts""], save=""results/test_plot.png""). ```. ```pytb. FileNotFoundError: [Errno 2] No such file or directory: 'violinresults/test_plot.png'. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.6.0. sinfo 0.3.1. -----. IPython 7.19.0. PIL 8.0.1. anndata 0.7.5. backcall 0.2.0. cffi 1.14.4. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. flufl NA. get_version 2.1. h5py 3.1.0. igraph 0.8.3. ipython_genutils 0.2.0. jedi 0.17.2. joblib 0.17.0. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.35.0rc3. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.1.0. numba 0.51.2. numexpr 2.7.1. numpy 1.19.4. packaging 20.4. pandas 1.1.4. parso 0.7.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.8. ptyprocess 0.6.0. pygments 2.7.2. pyparsing 2.4.7. pytz 2020.4. ruamel NA. scanpy 1.6.0. scipy 1.5.4. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. storemagic NA. tables 3.6.1. texttable 1.6.3. traitlets 5.0.5. typing_extensions NA. wcwidth 0.2.5. yaml 5.3.1. zc NA. -----. Python 3.8.4 (default, Jul 16 2020, 19:35:12) [GCC 9.3.0]. Linux-5.4.0-54-generic-x86_64-with-glibc2.29. 8 logical CPU cores, x86_64. -----. Session information updated at 2020-11-25 11:03. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1508
https://github.com/scverse/scanpy/issues/1508:2618,deployability,updat,updated,2618,"is in a `results/` directory, with each step having its own subdirectory. Currently, this doesn't seem possible. If I set `sc.settings.figdir = ./results`, then try to save to, say ""qcmetrics/total_counts.png"", the code fails as ""violinqcmetrics/total_counts.png"" does not exist. A partial work around is to set `sc.settings.figdir` every time I want to save in a different directory, but this feels quite clunky to me. And it will still result in all my files being prepended with ""violin"" (or ""scatter"", etc.), which I'd like to avoid. Is there any way to disable this prefix on save behaviour? ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.settings.figdir = ""./"". sc.pl.violin(adata, [""total_counts""], save=""results/test_plot.png""). ```. ```pytb. FileNotFoundError: [Errno 2] No such file or directory: 'violinresults/test_plot.png'. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.6.0. sinfo 0.3.1. -----. IPython 7.19.0. PIL 8.0.1. anndata 0.7.5. backcall 0.2.0. cffi 1.14.4. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. flufl NA. get_version 2.1. h5py 3.1.0. igraph 0.8.3. ipython_genutils 0.2.0. jedi 0.17.2. joblib 0.17.0. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.35.0rc3. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.1.0. numba 0.51.2. numexpr 2.7.1. numpy 1.19.4. packaging 20.4. pandas 1.1.4. parso 0.7.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.8. ptyprocess 0.6.0. pygments 2.7.2. pyparsing 2.4.7. pytz 2020.4. ruamel NA. scanpy 1.6.0. scipy 1.5.4. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. storemagic NA. tables 3.6.1. texttable 1.6.3. traitlets 5.0.5. typing_extensions NA. wcwidth 0.2.5. yaml 5.3.1. zc NA. -----. Python 3.8.4 (default, Jul 16 2020, 19:35:12) [GCC 9.3.0]. Linux-5.4.0-54-generic-x86_64-with-glibc2.29. 8 logical CPU cores, x86_64. -----. Session information updated at 2020-11-25 11:03. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1508
https://github.com/scverse/scanpy/issues/1508:732,energy efficiency,Current,Currently,732,"Saving plots results in a prefixed filename, regardless of sc.settings.figdir; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. As far as I can tell, `sc.pl.violin` always prepends the string ""violin"" to all save filed, regardless of `sc.settings.figdir`. This complicates programatically setting the filename for outputs. I've also confirmed this behaviour for `sc.pl.scatter`, and suspect it holds true for other `sc.pl` methods. As an example: I keep all results from my analysis in a `results/` directory, with each step having its own subdirectory. Currently, this doesn't seem possible. If I set `sc.settings.figdir = ./results`, then try to save to, say ""qcmetrics/total_counts.png"", the code fails as ""violinqcmetrics/total_counts.png"" does not exist. A partial work around is to set `sc.settings.figdir` every time I want to save in a different directory, but this feels quite clunky to me. And it will still result in all my files being prepended with ""violin"" (or ""scatter"", etc.), which I'd like to avoid. Is there any way to disable this prefix on save behaviour? ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.settings.figdir = ""./"". sc.pl.violin(adata, [""total_counts""], save=""results/test_plot.png""). ```. ```pytb. FileNotFoundError: [Errno 2] No such file or directory: 'violinresults/test_plot.png'. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.6.0. sinfo 0.3.1. -----. IPython 7.19.0. PIL 8.0.1. anndata 0.7.5. backcall 0.2.0. cffi 1.14.4. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. flufl NA. get_version 2.1. h5py 3.1.0. igraph 0.8.3. ipython_genutils 0.2.0. jedi 0.17.2. joblib 0.17.0. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.35.0rc3. matplotlib 3.3.3. mpl_toolkits NA. natsor",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1508
https://github.com/scverse/scanpy/issues/1508:2572,energy efficiency,CPU,CPU,2572,"is in a `results/` directory, with each step having its own subdirectory. Currently, this doesn't seem possible. If I set `sc.settings.figdir = ./results`, then try to save to, say ""qcmetrics/total_counts.png"", the code fails as ""violinqcmetrics/total_counts.png"" does not exist. A partial work around is to set `sc.settings.figdir` every time I want to save in a different directory, but this feels quite clunky to me. And it will still result in all my files being prepended with ""violin"" (or ""scatter"", etc.), which I'd like to avoid. Is there any way to disable this prefix on save behaviour? ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.settings.figdir = ""./"". sc.pl.violin(adata, [""total_counts""], save=""results/test_plot.png""). ```. ```pytb. FileNotFoundError: [Errno 2] No such file or directory: 'violinresults/test_plot.png'. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.6.0. sinfo 0.3.1. -----. IPython 7.19.0. PIL 8.0.1. anndata 0.7.5. backcall 0.2.0. cffi 1.14.4. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. flufl NA. get_version 2.1. h5py 3.1.0. igraph 0.8.3. ipython_genutils 0.2.0. jedi 0.17.2. joblib 0.17.0. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.35.0rc3. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.1.0. numba 0.51.2. numexpr 2.7.1. numpy 1.19.4. packaging 20.4. pandas 1.1.4. parso 0.7.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.8. ptyprocess 0.6.0. pygments 2.7.2. pyparsing 2.4.7. pytz 2020.4. ruamel NA. scanpy 1.6.0. scipy 1.5.4. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. storemagic NA. tables 3.6.1. texttable 1.6.3. traitlets 5.0.5. typing_extensions NA. wcwidth 0.2.5. yaml 5.3.1. zc NA. -----. Python 3.8.4 (default, Jul 16 2020, 19:35:12) [GCC 9.3.0]. Linux-5.4.0-54-generic-x86_64-with-glibc2.29. 8 logical CPU cores, x86_64. -----. Session information updated at 2020-11-25 11:03. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1508
https://github.com/scverse/scanpy/issues/1508:2576,energy efficiency,core,cores,2576,"is in a `results/` directory, with each step having its own subdirectory. Currently, this doesn't seem possible. If I set `sc.settings.figdir = ./results`, then try to save to, say ""qcmetrics/total_counts.png"", the code fails as ""violinqcmetrics/total_counts.png"" does not exist. A partial work around is to set `sc.settings.figdir` every time I want to save in a different directory, but this feels quite clunky to me. And it will still result in all my files being prepended with ""violin"" (or ""scatter"", etc.), which I'd like to avoid. Is there any way to disable this prefix on save behaviour? ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.settings.figdir = ""./"". sc.pl.violin(adata, [""total_counts""], save=""results/test_plot.png""). ```. ```pytb. FileNotFoundError: [Errno 2] No such file or directory: 'violinresults/test_plot.png'. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.6.0. sinfo 0.3.1. -----. IPython 7.19.0. PIL 8.0.1. anndata 0.7.5. backcall 0.2.0. cffi 1.14.4. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. flufl NA. get_version 2.1. h5py 3.1.0. igraph 0.8.3. ipython_genutils 0.2.0. jedi 0.17.2. joblib 0.17.0. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.35.0rc3. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.1.0. numba 0.51.2. numexpr 2.7.1. numpy 1.19.4. packaging 20.4. pandas 1.1.4. parso 0.7.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.8. ptyprocess 0.6.0. pygments 2.7.2. pyparsing 2.4.7. pytz 2020.4. ruamel NA. scanpy 1.6.0. scipy 1.5.4. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. storemagic NA. tables 3.6.1. texttable 1.6.3. traitlets 5.0.5. typing_extensions NA. wcwidth 0.2.5. yaml 5.3.1. zc NA. -----. Python 3.8.4 (default, Jul 16 2020, 19:35:12) [GCC 9.3.0]. Linux-5.4.0-54-generic-x86_64-with-glibc2.29. 8 logical CPU cores, x86_64. -----. Session information updated at 2020-11-25 11:03. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1508
https://github.com/scverse/scanpy/issues/1508:200,integrability,version,version,200,"Saving plots results in a prefixed filename, regardless of sc.settings.figdir; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. As far as I can tell, `sc.pl.violin` always prepends the string ""violin"" to all save filed, regardless of `sc.settings.figdir`. This complicates programatically setting the filename for outputs. I've also confirmed this behaviour for `sc.pl.scatter`, and suspect it holds true for other `sc.pl` methods. As an example: I keep all results from my analysis in a `results/` directory, with each step having its own subdirectory. Currently, this doesn't seem possible. If I set `sc.settings.figdir = ./results`, then try to save to, say ""qcmetrics/total_counts.png"", the code fails as ""violinqcmetrics/total_counts.png"" does not exist. A partial work around is to set `sc.settings.figdir` every time I want to save in a different directory, but this feels quite clunky to me. And it will still result in all my files being prepended with ""violin"" (or ""scatter"", etc.), which I'd like to avoid. Is there any way to disable this prefix on save behaviour? ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.settings.figdir = ""./"". sc.pl.violin(adata, [""total_counts""], save=""results/test_plot.png""). ```. ```pytb. FileNotFoundError: [Errno 2] No such file or directory: 'violinresults/test_plot.png'. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.6.0. sinfo 0.3.1. -----. IPython 7.19.0. PIL 8.0.1. anndata 0.7.5. backcall 0.2.0. cffi 1.14.4. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. flufl NA. get_version 2.1. h5py 3.1.0. igraph 0.8.3. ipython_genutils 0.2.0. jedi 0.17.2. joblib 0.17.0. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.35.0rc3. matplotlib 3.3.3. mpl_toolkits NA. natsor",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1508
https://github.com/scverse/scanpy/issues/1508:718,integrability,sub,subdirectory,718,"Saving plots results in a prefixed filename, regardless of sc.settings.figdir; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. As far as I can tell, `sc.pl.violin` always prepends the string ""violin"" to all save filed, regardless of `sc.settings.figdir`. This complicates programatically setting the filename for outputs. I've also confirmed this behaviour for `sc.pl.scatter`, and suspect it holds true for other `sc.pl` methods. As an example: I keep all results from my analysis in a `results/` directory, with each step having its own subdirectory. Currently, this doesn't seem possible. If I set `sc.settings.figdir = ./results`, then try to save to, say ""qcmetrics/total_counts.png"", the code fails as ""violinqcmetrics/total_counts.png"" does not exist. A partial work around is to set `sc.settings.figdir` every time I want to save in a different directory, but this feels quite clunky to me. And it will still result in all my files being prepended with ""violin"" (or ""scatter"", etc.), which I'd like to avoid. Is there any way to disable this prefix on save behaviour? ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.settings.figdir = ""./"". sc.pl.violin(adata, [""total_counts""], save=""results/test_plot.png""). ```. ```pytb. FileNotFoundError: [Errno 2] No such file or directory: 'violinresults/test_plot.png'. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.6.0. sinfo 0.3.1. -----. IPython 7.19.0. PIL 8.0.1. anndata 0.7.5. backcall 0.2.0. cffi 1.14.4. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. flufl NA. get_version 2.1. h5py 3.1.0. igraph 0.8.3. ipython_genutils 0.2.0. jedi 0.17.2. joblib 0.17.0. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.35.0rc3. matplotlib 3.3.3. mpl_toolkits NA. natsor",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1508
https://github.com/scverse/scanpy/issues/1508:1547,integrability,Version,Versions,1547,"ter`, and suspect it holds true for other `sc.pl` methods. As an example: I keep all results from my analysis in a `results/` directory, with each step having its own subdirectory. Currently, this doesn't seem possible. If I set `sc.settings.figdir = ./results`, then try to save to, say ""qcmetrics/total_counts.png"", the code fails as ""violinqcmetrics/total_counts.png"" does not exist. A partial work around is to set `sc.settings.figdir` every time I want to save in a different directory, but this feels quite clunky to me. And it will still result in all my files being prepended with ""violin"" (or ""scatter"", etc.), which I'd like to avoid. Is there any way to disable this prefix on save behaviour? ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.settings.figdir = ""./"". sc.pl.violin(adata, [""total_counts""], save=""results/test_plot.png""). ```. ```pytb. FileNotFoundError: [Errno 2] No such file or directory: 'violinresults/test_plot.png'. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.6.0. sinfo 0.3.1. -----. IPython 7.19.0. PIL 8.0.1. anndata 0.7.5. backcall 0.2.0. cffi 1.14.4. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. flufl NA. get_version 2.1. h5py 3.1.0. igraph 0.8.3. ipython_genutils 0.2.0. jedi 0.17.2. joblib 0.17.0. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.35.0rc3. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.1.0. numba 0.51.2. numexpr 2.7.1. numpy 1.19.4. packaging 20.4. pandas 1.1.4. parso 0.7.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.8. ptyprocess 0.6.0. pygments 2.7.2. pyparsing 2.4.7. pytz 2020.4. ruamel NA. scanpy 1.6.0. scipy 1.5.4. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. storemagic NA. tables 3.6.1. texttable 1.6.3. traitlets 5.0.5. typing_extensions NA. wcwidth 0.2.5. yaml 5.3.1. zc NA. -----. Python 3.8.4 (default, Jul 16 2020, 19:35:12) [GCC 9.3.0]. Linux-5.4.0-54-generic-x86_64-with-",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1508
https://github.com/scverse/scanpy/issues/1508:200,modifiability,version,version,200,"Saving plots results in a prefixed filename, regardless of sc.settings.figdir; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. As far as I can tell, `sc.pl.violin` always prepends the string ""violin"" to all save filed, regardless of `sc.settings.figdir`. This complicates programatically setting the filename for outputs. I've also confirmed this behaviour for `sc.pl.scatter`, and suspect it holds true for other `sc.pl` methods. As an example: I keep all results from my analysis in a `results/` directory, with each step having its own subdirectory. Currently, this doesn't seem possible. If I set `sc.settings.figdir = ./results`, then try to save to, say ""qcmetrics/total_counts.png"", the code fails as ""violinqcmetrics/total_counts.png"" does not exist. A partial work around is to set `sc.settings.figdir` every time I want to save in a different directory, but this feels quite clunky to me. And it will still result in all my files being prepended with ""violin"" (or ""scatter"", etc.), which I'd like to avoid. Is there any way to disable this prefix on save behaviour? ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.settings.figdir = ""./"". sc.pl.violin(adata, [""total_counts""], save=""results/test_plot.png""). ```. ```pytb. FileNotFoundError: [Errno 2] No such file or directory: 'violinresults/test_plot.png'. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.6.0. sinfo 0.3.1. -----. IPython 7.19.0. PIL 8.0.1. anndata 0.7.5. backcall 0.2.0. cffi 1.14.4. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. flufl NA. get_version 2.1. h5py 3.1.0. igraph 0.8.3. ipython_genutils 0.2.0. jedi 0.17.2. joblib 0.17.0. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.35.0rc3. matplotlib 3.3.3. mpl_toolkits NA. natsor",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1508
https://github.com/scverse/scanpy/issues/1508:1547,modifiability,Version,Versions,1547,"ter`, and suspect it holds true for other `sc.pl` methods. As an example: I keep all results from my analysis in a `results/` directory, with each step having its own subdirectory. Currently, this doesn't seem possible. If I set `sc.settings.figdir = ./results`, then try to save to, say ""qcmetrics/total_counts.png"", the code fails as ""violinqcmetrics/total_counts.png"" does not exist. A partial work around is to set `sc.settings.figdir` every time I want to save in a different directory, but this feels quite clunky to me. And it will still result in all my files being prepended with ""violin"" (or ""scatter"", etc.), which I'd like to avoid. Is there any way to disable this prefix on save behaviour? ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.settings.figdir = ""./"". sc.pl.violin(adata, [""total_counts""], save=""results/test_plot.png""). ```. ```pytb. FileNotFoundError: [Errno 2] No such file or directory: 'violinresults/test_plot.png'. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.6.0. sinfo 0.3.1. -----. IPython 7.19.0. PIL 8.0.1. anndata 0.7.5. backcall 0.2.0. cffi 1.14.4. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. flufl NA. get_version 2.1. h5py 3.1.0. igraph 0.8.3. ipython_genutils 0.2.0. jedi 0.17.2. joblib 0.17.0. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.35.0rc3. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.1.0. numba 0.51.2. numexpr 2.7.1. numpy 1.19.4. packaging 20.4. pandas 1.1.4. parso 0.7.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.8. ptyprocess 0.6.0. pygments 2.7.2. pyparsing 2.4.7. pytz 2020.4. ruamel NA. scanpy 1.6.0. scipy 1.5.4. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. storemagic NA. tables 3.6.1. texttable 1.6.3. traitlets 5.0.5. typing_extensions NA. wcwidth 0.2.5. yaml 5.3.1. zc NA. -----. Python 3.8.4 (default, Jul 16 2020, 19:35:12) [GCC 9.3.0]. Linux-5.4.0-54-generic-x86_64-with-",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1508
https://github.com/scverse/scanpy/issues/1508:1761,modifiability,deco,decorator,1761,"is in a `results/` directory, with each step having its own subdirectory. Currently, this doesn't seem possible. If I set `sc.settings.figdir = ./results`, then try to save to, say ""qcmetrics/total_counts.png"", the code fails as ""violinqcmetrics/total_counts.png"" does not exist. A partial work around is to set `sc.settings.figdir` every time I want to save in a different directory, but this feels quite clunky to me. And it will still result in all my files being prepended with ""violin"" (or ""scatter"", etc.), which I'd like to avoid. Is there any way to disable this prefix on save behaviour? ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.settings.figdir = ""./"". sc.pl.violin(adata, [""total_counts""], save=""results/test_plot.png""). ```. ```pytb. FileNotFoundError: [Errno 2] No such file or directory: 'violinresults/test_plot.png'. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.6.0. sinfo 0.3.1. -----. IPython 7.19.0. PIL 8.0.1. anndata 0.7.5. backcall 0.2.0. cffi 1.14.4. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. flufl NA. get_version 2.1. h5py 3.1.0. igraph 0.8.3. ipython_genutils 0.2.0. jedi 0.17.2. joblib 0.17.0. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.35.0rc3. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.1.0. numba 0.51.2. numexpr 2.7.1. numpy 1.19.4. packaging 20.4. pandas 1.1.4. parso 0.7.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.8. ptyprocess 0.6.0. pygments 2.7.2. pyparsing 2.4.7. pytz 2020.4. ruamel NA. scanpy 1.6.0. scipy 1.5.4. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. storemagic NA. tables 3.6.1. texttable 1.6.3. traitlets 5.0.5. typing_extensions NA. wcwidth 0.2.5. yaml 5.3.1. zc NA. -----. Python 3.8.4 (default, Jul 16 2020, 19:35:12) [GCC 9.3.0]. Linux-5.4.0-54-generic-x86_64-with-glibc2.29. 8 logical CPU cores, x86_64. -----. Session information updated at 2020-11-25 11:03. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1508
https://github.com/scverse/scanpy/issues/1508:2052,modifiability,pac,packaging,2052,"is in a `results/` directory, with each step having its own subdirectory. Currently, this doesn't seem possible. If I set `sc.settings.figdir = ./results`, then try to save to, say ""qcmetrics/total_counts.png"", the code fails as ""violinqcmetrics/total_counts.png"" does not exist. A partial work around is to set `sc.settings.figdir` every time I want to save in a different directory, but this feels quite clunky to me. And it will still result in all my files being prepended with ""violin"" (or ""scatter"", etc.), which I'd like to avoid. Is there any way to disable this prefix on save behaviour? ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.settings.figdir = ""./"". sc.pl.violin(adata, [""total_counts""], save=""results/test_plot.png""). ```. ```pytb. FileNotFoundError: [Errno 2] No such file or directory: 'violinresults/test_plot.png'. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.6.0. sinfo 0.3.1. -----. IPython 7.19.0. PIL 8.0.1. anndata 0.7.5. backcall 0.2.0. cffi 1.14.4. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. flufl NA. get_version 2.1. h5py 3.1.0. igraph 0.8.3. ipython_genutils 0.2.0. jedi 0.17.2. joblib 0.17.0. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.35.0rc3. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.1.0. numba 0.51.2. numexpr 2.7.1. numpy 1.19.4. packaging 20.4. pandas 1.1.4. parso 0.7.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.8. ptyprocess 0.6.0. pygments 2.7.2. pyparsing 2.4.7. pytz 2020.4. ruamel NA. scanpy 1.6.0. scipy 1.5.4. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. storemagic NA. tables 3.6.1. texttable 1.6.3. traitlets 5.0.5. typing_extensions NA. wcwidth 0.2.5. yaml 5.3.1. zc NA. -----. Python 3.8.4 (default, Jul 16 2020, 19:35:12) [GCC 9.3.0]. Linux-5.4.0-54-generic-x86_64-with-glibc2.29. 8 logical CPU cores, x86_64. -----. Session information updated at 2020-11-25 11:03. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1508
https://github.com/scverse/scanpy/issues/1508:997,performance,time,time,997,"Saving plots results in a prefixed filename, regardless of sc.settings.figdir; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. As far as I can tell, `sc.pl.violin` always prepends the string ""violin"" to all save filed, regardless of `sc.settings.figdir`. This complicates programatically setting the filename for outputs. I've also confirmed this behaviour for `sc.pl.scatter`, and suspect it holds true for other `sc.pl` methods. As an example: I keep all results from my analysis in a `results/` directory, with each step having its own subdirectory. Currently, this doesn't seem possible. If I set `sc.settings.figdir = ./results`, then try to save to, say ""qcmetrics/total_counts.png"", the code fails as ""violinqcmetrics/total_counts.png"" does not exist. A partial work around is to set `sc.settings.figdir` every time I want to save in a different directory, but this feels quite clunky to me. And it will still result in all my files being prepended with ""violin"" (or ""scatter"", etc.), which I'd like to avoid. Is there any way to disable this prefix on save behaviour? ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.settings.figdir = ""./"". sc.pl.violin(adata, [""total_counts""], save=""results/test_plot.png""). ```. ```pytb. FileNotFoundError: [Errno 2] No such file or directory: 'violinresults/test_plot.png'. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.6.0. sinfo 0.3.1. -----. IPython 7.19.0. PIL 8.0.1. anndata 0.7.5. backcall 0.2.0. cffi 1.14.4. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. flufl NA. get_version 2.1. h5py 3.1.0. igraph 0.8.3. ipython_genutils 0.2.0. jedi 0.17.2. joblib 0.17.0. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.35.0rc3. matplotlib 3.3.3. mpl_toolkits NA. natsor",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1508
https://github.com/scverse/scanpy/issues/1508:2572,performance,CPU,CPU,2572,"is in a `results/` directory, with each step having its own subdirectory. Currently, this doesn't seem possible. If I set `sc.settings.figdir = ./results`, then try to save to, say ""qcmetrics/total_counts.png"", the code fails as ""violinqcmetrics/total_counts.png"" does not exist. A partial work around is to set `sc.settings.figdir` every time I want to save in a different directory, but this feels quite clunky to me. And it will still result in all my files being prepended with ""violin"" (or ""scatter"", etc.), which I'd like to avoid. Is there any way to disable this prefix on save behaviour? ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.settings.figdir = ""./"". sc.pl.violin(adata, [""total_counts""], save=""results/test_plot.png""). ```. ```pytb. FileNotFoundError: [Errno 2] No such file or directory: 'violinresults/test_plot.png'. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.6.0. sinfo 0.3.1. -----. IPython 7.19.0. PIL 8.0.1. anndata 0.7.5. backcall 0.2.0. cffi 1.14.4. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. flufl NA. get_version 2.1. h5py 3.1.0. igraph 0.8.3. ipython_genutils 0.2.0. jedi 0.17.2. joblib 0.17.0. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.35.0rc3. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.1.0. numba 0.51.2. numexpr 2.7.1. numpy 1.19.4. packaging 20.4. pandas 1.1.4. parso 0.7.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.8. ptyprocess 0.6.0. pygments 2.7.2. pyparsing 2.4.7. pytz 2020.4. ruamel NA. scanpy 1.6.0. scipy 1.5.4. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. storemagic NA. tables 3.6.1. texttable 1.6.3. traitlets 5.0.5. typing_extensions NA. wcwidth 0.2.5. yaml 5.3.1. zc NA. -----. Python 3.8.4 (default, Jul 16 2020, 19:35:12) [GCC 9.3.0]. Linux-5.4.0-54-generic-x86_64-with-glibc2.29. 8 logical CPU cores, x86_64. -----. Session information updated at 2020-11-25 11:03. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1508
https://github.com/scverse/scanpy/issues/1508:748,reliability,doe,doesn,748,"Saving plots results in a prefixed filename, regardless of sc.settings.figdir; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. As far as I can tell, `sc.pl.violin` always prepends the string ""violin"" to all save filed, regardless of `sc.settings.figdir`. This complicates programatically setting the filename for outputs. I've also confirmed this behaviour for `sc.pl.scatter`, and suspect it holds true for other `sc.pl` methods. As an example: I keep all results from my analysis in a `results/` directory, with each step having its own subdirectory. Currently, this doesn't seem possible. If I set `sc.settings.figdir = ./results`, then try to save to, say ""qcmetrics/total_counts.png"", the code fails as ""violinqcmetrics/total_counts.png"" does not exist. A partial work around is to set `sc.settings.figdir` every time I want to save in a different directory, but this feels quite clunky to me. And it will still result in all my files being prepended with ""violin"" (or ""scatter"", etc.), which I'd like to avoid. Is there any way to disable this prefix on save behaviour? ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.settings.figdir = ""./"". sc.pl.violin(adata, [""total_counts""], save=""results/test_plot.png""). ```. ```pytb. FileNotFoundError: [Errno 2] No such file or directory: 'violinresults/test_plot.png'. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.6.0. sinfo 0.3.1. -----. IPython 7.19.0. PIL 8.0.1. anndata 0.7.5. backcall 0.2.0. cffi 1.14.4. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. flufl NA. get_version 2.1. h5py 3.1.0. igraph 0.8.3. ipython_genutils 0.2.0. jedi 0.17.2. joblib 0.17.0. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.35.0rc3. matplotlib 3.3.3. mpl_toolkits NA. natsor",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1508
https://github.com/scverse/scanpy/issues/1508:878,reliability,fail,fails,878,"Saving plots results in a prefixed filename, regardless of sc.settings.figdir; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. As far as I can tell, `sc.pl.violin` always prepends the string ""violin"" to all save filed, regardless of `sc.settings.figdir`. This complicates programatically setting the filename for outputs. I've also confirmed this behaviour for `sc.pl.scatter`, and suspect it holds true for other `sc.pl` methods. As an example: I keep all results from my analysis in a `results/` directory, with each step having its own subdirectory. Currently, this doesn't seem possible. If I set `sc.settings.figdir = ./results`, then try to save to, say ""qcmetrics/total_counts.png"", the code fails as ""violinqcmetrics/total_counts.png"" does not exist. A partial work around is to set `sc.settings.figdir` every time I want to save in a different directory, but this feels quite clunky to me. And it will still result in all my files being prepended with ""violin"" (or ""scatter"", etc.), which I'd like to avoid. Is there any way to disable this prefix on save behaviour? ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.settings.figdir = ""./"". sc.pl.violin(adata, [""total_counts""], save=""results/test_plot.png""). ```. ```pytb. FileNotFoundError: [Errno 2] No such file or directory: 'violinresults/test_plot.png'. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.6.0. sinfo 0.3.1. -----. IPython 7.19.0. PIL 8.0.1. anndata 0.7.5. backcall 0.2.0. cffi 1.14.4. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. flufl NA. get_version 2.1. h5py 3.1.0. igraph 0.8.3. ipython_genutils 0.2.0. jedi 0.17.2. joblib 0.17.0. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.35.0rc3. matplotlib 3.3.3. mpl_toolkits NA. natsor",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1508
https://github.com/scverse/scanpy/issues/1508:922,reliability,doe,does,922,"Saving plots results in a prefixed filename, regardless of sc.settings.figdir; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. As far as I can tell, `sc.pl.violin` always prepends the string ""violin"" to all save filed, regardless of `sc.settings.figdir`. This complicates programatically setting the filename for outputs. I've also confirmed this behaviour for `sc.pl.scatter`, and suspect it holds true for other `sc.pl` methods. As an example: I keep all results from my analysis in a `results/` directory, with each step having its own subdirectory. Currently, this doesn't seem possible. If I set `sc.settings.figdir = ./results`, then try to save to, say ""qcmetrics/total_counts.png"", the code fails as ""violinqcmetrics/total_counts.png"" does not exist. A partial work around is to set `sc.settings.figdir` every time I want to save in a different directory, but this feels quite clunky to me. And it will still result in all my files being prepended with ""violin"" (or ""scatter"", etc.), which I'd like to avoid. Is there any way to disable this prefix on save behaviour? ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.settings.figdir = ""./"". sc.pl.violin(adata, [""total_counts""], save=""results/test_plot.png""). ```. ```pytb. FileNotFoundError: [Errno 2] No such file or directory: 'violinresults/test_plot.png'. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.6.0. sinfo 0.3.1. -----. IPython 7.19.0. PIL 8.0.1. anndata 0.7.5. backcall 0.2.0. cffi 1.14.4. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. flufl NA. get_version 2.1. h5py 3.1.0. igraph 0.8.3. ipython_genutils 0.2.0. jedi 0.17.2. joblib 0.17.0. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.35.0rc3. matplotlib 3.3.3. mpl_toolkits NA. natsor",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1508
https://github.com/scverse/scanpy/issues/1508:439,safety,compl,complicates,439,"Saving plots results in a prefixed filename, regardless of sc.settings.figdir; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. As far as I can tell, `sc.pl.violin` always prepends the string ""violin"" to all save filed, regardless of `sc.settings.figdir`. This complicates programatically setting the filename for outputs. I've also confirmed this behaviour for `sc.pl.scatter`, and suspect it holds true for other `sc.pl` methods. As an example: I keep all results from my analysis in a `results/` directory, with each step having its own subdirectory. Currently, this doesn't seem possible. If I set `sc.settings.figdir = ./results`, then try to save to, say ""qcmetrics/total_counts.png"", the code fails as ""violinqcmetrics/total_counts.png"" does not exist. A partial work around is to set `sc.settings.figdir` every time I want to save in a different directory, but this feels quite clunky to me. And it will still result in all my files being prepended with ""violin"" (or ""scatter"", etc.), which I'd like to avoid. Is there any way to disable this prefix on save behaviour? ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.settings.figdir = ""./"". sc.pl.violin(adata, [""total_counts""], save=""results/test_plot.png""). ```. ```pytb. FileNotFoundError: [Errno 2] No such file or directory: 'violinresults/test_plot.png'. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.6.0. sinfo 0.3.1. -----. IPython 7.19.0. PIL 8.0.1. anndata 0.7.5. backcall 0.2.0. cffi 1.14.4. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. flufl NA. get_version 2.1. h5py 3.1.0. igraph 0.8.3. ipython_genutils 0.2.0. jedi 0.17.2. joblib 0.17.0. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.35.0rc3. matplotlib 3.3.3. mpl_toolkits NA. natsor",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1508
https://github.com/scverse/scanpy/issues/1508:1189,safety,avoid,avoid,1189," latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. As far as I can tell, `sc.pl.violin` always prepends the string ""violin"" to all save filed, regardless of `sc.settings.figdir`. This complicates programatically setting the filename for outputs. I've also confirmed this behaviour for `sc.pl.scatter`, and suspect it holds true for other `sc.pl` methods. As an example: I keep all results from my analysis in a `results/` directory, with each step having its own subdirectory. Currently, this doesn't seem possible. If I set `sc.settings.figdir = ./results`, then try to save to, say ""qcmetrics/total_counts.png"", the code fails as ""violinqcmetrics/total_counts.png"" does not exist. A partial work around is to set `sc.settings.figdir` every time I want to save in a different directory, but this feels quite clunky to me. And it will still result in all my files being prepended with ""violin"" (or ""scatter"", etc.), which I'd like to avoid. Is there any way to disable this prefix on save behaviour? ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.settings.figdir = ""./"". sc.pl.violin(adata, [""total_counts""], save=""results/test_plot.png""). ```. ```pytb. FileNotFoundError: [Errno 2] No such file or directory: 'violinresults/test_plot.png'. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.6.0. sinfo 0.3.1. -----. IPython 7.19.0. PIL 8.0.1. anndata 0.7.5. backcall 0.2.0. cffi 1.14.4. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. flufl NA. get_version 2.1. h5py 3.1.0. igraph 0.8.3. ipython_genutils 0.2.0. jedi 0.17.2. joblib 0.17.0. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.35.0rc3. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.1.0. numba 0.51.2. numexpr 2.7.1. numpy 1.19.4. packaging 20.4. pandas 1.1.4. parso 0.7.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.8. ptyprocess 0.6.0. pygme",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1508
https://github.com/scverse/scanpy/issues/1508:2564,safety,log,logical,2564,"is in a `results/` directory, with each step having its own subdirectory. Currently, this doesn't seem possible. If I set `sc.settings.figdir = ./results`, then try to save to, say ""qcmetrics/total_counts.png"", the code fails as ""violinqcmetrics/total_counts.png"" does not exist. A partial work around is to set `sc.settings.figdir` every time I want to save in a different directory, but this feels quite clunky to me. And it will still result in all my files being prepended with ""violin"" (or ""scatter"", etc.), which I'd like to avoid. Is there any way to disable this prefix on save behaviour? ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.settings.figdir = ""./"". sc.pl.violin(adata, [""total_counts""], save=""results/test_plot.png""). ```. ```pytb. FileNotFoundError: [Errno 2] No such file or directory: 'violinresults/test_plot.png'. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.6.0. sinfo 0.3.1. -----. IPython 7.19.0. PIL 8.0.1. anndata 0.7.5. backcall 0.2.0. cffi 1.14.4. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. flufl NA. get_version 2.1. h5py 3.1.0. igraph 0.8.3. ipython_genutils 0.2.0. jedi 0.17.2. joblib 0.17.0. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.35.0rc3. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.1.0. numba 0.51.2. numexpr 2.7.1. numpy 1.19.4. packaging 20.4. pandas 1.1.4. parso 0.7.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.8. ptyprocess 0.6.0. pygments 2.7.2. pyparsing 2.4.7. pytz 2020.4. ruamel NA. scanpy 1.6.0. scipy 1.5.4. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. storemagic NA. tables 3.6.1. texttable 1.6.3. traitlets 5.0.5. typing_extensions NA. wcwidth 0.2.5. yaml 5.3.1. zc NA. -----. Python 3.8.4 (default, Jul 16 2020, 19:35:12) [GCC 9.3.0]. Linux-5.4.0-54-generic-x86_64-with-glibc2.29. 8 logical CPU cores, x86_64. -----. Session information updated at 2020-11-25 11:03. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1508
https://github.com/scverse/scanpy/issues/1508:2618,safety,updat,updated,2618,"is in a `results/` directory, with each step having its own subdirectory. Currently, this doesn't seem possible. If I set `sc.settings.figdir = ./results`, then try to save to, say ""qcmetrics/total_counts.png"", the code fails as ""violinqcmetrics/total_counts.png"" does not exist. A partial work around is to set `sc.settings.figdir` every time I want to save in a different directory, but this feels quite clunky to me. And it will still result in all my files being prepended with ""violin"" (or ""scatter"", etc.), which I'd like to avoid. Is there any way to disable this prefix on save behaviour? ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.settings.figdir = ""./"". sc.pl.violin(adata, [""total_counts""], save=""results/test_plot.png""). ```. ```pytb. FileNotFoundError: [Errno 2] No such file or directory: 'violinresults/test_plot.png'. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.6.0. sinfo 0.3.1. -----. IPython 7.19.0. PIL 8.0.1. anndata 0.7.5. backcall 0.2.0. cffi 1.14.4. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. flufl NA. get_version 2.1. h5py 3.1.0. igraph 0.8.3. ipython_genutils 0.2.0. jedi 0.17.2. joblib 0.17.0. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.35.0rc3. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.1.0. numba 0.51.2. numexpr 2.7.1. numpy 1.19.4. packaging 20.4. pandas 1.1.4. parso 0.7.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.8. ptyprocess 0.6.0. pygments 2.7.2. pyparsing 2.4.7. pytz 2020.4. ruamel NA. scanpy 1.6.0. scipy 1.5.4. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. storemagic NA. tables 3.6.1. texttable 1.6.3. traitlets 5.0.5. typing_extensions NA. wcwidth 0.2.5. yaml 5.3.1. zc NA. -----. Python 3.8.4 (default, Jul 16 2020, 19:35:12) [GCC 9.3.0]. Linux-5.4.0-54-generic-x86_64-with-glibc2.29. 8 logical CPU cores, x86_64. -----. Session information updated at 2020-11-25 11:03. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1508
https://github.com/scverse/scanpy/issues/1508:439,security,compl,complicates,439,"Saving plots results in a prefixed filename, regardless of sc.settings.figdir; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. As far as I can tell, `sc.pl.violin` always prepends the string ""violin"" to all save filed, regardless of `sc.settings.figdir`. This complicates programatically setting the filename for outputs. I've also confirmed this behaviour for `sc.pl.scatter`, and suspect it holds true for other `sc.pl` methods. As an example: I keep all results from my analysis in a `results/` directory, with each step having its own subdirectory. Currently, this doesn't seem possible. If I set `sc.settings.figdir = ./results`, then try to save to, say ""qcmetrics/total_counts.png"", the code fails as ""violinqcmetrics/total_counts.png"" does not exist. A partial work around is to set `sc.settings.figdir` every time I want to save in a different directory, but this feels quite clunky to me. And it will still result in all my files being prepended with ""violin"" (or ""scatter"", etc.), which I'd like to avoid. Is there any way to disable this prefix on save behaviour? ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.settings.figdir = ""./"". sc.pl.violin(adata, [""total_counts""], save=""results/test_plot.png""). ```. ```pytb. FileNotFoundError: [Errno 2] No such file or directory: 'violinresults/test_plot.png'. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.6.0. sinfo 0.3.1. -----. IPython 7.19.0. PIL 8.0.1. anndata 0.7.5. backcall 0.2.0. cffi 1.14.4. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. flufl NA. get_version 2.1. h5py 3.1.0. igraph 0.8.3. ipython_genutils 0.2.0. jedi 0.17.2. joblib 0.17.0. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.35.0rc3. matplotlib 3.3.3. mpl_toolkits NA. natsor",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1508
https://github.com/scverse/scanpy/issues/1508:2564,security,log,logical,2564,"is in a `results/` directory, with each step having its own subdirectory. Currently, this doesn't seem possible. If I set `sc.settings.figdir = ./results`, then try to save to, say ""qcmetrics/total_counts.png"", the code fails as ""violinqcmetrics/total_counts.png"" does not exist. A partial work around is to set `sc.settings.figdir` every time I want to save in a different directory, but this feels quite clunky to me. And it will still result in all my files being prepended with ""violin"" (or ""scatter"", etc.), which I'd like to avoid. Is there any way to disable this prefix on save behaviour? ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.settings.figdir = ""./"". sc.pl.violin(adata, [""total_counts""], save=""results/test_plot.png""). ```. ```pytb. FileNotFoundError: [Errno 2] No such file or directory: 'violinresults/test_plot.png'. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.6.0. sinfo 0.3.1. -----. IPython 7.19.0. PIL 8.0.1. anndata 0.7.5. backcall 0.2.0. cffi 1.14.4. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. flufl NA. get_version 2.1. h5py 3.1.0. igraph 0.8.3. ipython_genutils 0.2.0. jedi 0.17.2. joblib 0.17.0. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.35.0rc3. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.1.0. numba 0.51.2. numexpr 2.7.1. numpy 1.19.4. packaging 20.4. pandas 1.1.4. parso 0.7.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.8. ptyprocess 0.6.0. pygments 2.7.2. pyparsing 2.4.7. pytz 2020.4. ruamel NA. scanpy 1.6.0. scipy 1.5.4. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. storemagic NA. tables 3.6.1. texttable 1.6.3. traitlets 5.0.5. typing_extensions NA. wcwidth 0.2.5. yaml 5.3.1. zc NA. -----. Python 3.8.4 (default, Jul 16 2020, 19:35:12) [GCC 9.3.0]. Linux-5.4.0-54-generic-x86_64-with-glibc2.29. 8 logical CPU cores, x86_64. -----. Session information updated at 2020-11-25 11:03. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1508
https://github.com/scverse/scanpy/issues/1508:2598,security,Session,Session,2598,"is in a `results/` directory, with each step having its own subdirectory. Currently, this doesn't seem possible. If I set `sc.settings.figdir = ./results`, then try to save to, say ""qcmetrics/total_counts.png"", the code fails as ""violinqcmetrics/total_counts.png"" does not exist. A partial work around is to set `sc.settings.figdir` every time I want to save in a different directory, but this feels quite clunky to me. And it will still result in all my files being prepended with ""violin"" (or ""scatter"", etc.), which I'd like to avoid. Is there any way to disable this prefix on save behaviour? ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.settings.figdir = ""./"". sc.pl.violin(adata, [""total_counts""], save=""results/test_plot.png""). ```. ```pytb. FileNotFoundError: [Errno 2] No such file or directory: 'violinresults/test_plot.png'. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.6.0. sinfo 0.3.1. -----. IPython 7.19.0. PIL 8.0.1. anndata 0.7.5. backcall 0.2.0. cffi 1.14.4. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. flufl NA. get_version 2.1. h5py 3.1.0. igraph 0.8.3. ipython_genutils 0.2.0. jedi 0.17.2. joblib 0.17.0. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.35.0rc3. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.1.0. numba 0.51.2. numexpr 2.7.1. numpy 1.19.4. packaging 20.4. pandas 1.1.4. parso 0.7.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.8. ptyprocess 0.6.0. pygments 2.7.2. pyparsing 2.4.7. pytz 2020.4. ruamel NA. scanpy 1.6.0. scipy 1.5.4. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. storemagic NA. tables 3.6.1. texttable 1.6.3. traitlets 5.0.5. typing_extensions NA. wcwidth 0.2.5. yaml 5.3.1. zc NA. -----. Python 3.8.4 (default, Jul 16 2020, 19:35:12) [GCC 9.3.0]. Linux-5.4.0-54-generic-x86_64-with-glibc2.29. 8 logical CPU cores, x86_64. -----. Session information updated at 2020-11-25 11:03. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1508
https://github.com/scverse/scanpy/issues/1508:2618,security,updat,updated,2618,"is in a `results/` directory, with each step having its own subdirectory. Currently, this doesn't seem possible. If I set `sc.settings.figdir = ./results`, then try to save to, say ""qcmetrics/total_counts.png"", the code fails as ""violinqcmetrics/total_counts.png"" does not exist. A partial work around is to set `sc.settings.figdir` every time I want to save in a different directory, but this feels quite clunky to me. And it will still result in all my files being prepended with ""violin"" (or ""scatter"", etc.), which I'd like to avoid. Is there any way to disable this prefix on save behaviour? ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.settings.figdir = ""./"". sc.pl.violin(adata, [""total_counts""], save=""results/test_plot.png""). ```. ```pytb. FileNotFoundError: [Errno 2] No such file or directory: 'violinresults/test_plot.png'. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.6.0. sinfo 0.3.1. -----. IPython 7.19.0. PIL 8.0.1. anndata 0.7.5. backcall 0.2.0. cffi 1.14.4. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. flufl NA. get_version 2.1. h5py 3.1.0. igraph 0.8.3. ipython_genutils 0.2.0. jedi 0.17.2. joblib 0.17.0. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.35.0rc3. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.1.0. numba 0.51.2. numexpr 2.7.1. numpy 1.19.4. packaging 20.4. pandas 1.1.4. parso 0.7.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.8. ptyprocess 0.6.0. pygments 2.7.2. pyparsing 2.4.7. pytz 2020.4. ruamel NA. scanpy 1.6.0. scipy 1.5.4. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. storemagic NA. tables 3.6.1. texttable 1.6.3. traitlets 5.0.5. typing_extensions NA. wcwidth 0.2.5. yaml 5.3.1. zc NA. -----. Python 3.8.4 (default, Jul 16 2020, 19:35:12) [GCC 9.3.0]. Linux-5.4.0-54-generic-x86_64-with-glibc2.29. 8 logical CPU cores, x86_64. -----. Session information updated at 2020-11-25 11:03. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1508
https://github.com/scverse/scanpy/issues/1508:2564,testability,log,logical,2564,"is in a `results/` directory, with each step having its own subdirectory. Currently, this doesn't seem possible. If I set `sc.settings.figdir = ./results`, then try to save to, say ""qcmetrics/total_counts.png"", the code fails as ""violinqcmetrics/total_counts.png"" does not exist. A partial work around is to set `sc.settings.figdir` every time I want to save in a different directory, but this feels quite clunky to me. And it will still result in all my files being prepended with ""violin"" (or ""scatter"", etc.), which I'd like to avoid. Is there any way to disable this prefix on save behaviour? ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.settings.figdir = ""./"". sc.pl.violin(adata, [""total_counts""], save=""results/test_plot.png""). ```. ```pytb. FileNotFoundError: [Errno 2] No such file or directory: 'violinresults/test_plot.png'. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.6.0. sinfo 0.3.1. -----. IPython 7.19.0. PIL 8.0.1. anndata 0.7.5. backcall 0.2.0. cffi 1.14.4. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. flufl NA. get_version 2.1. h5py 3.1.0. igraph 0.8.3. ipython_genutils 0.2.0. jedi 0.17.2. joblib 0.17.0. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.35.0rc3. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.1.0. numba 0.51.2. numexpr 2.7.1. numpy 1.19.4. packaging 20.4. pandas 1.1.4. parso 0.7.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.8. ptyprocess 0.6.0. pygments 2.7.2. pyparsing 2.4.7. pytz 2020.4. ruamel NA. scanpy 1.6.0. scipy 1.5.4. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. storemagic NA. tables 3.6.1. texttable 1.6.3. traitlets 5.0.5. typing_extensions NA. wcwidth 0.2.5. yaml 5.3.1. zc NA. -----. Python 3.8.4 (default, Jul 16 2020, 19:35:12) [GCC 9.3.0]. Linux-5.4.0-54-generic-x86_64-with-glibc2.29. 8 logical CPU cores, x86_64. -----. Session information updated at 2020-11-25 11:03. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1508
https://github.com/scverse/scanpy/issues/1508:160,usability,confirm,confirmed,160,"Saving plots results in a prefixed filename, regardless of sc.settings.figdir; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. As far as I can tell, `sc.pl.violin` always prepends the string ""violin"" to all save filed, regardless of `sc.settings.figdir`. This complicates programatically setting the filename for outputs. I've also confirmed this behaviour for `sc.pl.scatter`, and suspect it holds true for other `sc.pl` methods. As an example: I keep all results from my analysis in a `results/` directory, with each step having its own subdirectory. Currently, this doesn't seem possible. If I set `sc.settings.figdir = ./results`, then try to save to, say ""qcmetrics/total_counts.png"", the code fails as ""violinqcmetrics/total_counts.png"" does not exist. A partial work around is to set `sc.settings.figdir` every time I want to save in a different directory, but this feels quite clunky to me. And it will still result in all my files being prepended with ""violin"" (or ""scatter"", etc.), which I'd like to avoid. Is there any way to disable this prefix on save behaviour? ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.settings.figdir = ""./"". sc.pl.violin(adata, [""total_counts""], save=""results/test_plot.png""). ```. ```pytb. FileNotFoundError: [Errno 2] No such file or directory: 'violinresults/test_plot.png'. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.6.0. sinfo 0.3.1. -----. IPython 7.19.0. PIL 8.0.1. anndata 0.7.5. backcall 0.2.0. cffi 1.14.4. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. flufl NA. get_version 2.1. h5py 3.1.0. igraph 0.8.3. ipython_genutils 0.2.0. jedi 0.17.2. joblib 0.17.0. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.35.0rc3. matplotlib 3.3.3. mpl_toolkits NA. natsor",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1508
https://github.com/scverse/scanpy/issues/1508:243,usability,confirm,confirmed,243,"Saving plots results in a prefixed filename, regardless of sc.settings.figdir; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. As far as I can tell, `sc.pl.violin` always prepends the string ""violin"" to all save filed, regardless of `sc.settings.figdir`. This complicates programatically setting the filename for outputs. I've also confirmed this behaviour for `sc.pl.scatter`, and suspect it holds true for other `sc.pl` methods. As an example: I keep all results from my analysis in a `results/` directory, with each step having its own subdirectory. Currently, this doesn't seem possible. If I set `sc.settings.figdir = ./results`, then try to save to, say ""qcmetrics/total_counts.png"", the code fails as ""violinqcmetrics/total_counts.png"" does not exist. A partial work around is to set `sc.settings.figdir` every time I want to save in a different directory, but this feels quite clunky to me. And it will still result in all my files being prepended with ""violin"" (or ""scatter"", etc.), which I'd like to avoid. Is there any way to disable this prefix on save behaviour? ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.settings.figdir = ""./"". sc.pl.violin(adata, [""total_counts""], save=""results/test_plot.png""). ```. ```pytb. FileNotFoundError: [Errno 2] No such file or directory: 'violinresults/test_plot.png'. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.6.0. sinfo 0.3.1. -----. IPython 7.19.0. PIL 8.0.1. anndata 0.7.5. backcall 0.2.0. cffi 1.14.4. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. flufl NA. get_version 2.1. h5py 3.1.0. igraph 0.8.3. ipython_genutils 0.2.0. jedi 0.17.2. joblib 0.17.0. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.35.0rc3. matplotlib 3.3.3. mpl_toolkits NA. natsor",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1508
https://github.com/scverse/scanpy/issues/1508:511,usability,confirm,confirmed,511,"Saving plots results in a prefixed filename, regardless of sc.settings.figdir; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. As far as I can tell, `sc.pl.violin` always prepends the string ""violin"" to all save filed, regardless of `sc.settings.figdir`. This complicates programatically setting the filename for outputs. I've also confirmed this behaviour for `sc.pl.scatter`, and suspect it holds true for other `sc.pl` methods. As an example: I keep all results from my analysis in a `results/` directory, with each step having its own subdirectory. Currently, this doesn't seem possible. If I set `sc.settings.figdir = ./results`, then try to save to, say ""qcmetrics/total_counts.png"", the code fails as ""violinqcmetrics/total_counts.png"" does not exist. A partial work around is to set `sc.settings.figdir` every time I want to save in a different directory, but this feels quite clunky to me. And it will still result in all my files being prepended with ""violin"" (or ""scatter"", etc.), which I'd like to avoid. Is there any way to disable this prefix on save behaviour? ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.settings.figdir = ""./"". sc.pl.violin(adata, [""total_counts""], save=""results/test_plot.png""). ```. ```pytb. FileNotFoundError: [Errno 2] No such file or directory: 'violinresults/test_plot.png'. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.6.0. sinfo 0.3.1. -----. IPython 7.19.0. PIL 8.0.1. anndata 0.7.5. backcall 0.2.0. cffi 1.14.4. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. flufl NA. get_version 2.1. h5py 3.1.0. igraph 0.8.3. ipython_genutils 0.2.0. jedi 0.17.2. joblib 0.17.0. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.35.0rc3. matplotlib 3.3.3. mpl_toolkits NA. natsor",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1508
https://github.com/scverse/scanpy/issues/1508:526,usability,behavi,behaviour,526,"Saving plots results in a prefixed filename, regardless of sc.settings.figdir; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. As far as I can tell, `sc.pl.violin` always prepends the string ""violin"" to all save filed, regardless of `sc.settings.figdir`. This complicates programatically setting the filename for outputs. I've also confirmed this behaviour for `sc.pl.scatter`, and suspect it holds true for other `sc.pl` methods. As an example: I keep all results from my analysis in a `results/` directory, with each step having its own subdirectory. Currently, this doesn't seem possible. If I set `sc.settings.figdir = ./results`, then try to save to, say ""qcmetrics/total_counts.png"", the code fails as ""violinqcmetrics/total_counts.png"" does not exist. A partial work around is to set `sc.settings.figdir` every time I want to save in a different directory, but this feels quite clunky to me. And it will still result in all my files being prepended with ""violin"" (or ""scatter"", etc.), which I'd like to avoid. Is there any way to disable this prefix on save behaviour? ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.settings.figdir = ""./"". sc.pl.violin(adata, [""total_counts""], save=""results/test_plot.png""). ```. ```pytb. FileNotFoundError: [Errno 2] No such file or directory: 'violinresults/test_plot.png'. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.6.0. sinfo 0.3.1. -----. IPython 7.19.0. PIL 8.0.1. anndata 0.7.5. backcall 0.2.0. cffi 1.14.4. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. flufl NA. get_version 2.1. h5py 3.1.0. igraph 0.8.3. ipython_genutils 0.2.0. jedi 0.17.2. joblib 0.17.0. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.35.0rc3. matplotlib 3.3.3. mpl_toolkits NA. natsor",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1508
https://github.com/scverse/scanpy/issues/1508:1244,usability,behavi,behaviour,1244,"med this bug exists on the master branch of scanpy. ---. As far as I can tell, `sc.pl.violin` always prepends the string ""violin"" to all save filed, regardless of `sc.settings.figdir`. This complicates programatically setting the filename for outputs. I've also confirmed this behaviour for `sc.pl.scatter`, and suspect it holds true for other `sc.pl` methods. As an example: I keep all results from my analysis in a `results/` directory, with each step having its own subdirectory. Currently, this doesn't seem possible. If I set `sc.settings.figdir = ./results`, then try to save to, say ""qcmetrics/total_counts.png"", the code fails as ""violinqcmetrics/total_counts.png"" does not exist. A partial work around is to set `sc.settings.figdir` every time I want to save in a different directory, but this feels quite clunky to me. And it will still result in all my files being prepended with ""violin"" (or ""scatter"", etc.), which I'd like to avoid. Is there any way to disable this prefix on save behaviour? ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.settings.figdir = ""./"". sc.pl.violin(adata, [""total_counts""], save=""results/test_plot.png""). ```. ```pytb. FileNotFoundError: [Errno 2] No such file or directory: 'violinresults/test_plot.png'. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.6.0. sinfo 0.3.1. -----. IPython 7.19.0. PIL 8.0.1. anndata 0.7.5. backcall 0.2.0. cffi 1.14.4. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. flufl NA. get_version 2.1. h5py 3.1.0. igraph 0.8.3. ipython_genutils 0.2.0. jedi 0.17.2. joblib 0.17.0. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.35.0rc3. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.1.0. numba 0.51.2. numexpr 2.7.1. numpy 1.19.4. packaging 20.4. pandas 1.1.4. parso 0.7.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.8. ptyprocess 0.6.0. pygments 2.7.2. pyparsing 2.4.7. pytz 2020.4. ruamel NA. scanp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1508
https://github.com/scverse/scanpy/issues/1508:1259,usability,Minim,Minimal,1259,"xists on the master branch of scanpy. ---. As far as I can tell, `sc.pl.violin` always prepends the string ""violin"" to all save filed, regardless of `sc.settings.figdir`. This complicates programatically setting the filename for outputs. I've also confirmed this behaviour for `sc.pl.scatter`, and suspect it holds true for other `sc.pl` methods. As an example: I keep all results from my analysis in a `results/` directory, with each step having its own subdirectory. Currently, this doesn't seem possible. If I set `sc.settings.figdir = ./results`, then try to save to, say ""qcmetrics/total_counts.png"", the code fails as ""violinqcmetrics/total_counts.png"" does not exist. A partial work around is to set `sc.settings.figdir` every time I want to save in a different directory, but this feels quite clunky to me. And it will still result in all my files being prepended with ""violin"" (or ""scatter"", etc.), which I'd like to avoid. Is there any way to disable this prefix on save behaviour? ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.settings.figdir = ""./"". sc.pl.violin(adata, [""total_counts""], save=""results/test_plot.png""). ```. ```pytb. FileNotFoundError: [Errno 2] No such file or directory: 'violinresults/test_plot.png'. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.6.0. sinfo 0.3.1. -----. IPython 7.19.0. PIL 8.0.1. anndata 0.7.5. backcall 0.2.0. cffi 1.14.4. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. flufl NA. get_version 2.1. h5py 3.1.0. igraph 0.8.3. ipython_genutils 0.2.0. jedi 0.17.2. joblib 0.17.0. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.3. llvmlite 0.35.0rc3. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.1.0. numba 0.51.2. numexpr 2.7.1. numpy 1.19.4. packaging 20.4. pandas 1.1.4. parso 0.7.1. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.8. ptyprocess 0.6.0. pygments 2.7.2. pyparsing 2.4.7. pytz 2020.4. ruamel NA. scanpy 1.6.0. scipy",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1508
https://github.com/scverse/scanpy/issues/1509:97,deployability,releas,released,97,umap 0.5 compatibility; It'd be good to make sure everything works with umap 0.5 before it get's released.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1509
https://github.com/scverse/scanpy/issues/1509:9,interoperability,compatib,compatibility,9,umap 0.5 compatibility; It'd be good to make sure everything works with umap 0.5 before it get's released.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1509
https://github.com/scverse/scanpy/issues/1510:0,availability,Error,Error,0,"Error exporting adata using sc.export_to.spring_project ; Hi, . Thanks for the awesome tool! May I know in which version can I find [`sc.export_to.spring_project`](https://scanpy.readthedocs.io/en/stable/external/scanpy.external.exporting.spring_project.html)? I have tried scanpy==1.6.0, 1.0.3, 1.1a1 but faced this error . ![image](https://user-images.githubusercontent.com/26448066/100419830-47b79600-30c0-11eb-9e08-b3ae1e18ea1b.png). [This tutorial](https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/171111_SPRING_export/SPRING_export.ipynb) indicates that it worked in scanpy==1.0.4, however, I failed to fix the bug to install version 1.0.4. Any help will be great! . Many thanks, . Justine",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1510
https://github.com/scverse/scanpy/issues/1510:317,availability,error,error,317,"Error exporting adata using sc.export_to.spring_project ; Hi, . Thanks for the awesome tool! May I know in which version can I find [`sc.export_to.spring_project`](https://scanpy.readthedocs.io/en/stable/external/scanpy.external.exporting.spring_project.html)? I have tried scanpy==1.6.0, 1.0.3, 1.1a1 but faced this error . ![image](https://user-images.githubusercontent.com/26448066/100419830-47b79600-30c0-11eb-9e08-b3ae1e18ea1b.png). [This tutorial](https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/171111_SPRING_export/SPRING_export.ipynb) indicates that it worked in scanpy==1.0.4, however, I failed to fix the bug to install version 1.0.4. Any help will be great! . Many thanks, . Justine",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1510
https://github.com/scverse/scanpy/issues/1510:113,deployability,version,version,113,"Error exporting adata using sc.export_to.spring_project ; Hi, . Thanks for the awesome tool! May I know in which version can I find [`sc.export_to.spring_project`](https://scanpy.readthedocs.io/en/stable/external/scanpy.external.exporting.spring_project.html)? I have tried scanpy==1.6.0, 1.0.3, 1.1a1 but faced this error . ![image](https://user-images.githubusercontent.com/26448066/100419830-47b79600-30c0-11eb-9e08-b3ae1e18ea1b.png). [This tutorial](https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/171111_SPRING_export/SPRING_export.ipynb) indicates that it worked in scanpy==1.0.4, however, I failed to fix the bug to install version 1.0.4. Any help will be great! . Many thanks, . Justine",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1510
https://github.com/scverse/scanpy/issues/1510:620,deployability,fail,failed,620,"Error exporting adata using sc.export_to.spring_project ; Hi, . Thanks for the awesome tool! May I know in which version can I find [`sc.export_to.spring_project`](https://scanpy.readthedocs.io/en/stable/external/scanpy.external.exporting.spring_project.html)? I have tried scanpy==1.6.0, 1.0.3, 1.1a1 but faced this error . ![image](https://user-images.githubusercontent.com/26448066/100419830-47b79600-30c0-11eb-9e08-b3ae1e18ea1b.png). [This tutorial](https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/171111_SPRING_export/SPRING_export.ipynb) indicates that it worked in scanpy==1.0.4, however, I failed to fix the bug to install version 1.0.4. Any help will be great! . Many thanks, . Justine",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1510
https://github.com/scverse/scanpy/issues/1510:645,deployability,instal,install,645,"Error exporting adata using sc.export_to.spring_project ; Hi, . Thanks for the awesome tool! May I know in which version can I find [`sc.export_to.spring_project`](https://scanpy.readthedocs.io/en/stable/external/scanpy.external.exporting.spring_project.html)? I have tried scanpy==1.6.0, 1.0.3, 1.1a1 but faced this error . ![image](https://user-images.githubusercontent.com/26448066/100419830-47b79600-30c0-11eb-9e08-b3ae1e18ea1b.png). [This tutorial](https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/171111_SPRING_export/SPRING_export.ipynb) indicates that it worked in scanpy==1.0.4, however, I failed to fix the bug to install version 1.0.4. Any help will be great! . Many thanks, . Justine",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1510
https://github.com/scverse/scanpy/issues/1510:653,deployability,version,version,653,"Error exporting adata using sc.export_to.spring_project ; Hi, . Thanks for the awesome tool! May I know in which version can I find [`sc.export_to.spring_project`](https://scanpy.readthedocs.io/en/stable/external/scanpy.external.exporting.spring_project.html)? I have tried scanpy==1.6.0, 1.0.3, 1.1a1 but faced this error . ![image](https://user-images.githubusercontent.com/26448066/100419830-47b79600-30c0-11eb-9e08-b3ae1e18ea1b.png). [This tutorial](https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/171111_SPRING_export/SPRING_export.ipynb) indicates that it worked in scanpy==1.0.4, however, I failed to fix the bug to install version 1.0.4. Any help will be great! . Many thanks, . Justine",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1510
https://github.com/scverse/scanpy/issues/1510:113,integrability,version,version,113,"Error exporting adata using sc.export_to.spring_project ; Hi, . Thanks for the awesome tool! May I know in which version can I find [`sc.export_to.spring_project`](https://scanpy.readthedocs.io/en/stable/external/scanpy.external.exporting.spring_project.html)? I have tried scanpy==1.6.0, 1.0.3, 1.1a1 but faced this error . ![image](https://user-images.githubusercontent.com/26448066/100419830-47b79600-30c0-11eb-9e08-b3ae1e18ea1b.png). [This tutorial](https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/171111_SPRING_export/SPRING_export.ipynb) indicates that it worked in scanpy==1.0.4, however, I failed to fix the bug to install version 1.0.4. Any help will be great! . Many thanks, . Justine",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1510
https://github.com/scverse/scanpy/issues/1510:653,integrability,version,version,653,"Error exporting adata using sc.export_to.spring_project ; Hi, . Thanks for the awesome tool! May I know in which version can I find [`sc.export_to.spring_project`](https://scanpy.readthedocs.io/en/stable/external/scanpy.external.exporting.spring_project.html)? I have tried scanpy==1.6.0, 1.0.3, 1.1a1 but faced this error . ![image](https://user-images.githubusercontent.com/26448066/100419830-47b79600-30c0-11eb-9e08-b3ae1e18ea1b.png). [This tutorial](https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/171111_SPRING_export/SPRING_export.ipynb) indicates that it worked in scanpy==1.0.4, however, I failed to fix the bug to install version 1.0.4. Any help will be great! . Many thanks, . Justine",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1510
https://github.com/scverse/scanpy/issues/1510:113,modifiability,version,version,113,"Error exporting adata using sc.export_to.spring_project ; Hi, . Thanks for the awesome tool! May I know in which version can I find [`sc.export_to.spring_project`](https://scanpy.readthedocs.io/en/stable/external/scanpy.external.exporting.spring_project.html)? I have tried scanpy==1.6.0, 1.0.3, 1.1a1 but faced this error . ![image](https://user-images.githubusercontent.com/26448066/100419830-47b79600-30c0-11eb-9e08-b3ae1e18ea1b.png). [This tutorial](https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/171111_SPRING_export/SPRING_export.ipynb) indicates that it worked in scanpy==1.0.4, however, I failed to fix the bug to install version 1.0.4. Any help will be great! . Many thanks, . Justine",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1510
https://github.com/scverse/scanpy/issues/1510:653,modifiability,version,version,653,"Error exporting adata using sc.export_to.spring_project ; Hi, . Thanks for the awesome tool! May I know in which version can I find [`sc.export_to.spring_project`](https://scanpy.readthedocs.io/en/stable/external/scanpy.external.exporting.spring_project.html)? I have tried scanpy==1.6.0, 1.0.3, 1.1a1 but faced this error . ![image](https://user-images.githubusercontent.com/26448066/100419830-47b79600-30c0-11eb-9e08-b3ae1e18ea1b.png). [This tutorial](https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/171111_SPRING_export/SPRING_export.ipynb) indicates that it worked in scanpy==1.0.4, however, I failed to fix the bug to install version 1.0.4. Any help will be great! . Many thanks, . Justine",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1510
https://github.com/scverse/scanpy/issues/1510:0,performance,Error,Error,0,"Error exporting adata using sc.export_to.spring_project ; Hi, . Thanks for the awesome tool! May I know in which version can I find [`sc.export_to.spring_project`](https://scanpy.readthedocs.io/en/stable/external/scanpy.external.exporting.spring_project.html)? I have tried scanpy==1.6.0, 1.0.3, 1.1a1 but faced this error . ![image](https://user-images.githubusercontent.com/26448066/100419830-47b79600-30c0-11eb-9e08-b3ae1e18ea1b.png). [This tutorial](https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/171111_SPRING_export/SPRING_export.ipynb) indicates that it worked in scanpy==1.0.4, however, I failed to fix the bug to install version 1.0.4. Any help will be great! . Many thanks, . Justine",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1510
https://github.com/scverse/scanpy/issues/1510:317,performance,error,error,317,"Error exporting adata using sc.export_to.spring_project ; Hi, . Thanks for the awesome tool! May I know in which version can I find [`sc.export_to.spring_project`](https://scanpy.readthedocs.io/en/stable/external/scanpy.external.exporting.spring_project.html)? I have tried scanpy==1.6.0, 1.0.3, 1.1a1 but faced this error . ![image](https://user-images.githubusercontent.com/26448066/100419830-47b79600-30c0-11eb-9e08-b3ae1e18ea1b.png). [This tutorial](https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/171111_SPRING_export/SPRING_export.ipynb) indicates that it worked in scanpy==1.0.4, however, I failed to fix the bug to install version 1.0.4. Any help will be great! . Many thanks, . Justine",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1510
https://github.com/scverse/scanpy/issues/1510:620,reliability,fail,failed,620,"Error exporting adata using sc.export_to.spring_project ; Hi, . Thanks for the awesome tool! May I know in which version can I find [`sc.export_to.spring_project`](https://scanpy.readthedocs.io/en/stable/external/scanpy.external.exporting.spring_project.html)? I have tried scanpy==1.6.0, 1.0.3, 1.1a1 but faced this error . ![image](https://user-images.githubusercontent.com/26448066/100419830-47b79600-30c0-11eb-9e08-b3ae1e18ea1b.png). [This tutorial](https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/171111_SPRING_export/SPRING_export.ipynb) indicates that it worked in scanpy==1.0.4, however, I failed to fix the bug to install version 1.0.4. Any help will be great! . Many thanks, . Justine",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1510
https://github.com/scverse/scanpy/issues/1510:0,safety,Error,Error,0,"Error exporting adata using sc.export_to.spring_project ; Hi, . Thanks for the awesome tool! May I know in which version can I find [`sc.export_to.spring_project`](https://scanpy.readthedocs.io/en/stable/external/scanpy.external.exporting.spring_project.html)? I have tried scanpy==1.6.0, 1.0.3, 1.1a1 but faced this error . ![image](https://user-images.githubusercontent.com/26448066/100419830-47b79600-30c0-11eb-9e08-b3ae1e18ea1b.png). [This tutorial](https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/171111_SPRING_export/SPRING_export.ipynb) indicates that it worked in scanpy==1.0.4, however, I failed to fix the bug to install version 1.0.4. Any help will be great! . Many thanks, . Justine",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1510
https://github.com/scverse/scanpy/issues/1510:317,safety,error,error,317,"Error exporting adata using sc.export_to.spring_project ; Hi, . Thanks for the awesome tool! May I know in which version can I find [`sc.export_to.spring_project`](https://scanpy.readthedocs.io/en/stable/external/scanpy.external.exporting.spring_project.html)? I have tried scanpy==1.6.0, 1.0.3, 1.1a1 but faced this error . ![image](https://user-images.githubusercontent.com/26448066/100419830-47b79600-30c0-11eb-9e08-b3ae1e18ea1b.png). [This tutorial](https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/171111_SPRING_export/SPRING_export.ipynb) indicates that it worked in scanpy==1.0.4, however, I failed to fix the bug to install version 1.0.4. Any help will be great! . Many thanks, . Justine",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1510
https://github.com/scverse/scanpy/issues/1510:0,usability,Error,Error,0,"Error exporting adata using sc.export_to.spring_project ; Hi, . Thanks for the awesome tool! May I know in which version can I find [`sc.export_to.spring_project`](https://scanpy.readthedocs.io/en/stable/external/scanpy.external.exporting.spring_project.html)? I have tried scanpy==1.6.0, 1.0.3, 1.1a1 but faced this error . ![image](https://user-images.githubusercontent.com/26448066/100419830-47b79600-30c0-11eb-9e08-b3ae1e18ea1b.png). [This tutorial](https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/171111_SPRING_export/SPRING_export.ipynb) indicates that it worked in scanpy==1.0.4, however, I failed to fix the bug to install version 1.0.4. Any help will be great! . Many thanks, . Justine",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1510
https://github.com/scverse/scanpy/issues/1510:87,usability,tool,tool,87,"Error exporting adata using sc.export_to.spring_project ; Hi, . Thanks for the awesome tool! May I know in which version can I find [`sc.export_to.spring_project`](https://scanpy.readthedocs.io/en/stable/external/scanpy.external.exporting.spring_project.html)? I have tried scanpy==1.6.0, 1.0.3, 1.1a1 but faced this error . ![image](https://user-images.githubusercontent.com/26448066/100419830-47b79600-30c0-11eb-9e08-b3ae1e18ea1b.png). [This tutorial](https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/171111_SPRING_export/SPRING_export.ipynb) indicates that it worked in scanpy==1.0.4, however, I failed to fix the bug to install version 1.0.4. Any help will be great! . Many thanks, . Justine",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1510
https://github.com/scverse/scanpy/issues/1510:317,usability,error,error,317,"Error exporting adata using sc.export_to.spring_project ; Hi, . Thanks for the awesome tool! May I know in which version can I find [`sc.export_to.spring_project`](https://scanpy.readthedocs.io/en/stable/external/scanpy.external.exporting.spring_project.html)? I have tried scanpy==1.6.0, 1.0.3, 1.1a1 but faced this error . ![image](https://user-images.githubusercontent.com/26448066/100419830-47b79600-30c0-11eb-9e08-b3ae1e18ea1b.png). [This tutorial](https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/171111_SPRING_export/SPRING_export.ipynb) indicates that it worked in scanpy==1.0.4, however, I failed to fix the bug to install version 1.0.4. Any help will be great! . Many thanks, . Justine",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1510
https://github.com/scverse/scanpy/issues/1510:342,usability,user,user-images,342,"Error exporting adata using sc.export_to.spring_project ; Hi, . Thanks for the awesome tool! May I know in which version can I find [`sc.export_to.spring_project`](https://scanpy.readthedocs.io/en/stable/external/scanpy.external.exporting.spring_project.html)? I have tried scanpy==1.6.0, 1.0.3, 1.1a1 but faced this error . ![image](https://user-images.githubusercontent.com/26448066/100419830-47b79600-30c0-11eb-9e08-b3ae1e18ea1b.png). [This tutorial](https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/171111_SPRING_export/SPRING_export.ipynb) indicates that it worked in scanpy==1.0.4, however, I failed to fix the bug to install version 1.0.4. Any help will be great! . Many thanks, . Justine",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1510
https://github.com/scverse/scanpy/issues/1510:566,usability,indicat,indicates,566,"Error exporting adata using sc.export_to.spring_project ; Hi, . Thanks for the awesome tool! May I know in which version can I find [`sc.export_to.spring_project`](https://scanpy.readthedocs.io/en/stable/external/scanpy.external.exporting.spring_project.html)? I have tried scanpy==1.6.0, 1.0.3, 1.1a1 but faced this error . ![image](https://user-images.githubusercontent.com/26448066/100419830-47b79600-30c0-11eb-9e08-b3ae1e18ea1b.png). [This tutorial](https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/171111_SPRING_export/SPRING_export.ipynb) indicates that it worked in scanpy==1.0.4, however, I failed to fix the bug to install version 1.0.4. Any help will be great! . Many thanks, . Justine",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1510
https://github.com/scverse/scanpy/issues/1510:672,usability,help,help,672,"Error exporting adata using sc.export_to.spring_project ; Hi, . Thanks for the awesome tool! May I know in which version can I find [`sc.export_to.spring_project`](https://scanpy.readthedocs.io/en/stable/external/scanpy.external.exporting.spring_project.html)? I have tried scanpy==1.6.0, 1.0.3, 1.1a1 but faced this error . ![image](https://user-images.githubusercontent.com/26448066/100419830-47b79600-30c0-11eb-9e08-b3ae1e18ea1b.png). [This tutorial](https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/171111_SPRING_export/SPRING_export.ipynb) indicates that it worked in scanpy==1.0.4, however, I failed to fix the bug to install version 1.0.4. Any help will be great! . Many thanks, . Justine",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1510
https://github.com/scverse/scanpy/pull/1511:0,energy efficiency,Heat,Heatmap,0,"Heatmap colormatching; Corrected colouring of groups in heat map, so that row and column colors match up. Related to issue #1479 . - [x] black. - [x] fix scanpy tutorial https://scanpy-tutorials.readthedocs.io/en/latest/plotting/core.html#Heatmaps. - [x] account for case where var_group_labels are not a subset of groupby groups. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1511
https://github.com/scverse/scanpy/pull/1511:56,energy efficiency,heat,heat,56,"Heatmap colormatching; Corrected colouring of groups in heat map, so that row and column colors match up. Related to issue #1479 . - [x] black. - [x] fix scanpy tutorial https://scanpy-tutorials.readthedocs.io/en/latest/plotting/core.html#Heatmaps. - [x] account for case where var_group_labels are not a subset of groupby groups. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1511
https://github.com/scverse/scanpy/pull/1511:229,energy efficiency,core,core,229,"Heatmap colormatching; Corrected colouring of groups in heat map, so that row and column colors match up. Related to issue #1479 . - [x] black. - [x] fix scanpy tutorial https://scanpy-tutorials.readthedocs.io/en/latest/plotting/core.html#Heatmaps. - [x] account for case where var_group_labels are not a subset of groupby groups. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1511
https://github.com/scverse/scanpy/pull/1511:239,energy efficiency,Heat,Heatmaps,239,"Heatmap colormatching; Corrected colouring of groups in heat map, so that row and column colors match up. Related to issue #1479 . - [x] black. - [x] fix scanpy tutorial https://scanpy-tutorials.readthedocs.io/en/latest/plotting/core.html#Heatmaps. - [x] account for case where var_group_labels are not a subset of groupby groups. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1511
https://github.com/scverse/scanpy/pull/1511:305,integrability,sub,subset,305,"Heatmap colormatching; Corrected colouring of groups in heat map, so that row and column colors match up. Related to issue #1479 . - [x] black. - [x] fix scanpy tutorial https://scanpy-tutorials.readthedocs.io/en/latest/plotting/core.html#Heatmaps. - [x] account for case where var_group_labels are not a subset of groupby groups. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1511
https://github.com/scverse/scanpy/pull/1512:4,deployability,log,logic,4,"fix logic for empty library_id and images; fix logic in order to accomodate non-visium plotting (e.g. seqfish). essentially, for non-visium, scatterplot should be used because we can't find heuristic for spot size. We can't find heuristic for spot size because spatial axis could be any dimension (e.g. I just found z-scored ones). With visium instead, spatial axis will always be pixel dimension, and so ok to use circles and thus set the heuristics (not changed, but just for references it's line 328 of scatterplots).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:47,deployability,log,logic,47,"fix logic for empty library_id and images; fix logic in order to accomodate non-visium plotting (e.g. seqfish). essentially, for non-visium, scatterplot should be used because we can't find heuristic for spot size. We can't find heuristic for spot size because spatial axis could be any dimension (e.g. I just found z-scored ones). With visium instead, spatial axis will always be pixel dimension, and so ok to use circles and thus set the heuristics (not changed, but just for references it's line 328 of scatterplots).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:4,safety,log,logic,4,"fix logic for empty library_id and images; fix logic in order to accomodate non-visium plotting (e.g. seqfish). essentially, for non-visium, scatterplot should be used because we can't find heuristic for spot size. We can't find heuristic for spot size because spatial axis could be any dimension (e.g. I just found z-scored ones). With visium instead, spatial axis will always be pixel dimension, and so ok to use circles and thus set the heuristics (not changed, but just for references it's line 328 of scatterplots).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:47,safety,log,logic,47,"fix logic for empty library_id and images; fix logic in order to accomodate non-visium plotting (e.g. seqfish). essentially, for non-visium, scatterplot should be used because we can't find heuristic for spot size. We can't find heuristic for spot size because spatial axis could be any dimension (e.g. I just found z-scored ones). With visium instead, spatial axis will always be pixel dimension, and so ok to use circles and thus set the heuristics (not changed, but just for references it's line 328 of scatterplots).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:4,security,log,logic,4,"fix logic for empty library_id and images; fix logic in order to accomodate non-visium plotting (e.g. seqfish). essentially, for non-visium, scatterplot should be used because we can't find heuristic for spot size. We can't find heuristic for spot size because spatial axis could be any dimension (e.g. I just found z-scored ones). With visium instead, spatial axis will always be pixel dimension, and so ok to use circles and thus set the heuristics (not changed, but just for references it's line 328 of scatterplots).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:47,security,log,logic,47,"fix logic for empty library_id and images; fix logic in order to accomodate non-visium plotting (e.g. seqfish). essentially, for non-visium, scatterplot should be used because we can't find heuristic for spot size. We can't find heuristic for spot size because spatial axis could be any dimension (e.g. I just found z-scored ones). With visium instead, spatial axis will always be pixel dimension, and so ok to use circles and thus set the heuristics (not changed, but just for references it's line 328 of scatterplots).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:4,testability,log,logic,4,"fix logic for empty library_id and images; fix logic in order to accomodate non-visium plotting (e.g. seqfish). essentially, for non-visium, scatterplot should be used because we can't find heuristic for spot size. We can't find heuristic for spot size because spatial axis could be any dimension (e.g. I just found z-scored ones). With visium instead, spatial axis will always be pixel dimension, and so ok to use circles and thus set the heuristics (not changed, but just for references it's line 328 of scatterplots).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/pull/1512:47,testability,log,logic,47,"fix logic for empty library_id and images; fix logic in order to accomodate non-visium plotting (e.g. seqfish). essentially, for non-visium, scatterplot should be used because we can't find heuristic for spot size. We can't find heuristic for spot size because spatial axis could be any dimension (e.g. I just found z-scored ones). With visium instead, spatial axis will always be pixel dimension, and so ok to use circles and thus set the heuristics (not changed, but just for references it's line 328 of scatterplots).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1512
https://github.com/scverse/scanpy/issues/1513:562,deployability,automat,automatic,562,"adjustText for `legend_loc=""on data""` leged location; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. would be really cool to have adjustText for automatic ordering of text in `sc.pl.embedding`. https://github.com/Phlya/adjustText. has anybody ever looked into it?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1513
https://github.com/scverse/scanpy/issues/1513:534,energy efficiency,cool,cool,534,"adjustText for `legend_loc=""on data""` leged location; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. would be really cool to have adjustText for automatic ordering of text in `sc.pl.embedding`. https://github.com/Phlya/adjustText. has anybody ever looked into it?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1513
https://github.com/scverse/scanpy/issues/1513:138,modifiability,paramet,parameters,138,"adjustText for `legend_loc=""on data""` leged location; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. would be really cool to have adjustText for automatic ordering of text in `sc.pl.embedding`. https://github.com/Phlya/adjustText. has anybody ever looked into it?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1513
https://github.com/scverse/scanpy/issues/1513:415,modifiability,pac,package,415,"adjustText for `legend_loc=""on data""` leged location; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. would be really cool to have adjustText for automatic ordering of text in `sc.pl.embedding`. https://github.com/Phlya/adjustText. has anybody ever looked into it?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1513
https://github.com/scverse/scanpy/issues/1513:220,testability,simpl,simple,220,"adjustText for `legend_loc=""on data""` leged location; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. would be really cool to have adjustText for automatic ordering of text in `sc.pl.embedding`. https://github.com/Phlya/adjustText. has anybody ever looked into it?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1513
https://github.com/scverse/scanpy/issues/1513:562,testability,automat,automatic,562,"adjustText for `legend_loc=""on data""` leged location; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. would be really cool to have adjustText for automatic ordering of text in `sc.pl.embedding`. https://github.com/Phlya/adjustText. has anybody ever looked into it?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1513
https://github.com/scverse/scanpy/issues/1513:212,usability,tool,tool,212,"adjustText for `legend_loc=""on data""` leged location; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. would be really cool to have adjustText for automatic ordering of text in `sc.pl.embedding`. https://github.com/Phlya/adjustText. has anybody ever looked into it?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1513
https://github.com/scverse/scanpy/issues/1513:220,usability,simpl,simple,220,"adjustText for `legend_loc=""on data""` leged location; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. would be really cool to have adjustText for automatic ordering of text in `sc.pl.embedding`. https://github.com/Phlya/adjustText. has anybody ever looked into it?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1513
https://github.com/scverse/scanpy/issues/1513:236,usability,tool,tool,236,"adjustText for `legend_loc=""on data""` leged location; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. would be really cool to have adjustText for automatic ordering of text in `sc.pl.embedding`. https://github.com/Phlya/adjustText. has anybody ever looked into it?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1513
https://github.com/scverse/scanpy/issues/1513:284,usability,tool,tools,284,"adjustText for `legend_loc=""on data""` leged location; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. would be really cool to have adjustText for automatic ordering of text in `sc.pl.embedding`. https://github.com/Phlya/adjustText. has anybody ever looked into it?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1513
https://github.com/scverse/scanpy/issues/1513:384,usability,tool,tools,384,"adjustText for `legend_loc=""on data""` leged location; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. would be really cool to have adjustText for automatic ordering of text in `sc.pl.embedding`. https://github.com/Phlya/adjustText. has anybody ever looked into it?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1513
https://github.com/scverse/scanpy/issues/1514:30,availability,slo,slower,30,"filter_rank_genes_groups much slower than rank_genes_groups; I was using Scanpy 1.5.0. It took me more than two hours to finish filter_rank_genes_groups with default parameters while rank_genes_groups takes less than 5 minutes. But theoretically, it shouldn't be too different from rank_genes_groups right? . But it seems way slower than rank_genes_groups and much slower than Seurat. Is there a way to make it faster?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1514
https://github.com/scverse/scanpy/issues/1514:326,availability,slo,slower,326,"filter_rank_genes_groups much slower than rank_genes_groups; I was using Scanpy 1.5.0. It took me more than two hours to finish filter_rank_genes_groups with default parameters while rank_genes_groups takes less than 5 minutes. But theoretically, it shouldn't be too different from rank_genes_groups right? . But it seems way slower than rank_genes_groups and much slower than Seurat. Is there a way to make it faster?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1514
https://github.com/scverse/scanpy/issues/1514:365,availability,slo,slower,365,"filter_rank_genes_groups much slower than rank_genes_groups; I was using Scanpy 1.5.0. It took me more than two hours to finish filter_rank_genes_groups with default parameters while rank_genes_groups takes less than 5 minutes. But theoretically, it shouldn't be too different from rank_genes_groups right? . But it seems way slower than rank_genes_groups and much slower than Seurat. Is there a way to make it faster?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1514
https://github.com/scverse/scanpy/issues/1514:166,modifiability,paramet,parameters,166,"filter_rank_genes_groups much slower than rank_genes_groups; I was using Scanpy 1.5.0. It took me more than two hours to finish filter_rank_genes_groups with default parameters while rank_genes_groups takes less than 5 minutes. But theoretically, it shouldn't be too different from rank_genes_groups right? . But it seems way slower than rank_genes_groups and much slower than Seurat. Is there a way to make it faster?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1514
https://github.com/scverse/scanpy/issues/1514:30,reliability,slo,slower,30,"filter_rank_genes_groups much slower than rank_genes_groups; I was using Scanpy 1.5.0. It took me more than two hours to finish filter_rank_genes_groups with default parameters while rank_genes_groups takes less than 5 minutes. But theoretically, it shouldn't be too different from rank_genes_groups right? . But it seems way slower than rank_genes_groups and much slower than Seurat. Is there a way to make it faster?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1514
https://github.com/scverse/scanpy/issues/1514:326,reliability,slo,slower,326,"filter_rank_genes_groups much slower than rank_genes_groups; I was using Scanpy 1.5.0. It took me more than two hours to finish filter_rank_genes_groups with default parameters while rank_genes_groups takes less than 5 minutes. But theoretically, it shouldn't be too different from rank_genes_groups right? . But it seems way slower than rank_genes_groups and much slower than Seurat. Is there a way to make it faster?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1514
https://github.com/scverse/scanpy/issues/1514:365,reliability,slo,slower,365,"filter_rank_genes_groups much slower than rank_genes_groups; I was using Scanpy 1.5.0. It took me more than two hours to finish filter_rank_genes_groups with default parameters while rank_genes_groups takes less than 5 minutes. But theoretically, it shouldn't be too different from rank_genes_groups right? . But it seems way slower than rank_genes_groups and much slower than Seurat. Is there a way to make it faster?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1514
https://github.com/scverse/scanpy/issues/1515:267,deployability,updat,updated,267,"moignard15 dataset link broken; `sc.datasets.moignard15()` results in a 404. The previous link http://www.nature.com/nbt/journal/v33/n3/extref/nbt.3154-S3.xlsx seems to not be working anymore. It looks like supp info is still there, so links probably just need to be updated: https://www.nature.com/articles/nbt.3154#Sec24. Alternatively, maybe springer needs the 10k in publishing fees to keep their servers running.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1515
https://github.com/scverse/scanpy/issues/1515:371,integrability,pub,publishing,371,"moignard15 dataset link broken; `sc.datasets.moignard15()` results in a 404. The previous link http://www.nature.com/nbt/journal/v33/n3/extref/nbt.3154-S3.xlsx seems to not be working anymore. It looks like supp info is still there, so links probably just need to be updated: https://www.nature.com/articles/nbt.3154#Sec24. Alternatively, maybe springer needs the 10k in publishing fees to keep their servers running.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1515
https://github.com/scverse/scanpy/issues/1515:267,safety,updat,updated,267,"moignard15 dataset link broken; `sc.datasets.moignard15()` results in a 404. The previous link http://www.nature.com/nbt/journal/v33/n3/extref/nbt.3154-S3.xlsx seems to not be working anymore. It looks like supp info is still there, so links probably just need to be updated: https://www.nature.com/articles/nbt.3154#Sec24. Alternatively, maybe springer needs the 10k in publishing fees to keep their servers running.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1515
https://github.com/scverse/scanpy/issues/1515:267,security,updat,updated,267,"moignard15 dataset link broken; `sc.datasets.moignard15()` results in a 404. The previous link http://www.nature.com/nbt/journal/v33/n3/extref/nbt.3154-S3.xlsx seems to not be working anymore. It looks like supp info is still there, so links probably just need to be updated: https://www.nature.com/articles/nbt.3154#Sec24. Alternatively, maybe springer needs the 10k in publishing fees to keep their servers running.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1515
https://github.com/scverse/scanpy/pull/1516:13,deployability,Pipelin,Pipelines,13,Set up Azure Pipelines with initial configuration;,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1516
https://github.com/scverse/scanpy/pull/1516:36,deployability,configurat,configuration,36,Set up Azure Pipelines with initial configuration;,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1516
https://github.com/scverse/scanpy/pull/1516:13,integrability,Pipelin,Pipelines,13,Set up Azure Pipelines with initial configuration;,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1516
https://github.com/scverse/scanpy/pull/1516:36,integrability,configur,configuration,36,Set up Azure Pipelines with initial configuration;,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1516
https://github.com/scverse/scanpy/pull/1516:36,modifiability,configur,configuration,36,Set up Azure Pipelines with initial configuration;,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1516
https://github.com/scverse/scanpy/pull/1516:36,security,configur,configuration,36,Set up Azure Pipelines with initial configuration;,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1516
https://github.com/scverse/scanpy/pull/1517:23,deployability,pipelin,pipeline,23,"Modifications to azure pipeline; I'm going to use this PR to test some modifications to the azure pipelines. First off, can we lint in the same job as running tests.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1517
https://github.com/scverse/scanpy/pull/1517:98,deployability,pipelin,pipelines,98,"Modifications to azure pipeline; I'm going to use this PR to test some modifications to the azure pipelines. First off, can we lint in the same job as running tests.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1517
https://github.com/scverse/scanpy/pull/1517:23,integrability,pipelin,pipeline,23,"Modifications to azure pipeline; I'm going to use this PR to test some modifications to the azure pipelines. First off, can we lint in the same job as running tests.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1517
https://github.com/scverse/scanpy/pull/1517:98,integrability,pipelin,pipelines,98,"Modifications to azure pipeline; I'm going to use this PR to test some modifications to the azure pipelines. First off, can we lint in the same job as running tests.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1517
https://github.com/scverse/scanpy/pull/1517:61,safety,test,test,61,"Modifications to azure pipeline; I'm going to use this PR to test some modifications to the azure pipelines. First off, can we lint in the same job as running tests.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1517
https://github.com/scverse/scanpy/pull/1517:159,safety,test,tests,159,"Modifications to azure pipeline; I'm going to use this PR to test some modifications to the azure pipelines. First off, can we lint in the same job as running tests.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1517
https://github.com/scverse/scanpy/pull/1517:0,security,Modif,Modifications,0,"Modifications to azure pipeline; I'm going to use this PR to test some modifications to the azure pipelines. First off, can we lint in the same job as running tests.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1517
https://github.com/scverse/scanpy/pull/1517:71,security,modif,modifications,71,"Modifications to azure pipeline; I'm going to use this PR to test some modifications to the azure pipelines. First off, can we lint in the same job as running tests.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1517
https://github.com/scverse/scanpy/pull/1517:61,testability,test,test,61,"Modifications to azure pipeline; I'm going to use this PR to test some modifications to the azure pipelines. First off, can we lint in the same job as running tests.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1517
https://github.com/scverse/scanpy/pull/1517:159,testability,test,tests,159,"Modifications to azure pipeline; I'm going to use this PR to test some modifications to the azure pipelines. First off, can we lint in the same job as running tests.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1517
https://github.com/scverse/scanpy/pull/1518:4,testability,coverag,coverage,4,Try coverage; Trying some more stuff with the new CI,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1518
https://github.com/scverse/scanpy/issues/1519:469,availability,cluster,clusters,469,"rank_genes_groups ""groups"" argument ignored or not clearly explained; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi,. My understanding of the ""groups"" argument in sc.tl.rank_genes_groups is that it subsets the data and then performs the differential expression testing. I.e. if I have clusters 1 to 10, and I set groups=[1,2], the output will give me the genes differentially expressed in cluster 1 as compared to cluster 2 (and 2 vs 1). However, the current function still compares to all other clusters (see below). . Is that the intention? If so, we should update the readthedocs I think. If this is a bug, let's try to fix it :) I can take a look myself in that case. Just wanted to check if I misinterpreted the readthedocs. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. # load data. adata = sc.datasets.pbmc68k_reduced(). # cluster. sc.tl.leiden(adata, key_added=""clusters"", resolution=0.5). print(""Clusters:"", sorted(set(adata.obs[""clusters""]))). # do test with groups=""all"". sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=""all""). # store results, sorting genes by logfc. genes_cluster_0_vs_all = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # do test with groups=[""0"",""1""], i.e. only a subset of the clusters. sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=[""0"", ""1""]). # store result. genes_cluster_0_vs_1 = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # print top 5 genes and logfcs for both,. # they're the same and should not be. print(""Top genes clust",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1519
https://github.com/scverse/scanpy/issues/1519:573,availability,cluster,cluster,573,"rank_genes_groups ""groups"" argument ignored or not clearly explained; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi,. My understanding of the ""groups"" argument in sc.tl.rank_genes_groups is that it subsets the data and then performs the differential expression testing. I.e. if I have clusters 1 to 10, and I set groups=[1,2], the output will give me the genes differentially expressed in cluster 1 as compared to cluster 2 (and 2 vs 1). However, the current function still compares to all other clusters (see below). . Is that the intention? If so, we should update the readthedocs I think. If this is a bug, let's try to fix it :) I can take a look myself in that case. Just wanted to check if I misinterpreted the readthedocs. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. # load data. adata = sc.datasets.pbmc68k_reduced(). # cluster. sc.tl.leiden(adata, key_added=""clusters"", resolution=0.5). print(""Clusters:"", sorted(set(adata.obs[""clusters""]))). # do test with groups=""all"". sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=""all""). # store results, sorting genes by logfc. genes_cluster_0_vs_all = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # do test with groups=[""0"",""1""], i.e. only a subset of the clusters. sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=[""0"", ""1""]). # store result. genes_cluster_0_vs_1 = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # print top 5 genes and logfcs for both,. # they're the same and should not be. print(""Top genes clust",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1519
https://github.com/scverse/scanpy/issues/1519:598,availability,cluster,cluster,598,"rank_genes_groups ""groups"" argument ignored or not clearly explained; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi,. My understanding of the ""groups"" argument in sc.tl.rank_genes_groups is that it subsets the data and then performs the differential expression testing. I.e. if I have clusters 1 to 10, and I set groups=[1,2], the output will give me the genes differentially expressed in cluster 1 as compared to cluster 2 (and 2 vs 1). However, the current function still compares to all other clusters (see below). . Is that the intention? If so, we should update the readthedocs I think. If this is a bug, let's try to fix it :) I can take a look myself in that case. Just wanted to check if I misinterpreted the readthedocs. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. # load data. adata = sc.datasets.pbmc68k_reduced(). # cluster. sc.tl.leiden(adata, key_added=""clusters"", resolution=0.5). print(""Clusters:"", sorted(set(adata.obs[""clusters""]))). # do test with groups=""all"". sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=""all""). # store results, sorting genes by logfc. genes_cluster_0_vs_all = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # do test with groups=[""0"",""1""], i.e. only a subset of the clusters. sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=[""0"", ""1""]). # store result. genes_cluster_0_vs_1 = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # print top 5 genes and logfcs for both,. # they're the same and should not be. print(""Top genes clust",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1519
https://github.com/scverse/scanpy/issues/1519:680,availability,cluster,clusters,680,"rank_genes_groups ""groups"" argument ignored or not clearly explained; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi,. My understanding of the ""groups"" argument in sc.tl.rank_genes_groups is that it subsets the data and then performs the differential expression testing. I.e. if I have clusters 1 to 10, and I set groups=[1,2], the output will give me the genes differentially expressed in cluster 1 as compared to cluster 2 (and 2 vs 1). However, the current function still compares to all other clusters (see below). . Is that the intention? If so, we should update the readthedocs I think. If this is a bug, let's try to fix it :) I can take a look myself in that case. Just wanted to check if I misinterpreted the readthedocs. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. # load data. adata = sc.datasets.pbmc68k_reduced(). # cluster. sc.tl.leiden(adata, key_added=""clusters"", resolution=0.5). print(""Clusters:"", sorted(set(adata.obs[""clusters""]))). # do test with groups=""all"". sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=""all""). # store results, sorting genes by logfc. genes_cluster_0_vs_all = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # do test with groups=[""0"",""1""], i.e. only a subset of the clusters. sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=[""0"", ""1""]). # store result. genes_cluster_0_vs_1 = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # print top 5 genes and logfcs for both,. # they're the same and should not be. print(""Top genes clust",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1519
https://github.com/scverse/scanpy/issues/1519:1074,availability,cluster,cluster,1074,"have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi,. My understanding of the ""groups"" argument in sc.tl.rank_genes_groups is that it subsets the data and then performs the differential expression testing. I.e. if I have clusters 1 to 10, and I set groups=[1,2], the output will give me the genes differentially expressed in cluster 1 as compared to cluster 2 (and 2 vs 1). However, the current function still compares to all other clusters (see below). . Is that the intention? If so, we should update the readthedocs I think. If this is a bug, let's try to fix it :) I can take a look myself in that case. Just wanted to check if I misinterpreted the readthedocs. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. # load data. adata = sc.datasets.pbmc68k_reduced(). # cluster. sc.tl.leiden(adata, key_added=""clusters"", resolution=0.5). print(""Clusters:"", sorted(set(adata.obs[""clusters""]))). # do test with groups=""all"". sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=""all""). # store results, sorting genes by logfc. genes_cluster_0_vs_all = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # do test with groups=[""0"",""1""], i.e. only a subset of the clusters. sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=[""0"", ""1""]). # store result. genes_cluster_0_vs_1 = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # print top 5 genes and logfcs for both,. # they're the same and should not be. print(""Top genes cluster 0 versus all:\n"", genes_cluster_0_vs_all[:5]). print(""Top genes cluster 0 v",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1519
https://github.com/scverse/scanpy/issues/1519:1114,availability,cluster,clusters,1114,"eady been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi,. My understanding of the ""groups"" argument in sc.tl.rank_genes_groups is that it subsets the data and then performs the differential expression testing. I.e. if I have clusters 1 to 10, and I set groups=[1,2], the output will give me the genes differentially expressed in cluster 1 as compared to cluster 2 (and 2 vs 1). However, the current function still compares to all other clusters (see below). . Is that the intention? If so, we should update the readthedocs I think. If this is a bug, let's try to fix it :) I can take a look myself in that case. Just wanted to check if I misinterpreted the readthedocs. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. # load data. adata = sc.datasets.pbmc68k_reduced(). # cluster. sc.tl.leiden(adata, key_added=""clusters"", resolution=0.5). print(""Clusters:"", sorted(set(adata.obs[""clusters""]))). # do test with groups=""all"". sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=""all""). # store results, sorting genes by logfc. genes_cluster_0_vs_all = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # do test with groups=[""0"",""1""], i.e. only a subset of the clusters. sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=[""0"", ""1""]). # store result. genes_cluster_0_vs_1 = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # print top 5 genes and logfcs for both,. # they're the same and should not be. print(""Top genes cluster 0 versus all:\n"", genes_cluster_0_vs_all[:5]). print(""Top genes cluster 0 versus cluster 1:\n"", genes_cluster_0_vs_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1519
https://github.com/scverse/scanpy/issues/1519:1149,availability,Cluster,Clusters,1149,"nfirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi,. My understanding of the ""groups"" argument in sc.tl.rank_genes_groups is that it subsets the data and then performs the differential expression testing. I.e. if I have clusters 1 to 10, and I set groups=[1,2], the output will give me the genes differentially expressed in cluster 1 as compared to cluster 2 (and 2 vs 1). However, the current function still compares to all other clusters (see below). . Is that the intention? If so, we should update the readthedocs I think. If this is a bug, let's try to fix it :) I can take a look myself in that case. Just wanted to check if I misinterpreted the readthedocs. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. # load data. adata = sc.datasets.pbmc68k_reduced(). # cluster. sc.tl.leiden(adata, key_added=""clusters"", resolution=0.5). print(""Clusters:"", sorted(set(adata.obs[""clusters""]))). # do test with groups=""all"". sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=""all""). # store results, sorting genes by logfc. genes_cluster_0_vs_all = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # do test with groups=[""0"",""1""], i.e. only a subset of the clusters. sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=[""0"", ""1""]). # store result. genes_cluster_0_vs_1 = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # print top 5 genes and logfcs for both,. # they're the same and should not be. print(""Top genes cluster 0 versus all:\n"", genes_cluster_0_vs_all[:5]). print(""Top genes cluster 0 versus cluster 1:\n"", genes_cluster_0_vs_1[:5]). ```. ```pytb. Clusters: ['0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1519
https://github.com/scverse/scanpy/issues/1519:1183,availability,cluster,clusters,1183,"est version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi,. My understanding of the ""groups"" argument in sc.tl.rank_genes_groups is that it subsets the data and then performs the differential expression testing. I.e. if I have clusters 1 to 10, and I set groups=[1,2], the output will give me the genes differentially expressed in cluster 1 as compared to cluster 2 (and 2 vs 1). However, the current function still compares to all other clusters (see below). . Is that the intention? If so, we should update the readthedocs I think. If this is a bug, let's try to fix it :) I can take a look myself in that case. Just wanted to check if I misinterpreted the readthedocs. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. # load data. adata = sc.datasets.pbmc68k_reduced(). # cluster. sc.tl.leiden(adata, key_added=""clusters"", resolution=0.5). print(""Clusters:"", sorted(set(adata.obs[""clusters""]))). # do test with groups=""all"". sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=""all""). # store results, sorting genes by logfc. genes_cluster_0_vs_all = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # do test with groups=[""0"",""1""], i.e. only a subset of the clusters. sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=[""0"", ""1""]). # store result. genes_cluster_0_vs_1 = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # print top 5 genes and logfcs for both,. # they're the same and should not be. print(""Top genes cluster 0 versus all:\n"", genes_cluster_0_vs_all[:5]). print(""Top genes cluster 0 versus cluster 1:\n"", genes_cluster_0_vs_1[:5]). ```. ```pytb. Clusters: ['0', '1', '2', '3', '4', '5', '6', '",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1519
https://github.com/scverse/scanpy/issues/1519:1267,availability,cluster,clusters,1267,"er branch of scanpy. ---. Hi,. My understanding of the ""groups"" argument in sc.tl.rank_genes_groups is that it subsets the data and then performs the differential expression testing. I.e. if I have clusters 1 to 10, and I set groups=[1,2], the output will give me the genes differentially expressed in cluster 1 as compared to cluster 2 (and 2 vs 1). However, the current function still compares to all other clusters (see below). . Is that the intention? If so, we should update the readthedocs I think. If this is a bug, let's try to fix it :) I can take a look myself in that case. Just wanted to check if I misinterpreted the readthedocs. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. # load data. adata = sc.datasets.pbmc68k_reduced(). # cluster. sc.tl.leiden(adata, key_added=""clusters"", resolution=0.5). print(""Clusters:"", sorted(set(adata.obs[""clusters""]))). # do test with groups=""all"". sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=""all""). # store results, sorting genes by logfc. genes_cluster_0_vs_all = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # do test with groups=[""0"",""1""], i.e. only a subset of the clusters. sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=[""0"", ""1""]). # store result. genes_cluster_0_vs_1 = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # print top 5 genes and logfcs for both,. # they're the same and should not be. print(""Top genes cluster 0 versus all:\n"", genes_cluster_0_vs_all[:5]). print(""Top genes cluster 0 versus cluster 1:\n"", genes_cluster_0_vs_1[:5]). ```. ```pytb. Clusters: ['0', '1', '2', '3', '4', '5', '6', '7', '8']. WARNING: Default of the method has been changed to 't-test' from 't-test_o",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1519
https://github.com/scverse/scanpy/issues/1519:1598,availability,cluster,clusters,1598,"ter 2 (and 2 vs 1). However, the current function still compares to all other clusters (see below). . Is that the intention? If so, we should update the readthedocs I think. If this is a bug, let's try to fix it :) I can take a look myself in that case. Just wanted to check if I misinterpreted the readthedocs. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. # load data. adata = sc.datasets.pbmc68k_reduced(). # cluster. sc.tl.leiden(adata, key_added=""clusters"", resolution=0.5). print(""Clusters:"", sorted(set(adata.obs[""clusters""]))). # do test with groups=""all"". sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=""all""). # store results, sorting genes by logfc. genes_cluster_0_vs_all = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # do test with groups=[""0"",""1""], i.e. only a subset of the clusters. sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=[""0"", ""1""]). # store result. genes_cluster_0_vs_1 = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # print top 5 genes and logfcs for both,. # they're the same and should not be. print(""Top genes cluster 0 versus all:\n"", genes_cluster_0_vs_all[:5]). print(""Top genes cluster 0 versus cluster 1:\n"", genes_cluster_0_vs_1[:5]). ```. ```pytb. Clusters: ['0', '1', '2', '3', '4', '5', '6', '7', '8']. WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'. WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'. Top genes cluster 0 versus all:. [('LYPD2', 29.707254), ('C1QA', 7.7860994), ('FCGR3A', 7.2558727), ('HES4', 7.201066), ('C1QB', 6.6123295)]. Top genes cluster 0 versus cluster 1:. [('LYPD2', 29.707254), ('C1QA', 7.7860994), ('",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1519
https://github.com/scverse/scanpy/issues/1519:1648,availability,cluster,clusters,1648,"still compares to all other clusters (see below). . Is that the intention? If so, we should update the readthedocs I think. If this is a bug, let's try to fix it :) I can take a look myself in that case. Just wanted to check if I misinterpreted the readthedocs. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. # load data. adata = sc.datasets.pbmc68k_reduced(). # cluster. sc.tl.leiden(adata, key_added=""clusters"", resolution=0.5). print(""Clusters:"", sorted(set(adata.obs[""clusters""]))). # do test with groups=""all"". sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=""all""). # store results, sorting genes by logfc. genes_cluster_0_vs_all = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # do test with groups=[""0"",""1""], i.e. only a subset of the clusters. sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=[""0"", ""1""]). # store result. genes_cluster_0_vs_1 = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # print top 5 genes and logfcs for both,. # they're the same and should not be. print(""Top genes cluster 0 versus all:\n"", genes_cluster_0_vs_all[:5]). print(""Top genes cluster 0 versus cluster 1:\n"", genes_cluster_0_vs_1[:5]). ```. ```pytb. Clusters: ['0', '1', '2', '3', '4', '5', '6', '7', '8']. WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'. WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'. Top genes cluster 0 versus all:. [('LYPD2', 29.707254), ('C1QA', 7.7860994), ('FCGR3A', 7.2558727), ('HES4', 7.201066), ('C1QB', 6.6123295)]. Top genes cluster 0 versus cluster 1:. [('LYPD2', 29.707254), ('C1QA', 7.7860994), ('FCGR3A', 7.2558727), ('HES4', 7.201066), ('C1QB', ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1519
https://github.com/scverse/scanpy/issues/1519:1995,availability,cluster,cluster,1995,"to all other clusters (see below). . Is that the intention? If so, we should update the readthedocs I think. If this is a bug, let's try to fix it :) I can take a look myself in that case. Just wanted to check if I misinterpreted the readthedocs. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. # load data. adata = sc.datasets.pbmc68k_reduced(). # cluster. sc.tl.leiden(adata, key_added=""clusters"", resolution=0.5). print(""Clusters:"", sorted(set(adata.obs[""clusters""]))). # do test with groups=""all"". sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=""all""). # store results, sorting genes by logfc. genes_cluster_0_vs_all = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # do test with groups=[""0"",""1""], i.e. only a subset of the clusters. sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=[""0"", ""1""]). # store result. genes_cluster_0_vs_1 = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # print top 5 genes and logfcs for both,. # they're the same and should not be. print(""Top genes cluster 0 versus all:\n"", genes_cluster_0_vs_all[:5]). print(""Top genes cluster 0 versus cluster 1:\n"", genes_cluster_0_vs_1[:5]). ```. ```pytb. Clusters: ['0', '1', '2', '3', '4', '5', '6', '7', '8']. WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'. WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'. Top genes cluster 0 versus all:. [('LYPD2', 29.707254), ('C1QA', 7.7860994), ('FCGR3A', 7.2558727), ('HES4', 7.201066), ('C1QB', 6.6123295)]. Top genes cluster 0 versus cluster 1:. [('LYPD2', 29.707254), ('C1QA', 7.7860994), ('FCGR3A', 7.2558727), ('HES4', 7.201066), ('C1QB', 6.6123295)]```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1519
https://github.com/scverse/scanpy/issues/1519:2067,availability,cluster,cluster,2067,"to all other clusters (see below). . Is that the intention? If so, we should update the readthedocs I think. If this is a bug, let's try to fix it :) I can take a look myself in that case. Just wanted to check if I misinterpreted the readthedocs. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. # load data. adata = sc.datasets.pbmc68k_reduced(). # cluster. sc.tl.leiden(adata, key_added=""clusters"", resolution=0.5). print(""Clusters:"", sorted(set(adata.obs[""clusters""]))). # do test with groups=""all"". sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=""all""). # store results, sorting genes by logfc. genes_cluster_0_vs_all = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # do test with groups=[""0"",""1""], i.e. only a subset of the clusters. sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=[""0"", ""1""]). # store result. genes_cluster_0_vs_1 = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # print top 5 genes and logfcs for both,. # they're the same and should not be. print(""Top genes cluster 0 versus all:\n"", genes_cluster_0_vs_all[:5]). print(""Top genes cluster 0 versus cluster 1:\n"", genes_cluster_0_vs_1[:5]). ```. ```pytb. Clusters: ['0', '1', '2', '3', '4', '5', '6', '7', '8']. WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'. WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'. Top genes cluster 0 versus all:. [('LYPD2', 29.707254), ('C1QA', 7.7860994), ('FCGR3A', 7.2558727), ('HES4', 7.201066), ('C1QB', 6.6123295)]. Top genes cluster 0 versus cluster 1:. [('LYPD2', 29.707254), ('C1QA', 7.7860994), ('FCGR3A', 7.2558727), ('HES4', 7.201066), ('C1QB', 6.6123295)]```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1519
https://github.com/scverse/scanpy/issues/1519:2084,availability,cluster,cluster,2084,"to all other clusters (see below). . Is that the intention? If so, we should update the readthedocs I think. If this is a bug, let's try to fix it :) I can take a look myself in that case. Just wanted to check if I misinterpreted the readthedocs. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. # load data. adata = sc.datasets.pbmc68k_reduced(). # cluster. sc.tl.leiden(adata, key_added=""clusters"", resolution=0.5). print(""Clusters:"", sorted(set(adata.obs[""clusters""]))). # do test with groups=""all"". sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=""all""). # store results, sorting genes by logfc. genes_cluster_0_vs_all = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # do test with groups=[""0"",""1""], i.e. only a subset of the clusters. sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=[""0"", ""1""]). # store result. genes_cluster_0_vs_1 = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # print top 5 genes and logfcs for both,. # they're the same and should not be. print(""Top genes cluster 0 versus all:\n"", genes_cluster_0_vs_all[:5]). print(""Top genes cluster 0 versus cluster 1:\n"", genes_cluster_0_vs_1[:5]). ```. ```pytb. Clusters: ['0', '1', '2', '3', '4', '5', '6', '7', '8']. WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'. WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'. Top genes cluster 0 versus all:. [('LYPD2', 29.707254), ('C1QA', 7.7860994), ('FCGR3A', 7.2558727), ('HES4', 7.201066), ('C1QB', 6.6123295)]. Top genes cluster 0 versus cluster 1:. [('LYPD2', 29.707254), ('C1QA', 7.7860994), ('FCGR3A', 7.2558727), ('HES4', 7.201066), ('C1QB', 6.6123295)]```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1519
https://github.com/scverse/scanpy/issues/1519:2140,availability,Cluster,Clusters,2140,"to all other clusters (see below). . Is that the intention? If so, we should update the readthedocs I think. If this is a bug, let's try to fix it :) I can take a look myself in that case. Just wanted to check if I misinterpreted the readthedocs. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. # load data. adata = sc.datasets.pbmc68k_reduced(). # cluster. sc.tl.leiden(adata, key_added=""clusters"", resolution=0.5). print(""Clusters:"", sorted(set(adata.obs[""clusters""]))). # do test with groups=""all"". sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=""all""). # store results, sorting genes by logfc. genes_cluster_0_vs_all = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # do test with groups=[""0"",""1""], i.e. only a subset of the clusters. sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=[""0"", ""1""]). # store result. genes_cluster_0_vs_1 = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # print top 5 genes and logfcs for both,. # they're the same and should not be. print(""Top genes cluster 0 versus all:\n"", genes_cluster_0_vs_all[:5]). print(""Top genes cluster 0 versus cluster 1:\n"", genes_cluster_0_vs_1[:5]). ```. ```pytb. Clusters: ['0', '1', '2', '3', '4', '5', '6', '7', '8']. WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'. WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'. Top genes cluster 0 versus all:. [('LYPD2', 29.707254), ('C1QA', 7.7860994), ('FCGR3A', 7.2558727), ('HES4', 7.201066), ('C1QB', 6.6123295)]. Top genes cluster 0 versus cluster 1:. [('LYPD2', 29.707254), ('C1QA', 7.7860994), ('FCGR3A', 7.2558727), ('HES4', 7.201066), ('C1QB', 6.6123295)]```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1519
https://github.com/scverse/scanpy/issues/1519:2385,availability,cluster,cluster,2385,"to all other clusters (see below). . Is that the intention? If so, we should update the readthedocs I think. If this is a bug, let's try to fix it :) I can take a look myself in that case. Just wanted to check if I misinterpreted the readthedocs. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. # load data. adata = sc.datasets.pbmc68k_reduced(). # cluster. sc.tl.leiden(adata, key_added=""clusters"", resolution=0.5). print(""Clusters:"", sorted(set(adata.obs[""clusters""]))). # do test with groups=""all"". sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=""all""). # store results, sorting genes by logfc. genes_cluster_0_vs_all = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # do test with groups=[""0"",""1""], i.e. only a subset of the clusters. sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=[""0"", ""1""]). # store result. genes_cluster_0_vs_1 = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # print top 5 genes and logfcs for both,. # they're the same and should not be. print(""Top genes cluster 0 versus all:\n"", genes_cluster_0_vs_all[:5]). print(""Top genes cluster 0 versus cluster 1:\n"", genes_cluster_0_vs_1[:5]). ```. ```pytb. Clusters: ['0', '1', '2', '3', '4', '5', '6', '7', '8']. WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'. WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'. Top genes cluster 0 versus all:. [('LYPD2', 29.707254), ('C1QA', 7.7860994), ('FCGR3A', 7.2558727), ('HES4', 7.201066), ('C1QB', 6.6123295)]. Top genes cluster 0 versus cluster 1:. [('LYPD2', 29.707254), ('C1QA', 7.7860994), ('FCGR3A', 7.2558727), ('HES4', 7.201066), ('C1QB', 6.6123295)]```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1519
https://github.com/scverse/scanpy/issues/1519:2527,availability,cluster,cluster,2527,"to all other clusters (see below). . Is that the intention? If so, we should update the readthedocs I think. If this is a bug, let's try to fix it :) I can take a look myself in that case. Just wanted to check if I misinterpreted the readthedocs. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. # load data. adata = sc.datasets.pbmc68k_reduced(). # cluster. sc.tl.leiden(adata, key_added=""clusters"", resolution=0.5). print(""Clusters:"", sorted(set(adata.obs[""clusters""]))). # do test with groups=""all"". sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=""all""). # store results, sorting genes by logfc. genes_cluster_0_vs_all = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # do test with groups=[""0"",""1""], i.e. only a subset of the clusters. sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=[""0"", ""1""]). # store result. genes_cluster_0_vs_1 = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # print top 5 genes and logfcs for both,. # they're the same and should not be. print(""Top genes cluster 0 versus all:\n"", genes_cluster_0_vs_all[:5]). print(""Top genes cluster 0 versus cluster 1:\n"", genes_cluster_0_vs_1[:5]). ```. ```pytb. Clusters: ['0', '1', '2', '3', '4', '5', '6', '7', '8']. WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'. WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'. Top genes cluster 0 versus all:. [('LYPD2', 29.707254), ('C1QA', 7.7860994), ('FCGR3A', 7.2558727), ('HES4', 7.201066), ('C1QB', 6.6123295)]. Top genes cluster 0 versus cluster 1:. [('LYPD2', 29.707254), ('C1QA', 7.7860994), ('FCGR3A', 7.2558727), ('HES4', 7.201066), ('C1QB', 6.6123295)]```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1519
https://github.com/scverse/scanpy/issues/1519:2544,availability,cluster,cluster,2544,"to all other clusters (see below). . Is that the intention? If so, we should update the readthedocs I think. If this is a bug, let's try to fix it :) I can take a look myself in that case. Just wanted to check if I misinterpreted the readthedocs. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. # load data. adata = sc.datasets.pbmc68k_reduced(). # cluster. sc.tl.leiden(adata, key_added=""clusters"", resolution=0.5). print(""Clusters:"", sorted(set(adata.obs[""clusters""]))). # do test with groups=""all"". sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=""all""). # store results, sorting genes by logfc. genes_cluster_0_vs_all = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # do test with groups=[""0"",""1""], i.e. only a subset of the clusters. sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=[""0"", ""1""]). # store result. genes_cluster_0_vs_1 = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # print top 5 genes and logfcs for both,. # they're the same and should not be. print(""Top genes cluster 0 versus all:\n"", genes_cluster_0_vs_all[:5]). print(""Top genes cluster 0 versus cluster 1:\n"", genes_cluster_0_vs_1[:5]). ```. ```pytb. Clusters: ['0', '1', '2', '3', '4', '5', '6', '7', '8']. WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'. WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'. Top genes cluster 0 versus all:. [('LYPD2', 29.707254), ('C1QA', 7.7860994), ('FCGR3A', 7.2558727), ('HES4', 7.201066), ('C1QB', 6.6123295)]. Top genes cluster 0 versus cluster 1:. [('LYPD2', 29.707254), ('C1QA', 7.7860994), ('FCGR3A', 7.2558727), ('HES4', 7.201066), ('C1QB', 6.6123295)]```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1519
https://github.com/scverse/scanpy/issues/1519:191,deployability,version,version,191,"rank_genes_groups ""groups"" argument ignored or not clearly explained; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi,. My understanding of the ""groups"" argument in sc.tl.rank_genes_groups is that it subsets the data and then performs the differential expression testing. I.e. if I have clusters 1 to 10, and I set groups=[1,2], the output will give me the genes differentially expressed in cluster 1 as compared to cluster 2 (and 2 vs 1). However, the current function still compares to all other clusters (see below). . Is that the intention? If so, we should update the readthedocs I think. If this is a bug, let's try to fix it :) I can take a look myself in that case. Just wanted to check if I misinterpreted the readthedocs. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. # load data. adata = sc.datasets.pbmc68k_reduced(). # cluster. sc.tl.leiden(adata, key_added=""clusters"", resolution=0.5). print(""Clusters:"", sorted(set(adata.obs[""clusters""]))). # do test with groups=""all"". sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=""all""). # store results, sorting genes by logfc. genes_cluster_0_vs_all = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # do test with groups=[""0"",""1""], i.e. only a subset of the clusters. sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=[""0"", ""1""]). # store result. genes_cluster_0_vs_1 = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # print top 5 genes and logfcs for both,. # they're the same and should not be. print(""Top genes clust",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1519
https://github.com/scverse/scanpy/issues/1519:469,deployability,cluster,clusters,469,"rank_genes_groups ""groups"" argument ignored or not clearly explained; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi,. My understanding of the ""groups"" argument in sc.tl.rank_genes_groups is that it subsets the data and then performs the differential expression testing. I.e. if I have clusters 1 to 10, and I set groups=[1,2], the output will give me the genes differentially expressed in cluster 1 as compared to cluster 2 (and 2 vs 1). However, the current function still compares to all other clusters (see below). . Is that the intention? If so, we should update the readthedocs I think. If this is a bug, let's try to fix it :) I can take a look myself in that case. Just wanted to check if I misinterpreted the readthedocs. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. # load data. adata = sc.datasets.pbmc68k_reduced(). # cluster. sc.tl.leiden(adata, key_added=""clusters"", resolution=0.5). print(""Clusters:"", sorted(set(adata.obs[""clusters""]))). # do test with groups=""all"". sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=""all""). # store results, sorting genes by logfc. genes_cluster_0_vs_all = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # do test with groups=[""0"",""1""], i.e. only a subset of the clusters. sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=[""0"", ""1""]). # store result. genes_cluster_0_vs_1 = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # print top 5 genes and logfcs for both,. # they're the same and should not be. print(""Top genes clust",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1519
https://github.com/scverse/scanpy/issues/1519:573,deployability,cluster,cluster,573,"rank_genes_groups ""groups"" argument ignored or not clearly explained; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi,. My understanding of the ""groups"" argument in sc.tl.rank_genes_groups is that it subsets the data and then performs the differential expression testing. I.e. if I have clusters 1 to 10, and I set groups=[1,2], the output will give me the genes differentially expressed in cluster 1 as compared to cluster 2 (and 2 vs 1). However, the current function still compares to all other clusters (see below). . Is that the intention? If so, we should update the readthedocs I think. If this is a bug, let's try to fix it :) I can take a look myself in that case. Just wanted to check if I misinterpreted the readthedocs. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. # load data. adata = sc.datasets.pbmc68k_reduced(). # cluster. sc.tl.leiden(adata, key_added=""clusters"", resolution=0.5). print(""Clusters:"", sorted(set(adata.obs[""clusters""]))). # do test with groups=""all"". sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=""all""). # store results, sorting genes by logfc. genes_cluster_0_vs_all = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # do test with groups=[""0"",""1""], i.e. only a subset of the clusters. sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=[""0"", ""1""]). # store result. genes_cluster_0_vs_1 = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # print top 5 genes and logfcs for both,. # they're the same and should not be. print(""Top genes clust",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1519
https://github.com/scverse/scanpy/issues/1519:598,deployability,cluster,cluster,598,"rank_genes_groups ""groups"" argument ignored or not clearly explained; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi,. My understanding of the ""groups"" argument in sc.tl.rank_genes_groups is that it subsets the data and then performs the differential expression testing. I.e. if I have clusters 1 to 10, and I set groups=[1,2], the output will give me the genes differentially expressed in cluster 1 as compared to cluster 2 (and 2 vs 1). However, the current function still compares to all other clusters (see below). . Is that the intention? If so, we should update the readthedocs I think. If this is a bug, let's try to fix it :) I can take a look myself in that case. Just wanted to check if I misinterpreted the readthedocs. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. # load data. adata = sc.datasets.pbmc68k_reduced(). # cluster. sc.tl.leiden(adata, key_added=""clusters"", resolution=0.5). print(""Clusters:"", sorted(set(adata.obs[""clusters""]))). # do test with groups=""all"". sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=""all""). # store results, sorting genes by logfc. genes_cluster_0_vs_all = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # do test with groups=[""0"",""1""], i.e. only a subset of the clusters. sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=[""0"", ""1""]). # store result. genes_cluster_0_vs_1 = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # print top 5 genes and logfcs for both,. # they're the same and should not be. print(""Top genes clust",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1519
https://github.com/scverse/scanpy/issues/1519:680,deployability,cluster,clusters,680,"rank_genes_groups ""groups"" argument ignored or not clearly explained; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi,. My understanding of the ""groups"" argument in sc.tl.rank_genes_groups is that it subsets the data and then performs the differential expression testing. I.e. if I have clusters 1 to 10, and I set groups=[1,2], the output will give me the genes differentially expressed in cluster 1 as compared to cluster 2 (and 2 vs 1). However, the current function still compares to all other clusters (see below). . Is that the intention? If so, we should update the readthedocs I think. If this is a bug, let's try to fix it :) I can take a look myself in that case. Just wanted to check if I misinterpreted the readthedocs. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. # load data. adata = sc.datasets.pbmc68k_reduced(). # cluster. sc.tl.leiden(adata, key_added=""clusters"", resolution=0.5). print(""Clusters:"", sorted(set(adata.obs[""clusters""]))). # do test with groups=""all"". sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=""all""). # store results, sorting genes by logfc. genes_cluster_0_vs_all = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # do test with groups=[""0"",""1""], i.e. only a subset of the clusters. sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=[""0"", ""1""]). # store result. genes_cluster_0_vs_1 = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # print top 5 genes and logfcs for both,. # they're the same and should not be. print(""Top genes clust",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1519
https://github.com/scverse/scanpy/issues/1519:744,deployability,updat,update,744,"rank_genes_groups ""groups"" argument ignored or not clearly explained; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi,. My understanding of the ""groups"" argument in sc.tl.rank_genes_groups is that it subsets the data and then performs the differential expression testing. I.e. if I have clusters 1 to 10, and I set groups=[1,2], the output will give me the genes differentially expressed in cluster 1 as compared to cluster 2 (and 2 vs 1). However, the current function still compares to all other clusters (see below). . Is that the intention? If so, we should update the readthedocs I think. If this is a bug, let's try to fix it :) I can take a look myself in that case. Just wanted to check if I misinterpreted the readthedocs. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. # load data. adata = sc.datasets.pbmc68k_reduced(). # cluster. sc.tl.leiden(adata, key_added=""clusters"", resolution=0.5). print(""Clusters:"", sorted(set(adata.obs[""clusters""]))). # do test with groups=""all"". sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=""all""). # store results, sorting genes by logfc. genes_cluster_0_vs_all = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # do test with groups=[""0"",""1""], i.e. only a subset of the clusters. sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=[""0"", ""1""]). # store result. genes_cluster_0_vs_1 = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # print top 5 genes and logfcs for both,. # they're the same and should not be. print(""Top genes clust",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1519
https://github.com/scverse/scanpy/issues/1519:1074,deployability,cluster,cluster,1074,"have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi,. My understanding of the ""groups"" argument in sc.tl.rank_genes_groups is that it subsets the data and then performs the differential expression testing. I.e. if I have clusters 1 to 10, and I set groups=[1,2], the output will give me the genes differentially expressed in cluster 1 as compared to cluster 2 (and 2 vs 1). However, the current function still compares to all other clusters (see below). . Is that the intention? If so, we should update the readthedocs I think. If this is a bug, let's try to fix it :) I can take a look myself in that case. Just wanted to check if I misinterpreted the readthedocs. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. # load data. adata = sc.datasets.pbmc68k_reduced(). # cluster. sc.tl.leiden(adata, key_added=""clusters"", resolution=0.5). print(""Clusters:"", sorted(set(adata.obs[""clusters""]))). # do test with groups=""all"". sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=""all""). # store results, sorting genes by logfc. genes_cluster_0_vs_all = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # do test with groups=[""0"",""1""], i.e. only a subset of the clusters. sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=[""0"", ""1""]). # store result. genes_cluster_0_vs_1 = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # print top 5 genes and logfcs for both,. # they're the same and should not be. print(""Top genes cluster 0 versus all:\n"", genes_cluster_0_vs_all[:5]). print(""Top genes cluster 0 v",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1519
https://github.com/scverse/scanpy/issues/1519:1114,deployability,cluster,clusters,1114,"eady been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi,. My understanding of the ""groups"" argument in sc.tl.rank_genes_groups is that it subsets the data and then performs the differential expression testing. I.e. if I have clusters 1 to 10, and I set groups=[1,2], the output will give me the genes differentially expressed in cluster 1 as compared to cluster 2 (and 2 vs 1). However, the current function still compares to all other clusters (see below). . Is that the intention? If so, we should update the readthedocs I think. If this is a bug, let's try to fix it :) I can take a look myself in that case. Just wanted to check if I misinterpreted the readthedocs. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. # load data. adata = sc.datasets.pbmc68k_reduced(). # cluster. sc.tl.leiden(adata, key_added=""clusters"", resolution=0.5). print(""Clusters:"", sorted(set(adata.obs[""clusters""]))). # do test with groups=""all"". sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=""all""). # store results, sorting genes by logfc. genes_cluster_0_vs_all = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # do test with groups=[""0"",""1""], i.e. only a subset of the clusters. sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=[""0"", ""1""]). # store result. genes_cluster_0_vs_1 = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # print top 5 genes and logfcs for both,. # they're the same and should not be. print(""Top genes cluster 0 versus all:\n"", genes_cluster_0_vs_all[:5]). print(""Top genes cluster 0 versus cluster 1:\n"", genes_cluster_0_vs_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1519
https://github.com/scverse/scanpy/issues/1519:1149,deployability,Cluster,Clusters,1149,"nfirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi,. My understanding of the ""groups"" argument in sc.tl.rank_genes_groups is that it subsets the data and then performs the differential expression testing. I.e. if I have clusters 1 to 10, and I set groups=[1,2], the output will give me the genes differentially expressed in cluster 1 as compared to cluster 2 (and 2 vs 1). However, the current function still compares to all other clusters (see below). . Is that the intention? If so, we should update the readthedocs I think. If this is a bug, let's try to fix it :) I can take a look myself in that case. Just wanted to check if I misinterpreted the readthedocs. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. # load data. adata = sc.datasets.pbmc68k_reduced(). # cluster. sc.tl.leiden(adata, key_added=""clusters"", resolution=0.5). print(""Clusters:"", sorted(set(adata.obs[""clusters""]))). # do test with groups=""all"". sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=""all""). # store results, sorting genes by logfc. genes_cluster_0_vs_all = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # do test with groups=[""0"",""1""], i.e. only a subset of the clusters. sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=[""0"", ""1""]). # store result. genes_cluster_0_vs_1 = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # print top 5 genes and logfcs for both,. # they're the same and should not be. print(""Top genes cluster 0 versus all:\n"", genes_cluster_0_vs_all[:5]). print(""Top genes cluster 0 versus cluster 1:\n"", genes_cluster_0_vs_1[:5]). ```. ```pytb. Clusters: ['0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1519
https://github.com/scverse/scanpy/issues/1519:1183,deployability,cluster,clusters,1183,"est version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi,. My understanding of the ""groups"" argument in sc.tl.rank_genes_groups is that it subsets the data and then performs the differential expression testing. I.e. if I have clusters 1 to 10, and I set groups=[1,2], the output will give me the genes differentially expressed in cluster 1 as compared to cluster 2 (and 2 vs 1). However, the current function still compares to all other clusters (see below). . Is that the intention? If so, we should update the readthedocs I think. If this is a bug, let's try to fix it :) I can take a look myself in that case. Just wanted to check if I misinterpreted the readthedocs. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. # load data. adata = sc.datasets.pbmc68k_reduced(). # cluster. sc.tl.leiden(adata, key_added=""clusters"", resolution=0.5). print(""Clusters:"", sorted(set(adata.obs[""clusters""]))). # do test with groups=""all"". sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=""all""). # store results, sorting genes by logfc. genes_cluster_0_vs_all = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # do test with groups=[""0"",""1""], i.e. only a subset of the clusters. sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=[""0"", ""1""]). # store result. genes_cluster_0_vs_1 = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # print top 5 genes and logfcs for both,. # they're the same and should not be. print(""Top genes cluster 0 versus all:\n"", genes_cluster_0_vs_all[:5]). print(""Top genes cluster 0 versus cluster 1:\n"", genes_cluster_0_vs_1[:5]). ```. ```pytb. Clusters: ['0', '1', '2', '3', '4', '5', '6', '",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1519
https://github.com/scverse/scanpy/issues/1519:1267,deployability,cluster,clusters,1267,"er branch of scanpy. ---. Hi,. My understanding of the ""groups"" argument in sc.tl.rank_genes_groups is that it subsets the data and then performs the differential expression testing. I.e. if I have clusters 1 to 10, and I set groups=[1,2], the output will give me the genes differentially expressed in cluster 1 as compared to cluster 2 (and 2 vs 1). However, the current function still compares to all other clusters (see below). . Is that the intention? If so, we should update the readthedocs I think. If this is a bug, let's try to fix it :) I can take a look myself in that case. Just wanted to check if I misinterpreted the readthedocs. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. # load data. adata = sc.datasets.pbmc68k_reduced(). # cluster. sc.tl.leiden(adata, key_added=""clusters"", resolution=0.5). print(""Clusters:"", sorted(set(adata.obs[""clusters""]))). # do test with groups=""all"". sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=""all""). # store results, sorting genes by logfc. genes_cluster_0_vs_all = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # do test with groups=[""0"",""1""], i.e. only a subset of the clusters. sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=[""0"", ""1""]). # store result. genes_cluster_0_vs_1 = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # print top 5 genes and logfcs for both,. # they're the same and should not be. print(""Top genes cluster 0 versus all:\n"", genes_cluster_0_vs_all[:5]). print(""Top genes cluster 0 versus cluster 1:\n"", genes_cluster_0_vs_1[:5]). ```. ```pytb. Clusters: ['0', '1', '2', '3', '4', '5', '6', '7', '8']. WARNING: Default of the method has been changed to 't-test' from 't-test_o",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1519
https://github.com/scverse/scanpy/issues/1519:1327,deployability,log,logfc,1327,"ups"" argument in sc.tl.rank_genes_groups is that it subsets the data and then performs the differential expression testing. I.e. if I have clusters 1 to 10, and I set groups=[1,2], the output will give me the genes differentially expressed in cluster 1 as compared to cluster 2 (and 2 vs 1). However, the current function still compares to all other clusters (see below). . Is that the intention? If so, we should update the readthedocs I think. If this is a bug, let's try to fix it :) I can take a look myself in that case. Just wanted to check if I misinterpreted the readthedocs. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. # load data. adata = sc.datasets.pbmc68k_reduced(). # cluster. sc.tl.leiden(adata, key_added=""clusters"", resolution=0.5). print(""Clusters:"", sorted(set(adata.obs[""clusters""]))). # do test with groups=""all"". sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=""all""). # store results, sorting genes by logfc. genes_cluster_0_vs_all = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # do test with groups=[""0"",""1""], i.e. only a subset of the clusters. sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=[""0"", ""1""]). # store result. genes_cluster_0_vs_1 = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # print top 5 genes and logfcs for both,. # they're the same and should not be. print(""Top genes cluster 0 versus all:\n"", genes_cluster_0_vs_all[:5]). print(""Top genes cluster 0 versus cluster 1:\n"", genes_cluster_0_vs_1[:5]). ```. ```pytb. Clusters: ['0', '1', '2', '3', '4', '5', '6', '7', '8']. WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'. WARNING: Default of the method has been chan",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1519
https://github.com/scverse/scanpy/issues/1519:1369,deployability,log,logfc,1369,"s that it subsets the data and then performs the differential expression testing. I.e. if I have clusters 1 to 10, and I set groups=[1,2], the output will give me the genes differentially expressed in cluster 1 as compared to cluster 2 (and 2 vs 1). However, the current function still compares to all other clusters (see below). . Is that the intention? If so, we should update the readthedocs I think. If this is a bug, let's try to fix it :) I can take a look myself in that case. Just wanted to check if I misinterpreted the readthedocs. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. # load data. adata = sc.datasets.pbmc68k_reduced(). # cluster. sc.tl.leiden(adata, key_added=""clusters"", resolution=0.5). print(""Clusters:"", sorted(set(adata.obs[""clusters""]))). # do test with groups=""all"". sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=""all""). # store results, sorting genes by logfc. genes_cluster_0_vs_all = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # do test with groups=[""0"",""1""], i.e. only a subset of the clusters. sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=[""0"", ""1""]). # store result. genes_cluster_0_vs_1 = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # print top 5 genes and logfcs for both,. # they're the same and should not be. print(""Top genes cluster 0 versus all:\n"", genes_cluster_0_vs_all[:5]). print(""Top genes cluster 0 versus cluster 1:\n"", genes_cluster_0_vs_1[:5]). ```. ```pytb. Clusters: ['0', '1', '2', '3', '4', '5', '6', '7', '8']. WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'. WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1519
https://github.com/scverse/scanpy/issues/1519:1381,deployability,log,logfc,1381,"bsets the data and then performs the differential expression testing. I.e. if I have clusters 1 to 10, and I set groups=[1,2], the output will give me the genes differentially expressed in cluster 1 as compared to cluster 2 (and 2 vs 1). However, the current function still compares to all other clusters (see below). . Is that the intention? If so, we should update the readthedocs I think. If this is a bug, let's try to fix it :) I can take a look myself in that case. Just wanted to check if I misinterpreted the readthedocs. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. # load data. adata = sc.datasets.pbmc68k_reduced(). # cluster. sc.tl.leiden(adata, key_added=""clusters"", resolution=0.5). print(""Clusters:"", sorted(set(adata.obs[""clusters""]))). # do test with groups=""all"". sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=""all""). # store results, sorting genes by logfc. genes_cluster_0_vs_all = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # do test with groups=[""0"",""1""], i.e. only a subset of the clusters. sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=[""0"", ""1""]). # store result. genes_cluster_0_vs_1 = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # print top 5 genes and logfcs for both,. # they're the same and should not be. print(""Top genes cluster 0 versus all:\n"", genes_cluster_0_vs_all[:5]). print(""Top genes cluster 0 versus cluster 1:\n"", genes_cluster_0_vs_1[:5]). ```. ```pytb. Clusters: ['0', '1', '2', '3', '4', '5', '6', '7', '8']. WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'. WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'. Top genes",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1519
https://github.com/scverse/scanpy/issues/1519:1443,deployability,log,logfoldchanges,1443,"ng. I.e. if I have clusters 1 to 10, and I set groups=[1,2], the output will give me the genes differentially expressed in cluster 1 as compared to cluster 2 (and 2 vs 1). However, the current function still compares to all other clusters (see below). . Is that the intention? If so, we should update the readthedocs I think. If this is a bug, let's try to fix it :) I can take a look myself in that case. Just wanted to check if I misinterpreted the readthedocs. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. # load data. adata = sc.datasets.pbmc68k_reduced(). # cluster. sc.tl.leiden(adata, key_added=""clusters"", resolution=0.5). print(""Clusters:"", sorted(set(adata.obs[""clusters""]))). # do test with groups=""all"". sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=""all""). # store results, sorting genes by logfc. genes_cluster_0_vs_all = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # do test with groups=[""0"",""1""], i.e. only a subset of the clusters. sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=[""0"", ""1""]). # store result. genes_cluster_0_vs_1 = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # print top 5 genes and logfcs for both,. # they're the same and should not be. print(""Top genes cluster 0 versus all:\n"", genes_cluster_0_vs_all[:5]). print(""Top genes cluster 0 versus cluster 1:\n"", genes_cluster_0_vs_1[:5]). ```. ```pytb. Clusters: ['0', '1', '2', '3', '4', '5', '6', '7', '8']. WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'. WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'. Top genes cluster 0 versus all:. [('LYPD2', 29.707254), ('C1QA', 7.7860994)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1519
https://github.com/scverse/scanpy/issues/1519:1598,deployability,cluster,clusters,1598,"ter 2 (and 2 vs 1). However, the current function still compares to all other clusters (see below). . Is that the intention? If so, we should update the readthedocs I think. If this is a bug, let's try to fix it :) I can take a look myself in that case. Just wanted to check if I misinterpreted the readthedocs. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. # load data. adata = sc.datasets.pbmc68k_reduced(). # cluster. sc.tl.leiden(adata, key_added=""clusters"", resolution=0.5). print(""Clusters:"", sorted(set(adata.obs[""clusters""]))). # do test with groups=""all"". sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=""all""). # store results, sorting genes by logfc. genes_cluster_0_vs_all = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # do test with groups=[""0"",""1""], i.e. only a subset of the clusters. sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=[""0"", ""1""]). # store result. genes_cluster_0_vs_1 = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # print top 5 genes and logfcs for both,. # they're the same and should not be. print(""Top genes cluster 0 versus all:\n"", genes_cluster_0_vs_all[:5]). print(""Top genes cluster 0 versus cluster 1:\n"", genes_cluster_0_vs_1[:5]). ```. ```pytb. Clusters: ['0', '1', '2', '3', '4', '5', '6', '7', '8']. WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'. WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'. Top genes cluster 0 versus all:. [('LYPD2', 29.707254), ('C1QA', 7.7860994), ('FCGR3A', 7.2558727), ('HES4', 7.201066), ('C1QB', 6.6123295)]. Top genes cluster 0 versus cluster 1:. [('LYPD2', 29.707254), ('C1QA', 7.7860994), ('",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1519
https://github.com/scverse/scanpy/issues/1519:1648,deployability,cluster,clusters,1648,"still compares to all other clusters (see below). . Is that the intention? If so, we should update the readthedocs I think. If this is a bug, let's try to fix it :) I can take a look myself in that case. Just wanted to check if I misinterpreted the readthedocs. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. # load data. adata = sc.datasets.pbmc68k_reduced(). # cluster. sc.tl.leiden(adata, key_added=""clusters"", resolution=0.5). print(""Clusters:"", sorted(set(adata.obs[""clusters""]))). # do test with groups=""all"". sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=""all""). # store results, sorting genes by logfc. genes_cluster_0_vs_all = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # do test with groups=[""0"",""1""], i.e. only a subset of the clusters. sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=[""0"", ""1""]). # store result. genes_cluster_0_vs_1 = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # print top 5 genes and logfcs for both,. # they're the same and should not be. print(""Top genes cluster 0 versus all:\n"", genes_cluster_0_vs_all[:5]). print(""Top genes cluster 0 versus cluster 1:\n"", genes_cluster_0_vs_1[:5]). ```. ```pytb. Clusters: ['0', '1', '2', '3', '4', '5', '6', '7', '8']. WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'. WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'. Top genes cluster 0 versus all:. [('LYPD2', 29.707254), ('C1QA', 7.7860994), ('FCGR3A', 7.2558727), ('HES4', 7.201066), ('C1QB', 6.6123295)]. Top genes cluster 0 versus cluster 1:. [('LYPD2', 29.707254), ('C1QA', 7.7860994), ('FCGR3A', 7.2558727), ('HES4', 7.201066), ('C1QB', ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1519
https://github.com/scverse/scanpy/issues/1519:1728,deployability,log,logfc,1728,"to all other clusters (see below). . Is that the intention? If so, we should update the readthedocs I think. If this is a bug, let's try to fix it :) I can take a look myself in that case. Just wanted to check if I misinterpreted the readthedocs. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. # load data. adata = sc.datasets.pbmc68k_reduced(). # cluster. sc.tl.leiden(adata, key_added=""clusters"", resolution=0.5). print(""Clusters:"", sorted(set(adata.obs[""clusters""]))). # do test with groups=""all"". sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=""all""). # store results, sorting genes by logfc. genes_cluster_0_vs_all = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # do test with groups=[""0"",""1""], i.e. only a subset of the clusters. sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=[""0"", ""1""]). # store result. genes_cluster_0_vs_1 = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # print top 5 genes and logfcs for both,. # they're the same and should not be. print(""Top genes cluster 0 versus all:\n"", genes_cluster_0_vs_all[:5]). print(""Top genes cluster 0 versus cluster 1:\n"", genes_cluster_0_vs_1[:5]). ```. ```pytb. Clusters: ['0', '1', '2', '3', '4', '5', '6', '7', '8']. WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'. WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'. Top genes cluster 0 versus all:. [('LYPD2', 29.707254), ('C1QA', 7.7860994), ('FCGR3A', 7.2558727), ('HES4', 7.201066), ('C1QB', 6.6123295)]. Top genes cluster 0 versus cluster 1:. [('LYPD2', 29.707254), ('C1QA', 7.7860994), ('FCGR3A', 7.2558727), ('HES4', 7.201066), ('C1QB', 6.6123295)]```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1519
https://github.com/scverse/scanpy/issues/1519:1740,deployability,log,logfc,1740,"to all other clusters (see below). . Is that the intention? If so, we should update the readthedocs I think. If this is a bug, let's try to fix it :) I can take a look myself in that case. Just wanted to check if I misinterpreted the readthedocs. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. # load data. adata = sc.datasets.pbmc68k_reduced(). # cluster. sc.tl.leiden(adata, key_added=""clusters"", resolution=0.5). print(""Clusters:"", sorted(set(adata.obs[""clusters""]))). # do test with groups=""all"". sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=""all""). # store results, sorting genes by logfc. genes_cluster_0_vs_all = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # do test with groups=[""0"",""1""], i.e. only a subset of the clusters. sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=[""0"", ""1""]). # store result. genes_cluster_0_vs_1 = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # print top 5 genes and logfcs for both,. # they're the same and should not be. print(""Top genes cluster 0 versus all:\n"", genes_cluster_0_vs_all[:5]). print(""Top genes cluster 0 versus cluster 1:\n"", genes_cluster_0_vs_1[:5]). ```. ```pytb. Clusters: ['0', '1', '2', '3', '4', '5', '6', '7', '8']. WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'. WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'. Top genes cluster 0 versus all:. [('LYPD2', 29.707254), ('C1QA', 7.7860994), ('FCGR3A', 7.2558727), ('HES4', 7.201066), ('C1QB', 6.6123295)]. Top genes cluster 0 versus cluster 1:. [('LYPD2', 29.707254), ('C1QA', 7.7860994), ('FCGR3A', 7.2558727), ('HES4', 7.201066), ('C1QB', 6.6123295)]```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1519
https://github.com/scverse/scanpy/issues/1519:1802,deployability,log,logfoldchanges,1802,"to all other clusters (see below). . Is that the intention? If so, we should update the readthedocs I think. If this is a bug, let's try to fix it :) I can take a look myself in that case. Just wanted to check if I misinterpreted the readthedocs. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. # load data. adata = sc.datasets.pbmc68k_reduced(). # cluster. sc.tl.leiden(adata, key_added=""clusters"", resolution=0.5). print(""Clusters:"", sorted(set(adata.obs[""clusters""]))). # do test with groups=""all"". sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=""all""). # store results, sorting genes by logfc. genes_cluster_0_vs_all = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # do test with groups=[""0"",""1""], i.e. only a subset of the clusters. sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=[""0"", ""1""]). # store result. genes_cluster_0_vs_1 = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # print top 5 genes and logfcs for both,. # they're the same and should not be. print(""Top genes cluster 0 versus all:\n"", genes_cluster_0_vs_all[:5]). print(""Top genes cluster 0 versus cluster 1:\n"", genes_cluster_0_vs_1[:5]). ```. ```pytb. Clusters: ['0', '1', '2', '3', '4', '5', '6', '7', '8']. WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'. WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'. Top genes cluster 0 versus all:. [('LYPD2', 29.707254), ('C1QA', 7.7860994), ('FCGR3A', 7.2558727), ('HES4', 7.201066), ('C1QB', 6.6123295)]. Top genes cluster 0 versus cluster 1:. [('LYPD2', 29.707254), ('C1QA', 7.7860994), ('FCGR3A', 7.2558727), ('HES4', 7.201066), ('C1QB', 6.6123295)]```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1519
https://github.com/scverse/scanpy/issues/1519:1922,deployability,log,logfcs,1922,"to all other clusters (see below). . Is that the intention? If so, we should update the readthedocs I think. If this is a bug, let's try to fix it :) I can take a look myself in that case. Just wanted to check if I misinterpreted the readthedocs. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. # load data. adata = sc.datasets.pbmc68k_reduced(). # cluster. sc.tl.leiden(adata, key_added=""clusters"", resolution=0.5). print(""Clusters:"", sorted(set(adata.obs[""clusters""]))). # do test with groups=""all"". sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=""all""). # store results, sorting genes by logfc. genes_cluster_0_vs_all = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # do test with groups=[""0"",""1""], i.e. only a subset of the clusters. sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=[""0"", ""1""]). # store result. genes_cluster_0_vs_1 = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # print top 5 genes and logfcs for both,. # they're the same and should not be. print(""Top genes cluster 0 versus all:\n"", genes_cluster_0_vs_all[:5]). print(""Top genes cluster 0 versus cluster 1:\n"", genes_cluster_0_vs_1[:5]). ```. ```pytb. Clusters: ['0', '1', '2', '3', '4', '5', '6', '7', '8']. WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'. WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'. Top genes cluster 0 versus all:. [('LYPD2', 29.707254), ('C1QA', 7.7860994), ('FCGR3A', 7.2558727), ('HES4', 7.201066), ('C1QB', 6.6123295)]. Top genes cluster 0 versus cluster 1:. [('LYPD2', 29.707254), ('C1QA', 7.7860994), ('FCGR3A', 7.2558727), ('HES4', 7.201066), ('C1QB', 6.6123295)]```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1519
https://github.com/scverse/scanpy/issues/1519:1995,deployability,cluster,cluster,1995,"to all other clusters (see below). . Is that the intention? If so, we should update the readthedocs I think. If this is a bug, let's try to fix it :) I can take a look myself in that case. Just wanted to check if I misinterpreted the readthedocs. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. # load data. adata = sc.datasets.pbmc68k_reduced(). # cluster. sc.tl.leiden(adata, key_added=""clusters"", resolution=0.5). print(""Clusters:"", sorted(set(adata.obs[""clusters""]))). # do test with groups=""all"". sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=""all""). # store results, sorting genes by logfc. genes_cluster_0_vs_all = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # do test with groups=[""0"",""1""], i.e. only a subset of the clusters. sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=[""0"", ""1""]). # store result. genes_cluster_0_vs_1 = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # print top 5 genes and logfcs for both,. # they're the same and should not be. print(""Top genes cluster 0 versus all:\n"", genes_cluster_0_vs_all[:5]). print(""Top genes cluster 0 versus cluster 1:\n"", genes_cluster_0_vs_1[:5]). ```. ```pytb. Clusters: ['0', '1', '2', '3', '4', '5', '6', '7', '8']. WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'. WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'. Top genes cluster 0 versus all:. [('LYPD2', 29.707254), ('C1QA', 7.7860994), ('FCGR3A', 7.2558727), ('HES4', 7.201066), ('C1QB', 6.6123295)]. Top genes cluster 0 versus cluster 1:. [('LYPD2', 29.707254), ('C1QA', 7.7860994), ('FCGR3A', 7.2558727), ('HES4', 7.201066), ('C1QB', 6.6123295)]```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1519
https://github.com/scverse/scanpy/issues/1519:2067,deployability,cluster,cluster,2067,"to all other clusters (see below). . Is that the intention? If so, we should update the readthedocs I think. If this is a bug, let's try to fix it :) I can take a look myself in that case. Just wanted to check if I misinterpreted the readthedocs. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. # load data. adata = sc.datasets.pbmc68k_reduced(). # cluster. sc.tl.leiden(adata, key_added=""clusters"", resolution=0.5). print(""Clusters:"", sorted(set(adata.obs[""clusters""]))). # do test with groups=""all"". sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=""all""). # store results, sorting genes by logfc. genes_cluster_0_vs_all = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # do test with groups=[""0"",""1""], i.e. only a subset of the clusters. sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=[""0"", ""1""]). # store result. genes_cluster_0_vs_1 = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # print top 5 genes and logfcs for both,. # they're the same and should not be. print(""Top genes cluster 0 versus all:\n"", genes_cluster_0_vs_all[:5]). print(""Top genes cluster 0 versus cluster 1:\n"", genes_cluster_0_vs_1[:5]). ```. ```pytb. Clusters: ['0', '1', '2', '3', '4', '5', '6', '7', '8']. WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'. WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'. Top genes cluster 0 versus all:. [('LYPD2', 29.707254), ('C1QA', 7.7860994), ('FCGR3A', 7.2558727), ('HES4', 7.201066), ('C1QB', 6.6123295)]. Top genes cluster 0 versus cluster 1:. [('LYPD2', 29.707254), ('C1QA', 7.7860994), ('FCGR3A', 7.2558727), ('HES4', 7.201066), ('C1QB', 6.6123295)]```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1519
https://github.com/scverse/scanpy/issues/1519:2084,deployability,cluster,cluster,2084,"to all other clusters (see below). . Is that the intention? If so, we should update the readthedocs I think. If this is a bug, let's try to fix it :) I can take a look myself in that case. Just wanted to check if I misinterpreted the readthedocs. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. # load data. adata = sc.datasets.pbmc68k_reduced(). # cluster. sc.tl.leiden(adata, key_added=""clusters"", resolution=0.5). print(""Clusters:"", sorted(set(adata.obs[""clusters""]))). # do test with groups=""all"". sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=""all""). # store results, sorting genes by logfc. genes_cluster_0_vs_all = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # do test with groups=[""0"",""1""], i.e. only a subset of the clusters. sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=[""0"", ""1""]). # store result. genes_cluster_0_vs_1 = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # print top 5 genes and logfcs for both,. # they're the same and should not be. print(""Top genes cluster 0 versus all:\n"", genes_cluster_0_vs_all[:5]). print(""Top genes cluster 0 versus cluster 1:\n"", genes_cluster_0_vs_1[:5]). ```. ```pytb. Clusters: ['0', '1', '2', '3', '4', '5', '6', '7', '8']. WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'. WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'. Top genes cluster 0 versus all:. [('LYPD2', 29.707254), ('C1QA', 7.7860994), ('FCGR3A', 7.2558727), ('HES4', 7.201066), ('C1QB', 6.6123295)]. Top genes cluster 0 versus cluster 1:. [('LYPD2', 29.707254), ('C1QA', 7.7860994), ('FCGR3A', 7.2558727), ('HES4', 7.201066), ('C1QB', 6.6123295)]```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1519
https://github.com/scverse/scanpy/issues/1519:2140,deployability,Cluster,Clusters,2140,"to all other clusters (see below). . Is that the intention? If so, we should update the readthedocs I think. If this is a bug, let's try to fix it :) I can take a look myself in that case. Just wanted to check if I misinterpreted the readthedocs. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. # load data. adata = sc.datasets.pbmc68k_reduced(). # cluster. sc.tl.leiden(adata, key_added=""clusters"", resolution=0.5). print(""Clusters:"", sorted(set(adata.obs[""clusters""]))). # do test with groups=""all"". sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=""all""). # store results, sorting genes by logfc. genes_cluster_0_vs_all = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # do test with groups=[""0"",""1""], i.e. only a subset of the clusters. sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=[""0"", ""1""]). # store result. genes_cluster_0_vs_1 = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # print top 5 genes and logfcs for both,. # they're the same and should not be. print(""Top genes cluster 0 versus all:\n"", genes_cluster_0_vs_all[:5]). print(""Top genes cluster 0 versus cluster 1:\n"", genes_cluster_0_vs_1[:5]). ```. ```pytb. Clusters: ['0', '1', '2', '3', '4', '5', '6', '7', '8']. WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'. WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'. Top genes cluster 0 versus all:. [('LYPD2', 29.707254), ('C1QA', 7.7860994), ('FCGR3A', 7.2558727), ('HES4', 7.201066), ('C1QB', 6.6123295)]. Top genes cluster 0 versus cluster 1:. [('LYPD2', 29.707254), ('C1QA', 7.7860994), ('FCGR3A', 7.2558727), ('HES4', 7.201066), ('C1QB', 6.6123295)]```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1519
https://github.com/scverse/scanpy/issues/1519:2385,deployability,cluster,cluster,2385,"to all other clusters (see below). . Is that the intention? If so, we should update the readthedocs I think. If this is a bug, let's try to fix it :) I can take a look myself in that case. Just wanted to check if I misinterpreted the readthedocs. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. # load data. adata = sc.datasets.pbmc68k_reduced(). # cluster. sc.tl.leiden(adata, key_added=""clusters"", resolution=0.5). print(""Clusters:"", sorted(set(adata.obs[""clusters""]))). # do test with groups=""all"". sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=""all""). # store results, sorting genes by logfc. genes_cluster_0_vs_all = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # do test with groups=[""0"",""1""], i.e. only a subset of the clusters. sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=[""0"", ""1""]). # store result. genes_cluster_0_vs_1 = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # print top 5 genes and logfcs for both,. # they're the same and should not be. print(""Top genes cluster 0 versus all:\n"", genes_cluster_0_vs_all[:5]). print(""Top genes cluster 0 versus cluster 1:\n"", genes_cluster_0_vs_1[:5]). ```. ```pytb. Clusters: ['0', '1', '2', '3', '4', '5', '6', '7', '8']. WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'. WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'. Top genes cluster 0 versus all:. [('LYPD2', 29.707254), ('C1QA', 7.7860994), ('FCGR3A', 7.2558727), ('HES4', 7.201066), ('C1QB', 6.6123295)]. Top genes cluster 0 versus cluster 1:. [('LYPD2', 29.707254), ('C1QA', 7.7860994), ('FCGR3A', 7.2558727), ('HES4', 7.201066), ('C1QB', 6.6123295)]```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1519
https://github.com/scverse/scanpy/issues/1519:2527,deployability,cluster,cluster,2527,"to all other clusters (see below). . Is that the intention? If so, we should update the readthedocs I think. If this is a bug, let's try to fix it :) I can take a look myself in that case. Just wanted to check if I misinterpreted the readthedocs. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. # load data. adata = sc.datasets.pbmc68k_reduced(). # cluster. sc.tl.leiden(adata, key_added=""clusters"", resolution=0.5). print(""Clusters:"", sorted(set(adata.obs[""clusters""]))). # do test with groups=""all"". sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=""all""). # store results, sorting genes by logfc. genes_cluster_0_vs_all = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # do test with groups=[""0"",""1""], i.e. only a subset of the clusters. sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=[""0"", ""1""]). # store result. genes_cluster_0_vs_1 = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # print top 5 genes and logfcs for both,. # they're the same and should not be. print(""Top genes cluster 0 versus all:\n"", genes_cluster_0_vs_all[:5]). print(""Top genes cluster 0 versus cluster 1:\n"", genes_cluster_0_vs_1[:5]). ```. ```pytb. Clusters: ['0', '1', '2', '3', '4', '5', '6', '7', '8']. WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'. WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'. Top genes cluster 0 versus all:. [('LYPD2', 29.707254), ('C1QA', 7.7860994), ('FCGR3A', 7.2558727), ('HES4', 7.201066), ('C1QB', 6.6123295)]. Top genes cluster 0 versus cluster 1:. [('LYPD2', 29.707254), ('C1QA', 7.7860994), ('FCGR3A', 7.2558727), ('HES4', 7.201066), ('C1QB', 6.6123295)]```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1519
https://github.com/scverse/scanpy/issues/1519:2544,deployability,cluster,cluster,2544,"to all other clusters (see below). . Is that the intention? If so, we should update the readthedocs I think. If this is a bug, let's try to fix it :) I can take a look myself in that case. Just wanted to check if I misinterpreted the readthedocs. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. # load data. adata = sc.datasets.pbmc68k_reduced(). # cluster. sc.tl.leiden(adata, key_added=""clusters"", resolution=0.5). print(""Clusters:"", sorted(set(adata.obs[""clusters""]))). # do test with groups=""all"". sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=""all""). # store results, sorting genes by logfc. genes_cluster_0_vs_all = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # do test with groups=[""0"",""1""], i.e. only a subset of the clusters. sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=[""0"", ""1""]). # store result. genes_cluster_0_vs_1 = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # print top 5 genes and logfcs for both,. # they're the same and should not be. print(""Top genes cluster 0 versus all:\n"", genes_cluster_0_vs_all[:5]). print(""Top genes cluster 0 versus cluster 1:\n"", genes_cluster_0_vs_1[:5]). ```. ```pytb. Clusters: ['0', '1', '2', '3', '4', '5', '6', '7', '8']. WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'. WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'. Top genes cluster 0 versus all:. [('LYPD2', 29.707254), ('C1QA', 7.7860994), ('FCGR3A', 7.2558727), ('HES4', 7.201066), ('C1QB', 6.6123295)]. Top genes cluster 0 versus cluster 1:. [('LYPD2', 29.707254), ('C1QA', 7.7860994), ('FCGR3A', 7.2558727), ('HES4', 7.201066), ('C1QB', 6.6123295)]```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1519
https://github.com/scverse/scanpy/issues/1519:635,energy efficiency,current,current,635,"rank_genes_groups ""groups"" argument ignored or not clearly explained; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi,. My understanding of the ""groups"" argument in sc.tl.rank_genes_groups is that it subsets the data and then performs the differential expression testing. I.e. if I have clusters 1 to 10, and I set groups=[1,2], the output will give me the genes differentially expressed in cluster 1 as compared to cluster 2 (and 2 vs 1). However, the current function still compares to all other clusters (see below). . Is that the intention? If so, we should update the readthedocs I think. If this is a bug, let's try to fix it :) I can take a look myself in that case. Just wanted to check if I misinterpreted the readthedocs. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. # load data. adata = sc.datasets.pbmc68k_reduced(). # cluster. sc.tl.leiden(adata, key_added=""clusters"", resolution=0.5). print(""Clusters:"", sorted(set(adata.obs[""clusters""]))). # do test with groups=""all"". sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=""all""). # store results, sorting genes by logfc. genes_cluster_0_vs_all = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # do test with groups=[""0"",""1""], i.e. only a subset of the clusters. sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=[""0"", ""1""]). # store result. genes_cluster_0_vs_1 = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # print top 5 genes and logfcs for both,. # they're the same and should not be. print(""Top genes clust",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1519
https://github.com/scverse/scanpy/issues/1519:1022,energy efficiency,load,load,1022,"s"" argument ignored or not clearly explained; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi,. My understanding of the ""groups"" argument in sc.tl.rank_genes_groups is that it subsets the data and then performs the differential expression testing. I.e. if I have clusters 1 to 10, and I set groups=[1,2], the output will give me the genes differentially expressed in cluster 1 as compared to cluster 2 (and 2 vs 1). However, the current function still compares to all other clusters (see below). . Is that the intention? If so, we should update the readthedocs I think. If this is a bug, let's try to fix it :) I can take a look myself in that case. Just wanted to check if I misinterpreted the readthedocs. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. # load data. adata = sc.datasets.pbmc68k_reduced(). # cluster. sc.tl.leiden(adata, key_added=""clusters"", resolution=0.5). print(""Clusters:"", sorted(set(adata.obs[""clusters""]))). # do test with groups=""all"". sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=""all""). # store results, sorting genes by logfc. genes_cluster_0_vs_all = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # do test with groups=[""0"",""1""], i.e. only a subset of the clusters. sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=[""0"", ""1""]). # store result. genes_cluster_0_vs_1 = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # print top 5 genes and logfcs for both,. # they're the same and should not be. print(""Top genes cluster 0 versus all:\n"", gen",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1519
https://github.com/scverse/scanpy/issues/1519:191,integrability,version,version,191,"rank_genes_groups ""groups"" argument ignored or not clearly explained; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi,. My understanding of the ""groups"" argument in sc.tl.rank_genes_groups is that it subsets the data and then performs the differential expression testing. I.e. if I have clusters 1 to 10, and I set groups=[1,2], the output will give me the genes differentially expressed in cluster 1 as compared to cluster 2 (and 2 vs 1). However, the current function still compares to all other clusters (see below). . Is that the intention? If so, we should update the readthedocs I think. If this is a bug, let's try to fix it :) I can take a look myself in that case. Just wanted to check if I misinterpreted the readthedocs. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. # load data. adata = sc.datasets.pbmc68k_reduced(). # cluster. sc.tl.leiden(adata, key_added=""clusters"", resolution=0.5). print(""Clusters:"", sorted(set(adata.obs[""clusters""]))). # do test with groups=""all"". sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=""all""). # store results, sorting genes by logfc. genes_cluster_0_vs_all = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # do test with groups=[""0"",""1""], i.e. only a subset of the clusters. sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=[""0"", ""1""]). # store result. genes_cluster_0_vs_1 = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # print top 5 genes and logfcs for both,. # they're the same and should not be. print(""Top genes clust",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1519
https://github.com/scverse/scanpy/issues/1519:382,integrability,sub,subsets,382,"rank_genes_groups ""groups"" argument ignored or not clearly explained; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi,. My understanding of the ""groups"" argument in sc.tl.rank_genes_groups is that it subsets the data and then performs the differential expression testing. I.e. if I have clusters 1 to 10, and I set groups=[1,2], the output will give me the genes differentially expressed in cluster 1 as compared to cluster 2 (and 2 vs 1). However, the current function still compares to all other clusters (see below). . Is that the intention? If so, we should update the readthedocs I think. If this is a bug, let's try to fix it :) I can take a look myself in that case. Just wanted to check if I misinterpreted the readthedocs. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. # load data. adata = sc.datasets.pbmc68k_reduced(). # cluster. sc.tl.leiden(adata, key_added=""clusters"", resolution=0.5). print(""Clusters:"", sorted(set(adata.obs[""clusters""]))). # do test with groups=""all"". sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=""all""). # store results, sorting genes by logfc. genes_cluster_0_vs_all = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # do test with groups=[""0"",""1""], i.e. only a subset of the clusters. sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=[""0"", ""1""]). # store result. genes_cluster_0_vs_1 = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # print top 5 genes and logfcs for both,. # they're the same and should not be. print(""Top genes clust",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1519
https://github.com/scverse/scanpy/issues/1519:1584,integrability,sub,subset,1584,"ompared to cluster 2 (and 2 vs 1). However, the current function still compares to all other clusters (see below). . Is that the intention? If so, we should update the readthedocs I think. If this is a bug, let's try to fix it :) I can take a look myself in that case. Just wanted to check if I misinterpreted the readthedocs. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. # load data. adata = sc.datasets.pbmc68k_reduced(). # cluster. sc.tl.leiden(adata, key_added=""clusters"", resolution=0.5). print(""Clusters:"", sorted(set(adata.obs[""clusters""]))). # do test with groups=""all"". sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=""all""). # store results, sorting genes by logfc. genes_cluster_0_vs_all = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # do test with groups=[""0"",""1""], i.e. only a subset of the clusters. sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=[""0"", ""1""]). # store result. genes_cluster_0_vs_1 = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # print top 5 genes and logfcs for both,. # they're the same and should not be. print(""Top genes cluster 0 versus all:\n"", genes_cluster_0_vs_all[:5]). print(""Top genes cluster 0 versus cluster 1:\n"", genes_cluster_0_vs_1[:5]). ```. ```pytb. Clusters: ['0', '1', '2', '3', '4', '5', '6', '7', '8']. WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'. WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'. Top genes cluster 0 versus all:. [('LYPD2', 29.707254), ('C1QA', 7.7860994), ('FCGR3A', 7.2558727), ('HES4', 7.201066), ('C1QB', 6.6123295)]. Top genes cluster 0 versus cluster 1:. [('LYPD2', 29.707254), ('C1QA',",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1519
https://github.com/scverse/scanpy/issues/1519:191,modifiability,version,version,191,"rank_genes_groups ""groups"" argument ignored or not clearly explained; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi,. My understanding of the ""groups"" argument in sc.tl.rank_genes_groups is that it subsets the data and then performs the differential expression testing. I.e. if I have clusters 1 to 10, and I set groups=[1,2], the output will give me the genes differentially expressed in cluster 1 as compared to cluster 2 (and 2 vs 1). However, the current function still compares to all other clusters (see below). . Is that the intention? If so, we should update the readthedocs I think. If this is a bug, let's try to fix it :) I can take a look myself in that case. Just wanted to check if I misinterpreted the readthedocs. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. # load data. adata = sc.datasets.pbmc68k_reduced(). # cluster. sc.tl.leiden(adata, key_added=""clusters"", resolution=0.5). print(""Clusters:"", sorted(set(adata.obs[""clusters""]))). # do test with groups=""all"". sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=""all""). # store results, sorting genes by logfc. genes_cluster_0_vs_all = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # do test with groups=[""0"",""1""], i.e. only a subset of the clusters. sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=[""0"", ""1""]). # store result. genes_cluster_0_vs_1 = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # print top 5 genes and logfcs for both,. # they're the same and should not be. print(""Top genes clust",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1519
https://github.com/scverse/scanpy/issues/1519:408,performance,perform,performs,408,"rank_genes_groups ""groups"" argument ignored or not clearly explained; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi,. My understanding of the ""groups"" argument in sc.tl.rank_genes_groups is that it subsets the data and then performs the differential expression testing. I.e. if I have clusters 1 to 10, and I set groups=[1,2], the output will give me the genes differentially expressed in cluster 1 as compared to cluster 2 (and 2 vs 1). However, the current function still compares to all other clusters (see below). . Is that the intention? If so, we should update the readthedocs I think. If this is a bug, let's try to fix it :) I can take a look myself in that case. Just wanted to check if I misinterpreted the readthedocs. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. # load data. adata = sc.datasets.pbmc68k_reduced(). # cluster. sc.tl.leiden(adata, key_added=""clusters"", resolution=0.5). print(""Clusters:"", sorted(set(adata.obs[""clusters""]))). # do test with groups=""all"". sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=""all""). # store results, sorting genes by logfc. genes_cluster_0_vs_all = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # do test with groups=[""0"",""1""], i.e. only a subset of the clusters. sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=[""0"", ""1""]). # store result. genes_cluster_0_vs_1 = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # print top 5 genes and logfcs for both,. # they're the same and should not be. print(""Top genes clust",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1519
https://github.com/scverse/scanpy/issues/1519:1022,performance,load,load,1022,"s"" argument ignored or not clearly explained; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi,. My understanding of the ""groups"" argument in sc.tl.rank_genes_groups is that it subsets the data and then performs the differential expression testing. I.e. if I have clusters 1 to 10, and I set groups=[1,2], the output will give me the genes differentially expressed in cluster 1 as compared to cluster 2 (and 2 vs 1). However, the current function still compares to all other clusters (see below). . Is that the intention? If so, we should update the readthedocs I think. If this is a bug, let's try to fix it :) I can take a look myself in that case. Just wanted to check if I misinterpreted the readthedocs. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. # load data. adata = sc.datasets.pbmc68k_reduced(). # cluster. sc.tl.leiden(adata, key_added=""clusters"", resolution=0.5). print(""Clusters:"", sorted(set(adata.obs[""clusters""]))). # do test with groups=""all"". sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=""all""). # store results, sorting genes by logfc. genes_cluster_0_vs_all = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # do test with groups=[""0"",""1""], i.e. only a subset of the clusters. sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=[""0"", ""1""]). # store result. genes_cluster_0_vs_1 = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # print top 5 genes and logfcs for both,. # they're the same and should not be. print(""Top genes cluster 0 versus all:\n"", gen",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1519
https://github.com/scverse/scanpy/issues/1519:445,safety,test,testing,445,"rank_genes_groups ""groups"" argument ignored or not clearly explained; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi,. My understanding of the ""groups"" argument in sc.tl.rank_genes_groups is that it subsets the data and then performs the differential expression testing. I.e. if I have clusters 1 to 10, and I set groups=[1,2], the output will give me the genes differentially expressed in cluster 1 as compared to cluster 2 (and 2 vs 1). However, the current function still compares to all other clusters (see below). . Is that the intention? If so, we should update the readthedocs I think. If this is a bug, let's try to fix it :) I can take a look myself in that case. Just wanted to check if I misinterpreted the readthedocs. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. # load data. adata = sc.datasets.pbmc68k_reduced(). # cluster. sc.tl.leiden(adata, key_added=""clusters"", resolution=0.5). print(""Clusters:"", sorted(set(adata.obs[""clusters""]))). # do test with groups=""all"". sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=""all""). # store results, sorting genes by logfc. genes_cluster_0_vs_all = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # do test with groups=[""0"",""1""], i.e. only a subset of the clusters. sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=[""0"", ""1""]). # store result. genes_cluster_0_vs_1 = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # print top 5 genes and logfcs for both,. # they're the same and should not be. print(""Top genes clust",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1519
https://github.com/scverse/scanpy/issues/1519:744,safety,updat,update,744,"rank_genes_groups ""groups"" argument ignored or not clearly explained; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi,. My understanding of the ""groups"" argument in sc.tl.rank_genes_groups is that it subsets the data and then performs the differential expression testing. I.e. if I have clusters 1 to 10, and I set groups=[1,2], the output will give me the genes differentially expressed in cluster 1 as compared to cluster 2 (and 2 vs 1). However, the current function still compares to all other clusters (see below). . Is that the intention? If so, we should update the readthedocs I think. If this is a bug, let's try to fix it :) I can take a look myself in that case. Just wanted to check if I misinterpreted the readthedocs. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. # load data. adata = sc.datasets.pbmc68k_reduced(). # cluster. sc.tl.leiden(adata, key_added=""clusters"", resolution=0.5). print(""Clusters:"", sorted(set(adata.obs[""clusters""]))). # do test with groups=""all"". sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=""all""). # store results, sorting genes by logfc. genes_cluster_0_vs_all = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # do test with groups=[""0"",""1""], i.e. only a subset of the clusters. sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=[""0"", ""1""]). # store result. genes_cluster_0_vs_1 = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # print top 5 genes and logfcs for both,. # they're the same and should not be. print(""Top genes clust",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1519
https://github.com/scverse/scanpy/issues/1519:1203,safety,test,test,1203,"npy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi,. My understanding of the ""groups"" argument in sc.tl.rank_genes_groups is that it subsets the data and then performs the differential expression testing. I.e. if I have clusters 1 to 10, and I set groups=[1,2], the output will give me the genes differentially expressed in cluster 1 as compared to cluster 2 (and 2 vs 1). However, the current function still compares to all other clusters (see below). . Is that the intention? If so, we should update the readthedocs I think. If this is a bug, let's try to fix it :) I can take a look myself in that case. Just wanted to check if I misinterpreted the readthedocs. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. # load data. adata = sc.datasets.pbmc68k_reduced(). # cluster. sc.tl.leiden(adata, key_added=""clusters"", resolution=0.5). print(""Clusters:"", sorted(set(adata.obs[""clusters""]))). # do test with groups=""all"". sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=""all""). # store results, sorting genes by logfc. genes_cluster_0_vs_all = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # do test with groups=[""0"",""1""], i.e. only a subset of the clusters. sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=[""0"", ""1""]). # store result. genes_cluster_0_vs_1 = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # print top 5 genes and logfcs for both,. # they're the same and should not be. print(""Top genes cluster 0 versus all:\n"", genes_cluster_0_vs_all[:5]). print(""Top genes cluster 0 versus cluster 1:\n"", genes_cluster_0_vs_1[:5]). ```. ```pytb. Clusters: ['0', '1', '2', '3', '4', '5', '6', '7', '8']. WARNING:",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1519
https://github.com/scverse/scanpy/issues/1519:1327,safety,log,logfc,1327,"ups"" argument in sc.tl.rank_genes_groups is that it subsets the data and then performs the differential expression testing. I.e. if I have clusters 1 to 10, and I set groups=[1,2], the output will give me the genes differentially expressed in cluster 1 as compared to cluster 2 (and 2 vs 1). However, the current function still compares to all other clusters (see below). . Is that the intention? If so, we should update the readthedocs I think. If this is a bug, let's try to fix it :) I can take a look myself in that case. Just wanted to check if I misinterpreted the readthedocs. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. # load data. adata = sc.datasets.pbmc68k_reduced(). # cluster. sc.tl.leiden(adata, key_added=""clusters"", resolution=0.5). print(""Clusters:"", sorted(set(adata.obs[""clusters""]))). # do test with groups=""all"". sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=""all""). # store results, sorting genes by logfc. genes_cluster_0_vs_all = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # do test with groups=[""0"",""1""], i.e. only a subset of the clusters. sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=[""0"", ""1""]). # store result. genes_cluster_0_vs_1 = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # print top 5 genes and logfcs for both,. # they're the same and should not be. print(""Top genes cluster 0 versus all:\n"", genes_cluster_0_vs_all[:5]). print(""Top genes cluster 0 versus cluster 1:\n"", genes_cluster_0_vs_1[:5]). ```. ```pytb. Clusters: ['0', '1', '2', '3', '4', '5', '6', '7', '8']. WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'. WARNING: Default of the method has been chan",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1519
https://github.com/scverse/scanpy/issues/1519:1369,safety,log,logfc,1369,"s that it subsets the data and then performs the differential expression testing. I.e. if I have clusters 1 to 10, and I set groups=[1,2], the output will give me the genes differentially expressed in cluster 1 as compared to cluster 2 (and 2 vs 1). However, the current function still compares to all other clusters (see below). . Is that the intention? If so, we should update the readthedocs I think. If this is a bug, let's try to fix it :) I can take a look myself in that case. Just wanted to check if I misinterpreted the readthedocs. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. # load data. adata = sc.datasets.pbmc68k_reduced(). # cluster. sc.tl.leiden(adata, key_added=""clusters"", resolution=0.5). print(""Clusters:"", sorted(set(adata.obs[""clusters""]))). # do test with groups=""all"". sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=""all""). # store results, sorting genes by logfc. genes_cluster_0_vs_all = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # do test with groups=[""0"",""1""], i.e. only a subset of the clusters. sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=[""0"", ""1""]). # store result. genes_cluster_0_vs_1 = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # print top 5 genes and logfcs for both,. # they're the same and should not be. print(""Top genes cluster 0 versus all:\n"", genes_cluster_0_vs_all[:5]). print(""Top genes cluster 0 versus cluster 1:\n"", genes_cluster_0_vs_1[:5]). ```. ```pytb. Clusters: ['0', '1', '2', '3', '4', '5', '6', '7', '8']. WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'. WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1519
https://github.com/scverse/scanpy/issues/1519:1381,safety,log,logfc,1381,"bsets the data and then performs the differential expression testing. I.e. if I have clusters 1 to 10, and I set groups=[1,2], the output will give me the genes differentially expressed in cluster 1 as compared to cluster 2 (and 2 vs 1). However, the current function still compares to all other clusters (see below). . Is that the intention? If so, we should update the readthedocs I think. If this is a bug, let's try to fix it :) I can take a look myself in that case. Just wanted to check if I misinterpreted the readthedocs. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. # load data. adata = sc.datasets.pbmc68k_reduced(). # cluster. sc.tl.leiden(adata, key_added=""clusters"", resolution=0.5). print(""Clusters:"", sorted(set(adata.obs[""clusters""]))). # do test with groups=""all"". sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=""all""). # store results, sorting genes by logfc. genes_cluster_0_vs_all = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # do test with groups=[""0"",""1""], i.e. only a subset of the clusters. sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=[""0"", ""1""]). # store result. genes_cluster_0_vs_1 = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # print top 5 genes and logfcs for both,. # they're the same and should not be. print(""Top genes cluster 0 versus all:\n"", genes_cluster_0_vs_all[:5]). print(""Top genes cluster 0 versus cluster 1:\n"", genes_cluster_0_vs_1[:5]). ```. ```pytb. Clusters: ['0', '1', '2', '3', '4', '5', '6', '7', '8']. WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'. WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'. Top genes",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1519
https://github.com/scverse/scanpy/issues/1519:1443,safety,log,logfoldchanges,1443,"ng. I.e. if I have clusters 1 to 10, and I set groups=[1,2], the output will give me the genes differentially expressed in cluster 1 as compared to cluster 2 (and 2 vs 1). However, the current function still compares to all other clusters (see below). . Is that the intention? If so, we should update the readthedocs I think. If this is a bug, let's try to fix it :) I can take a look myself in that case. Just wanted to check if I misinterpreted the readthedocs. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. # load data. adata = sc.datasets.pbmc68k_reduced(). # cluster. sc.tl.leiden(adata, key_added=""clusters"", resolution=0.5). print(""Clusters:"", sorted(set(adata.obs[""clusters""]))). # do test with groups=""all"". sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=""all""). # store results, sorting genes by logfc. genes_cluster_0_vs_all = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # do test with groups=[""0"",""1""], i.e. only a subset of the clusters. sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=[""0"", ""1""]). # store result. genes_cluster_0_vs_1 = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # print top 5 genes and logfcs for both,. # they're the same and should not be. print(""Top genes cluster 0 versus all:\n"", genes_cluster_0_vs_all[:5]). print(""Top genes cluster 0 versus cluster 1:\n"", genes_cluster_0_vs_1[:5]). ```. ```pytb. Clusters: ['0', '1', '2', '3', '4', '5', '6', '7', '8']. WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'. WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'. Top genes cluster 0 versus all:. [('LYPD2', 29.707254), ('C1QA', 7.7860994)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1519
https://github.com/scverse/scanpy/issues/1519:1544,safety,test,test,1544,"ifferentially expressed in cluster 1 as compared to cluster 2 (and 2 vs 1). However, the current function still compares to all other clusters (see below). . Is that the intention? If so, we should update the readthedocs I think. If this is a bug, let's try to fix it :) I can take a look myself in that case. Just wanted to check if I misinterpreted the readthedocs. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. # load data. adata = sc.datasets.pbmc68k_reduced(). # cluster. sc.tl.leiden(adata, key_added=""clusters"", resolution=0.5). print(""Clusters:"", sorted(set(adata.obs[""clusters""]))). # do test with groups=""all"". sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=""all""). # store results, sorting genes by logfc. genes_cluster_0_vs_all = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # do test with groups=[""0"",""1""], i.e. only a subset of the clusters. sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=[""0"", ""1""]). # store result. genes_cluster_0_vs_1 = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # print top 5 genes and logfcs for both,. # they're the same and should not be. print(""Top genes cluster 0 versus all:\n"", genes_cluster_0_vs_all[:5]). print(""Top genes cluster 0 versus cluster 1:\n"", genes_cluster_0_vs_1[:5]). ```. ```pytb. Clusters: ['0', '1', '2', '3', '4', '5', '6', '7', '8']. WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'. WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'. Top genes cluster 0 versus all:. [('LYPD2', 29.707254), ('C1QA', 7.7860994), ('FCGR3A', 7.2558727), ('HES4', 7.201066), ('C1QB', 6.6123295)]. Top genes cluster 0 versus cl",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1519
https://github.com/scverse/scanpy/issues/1519:1728,safety,log,logfc,1728,"to all other clusters (see below). . Is that the intention? If so, we should update the readthedocs I think. If this is a bug, let's try to fix it :) I can take a look myself in that case. Just wanted to check if I misinterpreted the readthedocs. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. # load data. adata = sc.datasets.pbmc68k_reduced(). # cluster. sc.tl.leiden(adata, key_added=""clusters"", resolution=0.5). print(""Clusters:"", sorted(set(adata.obs[""clusters""]))). # do test with groups=""all"". sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=""all""). # store results, sorting genes by logfc. genes_cluster_0_vs_all = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # do test with groups=[""0"",""1""], i.e. only a subset of the clusters. sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=[""0"", ""1""]). # store result. genes_cluster_0_vs_1 = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # print top 5 genes and logfcs for both,. # they're the same and should not be. print(""Top genes cluster 0 versus all:\n"", genes_cluster_0_vs_all[:5]). print(""Top genes cluster 0 versus cluster 1:\n"", genes_cluster_0_vs_1[:5]). ```. ```pytb. Clusters: ['0', '1', '2', '3', '4', '5', '6', '7', '8']. WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'. WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'. Top genes cluster 0 versus all:. [('LYPD2', 29.707254), ('C1QA', 7.7860994), ('FCGR3A', 7.2558727), ('HES4', 7.201066), ('C1QB', 6.6123295)]. Top genes cluster 0 versus cluster 1:. [('LYPD2', 29.707254), ('C1QA', 7.7860994), ('FCGR3A', 7.2558727), ('HES4', 7.201066), ('C1QB', 6.6123295)]```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1519
https://github.com/scverse/scanpy/issues/1519:1740,safety,log,logfc,1740,"to all other clusters (see below). . Is that the intention? If so, we should update the readthedocs I think. If this is a bug, let's try to fix it :) I can take a look myself in that case. Just wanted to check if I misinterpreted the readthedocs. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. # load data. adata = sc.datasets.pbmc68k_reduced(). # cluster. sc.tl.leiden(adata, key_added=""clusters"", resolution=0.5). print(""Clusters:"", sorted(set(adata.obs[""clusters""]))). # do test with groups=""all"". sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=""all""). # store results, sorting genes by logfc. genes_cluster_0_vs_all = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # do test with groups=[""0"",""1""], i.e. only a subset of the clusters. sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=[""0"", ""1""]). # store result. genes_cluster_0_vs_1 = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # print top 5 genes and logfcs for both,. # they're the same and should not be. print(""Top genes cluster 0 versus all:\n"", genes_cluster_0_vs_all[:5]). print(""Top genes cluster 0 versus cluster 1:\n"", genes_cluster_0_vs_1[:5]). ```. ```pytb. Clusters: ['0', '1', '2', '3', '4', '5', '6', '7', '8']. WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'. WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'. Top genes cluster 0 versus all:. [('LYPD2', 29.707254), ('C1QA', 7.7860994), ('FCGR3A', 7.2558727), ('HES4', 7.201066), ('C1QB', 6.6123295)]. Top genes cluster 0 versus cluster 1:. [('LYPD2', 29.707254), ('C1QA', 7.7860994), ('FCGR3A', 7.2558727), ('HES4', 7.201066), ('C1QB', 6.6123295)]```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1519
https://github.com/scverse/scanpy/issues/1519:1802,safety,log,logfoldchanges,1802,"to all other clusters (see below). . Is that the intention? If so, we should update the readthedocs I think. If this is a bug, let's try to fix it :) I can take a look myself in that case. Just wanted to check if I misinterpreted the readthedocs. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. # load data. adata = sc.datasets.pbmc68k_reduced(). # cluster. sc.tl.leiden(adata, key_added=""clusters"", resolution=0.5). print(""Clusters:"", sorted(set(adata.obs[""clusters""]))). # do test with groups=""all"". sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=""all""). # store results, sorting genes by logfc. genes_cluster_0_vs_all = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # do test with groups=[""0"",""1""], i.e. only a subset of the clusters. sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=[""0"", ""1""]). # store result. genes_cluster_0_vs_1 = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # print top 5 genes and logfcs for both,. # they're the same and should not be. print(""Top genes cluster 0 versus all:\n"", genes_cluster_0_vs_all[:5]). print(""Top genes cluster 0 versus cluster 1:\n"", genes_cluster_0_vs_1[:5]). ```. ```pytb. Clusters: ['0', '1', '2', '3', '4', '5', '6', '7', '8']. WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'. WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'. Top genes cluster 0 versus all:. [('LYPD2', 29.707254), ('C1QA', 7.7860994), ('FCGR3A', 7.2558727), ('HES4', 7.201066), ('C1QB', 6.6123295)]. Top genes cluster 0 versus cluster 1:. [('LYPD2', 29.707254), ('C1QA', 7.7860994), ('FCGR3A', 7.2558727), ('HES4', 7.201066), ('C1QB', 6.6123295)]```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1519
https://github.com/scverse/scanpy/issues/1519:1922,safety,log,logfcs,1922,"to all other clusters (see below). . Is that the intention? If so, we should update the readthedocs I think. If this is a bug, let's try to fix it :) I can take a look myself in that case. Just wanted to check if I misinterpreted the readthedocs. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. # load data. adata = sc.datasets.pbmc68k_reduced(). # cluster. sc.tl.leiden(adata, key_added=""clusters"", resolution=0.5). print(""Clusters:"", sorted(set(adata.obs[""clusters""]))). # do test with groups=""all"". sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=""all""). # store results, sorting genes by logfc. genes_cluster_0_vs_all = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # do test with groups=[""0"",""1""], i.e. only a subset of the clusters. sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=[""0"", ""1""]). # store result. genes_cluster_0_vs_1 = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # print top 5 genes and logfcs for both,. # they're the same and should not be. print(""Top genes cluster 0 versus all:\n"", genes_cluster_0_vs_all[:5]). print(""Top genes cluster 0 versus cluster 1:\n"", genes_cluster_0_vs_1[:5]). ```. ```pytb. Clusters: ['0', '1', '2', '3', '4', '5', '6', '7', '8']. WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'. WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'. Top genes cluster 0 versus all:. [('LYPD2', 29.707254), ('C1QA', 7.7860994), ('FCGR3A', 7.2558727), ('HES4', 7.201066), ('C1QB', 6.6123295)]. Top genes cluster 0 versus cluster 1:. [('LYPD2', 29.707254), ('C1QA', 7.7860994), ('FCGR3A', 7.2558727), ('HES4', 7.201066), ('C1QB', 6.6123295)]```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1519
https://github.com/scverse/scanpy/issues/1519:2251,safety,test,test,2251,"to all other clusters (see below). . Is that the intention? If so, we should update the readthedocs I think. If this is a bug, let's try to fix it :) I can take a look myself in that case. Just wanted to check if I misinterpreted the readthedocs. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. # load data. adata = sc.datasets.pbmc68k_reduced(). # cluster. sc.tl.leiden(adata, key_added=""clusters"", resolution=0.5). print(""Clusters:"", sorted(set(adata.obs[""clusters""]))). # do test with groups=""all"". sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=""all""). # store results, sorting genes by logfc. genes_cluster_0_vs_all = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # do test with groups=[""0"",""1""], i.e. only a subset of the clusters. sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=[""0"", ""1""]). # store result. genes_cluster_0_vs_1 = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # print top 5 genes and logfcs for both,. # they're the same and should not be. print(""Top genes cluster 0 versus all:\n"", genes_cluster_0_vs_all[:5]). print(""Top genes cluster 0 versus cluster 1:\n"", genes_cluster_0_vs_1[:5]). ```. ```pytb. Clusters: ['0', '1', '2', '3', '4', '5', '6', '7', '8']. WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'. WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'. Top genes cluster 0 versus all:. [('LYPD2', 29.707254), ('C1QA', 7.7860994), ('FCGR3A', 7.2558727), ('HES4', 7.201066), ('C1QB', 6.6123295)]. Top genes cluster 0 versus cluster 1:. [('LYPD2', 29.707254), ('C1QA', 7.7860994), ('FCGR3A', 7.2558727), ('HES4', 7.201066), ('C1QB', 6.6123295)]```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1519
https://github.com/scverse/scanpy/issues/1519:2340,safety,test,test,2340,"to all other clusters (see below). . Is that the intention? If so, we should update the readthedocs I think. If this is a bug, let's try to fix it :) I can take a look myself in that case. Just wanted to check if I misinterpreted the readthedocs. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. # load data. adata = sc.datasets.pbmc68k_reduced(). # cluster. sc.tl.leiden(adata, key_added=""clusters"", resolution=0.5). print(""Clusters:"", sorted(set(adata.obs[""clusters""]))). # do test with groups=""all"". sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=""all""). # store results, sorting genes by logfc. genes_cluster_0_vs_all = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # do test with groups=[""0"",""1""], i.e. only a subset of the clusters. sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=[""0"", ""1""]). # store result. genes_cluster_0_vs_1 = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # print top 5 genes and logfcs for both,. # they're the same and should not be. print(""Top genes cluster 0 versus all:\n"", genes_cluster_0_vs_all[:5]). print(""Top genes cluster 0 versus cluster 1:\n"", genes_cluster_0_vs_1[:5]). ```. ```pytb. Clusters: ['0', '1', '2', '3', '4', '5', '6', '7', '8']. WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'. WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'. Top genes cluster 0 versus all:. [('LYPD2', 29.707254), ('C1QA', 7.7860994), ('FCGR3A', 7.2558727), ('HES4', 7.201066), ('C1QB', 6.6123295)]. Top genes cluster 0 versus cluster 1:. [('LYPD2', 29.707254), ('C1QA', 7.7860994), ('FCGR3A', 7.2558727), ('HES4', 7.201066), ('C1QB', 6.6123295)]```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1519
https://github.com/scverse/scanpy/issues/1519:744,security,updat,update,744,"rank_genes_groups ""groups"" argument ignored or not clearly explained; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi,. My understanding of the ""groups"" argument in sc.tl.rank_genes_groups is that it subsets the data and then performs the differential expression testing. I.e. if I have clusters 1 to 10, and I set groups=[1,2], the output will give me the genes differentially expressed in cluster 1 as compared to cluster 2 (and 2 vs 1). However, the current function still compares to all other clusters (see below). . Is that the intention? If so, we should update the readthedocs I think. If this is a bug, let's try to fix it :) I can take a look myself in that case. Just wanted to check if I misinterpreted the readthedocs. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. # load data. adata = sc.datasets.pbmc68k_reduced(). # cluster. sc.tl.leiden(adata, key_added=""clusters"", resolution=0.5). print(""Clusters:"", sorted(set(adata.obs[""clusters""]))). # do test with groups=""all"". sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=""all""). # store results, sorting genes by logfc. genes_cluster_0_vs_all = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # do test with groups=[""0"",""1""], i.e. only a subset of the clusters. sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=[""0"", ""1""]). # store result. genes_cluster_0_vs_1 = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # print top 5 genes and logfcs for both,. # they're the same and should not be. print(""Top genes clust",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1519
https://github.com/scverse/scanpy/issues/1519:1327,security,log,logfc,1327,"ups"" argument in sc.tl.rank_genes_groups is that it subsets the data and then performs the differential expression testing. I.e. if I have clusters 1 to 10, and I set groups=[1,2], the output will give me the genes differentially expressed in cluster 1 as compared to cluster 2 (and 2 vs 1). However, the current function still compares to all other clusters (see below). . Is that the intention? If so, we should update the readthedocs I think. If this is a bug, let's try to fix it :) I can take a look myself in that case. Just wanted to check if I misinterpreted the readthedocs. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. # load data. adata = sc.datasets.pbmc68k_reduced(). # cluster. sc.tl.leiden(adata, key_added=""clusters"", resolution=0.5). print(""Clusters:"", sorted(set(adata.obs[""clusters""]))). # do test with groups=""all"". sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=""all""). # store results, sorting genes by logfc. genes_cluster_0_vs_all = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # do test with groups=[""0"",""1""], i.e. only a subset of the clusters. sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=[""0"", ""1""]). # store result. genes_cluster_0_vs_1 = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # print top 5 genes and logfcs for both,. # they're the same and should not be. print(""Top genes cluster 0 versus all:\n"", genes_cluster_0_vs_all[:5]). print(""Top genes cluster 0 versus cluster 1:\n"", genes_cluster_0_vs_1[:5]). ```. ```pytb. Clusters: ['0', '1', '2', '3', '4', '5', '6', '7', '8']. WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'. WARNING: Default of the method has been chan",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1519
https://github.com/scverse/scanpy/issues/1519:1369,security,log,logfc,1369,"s that it subsets the data and then performs the differential expression testing. I.e. if I have clusters 1 to 10, and I set groups=[1,2], the output will give me the genes differentially expressed in cluster 1 as compared to cluster 2 (and 2 vs 1). However, the current function still compares to all other clusters (see below). . Is that the intention? If so, we should update the readthedocs I think. If this is a bug, let's try to fix it :) I can take a look myself in that case. Just wanted to check if I misinterpreted the readthedocs. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. # load data. adata = sc.datasets.pbmc68k_reduced(). # cluster. sc.tl.leiden(adata, key_added=""clusters"", resolution=0.5). print(""Clusters:"", sorted(set(adata.obs[""clusters""]))). # do test with groups=""all"". sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=""all""). # store results, sorting genes by logfc. genes_cluster_0_vs_all = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # do test with groups=[""0"",""1""], i.e. only a subset of the clusters. sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=[""0"", ""1""]). # store result. genes_cluster_0_vs_1 = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # print top 5 genes and logfcs for both,. # they're the same and should not be. print(""Top genes cluster 0 versus all:\n"", genes_cluster_0_vs_all[:5]). print(""Top genes cluster 0 versus cluster 1:\n"", genes_cluster_0_vs_1[:5]). ```. ```pytb. Clusters: ['0', '1', '2', '3', '4', '5', '6', '7', '8']. WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'. WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1519
https://github.com/scverse/scanpy/issues/1519:1381,security,log,logfc,1381,"bsets the data and then performs the differential expression testing. I.e. if I have clusters 1 to 10, and I set groups=[1,2], the output will give me the genes differentially expressed in cluster 1 as compared to cluster 2 (and 2 vs 1). However, the current function still compares to all other clusters (see below). . Is that the intention? If so, we should update the readthedocs I think. If this is a bug, let's try to fix it :) I can take a look myself in that case. Just wanted to check if I misinterpreted the readthedocs. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. # load data. adata = sc.datasets.pbmc68k_reduced(). # cluster. sc.tl.leiden(adata, key_added=""clusters"", resolution=0.5). print(""Clusters:"", sorted(set(adata.obs[""clusters""]))). # do test with groups=""all"". sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=""all""). # store results, sorting genes by logfc. genes_cluster_0_vs_all = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # do test with groups=[""0"",""1""], i.e. only a subset of the clusters. sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=[""0"", ""1""]). # store result. genes_cluster_0_vs_1 = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # print top 5 genes and logfcs for both,. # they're the same and should not be. print(""Top genes cluster 0 versus all:\n"", genes_cluster_0_vs_all[:5]). print(""Top genes cluster 0 versus cluster 1:\n"", genes_cluster_0_vs_1[:5]). ```. ```pytb. Clusters: ['0', '1', '2', '3', '4', '5', '6', '7', '8']. WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'. WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'. Top genes",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1519
https://github.com/scverse/scanpy/issues/1519:1443,security,log,logfoldchanges,1443,"ng. I.e. if I have clusters 1 to 10, and I set groups=[1,2], the output will give me the genes differentially expressed in cluster 1 as compared to cluster 2 (and 2 vs 1). However, the current function still compares to all other clusters (see below). . Is that the intention? If so, we should update the readthedocs I think. If this is a bug, let's try to fix it :) I can take a look myself in that case. Just wanted to check if I misinterpreted the readthedocs. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. # load data. adata = sc.datasets.pbmc68k_reduced(). # cluster. sc.tl.leiden(adata, key_added=""clusters"", resolution=0.5). print(""Clusters:"", sorted(set(adata.obs[""clusters""]))). # do test with groups=""all"". sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=""all""). # store results, sorting genes by logfc. genes_cluster_0_vs_all = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # do test with groups=[""0"",""1""], i.e. only a subset of the clusters. sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=[""0"", ""1""]). # store result. genes_cluster_0_vs_1 = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # print top 5 genes and logfcs for both,. # they're the same and should not be. print(""Top genes cluster 0 versus all:\n"", genes_cluster_0_vs_all[:5]). print(""Top genes cluster 0 versus cluster 1:\n"", genes_cluster_0_vs_1[:5]). ```. ```pytb. Clusters: ['0', '1', '2', '3', '4', '5', '6', '7', '8']. WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'. WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'. Top genes cluster 0 versus all:. [('LYPD2', 29.707254), ('C1QA', 7.7860994)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1519
https://github.com/scverse/scanpy/issues/1519:1728,security,log,logfc,1728,"to all other clusters (see below). . Is that the intention? If so, we should update the readthedocs I think. If this is a bug, let's try to fix it :) I can take a look myself in that case. Just wanted to check if I misinterpreted the readthedocs. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. # load data. adata = sc.datasets.pbmc68k_reduced(). # cluster. sc.tl.leiden(adata, key_added=""clusters"", resolution=0.5). print(""Clusters:"", sorted(set(adata.obs[""clusters""]))). # do test with groups=""all"". sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=""all""). # store results, sorting genes by logfc. genes_cluster_0_vs_all = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # do test with groups=[""0"",""1""], i.e. only a subset of the clusters. sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=[""0"", ""1""]). # store result. genes_cluster_0_vs_1 = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # print top 5 genes and logfcs for both,. # they're the same and should not be. print(""Top genes cluster 0 versus all:\n"", genes_cluster_0_vs_all[:5]). print(""Top genes cluster 0 versus cluster 1:\n"", genes_cluster_0_vs_1[:5]). ```. ```pytb. Clusters: ['0', '1', '2', '3', '4', '5', '6', '7', '8']. WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'. WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'. Top genes cluster 0 versus all:. [('LYPD2', 29.707254), ('C1QA', 7.7860994), ('FCGR3A', 7.2558727), ('HES4', 7.201066), ('C1QB', 6.6123295)]. Top genes cluster 0 versus cluster 1:. [('LYPD2', 29.707254), ('C1QA', 7.7860994), ('FCGR3A', 7.2558727), ('HES4', 7.201066), ('C1QB', 6.6123295)]```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1519
https://github.com/scverse/scanpy/issues/1519:1740,security,log,logfc,1740,"to all other clusters (see below). . Is that the intention? If so, we should update the readthedocs I think. If this is a bug, let's try to fix it :) I can take a look myself in that case. Just wanted to check if I misinterpreted the readthedocs. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. # load data. adata = sc.datasets.pbmc68k_reduced(). # cluster. sc.tl.leiden(adata, key_added=""clusters"", resolution=0.5). print(""Clusters:"", sorted(set(adata.obs[""clusters""]))). # do test with groups=""all"". sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=""all""). # store results, sorting genes by logfc. genes_cluster_0_vs_all = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # do test with groups=[""0"",""1""], i.e. only a subset of the clusters. sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=[""0"", ""1""]). # store result. genes_cluster_0_vs_1 = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # print top 5 genes and logfcs for both,. # they're the same and should not be. print(""Top genes cluster 0 versus all:\n"", genes_cluster_0_vs_all[:5]). print(""Top genes cluster 0 versus cluster 1:\n"", genes_cluster_0_vs_1[:5]). ```. ```pytb. Clusters: ['0', '1', '2', '3', '4', '5', '6', '7', '8']. WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'. WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'. Top genes cluster 0 versus all:. [('LYPD2', 29.707254), ('C1QA', 7.7860994), ('FCGR3A', 7.2558727), ('HES4', 7.201066), ('C1QB', 6.6123295)]. Top genes cluster 0 versus cluster 1:. [('LYPD2', 29.707254), ('C1QA', 7.7860994), ('FCGR3A', 7.2558727), ('HES4', 7.201066), ('C1QB', 6.6123295)]```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1519
https://github.com/scverse/scanpy/issues/1519:1802,security,log,logfoldchanges,1802,"to all other clusters (see below). . Is that the intention? If so, we should update the readthedocs I think. If this is a bug, let's try to fix it :) I can take a look myself in that case. Just wanted to check if I misinterpreted the readthedocs. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. # load data. adata = sc.datasets.pbmc68k_reduced(). # cluster. sc.tl.leiden(adata, key_added=""clusters"", resolution=0.5). print(""Clusters:"", sorted(set(adata.obs[""clusters""]))). # do test with groups=""all"". sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=""all""). # store results, sorting genes by logfc. genes_cluster_0_vs_all = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # do test with groups=[""0"",""1""], i.e. only a subset of the clusters. sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=[""0"", ""1""]). # store result. genes_cluster_0_vs_1 = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # print top 5 genes and logfcs for both,. # they're the same and should not be. print(""Top genes cluster 0 versus all:\n"", genes_cluster_0_vs_all[:5]). print(""Top genes cluster 0 versus cluster 1:\n"", genes_cluster_0_vs_1[:5]). ```. ```pytb. Clusters: ['0', '1', '2', '3', '4', '5', '6', '7', '8']. WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'. WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'. Top genes cluster 0 versus all:. [('LYPD2', 29.707254), ('C1QA', 7.7860994), ('FCGR3A', 7.2558727), ('HES4', 7.201066), ('C1QB', 6.6123295)]. Top genes cluster 0 versus cluster 1:. [('LYPD2', 29.707254), ('C1QA', 7.7860994), ('FCGR3A', 7.2558727), ('HES4', 7.201066), ('C1QB', 6.6123295)]```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1519
https://github.com/scverse/scanpy/issues/1519:1922,security,log,logfcs,1922,"to all other clusters (see below). . Is that the intention? If so, we should update the readthedocs I think. If this is a bug, let's try to fix it :) I can take a look myself in that case. Just wanted to check if I misinterpreted the readthedocs. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. # load data. adata = sc.datasets.pbmc68k_reduced(). # cluster. sc.tl.leiden(adata, key_added=""clusters"", resolution=0.5). print(""Clusters:"", sorted(set(adata.obs[""clusters""]))). # do test with groups=""all"". sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=""all""). # store results, sorting genes by logfc. genes_cluster_0_vs_all = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # do test with groups=[""0"",""1""], i.e. only a subset of the clusters. sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=[""0"", ""1""]). # store result. genes_cluster_0_vs_1 = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # print top 5 genes and logfcs for both,. # they're the same and should not be. print(""Top genes cluster 0 versus all:\n"", genes_cluster_0_vs_all[:5]). print(""Top genes cluster 0 versus cluster 1:\n"", genes_cluster_0_vs_1[:5]). ```. ```pytb. Clusters: ['0', '1', '2', '3', '4', '5', '6', '7', '8']. WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'. WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'. Top genes cluster 0 versus all:. [('LYPD2', 29.707254), ('C1QA', 7.7860994), ('FCGR3A', 7.2558727), ('HES4', 7.201066), ('C1QB', 6.6123295)]. Top genes cluster 0 versus cluster 1:. [('LYPD2', 29.707254), ('C1QA', 7.7860994), ('FCGR3A', 7.2558727), ('HES4', 7.201066), ('C1QB', 6.6123295)]```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1519
https://github.com/scverse/scanpy/issues/1519:305,testability,understand,understanding,305,"rank_genes_groups ""groups"" argument ignored or not clearly explained; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi,. My understanding of the ""groups"" argument in sc.tl.rank_genes_groups is that it subsets the data and then performs the differential expression testing. I.e. if I have clusters 1 to 10, and I set groups=[1,2], the output will give me the genes differentially expressed in cluster 1 as compared to cluster 2 (and 2 vs 1). However, the current function still compares to all other clusters (see below). . Is that the intention? If so, we should update the readthedocs I think. If this is a bug, let's try to fix it :) I can take a look myself in that case. Just wanted to check if I misinterpreted the readthedocs. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. # load data. adata = sc.datasets.pbmc68k_reduced(). # cluster. sc.tl.leiden(adata, key_added=""clusters"", resolution=0.5). print(""Clusters:"", sorted(set(adata.obs[""clusters""]))). # do test with groups=""all"". sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=""all""). # store results, sorting genes by logfc. genes_cluster_0_vs_all = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # do test with groups=[""0"",""1""], i.e. only a subset of the clusters. sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=[""0"", ""1""]). # store result. genes_cluster_0_vs_1 = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # print top 5 genes and logfcs for both,. # they're the same and should not be. print(""Top genes clust",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1519
https://github.com/scverse/scanpy/issues/1519:445,testability,test,testing,445,"rank_genes_groups ""groups"" argument ignored or not clearly explained; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi,. My understanding of the ""groups"" argument in sc.tl.rank_genes_groups is that it subsets the data and then performs the differential expression testing. I.e. if I have clusters 1 to 10, and I set groups=[1,2], the output will give me the genes differentially expressed in cluster 1 as compared to cluster 2 (and 2 vs 1). However, the current function still compares to all other clusters (see below). . Is that the intention? If so, we should update the readthedocs I think. If this is a bug, let's try to fix it :) I can take a look myself in that case. Just wanted to check if I misinterpreted the readthedocs. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. # load data. adata = sc.datasets.pbmc68k_reduced(). # cluster. sc.tl.leiden(adata, key_added=""clusters"", resolution=0.5). print(""Clusters:"", sorted(set(adata.obs[""clusters""]))). # do test with groups=""all"". sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=""all""). # store results, sorting genes by logfc. genes_cluster_0_vs_all = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # do test with groups=[""0"",""1""], i.e. only a subset of the clusters. sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=[""0"", ""1""]). # store result. genes_cluster_0_vs_1 = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # print top 5 genes and logfcs for both,. # they're the same and should not be. print(""Top genes clust",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1519
https://github.com/scverse/scanpy/issues/1519:1203,testability,test,test,1203,"npy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi,. My understanding of the ""groups"" argument in sc.tl.rank_genes_groups is that it subsets the data and then performs the differential expression testing. I.e. if I have clusters 1 to 10, and I set groups=[1,2], the output will give me the genes differentially expressed in cluster 1 as compared to cluster 2 (and 2 vs 1). However, the current function still compares to all other clusters (see below). . Is that the intention? If so, we should update the readthedocs I think. If this is a bug, let's try to fix it :) I can take a look myself in that case. Just wanted to check if I misinterpreted the readthedocs. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. # load data. adata = sc.datasets.pbmc68k_reduced(). # cluster. sc.tl.leiden(adata, key_added=""clusters"", resolution=0.5). print(""Clusters:"", sorted(set(adata.obs[""clusters""]))). # do test with groups=""all"". sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=""all""). # store results, sorting genes by logfc. genes_cluster_0_vs_all = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # do test with groups=[""0"",""1""], i.e. only a subset of the clusters. sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=[""0"", ""1""]). # store result. genes_cluster_0_vs_1 = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # print top 5 genes and logfcs for both,. # they're the same and should not be. print(""Top genes cluster 0 versus all:\n"", genes_cluster_0_vs_all[:5]). print(""Top genes cluster 0 versus cluster 1:\n"", genes_cluster_0_vs_1[:5]). ```. ```pytb. Clusters: ['0', '1', '2', '3', '4', '5', '6', '7', '8']. WARNING:",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1519
https://github.com/scverse/scanpy/issues/1519:1327,testability,log,logfc,1327,"ups"" argument in sc.tl.rank_genes_groups is that it subsets the data and then performs the differential expression testing. I.e. if I have clusters 1 to 10, and I set groups=[1,2], the output will give me the genes differentially expressed in cluster 1 as compared to cluster 2 (and 2 vs 1). However, the current function still compares to all other clusters (see below). . Is that the intention? If so, we should update the readthedocs I think. If this is a bug, let's try to fix it :) I can take a look myself in that case. Just wanted to check if I misinterpreted the readthedocs. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. # load data. adata = sc.datasets.pbmc68k_reduced(). # cluster. sc.tl.leiden(adata, key_added=""clusters"", resolution=0.5). print(""Clusters:"", sorted(set(adata.obs[""clusters""]))). # do test with groups=""all"". sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=""all""). # store results, sorting genes by logfc. genes_cluster_0_vs_all = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # do test with groups=[""0"",""1""], i.e. only a subset of the clusters. sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=[""0"", ""1""]). # store result. genes_cluster_0_vs_1 = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # print top 5 genes and logfcs for both,. # they're the same and should not be. print(""Top genes cluster 0 versus all:\n"", genes_cluster_0_vs_all[:5]). print(""Top genes cluster 0 versus cluster 1:\n"", genes_cluster_0_vs_1[:5]). ```. ```pytb. Clusters: ['0', '1', '2', '3', '4', '5', '6', '7', '8']. WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'. WARNING: Default of the method has been chan",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1519
https://github.com/scverse/scanpy/issues/1519:1369,testability,log,logfc,1369,"s that it subsets the data and then performs the differential expression testing. I.e. if I have clusters 1 to 10, and I set groups=[1,2], the output will give me the genes differentially expressed in cluster 1 as compared to cluster 2 (and 2 vs 1). However, the current function still compares to all other clusters (see below). . Is that the intention? If so, we should update the readthedocs I think. If this is a bug, let's try to fix it :) I can take a look myself in that case. Just wanted to check if I misinterpreted the readthedocs. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. # load data. adata = sc.datasets.pbmc68k_reduced(). # cluster. sc.tl.leiden(adata, key_added=""clusters"", resolution=0.5). print(""Clusters:"", sorted(set(adata.obs[""clusters""]))). # do test with groups=""all"". sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=""all""). # store results, sorting genes by logfc. genes_cluster_0_vs_all = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # do test with groups=[""0"",""1""], i.e. only a subset of the clusters. sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=[""0"", ""1""]). # store result. genes_cluster_0_vs_1 = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # print top 5 genes and logfcs for both,. # they're the same and should not be. print(""Top genes cluster 0 versus all:\n"", genes_cluster_0_vs_all[:5]). print(""Top genes cluster 0 versus cluster 1:\n"", genes_cluster_0_vs_1[:5]). ```. ```pytb. Clusters: ['0', '1', '2', '3', '4', '5', '6', '7', '8']. WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'. WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1519
https://github.com/scverse/scanpy/issues/1519:1381,testability,log,logfc,1381,"bsets the data and then performs the differential expression testing. I.e. if I have clusters 1 to 10, and I set groups=[1,2], the output will give me the genes differentially expressed in cluster 1 as compared to cluster 2 (and 2 vs 1). However, the current function still compares to all other clusters (see below). . Is that the intention? If so, we should update the readthedocs I think. If this is a bug, let's try to fix it :) I can take a look myself in that case. Just wanted to check if I misinterpreted the readthedocs. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. # load data. adata = sc.datasets.pbmc68k_reduced(). # cluster. sc.tl.leiden(adata, key_added=""clusters"", resolution=0.5). print(""Clusters:"", sorted(set(adata.obs[""clusters""]))). # do test with groups=""all"". sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=""all""). # store results, sorting genes by logfc. genes_cluster_0_vs_all = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # do test with groups=[""0"",""1""], i.e. only a subset of the clusters. sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=[""0"", ""1""]). # store result. genes_cluster_0_vs_1 = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # print top 5 genes and logfcs for both,. # they're the same and should not be. print(""Top genes cluster 0 versus all:\n"", genes_cluster_0_vs_all[:5]). print(""Top genes cluster 0 versus cluster 1:\n"", genes_cluster_0_vs_1[:5]). ```. ```pytb. Clusters: ['0', '1', '2', '3', '4', '5', '6', '7', '8']. WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'. WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'. Top genes",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1519
https://github.com/scverse/scanpy/issues/1519:1443,testability,log,logfoldchanges,1443,"ng. I.e. if I have clusters 1 to 10, and I set groups=[1,2], the output will give me the genes differentially expressed in cluster 1 as compared to cluster 2 (and 2 vs 1). However, the current function still compares to all other clusters (see below). . Is that the intention? If so, we should update the readthedocs I think. If this is a bug, let's try to fix it :) I can take a look myself in that case. Just wanted to check if I misinterpreted the readthedocs. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. # load data. adata = sc.datasets.pbmc68k_reduced(). # cluster. sc.tl.leiden(adata, key_added=""clusters"", resolution=0.5). print(""Clusters:"", sorted(set(adata.obs[""clusters""]))). # do test with groups=""all"". sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=""all""). # store results, sorting genes by logfc. genes_cluster_0_vs_all = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # do test with groups=[""0"",""1""], i.e. only a subset of the clusters. sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=[""0"", ""1""]). # store result. genes_cluster_0_vs_1 = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # print top 5 genes and logfcs for both,. # they're the same and should not be. print(""Top genes cluster 0 versus all:\n"", genes_cluster_0_vs_all[:5]). print(""Top genes cluster 0 versus cluster 1:\n"", genes_cluster_0_vs_1[:5]). ```. ```pytb. Clusters: ['0', '1', '2', '3', '4', '5', '6', '7', '8']. WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'. WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'. Top genes cluster 0 versus all:. [('LYPD2', 29.707254), ('C1QA', 7.7860994)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1519
https://github.com/scverse/scanpy/issues/1519:1544,testability,test,test,1544,"ifferentially expressed in cluster 1 as compared to cluster 2 (and 2 vs 1). However, the current function still compares to all other clusters (see below). . Is that the intention? If so, we should update the readthedocs I think. If this is a bug, let's try to fix it :) I can take a look myself in that case. Just wanted to check if I misinterpreted the readthedocs. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. # load data. adata = sc.datasets.pbmc68k_reduced(). # cluster. sc.tl.leiden(adata, key_added=""clusters"", resolution=0.5). print(""Clusters:"", sorted(set(adata.obs[""clusters""]))). # do test with groups=""all"". sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=""all""). # store results, sorting genes by logfc. genes_cluster_0_vs_all = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # do test with groups=[""0"",""1""], i.e. only a subset of the clusters. sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=[""0"", ""1""]). # store result. genes_cluster_0_vs_1 = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # print top 5 genes and logfcs for both,. # they're the same and should not be. print(""Top genes cluster 0 versus all:\n"", genes_cluster_0_vs_all[:5]). print(""Top genes cluster 0 versus cluster 1:\n"", genes_cluster_0_vs_1[:5]). ```. ```pytb. Clusters: ['0', '1', '2', '3', '4', '5', '6', '7', '8']. WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'. WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'. Top genes cluster 0 versus all:. [('LYPD2', 29.707254), ('C1QA', 7.7860994), ('FCGR3A', 7.2558727), ('HES4', 7.201066), ('C1QB', 6.6123295)]. Top genes cluster 0 versus cl",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1519
https://github.com/scverse/scanpy/issues/1519:1728,testability,log,logfc,1728,"to all other clusters (see below). . Is that the intention? If so, we should update the readthedocs I think. If this is a bug, let's try to fix it :) I can take a look myself in that case. Just wanted to check if I misinterpreted the readthedocs. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. # load data. adata = sc.datasets.pbmc68k_reduced(). # cluster. sc.tl.leiden(adata, key_added=""clusters"", resolution=0.5). print(""Clusters:"", sorted(set(adata.obs[""clusters""]))). # do test with groups=""all"". sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=""all""). # store results, sorting genes by logfc. genes_cluster_0_vs_all = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # do test with groups=[""0"",""1""], i.e. only a subset of the clusters. sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=[""0"", ""1""]). # store result. genes_cluster_0_vs_1 = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # print top 5 genes and logfcs for both,. # they're the same and should not be. print(""Top genes cluster 0 versus all:\n"", genes_cluster_0_vs_all[:5]). print(""Top genes cluster 0 versus cluster 1:\n"", genes_cluster_0_vs_1[:5]). ```. ```pytb. Clusters: ['0', '1', '2', '3', '4', '5', '6', '7', '8']. WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'. WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'. Top genes cluster 0 versus all:. [('LYPD2', 29.707254), ('C1QA', 7.7860994), ('FCGR3A', 7.2558727), ('HES4', 7.201066), ('C1QB', 6.6123295)]. Top genes cluster 0 versus cluster 1:. [('LYPD2', 29.707254), ('C1QA', 7.7860994), ('FCGR3A', 7.2558727), ('HES4', 7.201066), ('C1QB', 6.6123295)]```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1519
https://github.com/scverse/scanpy/issues/1519:1740,testability,log,logfc,1740,"to all other clusters (see below). . Is that the intention? If so, we should update the readthedocs I think. If this is a bug, let's try to fix it :) I can take a look myself in that case. Just wanted to check if I misinterpreted the readthedocs. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. # load data. adata = sc.datasets.pbmc68k_reduced(). # cluster. sc.tl.leiden(adata, key_added=""clusters"", resolution=0.5). print(""Clusters:"", sorted(set(adata.obs[""clusters""]))). # do test with groups=""all"". sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=""all""). # store results, sorting genes by logfc. genes_cluster_0_vs_all = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # do test with groups=[""0"",""1""], i.e. only a subset of the clusters. sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=[""0"", ""1""]). # store result. genes_cluster_0_vs_1 = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # print top 5 genes and logfcs for both,. # they're the same and should not be. print(""Top genes cluster 0 versus all:\n"", genes_cluster_0_vs_all[:5]). print(""Top genes cluster 0 versus cluster 1:\n"", genes_cluster_0_vs_1[:5]). ```. ```pytb. Clusters: ['0', '1', '2', '3', '4', '5', '6', '7', '8']. WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'. WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'. Top genes cluster 0 versus all:. [('LYPD2', 29.707254), ('C1QA', 7.7860994), ('FCGR3A', 7.2558727), ('HES4', 7.201066), ('C1QB', 6.6123295)]. Top genes cluster 0 versus cluster 1:. [('LYPD2', 29.707254), ('C1QA', 7.7860994), ('FCGR3A', 7.2558727), ('HES4', 7.201066), ('C1QB', 6.6123295)]```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1519
https://github.com/scverse/scanpy/issues/1519:1802,testability,log,logfoldchanges,1802,"to all other clusters (see below). . Is that the intention? If so, we should update the readthedocs I think. If this is a bug, let's try to fix it :) I can take a look myself in that case. Just wanted to check if I misinterpreted the readthedocs. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. # load data. adata = sc.datasets.pbmc68k_reduced(). # cluster. sc.tl.leiden(adata, key_added=""clusters"", resolution=0.5). print(""Clusters:"", sorted(set(adata.obs[""clusters""]))). # do test with groups=""all"". sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=""all""). # store results, sorting genes by logfc. genes_cluster_0_vs_all = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # do test with groups=[""0"",""1""], i.e. only a subset of the clusters. sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=[""0"", ""1""]). # store result. genes_cluster_0_vs_1 = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # print top 5 genes and logfcs for both,. # they're the same and should not be. print(""Top genes cluster 0 versus all:\n"", genes_cluster_0_vs_all[:5]). print(""Top genes cluster 0 versus cluster 1:\n"", genes_cluster_0_vs_1[:5]). ```. ```pytb. Clusters: ['0', '1', '2', '3', '4', '5', '6', '7', '8']. WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'. WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'. Top genes cluster 0 versus all:. [('LYPD2', 29.707254), ('C1QA', 7.7860994), ('FCGR3A', 7.2558727), ('HES4', 7.201066), ('C1QB', 6.6123295)]. Top genes cluster 0 versus cluster 1:. [('LYPD2', 29.707254), ('C1QA', 7.7860994), ('FCGR3A', 7.2558727), ('HES4', 7.201066), ('C1QB', 6.6123295)]```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1519
https://github.com/scverse/scanpy/issues/1519:1922,testability,log,logfcs,1922,"to all other clusters (see below). . Is that the intention? If so, we should update the readthedocs I think. If this is a bug, let's try to fix it :) I can take a look myself in that case. Just wanted to check if I misinterpreted the readthedocs. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. # load data. adata = sc.datasets.pbmc68k_reduced(). # cluster. sc.tl.leiden(adata, key_added=""clusters"", resolution=0.5). print(""Clusters:"", sorted(set(adata.obs[""clusters""]))). # do test with groups=""all"". sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=""all""). # store results, sorting genes by logfc. genes_cluster_0_vs_all = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # do test with groups=[""0"",""1""], i.e. only a subset of the clusters. sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=[""0"", ""1""]). # store result. genes_cluster_0_vs_1 = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # print top 5 genes and logfcs for both,. # they're the same and should not be. print(""Top genes cluster 0 versus all:\n"", genes_cluster_0_vs_all[:5]). print(""Top genes cluster 0 versus cluster 1:\n"", genes_cluster_0_vs_1[:5]). ```. ```pytb. Clusters: ['0', '1', '2', '3', '4', '5', '6', '7', '8']. WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'. WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'. Top genes cluster 0 versus all:. [('LYPD2', 29.707254), ('C1QA', 7.7860994), ('FCGR3A', 7.2558727), ('HES4', 7.201066), ('C1QB', 6.6123295)]. Top genes cluster 0 versus cluster 1:. [('LYPD2', 29.707254), ('C1QA', 7.7860994), ('FCGR3A', 7.2558727), ('HES4', 7.201066), ('C1QB', 6.6123295)]```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1519
https://github.com/scverse/scanpy/issues/1519:2251,testability,test,test,2251,"to all other clusters (see below). . Is that the intention? If so, we should update the readthedocs I think. If this is a bug, let's try to fix it :) I can take a look myself in that case. Just wanted to check if I misinterpreted the readthedocs. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. # load data. adata = sc.datasets.pbmc68k_reduced(). # cluster. sc.tl.leiden(adata, key_added=""clusters"", resolution=0.5). print(""Clusters:"", sorted(set(adata.obs[""clusters""]))). # do test with groups=""all"". sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=""all""). # store results, sorting genes by logfc. genes_cluster_0_vs_all = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # do test with groups=[""0"",""1""], i.e. only a subset of the clusters. sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=[""0"", ""1""]). # store result. genes_cluster_0_vs_1 = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # print top 5 genes and logfcs for both,. # they're the same and should not be. print(""Top genes cluster 0 versus all:\n"", genes_cluster_0_vs_all[:5]). print(""Top genes cluster 0 versus cluster 1:\n"", genes_cluster_0_vs_1[:5]). ```. ```pytb. Clusters: ['0', '1', '2', '3', '4', '5', '6', '7', '8']. WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'. WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'. Top genes cluster 0 versus all:. [('LYPD2', 29.707254), ('C1QA', 7.7860994), ('FCGR3A', 7.2558727), ('HES4', 7.201066), ('C1QB', 6.6123295)]. Top genes cluster 0 versus cluster 1:. [('LYPD2', 29.707254), ('C1QA', 7.7860994), ('FCGR3A', 7.2558727), ('HES4', 7.201066), ('C1QB', 6.6123295)]```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1519
https://github.com/scverse/scanpy/issues/1519:2340,testability,test,test,2340,"to all other clusters (see below). . Is that the intention? If so, we should update the readthedocs I think. If this is a bug, let's try to fix it :) I can take a look myself in that case. Just wanted to check if I misinterpreted the readthedocs. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. # load data. adata = sc.datasets.pbmc68k_reduced(). # cluster. sc.tl.leiden(adata, key_added=""clusters"", resolution=0.5). print(""Clusters:"", sorted(set(adata.obs[""clusters""]))). # do test with groups=""all"". sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=""all""). # store results, sorting genes by logfc. genes_cluster_0_vs_all = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # do test with groups=[""0"",""1""], i.e. only a subset of the clusters. sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=[""0"", ""1""]). # store result. genes_cluster_0_vs_1 = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # print top 5 genes and logfcs for both,. # they're the same and should not be. print(""Top genes cluster 0 versus all:\n"", genes_cluster_0_vs_all[:5]). print(""Top genes cluster 0 versus cluster 1:\n"", genes_cluster_0_vs_1[:5]). ```. ```pytb. Clusters: ['0', '1', '2', '3', '4', '5', '6', '7', '8']. WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'. WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'. Top genes cluster 0 versus all:. [('LYPD2', 29.707254), ('C1QA', 7.7860994), ('FCGR3A', 7.2558727), ('HES4', 7.201066), ('C1QB', 6.6123295)]. Top genes cluster 0 versus cluster 1:. [('LYPD2', 29.707254), ('C1QA', 7.7860994), ('FCGR3A', 7.2558727), ('HES4', 7.201066), ('C1QB', 6.6123295)]```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1519
https://github.com/scverse/scanpy/issues/1519:51,usability,clear,clearly,51,"rank_genes_groups ""groups"" argument ignored or not clearly explained; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi,. My understanding of the ""groups"" argument in sc.tl.rank_genes_groups is that it subsets the data and then performs the differential expression testing. I.e. if I have clusters 1 to 10, and I set groups=[1,2], the output will give me the genes differentially expressed in cluster 1 as compared to cluster 2 (and 2 vs 1). However, the current function still compares to all other clusters (see below). . Is that the intention? If so, we should update the readthedocs I think. If this is a bug, let's try to fix it :) I can take a look myself in that case. Just wanted to check if I misinterpreted the readthedocs. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. # load data. adata = sc.datasets.pbmc68k_reduced(). # cluster. sc.tl.leiden(adata, key_added=""clusters"", resolution=0.5). print(""Clusters:"", sorted(set(adata.obs[""clusters""]))). # do test with groups=""all"". sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=""all""). # store results, sorting genes by logfc. genes_cluster_0_vs_all = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # do test with groups=[""0"",""1""], i.e. only a subset of the clusters. sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=[""0"", ""1""]). # store result. genes_cluster_0_vs_1 = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # print top 5 genes and logfcs for both,. # they're the same and should not be. print(""Top genes clust",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1519
https://github.com/scverse/scanpy/issues/1519:151,usability,confirm,confirmed,151,"rank_genes_groups ""groups"" argument ignored or not clearly explained; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi,. My understanding of the ""groups"" argument in sc.tl.rank_genes_groups is that it subsets the data and then performs the differential expression testing. I.e. if I have clusters 1 to 10, and I set groups=[1,2], the output will give me the genes differentially expressed in cluster 1 as compared to cluster 2 (and 2 vs 1). However, the current function still compares to all other clusters (see below). . Is that the intention? If so, we should update the readthedocs I think. If this is a bug, let's try to fix it :) I can take a look myself in that case. Just wanted to check if I misinterpreted the readthedocs. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. # load data. adata = sc.datasets.pbmc68k_reduced(). # cluster. sc.tl.leiden(adata, key_added=""clusters"", resolution=0.5). print(""Clusters:"", sorted(set(adata.obs[""clusters""]))). # do test with groups=""all"". sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=""all""). # store results, sorting genes by logfc. genes_cluster_0_vs_all = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # do test with groups=[""0"",""1""], i.e. only a subset of the clusters. sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=[""0"", ""1""]). # store result. genes_cluster_0_vs_1 = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # print top 5 genes and logfcs for both,. # they're the same and should not be. print(""Top genes clust",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1519
https://github.com/scverse/scanpy/issues/1519:234,usability,confirm,confirmed,234,"rank_genes_groups ""groups"" argument ignored or not clearly explained; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi,. My understanding of the ""groups"" argument in sc.tl.rank_genes_groups is that it subsets the data and then performs the differential expression testing. I.e. if I have clusters 1 to 10, and I set groups=[1,2], the output will give me the genes differentially expressed in cluster 1 as compared to cluster 2 (and 2 vs 1). However, the current function still compares to all other clusters (see below). . Is that the intention? If so, we should update the readthedocs I think. If this is a bug, let's try to fix it :) I can take a look myself in that case. Just wanted to check if I misinterpreted the readthedocs. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. # load data. adata = sc.datasets.pbmc68k_reduced(). # cluster. sc.tl.leiden(adata, key_added=""clusters"", resolution=0.5). print(""Clusters:"", sorted(set(adata.obs[""clusters""]))). # do test with groups=""all"". sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=""all""). # store results, sorting genes by logfc. genes_cluster_0_vs_all = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # do test with groups=[""0"",""1""], i.e. only a subset of the clusters. sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=[""0"", ""1""]). # store result. genes_cluster_0_vs_1 = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # print top 5 genes and logfcs for both,. # they're the same and should not be. print(""Top genes clust",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1519
https://github.com/scverse/scanpy/issues/1519:408,usability,perform,performs,408,"rank_genes_groups ""groups"" argument ignored or not clearly explained; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi,. My understanding of the ""groups"" argument in sc.tl.rank_genes_groups is that it subsets the data and then performs the differential expression testing. I.e. if I have clusters 1 to 10, and I set groups=[1,2], the output will give me the genes differentially expressed in cluster 1 as compared to cluster 2 (and 2 vs 1). However, the current function still compares to all other clusters (see below). . Is that the intention? If so, we should update the readthedocs I think. If this is a bug, let's try to fix it :) I can take a look myself in that case. Just wanted to check if I misinterpreted the readthedocs. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. # load data. adata = sc.datasets.pbmc68k_reduced(). # cluster. sc.tl.leiden(adata, key_added=""clusters"", resolution=0.5). print(""Clusters:"", sorted(set(adata.obs[""clusters""]))). # do test with groups=""all"". sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=""all""). # store results, sorting genes by logfc. genes_cluster_0_vs_all = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # do test with groups=[""0"",""1""], i.e. only a subset of the clusters. sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=[""0"", ""1""]). # store result. genes_cluster_0_vs_1 = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # print top 5 genes and logfcs for both,. # they're the same and should not be. print(""Top genes clust",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1519
https://github.com/scverse/scanpy/issues/1519:918,usability,Minim,Minimal,918,"rank_genes_groups ""groups"" argument ignored or not clearly explained; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi,. My understanding of the ""groups"" argument in sc.tl.rank_genes_groups is that it subsets the data and then performs the differential expression testing. I.e. if I have clusters 1 to 10, and I set groups=[1,2], the output will give me the genes differentially expressed in cluster 1 as compared to cluster 2 (and 2 vs 1). However, the current function still compares to all other clusters (see below). . Is that the intention? If so, we should update the readthedocs I think. If this is a bug, let's try to fix it :) I can take a look myself in that case. Just wanted to check if I misinterpreted the readthedocs. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. # load data. adata = sc.datasets.pbmc68k_reduced(). # cluster. sc.tl.leiden(adata, key_added=""clusters"", resolution=0.5). print(""Clusters:"", sorted(set(adata.obs[""clusters""]))). # do test with groups=""all"". sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=""all""). # store results, sorting genes by logfc. genes_cluster_0_vs_all = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # do test with groups=[""0"",""1""], i.e. only a subset of the clusters. sc.tl.rank_genes_groups(adata, groupby=""clusters"", groups=[""0"", ""1""]). # store result. genes_cluster_0_vs_1 = [. (name, logfc). for logfc, name in sorted(. zip(. adata.uns[""rank_genes_groups""][""logfoldchanges""][""0""],. adata.uns[""rank_genes_groups""][""names""][""0""],. ),. reverse=True,. ). ]. # print top 5 genes and logfcs for both,. # they're the same and should not be. print(""Top genes clust",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1519
https://github.com/scverse/scanpy/issues/1521:1752,availability,down,down,1752," using `.uns[""dendrogram_['groups']""]`. WARNING: dendrogram data not found (using key=dendrogram_groups). Running `sc.tl.dendrogram` with default parameters. For fine tuning it is recommended to run `sc.tl.dendrogram` independently. using data matrix X directly. Storing dendrogram info using `.uns['dendrogram_groups']`. ```. ### Description. So as you can see in the reproduction, it looks like `sc.tl.dendrogram(fake, groupby = ""groups"")` **stores** the created dendrogram like this `.uns[""dendrogram_['groups']""] = dendro_data`. But it looks like `sc.pl.dendrogram(fake, groupby = ""groups"")` __expects__ to access this dendrogram like this `fake.uns['dendrogram_groups']` and when it can't find it, it creates a new dendrogram and stores it in `fake.uns['dendrogram_groups']`. My guess is that there is a mismatch in the logic of the code that builds the names of dendros in `sc.tl.dendrogram` vs the code that builds the names in `sc.pl.dendrogram`. If I had more time i would try to track it down for you and maybe even send a PR. Sorry though, I dont. . Can anyone confirm that this is NOT the expected behavior? #### Versions. <details>. ```. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.6.0. sinfo 0.3.1. -----. OpenSSL 19.1.0. PIL 8.0.1. anndata 0.7.5. annoy NA. autoreload NA. backcall 0.2.0. botocore 1.19.22. brotli NA. certifi 2020.11.08. cffi 1.14.3. colorama 0.4.3. cryptography 3.2.1. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. defusedxml 0.6.0. fbpca NA. fsspec 0.8.4. get_version 2.1. h5py 3.1.0. igraph 0.8.3. intervaltree NA. invoke 1.4.1. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. jinja2 2.11.2. jmespath 0.10.0. joblib 0.17.0. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.3. llvmlite 0.34.0. logzero 1.6.3. markupsafe 1.1.1. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.0.1. numba 0.51.2. numexpr 2.7.1. numpy 1.19.4. packaging 20.4. pandas 1.1.4. parso 0.7.1. pe",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1521
https://github.com/scverse/scanpy/issues/1521:188,deployability,version,version,188,"creating and plotting dendrograms do not see the same dendrogram ; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. np.random.seed(seed=0). df = pd.DataFrame(np.random.randn(50,50)). fake = sc.AnnData(df). fake.obs[""groups""] = np.random.choice(a=""a.b.c"".split("".""), size=50). fake.obs[""groups""] = fake.obs[""groups""].astype(""category""). sc.tl.dendrogram(fake, groupby = ""groups""). sc.pl.dendrogram(fake, groupby = ""groups""). ```. ```pytb. using data matrix X directly. Storing dendrogram info using `.uns[""dendrogram_['groups']""]`. WARNING: dendrogram data not found (using key=dendrogram_groups). Running `sc.tl.dendrogram` with default parameters. For fine tuning it is recommended to run `sc.tl.dendrogram` independently. using data matrix X directly. Storing dendrogram info using `.uns['dendrogram_groups']`. ```. ### Description. So as you can see in the reproduction, it looks like `sc.tl.dendrogram(fake, groupby = ""groups"")` **stores** the created dendrogram like this `.uns[""dendrogram_['groups']""] = dendro_data`. But it looks like `sc.pl.dendrogram(fake, groupby = ""groups"")` __expects__ to access this dendrogram like this `fake.uns['dendrogram_groups']` and when it can't find it, it creates a new dendrogram and stores it in `fake.uns['dendrogram_groups']`. My guess is that there is a mismatch in the logic of the code that builds the names of dendros in `sc.tl.dendrogram` vs the code that builds the names in `sc.pl.dendrogram`. If I had more time i would try to track it down for you and maybe even send a PR. Sorry though, I dont. . Can anyone confirm that this is NOT the expected behavior? #### Versions. <details>. ```. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1521
https://github.com/scverse/scanpy/issues/1521:1579,deployability,log,logic,1579,"ype(""category""). sc.tl.dendrogram(fake, groupby = ""groups""). sc.pl.dendrogram(fake, groupby = ""groups""). ```. ```pytb. using data matrix X directly. Storing dendrogram info using `.uns[""dendrogram_['groups']""]`. WARNING: dendrogram data not found (using key=dendrogram_groups). Running `sc.tl.dendrogram` with default parameters. For fine tuning it is recommended to run `sc.tl.dendrogram` independently. using data matrix X directly. Storing dendrogram info using `.uns['dendrogram_groups']`. ```. ### Description. So as you can see in the reproduction, it looks like `sc.tl.dendrogram(fake, groupby = ""groups"")` **stores** the created dendrogram like this `.uns[""dendrogram_['groups']""] = dendro_data`. But it looks like `sc.pl.dendrogram(fake, groupby = ""groups"")` __expects__ to access this dendrogram like this `fake.uns['dendrogram_groups']` and when it can't find it, it creates a new dendrogram and stores it in `fake.uns['dendrogram_groups']`. My guess is that there is a mismatch in the logic of the code that builds the names of dendros in `sc.tl.dendrogram` vs the code that builds the names in `sc.pl.dendrogram`. If I had more time i would try to track it down for you and maybe even send a PR. Sorry though, I dont. . Can anyone confirm that this is NOT the expected behavior? #### Versions. <details>. ```. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.6.0. sinfo 0.3.1. -----. OpenSSL 19.1.0. PIL 8.0.1. anndata 0.7.5. annoy NA. autoreload NA. backcall 0.2.0. botocore 1.19.22. brotli NA. certifi 2020.11.08. cffi 1.14.3. colorama 0.4.3. cryptography 3.2.1. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. defusedxml 0.6.0. fbpca NA. fsspec 0.8.4. get_version 2.1. h5py 3.1.0. igraph 0.8.3. intervaltree NA. invoke 1.4.1. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. jinja2 2.11.2. jmespath 0.10.0. joblib 0.17.0. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.3. llvmlite 0.34.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1521
https://github.com/scverse/scanpy/issues/1521:1602,deployability,build,builds,1602,"dendrogram(fake, groupby = ""groups""). sc.pl.dendrogram(fake, groupby = ""groups""). ```. ```pytb. using data matrix X directly. Storing dendrogram info using `.uns[""dendrogram_['groups']""]`. WARNING: dendrogram data not found (using key=dendrogram_groups). Running `sc.tl.dendrogram` with default parameters. For fine tuning it is recommended to run `sc.tl.dendrogram` independently. using data matrix X directly. Storing dendrogram info using `.uns['dendrogram_groups']`. ```. ### Description. So as you can see in the reproduction, it looks like `sc.tl.dendrogram(fake, groupby = ""groups"")` **stores** the created dendrogram like this `.uns[""dendrogram_['groups']""] = dendro_data`. But it looks like `sc.pl.dendrogram(fake, groupby = ""groups"")` __expects__ to access this dendrogram like this `fake.uns['dendrogram_groups']` and when it can't find it, it creates a new dendrogram and stores it in `fake.uns['dendrogram_groups']`. My guess is that there is a mismatch in the logic of the code that builds the names of dendros in `sc.tl.dendrogram` vs the code that builds the names in `sc.pl.dendrogram`. If I had more time i would try to track it down for you and maybe even send a PR. Sorry though, I dont. . Can anyone confirm that this is NOT the expected behavior? #### Versions. <details>. ```. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.6.0. sinfo 0.3.1. -----. OpenSSL 19.1.0. PIL 8.0.1. anndata 0.7.5. annoy NA. autoreload NA. backcall 0.2.0. botocore 1.19.22. brotli NA. certifi 2020.11.08. cffi 1.14.3. colorama 0.4.3. cryptography 3.2.1. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. defusedxml 0.6.0. fbpca NA. fsspec 0.8.4. get_version 2.1. h5py 3.1.0. igraph 0.8.3. intervaltree NA. invoke 1.4.1. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. jinja2 2.11.2. jmespath 0.10.0. joblib 0.17.0. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.3. llvmlite 0.34.0. logzero 1.6.3. markups",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1521
https://github.com/scverse/scanpy/issues/1521:1669,deployability,build,builds,1669,"y = ""groups""). ```. ```pytb. using data matrix X directly. Storing dendrogram info using `.uns[""dendrogram_['groups']""]`. WARNING: dendrogram data not found (using key=dendrogram_groups). Running `sc.tl.dendrogram` with default parameters. For fine tuning it is recommended to run `sc.tl.dendrogram` independently. using data matrix X directly. Storing dendrogram info using `.uns['dendrogram_groups']`. ```. ### Description. So as you can see in the reproduction, it looks like `sc.tl.dendrogram(fake, groupby = ""groups"")` **stores** the created dendrogram like this `.uns[""dendrogram_['groups']""] = dendro_data`. But it looks like `sc.pl.dendrogram(fake, groupby = ""groups"")` __expects__ to access this dendrogram like this `fake.uns['dendrogram_groups']` and when it can't find it, it creates a new dendrogram and stores it in `fake.uns['dendrogram_groups']`. My guess is that there is a mismatch in the logic of the code that builds the names of dendros in `sc.tl.dendrogram` vs the code that builds the names in `sc.pl.dendrogram`. If I had more time i would try to track it down for you and maybe even send a PR. Sorry though, I dont. . Can anyone confirm that this is NOT the expected behavior? #### Versions. <details>. ```. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.6.0. sinfo 0.3.1. -----. OpenSSL 19.1.0. PIL 8.0.1. anndata 0.7.5. annoy NA. autoreload NA. backcall 0.2.0. botocore 1.19.22. brotli NA. certifi 2020.11.08. cffi 1.14.3. colorama 0.4.3. cryptography 3.2.1. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. defusedxml 0.6.0. fbpca NA. fsspec 0.8.4. get_version 2.1. h5py 3.1.0. igraph 0.8.3. intervaltree NA. invoke 1.4.1. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. jinja2 2.11.2. jmespath 0.10.0. joblib 0.17.0. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.3. llvmlite 0.34.0. logzero 1.6.3. markupsafe 1.1.1. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.0.1. numba ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1521
https://github.com/scverse/scanpy/issues/1521:1879,deployability,Version,Versions,1879,"am` with default parameters. For fine tuning it is recommended to run `sc.tl.dendrogram` independently. using data matrix X directly. Storing dendrogram info using `.uns['dendrogram_groups']`. ```. ### Description. So as you can see in the reproduction, it looks like `sc.tl.dendrogram(fake, groupby = ""groups"")` **stores** the created dendrogram like this `.uns[""dendrogram_['groups']""] = dendro_data`. But it looks like `sc.pl.dendrogram(fake, groupby = ""groups"")` __expects__ to access this dendrogram like this `fake.uns['dendrogram_groups']` and when it can't find it, it creates a new dendrogram and stores it in `fake.uns['dendrogram_groups']`. My guess is that there is a mismatch in the logic of the code that builds the names of dendros in `sc.tl.dendrogram` vs the code that builds the names in `sc.pl.dendrogram`. If I had more time i would try to track it down for you and maybe even send a PR. Sorry though, I dont. . Can anyone confirm that this is NOT the expected behavior? #### Versions. <details>. ```. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.6.0. sinfo 0.3.1. -----. OpenSSL 19.1.0. PIL 8.0.1. anndata 0.7.5. annoy NA. autoreload NA. backcall 0.2.0. botocore 1.19.22. brotli NA. certifi 2020.11.08. cffi 1.14.3. colorama 0.4.3. cryptography 3.2.1. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. defusedxml 0.6.0. fbpca NA. fsspec 0.8.4. get_version 2.1. h5py 3.1.0. igraph 0.8.3. intervaltree NA. invoke 1.4.1. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. jinja2 2.11.2. jmespath 0.10.0. joblib 0.17.0. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.3. llvmlite 0.34.0. logzero 1.6.3. markupsafe 1.1.1. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.0.1. numba 0.51.2. numexpr 2.7.1. numpy 1.19.4. packaging 20.4. pandas 1.1.4. parso 0.7.1. pendulum 2.1.2. pexpect 4.8.0. pheno_tools 0.0.1. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.8. ptyprocess 0.6.0. pycp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1521
https://github.com/scverse/scanpy/issues/1521:2583,deployability,log,logzero,2583," the code that builds the names of dendros in `sc.tl.dendrogram` vs the code that builds the names in `sc.pl.dendrogram`. If I had more time i would try to track it down for you and maybe even send a PR. Sorry though, I dont. . Can anyone confirm that this is NOT the expected behavior? #### Versions. <details>. ```. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.6.0. sinfo 0.3.1. -----. OpenSSL 19.1.0. PIL 8.0.1. anndata 0.7.5. annoy NA. autoreload NA. backcall 0.2.0. botocore 1.19.22. brotli NA. certifi 2020.11.08. cffi 1.14.3. colorama 0.4.3. cryptography 3.2.1. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. defusedxml 0.6.0. fbpca NA. fsspec 0.8.4. get_version 2.1. h5py 3.1.0. igraph 0.8.3. intervaltree NA. invoke 1.4.1. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. jinja2 2.11.2. jmespath 0.10.0. joblib 0.17.0. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.3. llvmlite 0.34.0. logzero 1.6.3. markupsafe 1.1.1. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.0.1. numba 0.51.2. numexpr 2.7.1. numpy 1.19.4. packaging 20.4. pandas 1.1.4. parso 0.7.1. pendulum 2.1.2. pexpect 4.8.0. pheno_tools 0.0.1. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.8. ptyprocess 0.6.0. pycparser 2.20. pygments 2.7.2. pyparsing 2.4.7. pytz 2020.4. pytzdata NA. s3fs 0.4.2. scanorama 1.7. scanpy 1.6.0. scipy 1.5.3. seaborn 0.11.0. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. sortedcontainers 2.3.0. sphinxcontrib NA. statsmodels 0.12.1. storemagic NA. tables 3.6.1. texttable 1.6.3. tornado 6.1. tqdm 4.52.0. traitlets 5.0.5. typing_extensions NA. umap 0.4.6. urllib3 1.25.11. wcwidth 0.2.5. xlrd 1.2.0. yaml 5.3.1. zmq 20.0.0. -----. IPython 7.19.0. jupyter_client 6.1.7. jupyter_core 4.7.0. jupyterlab 2.2.9. notebook 6.1.5. -----. Python 3.8.6 | packaged by conda-forge | (default, Oct 7 2020, 19:08:05) [GCC 7.5.0]. Linux-4.4.0-1106-aws-x86_64-with-glibc2.10. 36 logical CPU",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1521
https://github.com/scverse/scanpy/issues/1521:3576,deployability,log,logical,3576," the names in `sc.pl.dendrogram`. If I had more time i would try to track it down for you and maybe even send a PR. Sorry though, I dont. . Can anyone confirm that this is NOT the expected behavior? #### Versions. <details>. ```. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.6.0. sinfo 0.3.1. -----. OpenSSL 19.1.0. PIL 8.0.1. anndata 0.7.5. annoy NA. autoreload NA. backcall 0.2.0. botocore 1.19.22. brotli NA. certifi 2020.11.08. cffi 1.14.3. colorama 0.4.3. cryptography 3.2.1. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. defusedxml 0.6.0. fbpca NA. fsspec 0.8.4. get_version 2.1. h5py 3.1.0. igraph 0.8.3. intervaltree NA. invoke 1.4.1. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. jinja2 2.11.2. jmespath 0.10.0. joblib 0.17.0. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.3. llvmlite 0.34.0. logzero 1.6.3. markupsafe 1.1.1. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.0.1. numba 0.51.2. numexpr 2.7.1. numpy 1.19.4. packaging 20.4. pandas 1.1.4. parso 0.7.1. pendulum 2.1.2. pexpect 4.8.0. pheno_tools 0.0.1. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.8. ptyprocess 0.6.0. pycparser 2.20. pygments 2.7.2. pyparsing 2.4.7. pytz 2020.4. pytzdata NA. s3fs 0.4.2. scanorama 1.7. scanpy 1.6.0. scipy 1.5.3. seaborn 0.11.0. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. sortedcontainers 2.3.0. sphinxcontrib NA. statsmodels 0.12.1. storemagic NA. tables 3.6.1. texttable 1.6.3. tornado 6.1. tqdm 4.52.0. traitlets 5.0.5. typing_extensions NA. umap 0.4.6. urllib3 1.25.11. wcwidth 0.2.5. xlrd 1.2.0. yaml 5.3.1. zmq 20.0.0. -----. IPython 7.19.0. jupyter_client 6.1.7. jupyter_core 4.7.0. jupyterlab 2.2.9. notebook 6.1.5. -----. Python 3.8.6 | packaged by conda-forge | (default, Oct 7 2020, 19:08:05) [GCC 7.5.0]. Linux-4.4.0-1106-aws-x86_64-with-glibc2.10. 36 logical CPU cores, x86_64. -----. Session information updated at 2020-12-02 22:22. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1521
https://github.com/scverse/scanpy/issues/1521:3630,deployability,updat,updated,3630," the names in `sc.pl.dendrogram`. If I had more time i would try to track it down for you and maybe even send a PR. Sorry though, I dont. . Can anyone confirm that this is NOT the expected behavior? #### Versions. <details>. ```. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.6.0. sinfo 0.3.1. -----. OpenSSL 19.1.0. PIL 8.0.1. anndata 0.7.5. annoy NA. autoreload NA. backcall 0.2.0. botocore 1.19.22. brotli NA. certifi 2020.11.08. cffi 1.14.3. colorama 0.4.3. cryptography 3.2.1. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. defusedxml 0.6.0. fbpca NA. fsspec 0.8.4. get_version 2.1. h5py 3.1.0. igraph 0.8.3. intervaltree NA. invoke 1.4.1. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. jinja2 2.11.2. jmespath 0.10.0. joblib 0.17.0. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.3. llvmlite 0.34.0. logzero 1.6.3. markupsafe 1.1.1. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.0.1. numba 0.51.2. numexpr 2.7.1. numpy 1.19.4. packaging 20.4. pandas 1.1.4. parso 0.7.1. pendulum 2.1.2. pexpect 4.8.0. pheno_tools 0.0.1. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.8. ptyprocess 0.6.0. pycparser 2.20. pygments 2.7.2. pyparsing 2.4.7. pytz 2020.4. pytzdata NA. s3fs 0.4.2. scanorama 1.7. scanpy 1.6.0. scipy 1.5.3. seaborn 0.11.0. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. sortedcontainers 2.3.0. sphinxcontrib NA. statsmodels 0.12.1. storemagic NA. tables 3.6.1. texttable 1.6.3. tornado 6.1. tqdm 4.52.0. traitlets 5.0.5. typing_extensions NA. umap 0.4.6. urllib3 1.25.11. wcwidth 0.2.5. xlrd 1.2.0. yaml 5.3.1. zmq 20.0.0. -----. IPython 7.19.0. jupyter_client 6.1.7. jupyter_core 4.7.0. jupyterlab 2.2.9. notebook 6.1.5. -----. Python 3.8.6 | packaged by conda-forge | (default, Oct 7 2020, 19:08:05) [GCC 7.5.0]. Linux-4.4.0-1106-aws-x86_64-with-glibc2.10. 36 logical CPU cores, x86_64. -----. Session information updated at 2020-12-02 22:22. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1521
https://github.com/scverse/scanpy/issues/1521:3584,energy efficiency,CPU,CPU,3584," the names in `sc.pl.dendrogram`. If I had more time i would try to track it down for you and maybe even send a PR. Sorry though, I dont. . Can anyone confirm that this is NOT the expected behavior? #### Versions. <details>. ```. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.6.0. sinfo 0.3.1. -----. OpenSSL 19.1.0. PIL 8.0.1. anndata 0.7.5. annoy NA. autoreload NA. backcall 0.2.0. botocore 1.19.22. brotli NA. certifi 2020.11.08. cffi 1.14.3. colorama 0.4.3. cryptography 3.2.1. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. defusedxml 0.6.0. fbpca NA. fsspec 0.8.4. get_version 2.1. h5py 3.1.0. igraph 0.8.3. intervaltree NA. invoke 1.4.1. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. jinja2 2.11.2. jmespath 0.10.0. joblib 0.17.0. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.3. llvmlite 0.34.0. logzero 1.6.3. markupsafe 1.1.1. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.0.1. numba 0.51.2. numexpr 2.7.1. numpy 1.19.4. packaging 20.4. pandas 1.1.4. parso 0.7.1. pendulum 2.1.2. pexpect 4.8.0. pheno_tools 0.0.1. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.8. ptyprocess 0.6.0. pycparser 2.20. pygments 2.7.2. pyparsing 2.4.7. pytz 2020.4. pytzdata NA. s3fs 0.4.2. scanorama 1.7. scanpy 1.6.0. scipy 1.5.3. seaborn 0.11.0. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. sortedcontainers 2.3.0. sphinxcontrib NA. statsmodels 0.12.1. storemagic NA. tables 3.6.1. texttable 1.6.3. tornado 6.1. tqdm 4.52.0. traitlets 5.0.5. typing_extensions NA. umap 0.4.6. urllib3 1.25.11. wcwidth 0.2.5. xlrd 1.2.0. yaml 5.3.1. zmq 20.0.0. -----. IPython 7.19.0. jupyter_client 6.1.7. jupyter_core 4.7.0. jupyterlab 2.2.9. notebook 6.1.5. -----. Python 3.8.6 | packaged by conda-forge | (default, Oct 7 2020, 19:08:05) [GCC 7.5.0]. Linux-4.4.0-1106-aws-x86_64-with-glibc2.10. 36 logical CPU cores, x86_64. -----. Session information updated at 2020-12-02 22:22. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1521
https://github.com/scverse/scanpy/issues/1521:3588,energy efficiency,core,cores,3588," the names in `sc.pl.dendrogram`. If I had more time i would try to track it down for you and maybe even send a PR. Sorry though, I dont. . Can anyone confirm that this is NOT the expected behavior? #### Versions. <details>. ```. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.6.0. sinfo 0.3.1. -----. OpenSSL 19.1.0. PIL 8.0.1. anndata 0.7.5. annoy NA. autoreload NA. backcall 0.2.0. botocore 1.19.22. brotli NA. certifi 2020.11.08. cffi 1.14.3. colorama 0.4.3. cryptography 3.2.1. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. defusedxml 0.6.0. fbpca NA. fsspec 0.8.4. get_version 2.1. h5py 3.1.0. igraph 0.8.3. intervaltree NA. invoke 1.4.1. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. jinja2 2.11.2. jmespath 0.10.0. joblib 0.17.0. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.3. llvmlite 0.34.0. logzero 1.6.3. markupsafe 1.1.1. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.0.1. numba 0.51.2. numexpr 2.7.1. numpy 1.19.4. packaging 20.4. pandas 1.1.4. parso 0.7.1. pendulum 2.1.2. pexpect 4.8.0. pheno_tools 0.0.1. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.8. ptyprocess 0.6.0. pycparser 2.20. pygments 2.7.2. pyparsing 2.4.7. pytz 2020.4. pytzdata NA. s3fs 0.4.2. scanorama 1.7. scanpy 1.6.0. scipy 1.5.3. seaborn 0.11.0. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. sortedcontainers 2.3.0. sphinxcontrib NA. statsmodels 0.12.1. storemagic NA. tables 3.6.1. texttable 1.6.3. tornado 6.1. tqdm 4.52.0. traitlets 5.0.5. typing_extensions NA. umap 0.4.6. urllib3 1.25.11. wcwidth 0.2.5. xlrd 1.2.0. yaml 5.3.1. zmq 20.0.0. -----. IPython 7.19.0. jupyter_client 6.1.7. jupyter_core 4.7.0. jupyterlab 2.2.9. notebook 6.1.5. -----. Python 3.8.6 | packaged by conda-forge | (default, Oct 7 2020, 19:08:05) [GCC 7.5.0]. Linux-4.4.0-1106-aws-x86_64-with-glibc2.10. 36 logical CPU cores, x86_64. -----. Session information updated at 2020-12-02 22:22. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1521
https://github.com/scverse/scanpy/issues/1521:188,integrability,version,version,188,"creating and plotting dendrograms do not see the same dendrogram ; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. np.random.seed(seed=0). df = pd.DataFrame(np.random.randn(50,50)). fake = sc.AnnData(df). fake.obs[""groups""] = np.random.choice(a=""a.b.c"".split("".""), size=50). fake.obs[""groups""] = fake.obs[""groups""].astype(""category""). sc.tl.dendrogram(fake, groupby = ""groups""). sc.pl.dendrogram(fake, groupby = ""groups""). ```. ```pytb. using data matrix X directly. Storing dendrogram info using `.uns[""dendrogram_['groups']""]`. WARNING: dendrogram data not found (using key=dendrogram_groups). Running `sc.tl.dendrogram` with default parameters. For fine tuning it is recommended to run `sc.tl.dendrogram` independently. using data matrix X directly. Storing dendrogram info using `.uns['dendrogram_groups']`. ```. ### Description. So as you can see in the reproduction, it looks like `sc.tl.dendrogram(fake, groupby = ""groups"")` **stores** the created dendrogram like this `.uns[""dendrogram_['groups']""] = dendro_data`. But it looks like `sc.pl.dendrogram(fake, groupby = ""groups"")` __expects__ to access this dendrogram like this `fake.uns['dendrogram_groups']` and when it can't find it, it creates a new dendrogram and stores it in `fake.uns['dendrogram_groups']`. My guess is that there is a mismatch in the logic of the code that builds the names of dendros in `sc.tl.dendrogram` vs the code that builds the names in `sc.pl.dendrogram`. If I had more time i would try to track it down for you and maybe even send a PR. Sorry though, I dont. . Can anyone confirm that this is NOT the expected behavior? #### Versions. <details>. ```. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1521
https://github.com/scverse/scanpy/issues/1521:1879,integrability,Version,Versions,1879,"am` with default parameters. For fine tuning it is recommended to run `sc.tl.dendrogram` independently. using data matrix X directly. Storing dendrogram info using `.uns['dendrogram_groups']`. ```. ### Description. So as you can see in the reproduction, it looks like `sc.tl.dendrogram(fake, groupby = ""groups"")` **stores** the created dendrogram like this `.uns[""dendrogram_['groups']""] = dendro_data`. But it looks like `sc.pl.dendrogram(fake, groupby = ""groups"")` __expects__ to access this dendrogram like this `fake.uns['dendrogram_groups']` and when it can't find it, it creates a new dendrogram and stores it in `fake.uns['dendrogram_groups']`. My guess is that there is a mismatch in the logic of the code that builds the names of dendros in `sc.tl.dendrogram` vs the code that builds the names in `sc.pl.dendrogram`. If I had more time i would try to track it down for you and maybe even send a PR. Sorry though, I dont. . Can anyone confirm that this is NOT the expected behavior? #### Versions. <details>. ```. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.6.0. sinfo 0.3.1. -----. OpenSSL 19.1.0. PIL 8.0.1. anndata 0.7.5. annoy NA. autoreload NA. backcall 0.2.0. botocore 1.19.22. brotli NA. certifi 2020.11.08. cffi 1.14.3. colorama 0.4.3. cryptography 3.2.1. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. defusedxml 0.6.0. fbpca NA. fsspec 0.8.4. get_version 2.1. h5py 3.1.0. igraph 0.8.3. intervaltree NA. invoke 1.4.1. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. jinja2 2.11.2. jmespath 0.10.0. joblib 0.17.0. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.3. llvmlite 0.34.0. logzero 1.6.3. markupsafe 1.1.1. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.0.1. numba 0.51.2. numexpr 2.7.1. numpy 1.19.4. packaging 20.4. pandas 1.1.4. parso 0.7.1. pendulum 2.1.2. pexpect 4.8.0. pheno_tools 0.0.1. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.8. ptyprocess 0.6.0. pycp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1521
https://github.com/scverse/scanpy/issues/1521:1563,interoperability,mismatch,mismatch,1563,"s[""groups""].astype(""category""). sc.tl.dendrogram(fake, groupby = ""groups""). sc.pl.dendrogram(fake, groupby = ""groups""). ```. ```pytb. using data matrix X directly. Storing dendrogram info using `.uns[""dendrogram_['groups']""]`. WARNING: dendrogram data not found (using key=dendrogram_groups). Running `sc.tl.dendrogram` with default parameters. For fine tuning it is recommended to run `sc.tl.dendrogram` independently. using data matrix X directly. Storing dendrogram info using `.uns['dendrogram_groups']`. ```. ### Description. So as you can see in the reproduction, it looks like `sc.tl.dendrogram(fake, groupby = ""groups"")` **stores** the created dendrogram like this `.uns[""dendrogram_['groups']""] = dendro_data`. But it looks like `sc.pl.dendrogram(fake, groupby = ""groups"")` __expects__ to access this dendrogram like this `fake.uns['dendrogram_groups']` and when it can't find it, it creates a new dendrogram and stores it in `fake.uns['dendrogram_groups']`. My guess is that there is a mismatch in the logic of the code that builds the names of dendros in `sc.tl.dendrogram` vs the code that builds the names in `sc.pl.dendrogram`. If I had more time i would try to track it down for you and maybe even send a PR. Sorry though, I dont. . Can anyone confirm that this is NOT the expected behavior? #### Versions. <details>. ```. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.6.0. sinfo 0.3.1. -----. OpenSSL 19.1.0. PIL 8.0.1. anndata 0.7.5. annoy NA. autoreload NA. backcall 0.2.0. botocore 1.19.22. brotli NA. certifi 2020.11.08. cffi 1.14.3. colorama 0.4.3. cryptography 3.2.1. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. defusedxml 0.6.0. fbpca NA. fsspec 0.8.4. get_version 2.1. h5py 3.1.0. igraph 0.8.3. intervaltree NA. invoke 1.4.1. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. jinja2 2.11.2. jmespath 0.10.0. joblib 0.17.0. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.3. l",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1521
https://github.com/scverse/scanpy/issues/1521:188,modifiability,version,version,188,"creating and plotting dendrograms do not see the same dendrogram ; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. np.random.seed(seed=0). df = pd.DataFrame(np.random.randn(50,50)). fake = sc.AnnData(df). fake.obs[""groups""] = np.random.choice(a=""a.b.c"".split("".""), size=50). fake.obs[""groups""] = fake.obs[""groups""].astype(""category""). sc.tl.dendrogram(fake, groupby = ""groups""). sc.pl.dendrogram(fake, groupby = ""groups""). ```. ```pytb. using data matrix X directly. Storing dendrogram info using `.uns[""dendrogram_['groups']""]`. WARNING: dendrogram data not found (using key=dendrogram_groups). Running `sc.tl.dendrogram` with default parameters. For fine tuning it is recommended to run `sc.tl.dendrogram` independently. using data matrix X directly. Storing dendrogram info using `.uns['dendrogram_groups']`. ```. ### Description. So as you can see in the reproduction, it looks like `sc.tl.dendrogram(fake, groupby = ""groups"")` **stores** the created dendrogram like this `.uns[""dendrogram_['groups']""] = dendro_data`. But it looks like `sc.pl.dendrogram(fake, groupby = ""groups"")` __expects__ to access this dendrogram like this `fake.uns['dendrogram_groups']` and when it can't find it, it creates a new dendrogram and stores it in `fake.uns['dendrogram_groups']`. My guess is that there is a mismatch in the logic of the code that builds the names of dendros in `sc.tl.dendrogram` vs the code that builds the names in `sc.pl.dendrogram`. If I had more time i would try to track it down for you and maybe even send a PR. Sorry though, I dont. . Can anyone confirm that this is NOT the expected behavior? #### Versions. <details>. ```. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1521
https://github.com/scverse/scanpy/issues/1521:900,modifiability,paramet,parameters,900,"creating and plotting dendrograms do not see the same dendrogram ; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. np.random.seed(seed=0). df = pd.DataFrame(np.random.randn(50,50)). fake = sc.AnnData(df). fake.obs[""groups""] = np.random.choice(a=""a.b.c"".split("".""), size=50). fake.obs[""groups""] = fake.obs[""groups""].astype(""category""). sc.tl.dendrogram(fake, groupby = ""groups""). sc.pl.dendrogram(fake, groupby = ""groups""). ```. ```pytb. using data matrix X directly. Storing dendrogram info using `.uns[""dendrogram_['groups']""]`. WARNING: dendrogram data not found (using key=dendrogram_groups). Running `sc.tl.dendrogram` with default parameters. For fine tuning it is recommended to run `sc.tl.dendrogram` independently. using data matrix X directly. Storing dendrogram info using `.uns['dendrogram_groups']`. ```. ### Description. So as you can see in the reproduction, it looks like `sc.tl.dendrogram(fake, groupby = ""groups"")` **stores** the created dendrogram like this `.uns[""dendrogram_['groups']""] = dendro_data`. But it looks like `sc.pl.dendrogram(fake, groupby = ""groups"")` __expects__ to access this dendrogram like this `fake.uns['dendrogram_groups']` and when it can't find it, it creates a new dendrogram and stores it in `fake.uns['dendrogram_groups']`. My guess is that there is a mismatch in the logic of the code that builds the names of dendros in `sc.tl.dendrogram` vs the code that builds the names in `sc.pl.dendrogram`. If I had more time i would try to track it down for you and maybe even send a PR. Sorry though, I dont. . Can anyone confirm that this is NOT the expected behavior? #### Versions. <details>. ```. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1521
https://github.com/scverse/scanpy/issues/1521:1879,modifiability,Version,Versions,1879,"am` with default parameters. For fine tuning it is recommended to run `sc.tl.dendrogram` independently. using data matrix X directly. Storing dendrogram info using `.uns['dendrogram_groups']`. ```. ### Description. So as you can see in the reproduction, it looks like `sc.tl.dendrogram(fake, groupby = ""groups"")` **stores** the created dendrogram like this `.uns[""dendrogram_['groups']""] = dendro_data`. But it looks like `sc.pl.dendrogram(fake, groupby = ""groups"")` __expects__ to access this dendrogram like this `fake.uns['dendrogram_groups']` and when it can't find it, it creates a new dendrogram and stores it in `fake.uns['dendrogram_groups']`. My guess is that there is a mismatch in the logic of the code that builds the names of dendros in `sc.tl.dendrogram` vs the code that builds the names in `sc.pl.dendrogram`. If I had more time i would try to track it down for you and maybe even send a PR. Sorry though, I dont. . Can anyone confirm that this is NOT the expected behavior? #### Versions. <details>. ```. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.6.0. sinfo 0.3.1. -----. OpenSSL 19.1.0. PIL 8.0.1. anndata 0.7.5. annoy NA. autoreload NA. backcall 0.2.0. botocore 1.19.22. brotli NA. certifi 2020.11.08. cffi 1.14.3. colorama 0.4.3. cryptography 3.2.1. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. defusedxml 0.6.0. fbpca NA. fsspec 0.8.4. get_version 2.1. h5py 3.1.0. igraph 0.8.3. intervaltree NA. invoke 1.4.1. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. jinja2 2.11.2. jmespath 0.10.0. joblib 0.17.0. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.3. llvmlite 0.34.0. logzero 1.6.3. markupsafe 1.1.1. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.0.1. numba 0.51.2. numexpr 2.7.1. numpy 1.19.4. packaging 20.4. pandas 1.1.4. parso 0.7.1. pendulum 2.1.2. pexpect 4.8.0. pheno_tools 0.0.1. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.8. ptyprocess 0.6.0. pycp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1521
https://github.com/scverse/scanpy/issues/1521:2256,modifiability,deco,decorator,2256,"roups']""] = dendro_data`. But it looks like `sc.pl.dendrogram(fake, groupby = ""groups"")` __expects__ to access this dendrogram like this `fake.uns['dendrogram_groups']` and when it can't find it, it creates a new dendrogram and stores it in `fake.uns['dendrogram_groups']`. My guess is that there is a mismatch in the logic of the code that builds the names of dendros in `sc.tl.dendrogram` vs the code that builds the names in `sc.pl.dendrogram`. If I had more time i would try to track it down for you and maybe even send a PR. Sorry though, I dont. . Can anyone confirm that this is NOT the expected behavior? #### Versions. <details>. ```. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.6.0. sinfo 0.3.1. -----. OpenSSL 19.1.0. PIL 8.0.1. anndata 0.7.5. annoy NA. autoreload NA. backcall 0.2.0. botocore 1.19.22. brotli NA. certifi 2020.11.08. cffi 1.14.3. colorama 0.4.3. cryptography 3.2.1. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. defusedxml 0.6.0. fbpca NA. fsspec 0.8.4. get_version 2.1. h5py 3.1.0. igraph 0.8.3. intervaltree NA. invoke 1.4.1. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. jinja2 2.11.2. jmespath 0.10.0. joblib 0.17.0. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.3. llvmlite 0.34.0. logzero 1.6.3. markupsafe 1.1.1. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.0.1. numba 0.51.2. numexpr 2.7.1. numpy 1.19.4. packaging 20.4. pandas 1.1.4. parso 0.7.1. pendulum 2.1.2. pexpect 4.8.0. pheno_tools 0.0.1. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.8. ptyprocess 0.6.0. pycparser 2.20. pygments 2.7.2. pyparsing 2.4.7. pytz 2020.4. pytzdata NA. s3fs 0.4.2. scanorama 1.7. scanpy 1.6.0. scipy 1.5.3. seaborn 0.11.0. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. sortedcontainers 2.3.0. sphinxcontrib NA. statsmodels 0.12.1. storemagic NA. tables 3.6.1. texttable 1.6.3. tornado 6.1. tqdm 4.52.0. traitlets 5.0.5. typing_extensions NA. umap",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1521
https://github.com/scverse/scanpy/issues/1521:2709,modifiability,pac,packaging,2709," the names in `sc.pl.dendrogram`. If I had more time i would try to track it down for you and maybe even send a PR. Sorry though, I dont. . Can anyone confirm that this is NOT the expected behavior? #### Versions. <details>. ```. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.6.0. sinfo 0.3.1. -----. OpenSSL 19.1.0. PIL 8.0.1. anndata 0.7.5. annoy NA. autoreload NA. backcall 0.2.0. botocore 1.19.22. brotli NA. certifi 2020.11.08. cffi 1.14.3. colorama 0.4.3. cryptography 3.2.1. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. defusedxml 0.6.0. fbpca NA. fsspec 0.8.4. get_version 2.1. h5py 3.1.0. igraph 0.8.3. intervaltree NA. invoke 1.4.1. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. jinja2 2.11.2. jmespath 0.10.0. joblib 0.17.0. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.3. llvmlite 0.34.0. logzero 1.6.3. markupsafe 1.1.1. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.0.1. numba 0.51.2. numexpr 2.7.1. numpy 1.19.4. packaging 20.4. pandas 1.1.4. parso 0.7.1. pendulum 2.1.2. pexpect 4.8.0. pheno_tools 0.0.1. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.8. ptyprocess 0.6.0. pycparser 2.20. pygments 2.7.2. pyparsing 2.4.7. pytz 2020.4. pytzdata NA. s3fs 0.4.2. scanorama 1.7. scanpy 1.6.0. scipy 1.5.3. seaborn 0.11.0. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. sortedcontainers 2.3.0. sphinxcontrib NA. statsmodels 0.12.1. storemagic NA. tables 3.6.1. texttable 1.6.3. tornado 6.1. tqdm 4.52.0. traitlets 5.0.5. typing_extensions NA. umap 0.4.6. urllib3 1.25.11. wcwidth 0.2.5. xlrd 1.2.0. yaml 5.3.1. zmq 20.0.0. -----. IPython 7.19.0. jupyter_client 6.1.7. jupyter_core 4.7.0. jupyterlab 2.2.9. notebook 6.1.5. -----. Python 3.8.6 | packaged by conda-forge | (default, Oct 7 2020, 19:08:05) [GCC 7.5.0]. Linux-4.4.0-1106-aws-x86_64-with-glibc2.10. 36 logical CPU cores, x86_64. -----. Session information updated at 2020-12-02 22:22. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1521
https://github.com/scverse/scanpy/issues/1521:3458,modifiability,pac,packaged,3458," the names in `sc.pl.dendrogram`. If I had more time i would try to track it down for you and maybe even send a PR. Sorry though, I dont. . Can anyone confirm that this is NOT the expected behavior? #### Versions. <details>. ```. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.6.0. sinfo 0.3.1. -----. OpenSSL 19.1.0. PIL 8.0.1. anndata 0.7.5. annoy NA. autoreload NA. backcall 0.2.0. botocore 1.19.22. brotli NA. certifi 2020.11.08. cffi 1.14.3. colorama 0.4.3. cryptography 3.2.1. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. defusedxml 0.6.0. fbpca NA. fsspec 0.8.4. get_version 2.1. h5py 3.1.0. igraph 0.8.3. intervaltree NA. invoke 1.4.1. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. jinja2 2.11.2. jmespath 0.10.0. joblib 0.17.0. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.3. llvmlite 0.34.0. logzero 1.6.3. markupsafe 1.1.1. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.0.1. numba 0.51.2. numexpr 2.7.1. numpy 1.19.4. packaging 20.4. pandas 1.1.4. parso 0.7.1. pendulum 2.1.2. pexpect 4.8.0. pheno_tools 0.0.1. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.8. ptyprocess 0.6.0. pycparser 2.20. pygments 2.7.2. pyparsing 2.4.7. pytz 2020.4. pytzdata NA. s3fs 0.4.2. scanorama 1.7. scanpy 1.6.0. scipy 1.5.3. seaborn 0.11.0. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. sortedcontainers 2.3.0. sphinxcontrib NA. statsmodels 0.12.1. storemagic NA. tables 3.6.1. texttable 1.6.3. tornado 6.1. tqdm 4.52.0. traitlets 5.0.5. typing_extensions NA. umap 0.4.6. urllib3 1.25.11. wcwidth 0.2.5. xlrd 1.2.0. yaml 5.3.1. zmq 20.0.0. -----. IPython 7.19.0. jupyter_client 6.1.7. jupyter_core 4.7.0. jupyterlab 2.2.9. notebook 6.1.5. -----. Python 3.8.6 | packaged by conda-forge | (default, Oct 7 2020, 19:08:05) [GCC 7.5.0]. Linux-4.4.0-1106-aws-x86_64-with-glibc2.10. 36 logical CPU cores, x86_64. -----. Session information updated at 2020-12-02 22:22. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1521
https://github.com/scverse/scanpy/issues/1521:1723,performance,time,time,1723,"ctly. Storing dendrogram info using `.uns[""dendrogram_['groups']""]`. WARNING: dendrogram data not found (using key=dendrogram_groups). Running `sc.tl.dendrogram` with default parameters. For fine tuning it is recommended to run `sc.tl.dendrogram` independently. using data matrix X directly. Storing dendrogram info using `.uns['dendrogram_groups']`. ```. ### Description. So as you can see in the reproduction, it looks like `sc.tl.dendrogram(fake, groupby = ""groups"")` **stores** the created dendrogram like this `.uns[""dendrogram_['groups']""] = dendro_data`. But it looks like `sc.pl.dendrogram(fake, groupby = ""groups"")` __expects__ to access this dendrogram like this `fake.uns['dendrogram_groups']` and when it can't find it, it creates a new dendrogram and stores it in `fake.uns['dendrogram_groups']`. My guess is that there is a mismatch in the logic of the code that builds the names of dendros in `sc.tl.dendrogram` vs the code that builds the names in `sc.pl.dendrogram`. If I had more time i would try to track it down for you and maybe even send a PR. Sorry though, I dont. . Can anyone confirm that this is NOT the expected behavior? #### Versions. <details>. ```. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.6.0. sinfo 0.3.1. -----. OpenSSL 19.1.0. PIL 8.0.1. anndata 0.7.5. annoy NA. autoreload NA. backcall 0.2.0. botocore 1.19.22. brotli NA. certifi 2020.11.08. cffi 1.14.3. colorama 0.4.3. cryptography 3.2.1. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. defusedxml 0.6.0. fbpca NA. fsspec 0.8.4. get_version 2.1. h5py 3.1.0. igraph 0.8.3. intervaltree NA. invoke 1.4.1. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. jinja2 2.11.2. jmespath 0.10.0. joblib 0.17.0. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.3. llvmlite 0.34.0. logzero 1.6.3. markupsafe 1.1.1. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.0.1. numba 0.51.2. numexpr 2.7.1. numpy 1.19.4. packaging 20.4. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1521
https://github.com/scverse/scanpy/issues/1521:3584,performance,CPU,CPU,3584," the names in `sc.pl.dendrogram`. If I had more time i would try to track it down for you and maybe even send a PR. Sorry though, I dont. . Can anyone confirm that this is NOT the expected behavior? #### Versions. <details>. ```. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.6.0. sinfo 0.3.1. -----. OpenSSL 19.1.0. PIL 8.0.1. anndata 0.7.5. annoy NA. autoreload NA. backcall 0.2.0. botocore 1.19.22. brotli NA. certifi 2020.11.08. cffi 1.14.3. colorama 0.4.3. cryptography 3.2.1. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. defusedxml 0.6.0. fbpca NA. fsspec 0.8.4. get_version 2.1. h5py 3.1.0. igraph 0.8.3. intervaltree NA. invoke 1.4.1. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. jinja2 2.11.2. jmespath 0.10.0. joblib 0.17.0. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.3. llvmlite 0.34.0. logzero 1.6.3. markupsafe 1.1.1. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.0.1. numba 0.51.2. numexpr 2.7.1. numpy 1.19.4. packaging 20.4. pandas 1.1.4. parso 0.7.1. pendulum 2.1.2. pexpect 4.8.0. pheno_tools 0.0.1. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.8. ptyprocess 0.6.0. pycparser 2.20. pygments 2.7.2. pyparsing 2.4.7. pytz 2020.4. pytzdata NA. s3fs 0.4.2. scanorama 1.7. scanpy 1.6.0. scipy 1.5.3. seaborn 0.11.0. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. sortedcontainers 2.3.0. sphinxcontrib NA. statsmodels 0.12.1. storemagic NA. tables 3.6.1. texttable 1.6.3. tornado 6.1. tqdm 4.52.0. traitlets 5.0.5. typing_extensions NA. umap 0.4.6. urllib3 1.25.11. wcwidth 0.2.5. xlrd 1.2.0. yaml 5.3.1. zmq 20.0.0. -----. IPython 7.19.0. jupyter_client 6.1.7. jupyter_core 4.7.0. jupyterlab 2.2.9. notebook 6.1.5. -----. Python 3.8.6 | packaged by conda-forge | (default, Oct 7 2020, 19:08:05) [GCC 7.5.0]. Linux-4.4.0-1106-aws-x86_64-with-glibc2.10. 36 logical CPU cores, x86_64. -----. Session information updated at 2020-12-02 22:22. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1521
https://github.com/scverse/scanpy/issues/1521:1579,safety,log,logic,1579,"ype(""category""). sc.tl.dendrogram(fake, groupby = ""groups""). sc.pl.dendrogram(fake, groupby = ""groups""). ```. ```pytb. using data matrix X directly. Storing dendrogram info using `.uns[""dendrogram_['groups']""]`. WARNING: dendrogram data not found (using key=dendrogram_groups). Running `sc.tl.dendrogram` with default parameters. For fine tuning it is recommended to run `sc.tl.dendrogram` independently. using data matrix X directly. Storing dendrogram info using `.uns['dendrogram_groups']`. ```. ### Description. So as you can see in the reproduction, it looks like `sc.tl.dendrogram(fake, groupby = ""groups"")` **stores** the created dendrogram like this `.uns[""dendrogram_['groups']""] = dendro_data`. But it looks like `sc.pl.dendrogram(fake, groupby = ""groups"")` __expects__ to access this dendrogram like this `fake.uns['dendrogram_groups']` and when it can't find it, it creates a new dendrogram and stores it in `fake.uns['dendrogram_groups']`. My guess is that there is a mismatch in the logic of the code that builds the names of dendros in `sc.tl.dendrogram` vs the code that builds the names in `sc.pl.dendrogram`. If I had more time i would try to track it down for you and maybe even send a PR. Sorry though, I dont. . Can anyone confirm that this is NOT the expected behavior? #### Versions. <details>. ```. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.6.0. sinfo 0.3.1. -----. OpenSSL 19.1.0. PIL 8.0.1. anndata 0.7.5. annoy NA. autoreload NA. backcall 0.2.0. botocore 1.19.22. brotli NA. certifi 2020.11.08. cffi 1.14.3. colorama 0.4.3. cryptography 3.2.1. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. defusedxml 0.6.0. fbpca NA. fsspec 0.8.4. get_version 2.1. h5py 3.1.0. igraph 0.8.3. intervaltree NA. invoke 1.4.1. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. jinja2 2.11.2. jmespath 0.10.0. joblib 0.17.0. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.3. llvmlite 0.34.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1521
https://github.com/scverse/scanpy/issues/1521:2583,safety,log,logzero,2583," the code that builds the names of dendros in `sc.tl.dendrogram` vs the code that builds the names in `sc.pl.dendrogram`. If I had more time i would try to track it down for you and maybe even send a PR. Sorry though, I dont. . Can anyone confirm that this is NOT the expected behavior? #### Versions. <details>. ```. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.6.0. sinfo 0.3.1. -----. OpenSSL 19.1.0. PIL 8.0.1. anndata 0.7.5. annoy NA. autoreload NA. backcall 0.2.0. botocore 1.19.22. brotli NA. certifi 2020.11.08. cffi 1.14.3. colorama 0.4.3. cryptography 3.2.1. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. defusedxml 0.6.0. fbpca NA. fsspec 0.8.4. get_version 2.1. h5py 3.1.0. igraph 0.8.3. intervaltree NA. invoke 1.4.1. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. jinja2 2.11.2. jmespath 0.10.0. joblib 0.17.0. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.3. llvmlite 0.34.0. logzero 1.6.3. markupsafe 1.1.1. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.0.1. numba 0.51.2. numexpr 2.7.1. numpy 1.19.4. packaging 20.4. pandas 1.1.4. parso 0.7.1. pendulum 2.1.2. pexpect 4.8.0. pheno_tools 0.0.1. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.8. ptyprocess 0.6.0. pycparser 2.20. pygments 2.7.2. pyparsing 2.4.7. pytz 2020.4. pytzdata NA. s3fs 0.4.2. scanorama 1.7. scanpy 1.6.0. scipy 1.5.3. seaborn 0.11.0. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. sortedcontainers 2.3.0. sphinxcontrib NA. statsmodels 0.12.1. storemagic NA. tables 3.6.1. texttable 1.6.3. tornado 6.1. tqdm 4.52.0. traitlets 5.0.5. typing_extensions NA. umap 0.4.6. urllib3 1.25.11. wcwidth 0.2.5. xlrd 1.2.0. yaml 5.3.1. zmq 20.0.0. -----. IPython 7.19.0. jupyter_client 6.1.7. jupyter_core 4.7.0. jupyterlab 2.2.9. notebook 6.1.5. -----. Python 3.8.6 | packaged by conda-forge | (default, Oct 7 2020, 19:08:05) [GCC 7.5.0]. Linux-4.4.0-1106-aws-x86_64-with-glibc2.10. 36 logical CPU",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1521
https://github.com/scverse/scanpy/issues/1521:3576,safety,log,logical,3576," the names in `sc.pl.dendrogram`. If I had more time i would try to track it down for you and maybe even send a PR. Sorry though, I dont. . Can anyone confirm that this is NOT the expected behavior? #### Versions. <details>. ```. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.6.0. sinfo 0.3.1. -----. OpenSSL 19.1.0. PIL 8.0.1. anndata 0.7.5. annoy NA. autoreload NA. backcall 0.2.0. botocore 1.19.22. brotli NA. certifi 2020.11.08. cffi 1.14.3. colorama 0.4.3. cryptography 3.2.1. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. defusedxml 0.6.0. fbpca NA. fsspec 0.8.4. get_version 2.1. h5py 3.1.0. igraph 0.8.3. intervaltree NA. invoke 1.4.1. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. jinja2 2.11.2. jmespath 0.10.0. joblib 0.17.0. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.3. llvmlite 0.34.0. logzero 1.6.3. markupsafe 1.1.1. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.0.1. numba 0.51.2. numexpr 2.7.1. numpy 1.19.4. packaging 20.4. pandas 1.1.4. parso 0.7.1. pendulum 2.1.2. pexpect 4.8.0. pheno_tools 0.0.1. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.8. ptyprocess 0.6.0. pycparser 2.20. pygments 2.7.2. pyparsing 2.4.7. pytz 2020.4. pytzdata NA. s3fs 0.4.2. scanorama 1.7. scanpy 1.6.0. scipy 1.5.3. seaborn 0.11.0. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. sortedcontainers 2.3.0. sphinxcontrib NA. statsmodels 0.12.1. storemagic NA. tables 3.6.1. texttable 1.6.3. tornado 6.1. tqdm 4.52.0. traitlets 5.0.5. typing_extensions NA. umap 0.4.6. urllib3 1.25.11. wcwidth 0.2.5. xlrd 1.2.0. yaml 5.3.1. zmq 20.0.0. -----. IPython 7.19.0. jupyter_client 6.1.7. jupyter_core 4.7.0. jupyterlab 2.2.9. notebook 6.1.5. -----. Python 3.8.6 | packaged by conda-forge | (default, Oct 7 2020, 19:08:05) [GCC 7.5.0]. Linux-4.4.0-1106-aws-x86_64-with-glibc2.10. 36 logical CPU cores, x86_64. -----. Session information updated at 2020-12-02 22:22. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1521
https://github.com/scverse/scanpy/issues/1521:3630,safety,updat,updated,3630," the names in `sc.pl.dendrogram`. If I had more time i would try to track it down for you and maybe even send a PR. Sorry though, I dont. . Can anyone confirm that this is NOT the expected behavior? #### Versions. <details>. ```. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.6.0. sinfo 0.3.1. -----. OpenSSL 19.1.0. PIL 8.0.1. anndata 0.7.5. annoy NA. autoreload NA. backcall 0.2.0. botocore 1.19.22. brotli NA. certifi 2020.11.08. cffi 1.14.3. colorama 0.4.3. cryptography 3.2.1. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. defusedxml 0.6.0. fbpca NA. fsspec 0.8.4. get_version 2.1. h5py 3.1.0. igraph 0.8.3. intervaltree NA. invoke 1.4.1. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. jinja2 2.11.2. jmespath 0.10.0. joblib 0.17.0. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.3. llvmlite 0.34.0. logzero 1.6.3. markupsafe 1.1.1. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.0.1. numba 0.51.2. numexpr 2.7.1. numpy 1.19.4. packaging 20.4. pandas 1.1.4. parso 0.7.1. pendulum 2.1.2. pexpect 4.8.0. pheno_tools 0.0.1. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.8. ptyprocess 0.6.0. pycparser 2.20. pygments 2.7.2. pyparsing 2.4.7. pytz 2020.4. pytzdata NA. s3fs 0.4.2. scanorama 1.7. scanpy 1.6.0. scipy 1.5.3. seaborn 0.11.0. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. sortedcontainers 2.3.0. sphinxcontrib NA. statsmodels 0.12.1. storemagic NA. tables 3.6.1. texttable 1.6.3. tornado 6.1. tqdm 4.52.0. traitlets 5.0.5. typing_extensions NA. umap 0.4.6. urllib3 1.25.11. wcwidth 0.2.5. xlrd 1.2.0. yaml 5.3.1. zmq 20.0.0. -----. IPython 7.19.0. jupyter_client 6.1.7. jupyter_core 4.7.0. jupyterlab 2.2.9. notebook 6.1.5. -----. Python 3.8.6 | packaged by conda-forge | (default, Oct 7 2020, 19:08:05) [GCC 7.5.0]. Linux-4.4.0-1106-aws-x86_64-with-glibc2.10. 36 logical CPU cores, x86_64. -----. Session information updated at 2020-12-02 22:22. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1521
https://github.com/scverse/scanpy/issues/1521:1365,security,access,access,1365,"```python. np.random.seed(seed=0). df = pd.DataFrame(np.random.randn(50,50)). fake = sc.AnnData(df). fake.obs[""groups""] = np.random.choice(a=""a.b.c"".split("".""), size=50). fake.obs[""groups""] = fake.obs[""groups""].astype(""category""). sc.tl.dendrogram(fake, groupby = ""groups""). sc.pl.dendrogram(fake, groupby = ""groups""). ```. ```pytb. using data matrix X directly. Storing dendrogram info using `.uns[""dendrogram_['groups']""]`. WARNING: dendrogram data not found (using key=dendrogram_groups). Running `sc.tl.dendrogram` with default parameters. For fine tuning it is recommended to run `sc.tl.dendrogram` independently. using data matrix X directly. Storing dendrogram info using `.uns['dendrogram_groups']`. ```. ### Description. So as you can see in the reproduction, it looks like `sc.tl.dendrogram(fake, groupby = ""groups"")` **stores** the created dendrogram like this `.uns[""dendrogram_['groups']""] = dendro_data`. But it looks like `sc.pl.dendrogram(fake, groupby = ""groups"")` __expects__ to access this dendrogram like this `fake.uns['dendrogram_groups']` and when it can't find it, it creates a new dendrogram and stores it in `fake.uns['dendrogram_groups']`. My guess is that there is a mismatch in the logic of the code that builds the names of dendros in `sc.tl.dendrogram` vs the code that builds the names in `sc.pl.dendrogram`. If I had more time i would try to track it down for you and maybe even send a PR. Sorry though, I dont. . Can anyone confirm that this is NOT the expected behavior? #### Versions. <details>. ```. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.6.0. sinfo 0.3.1. -----. OpenSSL 19.1.0. PIL 8.0.1. anndata 0.7.5. annoy NA. autoreload NA. backcall 0.2.0. botocore 1.19.22. brotli NA. certifi 2020.11.08. cffi 1.14.3. colorama 0.4.3. cryptography 3.2.1. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. defusedxml 0.6.0. fbpca NA. fsspec 0.8.4. get_version 2.1. h5py 3.1.0. igraph 0.8.3. intervaltr",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1521
https://github.com/scverse/scanpy/issues/1521:1579,security,log,logic,1579,"ype(""category""). sc.tl.dendrogram(fake, groupby = ""groups""). sc.pl.dendrogram(fake, groupby = ""groups""). ```. ```pytb. using data matrix X directly. Storing dendrogram info using `.uns[""dendrogram_['groups']""]`. WARNING: dendrogram data not found (using key=dendrogram_groups). Running `sc.tl.dendrogram` with default parameters. For fine tuning it is recommended to run `sc.tl.dendrogram` independently. using data matrix X directly. Storing dendrogram info using `.uns['dendrogram_groups']`. ```. ### Description. So as you can see in the reproduction, it looks like `sc.tl.dendrogram(fake, groupby = ""groups"")` **stores** the created dendrogram like this `.uns[""dendrogram_['groups']""] = dendro_data`. But it looks like `sc.pl.dendrogram(fake, groupby = ""groups"")` __expects__ to access this dendrogram like this `fake.uns['dendrogram_groups']` and when it can't find it, it creates a new dendrogram and stores it in `fake.uns['dendrogram_groups']`. My guess is that there is a mismatch in the logic of the code that builds the names of dendros in `sc.tl.dendrogram` vs the code that builds the names in `sc.pl.dendrogram`. If I had more time i would try to track it down for you and maybe even send a PR. Sorry though, I dont. . Can anyone confirm that this is NOT the expected behavior? #### Versions. <details>. ```. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.6.0. sinfo 0.3.1. -----. OpenSSL 19.1.0. PIL 8.0.1. anndata 0.7.5. annoy NA. autoreload NA. backcall 0.2.0. botocore 1.19.22. brotli NA. certifi 2020.11.08. cffi 1.14.3. colorama 0.4.3. cryptography 3.2.1. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. defusedxml 0.6.0. fbpca NA. fsspec 0.8.4. get_version 2.1. h5py 3.1.0. igraph 0.8.3. intervaltree NA. invoke 1.4.1. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. jinja2 2.11.2. jmespath 0.10.0. joblib 0.17.0. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.3. llvmlite 0.34.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1521
https://github.com/scverse/scanpy/issues/1521:2137,security,certif,certifi,2137,"ooks like `sc.tl.dendrogram(fake, groupby = ""groups"")` **stores** the created dendrogram like this `.uns[""dendrogram_['groups']""] = dendro_data`. But it looks like `sc.pl.dendrogram(fake, groupby = ""groups"")` __expects__ to access this dendrogram like this `fake.uns['dendrogram_groups']` and when it can't find it, it creates a new dendrogram and stores it in `fake.uns['dendrogram_groups']`. My guess is that there is a mismatch in the logic of the code that builds the names of dendros in `sc.tl.dendrogram` vs the code that builds the names in `sc.pl.dendrogram`. If I had more time i would try to track it down for you and maybe even send a PR. Sorry though, I dont. . Can anyone confirm that this is NOT the expected behavior? #### Versions. <details>. ```. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.6.0. sinfo 0.3.1. -----. OpenSSL 19.1.0. PIL 8.0.1. anndata 0.7.5. annoy NA. autoreload NA. backcall 0.2.0. botocore 1.19.22. brotli NA. certifi 2020.11.08. cffi 1.14.3. colorama 0.4.3. cryptography 3.2.1. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. defusedxml 0.6.0. fbpca NA. fsspec 0.8.4. get_version 2.1. h5py 3.1.0. igraph 0.8.3. intervaltree NA. invoke 1.4.1. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. jinja2 2.11.2. jmespath 0.10.0. joblib 0.17.0. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.3. llvmlite 0.34.0. logzero 1.6.3. markupsafe 1.1.1. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.0.1. numba 0.51.2. numexpr 2.7.1. numpy 1.19.4. packaging 20.4. pandas 1.1.4. parso 0.7.1. pendulum 2.1.2. pexpect 4.8.0. pheno_tools 0.0.1. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.8. ptyprocess 0.6.0. pycparser 2.20. pygments 2.7.2. pyparsing 2.4.7. pytz 2020.4. pytzdata NA. s3fs 0.4.2. scanorama 1.7. scanpy 1.6.0. scipy 1.5.3. seaborn 0.11.0. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. sortedcontainers 2.3.0. sphinxcontrib NA. statsmodels 0.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1521
https://github.com/scverse/scanpy/issues/1521:2186,security,cryptograph,cryptography,2186,""")` **stores** the created dendrogram like this `.uns[""dendrogram_['groups']""] = dendro_data`. But it looks like `sc.pl.dendrogram(fake, groupby = ""groups"")` __expects__ to access this dendrogram like this `fake.uns['dendrogram_groups']` and when it can't find it, it creates a new dendrogram and stores it in `fake.uns['dendrogram_groups']`. My guess is that there is a mismatch in the logic of the code that builds the names of dendros in `sc.tl.dendrogram` vs the code that builds the names in `sc.pl.dendrogram`. If I had more time i would try to track it down for you and maybe even send a PR. Sorry though, I dont. . Can anyone confirm that this is NOT the expected behavior? #### Versions. <details>. ```. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.6.0. sinfo 0.3.1. -----. OpenSSL 19.1.0. PIL 8.0.1. anndata 0.7.5. annoy NA. autoreload NA. backcall 0.2.0. botocore 1.19.22. brotli NA. certifi 2020.11.08. cffi 1.14.3. colorama 0.4.3. cryptography 3.2.1. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. defusedxml 0.6.0. fbpca NA. fsspec 0.8.4. get_version 2.1. h5py 3.1.0. igraph 0.8.3. intervaltree NA. invoke 1.4.1. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. jinja2 2.11.2. jmespath 0.10.0. joblib 0.17.0. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.3. llvmlite 0.34.0. logzero 1.6.3. markupsafe 1.1.1. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.0.1. numba 0.51.2. numexpr 2.7.1. numpy 1.19.4. packaging 20.4. pandas 1.1.4. parso 0.7.1. pendulum 2.1.2. pexpect 4.8.0. pheno_tools 0.0.1. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.8. ptyprocess 0.6.0. pycparser 2.20. pygments 2.7.2. pyparsing 2.4.7. pytz 2020.4. pytzdata NA. s3fs 0.4.2. scanorama 1.7. scanpy 1.6.0. scipy 1.5.3. seaborn 0.11.0. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. sortedcontainers 2.3.0. sphinxcontrib NA. statsmodels 0.12.1. storemagic NA. tables 3.6.1. texttable 1.6.3. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1521
https://github.com/scverse/scanpy/issues/1521:2583,security,log,logzero,2583," the code that builds the names of dendros in `sc.tl.dendrogram` vs the code that builds the names in `sc.pl.dendrogram`. If I had more time i would try to track it down for you and maybe even send a PR. Sorry though, I dont. . Can anyone confirm that this is NOT the expected behavior? #### Versions. <details>. ```. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.6.0. sinfo 0.3.1. -----. OpenSSL 19.1.0. PIL 8.0.1. anndata 0.7.5. annoy NA. autoreload NA. backcall 0.2.0. botocore 1.19.22. brotli NA. certifi 2020.11.08. cffi 1.14.3. colorama 0.4.3. cryptography 3.2.1. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. defusedxml 0.6.0. fbpca NA. fsspec 0.8.4. get_version 2.1. h5py 3.1.0. igraph 0.8.3. intervaltree NA. invoke 1.4.1. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. jinja2 2.11.2. jmespath 0.10.0. joblib 0.17.0. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.3. llvmlite 0.34.0. logzero 1.6.3. markupsafe 1.1.1. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.0.1. numba 0.51.2. numexpr 2.7.1. numpy 1.19.4. packaging 20.4. pandas 1.1.4. parso 0.7.1. pendulum 2.1.2. pexpect 4.8.0. pheno_tools 0.0.1. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.8. ptyprocess 0.6.0. pycparser 2.20. pygments 2.7.2. pyparsing 2.4.7. pytz 2020.4. pytzdata NA. s3fs 0.4.2. scanorama 1.7. scanpy 1.6.0. scipy 1.5.3. seaborn 0.11.0. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. sortedcontainers 2.3.0. sphinxcontrib NA. statsmodels 0.12.1. storemagic NA. tables 3.6.1. texttable 1.6.3. tornado 6.1. tqdm 4.52.0. traitlets 5.0.5. typing_extensions NA. umap 0.4.6. urllib3 1.25.11. wcwidth 0.2.5. xlrd 1.2.0. yaml 5.3.1. zmq 20.0.0. -----. IPython 7.19.0. jupyter_client 6.1.7. jupyter_core 4.7.0. jupyterlab 2.2.9. notebook 6.1.5. -----. Python 3.8.6 | packaged by conda-forge | (default, Oct 7 2020, 19:08:05) [GCC 7.5.0]. Linux-4.4.0-1106-aws-x86_64-with-glibc2.10. 36 logical CPU",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1521
https://github.com/scverse/scanpy/issues/1521:3576,security,log,logical,3576," the names in `sc.pl.dendrogram`. If I had more time i would try to track it down for you and maybe even send a PR. Sorry though, I dont. . Can anyone confirm that this is NOT the expected behavior? #### Versions. <details>. ```. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.6.0. sinfo 0.3.1. -----. OpenSSL 19.1.0. PIL 8.0.1. anndata 0.7.5. annoy NA. autoreload NA. backcall 0.2.0. botocore 1.19.22. brotli NA. certifi 2020.11.08. cffi 1.14.3. colorama 0.4.3. cryptography 3.2.1. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. defusedxml 0.6.0. fbpca NA. fsspec 0.8.4. get_version 2.1. h5py 3.1.0. igraph 0.8.3. intervaltree NA. invoke 1.4.1. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. jinja2 2.11.2. jmespath 0.10.0. joblib 0.17.0. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.3. llvmlite 0.34.0. logzero 1.6.3. markupsafe 1.1.1. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.0.1. numba 0.51.2. numexpr 2.7.1. numpy 1.19.4. packaging 20.4. pandas 1.1.4. parso 0.7.1. pendulum 2.1.2. pexpect 4.8.0. pheno_tools 0.0.1. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.8. ptyprocess 0.6.0. pycparser 2.20. pygments 2.7.2. pyparsing 2.4.7. pytz 2020.4. pytzdata NA. s3fs 0.4.2. scanorama 1.7. scanpy 1.6.0. scipy 1.5.3. seaborn 0.11.0. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. sortedcontainers 2.3.0. sphinxcontrib NA. statsmodels 0.12.1. storemagic NA. tables 3.6.1. texttable 1.6.3. tornado 6.1. tqdm 4.52.0. traitlets 5.0.5. typing_extensions NA. umap 0.4.6. urllib3 1.25.11. wcwidth 0.2.5. xlrd 1.2.0. yaml 5.3.1. zmq 20.0.0. -----. IPython 7.19.0. jupyter_client 6.1.7. jupyter_core 4.7.0. jupyterlab 2.2.9. notebook 6.1.5. -----. Python 3.8.6 | packaged by conda-forge | (default, Oct 7 2020, 19:08:05) [GCC 7.5.0]. Linux-4.4.0-1106-aws-x86_64-with-glibc2.10. 36 logical CPU cores, x86_64. -----. Session information updated at 2020-12-02 22:22. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1521
https://github.com/scverse/scanpy/issues/1521:3610,security,Session,Session,3610," the names in `sc.pl.dendrogram`. If I had more time i would try to track it down for you and maybe even send a PR. Sorry though, I dont. . Can anyone confirm that this is NOT the expected behavior? #### Versions. <details>. ```. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.6.0. sinfo 0.3.1. -----. OpenSSL 19.1.0. PIL 8.0.1. anndata 0.7.5. annoy NA. autoreload NA. backcall 0.2.0. botocore 1.19.22. brotli NA. certifi 2020.11.08. cffi 1.14.3. colorama 0.4.3. cryptography 3.2.1. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. defusedxml 0.6.0. fbpca NA. fsspec 0.8.4. get_version 2.1. h5py 3.1.0. igraph 0.8.3. intervaltree NA. invoke 1.4.1. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. jinja2 2.11.2. jmespath 0.10.0. joblib 0.17.0. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.3. llvmlite 0.34.0. logzero 1.6.3. markupsafe 1.1.1. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.0.1. numba 0.51.2. numexpr 2.7.1. numpy 1.19.4. packaging 20.4. pandas 1.1.4. parso 0.7.1. pendulum 2.1.2. pexpect 4.8.0. pheno_tools 0.0.1. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.8. ptyprocess 0.6.0. pycparser 2.20. pygments 2.7.2. pyparsing 2.4.7. pytz 2020.4. pytzdata NA. s3fs 0.4.2. scanorama 1.7. scanpy 1.6.0. scipy 1.5.3. seaborn 0.11.0. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. sortedcontainers 2.3.0. sphinxcontrib NA. statsmodels 0.12.1. storemagic NA. tables 3.6.1. texttable 1.6.3. tornado 6.1. tqdm 4.52.0. traitlets 5.0.5. typing_extensions NA. umap 0.4.6. urllib3 1.25.11. wcwidth 0.2.5. xlrd 1.2.0. yaml 5.3.1. zmq 20.0.0. -----. IPython 7.19.0. jupyter_client 6.1.7. jupyter_core 4.7.0. jupyterlab 2.2.9. notebook 6.1.5. -----. Python 3.8.6 | packaged by conda-forge | (default, Oct 7 2020, 19:08:05) [GCC 7.5.0]. Linux-4.4.0-1106-aws-x86_64-with-glibc2.10. 36 logical CPU cores, x86_64. -----. Session information updated at 2020-12-02 22:22. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1521
https://github.com/scverse/scanpy/issues/1521:3630,security,updat,updated,3630," the names in `sc.pl.dendrogram`. If I had more time i would try to track it down for you and maybe even send a PR. Sorry though, I dont. . Can anyone confirm that this is NOT the expected behavior? #### Versions. <details>. ```. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.6.0. sinfo 0.3.1. -----. OpenSSL 19.1.0. PIL 8.0.1. anndata 0.7.5. annoy NA. autoreload NA. backcall 0.2.0. botocore 1.19.22. brotli NA. certifi 2020.11.08. cffi 1.14.3. colorama 0.4.3. cryptography 3.2.1. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. defusedxml 0.6.0. fbpca NA. fsspec 0.8.4. get_version 2.1. h5py 3.1.0. igraph 0.8.3. intervaltree NA. invoke 1.4.1. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. jinja2 2.11.2. jmespath 0.10.0. joblib 0.17.0. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.3. llvmlite 0.34.0. logzero 1.6.3. markupsafe 1.1.1. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.0.1. numba 0.51.2. numexpr 2.7.1. numpy 1.19.4. packaging 20.4. pandas 1.1.4. parso 0.7.1. pendulum 2.1.2. pexpect 4.8.0. pheno_tools 0.0.1. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.8. ptyprocess 0.6.0. pycparser 2.20. pygments 2.7.2. pyparsing 2.4.7. pytz 2020.4. pytzdata NA. s3fs 0.4.2. scanorama 1.7. scanpy 1.6.0. scipy 1.5.3. seaborn 0.11.0. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. sortedcontainers 2.3.0. sphinxcontrib NA. statsmodels 0.12.1. storemagic NA. tables 3.6.1. texttable 1.6.3. tornado 6.1. tqdm 4.52.0. traitlets 5.0.5. typing_extensions NA. umap 0.4.6. urllib3 1.25.11. wcwidth 0.2.5. xlrd 1.2.0. yaml 5.3.1. zmq 20.0.0. -----. IPython 7.19.0. jupyter_client 6.1.7. jupyter_core 4.7.0. jupyterlab 2.2.9. notebook 6.1.5. -----. Python 3.8.6 | packaged by conda-forge | (default, Oct 7 2020, 19:08:05) [GCC 7.5.0]. Linux-4.4.0-1106-aws-x86_64-with-glibc2.10. 36 logical CPU cores, x86_64. -----. Session information updated at 2020-12-02 22:22. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1521
https://github.com/scverse/scanpy/issues/1521:1579,testability,log,logic,1579,"ype(""category""). sc.tl.dendrogram(fake, groupby = ""groups""). sc.pl.dendrogram(fake, groupby = ""groups""). ```. ```pytb. using data matrix X directly. Storing dendrogram info using `.uns[""dendrogram_['groups']""]`. WARNING: dendrogram data not found (using key=dendrogram_groups). Running `sc.tl.dendrogram` with default parameters. For fine tuning it is recommended to run `sc.tl.dendrogram` independently. using data matrix X directly. Storing dendrogram info using `.uns['dendrogram_groups']`. ```. ### Description. So as you can see in the reproduction, it looks like `sc.tl.dendrogram(fake, groupby = ""groups"")` **stores** the created dendrogram like this `.uns[""dendrogram_['groups']""] = dendro_data`. But it looks like `sc.pl.dendrogram(fake, groupby = ""groups"")` __expects__ to access this dendrogram like this `fake.uns['dendrogram_groups']` and when it can't find it, it creates a new dendrogram and stores it in `fake.uns['dendrogram_groups']`. My guess is that there is a mismatch in the logic of the code that builds the names of dendros in `sc.tl.dendrogram` vs the code that builds the names in `sc.pl.dendrogram`. If I had more time i would try to track it down for you and maybe even send a PR. Sorry though, I dont. . Can anyone confirm that this is NOT the expected behavior? #### Versions. <details>. ```. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.6.0. sinfo 0.3.1. -----. OpenSSL 19.1.0. PIL 8.0.1. anndata 0.7.5. annoy NA. autoreload NA. backcall 0.2.0. botocore 1.19.22. brotli NA. certifi 2020.11.08. cffi 1.14.3. colorama 0.4.3. cryptography 3.2.1. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. defusedxml 0.6.0. fbpca NA. fsspec 0.8.4. get_version 2.1. h5py 3.1.0. igraph 0.8.3. intervaltree NA. invoke 1.4.1. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. jinja2 2.11.2. jmespath 0.10.0. joblib 0.17.0. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.3. llvmlite 0.34.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1521
https://github.com/scverse/scanpy/issues/1521:2583,testability,log,logzero,2583," the code that builds the names of dendros in `sc.tl.dendrogram` vs the code that builds the names in `sc.pl.dendrogram`. If I had more time i would try to track it down for you and maybe even send a PR. Sorry though, I dont. . Can anyone confirm that this is NOT the expected behavior? #### Versions. <details>. ```. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.6.0. sinfo 0.3.1. -----. OpenSSL 19.1.0. PIL 8.0.1. anndata 0.7.5. annoy NA. autoreload NA. backcall 0.2.0. botocore 1.19.22. brotli NA. certifi 2020.11.08. cffi 1.14.3. colorama 0.4.3. cryptography 3.2.1. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. defusedxml 0.6.0. fbpca NA. fsspec 0.8.4. get_version 2.1. h5py 3.1.0. igraph 0.8.3. intervaltree NA. invoke 1.4.1. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. jinja2 2.11.2. jmespath 0.10.0. joblib 0.17.0. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.3. llvmlite 0.34.0. logzero 1.6.3. markupsafe 1.1.1. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.0.1. numba 0.51.2. numexpr 2.7.1. numpy 1.19.4. packaging 20.4. pandas 1.1.4. parso 0.7.1. pendulum 2.1.2. pexpect 4.8.0. pheno_tools 0.0.1. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.8. ptyprocess 0.6.0. pycparser 2.20. pygments 2.7.2. pyparsing 2.4.7. pytz 2020.4. pytzdata NA. s3fs 0.4.2. scanorama 1.7. scanpy 1.6.0. scipy 1.5.3. seaborn 0.11.0. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. sortedcontainers 2.3.0. sphinxcontrib NA. statsmodels 0.12.1. storemagic NA. tables 3.6.1. texttable 1.6.3. tornado 6.1. tqdm 4.52.0. traitlets 5.0.5. typing_extensions NA. umap 0.4.6. urllib3 1.25.11. wcwidth 0.2.5. xlrd 1.2.0. yaml 5.3.1. zmq 20.0.0. -----. IPython 7.19.0. jupyter_client 6.1.7. jupyter_core 4.7.0. jupyterlab 2.2.9. notebook 6.1.5. -----. Python 3.8.6 | packaged by conda-forge | (default, Oct 7 2020, 19:08:05) [GCC 7.5.0]. Linux-4.4.0-1106-aws-x86_64-with-glibc2.10. 36 logical CPU",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1521
https://github.com/scverse/scanpy/issues/1521:3576,testability,log,logical,3576," the names in `sc.pl.dendrogram`. If I had more time i would try to track it down for you and maybe even send a PR. Sorry though, I dont. . Can anyone confirm that this is NOT the expected behavior? #### Versions. <details>. ```. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.6.0. sinfo 0.3.1. -----. OpenSSL 19.1.0. PIL 8.0.1. anndata 0.7.5. annoy NA. autoreload NA. backcall 0.2.0. botocore 1.19.22. brotli NA. certifi 2020.11.08. cffi 1.14.3. colorama 0.4.3. cryptography 3.2.1. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. defusedxml 0.6.0. fbpca NA. fsspec 0.8.4. get_version 2.1. h5py 3.1.0. igraph 0.8.3. intervaltree NA. invoke 1.4.1. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. jinja2 2.11.2. jmespath 0.10.0. joblib 0.17.0. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.3. llvmlite 0.34.0. logzero 1.6.3. markupsafe 1.1.1. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.0.1. numba 0.51.2. numexpr 2.7.1. numpy 1.19.4. packaging 20.4. pandas 1.1.4. parso 0.7.1. pendulum 2.1.2. pexpect 4.8.0. pheno_tools 0.0.1. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.8. ptyprocess 0.6.0. pycparser 2.20. pygments 2.7.2. pyparsing 2.4.7. pytz 2020.4. pytzdata NA. s3fs 0.4.2. scanorama 1.7. scanpy 1.6.0. scipy 1.5.3. seaborn 0.11.0. setuptools_scm NA. sinfo 0.3.1. six 1.15.0. sklearn 0.23.2. sortedcontainers 2.3.0. sphinxcontrib NA. statsmodels 0.12.1. storemagic NA. tables 3.6.1. texttable 1.6.3. tornado 6.1. tqdm 4.52.0. traitlets 5.0.5. typing_extensions NA. umap 0.4.6. urllib3 1.25.11. wcwidth 0.2.5. xlrd 1.2.0. yaml 5.3.1. zmq 20.0.0. -----. IPython 7.19.0. jupyter_client 6.1.7. jupyter_core 4.7.0. jupyterlab 2.2.9. notebook 6.1.5. -----. Python 3.8.6 | packaged by conda-forge | (default, Oct 7 2020, 19:08:05) [GCC 7.5.0]. Linux-4.4.0-1106-aws-x86_64-with-glibc2.10. 36 logical CPU cores, x86_64. -----. Session information updated at 2020-12-02 22:22. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1521
https://github.com/scverse/scanpy/issues/1521:148,usability,confirm,confirmed,148,"creating and plotting dendrograms do not see the same dendrogram ; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. np.random.seed(seed=0). df = pd.DataFrame(np.random.randn(50,50)). fake = sc.AnnData(df). fake.obs[""groups""] = np.random.choice(a=""a.b.c"".split("".""), size=50). fake.obs[""groups""] = fake.obs[""groups""].astype(""category""). sc.tl.dendrogram(fake, groupby = ""groups""). sc.pl.dendrogram(fake, groupby = ""groups""). ```. ```pytb. using data matrix X directly. Storing dendrogram info using `.uns[""dendrogram_['groups']""]`. WARNING: dendrogram data not found (using key=dendrogram_groups). Running `sc.tl.dendrogram` with default parameters. For fine tuning it is recommended to run `sc.tl.dendrogram` independently. using data matrix X directly. Storing dendrogram info using `.uns['dendrogram_groups']`. ```. ### Description. So as you can see in the reproduction, it looks like `sc.tl.dendrogram(fake, groupby = ""groups"")` **stores** the created dendrogram like this `.uns[""dendrogram_['groups']""] = dendro_data`. But it looks like `sc.pl.dendrogram(fake, groupby = ""groups"")` __expects__ to access this dendrogram like this `fake.uns['dendrogram_groups']` and when it can't find it, it creates a new dendrogram and stores it in `fake.uns['dendrogram_groups']`. My guess is that there is a mismatch in the logic of the code that builds the names of dendros in `sc.tl.dendrogram` vs the code that builds the names in `sc.pl.dendrogram`. If I had more time i would try to track it down for you and maybe even send a PR. Sorry though, I dont. . Can anyone confirm that this is NOT the expected behavior? #### Versions. <details>. ```. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1521
https://github.com/scverse/scanpy/issues/1521:231,usability,confirm,confirmed,231,"creating and plotting dendrograms do not see the same dendrogram ; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. np.random.seed(seed=0). df = pd.DataFrame(np.random.randn(50,50)). fake = sc.AnnData(df). fake.obs[""groups""] = np.random.choice(a=""a.b.c"".split("".""), size=50). fake.obs[""groups""] = fake.obs[""groups""].astype(""category""). sc.tl.dendrogram(fake, groupby = ""groups""). sc.pl.dendrogram(fake, groupby = ""groups""). ```. ```pytb. using data matrix X directly. Storing dendrogram info using `.uns[""dendrogram_['groups']""]`. WARNING: dendrogram data not found (using key=dendrogram_groups). Running `sc.tl.dendrogram` with default parameters. For fine tuning it is recommended to run `sc.tl.dendrogram` independently. using data matrix X directly. Storing dendrogram info using `.uns['dendrogram_groups']`. ```. ### Description. So as you can see in the reproduction, it looks like `sc.tl.dendrogram(fake, groupby = ""groups"")` **stores** the created dendrogram like this `.uns[""dendrogram_['groups']""] = dendro_data`. But it looks like `sc.pl.dendrogram(fake, groupby = ""groups"")` __expects__ to access this dendrogram like this `fake.uns['dendrogram_groups']` and when it can't find it, it creates a new dendrogram and stores it in `fake.uns['dendrogram_groups']`. My guess is that there is a mismatch in the logic of the code that builds the names of dendros in `sc.tl.dendrogram` vs the code that builds the names in `sc.pl.dendrogram`. If I had more time i would try to track it down for you and maybe even send a PR. Sorry though, I dont. . Can anyone confirm that this is NOT the expected behavior? #### Versions. <details>. ```. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1521
https://github.com/scverse/scanpy/issues/1521:298,usability,Minim,Minimal,298,"creating and plotting dendrograms do not see the same dendrogram ; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. np.random.seed(seed=0). df = pd.DataFrame(np.random.randn(50,50)). fake = sc.AnnData(df). fake.obs[""groups""] = np.random.choice(a=""a.b.c"".split("".""), size=50). fake.obs[""groups""] = fake.obs[""groups""].astype(""category""). sc.tl.dendrogram(fake, groupby = ""groups""). sc.pl.dendrogram(fake, groupby = ""groups""). ```. ```pytb. using data matrix X directly. Storing dendrogram info using `.uns[""dendrogram_['groups']""]`. WARNING: dendrogram data not found (using key=dendrogram_groups). Running `sc.tl.dendrogram` with default parameters. For fine tuning it is recommended to run `sc.tl.dendrogram` independently. using data matrix X directly. Storing dendrogram info using `.uns['dendrogram_groups']`. ```. ### Description. So as you can see in the reproduction, it looks like `sc.tl.dendrogram(fake, groupby = ""groups"")` **stores** the created dendrogram like this `.uns[""dendrogram_['groups']""] = dendro_data`. But it looks like `sc.pl.dendrogram(fake, groupby = ""groups"")` __expects__ to access this dendrogram like this `fake.uns['dendrogram_groups']` and when it can't find it, it creates a new dendrogram and stores it in `fake.uns['dendrogram_groups']`. My guess is that there is a mismatch in the logic of the code that builds the names of dendros in `sc.tl.dendrogram` vs the code that builds the names in `sc.pl.dendrogram`. If I had more time i would try to track it down for you and maybe even send a PR. Sorry though, I dont. . Can anyone confirm that this is NOT the expected behavior? #### Versions. <details>. ```. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1521
https://github.com/scverse/scanpy/issues/1521:1826,usability,confirm,confirm,1826,"using key=dendrogram_groups). Running `sc.tl.dendrogram` with default parameters. For fine tuning it is recommended to run `sc.tl.dendrogram` independently. using data matrix X directly. Storing dendrogram info using `.uns['dendrogram_groups']`. ```. ### Description. So as you can see in the reproduction, it looks like `sc.tl.dendrogram(fake, groupby = ""groups"")` **stores** the created dendrogram like this `.uns[""dendrogram_['groups']""] = dendro_data`. But it looks like `sc.pl.dendrogram(fake, groupby = ""groups"")` __expects__ to access this dendrogram like this `fake.uns['dendrogram_groups']` and when it can't find it, it creates a new dendrogram and stores it in `fake.uns['dendrogram_groups']`. My guess is that there is a mismatch in the logic of the code that builds the names of dendros in `sc.tl.dendrogram` vs the code that builds the names in `sc.pl.dendrogram`. If I had more time i would try to track it down for you and maybe even send a PR. Sorry though, I dont. . Can anyone confirm that this is NOT the expected behavior? #### Versions. <details>. ```. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.6.0. sinfo 0.3.1. -----. OpenSSL 19.1.0. PIL 8.0.1. anndata 0.7.5. annoy NA. autoreload NA. backcall 0.2.0. botocore 1.19.22. brotli NA. certifi 2020.11.08. cffi 1.14.3. colorama 0.4.3. cryptography 3.2.1. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. defusedxml 0.6.0. fbpca NA. fsspec 0.8.4. get_version 2.1. h5py 3.1.0. igraph 0.8.3. intervaltree NA. invoke 1.4.1. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. jinja2 2.11.2. jmespath 0.10.0. joblib 0.17.0. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.3. llvmlite 0.34.0. logzero 1.6.3. markupsafe 1.1.1. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.0.1. numba 0.51.2. numexpr 2.7.1. numpy 1.19.4. packaging 20.4. pandas 1.1.4. parso 0.7.1. pendulum 2.1.2. pexpect 4.8.0. pheno_tools 0.0.1. pickleshare 0.7.5. pkg_resou",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1521
https://github.com/scverse/scanpy/issues/1521:1864,usability,behavi,behavior,1864,"`sc.tl.dendrogram` with default parameters. For fine tuning it is recommended to run `sc.tl.dendrogram` independently. using data matrix X directly. Storing dendrogram info using `.uns['dendrogram_groups']`. ```. ### Description. So as you can see in the reproduction, it looks like `sc.tl.dendrogram(fake, groupby = ""groups"")` **stores** the created dendrogram like this `.uns[""dendrogram_['groups']""] = dendro_data`. But it looks like `sc.pl.dendrogram(fake, groupby = ""groups"")` __expects__ to access this dendrogram like this `fake.uns['dendrogram_groups']` and when it can't find it, it creates a new dendrogram and stores it in `fake.uns['dendrogram_groups']`. My guess is that there is a mismatch in the logic of the code that builds the names of dendros in `sc.tl.dendrogram` vs the code that builds the names in `sc.pl.dendrogram`. If I had more time i would try to track it down for you and maybe even send a PR. Sorry though, I dont. . Can anyone confirm that this is NOT the expected behavior? #### Versions. <details>. ```. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.6.0. sinfo 0.3.1. -----. OpenSSL 19.1.0. PIL 8.0.1. anndata 0.7.5. annoy NA. autoreload NA. backcall 0.2.0. botocore 1.19.22. brotli NA. certifi 2020.11.08. cffi 1.14.3. colorama 0.4.3. cryptography 3.2.1. cycler 0.10.0. cython_runtime NA. dateutil 2.8.1. decorator 4.4.2. defusedxml 0.6.0. fbpca NA. fsspec 0.8.4. get_version 2.1. h5py 3.1.0. igraph 0.8.3. intervaltree NA. invoke 1.4.1. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. jinja2 2.11.2. jmespath 0.10.0. joblib 0.17.0. kiwisolver 1.3.1. legacy_api_wrap 0.0.0. leidenalg 0.8.3. llvmlite 0.34.0. logzero 1.6.3. markupsafe 1.1.1. matplotlib 3.3.3. mpl_toolkits NA. natsort 7.0.1. numba 0.51.2. numexpr 2.7.1. numpy 1.19.4. packaging 20.4. pandas 1.1.4. parso 0.7.1. pendulum 2.1.2. pexpect 4.8.0. pheno_tools 0.0.1. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.8. ptyproc",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1521
https://github.com/scverse/scanpy/pull/1524:13,deployability,depend,dependent,13,Skip louvain-dependent tests;  if not installed,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1524
https://github.com/scverse/scanpy/pull/1524:39,deployability,instal,installed,39,Skip louvain-dependent tests;  if not installed,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1524
https://github.com/scverse/scanpy/pull/1524:13,integrability,depend,dependent,13,Skip louvain-dependent tests;  if not installed,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1524
https://github.com/scverse/scanpy/pull/1524:13,modifiability,depend,dependent,13,Skip louvain-dependent tests;  if not installed,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1524
https://github.com/scverse/scanpy/pull/1524:13,safety,depend,dependent,13,Skip louvain-dependent tests;  if not installed,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1524
https://github.com/scverse/scanpy/pull/1524:23,safety,test,tests,23,Skip louvain-dependent tests;  if not installed,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1524
https://github.com/scverse/scanpy/pull/1524:13,testability,depend,dependent,13,Skip louvain-dependent tests;  if not installed,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1524
https://github.com/scverse/scanpy/pull/1524:23,testability,test,tests,23,Skip louvain-dependent tests;  if not installed,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1524
https://github.com/scverse/scanpy/pull/1527:45,deployability,instal,install,45,"Switch to flit; What stays the same:. - `pip install scanpy`. - `pip install . `. - `pip install git+https://...`. - you can install your deps with conda. - you can do a dev install. What changes:. - Please check the [install docs](https://scanpy.readthedocs.io/en/flit-for-isaac/installation.html#development-version), in short:. - `pip install -e .[every,single,extra]`  `flit install -s` for dev installs. - `beni pyproject.toml > environment.yml` for conda. - Extremely simple `flit build` and `flit publish`. Maybe install `keyring` to store your publish password, and you know everything you need to. - `flit build` doesnt clutter your dev directory with `build/` and `*.egg-info/` junk, it just creates `dist/scanpy-*{.whl,.tar.gz}`. - No more obscure stuff nobody understands (MANIFEST.in, package_data, ). - Centralized setup configuration in pyproject.toml instead of spread over multiple files",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:69,deployability,instal,install,69,"Switch to flit; What stays the same:. - `pip install scanpy`. - `pip install . `. - `pip install git+https://...`. - you can install your deps with conda. - you can do a dev install. What changes:. - Please check the [install docs](https://scanpy.readthedocs.io/en/flit-for-isaac/installation.html#development-version), in short:. - `pip install -e .[every,single,extra]`  `flit install -s` for dev installs. - `beni pyproject.toml > environment.yml` for conda. - Extremely simple `flit build` and `flit publish`. Maybe install `keyring` to store your publish password, and you know everything you need to. - `flit build` doesnt clutter your dev directory with `build/` and `*.egg-info/` junk, it just creates `dist/scanpy-*{.whl,.tar.gz}`. - No more obscure stuff nobody understands (MANIFEST.in, package_data, ). - Centralized setup configuration in pyproject.toml instead of spread over multiple files",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:89,deployability,instal,install,89,"Switch to flit; What stays the same:. - `pip install scanpy`. - `pip install . `. - `pip install git+https://...`. - you can install your deps with conda. - you can do a dev install. What changes:. - Please check the [install docs](https://scanpy.readthedocs.io/en/flit-for-isaac/installation.html#development-version), in short:. - `pip install -e .[every,single,extra]`  `flit install -s` for dev installs. - `beni pyproject.toml > environment.yml` for conda. - Extremely simple `flit build` and `flit publish`. Maybe install `keyring` to store your publish password, and you know everything you need to. - `flit build` doesnt clutter your dev directory with `build/` and `*.egg-info/` junk, it just creates `dist/scanpy-*{.whl,.tar.gz}`. - No more obscure stuff nobody understands (MANIFEST.in, package_data, ). - Centralized setup configuration in pyproject.toml instead of spread over multiple files",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:125,deployability,instal,install,125,"Switch to flit; What stays the same:. - `pip install scanpy`. - `pip install . `. - `pip install git+https://...`. - you can install your deps with conda. - you can do a dev install. What changes:. - Please check the [install docs](https://scanpy.readthedocs.io/en/flit-for-isaac/installation.html#development-version), in short:. - `pip install -e .[every,single,extra]`  `flit install -s` for dev installs. - `beni pyproject.toml > environment.yml` for conda. - Extremely simple `flit build` and `flit publish`. Maybe install `keyring` to store your publish password, and you know everything you need to. - `flit build` doesnt clutter your dev directory with `build/` and `*.egg-info/` junk, it just creates `dist/scanpy-*{.whl,.tar.gz}`. - No more obscure stuff nobody understands (MANIFEST.in, package_data, ). - Centralized setup configuration in pyproject.toml instead of spread over multiple files",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:174,deployability,instal,install,174,"Switch to flit; What stays the same:. - `pip install scanpy`. - `pip install . `. - `pip install git+https://...`. - you can install your deps with conda. - you can do a dev install. What changes:. - Please check the [install docs](https://scanpy.readthedocs.io/en/flit-for-isaac/installation.html#development-version), in short:. - `pip install -e .[every,single,extra]`  `flit install -s` for dev installs. - `beni pyproject.toml > environment.yml` for conda. - Extremely simple `flit build` and `flit publish`. Maybe install `keyring` to store your publish password, and you know everything you need to. - `flit build` doesnt clutter your dev directory with `build/` and `*.egg-info/` junk, it just creates `dist/scanpy-*{.whl,.tar.gz}`. - No more obscure stuff nobody understands (MANIFEST.in, package_data, ). - Centralized setup configuration in pyproject.toml instead of spread over multiple files",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:218,deployability,instal,install,218,"Switch to flit; What stays the same:. - `pip install scanpy`. - `pip install . `. - `pip install git+https://...`. - you can install your deps with conda. - you can do a dev install. What changes:. - Please check the [install docs](https://scanpy.readthedocs.io/en/flit-for-isaac/installation.html#development-version), in short:. - `pip install -e .[every,single,extra]`  `flit install -s` for dev installs. - `beni pyproject.toml > environment.yml` for conda. - Extremely simple `flit build` and `flit publish`. Maybe install `keyring` to store your publish password, and you know everything you need to. - `flit build` doesnt clutter your dev directory with `build/` and `*.egg-info/` junk, it just creates `dist/scanpy-*{.whl,.tar.gz}`. - No more obscure stuff nobody understands (MANIFEST.in, package_data, ). - Centralized setup configuration in pyproject.toml instead of spread over multiple files",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:280,deployability,instal,installation,280,"Switch to flit; What stays the same:. - `pip install scanpy`. - `pip install . `. - `pip install git+https://...`. - you can install your deps with conda. - you can do a dev install. What changes:. - Please check the [install docs](https://scanpy.readthedocs.io/en/flit-for-isaac/installation.html#development-version), in short:. - `pip install -e .[every,single,extra]`  `flit install -s` for dev installs. - `beni pyproject.toml > environment.yml` for conda. - Extremely simple `flit build` and `flit publish`. Maybe install `keyring` to store your publish password, and you know everything you need to. - `flit build` doesnt clutter your dev directory with `build/` and `*.egg-info/` junk, it just creates `dist/scanpy-*{.whl,.tar.gz}`. - No more obscure stuff nobody understands (MANIFEST.in, package_data, ). - Centralized setup configuration in pyproject.toml instead of spread over multiple files",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:310,deployability,version,version,310,"Switch to flit; What stays the same:. - `pip install scanpy`. - `pip install . `. - `pip install git+https://...`. - you can install your deps with conda. - you can do a dev install. What changes:. - Please check the [install docs](https://scanpy.readthedocs.io/en/flit-for-isaac/installation.html#development-version), in short:. - `pip install -e .[every,single,extra]`  `flit install -s` for dev installs. - `beni pyproject.toml > environment.yml` for conda. - Extremely simple `flit build` and `flit publish`. Maybe install `keyring` to store your publish password, and you know everything you need to. - `flit build` doesnt clutter your dev directory with `build/` and `*.egg-info/` junk, it just creates `dist/scanpy-*{.whl,.tar.gz}`. - No more obscure stuff nobody understands (MANIFEST.in, package_data, ). - Centralized setup configuration in pyproject.toml instead of spread over multiple files",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:338,deployability,instal,install,338,"Switch to flit; What stays the same:. - `pip install scanpy`. - `pip install . `. - `pip install git+https://...`. - you can install your deps with conda. - you can do a dev install. What changes:. - Please check the [install docs](https://scanpy.readthedocs.io/en/flit-for-isaac/installation.html#development-version), in short:. - `pip install -e .[every,single,extra]`  `flit install -s` for dev installs. - `beni pyproject.toml > environment.yml` for conda. - Extremely simple `flit build` and `flit publish`. Maybe install `keyring` to store your publish password, and you know everything you need to. - `flit build` doesnt clutter your dev directory with `build/` and `*.egg-info/` junk, it just creates `dist/scanpy-*{.whl,.tar.gz}`. - No more obscure stuff nobody understands (MANIFEST.in, package_data, ). - Centralized setup configuration in pyproject.toml instead of spread over multiple files",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:380,deployability,instal,install,380,"Switch to flit; What stays the same:. - `pip install scanpy`. - `pip install . `. - `pip install git+https://...`. - you can install your deps with conda. - you can do a dev install. What changes:. - Please check the [install docs](https://scanpy.readthedocs.io/en/flit-for-isaac/installation.html#development-version), in short:. - `pip install -e .[every,single,extra]`  `flit install -s` for dev installs. - `beni pyproject.toml > environment.yml` for conda. - Extremely simple `flit build` and `flit publish`. Maybe install `keyring` to store your publish password, and you know everything you need to. - `flit build` doesnt clutter your dev directory with `build/` and `*.egg-info/` junk, it just creates `dist/scanpy-*{.whl,.tar.gz}`. - No more obscure stuff nobody understands (MANIFEST.in, package_data, ). - Centralized setup configuration in pyproject.toml instead of spread over multiple files",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:400,deployability,instal,installs,400,"Switch to flit; What stays the same:. - `pip install scanpy`. - `pip install . `. - `pip install git+https://...`. - you can install your deps with conda. - you can do a dev install. What changes:. - Please check the [install docs](https://scanpy.readthedocs.io/en/flit-for-isaac/installation.html#development-version), in short:. - `pip install -e .[every,single,extra]`  `flit install -s` for dev installs. - `beni pyproject.toml > environment.yml` for conda. - Extremely simple `flit build` and `flit publish`. Maybe install `keyring` to store your publish password, and you know everything you need to. - `flit build` doesnt clutter your dev directory with `build/` and `*.egg-info/` junk, it just creates `dist/scanpy-*{.whl,.tar.gz}`. - No more obscure stuff nobody understands (MANIFEST.in, package_data, ). - Centralized setup configuration in pyproject.toml instead of spread over multiple files",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:488,deployability,build,build,488,"Switch to flit; What stays the same:. - `pip install scanpy`. - `pip install . `. - `pip install git+https://...`. - you can install your deps with conda. - you can do a dev install. What changes:. - Please check the [install docs](https://scanpy.readthedocs.io/en/flit-for-isaac/installation.html#development-version), in short:. - `pip install -e .[every,single,extra]`  `flit install -s` for dev installs. - `beni pyproject.toml > environment.yml` for conda. - Extremely simple `flit build` and `flit publish`. Maybe install `keyring` to store your publish password, and you know everything you need to. - `flit build` doesnt clutter your dev directory with `build/` and `*.egg-info/` junk, it just creates `dist/scanpy-*{.whl,.tar.gz}`. - No more obscure stuff nobody understands (MANIFEST.in, package_data, ). - Centralized setup configuration in pyproject.toml instead of spread over multiple files",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:521,deployability,instal,install,521,"Switch to flit; What stays the same:. - `pip install scanpy`. - `pip install . `. - `pip install git+https://...`. - you can install your deps with conda. - you can do a dev install. What changes:. - Please check the [install docs](https://scanpy.readthedocs.io/en/flit-for-isaac/installation.html#development-version), in short:. - `pip install -e .[every,single,extra]`  `flit install -s` for dev installs. - `beni pyproject.toml > environment.yml` for conda. - Extremely simple `flit build` and `flit publish`. Maybe install `keyring` to store your publish password, and you know everything you need to. - `flit build` doesnt clutter your dev directory with `build/` and `*.egg-info/` junk, it just creates `dist/scanpy-*{.whl,.tar.gz}`. - No more obscure stuff nobody understands (MANIFEST.in, package_data, ). - Centralized setup configuration in pyproject.toml instead of spread over multiple files",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:616,deployability,build,build,616,"Switch to flit; What stays the same:. - `pip install scanpy`. - `pip install . `. - `pip install git+https://...`. - you can install your deps with conda. - you can do a dev install. What changes:. - Please check the [install docs](https://scanpy.readthedocs.io/en/flit-for-isaac/installation.html#development-version), in short:. - `pip install -e .[every,single,extra]`  `flit install -s` for dev installs. - `beni pyproject.toml > environment.yml` for conda. - Extremely simple `flit build` and `flit publish`. Maybe install `keyring` to store your publish password, and you know everything you need to. - `flit build` doesnt clutter your dev directory with `build/` and `*.egg-info/` junk, it just creates `dist/scanpy-*{.whl,.tar.gz}`. - No more obscure stuff nobody understands (MANIFEST.in, package_data, ). - Centralized setup configuration in pyproject.toml instead of spread over multiple files",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:664,deployability,build,build,664,"Switch to flit; What stays the same:. - `pip install scanpy`. - `pip install . `. - `pip install git+https://...`. - you can install your deps with conda. - you can do a dev install. What changes:. - Please check the [install docs](https://scanpy.readthedocs.io/en/flit-for-isaac/installation.html#development-version), in short:. - `pip install -e .[every,single,extra]`  `flit install -s` for dev installs. - `beni pyproject.toml > environment.yml` for conda. - Extremely simple `flit build` and `flit publish`. Maybe install `keyring` to store your publish password, and you know everything you need to. - `flit build` doesnt clutter your dev directory with `build/` and `*.egg-info/` junk, it just creates `dist/scanpy-*{.whl,.tar.gz}`. - No more obscure stuff nobody understands (MANIFEST.in, package_data, ). - Centralized setup configuration in pyproject.toml instead of spread over multiple files",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:838,deployability,configurat,configuration,838,"Switch to flit; What stays the same:. - `pip install scanpy`. - `pip install . `. - `pip install git+https://...`. - you can install your deps with conda. - you can do a dev install. What changes:. - Please check the [install docs](https://scanpy.readthedocs.io/en/flit-for-isaac/installation.html#development-version), in short:. - `pip install -e .[every,single,extra]`  `flit install -s` for dev installs. - `beni pyproject.toml > environment.yml` for conda. - Extremely simple `flit build` and `flit publish`. Maybe install `keyring` to store your publish password, and you know everything you need to. - `flit build` doesnt clutter your dev directory with `build/` and `*.egg-info/` junk, it just creates `dist/scanpy-*{.whl,.tar.gz}`. - No more obscure stuff nobody understands (MANIFEST.in, package_data, ). - Centralized setup configuration in pyproject.toml instead of spread over multiple files",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:310,integrability,version,version,310,"Switch to flit; What stays the same:. - `pip install scanpy`. - `pip install . `. - `pip install git+https://...`. - you can install your deps with conda. - you can do a dev install. What changes:. - Please check the [install docs](https://scanpy.readthedocs.io/en/flit-for-isaac/installation.html#development-version), in short:. - `pip install -e .[every,single,extra]`  `flit install -s` for dev installs. - `beni pyproject.toml > environment.yml` for conda. - Extremely simple `flit build` and `flit publish`. Maybe install `keyring` to store your publish password, and you know everything you need to. - `flit build` doesnt clutter your dev directory with `build/` and `*.egg-info/` junk, it just creates `dist/scanpy-*{.whl,.tar.gz}`. - No more obscure stuff nobody understands (MANIFEST.in, package_data, ). - Centralized setup configuration in pyproject.toml instead of spread over multiple files",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:505,integrability,pub,publish,505,"Switch to flit; What stays the same:. - `pip install scanpy`. - `pip install . `. - `pip install git+https://...`. - you can install your deps with conda. - you can do a dev install. What changes:. - Please check the [install docs](https://scanpy.readthedocs.io/en/flit-for-isaac/installation.html#development-version), in short:. - `pip install -e .[every,single,extra]`  `flit install -s` for dev installs. - `beni pyproject.toml > environment.yml` for conda. - Extremely simple `flit build` and `flit publish`. Maybe install `keyring` to store your publish password, and you know everything you need to. - `flit build` doesnt clutter your dev directory with `build/` and `*.egg-info/` junk, it just creates `dist/scanpy-*{.whl,.tar.gz}`. - No more obscure stuff nobody understands (MANIFEST.in, package_data, ). - Centralized setup configuration in pyproject.toml instead of spread over multiple files",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:553,integrability,pub,publish,553,"Switch to flit; What stays the same:. - `pip install scanpy`. - `pip install . `. - `pip install git+https://...`. - you can install your deps with conda. - you can do a dev install. What changes:. - Please check the [install docs](https://scanpy.readthedocs.io/en/flit-for-isaac/installation.html#development-version), in short:. - `pip install -e .[every,single,extra]`  `flit install -s` for dev installs. - `beni pyproject.toml > environment.yml` for conda. - Extremely simple `flit build` and `flit publish`. Maybe install `keyring` to store your publish password, and you know everything you need to. - `flit build` doesnt clutter your dev directory with `build/` and `*.egg-info/` junk, it just creates `dist/scanpy-*{.whl,.tar.gz}`. - No more obscure stuff nobody understands (MANIFEST.in, package_data, ). - Centralized setup configuration in pyproject.toml instead of spread over multiple files",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:838,integrability,configur,configuration,838,"Switch to flit; What stays the same:. - `pip install scanpy`. - `pip install . `. - `pip install git+https://...`. - you can install your deps with conda. - you can do a dev install. What changes:. - Please check the [install docs](https://scanpy.readthedocs.io/en/flit-for-isaac/installation.html#development-version), in short:. - `pip install -e .[every,single,extra]`  `flit install -s` for dev installs. - `beni pyproject.toml > environment.yml` for conda. - Extremely simple `flit build` and `flit publish`. Maybe install `keyring` to store your publish password, and you know everything you need to. - `flit build` doesnt clutter your dev directory with `build/` and `*.egg-info/` junk, it just creates `dist/scanpy-*{.whl,.tar.gz}`. - No more obscure stuff nobody understands (MANIFEST.in, package_data, ). - Centralized setup configuration in pyproject.toml instead of spread over multiple files",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:310,modifiability,version,version,310,"Switch to flit; What stays the same:. - `pip install scanpy`. - `pip install . `. - `pip install git+https://...`. - you can install your deps with conda. - you can do a dev install. What changes:. - Please check the [install docs](https://scanpy.readthedocs.io/en/flit-for-isaac/installation.html#development-version), in short:. - `pip install -e .[every,single,extra]`  `flit install -s` for dev installs. - `beni pyproject.toml > environment.yml` for conda. - Extremely simple `flit build` and `flit publish`. Maybe install `keyring` to store your publish password, and you know everything you need to. - `flit build` doesnt clutter your dev directory with `build/` and `*.egg-info/` junk, it just creates `dist/scanpy-*{.whl,.tar.gz}`. - No more obscure stuff nobody understands (MANIFEST.in, package_data, ). - Centralized setup configuration in pyproject.toml instead of spread over multiple files",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:838,modifiability,configur,configuration,838,"Switch to flit; What stays the same:. - `pip install scanpy`. - `pip install . `. - `pip install git+https://...`. - you can install your deps with conda. - you can do a dev install. What changes:. - Please check the [install docs](https://scanpy.readthedocs.io/en/flit-for-isaac/installation.html#development-version), in short:. - `pip install -e .[every,single,extra]`  `flit install -s` for dev installs. - `beni pyproject.toml > environment.yml` for conda. - Extremely simple `flit build` and `flit publish`. Maybe install `keyring` to store your publish password, and you know everything you need to. - `flit build` doesnt clutter your dev directory with `build/` and `*.egg-info/` junk, it just creates `dist/scanpy-*{.whl,.tar.gz}`. - No more obscure stuff nobody understands (MANIFEST.in, package_data, ). - Centralized setup configuration in pyproject.toml instead of spread over multiple files",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:623,reliability,doe,doesn,623,"Switch to flit; What stays the same:. - `pip install scanpy`. - `pip install . `. - `pip install git+https://...`. - you can install your deps with conda. - you can do a dev install. What changes:. - Please check the [install docs](https://scanpy.readthedocs.io/en/flit-for-isaac/installation.html#development-version), in short:. - `pip install -e .[every,single,extra]`  `flit install -s` for dev installs. - `beni pyproject.toml > environment.yml` for conda. - Extremely simple `flit build` and `flit publish`. Maybe install `keyring` to store your publish password, and you know everything you need to. - `flit build` doesnt clutter your dev directory with `build/` and `*.egg-info/` junk, it just creates `dist/scanpy-*{.whl,.tar.gz}`. - No more obscure stuff nobody understands (MANIFEST.in, package_data, ). - Centralized setup configuration in pyproject.toml instead of spread over multiple files",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:561,security,password,password,561,"Switch to flit; What stays the same:. - `pip install scanpy`. - `pip install . `. - `pip install git+https://...`. - you can install your deps with conda. - you can do a dev install. What changes:. - Please check the [install docs](https://scanpy.readthedocs.io/en/flit-for-isaac/installation.html#development-version), in short:. - `pip install -e .[every,single,extra]`  `flit install -s` for dev installs. - `beni pyproject.toml > environment.yml` for conda. - Extremely simple `flit build` and `flit publish`. Maybe install `keyring` to store your publish password, and you know everything you need to. - `flit build` doesnt clutter your dev directory with `build/` and `*.egg-info/` junk, it just creates `dist/scanpy-*{.whl,.tar.gz}`. - No more obscure stuff nobody understands (MANIFEST.in, package_data, ). - Centralized setup configuration in pyproject.toml instead of spread over multiple files",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:838,security,configur,configuration,838,"Switch to flit; What stays the same:. - `pip install scanpy`. - `pip install . `. - `pip install git+https://...`. - you can install your deps with conda. - you can do a dev install. What changes:. - Please check the [install docs](https://scanpy.readthedocs.io/en/flit-for-isaac/installation.html#development-version), in short:. - `pip install -e .[every,single,extra]`  `flit install -s` for dev installs. - `beni pyproject.toml > environment.yml` for conda. - Extremely simple `flit build` and `flit publish`. Maybe install `keyring` to store your publish password, and you know everything you need to. - `flit build` doesnt clutter your dev directory with `build/` and `*.egg-info/` junk, it just creates `dist/scanpy-*{.whl,.tar.gz}`. - No more obscure stuff nobody understands (MANIFEST.in, package_data, ). - Centralized setup configuration in pyproject.toml instead of spread over multiple files",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:475,testability,simpl,simple,475,"Switch to flit; What stays the same:. - `pip install scanpy`. - `pip install . `. - `pip install git+https://...`. - you can install your deps with conda. - you can do a dev install. What changes:. - Please check the [install docs](https://scanpy.readthedocs.io/en/flit-for-isaac/installation.html#development-version), in short:. - `pip install -e .[every,single,extra]`  `flit install -s` for dev installs. - `beni pyproject.toml > environment.yml` for conda. - Extremely simple `flit build` and `flit publish`. Maybe install `keyring` to store your publish password, and you know everything you need to. - `flit build` doesnt clutter your dev directory with `build/` and `*.egg-info/` junk, it just creates `dist/scanpy-*{.whl,.tar.gz}`. - No more obscure stuff nobody understands (MANIFEST.in, package_data, ). - Centralized setup configuration in pyproject.toml instead of spread over multiple files",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:774,testability,understand,understands,774,"Switch to flit; What stays the same:. - `pip install scanpy`. - `pip install . `. - `pip install git+https://...`. - you can install your deps with conda. - you can do a dev install. What changes:. - Please check the [install docs](https://scanpy.readthedocs.io/en/flit-for-isaac/installation.html#development-version), in short:. - `pip install -e .[every,single,extra]`  `flit install -s` for dev installs. - `beni pyproject.toml > environment.yml` for conda. - Extremely simple `flit build` and `flit publish`. Maybe install `keyring` to store your publish password, and you know everything you need to. - `flit build` doesnt clutter your dev directory with `build/` and `*.egg-info/` junk, it just creates `dist/scanpy-*{.whl,.tar.gz}`. - No more obscure stuff nobody understands (MANIFEST.in, package_data, ). - Centralized setup configuration in pyproject.toml instead of spread over multiple files",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1527:475,usability,simpl,simple,475,"Switch to flit; What stays the same:. - `pip install scanpy`. - `pip install . `. - `pip install git+https://...`. - you can install your deps with conda. - you can do a dev install. What changes:. - Please check the [install docs](https://scanpy.readthedocs.io/en/flit-for-isaac/installation.html#development-version), in short:. - `pip install -e .[every,single,extra]`  `flit install -s` for dev installs. - `beni pyproject.toml > environment.yml` for conda. - Extremely simple `flit build` and `flit publish`. Maybe install `keyring` to store your publish password, and you know everything you need to. - `flit build` doesnt clutter your dev directory with `build/` and `*.egg-info/` junk, it just creates `dist/scanpy-*{.whl,.tar.gz}`. - No more obscure stuff nobody understands (MANIFEST.in, package_data, ). - Centralized setup configuration in pyproject.toml instead of spread over multiple files",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1527
https://github.com/scverse/scanpy/pull/1528:113,deployability,modul,modules,113,"Separate static analysis, move tests out of the package; This also fixes a few problems namely that tests are no modules, so you should use fixtures instead of importing. If we want test tools that dependent packages can use we should create a submodule like `scanpy.test_utils` or so. I forgot to add the new locations to `tool.black.exclude`, so the files got reformatted. I hope thats OK?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:198,deployability,depend,dependent,198,"Separate static analysis, move tests out of the package; This also fixes a few problems namely that tests are no modules, so you should use fixtures instead of importing. If we want test tools that dependent packages can use we should create a submodule like `scanpy.test_utils` or so. I forgot to add the new locations to `tool.black.exclude`, so the files got reformatted. I hope thats OK?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:198,integrability,depend,dependent,198,"Separate static analysis, move tests out of the package; This also fixes a few problems namely that tests are no modules, so you should use fixtures instead of importing. If we want test tools that dependent packages can use we should create a submodule like `scanpy.test_utils` or so. I forgot to add the new locations to `tool.black.exclude`, so the files got reformatted. I hope thats OK?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:244,integrability,sub,submodule,244,"Separate static analysis, move tests out of the package; This also fixes a few problems namely that tests are no modules, so you should use fixtures instead of importing. If we want test tools that dependent packages can use we should create a submodule like `scanpy.test_utils` or so. I forgot to add the new locations to `tool.black.exclude`, so the files got reformatted. I hope thats OK?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:48,modifiability,pac,package,48,"Separate static analysis, move tests out of the package; This also fixes a few problems namely that tests are no modules, so you should use fixtures instead of importing. If we want test tools that dependent packages can use we should create a submodule like `scanpy.test_utils` or so. I forgot to add the new locations to `tool.black.exclude`, so the files got reformatted. I hope thats OK?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:113,modifiability,modul,modules,113,"Separate static analysis, move tests out of the package; This also fixes a few problems namely that tests are no modules, so you should use fixtures instead of importing. If we want test tools that dependent packages can use we should create a submodule like `scanpy.test_utils` or so. I forgot to add the new locations to `tool.black.exclude`, so the files got reformatted. I hope thats OK?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:198,modifiability,depend,dependent,198,"Separate static analysis, move tests out of the package; This also fixes a few problems namely that tests are no modules, so you should use fixtures instead of importing. If we want test tools that dependent packages can use we should create a submodule like `scanpy.test_utils` or so. I forgot to add the new locations to `tool.black.exclude`, so the files got reformatted. I hope thats OK?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:208,modifiability,pac,packages,208,"Separate static analysis, move tests out of the package; This also fixes a few problems namely that tests are no modules, so you should use fixtures instead of importing. If we want test tools that dependent packages can use we should create a submodule like `scanpy.test_utils` or so. I forgot to add the new locations to `tool.black.exclude`, so the files got reformatted. I hope thats OK?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:31,safety,test,tests,31,"Separate static analysis, move tests out of the package; This also fixes a few problems namely that tests are no modules, so you should use fixtures instead of importing. If we want test tools that dependent packages can use we should create a submodule like `scanpy.test_utils` or so. I forgot to add the new locations to `tool.black.exclude`, so the files got reformatted. I hope thats OK?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:100,safety,test,tests,100,"Separate static analysis, move tests out of the package; This also fixes a few problems namely that tests are no modules, so you should use fixtures instead of importing. If we want test tools that dependent packages can use we should create a submodule like `scanpy.test_utils` or so. I forgot to add the new locations to `tool.black.exclude`, so the files got reformatted. I hope thats OK?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:113,safety,modul,modules,113,"Separate static analysis, move tests out of the package; This also fixes a few problems namely that tests are no modules, so you should use fixtures instead of importing. If we want test tools that dependent packages can use we should create a submodule like `scanpy.test_utils` or so. I forgot to add the new locations to `tool.black.exclude`, so the files got reformatted. I hope thats OK?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:182,safety,test,test,182,"Separate static analysis, move tests out of the package; This also fixes a few problems namely that tests are no modules, so you should use fixtures instead of importing. If we want test tools that dependent packages can use we should create a submodule like `scanpy.test_utils` or so. I forgot to add the new locations to `tool.black.exclude`, so the files got reformatted. I hope thats OK?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:198,safety,depend,dependent,198,"Separate static analysis, move tests out of the package; This also fixes a few problems namely that tests are no modules, so you should use fixtures instead of importing. If we want test tools that dependent packages can use we should create a submodule like `scanpy.test_utils` or so. I forgot to add the new locations to `tool.black.exclude`, so the files got reformatted. I hope thats OK?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:31,testability,test,tests,31,"Separate static analysis, move tests out of the package; This also fixes a few problems namely that tests are no modules, so you should use fixtures instead of importing. If we want test tools that dependent packages can use we should create a submodule like `scanpy.test_utils` or so. I forgot to add the new locations to `tool.black.exclude`, so the files got reformatted. I hope thats OK?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:100,testability,test,tests,100,"Separate static analysis, move tests out of the package; This also fixes a few problems namely that tests are no modules, so you should use fixtures instead of importing. If we want test tools that dependent packages can use we should create a submodule like `scanpy.test_utils` or so. I forgot to add the new locations to `tool.black.exclude`, so the files got reformatted. I hope thats OK?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:182,testability,test,test,182,"Separate static analysis, move tests out of the package; This also fixes a few problems namely that tests are no modules, so you should use fixtures instead of importing. If we want test tools that dependent packages can use we should create a submodule like `scanpy.test_utils` or so. I forgot to add the new locations to `tool.black.exclude`, so the files got reformatted. I hope thats OK?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:198,testability,depend,dependent,198,"Separate static analysis, move tests out of the package; This also fixes a few problems namely that tests are no modules, so you should use fixtures instead of importing. If we want test tools that dependent packages can use we should create a submodule like `scanpy.test_utils` or so. I forgot to add the new locations to `tool.black.exclude`, so the files got reformatted. I hope thats OK?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:187,usability,tool,tools,187,"Separate static analysis, move tests out of the package; This also fixes a few problems namely that tests are no modules, so you should use fixtures instead of importing. If we want test tools that dependent packages can use we should create a submodule like `scanpy.test_utils` or so. I forgot to add the new locations to `tool.black.exclude`, so the files got reformatted. I hope thats OK?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1528:324,usability,tool,tool,324,"Separate static analysis, move tests out of the package; This also fixes a few problems namely that tests are no modules, so you should use fixtures instead of importing. If we want test tools that dependent packages can use we should create a submodule like `scanpy.test_utils` or so. I forgot to add the new locations to `tool.black.exclude`, so the files got reformatted. I hope thats OK?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1528
https://github.com/scverse/scanpy/pull/1529:229,availability,cluster,cluster,229,new options to rank_genes_groups plots; This PR adds the following to `rank_genes_groups_*` plots:. * Allows `n_genes` to be a negative number to plot the bottom ranked `n_genes`. Useful to check what is not being expressed on a cluster. * Added `gene_names` to `rank_genes_groups_matrixplot` and `rank_genes_groups_dotplot`. This option is for checking a . given list of genes instead of the top or bottom ranked genes. This allows to check for example log fold change of p-values for. the given genes. * `gene_symbols` was not working properly. Now it is.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1529
https://github.com/scverse/scanpy/pull/1529:229,deployability,cluster,cluster,229,new options to rank_genes_groups plots; This PR adds the following to `rank_genes_groups_*` plots:. * Allows `n_genes` to be a negative number to plot the bottom ranked `n_genes`. Useful to check what is not being expressed on a cluster. * Added `gene_names` to `rank_genes_groups_matrixplot` and `rank_genes_groups_dotplot`. This option is for checking a . given list of genes instead of the top or bottom ranked genes. This allows to check for example log fold change of p-values for. the given genes. * `gene_symbols` was not working properly. Now it is.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1529
https://github.com/scverse/scanpy/pull/1529:454,deployability,log,log,454,new options to rank_genes_groups plots; This PR adds the following to `rank_genes_groups_*` plots:. * Allows `n_genes` to be a negative number to plot the bottom ranked `n_genes`. Useful to check what is not being expressed on a cluster. * Added `gene_names` to `rank_genes_groups_matrixplot` and `rank_genes_groups_dotplot`. This option is for checking a . given list of genes instead of the top or bottom ranked genes. This allows to check for example log fold change of p-values for. the given genes. * `gene_symbols` was not working properly. Now it is.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1529
https://github.com/scverse/scanpy/pull/1529:454,safety,log,log,454,new options to rank_genes_groups plots; This PR adds the following to `rank_genes_groups_*` plots:. * Allows `n_genes` to be a negative number to plot the bottom ranked `n_genes`. Useful to check what is not being expressed on a cluster. * Added `gene_names` to `rank_genes_groups_matrixplot` and `rank_genes_groups_dotplot`. This option is for checking a . given list of genes instead of the top or bottom ranked genes. This allows to check for example log fold change of p-values for. the given genes. * `gene_symbols` was not working properly. Now it is.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1529
https://github.com/scverse/scanpy/pull/1529:454,security,log,log,454,new options to rank_genes_groups plots; This PR adds the following to `rank_genes_groups_*` plots:. * Allows `n_genes` to be a negative number to plot the bottom ranked `n_genes`. Useful to check what is not being expressed on a cluster. * Added `gene_names` to `rank_genes_groups_matrixplot` and `rank_genes_groups_dotplot`. This option is for checking a . given list of genes instead of the top or bottom ranked genes. This allows to check for example log fold change of p-values for. the given genes. * `gene_symbols` was not working properly. Now it is.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1529
https://github.com/scverse/scanpy/pull/1529:454,testability,log,log,454,new options to rank_genes_groups plots; This PR adds the following to `rank_genes_groups_*` plots:. * Allows `n_genes` to be a negative number to plot the bottom ranked `n_genes`. Useful to check what is not being expressed on a cluster. * Added `gene_names` to `rank_genes_groups_matrixplot` and `rank_genes_groups_dotplot`. This option is for checking a . given list of genes instead of the top or bottom ranked genes. This allows to check for example log fold change of p-values for. the given genes. * `gene_symbols` was not working properly. Now it is.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1529
https://github.com/scverse/scanpy/issues/1530:41,availability,error,error,41,"rank_genes_groups method='logreg' causes error with `sc.get.rank_genes_groups_df`; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. when running `sc.tl.rank_genes_groups` with `method='logreg'` the `logfoldchanges` are not generated. However, this field is. required by `sc.get.rank_genes_groups_df`. . ```python. adata = sc.datasets.pbmc68k_reduced(). sc.tl.rank_genes_groups(adata, 'bulk_labels', method='logreg'). sc.get.rank_genes_groups_df(adata, 'Dendritic'). ```. ```pytb. /scanpy/scanpy/get.py in rank_genes_groups_df(adata, group, key, pval_cutoff, log2fc_min, log2fc_max, gene_symbols). 56 d = pd.DataFrame(). 57 for k in ['scores', 'names', 'logfoldchanges', 'pvals', 'pvals_adj']:. ---> 58 d[k] = adata.uns[key][k][group]. 59 if pval_cutoff is not None:. 60 d = d[d[""pvals_adj""] < pval_cutoff]. KeyError: 'logfoldchanges'. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1530
https://github.com/scverse/scanpy/issues/1530:26,deployability,log,logreg,26,"rank_genes_groups method='logreg' causes error with `sc.get.rank_genes_groups_df`; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. when running `sc.tl.rank_genes_groups` with `method='logreg'` the `logfoldchanges` are not generated. However, this field is. required by `sc.get.rank_genes_groups_df`. . ```python. adata = sc.datasets.pbmc68k_reduced(). sc.tl.rank_genes_groups(adata, 'bulk_labels', method='logreg'). sc.get.rank_genes_groups_df(adata, 'Dendritic'). ```. ```pytb. /scanpy/scanpy/get.py in rank_genes_groups_df(adata, group, key, pval_cutoff, log2fc_min, log2fc_max, gene_symbols). 56 d = pd.DataFrame(). 57 for k in ['scores', 'names', 'logfoldchanges', 'pvals', 'pvals_adj']:. ---> 58 d[k] = adata.uns[key][k][group]. 59 if pval_cutoff is not None:. 60 d = d[d[""pvals_adj""] < pval_cutoff]. KeyError: 'logfoldchanges'. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1530
https://github.com/scverse/scanpy/issues/1530:204,deployability,version,version,204,"rank_genes_groups method='logreg' causes error with `sc.get.rank_genes_groups_df`; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. when running `sc.tl.rank_genes_groups` with `method='logreg'` the `logfoldchanges` are not generated. However, this field is. required by `sc.get.rank_genes_groups_df`. . ```python. adata = sc.datasets.pbmc68k_reduced(). sc.tl.rank_genes_groups(adata, 'bulk_labels', method='logreg'). sc.get.rank_genes_groups_df(adata, 'Dendritic'). ```. ```pytb. /scanpy/scanpy/get.py in rank_genes_groups_df(adata, group, key, pval_cutoff, log2fc_min, log2fc_max, gene_symbols). 56 d = pd.DataFrame(). 57 for k in ['scores', 'names', 'logfoldchanges', 'pvals', 'pvals_adj']:. ---> 58 d[k] = adata.uns[key][k][group]. 59 if pval_cutoff is not None:. 60 d = d[d[""pvals_adj""] < pval_cutoff]. KeyError: 'logfoldchanges'. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1530
https://github.com/scverse/scanpy/issues/1530:363,deployability,log,logreg,363,"rank_genes_groups method='logreg' causes error with `sc.get.rank_genes_groups_df`; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. when running `sc.tl.rank_genes_groups` with `method='logreg'` the `logfoldchanges` are not generated. However, this field is. required by `sc.get.rank_genes_groups_df`. . ```python. adata = sc.datasets.pbmc68k_reduced(). sc.tl.rank_genes_groups(adata, 'bulk_labels', method='logreg'). sc.get.rank_genes_groups_df(adata, 'Dendritic'). ```. ```pytb. /scanpy/scanpy/get.py in rank_genes_groups_df(adata, group, key, pval_cutoff, log2fc_min, log2fc_max, gene_symbols). 56 d = pd.DataFrame(). 57 for k in ['scores', 'names', 'logfoldchanges', 'pvals', 'pvals_adj']:. ---> 58 d[k] = adata.uns[key][k][group]. 59 if pval_cutoff is not None:. 60 d = d[d[""pvals_adj""] < pval_cutoff]. KeyError: 'logfoldchanges'. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1530
https://github.com/scverse/scanpy/issues/1530:377,deployability,log,logfoldchanges,377,"rank_genes_groups method='logreg' causes error with `sc.get.rank_genes_groups_df`; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. when running `sc.tl.rank_genes_groups` with `method='logreg'` the `logfoldchanges` are not generated. However, this field is. required by `sc.get.rank_genes_groups_df`. . ```python. adata = sc.datasets.pbmc68k_reduced(). sc.tl.rank_genes_groups(adata, 'bulk_labels', method='logreg'). sc.get.rank_genes_groups_df(adata, 'Dendritic'). ```. ```pytb. /scanpy/scanpy/get.py in rank_genes_groups_df(adata, group, key, pval_cutoff, log2fc_min, log2fc_max, gene_symbols). 56 d = pd.DataFrame(). 57 for k in ['scores', 'names', 'logfoldchanges', 'pvals', 'pvals_adj']:. ---> 58 d[k] = adata.uns[key][k][group]. 59 if pval_cutoff is not None:. 60 d = d[d[""pvals_adj""] < pval_cutoff]. KeyError: 'logfoldchanges'. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1530
https://github.com/scverse/scanpy/issues/1530:585,deployability,log,logreg,585,"rank_genes_groups method='logreg' causes error with `sc.get.rank_genes_groups_df`; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. when running `sc.tl.rank_genes_groups` with `method='logreg'` the `logfoldchanges` are not generated. However, this field is. required by `sc.get.rank_genes_groups_df`. . ```python. adata = sc.datasets.pbmc68k_reduced(). sc.tl.rank_genes_groups(adata, 'bulk_labels', method='logreg'). sc.get.rank_genes_groups_df(adata, 'Dendritic'). ```. ```pytb. /scanpy/scanpy/get.py in rank_genes_groups_df(adata, group, key, pval_cutoff, log2fc_min, log2fc_max, gene_symbols). 56 d = pd.DataFrame(). 57 for k in ['scores', 'names', 'logfoldchanges', 'pvals', 'pvals_adj']:. ---> 58 d[k] = adata.uns[key][k][group]. 59 if pval_cutoff is not None:. 60 d = d[d[""pvals_adj""] < pval_cutoff]. KeyError: 'logfoldchanges'. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1530
https://github.com/scverse/scanpy/issues/1530:831,deployability,log,logfoldchanges,831,"rank_genes_groups method='logreg' causes error with `sc.get.rank_genes_groups_df`; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. when running `sc.tl.rank_genes_groups` with `method='logreg'` the `logfoldchanges` are not generated. However, this field is. required by `sc.get.rank_genes_groups_df`. . ```python. adata = sc.datasets.pbmc68k_reduced(). sc.tl.rank_genes_groups(adata, 'bulk_labels', method='logreg'). sc.get.rank_genes_groups_df(adata, 'Dendritic'). ```. ```pytb. /scanpy/scanpy/get.py in rank_genes_groups_df(adata, group, key, pval_cutoff, log2fc_min, log2fc_max, gene_symbols). 56 d = pd.DataFrame(). 57 for k in ['scores', 'names', 'logfoldchanges', 'pvals', 'pvals_adj']:. ---> 58 d[k] = adata.uns[key][k][group]. 59 if pval_cutoff is not None:. 60 d = d[d[""pvals_adj""] < pval_cutoff]. KeyError: 'logfoldchanges'. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1530
https://github.com/scverse/scanpy/issues/1530:996,deployability,log,logfoldchanges,996,"rank_genes_groups method='logreg' causes error with `sc.get.rank_genes_groups_df`; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. when running `sc.tl.rank_genes_groups` with `method='logreg'` the `logfoldchanges` are not generated. However, this field is. required by `sc.get.rank_genes_groups_df`. . ```python. adata = sc.datasets.pbmc68k_reduced(). sc.tl.rank_genes_groups(adata, 'bulk_labels', method='logreg'). sc.get.rank_genes_groups_df(adata, 'Dendritic'). ```. ```pytb. /scanpy/scanpy/get.py in rank_genes_groups_df(adata, group, key, pval_cutoff, log2fc_min, log2fc_max, gene_symbols). 56 d = pd.DataFrame(). 57 for k in ['scores', 'names', 'logfoldchanges', 'pvals', 'pvals_adj']:. ---> 58 d[k] = adata.uns[key][k][group]. 59 if pval_cutoff is not None:. 60 d = d[d[""pvals_adj""] < pval_cutoff]. KeyError: 'logfoldchanges'. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1530
https://github.com/scverse/scanpy/issues/1530:1023,deployability,Version,Versions,1023,"rank_genes_groups method='logreg' causes error with `sc.get.rank_genes_groups_df`; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. when running `sc.tl.rank_genes_groups` with `method='logreg'` the `logfoldchanges` are not generated. However, this field is. required by `sc.get.rank_genes_groups_df`. . ```python. adata = sc.datasets.pbmc68k_reduced(). sc.tl.rank_genes_groups(adata, 'bulk_labels', method='logreg'). sc.get.rank_genes_groups_df(adata, 'Dendritic'). ```. ```pytb. /scanpy/scanpy/get.py in rank_genes_groups_df(adata, group, key, pval_cutoff, log2fc_min, log2fc_max, gene_symbols). 56 d = pd.DataFrame(). 57 for k in ['scores', 'names', 'logfoldchanges', 'pvals', 'pvals_adj']:. ---> 58 d[k] = adata.uns[key][k][group]. 59 if pval_cutoff is not None:. 60 d = d[d[""pvals_adj""] < pval_cutoff]. KeyError: 'logfoldchanges'. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1530
https://github.com/scverse/scanpy/issues/1530:1072,deployability,log,logging,1072,"rank_genes_groups method='logreg' causes error with `sc.get.rank_genes_groups_df`; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. when running `sc.tl.rank_genes_groups` with `method='logreg'` the `logfoldchanges` are not generated. However, this field is. required by `sc.get.rank_genes_groups_df`. . ```python. adata = sc.datasets.pbmc68k_reduced(). sc.tl.rank_genes_groups(adata, 'bulk_labels', method='logreg'). sc.get.rank_genes_groups_df(adata, 'Dendritic'). ```. ```pytb. /scanpy/scanpy/get.py in rank_genes_groups_df(adata, group, key, pval_cutoff, log2fc_min, log2fc_max, gene_symbols). 56 d = pd.DataFrame(). 57 for k in ['scores', 'names', 'logfoldchanges', 'pvals', 'pvals_adj']:. ---> 58 d[k] = adata.uns[key][k][group]. 59 if pval_cutoff is not None:. 60 d = d[d[""pvals_adj""] < pval_cutoff]. KeyError: 'logfoldchanges'. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1530
https://github.com/scverse/scanpy/issues/1530:204,integrability,version,version,204,"rank_genes_groups method='logreg' causes error with `sc.get.rank_genes_groups_df`; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. when running `sc.tl.rank_genes_groups` with `method='logreg'` the `logfoldchanges` are not generated. However, this field is. required by `sc.get.rank_genes_groups_df`. . ```python. adata = sc.datasets.pbmc68k_reduced(). sc.tl.rank_genes_groups(adata, 'bulk_labels', method='logreg'). sc.get.rank_genes_groups_df(adata, 'Dendritic'). ```. ```pytb. /scanpy/scanpy/get.py in rank_genes_groups_df(adata, group, key, pval_cutoff, log2fc_min, log2fc_max, gene_symbols). 56 d = pd.DataFrame(). 57 for k in ['scores', 'names', 'logfoldchanges', 'pvals', 'pvals_adj']:. ---> 58 d[k] = adata.uns[key][k][group]. 59 if pval_cutoff is not None:. 60 d = d[d[""pvals_adj""] < pval_cutoff]. KeyError: 'logfoldchanges'. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1530
https://github.com/scverse/scanpy/issues/1530:1023,integrability,Version,Versions,1023,"rank_genes_groups method='logreg' causes error with `sc.get.rank_genes_groups_df`; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. when running `sc.tl.rank_genes_groups` with `method='logreg'` the `logfoldchanges` are not generated. However, this field is. required by `sc.get.rank_genes_groups_df`. . ```python. adata = sc.datasets.pbmc68k_reduced(). sc.tl.rank_genes_groups(adata, 'bulk_labels', method='logreg'). sc.get.rank_genes_groups_df(adata, 'Dendritic'). ```. ```pytb. /scanpy/scanpy/get.py in rank_genes_groups_df(adata, group, key, pval_cutoff, log2fc_min, log2fc_max, gene_symbols). 56 d = pd.DataFrame(). 57 for k in ['scores', 'names', 'logfoldchanges', 'pvals', 'pvals_adj']:. ---> 58 d[k] = adata.uns[key][k][group]. 59 if pval_cutoff is not None:. 60 d = d[d[""pvals_adj""] < pval_cutoff]. KeyError: 'logfoldchanges'. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1530
https://github.com/scverse/scanpy/issues/1530:204,modifiability,version,version,204,"rank_genes_groups method='logreg' causes error with `sc.get.rank_genes_groups_df`; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. when running `sc.tl.rank_genes_groups` with `method='logreg'` the `logfoldchanges` are not generated. However, this field is. required by `sc.get.rank_genes_groups_df`. . ```python. adata = sc.datasets.pbmc68k_reduced(). sc.tl.rank_genes_groups(adata, 'bulk_labels', method='logreg'). sc.get.rank_genes_groups_df(adata, 'Dendritic'). ```. ```pytb. /scanpy/scanpy/get.py in rank_genes_groups_df(adata, group, key, pval_cutoff, log2fc_min, log2fc_max, gene_symbols). 56 d = pd.DataFrame(). 57 for k in ['scores', 'names', 'logfoldchanges', 'pvals', 'pvals_adj']:. ---> 58 d[k] = adata.uns[key][k][group]. 59 if pval_cutoff is not None:. 60 d = d[d[""pvals_adj""] < pval_cutoff]. KeyError: 'logfoldchanges'. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1530
https://github.com/scverse/scanpy/issues/1530:1023,modifiability,Version,Versions,1023,"rank_genes_groups method='logreg' causes error with `sc.get.rank_genes_groups_df`; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. when running `sc.tl.rank_genes_groups` with `method='logreg'` the `logfoldchanges` are not generated. However, this field is. required by `sc.get.rank_genes_groups_df`. . ```python. adata = sc.datasets.pbmc68k_reduced(). sc.tl.rank_genes_groups(adata, 'bulk_labels', method='logreg'). sc.get.rank_genes_groups_df(adata, 'Dendritic'). ```. ```pytb. /scanpy/scanpy/get.py in rank_genes_groups_df(adata, group, key, pval_cutoff, log2fc_min, log2fc_max, gene_symbols). 56 d = pd.DataFrame(). 57 for k in ['scores', 'names', 'logfoldchanges', 'pvals', 'pvals_adj']:. ---> 58 d[k] = adata.uns[key][k][group]. 59 if pval_cutoff is not None:. 60 d = d[d[""pvals_adj""] < pval_cutoff]. KeyError: 'logfoldchanges'. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1530
https://github.com/scverse/scanpy/issues/1530:41,performance,error,error,41,"rank_genes_groups method='logreg' causes error with `sc.get.rank_genes_groups_df`; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. when running `sc.tl.rank_genes_groups` with `method='logreg'` the `logfoldchanges` are not generated. However, this field is. required by `sc.get.rank_genes_groups_df`. . ```python. adata = sc.datasets.pbmc68k_reduced(). sc.tl.rank_genes_groups(adata, 'bulk_labels', method='logreg'). sc.get.rank_genes_groups_df(adata, 'Dendritic'). ```. ```pytb. /scanpy/scanpy/get.py in rank_genes_groups_df(adata, group, key, pval_cutoff, log2fc_min, log2fc_max, gene_symbols). 56 d = pd.DataFrame(). 57 for k in ['scores', 'names', 'logfoldchanges', 'pvals', 'pvals_adj']:. ---> 58 d[k] = adata.uns[key][k][group]. 59 if pval_cutoff is not None:. 60 d = d[d[""pvals_adj""] < pval_cutoff]. KeyError: 'logfoldchanges'. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1530
https://github.com/scverse/scanpy/issues/1530:26,safety,log,logreg,26,"rank_genes_groups method='logreg' causes error with `sc.get.rank_genes_groups_df`; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. when running `sc.tl.rank_genes_groups` with `method='logreg'` the `logfoldchanges` are not generated. However, this field is. required by `sc.get.rank_genes_groups_df`. . ```python. adata = sc.datasets.pbmc68k_reduced(). sc.tl.rank_genes_groups(adata, 'bulk_labels', method='logreg'). sc.get.rank_genes_groups_df(adata, 'Dendritic'). ```. ```pytb. /scanpy/scanpy/get.py in rank_genes_groups_df(adata, group, key, pval_cutoff, log2fc_min, log2fc_max, gene_symbols). 56 d = pd.DataFrame(). 57 for k in ['scores', 'names', 'logfoldchanges', 'pvals', 'pvals_adj']:. ---> 58 d[k] = adata.uns[key][k][group]. 59 if pval_cutoff is not None:. 60 d = d[d[""pvals_adj""] < pval_cutoff]. KeyError: 'logfoldchanges'. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1530
https://github.com/scverse/scanpy/issues/1530:41,safety,error,error,41,"rank_genes_groups method='logreg' causes error with `sc.get.rank_genes_groups_df`; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. when running `sc.tl.rank_genes_groups` with `method='logreg'` the `logfoldchanges` are not generated. However, this field is. required by `sc.get.rank_genes_groups_df`. . ```python. adata = sc.datasets.pbmc68k_reduced(). sc.tl.rank_genes_groups(adata, 'bulk_labels', method='logreg'). sc.get.rank_genes_groups_df(adata, 'Dendritic'). ```. ```pytb. /scanpy/scanpy/get.py in rank_genes_groups_df(adata, group, key, pval_cutoff, log2fc_min, log2fc_max, gene_symbols). 56 d = pd.DataFrame(). 57 for k in ['scores', 'names', 'logfoldchanges', 'pvals', 'pvals_adj']:. ---> 58 d[k] = adata.uns[key][k][group]. 59 if pval_cutoff is not None:. 60 d = d[d[""pvals_adj""] < pval_cutoff]. KeyError: 'logfoldchanges'. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1530
https://github.com/scverse/scanpy/issues/1530:363,safety,log,logreg,363,"rank_genes_groups method='logreg' causes error with `sc.get.rank_genes_groups_df`; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. when running `sc.tl.rank_genes_groups` with `method='logreg'` the `logfoldchanges` are not generated. However, this field is. required by `sc.get.rank_genes_groups_df`. . ```python. adata = sc.datasets.pbmc68k_reduced(). sc.tl.rank_genes_groups(adata, 'bulk_labels', method='logreg'). sc.get.rank_genes_groups_df(adata, 'Dendritic'). ```. ```pytb. /scanpy/scanpy/get.py in rank_genes_groups_df(adata, group, key, pval_cutoff, log2fc_min, log2fc_max, gene_symbols). 56 d = pd.DataFrame(). 57 for k in ['scores', 'names', 'logfoldchanges', 'pvals', 'pvals_adj']:. ---> 58 d[k] = adata.uns[key][k][group]. 59 if pval_cutoff is not None:. 60 d = d[d[""pvals_adj""] < pval_cutoff]. KeyError: 'logfoldchanges'. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1530
https://github.com/scverse/scanpy/issues/1530:377,safety,log,logfoldchanges,377,"rank_genes_groups method='logreg' causes error with `sc.get.rank_genes_groups_df`; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. when running `sc.tl.rank_genes_groups` with `method='logreg'` the `logfoldchanges` are not generated. However, this field is. required by `sc.get.rank_genes_groups_df`. . ```python. adata = sc.datasets.pbmc68k_reduced(). sc.tl.rank_genes_groups(adata, 'bulk_labels', method='logreg'). sc.get.rank_genes_groups_df(adata, 'Dendritic'). ```. ```pytb. /scanpy/scanpy/get.py in rank_genes_groups_df(adata, group, key, pval_cutoff, log2fc_min, log2fc_max, gene_symbols). 56 d = pd.DataFrame(). 57 for k in ['scores', 'names', 'logfoldchanges', 'pvals', 'pvals_adj']:. ---> 58 d[k] = adata.uns[key][k][group]. 59 if pval_cutoff is not None:. 60 d = d[d[""pvals_adj""] < pval_cutoff]. KeyError: 'logfoldchanges'. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1530
https://github.com/scverse/scanpy/issues/1530:585,safety,log,logreg,585,"rank_genes_groups method='logreg' causes error with `sc.get.rank_genes_groups_df`; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. when running `sc.tl.rank_genes_groups` with `method='logreg'` the `logfoldchanges` are not generated. However, this field is. required by `sc.get.rank_genes_groups_df`. . ```python. adata = sc.datasets.pbmc68k_reduced(). sc.tl.rank_genes_groups(adata, 'bulk_labels', method='logreg'). sc.get.rank_genes_groups_df(adata, 'Dendritic'). ```. ```pytb. /scanpy/scanpy/get.py in rank_genes_groups_df(adata, group, key, pval_cutoff, log2fc_min, log2fc_max, gene_symbols). 56 d = pd.DataFrame(). 57 for k in ['scores', 'names', 'logfoldchanges', 'pvals', 'pvals_adj']:. ---> 58 d[k] = adata.uns[key][k][group]. 59 if pval_cutoff is not None:. 60 d = d[d[""pvals_adj""] < pval_cutoff]. KeyError: 'logfoldchanges'. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1530
https://github.com/scverse/scanpy/issues/1530:831,safety,log,logfoldchanges,831,"rank_genes_groups method='logreg' causes error with `sc.get.rank_genes_groups_df`; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. when running `sc.tl.rank_genes_groups` with `method='logreg'` the `logfoldchanges` are not generated. However, this field is. required by `sc.get.rank_genes_groups_df`. . ```python. adata = sc.datasets.pbmc68k_reduced(). sc.tl.rank_genes_groups(adata, 'bulk_labels', method='logreg'). sc.get.rank_genes_groups_df(adata, 'Dendritic'). ```. ```pytb. /scanpy/scanpy/get.py in rank_genes_groups_df(adata, group, key, pval_cutoff, log2fc_min, log2fc_max, gene_symbols). 56 d = pd.DataFrame(). 57 for k in ['scores', 'names', 'logfoldchanges', 'pvals', 'pvals_adj']:. ---> 58 d[k] = adata.uns[key][k][group]. 59 if pval_cutoff is not None:. 60 d = d[d[""pvals_adj""] < pval_cutoff]. KeyError: 'logfoldchanges'. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1530
https://github.com/scverse/scanpy/issues/1530:996,safety,log,logfoldchanges,996,"rank_genes_groups method='logreg' causes error with `sc.get.rank_genes_groups_df`; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. when running `sc.tl.rank_genes_groups` with `method='logreg'` the `logfoldchanges` are not generated. However, this field is. required by `sc.get.rank_genes_groups_df`. . ```python. adata = sc.datasets.pbmc68k_reduced(). sc.tl.rank_genes_groups(adata, 'bulk_labels', method='logreg'). sc.get.rank_genes_groups_df(adata, 'Dendritic'). ```. ```pytb. /scanpy/scanpy/get.py in rank_genes_groups_df(adata, group, key, pval_cutoff, log2fc_min, log2fc_max, gene_symbols). 56 d = pd.DataFrame(). 57 for k in ['scores', 'names', 'logfoldchanges', 'pvals', 'pvals_adj']:. ---> 58 d[k] = adata.uns[key][k][group]. 59 if pval_cutoff is not None:. 60 d = d[d[""pvals_adj""] < pval_cutoff]. KeyError: 'logfoldchanges'. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1530
https://github.com/scverse/scanpy/issues/1530:1072,safety,log,logging,1072,"rank_genes_groups method='logreg' causes error with `sc.get.rank_genes_groups_df`; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. when running `sc.tl.rank_genes_groups` with `method='logreg'` the `logfoldchanges` are not generated. However, this field is. required by `sc.get.rank_genes_groups_df`. . ```python. adata = sc.datasets.pbmc68k_reduced(). sc.tl.rank_genes_groups(adata, 'bulk_labels', method='logreg'). sc.get.rank_genes_groups_df(adata, 'Dendritic'). ```. ```pytb. /scanpy/scanpy/get.py in rank_genes_groups_df(adata, group, key, pval_cutoff, log2fc_min, log2fc_max, gene_symbols). 56 d = pd.DataFrame(). 57 for k in ['scores', 'names', 'logfoldchanges', 'pvals', 'pvals_adj']:. ---> 58 d[k] = adata.uns[key][k][group]. 59 if pval_cutoff is not None:. 60 d = d[d[""pvals_adj""] < pval_cutoff]. KeyError: 'logfoldchanges'. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1530
https://github.com/scverse/scanpy/issues/1530:26,security,log,logreg,26,"rank_genes_groups method='logreg' causes error with `sc.get.rank_genes_groups_df`; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. when running `sc.tl.rank_genes_groups` with `method='logreg'` the `logfoldchanges` are not generated. However, this field is. required by `sc.get.rank_genes_groups_df`. . ```python. adata = sc.datasets.pbmc68k_reduced(). sc.tl.rank_genes_groups(adata, 'bulk_labels', method='logreg'). sc.get.rank_genes_groups_df(adata, 'Dendritic'). ```. ```pytb. /scanpy/scanpy/get.py in rank_genes_groups_df(adata, group, key, pval_cutoff, log2fc_min, log2fc_max, gene_symbols). 56 d = pd.DataFrame(). 57 for k in ['scores', 'names', 'logfoldchanges', 'pvals', 'pvals_adj']:. ---> 58 d[k] = adata.uns[key][k][group]. 59 if pval_cutoff is not None:. 60 d = d[d[""pvals_adj""] < pval_cutoff]. KeyError: 'logfoldchanges'. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1530
https://github.com/scverse/scanpy/issues/1530:363,security,log,logreg,363,"rank_genes_groups method='logreg' causes error with `sc.get.rank_genes_groups_df`; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. when running `sc.tl.rank_genes_groups` with `method='logreg'` the `logfoldchanges` are not generated. However, this field is. required by `sc.get.rank_genes_groups_df`. . ```python. adata = sc.datasets.pbmc68k_reduced(). sc.tl.rank_genes_groups(adata, 'bulk_labels', method='logreg'). sc.get.rank_genes_groups_df(adata, 'Dendritic'). ```. ```pytb. /scanpy/scanpy/get.py in rank_genes_groups_df(adata, group, key, pval_cutoff, log2fc_min, log2fc_max, gene_symbols). 56 d = pd.DataFrame(). 57 for k in ['scores', 'names', 'logfoldchanges', 'pvals', 'pvals_adj']:. ---> 58 d[k] = adata.uns[key][k][group]. 59 if pval_cutoff is not None:. 60 d = d[d[""pvals_adj""] < pval_cutoff]. KeyError: 'logfoldchanges'. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1530
https://github.com/scverse/scanpy/issues/1530:377,security,log,logfoldchanges,377,"rank_genes_groups method='logreg' causes error with `sc.get.rank_genes_groups_df`; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. when running `sc.tl.rank_genes_groups` with `method='logreg'` the `logfoldchanges` are not generated. However, this field is. required by `sc.get.rank_genes_groups_df`. . ```python. adata = sc.datasets.pbmc68k_reduced(). sc.tl.rank_genes_groups(adata, 'bulk_labels', method='logreg'). sc.get.rank_genes_groups_df(adata, 'Dendritic'). ```. ```pytb. /scanpy/scanpy/get.py in rank_genes_groups_df(adata, group, key, pval_cutoff, log2fc_min, log2fc_max, gene_symbols). 56 d = pd.DataFrame(). 57 for k in ['scores', 'names', 'logfoldchanges', 'pvals', 'pvals_adj']:. ---> 58 d[k] = adata.uns[key][k][group]. 59 if pval_cutoff is not None:. 60 d = d[d[""pvals_adj""] < pval_cutoff]. KeyError: 'logfoldchanges'. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1530
https://github.com/scverse/scanpy/issues/1530:585,security,log,logreg,585,"rank_genes_groups method='logreg' causes error with `sc.get.rank_genes_groups_df`; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. when running `sc.tl.rank_genes_groups` with `method='logreg'` the `logfoldchanges` are not generated. However, this field is. required by `sc.get.rank_genes_groups_df`. . ```python. adata = sc.datasets.pbmc68k_reduced(). sc.tl.rank_genes_groups(adata, 'bulk_labels', method='logreg'). sc.get.rank_genes_groups_df(adata, 'Dendritic'). ```. ```pytb. /scanpy/scanpy/get.py in rank_genes_groups_df(adata, group, key, pval_cutoff, log2fc_min, log2fc_max, gene_symbols). 56 d = pd.DataFrame(). 57 for k in ['scores', 'names', 'logfoldchanges', 'pvals', 'pvals_adj']:. ---> 58 d[k] = adata.uns[key][k][group]. 59 if pval_cutoff is not None:. 60 d = d[d[""pvals_adj""] < pval_cutoff]. KeyError: 'logfoldchanges'. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1530
https://github.com/scverse/scanpy/issues/1530:831,security,log,logfoldchanges,831,"rank_genes_groups method='logreg' causes error with `sc.get.rank_genes_groups_df`; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. when running `sc.tl.rank_genes_groups` with `method='logreg'` the `logfoldchanges` are not generated. However, this field is. required by `sc.get.rank_genes_groups_df`. . ```python. adata = sc.datasets.pbmc68k_reduced(). sc.tl.rank_genes_groups(adata, 'bulk_labels', method='logreg'). sc.get.rank_genes_groups_df(adata, 'Dendritic'). ```. ```pytb. /scanpy/scanpy/get.py in rank_genes_groups_df(adata, group, key, pval_cutoff, log2fc_min, log2fc_max, gene_symbols). 56 d = pd.DataFrame(). 57 for k in ['scores', 'names', 'logfoldchanges', 'pvals', 'pvals_adj']:. ---> 58 d[k] = adata.uns[key][k][group]. 59 if pval_cutoff is not None:. 60 d = d[d[""pvals_adj""] < pval_cutoff]. KeyError: 'logfoldchanges'. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1530
https://github.com/scverse/scanpy/issues/1530:996,security,log,logfoldchanges,996,"rank_genes_groups method='logreg' causes error with `sc.get.rank_genes_groups_df`; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. when running `sc.tl.rank_genes_groups` with `method='logreg'` the `logfoldchanges` are not generated. However, this field is. required by `sc.get.rank_genes_groups_df`. . ```python. adata = sc.datasets.pbmc68k_reduced(). sc.tl.rank_genes_groups(adata, 'bulk_labels', method='logreg'). sc.get.rank_genes_groups_df(adata, 'Dendritic'). ```. ```pytb. /scanpy/scanpy/get.py in rank_genes_groups_df(adata, group, key, pval_cutoff, log2fc_min, log2fc_max, gene_symbols). 56 d = pd.DataFrame(). 57 for k in ['scores', 'names', 'logfoldchanges', 'pvals', 'pvals_adj']:. ---> 58 d[k] = adata.uns[key][k][group]. 59 if pval_cutoff is not None:. 60 d = d[d[""pvals_adj""] < pval_cutoff]. KeyError: 'logfoldchanges'. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1530
https://github.com/scverse/scanpy/issues/1530:1072,security,log,logging,1072,"rank_genes_groups method='logreg' causes error with `sc.get.rank_genes_groups_df`; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. when running `sc.tl.rank_genes_groups` with `method='logreg'` the `logfoldchanges` are not generated. However, this field is. required by `sc.get.rank_genes_groups_df`. . ```python. adata = sc.datasets.pbmc68k_reduced(). sc.tl.rank_genes_groups(adata, 'bulk_labels', method='logreg'). sc.get.rank_genes_groups_df(adata, 'Dendritic'). ```. ```pytb. /scanpy/scanpy/get.py in rank_genes_groups_df(adata, group, key, pval_cutoff, log2fc_min, log2fc_max, gene_symbols). 56 d = pd.DataFrame(). 57 for k in ['scores', 'names', 'logfoldchanges', 'pvals', 'pvals_adj']:. ---> 58 d[k] = adata.uns[key][k][group]. 59 if pval_cutoff is not None:. 60 d = d[d[""pvals_adj""] < pval_cutoff]. KeyError: 'logfoldchanges'. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1530
https://github.com/scverse/scanpy/issues/1530:26,testability,log,logreg,26,"rank_genes_groups method='logreg' causes error with `sc.get.rank_genes_groups_df`; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. when running `sc.tl.rank_genes_groups` with `method='logreg'` the `logfoldchanges` are not generated. However, this field is. required by `sc.get.rank_genes_groups_df`. . ```python. adata = sc.datasets.pbmc68k_reduced(). sc.tl.rank_genes_groups(adata, 'bulk_labels', method='logreg'). sc.get.rank_genes_groups_df(adata, 'Dendritic'). ```. ```pytb. /scanpy/scanpy/get.py in rank_genes_groups_df(adata, group, key, pval_cutoff, log2fc_min, log2fc_max, gene_symbols). 56 d = pd.DataFrame(). 57 for k in ['scores', 'names', 'logfoldchanges', 'pvals', 'pvals_adj']:. ---> 58 d[k] = adata.uns[key][k][group]. 59 if pval_cutoff is not None:. 60 d = d[d[""pvals_adj""] < pval_cutoff]. KeyError: 'logfoldchanges'. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1530
https://github.com/scverse/scanpy/issues/1530:363,testability,log,logreg,363,"rank_genes_groups method='logreg' causes error with `sc.get.rank_genes_groups_df`; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. when running `sc.tl.rank_genes_groups` with `method='logreg'` the `logfoldchanges` are not generated. However, this field is. required by `sc.get.rank_genes_groups_df`. . ```python. adata = sc.datasets.pbmc68k_reduced(). sc.tl.rank_genes_groups(adata, 'bulk_labels', method='logreg'). sc.get.rank_genes_groups_df(adata, 'Dendritic'). ```. ```pytb. /scanpy/scanpy/get.py in rank_genes_groups_df(adata, group, key, pval_cutoff, log2fc_min, log2fc_max, gene_symbols). 56 d = pd.DataFrame(). 57 for k in ['scores', 'names', 'logfoldchanges', 'pvals', 'pvals_adj']:. ---> 58 d[k] = adata.uns[key][k][group]. 59 if pval_cutoff is not None:. 60 d = d[d[""pvals_adj""] < pval_cutoff]. KeyError: 'logfoldchanges'. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1530
https://github.com/scverse/scanpy/issues/1530:377,testability,log,logfoldchanges,377,"rank_genes_groups method='logreg' causes error with `sc.get.rank_genes_groups_df`; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. when running `sc.tl.rank_genes_groups` with `method='logreg'` the `logfoldchanges` are not generated. However, this field is. required by `sc.get.rank_genes_groups_df`. . ```python. adata = sc.datasets.pbmc68k_reduced(). sc.tl.rank_genes_groups(adata, 'bulk_labels', method='logreg'). sc.get.rank_genes_groups_df(adata, 'Dendritic'). ```. ```pytb. /scanpy/scanpy/get.py in rank_genes_groups_df(adata, group, key, pval_cutoff, log2fc_min, log2fc_max, gene_symbols). 56 d = pd.DataFrame(). 57 for k in ['scores', 'names', 'logfoldchanges', 'pvals', 'pvals_adj']:. ---> 58 d[k] = adata.uns[key][k][group]. 59 if pval_cutoff is not None:. 60 d = d[d[""pvals_adj""] < pval_cutoff]. KeyError: 'logfoldchanges'. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1530
https://github.com/scverse/scanpy/issues/1530:585,testability,log,logreg,585,"rank_genes_groups method='logreg' causes error with `sc.get.rank_genes_groups_df`; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. when running `sc.tl.rank_genes_groups` with `method='logreg'` the `logfoldchanges` are not generated. However, this field is. required by `sc.get.rank_genes_groups_df`. . ```python. adata = sc.datasets.pbmc68k_reduced(). sc.tl.rank_genes_groups(adata, 'bulk_labels', method='logreg'). sc.get.rank_genes_groups_df(adata, 'Dendritic'). ```. ```pytb. /scanpy/scanpy/get.py in rank_genes_groups_df(adata, group, key, pval_cutoff, log2fc_min, log2fc_max, gene_symbols). 56 d = pd.DataFrame(). 57 for k in ['scores', 'names', 'logfoldchanges', 'pvals', 'pvals_adj']:. ---> 58 d[k] = adata.uns[key][k][group]. 59 if pval_cutoff is not None:. 60 d = d[d[""pvals_adj""] < pval_cutoff]. KeyError: 'logfoldchanges'. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1530
https://github.com/scverse/scanpy/issues/1530:831,testability,log,logfoldchanges,831,"rank_genes_groups method='logreg' causes error with `sc.get.rank_genes_groups_df`; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. when running `sc.tl.rank_genes_groups` with `method='logreg'` the `logfoldchanges` are not generated. However, this field is. required by `sc.get.rank_genes_groups_df`. . ```python. adata = sc.datasets.pbmc68k_reduced(). sc.tl.rank_genes_groups(adata, 'bulk_labels', method='logreg'). sc.get.rank_genes_groups_df(adata, 'Dendritic'). ```. ```pytb. /scanpy/scanpy/get.py in rank_genes_groups_df(adata, group, key, pval_cutoff, log2fc_min, log2fc_max, gene_symbols). 56 d = pd.DataFrame(). 57 for k in ['scores', 'names', 'logfoldchanges', 'pvals', 'pvals_adj']:. ---> 58 d[k] = adata.uns[key][k][group]. 59 if pval_cutoff is not None:. 60 d = d[d[""pvals_adj""] < pval_cutoff]. KeyError: 'logfoldchanges'. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1530
https://github.com/scverse/scanpy/issues/1530:996,testability,log,logfoldchanges,996,"rank_genes_groups method='logreg' causes error with `sc.get.rank_genes_groups_df`; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. when running `sc.tl.rank_genes_groups` with `method='logreg'` the `logfoldchanges` are not generated. However, this field is. required by `sc.get.rank_genes_groups_df`. . ```python. adata = sc.datasets.pbmc68k_reduced(). sc.tl.rank_genes_groups(adata, 'bulk_labels', method='logreg'). sc.get.rank_genes_groups_df(adata, 'Dendritic'). ```. ```pytb. /scanpy/scanpy/get.py in rank_genes_groups_df(adata, group, key, pval_cutoff, log2fc_min, log2fc_max, gene_symbols). 56 d = pd.DataFrame(). 57 for k in ['scores', 'names', 'logfoldchanges', 'pvals', 'pvals_adj']:. ---> 58 d[k] = adata.uns[key][k][group]. 59 if pval_cutoff is not None:. 60 d = d[d[""pvals_adj""] < pval_cutoff]. KeyError: 'logfoldchanges'. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1530
https://github.com/scverse/scanpy/issues/1530:1072,testability,log,logging,1072,"rank_genes_groups method='logreg' causes error with `sc.get.rank_genes_groups_df`; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. when running `sc.tl.rank_genes_groups` with `method='logreg'` the `logfoldchanges` are not generated. However, this field is. required by `sc.get.rank_genes_groups_df`. . ```python. adata = sc.datasets.pbmc68k_reduced(). sc.tl.rank_genes_groups(adata, 'bulk_labels', method='logreg'). sc.get.rank_genes_groups_df(adata, 'Dendritic'). ```. ```pytb. /scanpy/scanpy/get.py in rank_genes_groups_df(adata, group, key, pval_cutoff, log2fc_min, log2fc_max, gene_symbols). 56 d = pd.DataFrame(). 57 for k in ['scores', 'names', 'logfoldchanges', 'pvals', 'pvals_adj']:. ---> 58 d[k] = adata.uns[key][k][group]. 59 if pval_cutoff is not None:. 60 d = d[d[""pvals_adj""] < pval_cutoff]. KeyError: 'logfoldchanges'. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1530
https://github.com/scverse/scanpy/issues/1530:41,usability,error,error,41,"rank_genes_groups method='logreg' causes error with `sc.get.rank_genes_groups_df`; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. when running `sc.tl.rank_genes_groups` with `method='logreg'` the `logfoldchanges` are not generated. However, this field is. required by `sc.get.rank_genes_groups_df`. . ```python. adata = sc.datasets.pbmc68k_reduced(). sc.tl.rank_genes_groups(adata, 'bulk_labels', method='logreg'). sc.get.rank_genes_groups_df(adata, 'Dendritic'). ```. ```pytb. /scanpy/scanpy/get.py in rank_genes_groups_df(adata, group, key, pval_cutoff, log2fc_min, log2fc_max, gene_symbols). 56 d = pd.DataFrame(). 57 for k in ['scores', 'names', 'logfoldchanges', 'pvals', 'pvals_adj']:. ---> 58 d[k] = adata.uns[key][k][group]. 59 if pval_cutoff is not None:. 60 d = d[d[""pvals_adj""] < pval_cutoff]. KeyError: 'logfoldchanges'. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1530
https://github.com/scverse/scanpy/issues/1530:164,usability,confirm,confirmed,164,"rank_genes_groups method='logreg' causes error with `sc.get.rank_genes_groups_df`; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. when running `sc.tl.rank_genes_groups` with `method='logreg'` the `logfoldchanges` are not generated. However, this field is. required by `sc.get.rank_genes_groups_df`. . ```python. adata = sc.datasets.pbmc68k_reduced(). sc.tl.rank_genes_groups(adata, 'bulk_labels', method='logreg'). sc.get.rank_genes_groups_df(adata, 'Dendritic'). ```. ```pytb. /scanpy/scanpy/get.py in rank_genes_groups_df(adata, group, key, pval_cutoff, log2fc_min, log2fc_max, gene_symbols). 56 d = pd.DataFrame(). 57 for k in ['scores', 'names', 'logfoldchanges', 'pvals', 'pvals_adj']:. ---> 58 d[k] = adata.uns[key][k][group]. 59 if pval_cutoff is not None:. 60 d = d[d[""pvals_adj""] < pval_cutoff]. KeyError: 'logfoldchanges'. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1530
https://github.com/scverse/scanpy/issues/1530:247,usability,confirm,confirmed,247,"rank_genes_groups method='logreg' causes error with `sc.get.rank_genes_groups_df`; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. when running `sc.tl.rank_genes_groups` with `method='logreg'` the `logfoldchanges` are not generated. However, this field is. required by `sc.get.rank_genes_groups_df`. . ```python. adata = sc.datasets.pbmc68k_reduced(). sc.tl.rank_genes_groups(adata, 'bulk_labels', method='logreg'). sc.get.rank_genes_groups_df(adata, 'Dendritic'). ```. ```pytb. /scanpy/scanpy/get.py in rank_genes_groups_df(adata, group, key, pval_cutoff, log2fc_min, log2fc_max, gene_symbols). 56 d = pd.DataFrame(). 57 for k in ['scores', 'names', 'logfoldchanges', 'pvals', 'pvals_adj']:. ---> 58 d[k] = adata.uns[key][k][group]. 59 if pval_cutoff is not None:. 60 d = d[d[""pvals_adj""] < pval_cutoff]. KeyError: 'logfoldchanges'. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1530
https://github.com/scverse/scanpy/issues/1531:21,availability,cluster,clustering,21,"kNN graph and leiden clustering differences between scanpy and Seurat; <!--.  If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead . If you want to know about design decisions and the like, please ask below:. -->. In our analyses we wanted to try SCTransform normalization instead of default log-norm. I have done it quite crudely, but it works: I run SCT in Seurat and dump the counts on disk to load in scanpy. While verifying that this approach worked, we encountered slight inconsistencies between clustering using (1) vanilla log-norm scanpy (2) SCT imported scanpy and (3) SCT in Seurat. After investigation, it appears that vanilla scanpy sometimes better picks up some clusters than SCT+scanpy, despite the latter having more relevant genes in its HVG list. Here is the investigation: https://github.com/mxposed/notebooks/blob/master/sct-scanpy.ipynb. And here are the main questions that remain:. 1. Why Vanilla scanpy could resolve those populations, despite operating on less marker HVGs? 2. What is the difference between kNN graph construction and clustering between Seurat and scanpy? 3. How to be sure we did not undercluster and miss some smaller cell populations? I would be glad for any feedback or input, and of course if someone knows the answers, that's great! Best wishes,. Nick. PS. Thank you for scanpy!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1531
https://github.com/scverse/scanpy/issues/1531:505,availability,sli,slight,505,"kNN graph and leiden clustering differences between scanpy and Seurat; <!--.  If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead . If you want to know about design decisions and the like, please ask below:. -->. In our analyses we wanted to try SCTransform normalization instead of default log-norm. I have done it quite crudely, but it works: I run SCT in Seurat and dump the counts on disk to load in scanpy. While verifying that this approach worked, we encountered slight inconsistencies between clustering using (1) vanilla log-norm scanpy (2) SCT imported scanpy and (3) SCT in Seurat. After investigation, it appears that vanilla scanpy sometimes better picks up some clusters than SCT+scanpy, despite the latter having more relevant genes in its HVG list. Here is the investigation: https://github.com/mxposed/notebooks/blob/master/sct-scanpy.ipynb. And here are the main questions that remain:. 1. Why Vanilla scanpy could resolve those populations, despite operating on less marker HVGs? 2. What is the difference between kNN graph construction and clustering between Seurat and scanpy? 3. How to be sure we did not undercluster and miss some smaller cell populations? I would be glad for any feedback or input, and of course if someone knows the answers, that's great! Best wishes,. Nick. PS. Thank you for scanpy!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1531
https://github.com/scverse/scanpy/issues/1531:536,availability,cluster,clustering,536,"kNN graph and leiden clustering differences between scanpy and Seurat; <!--.  If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead . If you want to know about design decisions and the like, please ask below:. -->. In our analyses we wanted to try SCTransform normalization instead of default log-norm. I have done it quite crudely, but it works: I run SCT in Seurat and dump the counts on disk to load in scanpy. While verifying that this approach worked, we encountered slight inconsistencies between clustering using (1) vanilla log-norm scanpy (2) SCT imported scanpy and (3) SCT in Seurat. After investigation, it appears that vanilla scanpy sometimes better picks up some clusters than SCT+scanpy, despite the latter having more relevant genes in its HVG list. Here is the investigation: https://github.com/mxposed/notebooks/blob/master/sct-scanpy.ipynb. And here are the main questions that remain:. 1. Why Vanilla scanpy could resolve those populations, despite operating on less marker HVGs? 2. What is the difference between kNN graph construction and clustering between Seurat and scanpy? 3. How to be sure we did not undercluster and miss some smaller cell populations? I would be glad for any feedback or input, and of course if someone knows the answers, that's great! Best wishes,. Nick. PS. Thank you for scanpy!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1531
https://github.com/scverse/scanpy/issues/1531:711,availability,cluster,clusters,711,"kNN graph and leiden clustering differences between scanpy and Seurat; <!--.  If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead . If you want to know about design decisions and the like, please ask below:. -->. In our analyses we wanted to try SCTransform normalization instead of default log-norm. I have done it quite crudely, but it works: I run SCT in Seurat and dump the counts on disk to load in scanpy. While verifying that this approach worked, we encountered slight inconsistencies between clustering using (1) vanilla log-norm scanpy (2) SCT imported scanpy and (3) SCT in Seurat. After investigation, it appears that vanilla scanpy sometimes better picks up some clusters than SCT+scanpy, despite the latter having more relevant genes in its HVG list. Here is the investigation: https://github.com/mxposed/notebooks/blob/master/sct-scanpy.ipynb. And here are the main questions that remain:. 1. Why Vanilla scanpy could resolve those populations, despite operating on less marker HVGs? 2. What is the difference between kNN graph construction and clustering between Seurat and scanpy? 3. How to be sure we did not undercluster and miss some smaller cell populations? I would be glad for any feedback or input, and of course if someone knows the answers, that's great! Best wishes,. Nick. PS. Thank you for scanpy!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1531
https://github.com/scverse/scanpy/issues/1531:1003,availability,operat,operating,1003,"kNN graph and leiden clustering differences between scanpy and Seurat; <!--.  If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead . If you want to know about design decisions and the like, please ask below:. -->. In our analyses we wanted to try SCTransform normalization instead of default log-norm. I have done it quite crudely, but it works: I run SCT in Seurat and dump the counts on disk to load in scanpy. While verifying that this approach worked, we encountered slight inconsistencies between clustering using (1) vanilla log-norm scanpy (2) SCT imported scanpy and (3) SCT in Seurat. After investigation, it appears that vanilla scanpy sometimes better picks up some clusters than SCT+scanpy, despite the latter having more relevant genes in its HVG list. Here is the investigation: https://github.com/mxposed/notebooks/blob/master/sct-scanpy.ipynb. And here are the main questions that remain:. 1. Why Vanilla scanpy could resolve those populations, despite operating on less marker HVGs? 2. What is the difference between kNN graph construction and clustering between Seurat and scanpy? 3. How to be sure we did not undercluster and miss some smaller cell populations? I would be glad for any feedback or input, and of course if someone knows the answers, that's great! Best wishes,. Nick. PS. Thank you for scanpy!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1531
https://github.com/scverse/scanpy/issues/1531:1095,availability,cluster,clustering,1095,"kNN graph and leiden clustering differences between scanpy and Seurat; <!--.  If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead . If you want to know about design decisions and the like, please ask below:. -->. In our analyses we wanted to try SCTransform normalization instead of default log-norm. I have done it quite crudely, but it works: I run SCT in Seurat and dump the counts on disk to load in scanpy. While verifying that this approach worked, we encountered slight inconsistencies between clustering using (1) vanilla log-norm scanpy (2) SCT imported scanpy and (3) SCT in Seurat. After investigation, it appears that vanilla scanpy sometimes better picks up some clusters than SCT+scanpy, despite the latter having more relevant genes in its HVG list. Here is the investigation: https://github.com/mxposed/notebooks/blob/master/sct-scanpy.ipynb. And here are the main questions that remain:. 1. Why Vanilla scanpy could resolve those populations, despite operating on less marker HVGs? 2. What is the difference between kNN graph construction and clustering between Seurat and scanpy? 3. How to be sure we did not undercluster and miss some smaller cell populations? I would be glad for any feedback or input, and of course if someone knows the answers, that's great! Best wishes,. Nick. PS. Thank you for scanpy!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1531
https://github.com/scverse/scanpy/issues/1531:21,deployability,cluster,clustering,21,"kNN graph and leiden clustering differences between scanpy and Seurat; <!--.  If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead . If you want to know about design decisions and the like, please ask below:. -->. In our analyses we wanted to try SCTransform normalization instead of default log-norm. I have done it quite crudely, but it works: I run SCT in Seurat and dump the counts on disk to load in scanpy. While verifying that this approach worked, we encountered slight inconsistencies between clustering using (1) vanilla log-norm scanpy (2) SCT imported scanpy and (3) SCT in Seurat. After investigation, it appears that vanilla scanpy sometimes better picks up some clusters than SCT+scanpy, despite the latter having more relevant genes in its HVG list. Here is the investigation: https://github.com/mxposed/notebooks/blob/master/sct-scanpy.ipynb. And here are the main questions that remain:. 1. Why Vanilla scanpy could resolve those populations, despite operating on less marker HVGs? 2. What is the difference between kNN graph construction and clustering between Seurat and scanpy? 3. How to be sure we did not undercluster and miss some smaller cell populations? I would be glad for any feedback or input, and of course if someone knows the answers, that's great! Best wishes,. Nick. PS. Thank you for scanpy!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1531
https://github.com/scverse/scanpy/issues/1531:326,deployability,log,log-norm,326,"kNN graph and leiden clustering differences between scanpy and Seurat; <!--.  If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead . If you want to know about design decisions and the like, please ask below:. -->. In our analyses we wanted to try SCTransform normalization instead of default log-norm. I have done it quite crudely, but it works: I run SCT in Seurat and dump the counts on disk to load in scanpy. While verifying that this approach worked, we encountered slight inconsistencies between clustering using (1) vanilla log-norm scanpy (2) SCT imported scanpy and (3) SCT in Seurat. After investigation, it appears that vanilla scanpy sometimes better picks up some clusters than SCT+scanpy, despite the latter having more relevant genes in its HVG list. Here is the investigation: https://github.com/mxposed/notebooks/blob/master/sct-scanpy.ipynb. And here are the main questions that remain:. 1. Why Vanilla scanpy could resolve those populations, despite operating on less marker HVGs? 2. What is the difference between kNN graph construction and clustering between Seurat and scanpy? 3. How to be sure we did not undercluster and miss some smaller cell populations? I would be glad for any feedback or input, and of course if someone knows the answers, that's great! Best wishes,. Nick. PS. Thank you for scanpy!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1531
https://github.com/scverse/scanpy/issues/1531:536,deployability,cluster,clustering,536,"kNN graph and leiden clustering differences between scanpy and Seurat; <!--.  If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead . If you want to know about design decisions and the like, please ask below:. -->. In our analyses we wanted to try SCTransform normalization instead of default log-norm. I have done it quite crudely, but it works: I run SCT in Seurat and dump the counts on disk to load in scanpy. While verifying that this approach worked, we encountered slight inconsistencies between clustering using (1) vanilla log-norm scanpy (2) SCT imported scanpy and (3) SCT in Seurat. After investigation, it appears that vanilla scanpy sometimes better picks up some clusters than SCT+scanpy, despite the latter having more relevant genes in its HVG list. Here is the investigation: https://github.com/mxposed/notebooks/blob/master/sct-scanpy.ipynb. And here are the main questions that remain:. 1. Why Vanilla scanpy could resolve those populations, despite operating on less marker HVGs? 2. What is the difference between kNN graph construction and clustering between Seurat and scanpy? 3. How to be sure we did not undercluster and miss some smaller cell populations? I would be glad for any feedback or input, and of course if someone knows the answers, that's great! Best wishes,. Nick. PS. Thank you for scanpy!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1531
https://github.com/scverse/scanpy/issues/1531:565,deployability,log,log-norm,565,"kNN graph and leiden clustering differences between scanpy and Seurat; <!--.  If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead . If you want to know about design decisions and the like, please ask below:. -->. In our analyses we wanted to try SCTransform normalization instead of default log-norm. I have done it quite crudely, but it works: I run SCT in Seurat and dump the counts on disk to load in scanpy. While verifying that this approach worked, we encountered slight inconsistencies between clustering using (1) vanilla log-norm scanpy (2) SCT imported scanpy and (3) SCT in Seurat. After investigation, it appears that vanilla scanpy sometimes better picks up some clusters than SCT+scanpy, despite the latter having more relevant genes in its HVG list. Here is the investigation: https://github.com/mxposed/notebooks/blob/master/sct-scanpy.ipynb. And here are the main questions that remain:. 1. Why Vanilla scanpy could resolve those populations, despite operating on less marker HVGs? 2. What is the difference between kNN graph construction and clustering between Seurat and scanpy? 3. How to be sure we did not undercluster and miss some smaller cell populations? I would be glad for any feedback or input, and of course if someone knows the answers, that's great! Best wishes,. Nick. PS. Thank you for scanpy!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1531
https://github.com/scverse/scanpy/issues/1531:711,deployability,cluster,clusters,711,"kNN graph and leiden clustering differences between scanpy and Seurat; <!--.  If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead . If you want to know about design decisions and the like, please ask below:. -->. In our analyses we wanted to try SCTransform normalization instead of default log-norm. I have done it quite crudely, but it works: I run SCT in Seurat and dump the counts on disk to load in scanpy. While verifying that this approach worked, we encountered slight inconsistencies between clustering using (1) vanilla log-norm scanpy (2) SCT imported scanpy and (3) SCT in Seurat. After investigation, it appears that vanilla scanpy sometimes better picks up some clusters than SCT+scanpy, despite the latter having more relevant genes in its HVG list. Here is the investigation: https://github.com/mxposed/notebooks/blob/master/sct-scanpy.ipynb. And here are the main questions that remain:. 1. Why Vanilla scanpy could resolve those populations, despite operating on less marker HVGs? 2. What is the difference between kNN graph construction and clustering between Seurat and scanpy? 3. How to be sure we did not undercluster and miss some smaller cell populations? I would be glad for any feedback or input, and of course if someone knows the answers, that's great! Best wishes,. Nick. PS. Thank you for scanpy!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1531
https://github.com/scverse/scanpy/issues/1531:1095,deployability,cluster,clustering,1095,"kNN graph and leiden clustering differences between scanpy and Seurat; <!--.  If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead . If you want to know about design decisions and the like, please ask below:. -->. In our analyses we wanted to try SCTransform normalization instead of default log-norm. I have done it quite crudely, but it works: I run SCT in Seurat and dump the counts on disk to load in scanpy. While verifying that this approach worked, we encountered slight inconsistencies between clustering using (1) vanilla log-norm scanpy (2) SCT imported scanpy and (3) SCT in Seurat. After investigation, it appears that vanilla scanpy sometimes better picks up some clusters than SCT+scanpy, despite the latter having more relevant genes in its HVG list. Here is the investigation: https://github.com/mxposed/notebooks/blob/master/sct-scanpy.ipynb. And here are the main questions that remain:. 1. Why Vanilla scanpy could resolve those populations, despite operating on less marker HVGs? 2. What is the difference between kNN graph construction and clustering between Seurat and scanpy? 3. How to be sure we did not undercluster and miss some smaller cell populations? I would be glad for any feedback or input, and of course if someone knows the answers, that's great! Best wishes,. Nick. PS. Thank you for scanpy!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1531
https://github.com/scverse/scanpy/issues/1531:431,energy efficiency,load,load,431,"kNN graph and leiden clustering differences between scanpy and Seurat; <!--.  If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead . If you want to know about design decisions and the like, please ask below:. -->. In our analyses we wanted to try SCTransform normalization instead of default log-norm. I have done it quite crudely, but it works: I run SCT in Seurat and dump the counts on disk to load in scanpy. While verifying that this approach worked, we encountered slight inconsistencies between clustering using (1) vanilla log-norm scanpy (2) SCT imported scanpy and (3) SCT in Seurat. After investigation, it appears that vanilla scanpy sometimes better picks up some clusters than SCT+scanpy, despite the latter having more relevant genes in its HVG list. Here is the investigation: https://github.com/mxposed/notebooks/blob/master/sct-scanpy.ipynb. And here are the main questions that remain:. 1. Why Vanilla scanpy could resolve those populations, despite operating on less marker HVGs? 2. What is the difference between kNN graph construction and clustering between Seurat and scanpy? 3. How to be sure we did not undercluster and miss some smaller cell populations? I would be glad for any feedback or input, and of course if someone knows the answers, that's great! Best wishes,. Nick. PS. Thank you for scanpy!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1531
https://github.com/scverse/scanpy/issues/1531:193,modifiability,design decis,design decisions,193,"kNN graph and leiden clustering differences between scanpy and Seurat; <!--.  If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead . If you want to know about design decisions and the like, please ask below:. -->. In our analyses we wanted to try SCTransform normalization instead of default log-norm. I have done it quite crudely, but it works: I run SCT in Seurat and dump the counts on disk to load in scanpy. While verifying that this approach worked, we encountered slight inconsistencies between clustering using (1) vanilla log-norm scanpy (2) SCT imported scanpy and (3) SCT in Seurat. After investigation, it appears that vanilla scanpy sometimes better picks up some clusters than SCT+scanpy, despite the latter having more relevant genes in its HVG list. Here is the investigation: https://github.com/mxposed/notebooks/blob/master/sct-scanpy.ipynb. And here are the main questions that remain:. 1. Why Vanilla scanpy could resolve those populations, despite operating on less marker HVGs? 2. What is the difference between kNN graph construction and clustering between Seurat and scanpy? 3. How to be sure we did not undercluster and miss some smaller cell populations? I would be glad for any feedback or input, and of course if someone knows the answers, that's great! Best wishes,. Nick. PS. Thank you for scanpy!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1531
https://github.com/scverse/scanpy/issues/1531:423,performance,disk,disk,423,"kNN graph and leiden clustering differences between scanpy and Seurat; <!--.  If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead . If you want to know about design decisions and the like, please ask below:. -->. In our analyses we wanted to try SCTransform normalization instead of default log-norm. I have done it quite crudely, but it works: I run SCT in Seurat and dump the counts on disk to load in scanpy. While verifying that this approach worked, we encountered slight inconsistencies between clustering using (1) vanilla log-norm scanpy (2) SCT imported scanpy and (3) SCT in Seurat. After investigation, it appears that vanilla scanpy sometimes better picks up some clusters than SCT+scanpy, despite the latter having more relevant genes in its HVG list. Here is the investigation: https://github.com/mxposed/notebooks/blob/master/sct-scanpy.ipynb. And here are the main questions that remain:. 1. Why Vanilla scanpy could resolve those populations, despite operating on less marker HVGs? 2. What is the difference between kNN graph construction and clustering between Seurat and scanpy? 3. How to be sure we did not undercluster and miss some smaller cell populations? I would be glad for any feedback or input, and of course if someone knows the answers, that's great! Best wishes,. Nick. PS. Thank you for scanpy!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1531
https://github.com/scverse/scanpy/issues/1531:431,performance,load,load,431,"kNN graph and leiden clustering differences between scanpy and Seurat; <!--.  If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead . If you want to know about design decisions and the like, please ask below:. -->. In our analyses we wanted to try SCTransform normalization instead of default log-norm. I have done it quite crudely, but it works: I run SCT in Seurat and dump the counts on disk to load in scanpy. While verifying that this approach worked, we encountered slight inconsistencies between clustering using (1) vanilla log-norm scanpy (2) SCT imported scanpy and (3) SCT in Seurat. After investigation, it appears that vanilla scanpy sometimes better picks up some clusters than SCT+scanpy, despite the latter having more relevant genes in its HVG list. Here is the investigation: https://github.com/mxposed/notebooks/blob/master/sct-scanpy.ipynb. And here are the main questions that remain:. 1. Why Vanilla scanpy could resolve those populations, despite operating on less marker HVGs? 2. What is the difference between kNN graph construction and clustering between Seurat and scanpy? 3. How to be sure we did not undercluster and miss some smaller cell populations? I would be glad for any feedback or input, and of course if someone knows the answers, that's great! Best wishes,. Nick. PS. Thank you for scanpy!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1531
https://github.com/scverse/scanpy/issues/1531:505,reliability,sli,slight,505,"kNN graph and leiden clustering differences between scanpy and Seurat; <!--.  If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead . If you want to know about design decisions and the like, please ask below:. -->. In our analyses we wanted to try SCTransform normalization instead of default log-norm. I have done it quite crudely, but it works: I run SCT in Seurat and dump the counts on disk to load in scanpy. While verifying that this approach worked, we encountered slight inconsistencies between clustering using (1) vanilla log-norm scanpy (2) SCT imported scanpy and (3) SCT in Seurat. After investigation, it appears that vanilla scanpy sometimes better picks up some clusters than SCT+scanpy, despite the latter having more relevant genes in its HVG list. Here is the investigation: https://github.com/mxposed/notebooks/blob/master/sct-scanpy.ipynb. And here are the main questions that remain:. 1. Why Vanilla scanpy could resolve those populations, despite operating on less marker HVGs? 2. What is the difference between kNN graph construction and clustering between Seurat and scanpy? 3. How to be sure we did not undercluster and miss some smaller cell populations? I would be glad for any feedback or input, and of course if someone knows the answers, that's great! Best wishes,. Nick. PS. Thank you for scanpy!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1531
https://github.com/scverse/scanpy/issues/1531:326,safety,log,log-norm,326,"kNN graph and leiden clustering differences between scanpy and Seurat; <!--.  If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead . If you want to know about design decisions and the like, please ask below:. -->. In our analyses we wanted to try SCTransform normalization instead of default log-norm. I have done it quite crudely, but it works: I run SCT in Seurat and dump the counts on disk to load in scanpy. While verifying that this approach worked, we encountered slight inconsistencies between clustering using (1) vanilla log-norm scanpy (2) SCT imported scanpy and (3) SCT in Seurat. After investigation, it appears that vanilla scanpy sometimes better picks up some clusters than SCT+scanpy, despite the latter having more relevant genes in its HVG list. Here is the investigation: https://github.com/mxposed/notebooks/blob/master/sct-scanpy.ipynb. And here are the main questions that remain:. 1. Why Vanilla scanpy could resolve those populations, despite operating on less marker HVGs? 2. What is the difference between kNN graph construction and clustering between Seurat and scanpy? 3. How to be sure we did not undercluster and miss some smaller cell populations? I would be glad for any feedback or input, and of course if someone knows the answers, that's great! Best wishes,. Nick. PS. Thank you for scanpy!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1531
https://github.com/scverse/scanpy/issues/1531:565,safety,log,log-norm,565,"kNN graph and leiden clustering differences between scanpy and Seurat; <!--.  If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead . If you want to know about design decisions and the like, please ask below:. -->. In our analyses we wanted to try SCTransform normalization instead of default log-norm. I have done it quite crudely, but it works: I run SCT in Seurat and dump the counts on disk to load in scanpy. While verifying that this approach worked, we encountered slight inconsistencies between clustering using (1) vanilla log-norm scanpy (2) SCT imported scanpy and (3) SCT in Seurat. After investigation, it appears that vanilla scanpy sometimes better picks up some clusters than SCT+scanpy, despite the latter having more relevant genes in its HVG list. Here is the investigation: https://github.com/mxposed/notebooks/blob/master/sct-scanpy.ipynb. And here are the main questions that remain:. 1. Why Vanilla scanpy could resolve those populations, despite operating on less marker HVGs? 2. What is the difference between kNN graph construction and clustering between Seurat and scanpy? 3. How to be sure we did not undercluster and miss some smaller cell populations? I would be glad for any feedback or input, and of course if someone knows the answers, that's great! Best wishes,. Nick. PS. Thank you for scanpy!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1531
https://github.com/scverse/scanpy/issues/1531:1251,safety,input,input,1251,"kNN graph and leiden clustering differences between scanpy and Seurat; <!--.  If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead . If you want to know about design decisions and the like, please ask below:. -->. In our analyses we wanted to try SCTransform normalization instead of default log-norm. I have done it quite crudely, but it works: I run SCT in Seurat and dump the counts on disk to load in scanpy. While verifying that this approach worked, we encountered slight inconsistencies between clustering using (1) vanilla log-norm scanpy (2) SCT imported scanpy and (3) SCT in Seurat. After investigation, it appears that vanilla scanpy sometimes better picks up some clusters than SCT+scanpy, despite the latter having more relevant genes in its HVG list. Here is the investigation: https://github.com/mxposed/notebooks/blob/master/sct-scanpy.ipynb. And here are the main questions that remain:. 1. Why Vanilla scanpy could resolve those populations, despite operating on less marker HVGs? 2. What is the difference between kNN graph construction and clustering between Seurat and scanpy? 3. How to be sure we did not undercluster and miss some smaller cell populations? I would be glad for any feedback or input, and of course if someone knows the answers, that's great! Best wishes,. Nick. PS. Thank you for scanpy!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1531
https://github.com/scverse/scanpy/issues/1531:326,security,log,log-norm,326,"kNN graph and leiden clustering differences between scanpy and Seurat; <!--.  If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead . If you want to know about design decisions and the like, please ask below:. -->. In our analyses we wanted to try SCTransform normalization instead of default log-norm. I have done it quite crudely, but it works: I run SCT in Seurat and dump the counts on disk to load in scanpy. While verifying that this approach worked, we encountered slight inconsistencies between clustering using (1) vanilla log-norm scanpy (2) SCT imported scanpy and (3) SCT in Seurat. After investigation, it appears that vanilla scanpy sometimes better picks up some clusters than SCT+scanpy, despite the latter having more relevant genes in its HVG list. Here is the investigation: https://github.com/mxposed/notebooks/blob/master/sct-scanpy.ipynb. And here are the main questions that remain:. 1. Why Vanilla scanpy could resolve those populations, despite operating on less marker HVGs? 2. What is the difference between kNN graph construction and clustering between Seurat and scanpy? 3. How to be sure we did not undercluster and miss some smaller cell populations? I would be glad for any feedback or input, and of course if someone knows the answers, that's great! Best wishes,. Nick. PS. Thank you for scanpy!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1531
https://github.com/scverse/scanpy/issues/1531:565,security,log,log-norm,565,"kNN graph and leiden clustering differences between scanpy and Seurat; <!--.  If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead . If you want to know about design decisions and the like, please ask below:. -->. In our analyses we wanted to try SCTransform normalization instead of default log-norm. I have done it quite crudely, but it works: I run SCT in Seurat and dump the counts on disk to load in scanpy. While verifying that this approach worked, we encountered slight inconsistencies between clustering using (1) vanilla log-norm scanpy (2) SCT imported scanpy and (3) SCT in Seurat. After investigation, it appears that vanilla scanpy sometimes better picks up some clusters than SCT+scanpy, despite the latter having more relevant genes in its HVG list. Here is the investigation: https://github.com/mxposed/notebooks/blob/master/sct-scanpy.ipynb. And here are the main questions that remain:. 1. Why Vanilla scanpy could resolve those populations, despite operating on less marker HVGs? 2. What is the difference between kNN graph construction and clustering between Seurat and scanpy? 3. How to be sure we did not undercluster and miss some smaller cell populations? I would be glad for any feedback or input, and of course if someone knows the answers, that's great! Best wishes,. Nick. PS. Thank you for scanpy!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1531
https://github.com/scverse/scanpy/issues/1531:326,testability,log,log-norm,326,"kNN graph and leiden clustering differences between scanpy and Seurat; <!--.  If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead . If you want to know about design decisions and the like, please ask below:. -->. In our analyses we wanted to try SCTransform normalization instead of default log-norm. I have done it quite crudely, but it works: I run SCT in Seurat and dump the counts on disk to load in scanpy. While verifying that this approach worked, we encountered slight inconsistencies between clustering using (1) vanilla log-norm scanpy (2) SCT imported scanpy and (3) SCT in Seurat. After investigation, it appears that vanilla scanpy sometimes better picks up some clusters than SCT+scanpy, despite the latter having more relevant genes in its HVG list. Here is the investigation: https://github.com/mxposed/notebooks/blob/master/sct-scanpy.ipynb. And here are the main questions that remain:. 1. Why Vanilla scanpy could resolve those populations, despite operating on less marker HVGs? 2. What is the difference between kNN graph construction and clustering between Seurat and scanpy? 3. How to be sure we did not undercluster and miss some smaller cell populations? I would be glad for any feedback or input, and of course if someone knows the answers, that's great! Best wishes,. Nick. PS. Thank you for scanpy!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1531
https://github.com/scverse/scanpy/issues/1531:453,testability,verif,verifying,453,"kNN graph and leiden clustering differences between scanpy and Seurat; <!--.  If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead . If you want to know about design decisions and the like, please ask below:. -->. In our analyses we wanted to try SCTransform normalization instead of default log-norm. I have done it quite crudely, but it works: I run SCT in Seurat and dump the counts on disk to load in scanpy. While verifying that this approach worked, we encountered slight inconsistencies between clustering using (1) vanilla log-norm scanpy (2) SCT imported scanpy and (3) SCT in Seurat. After investigation, it appears that vanilla scanpy sometimes better picks up some clusters than SCT+scanpy, despite the latter having more relevant genes in its HVG list. Here is the investigation: https://github.com/mxposed/notebooks/blob/master/sct-scanpy.ipynb. And here are the main questions that remain:. 1. Why Vanilla scanpy could resolve those populations, despite operating on less marker HVGs? 2. What is the difference between kNN graph construction and clustering between Seurat and scanpy? 3. How to be sure we did not undercluster and miss some smaller cell populations? I would be glad for any feedback or input, and of course if someone knows the answers, that's great! Best wishes,. Nick. PS. Thank you for scanpy!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1531
https://github.com/scverse/scanpy/issues/1531:565,testability,log,log-norm,565,"kNN graph and leiden clustering differences between scanpy and Seurat; <!--.  If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead . If you want to know about design decisions and the like, please ask below:. -->. In our analyses we wanted to try SCTransform normalization instead of default log-norm. I have done it quite crudely, but it works: I run SCT in Seurat and dump the counts on disk to load in scanpy. While verifying that this approach worked, we encountered slight inconsistencies between clustering using (1) vanilla log-norm scanpy (2) SCT imported scanpy and (3) SCT in Seurat. After investigation, it appears that vanilla scanpy sometimes better picks up some clusters than SCT+scanpy, despite the latter having more relevant genes in its HVG list. Here is the investigation: https://github.com/mxposed/notebooks/blob/master/sct-scanpy.ipynb. And here are the main questions that remain:. 1. Why Vanilla scanpy could resolve those populations, despite operating on less marker HVGs? 2. What is the difference between kNN graph construction and clustering between Seurat and scanpy? 3. How to be sure we did not undercluster and miss some smaller cell populations? I would be glad for any feedback or input, and of course if someone knows the answers, that's great! Best wishes,. Nick. PS. Thank you for scanpy!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1531
https://github.com/scverse/scanpy/issues/1531:91,usability,help,help,91,"kNN graph and leiden clustering differences between scanpy and Seurat; <!--.  If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead . If you want to know about design decisions and the like, please ask below:. -->. In our analyses we wanted to try SCTransform normalization instead of default log-norm. I have done it quite crudely, but it works: I run SCT in Seurat and dump the counts on disk to load in scanpy. While verifying that this approach worked, we encountered slight inconsistencies between clustering using (1) vanilla log-norm scanpy (2) SCT imported scanpy and (3) SCT in Seurat. After investigation, it appears that vanilla scanpy sometimes better picks up some clusters than SCT+scanpy, despite the latter having more relevant genes in its HVG list. Here is the investigation: https://github.com/mxposed/notebooks/blob/master/sct-scanpy.ipynb. And here are the main questions that remain:. 1. Why Vanilla scanpy could resolve those populations, despite operating on less marker HVGs? 2. What is the difference between kNN graph construction and clustering between Seurat and scanpy? 3. How to be sure we did not undercluster and miss some smaller cell populations? I would be glad for any feedback or input, and of course if someone knows the answers, that's great! Best wishes,. Nick. PS. Thank you for scanpy!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1531
https://github.com/scverse/scanpy/issues/1531:1239,usability,feedback,feedback,1239,"kNN graph and leiden clustering differences between scanpy and Seurat; <!--.  If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead . If you want to know about design decisions and the like, please ask below:. -->. In our analyses we wanted to try SCTransform normalization instead of default log-norm. I have done it quite crudely, but it works: I run SCT in Seurat and dump the counts on disk to load in scanpy. While verifying that this approach worked, we encountered slight inconsistencies between clustering using (1) vanilla log-norm scanpy (2) SCT imported scanpy and (3) SCT in Seurat. After investigation, it appears that vanilla scanpy sometimes better picks up some clusters than SCT+scanpy, despite the latter having more relevant genes in its HVG list. Here is the investigation: https://github.com/mxposed/notebooks/blob/master/sct-scanpy.ipynb. And here are the main questions that remain:. 1. Why Vanilla scanpy could resolve those populations, despite operating on less marker HVGs? 2. What is the difference between kNN graph construction and clustering between Seurat and scanpy? 3. How to be sure we did not undercluster and miss some smaller cell populations? I would be glad for any feedback or input, and of course if someone knows the answers, that's great! Best wishes,. Nick. PS. Thank you for scanpy!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1531
https://github.com/scverse/scanpy/issues/1531:1251,usability,input,input,1251,"kNN graph and leiden clustering differences between scanpy and Seurat; <!--.  If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead . If you want to know about design decisions and the like, please ask below:. -->. In our analyses we wanted to try SCTransform normalization instead of default log-norm. I have done it quite crudely, but it works: I run SCT in Seurat and dump the counts on disk to load in scanpy. While verifying that this approach worked, we encountered slight inconsistencies between clustering using (1) vanilla log-norm scanpy (2) SCT imported scanpy and (3) SCT in Seurat. After investigation, it appears that vanilla scanpy sometimes better picks up some clusters than SCT+scanpy, despite the latter having more relevant genes in its HVG list. Here is the investigation: https://github.com/mxposed/notebooks/blob/master/sct-scanpy.ipynb. And here are the main questions that remain:. 1. Why Vanilla scanpy could resolve those populations, despite operating on less marker HVGs? 2. What is the difference between kNN graph construction and clustering between Seurat and scanpy? 3. How to be sure we did not undercluster and miss some smaller cell populations? I would be glad for any feedback or input, and of course if someone knows the answers, that's great! Best wishes,. Nick. PS. Thank you for scanpy!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1531
https://github.com/scverse/scanpy/pull/1532:22,usability,support,supported,22,Use a VM thats still supported 5 months from now;,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1532
https://github.com/scverse/scanpy/pull/1533:407,availability,sli,slightly,407,"Gpu additions; This PR aims to add more GPU functionalities and to integrate more an exisiting one:. * `tl.draw_graph` and `tl.leiden` can now both be GPU accelerated using rapids framework. * on `pp.neighbors`, now 'rapids' method allows for more metrics. Calculated distance does not need to be root squared anymore (_See https://github.com/rapidsai/cuml/issues/1078#issuecomment-551284134_). I also have slightly rearranged the code to integrate more 'rapids' into the general processing of neighbors, to ensure that distances and connectivities results between 'rapids' and 'umap' are the same.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:67,deployability,integr,integrate,67,"Gpu additions; This PR aims to add more GPU functionalities and to integrate more an exisiting one:. * `tl.draw_graph` and `tl.leiden` can now both be GPU accelerated using rapids framework. * on `pp.neighbors`, now 'rapids' method allows for more metrics. Calculated distance does not need to be root squared anymore (_See https://github.com/rapidsai/cuml/issues/1078#issuecomment-551284134_). I also have slightly rearranged the code to integrate more 'rapids' into the general processing of neighbors, to ensure that distances and connectivities results between 'rapids' and 'umap' are the same.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:439,deployability,integr,integrate,439,"Gpu additions; This PR aims to add more GPU functionalities and to integrate more an exisiting one:. * `tl.draw_graph` and `tl.leiden` can now both be GPU accelerated using rapids framework. * on `pp.neighbors`, now 'rapids' method allows for more metrics. Calculated distance does not need to be root squared anymore (_See https://github.com/rapidsai/cuml/issues/1078#issuecomment-551284134_). I also have slightly rearranged the code to integrate more 'rapids' into the general processing of neighbors, to ensure that distances and connectivities results between 'rapids' and 'umap' are the same.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:0,energy efficiency,Gpu,Gpu,0,"Gpu additions; This PR aims to add more GPU functionalities and to integrate more an exisiting one:. * `tl.draw_graph` and `tl.leiden` can now both be GPU accelerated using rapids framework. * on `pp.neighbors`, now 'rapids' method allows for more metrics. Calculated distance does not need to be root squared anymore (_See https://github.com/rapidsai/cuml/issues/1078#issuecomment-551284134_). I also have slightly rearranged the code to integrate more 'rapids' into the general processing of neighbors, to ensure that distances and connectivities results between 'rapids' and 'umap' are the same.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:40,energy efficiency,GPU,GPU,40,"Gpu additions; This PR aims to add more GPU functionalities and to integrate more an exisiting one:. * `tl.draw_graph` and `tl.leiden` can now both be GPU accelerated using rapids framework. * on `pp.neighbors`, now 'rapids' method allows for more metrics. Calculated distance does not need to be root squared anymore (_See https://github.com/rapidsai/cuml/issues/1078#issuecomment-551284134_). I also have slightly rearranged the code to integrate more 'rapids' into the general processing of neighbors, to ensure that distances and connectivities results between 'rapids' and 'umap' are the same.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:151,energy efficiency,GPU,GPU,151,"Gpu additions; This PR aims to add more GPU functionalities and to integrate more an exisiting one:. * `tl.draw_graph` and `tl.leiden` can now both be GPU accelerated using rapids framework. * on `pp.neighbors`, now 'rapids' method allows for more metrics. Calculated distance does not need to be root squared anymore (_See https://github.com/rapidsai/cuml/issues/1078#issuecomment-551284134_). I also have slightly rearranged the code to integrate more 'rapids' into the general processing of neighbors, to ensure that distances and connectivities results between 'rapids' and 'umap' are the same.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:67,integrability,integr,integrate,67,"Gpu additions; This PR aims to add more GPU functionalities and to integrate more an exisiting one:. * `tl.draw_graph` and `tl.leiden` can now both be GPU accelerated using rapids framework. * on `pp.neighbors`, now 'rapids' method allows for more metrics. Calculated distance does not need to be root squared anymore (_See https://github.com/rapidsai/cuml/issues/1078#issuecomment-551284134_). I also have slightly rearranged the code to integrate more 'rapids' into the general processing of neighbors, to ensure that distances and connectivities results between 'rapids' and 'umap' are the same.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:439,integrability,integr,integrate,439,"Gpu additions; This PR aims to add more GPU functionalities and to integrate more an exisiting one:. * `tl.draw_graph` and `tl.leiden` can now both be GPU accelerated using rapids framework. * on `pp.neighbors`, now 'rapids' method allows for more metrics. Calculated distance does not need to be root squared anymore (_See https://github.com/rapidsai/cuml/issues/1078#issuecomment-551284134_). I also have slightly rearranged the code to integrate more 'rapids' into the general processing of neighbors, to ensure that distances and connectivities results between 'rapids' and 'umap' are the same.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:67,interoperability,integr,integrate,67,"Gpu additions; This PR aims to add more GPU functionalities and to integrate more an exisiting one:. * `tl.draw_graph` and `tl.leiden` can now both be GPU accelerated using rapids framework. * on `pp.neighbors`, now 'rapids' method allows for more metrics. Calculated distance does not need to be root squared anymore (_See https://github.com/rapidsai/cuml/issues/1078#issuecomment-551284134_). I also have slightly rearranged the code to integrate more 'rapids' into the general processing of neighbors, to ensure that distances and connectivities results between 'rapids' and 'umap' are the same.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:439,interoperability,integr,integrate,439,"Gpu additions; This PR aims to add more GPU functionalities and to integrate more an exisiting one:. * `tl.draw_graph` and `tl.leiden` can now both be GPU accelerated using rapids framework. * on `pp.neighbors`, now 'rapids' method allows for more metrics. Calculated distance does not need to be root squared anymore (_See https://github.com/rapidsai/cuml/issues/1078#issuecomment-551284134_). I also have slightly rearranged the code to integrate more 'rapids' into the general processing of neighbors, to ensure that distances and connectivities results between 'rapids' and 'umap' are the same.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:67,modifiability,integr,integrate,67,"Gpu additions; This PR aims to add more GPU functionalities and to integrate more an exisiting one:. * `tl.draw_graph` and `tl.leiden` can now both be GPU accelerated using rapids framework. * on `pp.neighbors`, now 'rapids' method allows for more metrics. Calculated distance does not need to be root squared anymore (_See https://github.com/rapidsai/cuml/issues/1078#issuecomment-551284134_). I also have slightly rearranged the code to integrate more 'rapids' into the general processing of neighbors, to ensure that distances and connectivities results between 'rapids' and 'umap' are the same.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:439,modifiability,integr,integrate,439,"Gpu additions; This PR aims to add more GPU functionalities and to integrate more an exisiting one:. * `tl.draw_graph` and `tl.leiden` can now both be GPU accelerated using rapids framework. * on `pp.neighbors`, now 'rapids' method allows for more metrics. Calculated distance does not need to be root squared anymore (_See https://github.com/rapidsai/cuml/issues/1078#issuecomment-551284134_). I also have slightly rearranged the code to integrate more 'rapids' into the general processing of neighbors, to ensure that distances and connectivities results between 'rapids' and 'umap' are the same.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:0,performance,Gpu,Gpu,0,"Gpu additions; This PR aims to add more GPU functionalities and to integrate more an exisiting one:. * `tl.draw_graph` and `tl.leiden` can now both be GPU accelerated using rapids framework. * on `pp.neighbors`, now 'rapids' method allows for more metrics. Calculated distance does not need to be root squared anymore (_See https://github.com/rapidsai/cuml/issues/1078#issuecomment-551284134_). I also have slightly rearranged the code to integrate more 'rapids' into the general processing of neighbors, to ensure that distances and connectivities results between 'rapids' and 'umap' are the same.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:40,performance,GPU,GPU,40,"Gpu additions; This PR aims to add more GPU functionalities and to integrate more an exisiting one:. * `tl.draw_graph` and `tl.leiden` can now both be GPU accelerated using rapids framework. * on `pp.neighbors`, now 'rapids' method allows for more metrics. Calculated distance does not need to be root squared anymore (_See https://github.com/rapidsai/cuml/issues/1078#issuecomment-551284134_). I also have slightly rearranged the code to integrate more 'rapids' into the general processing of neighbors, to ensure that distances and connectivities results between 'rapids' and 'umap' are the same.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:151,performance,GPU,GPU,151,"Gpu additions; This PR aims to add more GPU functionalities and to integrate more an exisiting one:. * `tl.draw_graph` and `tl.leiden` can now both be GPU accelerated using rapids framework. * on `pp.neighbors`, now 'rapids' method allows for more metrics. Calculated distance does not need to be root squared anymore (_See https://github.com/rapidsai/cuml/issues/1078#issuecomment-551284134_). I also have slightly rearranged the code to integrate more 'rapids' into the general processing of neighbors, to ensure that distances and connectivities results between 'rapids' and 'umap' are the same.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:67,reliability,integr,integrate,67,"Gpu additions; This PR aims to add more GPU functionalities and to integrate more an exisiting one:. * `tl.draw_graph` and `tl.leiden` can now both be GPU accelerated using rapids framework. * on `pp.neighbors`, now 'rapids' method allows for more metrics. Calculated distance does not need to be root squared anymore (_See https://github.com/rapidsai/cuml/issues/1078#issuecomment-551284134_). I also have slightly rearranged the code to integrate more 'rapids' into the general processing of neighbors, to ensure that distances and connectivities results between 'rapids' and 'umap' are the same.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:277,reliability,doe,does,277,"Gpu additions; This PR aims to add more GPU functionalities and to integrate more an exisiting one:. * `tl.draw_graph` and `tl.leiden` can now both be GPU accelerated using rapids framework. * on `pp.neighbors`, now 'rapids' method allows for more metrics. Calculated distance does not need to be root squared anymore (_See https://github.com/rapidsai/cuml/issues/1078#issuecomment-551284134_). I also have slightly rearranged the code to integrate more 'rapids' into the general processing of neighbors, to ensure that distances and connectivities results between 'rapids' and 'umap' are the same.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:407,reliability,sli,slightly,407,"Gpu additions; This PR aims to add more GPU functionalities and to integrate more an exisiting one:. * `tl.draw_graph` and `tl.leiden` can now both be GPU accelerated using rapids framework. * on `pp.neighbors`, now 'rapids' method allows for more metrics. Calculated distance does not need to be root squared anymore (_See https://github.com/rapidsai/cuml/issues/1078#issuecomment-551284134_). I also have slightly rearranged the code to integrate more 'rapids' into the general processing of neighbors, to ensure that distances and connectivities results between 'rapids' and 'umap' are the same.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:439,reliability,integr,integrate,439,"Gpu additions; This PR aims to add more GPU functionalities and to integrate more an exisiting one:. * `tl.draw_graph` and `tl.leiden` can now both be GPU accelerated using rapids framework. * on `pp.neighbors`, now 'rapids' method allows for more metrics. Calculated distance does not need to be root squared anymore (_See https://github.com/rapidsai/cuml/issues/1078#issuecomment-551284134_). I also have slightly rearranged the code to integrate more 'rapids' into the general processing of neighbors, to ensure that distances and connectivities results between 'rapids' and 'umap' are the same.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:67,security,integr,integrate,67,"Gpu additions; This PR aims to add more GPU functionalities and to integrate more an exisiting one:. * `tl.draw_graph` and `tl.leiden` can now both be GPU accelerated using rapids framework. * on `pp.neighbors`, now 'rapids' method allows for more metrics. Calculated distance does not need to be root squared anymore (_See https://github.com/rapidsai/cuml/issues/1078#issuecomment-551284134_). I also have slightly rearranged the code to integrate more 'rapids' into the general processing of neighbors, to ensure that distances and connectivities results between 'rapids' and 'umap' are the same.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:439,security,integr,integrate,439,"Gpu additions; This PR aims to add more GPU functionalities and to integrate more an exisiting one:. * `tl.draw_graph` and `tl.leiden` can now both be GPU accelerated using rapids framework. * on `pp.neighbors`, now 'rapids' method allows for more metrics. Calculated distance does not need to be root squared anymore (_See https://github.com/rapidsai/cuml/issues/1078#issuecomment-551284134_). I also have slightly rearranged the code to integrate more 'rapids' into the general processing of neighbors, to ensure that distances and connectivities results between 'rapids' and 'umap' are the same.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:67,testability,integr,integrate,67,"Gpu additions; This PR aims to add more GPU functionalities and to integrate more an exisiting one:. * `tl.draw_graph` and `tl.leiden` can now both be GPU accelerated using rapids framework. * on `pp.neighbors`, now 'rapids' method allows for more metrics. Calculated distance does not need to be root squared anymore (_See https://github.com/rapidsai/cuml/issues/1078#issuecomment-551284134_). I also have slightly rearranged the code to integrate more 'rapids' into the general processing of neighbors, to ensure that distances and connectivities results between 'rapids' and 'umap' are the same.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/pull/1533:439,testability,integr,integrate,439,"Gpu additions; This PR aims to add more GPU functionalities and to integrate more an exisiting one:. * `tl.draw_graph` and `tl.leiden` can now both be GPU accelerated using rapids framework. * on `pp.neighbors`, now 'rapids' method allows for more metrics. Calculated distance does not need to be root squared anymore (_See https://github.com/rapidsai/cuml/issues/1078#issuecomment-551284134_). I also have slightly rearranged the code to integrate more 'rapids' into the general processing of neighbors, to ensure that distances and connectivities results between 'rapids' and 'umap' are the same.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1533
https://github.com/scverse/scanpy/issues/1534:210,deployability,version,version,210,"sc.pl.embedding with basis ""spatial"" has side-effects and is missing one row of points ; - [x] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. sc.pl.embedding with basis ""spatial"" behaves strangely. See code example below. . - when ""spatial"" is an `unit` array, the resulting plot is missing the top row of points (I think there might be an overflow happening). - when plotting edges and using basis ""spatial"", `adata.obsm[""spatial""] is modified after calling `sc.pl.embedding`. @giovp . ### Minimal code sample (that we can copy&paste without having any data). ```python. import numpy as np. import anndata as ad. import scanpy as sc. import matplotlib.pyplot as plt. print(sc.__version__). arr = np.array([[1888, 55],. [1887, 54],. [1888, 54],. [1889, 54],. [1887, 55],. [1889, 55],. [1887, 56],. [1888, 56],. [1889, 56]], dtype=np.uint8). conn = np.array([[0., 1., 1., 1., 1., 1., 1., 1., 1.],. [1., 0., 1., 0., 1., 0., 0., 0., 0.],. [1., 1., 0., 1., 1., 1., 0., 0., 0.],. [1., 0., 1., 0., 0., 1., 0., 0., 0.],. [1., 1., 1., 0., 0., 0., 1., 1., 0.],. [1., 0., 1., 1., 0., 0., 0., 1., 1.],. [1., 0., 0., 0., 1., 0., 0., 1., 0.],. [1., 0., 0., 0., 1., 1., 1., 0., 1.],. [1., 0., 0., 0., 0., 1., 0., 1., 0.]]). a = ad.AnnData(arr). a.uns = {'spatial': {'connectivities_key': 'spatial_connectivities', 'distances_key': 'spatial_distances', 'params': {'n_neighbors': 8, 'coord_type': None, 'radius': 1.5}}}. a.obsp['spatial_connectivities'] = conn. a.obsm['coords'] = arr.copy(). a.obsm['spatial'] = arr.copy(). sc.pl.embedding(a, 'coords', edges=True, neighbors_key = 'spatial'). print('coords', a.obsm['coords']). sc.pl.embedding(a, 'spatial'). print('spatial no edges', a.obsm['spatial']). sc.pl.embedding(a, 'spatial', edges=True, neighbors_key = 'spatial'). print('spatial edges', a.obsm['spatial']). ```. produces following",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1534
https://github.com/scverse/scanpy/issues/1534:2841,deployability,Version,Versions,2841,".],. [1., 0., 1., 0., 1., 0., 0., 0., 0.],. [1., 1., 0., 1., 1., 1., 0., 0., 0.],. [1., 0., 1., 0., 0., 1., 0., 0., 0.],. [1., 1., 1., 0., 0., 0., 1., 1., 0.],. [1., 0., 1., 1., 0., 0., 0., 1., 1.],. [1., 0., 0., 0., 1., 0., 0., 1., 0.],. [1., 0., 0., 0., 1., 1., 1., 0., 1.],. [1., 0., 0., 0., 0., 1., 0., 1., 0.]]). a = ad.AnnData(arr). a.uns = {'spatial': {'connectivities_key': 'spatial_connectivities', 'distances_key': 'spatial_distances', 'params': {'n_neighbors': 8, 'coord_type': None, 'radius': 1.5}}}. a.obsp['spatial_connectivities'] = conn. a.obsm['coords'] = arr.copy(). a.obsm['spatial'] = arr.copy(). sc.pl.embedding(a, 'coords', edges=True, neighbors_key = 'spatial'). print('coords', a.obsm['coords']). sc.pl.embedding(a, 'spatial'). print('spatial no edges', a.obsm['spatial']). sc.pl.embedding(a, 'spatial', edges=True, neighbors_key = 'spatial'). print('spatial edges', a.obsm['spatial']). ```. produces following output:. - expected (when plotting ""coords""). ![image](https://user-images.githubusercontent.com/13350159/101187374-9206bd00-3654-11eb-9b7c-38b5870ab815.png). ```. coords [[96 55]. [95 54]. [96 54]. [97 54]. [95 55]. [97 55]. [95 56]. [96 56]. [97 56]]. ```. - when plotting ""spatial"" without edges (obsm is not modified). ![image](https://user-images.githubusercontent.com/13350159/101187899-40aafd80-3655-11eb-9738-9899efba9d52.png). ```. spatial no edges [[96 55]. [95 54]. [96 54]. [97 54]. [95 55]. [97 55]. [95 56]. [96 56]. [97 56]]. ```. - when plotting ""spatial"" with edges (obsm is modified). ![image](https://user-images.githubusercontent.com/13350159/101187963-5ae4db80-3655-11eb-9866-6824831b18a9.png). ```. spatial edges [[ 96 255]. [ 95 254]. [ 96 254]. [ 97 254]. [ 95 255]. [ 97 255]. [ 95 0]. [ 96 0]. [ 97 0]]. ```. #### Versions. <details>. scanpy==1.6.1.dev70+g7f15d22d anndata==0.7.5 umap==0.4.6 numpy==1.19.4 scipy==1.5.3 pandas==1.1.4 scikit-learn==0.23.2 statsmodels==0.12.1 python-igraph==0.8.3 louvain==0.6.1 leidenalg==0.8.3. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1534
https://github.com/scverse/scanpy/issues/1534:210,integrability,version,version,210,"sc.pl.embedding with basis ""spatial"" has side-effects and is missing one row of points ; - [x] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. sc.pl.embedding with basis ""spatial"" behaves strangely. See code example below. . - when ""spatial"" is an `unit` array, the resulting plot is missing the top row of points (I think there might be an overflow happening). - when plotting edges and using basis ""spatial"", `adata.obsm[""spatial""] is modified after calling `sc.pl.embedding`. @giovp . ### Minimal code sample (that we can copy&paste without having any data). ```python. import numpy as np. import anndata as ad. import scanpy as sc. import matplotlib.pyplot as plt. print(sc.__version__). arr = np.array([[1888, 55],. [1887, 54],. [1888, 54],. [1889, 54],. [1887, 55],. [1889, 55],. [1887, 56],. [1888, 56],. [1889, 56]], dtype=np.uint8). conn = np.array([[0., 1., 1., 1., 1., 1., 1., 1., 1.],. [1., 0., 1., 0., 1., 0., 0., 0., 0.],. [1., 1., 0., 1., 1., 1., 0., 0., 0.],. [1., 0., 1., 0., 0., 1., 0., 0., 0.],. [1., 1., 1., 0., 0., 0., 1., 1., 0.],. [1., 0., 1., 1., 0., 0., 0., 1., 1.],. [1., 0., 0., 0., 1., 0., 0., 1., 0.],. [1., 0., 0., 0., 1., 1., 1., 0., 1.],. [1., 0., 0., 0., 0., 1., 0., 1., 0.]]). a = ad.AnnData(arr). a.uns = {'spatial': {'connectivities_key': 'spatial_connectivities', 'distances_key': 'spatial_distances', 'params': {'n_neighbors': 8, 'coord_type': None, 'radius': 1.5}}}. a.obsp['spatial_connectivities'] = conn. a.obsm['coords'] = arr.copy(). a.obsm['spatial'] = arr.copy(). sc.pl.embedding(a, 'coords', edges=True, neighbors_key = 'spatial'). print('coords', a.obsm['coords']). sc.pl.embedding(a, 'spatial'). print('spatial no edges', a.obsm['spatial']). sc.pl.embedding(a, 'spatial', edges=True, neighbors_key = 'spatial'). print('spatial edges', a.obsm['spatial']). ```. produces following",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1534
https://github.com/scverse/scanpy/issues/1534:2841,integrability,Version,Versions,2841,".],. [1., 0., 1., 0., 1., 0., 0., 0., 0.],. [1., 1., 0., 1., 1., 1., 0., 0., 0.],. [1., 0., 1., 0., 0., 1., 0., 0., 0.],. [1., 1., 1., 0., 0., 0., 1., 1., 0.],. [1., 0., 1., 1., 0., 0., 0., 1., 1.],. [1., 0., 0., 0., 1., 0., 0., 1., 0.],. [1., 0., 0., 0., 1., 1., 1., 0., 1.],. [1., 0., 0., 0., 0., 1., 0., 1., 0.]]). a = ad.AnnData(arr). a.uns = {'spatial': {'connectivities_key': 'spatial_connectivities', 'distances_key': 'spatial_distances', 'params': {'n_neighbors': 8, 'coord_type': None, 'radius': 1.5}}}. a.obsp['spatial_connectivities'] = conn. a.obsm['coords'] = arr.copy(). a.obsm['spatial'] = arr.copy(). sc.pl.embedding(a, 'coords', edges=True, neighbors_key = 'spatial'). print('coords', a.obsm['coords']). sc.pl.embedding(a, 'spatial'). print('spatial no edges', a.obsm['spatial']). sc.pl.embedding(a, 'spatial', edges=True, neighbors_key = 'spatial'). print('spatial edges', a.obsm['spatial']). ```. produces following output:. - expected (when plotting ""coords""). ![image](https://user-images.githubusercontent.com/13350159/101187374-9206bd00-3654-11eb-9b7c-38b5870ab815.png). ```. coords [[96 55]. [95 54]. [96 54]. [97 54]. [95 55]. [97 55]. [95 56]. [96 56]. [97 56]]. ```. - when plotting ""spatial"" without edges (obsm is not modified). ![image](https://user-images.githubusercontent.com/13350159/101187899-40aafd80-3655-11eb-9738-9899efba9d52.png). ```. spatial no edges [[96 55]. [95 54]. [96 54]. [97 54]. [95 55]. [97 55]. [95 56]. [96 56]. [97 56]]. ```. - when plotting ""spatial"" with edges (obsm is modified). ![image](https://user-images.githubusercontent.com/13350159/101187963-5ae4db80-3655-11eb-9866-6824831b18a9.png). ```. spatial edges [[ 96 255]. [ 95 254]. [ 96 254]. [ 97 254]. [ 95 255]. [ 97 255]. [ 95 0]. [ 96 0]. [ 97 0]]. ```. #### Versions. <details>. scanpy==1.6.1.dev70+g7f15d22d anndata==0.7.5 umap==0.4.6 numpy==1.19.4 scipy==1.5.3 pandas==1.1.4 scikit-learn==0.23.2 statsmodels==0.12.1 python-igraph==0.8.3 louvain==0.6.1 leidenalg==0.8.3. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1534
https://github.com/scverse/scanpy/issues/1534:210,modifiability,version,version,210,"sc.pl.embedding with basis ""spatial"" has side-effects and is missing one row of points ; - [x] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. sc.pl.embedding with basis ""spatial"" behaves strangely. See code example below. . - when ""spatial"" is an `unit` array, the resulting plot is missing the top row of points (I think there might be an overflow happening). - when plotting edges and using basis ""spatial"", `adata.obsm[""spatial""] is modified after calling `sc.pl.embedding`. @giovp . ### Minimal code sample (that we can copy&paste without having any data). ```python. import numpy as np. import anndata as ad. import scanpy as sc. import matplotlib.pyplot as plt. print(sc.__version__). arr = np.array([[1888, 55],. [1887, 54],. [1888, 54],. [1889, 54],. [1887, 55],. [1889, 55],. [1887, 56],. [1888, 56],. [1889, 56]], dtype=np.uint8). conn = np.array([[0., 1., 1., 1., 1., 1., 1., 1., 1.],. [1., 0., 1., 0., 1., 0., 0., 0., 0.],. [1., 1., 0., 1., 1., 1., 0., 0., 0.],. [1., 0., 1., 0., 0., 1., 0., 0., 0.],. [1., 1., 1., 0., 0., 0., 1., 1., 0.],. [1., 0., 1., 1., 0., 0., 0., 1., 1.],. [1., 0., 0., 0., 1., 0., 0., 1., 0.],. [1., 0., 0., 0., 1., 1., 1., 0., 1.],. [1., 0., 0., 0., 0., 1., 0., 1., 0.]]). a = ad.AnnData(arr). a.uns = {'spatial': {'connectivities_key': 'spatial_connectivities', 'distances_key': 'spatial_distances', 'params': {'n_neighbors': 8, 'coord_type': None, 'radius': 1.5}}}. a.obsp['spatial_connectivities'] = conn. a.obsm['coords'] = arr.copy(). a.obsm['spatial'] = arr.copy(). sc.pl.embedding(a, 'coords', edges=True, neighbors_key = 'spatial'). print('coords', a.obsm['coords']). sc.pl.embedding(a, 'spatial'). print('spatial no edges', a.obsm['spatial']). sc.pl.embedding(a, 'spatial', edges=True, neighbors_key = 'spatial'). print('spatial edges', a.obsm['spatial']). ```. produces following",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1534
https://github.com/scverse/scanpy/issues/1534:2841,modifiability,Version,Versions,2841,".],. [1., 0., 1., 0., 1., 0., 0., 0., 0.],. [1., 1., 0., 1., 1., 1., 0., 0., 0.],. [1., 0., 1., 0., 0., 1., 0., 0., 0.],. [1., 1., 1., 0., 0., 0., 1., 1., 0.],. [1., 0., 1., 1., 0., 0., 0., 1., 1.],. [1., 0., 0., 0., 1., 0., 0., 1., 0.],. [1., 0., 0., 0., 1., 1., 1., 0., 1.],. [1., 0., 0., 0., 0., 1., 0., 1., 0.]]). a = ad.AnnData(arr). a.uns = {'spatial': {'connectivities_key': 'spatial_connectivities', 'distances_key': 'spatial_distances', 'params': {'n_neighbors': 8, 'coord_type': None, 'radius': 1.5}}}. a.obsp['spatial_connectivities'] = conn. a.obsm['coords'] = arr.copy(). a.obsm['spatial'] = arr.copy(). sc.pl.embedding(a, 'coords', edges=True, neighbors_key = 'spatial'). print('coords', a.obsm['coords']). sc.pl.embedding(a, 'spatial'). print('spatial no edges', a.obsm['spatial']). sc.pl.embedding(a, 'spatial', edges=True, neighbors_key = 'spatial'). print('spatial edges', a.obsm['spatial']). ```. produces following output:. - expected (when plotting ""coords""). ![image](https://user-images.githubusercontent.com/13350159/101187374-9206bd00-3654-11eb-9b7c-38b5870ab815.png). ```. coords [[96 55]. [95 54]. [96 54]. [97 54]. [95 55]. [97 55]. [95 56]. [96 56]. [97 56]]. ```. - when plotting ""spatial"" without edges (obsm is not modified). ![image](https://user-images.githubusercontent.com/13350159/101187899-40aafd80-3655-11eb-9738-9899efba9d52.png). ```. spatial no edges [[96 55]. [95 54]. [96 54]. [97 54]. [95 55]. [97 55]. [95 56]. [96 56]. [97 56]]. ```. - when plotting ""spatial"" with edges (obsm is modified). ![image](https://user-images.githubusercontent.com/13350159/101187963-5ae4db80-3655-11eb-9866-6824831b18a9.png). ```. spatial edges [[ 96 255]. [ 95 254]. [ 96 254]. [ 97 254]. [ 95 255]. [ 97 255]. [ 95 0]. [ 96 0]. [ 97 0]]. ```. #### Versions. <details>. scanpy==1.6.1.dev70+g7f15d22d anndata==0.7.5 umap==0.4.6 numpy==1.19.4 scipy==1.5.3 pandas==1.1.4 scikit-learn==0.23.2 statsmodels==0.12.1 python-igraph==0.8.3 louvain==0.6.1 leidenalg==0.8.3. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1534
https://github.com/scverse/scanpy/issues/1534:610,security,modif,modified,610,"sc.pl.embedding with basis ""spatial"" has side-effects and is missing one row of points ; - [x] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. sc.pl.embedding with basis ""spatial"" behaves strangely. See code example below. . - when ""spatial"" is an `unit` array, the resulting plot is missing the top row of points (I think there might be an overflow happening). - when plotting edges and using basis ""spatial"", `adata.obsm[""spatial""] is modified after calling `sc.pl.embedding`. @giovp . ### Minimal code sample (that we can copy&paste without having any data). ```python. import numpy as np. import anndata as ad. import scanpy as sc. import matplotlib.pyplot as plt. print(sc.__version__). arr = np.array([[1888, 55],. [1887, 54],. [1888, 54],. [1889, 54],. [1887, 55],. [1889, 55],. [1887, 56],. [1888, 56],. [1889, 56]], dtype=np.uint8). conn = np.array([[0., 1., 1., 1., 1., 1., 1., 1., 1.],. [1., 0., 1., 0., 1., 0., 0., 0., 0.],. [1., 1., 0., 1., 1., 1., 0., 0., 0.],. [1., 0., 1., 0., 0., 1., 0., 0., 0.],. [1., 1., 1., 0., 0., 0., 1., 1., 0.],. [1., 0., 1., 1., 0., 0., 0., 1., 1.],. [1., 0., 0., 0., 1., 0., 0., 1., 0.],. [1., 0., 0., 0., 1., 1., 1., 0., 1.],. [1., 0., 0., 0., 0., 1., 0., 1., 0.]]). a = ad.AnnData(arr). a.uns = {'spatial': {'connectivities_key': 'spatial_connectivities', 'distances_key': 'spatial_distances', 'params': {'n_neighbors': 8, 'coord_type': None, 'radius': 1.5}}}. a.obsp['spatial_connectivities'] = conn. a.obsm['coords'] = arr.copy(). a.obsm['spatial'] = arr.copy(). sc.pl.embedding(a, 'coords', edges=True, neighbors_key = 'spatial'). print('coords', a.obsm['coords']). sc.pl.embedding(a, 'spatial'). print('spatial no edges', a.obsm['spatial']). sc.pl.embedding(a, 'spatial', edges=True, neighbors_key = 'spatial'). print('spatial edges', a.obsm['spatial']). ```. produces following",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1534
https://github.com/scverse/scanpy/issues/1534:2313,security,modif,modified,2313,".],. [1., 0., 1., 0., 1., 0., 0., 0., 0.],. [1., 1., 0., 1., 1., 1., 0., 0., 0.],. [1., 0., 1., 0., 0., 1., 0., 0., 0.],. [1., 1., 1., 0., 0., 0., 1., 1., 0.],. [1., 0., 1., 1., 0., 0., 0., 1., 1.],. [1., 0., 0., 0., 1., 0., 0., 1., 0.],. [1., 0., 0., 0., 1., 1., 1., 0., 1.],. [1., 0., 0., 0., 0., 1., 0., 1., 0.]]). a = ad.AnnData(arr). a.uns = {'spatial': {'connectivities_key': 'spatial_connectivities', 'distances_key': 'spatial_distances', 'params': {'n_neighbors': 8, 'coord_type': None, 'radius': 1.5}}}. a.obsp['spatial_connectivities'] = conn. a.obsm['coords'] = arr.copy(). a.obsm['spatial'] = arr.copy(). sc.pl.embedding(a, 'coords', edges=True, neighbors_key = 'spatial'). print('coords', a.obsm['coords']). sc.pl.embedding(a, 'spatial'). print('spatial no edges', a.obsm['spatial']). sc.pl.embedding(a, 'spatial', edges=True, neighbors_key = 'spatial'). print('spatial edges', a.obsm['spatial']). ```. produces following output:. - expected (when plotting ""coords""). ![image](https://user-images.githubusercontent.com/13350159/101187374-9206bd00-3654-11eb-9b7c-38b5870ab815.png). ```. coords [[96 55]. [95 54]. [96 54]. [97 54]. [95 55]. [97 55]. [95 56]. [96 56]. [97 56]]. ```. - when plotting ""spatial"" without edges (obsm is not modified). ![image](https://user-images.githubusercontent.com/13350159/101187899-40aafd80-3655-11eb-9738-9899efba9d52.png). ```. spatial no edges [[96 55]. [95 54]. [96 54]. [97 54]. [95 55]. [97 55]. [95 56]. [96 56]. [97 56]]. ```. - when plotting ""spatial"" with edges (obsm is modified). ![image](https://user-images.githubusercontent.com/13350159/101187963-5ae4db80-3655-11eb-9866-6824831b18a9.png). ```. spatial edges [[ 96 255]. [ 95 254]. [ 96 254]. [ 97 254]. [ 95 255]. [ 97 255]. [ 95 0]. [ 96 0]. [ 97 0]]. ```. #### Versions. <details>. scanpy==1.6.1.dev70+g7f15d22d anndata==0.7.5 umap==0.4.6 numpy==1.19.4 scipy==1.5.3 pandas==1.1.4 scikit-learn==0.23.2 statsmodels==0.12.1 python-igraph==0.8.3 louvain==0.6.1 leidenalg==0.8.3. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1534
https://github.com/scverse/scanpy/issues/1534:2593,security,modif,modified,2593,".],. [1., 0., 1., 0., 1., 0., 0., 0., 0.],. [1., 1., 0., 1., 1., 1., 0., 0., 0.],. [1., 0., 1., 0., 0., 1., 0., 0., 0.],. [1., 1., 1., 0., 0., 0., 1., 1., 0.],. [1., 0., 1., 1., 0., 0., 0., 1., 1.],. [1., 0., 0., 0., 1., 0., 0., 1., 0.],. [1., 0., 0., 0., 1., 1., 1., 0., 1.],. [1., 0., 0., 0., 0., 1., 0., 1., 0.]]). a = ad.AnnData(arr). a.uns = {'spatial': {'connectivities_key': 'spatial_connectivities', 'distances_key': 'spatial_distances', 'params': {'n_neighbors': 8, 'coord_type': None, 'radius': 1.5}}}. a.obsp['spatial_connectivities'] = conn. a.obsm['coords'] = arr.copy(). a.obsm['spatial'] = arr.copy(). sc.pl.embedding(a, 'coords', edges=True, neighbors_key = 'spatial'). print('coords', a.obsm['coords']). sc.pl.embedding(a, 'spatial'). print('spatial no edges', a.obsm['spatial']). sc.pl.embedding(a, 'spatial', edges=True, neighbors_key = 'spatial'). print('spatial edges', a.obsm['spatial']). ```. produces following output:. - expected (when plotting ""coords""). ![image](https://user-images.githubusercontent.com/13350159/101187374-9206bd00-3654-11eb-9b7c-38b5870ab815.png). ```. coords [[96 55]. [95 54]. [96 54]. [97 54]. [95 55]. [97 55]. [95 56]. [96 56]. [97 56]]. ```. - when plotting ""spatial"" without edges (obsm is not modified). ![image](https://user-images.githubusercontent.com/13350159/101187899-40aafd80-3655-11eb-9738-9899efba9d52.png). ```. spatial no edges [[96 55]. [95 54]. [96 54]. [97 54]. [95 55]. [97 55]. [95 56]. [96 56]. [97 56]]. ```. - when plotting ""spatial"" with edges (obsm is modified). ![image](https://user-images.githubusercontent.com/13350159/101187963-5ae4db80-3655-11eb-9866-6824831b18a9.png). ```. spatial edges [[ 96 255]. [ 95 254]. [ 96 254]. [ 97 254]. [ 95 255]. [ 97 255]. [ 95 0]. [ 96 0]. [ 97 0]]. ```. #### Versions. <details>. scanpy==1.6.1.dev70+g7f15d22d anndata==0.7.5 umap==0.4.6 numpy==1.19.4 scipy==1.5.3 pandas==1.1.4 scikit-learn==0.23.2 statsmodels==0.12.1 python-igraph==0.8.3 louvain==0.6.1 leidenalg==0.8.3. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1534
https://github.com/scverse/scanpy/issues/1534:422,testability,unit,unit,422,"sc.pl.embedding with basis ""spatial"" has side-effects and is missing one row of points ; - [x] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. sc.pl.embedding with basis ""spatial"" behaves strangely. See code example below. . - when ""spatial"" is an `unit` array, the resulting plot is missing the top row of points (I think there might be an overflow happening). - when plotting edges and using basis ""spatial"", `adata.obsm[""spatial""] is modified after calling `sc.pl.embedding`. @giovp . ### Minimal code sample (that we can copy&paste without having any data). ```python. import numpy as np. import anndata as ad. import scanpy as sc. import matplotlib.pyplot as plt. print(sc.__version__). arr = np.array([[1888, 55],. [1887, 54],. [1888, 54],. [1889, 54],. [1887, 55],. [1889, 55],. [1887, 56],. [1888, 56],. [1889, 56]], dtype=np.uint8). conn = np.array([[0., 1., 1., 1., 1., 1., 1., 1., 1.],. [1., 0., 1., 0., 1., 0., 0., 0., 0.],. [1., 1., 0., 1., 1., 1., 0., 0., 0.],. [1., 0., 1., 0., 0., 1., 0., 0., 0.],. [1., 1., 1., 0., 0., 0., 1., 1., 0.],. [1., 0., 1., 1., 0., 0., 0., 1., 1.],. [1., 0., 0., 0., 1., 0., 0., 1., 0.],. [1., 0., 0., 0., 1., 1., 1., 0., 1.],. [1., 0., 0., 0., 0., 1., 0., 1., 0.]]). a = ad.AnnData(arr). a.uns = {'spatial': {'connectivities_key': 'spatial_connectivities', 'distances_key': 'spatial_distances', 'params': {'n_neighbors': 8, 'coord_type': None, 'radius': 1.5}}}. a.obsp['spatial_connectivities'] = conn. a.obsm['coords'] = arr.copy(). a.obsm['spatial'] = arr.copy(). sc.pl.embedding(a, 'coords', edges=True, neighbors_key = 'spatial'). print('coords', a.obsm['coords']). sc.pl.embedding(a, 'spatial'). print('spatial no edges', a.obsm['spatial']). sc.pl.embedding(a, 'spatial', edges=True, neighbors_key = 'spatial'). print('spatial edges', a.obsm['spatial']). ```. produces following",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1534
https://github.com/scverse/scanpy/issues/1534:170,usability,confirm,confirmed,170,"sc.pl.embedding with basis ""spatial"" has side-effects and is missing one row of points ; - [x] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. sc.pl.embedding with basis ""spatial"" behaves strangely. See code example below. . - when ""spatial"" is an `unit` array, the resulting plot is missing the top row of points (I think there might be an overflow happening). - when plotting edges and using basis ""spatial"", `adata.obsm[""spatial""] is modified after calling `sc.pl.embedding`. @giovp . ### Minimal code sample (that we can copy&paste without having any data). ```python. import numpy as np. import anndata as ad. import scanpy as sc. import matplotlib.pyplot as plt. print(sc.__version__). arr = np.array([[1888, 55],. [1887, 54],. [1888, 54],. [1889, 54],. [1887, 55],. [1889, 55],. [1887, 56],. [1888, 56],. [1889, 56]], dtype=np.uint8). conn = np.array([[0., 1., 1., 1., 1., 1., 1., 1., 1.],. [1., 0., 1., 0., 1., 0., 0., 0., 0.],. [1., 1., 0., 1., 1., 1., 0., 0., 0.],. [1., 0., 1., 0., 0., 1., 0., 0., 0.],. [1., 1., 1., 0., 0., 0., 1., 1., 0.],. [1., 0., 1., 1., 0., 0., 0., 1., 1.],. [1., 0., 0., 0., 1., 0., 0., 1., 0.],. [1., 0., 0., 0., 1., 1., 1., 0., 1.],. [1., 0., 0., 0., 0., 1., 0., 1., 0.]]). a = ad.AnnData(arr). a.uns = {'spatial': {'connectivities_key': 'spatial_connectivities', 'distances_key': 'spatial_distances', 'params': {'n_neighbors': 8, 'coord_type': None, 'radius': 1.5}}}. a.obsp['spatial_connectivities'] = conn. a.obsm['coords'] = arr.copy(). a.obsm['spatial'] = arr.copy(). sc.pl.embedding(a, 'coords', edges=True, neighbors_key = 'spatial'). print('coords', a.obsm['coords']). sc.pl.embedding(a, 'spatial'). print('spatial no edges', a.obsm['spatial']). sc.pl.embedding(a, 'spatial', edges=True, neighbors_key = 'spatial'). print('spatial edges', a.obsm['spatial']). ```. produces following",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1534
https://github.com/scverse/scanpy/issues/1534:253,usability,confirm,confirmed,253,"sc.pl.embedding with basis ""spatial"" has side-effects and is missing one row of points ; - [x] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. sc.pl.embedding with basis ""spatial"" behaves strangely. See code example below. . - when ""spatial"" is an `unit` array, the resulting plot is missing the top row of points (I think there might be an overflow happening). - when plotting edges and using basis ""spatial"", `adata.obsm[""spatial""] is modified after calling `sc.pl.embedding`. @giovp . ### Minimal code sample (that we can copy&paste without having any data). ```python. import numpy as np. import anndata as ad. import scanpy as sc. import matplotlib.pyplot as plt. print(sc.__version__). arr = np.array([[1888, 55],. [1887, 54],. [1888, 54],. [1889, 54],. [1887, 55],. [1889, 55],. [1887, 56],. [1888, 56],. [1889, 56]], dtype=np.uint8). conn = np.array([[0., 1., 1., 1., 1., 1., 1., 1., 1.],. [1., 0., 1., 0., 1., 0., 0., 0., 0.],. [1., 1., 0., 1., 1., 1., 0., 0., 0.],. [1., 0., 1., 0., 0., 1., 0., 0., 0.],. [1., 1., 1., 0., 0., 0., 1., 1., 0.],. [1., 0., 1., 1., 0., 0., 0., 1., 1.],. [1., 0., 0., 0., 1., 0., 0., 1., 0.],. [1., 0., 0., 0., 1., 1., 1., 0., 1.],. [1., 0., 0., 0., 0., 1., 0., 1., 0.]]). a = ad.AnnData(arr). a.uns = {'spatial': {'connectivities_key': 'spatial_connectivities', 'distances_key': 'spatial_distances', 'params': {'n_neighbors': 8, 'coord_type': None, 'radius': 1.5}}}. a.obsp['spatial_connectivities'] = conn. a.obsm['coords'] = arr.copy(). a.obsm['spatial'] = arr.copy(). sc.pl.embedding(a, 'coords', edges=True, neighbors_key = 'spatial'). print('coords', a.obsm['coords']). sc.pl.embedding(a, 'spatial'). print('spatial no edges', a.obsm['spatial']). sc.pl.embedding(a, 'spatial', edges=True, neighbors_key = 'spatial'). print('spatial edges', a.obsm['spatial']). ```. produces following",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1534
https://github.com/scverse/scanpy/issues/1534:665,usability,Minim,Minimal,665,"sc.pl.embedding with basis ""spatial"" has side-effects and is missing one row of points ; - [x] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. sc.pl.embedding with basis ""spatial"" behaves strangely. See code example below. . - when ""spatial"" is an `unit` array, the resulting plot is missing the top row of points (I think there might be an overflow happening). - when plotting edges and using basis ""spatial"", `adata.obsm[""spatial""] is modified after calling `sc.pl.embedding`. @giovp . ### Minimal code sample (that we can copy&paste without having any data). ```python. import numpy as np. import anndata as ad. import scanpy as sc. import matplotlib.pyplot as plt. print(sc.__version__). arr = np.array([[1888, 55],. [1887, 54],. [1888, 54],. [1889, 54],. [1887, 55],. [1889, 55],. [1887, 56],. [1888, 56],. [1889, 56]], dtype=np.uint8). conn = np.array([[0., 1., 1., 1., 1., 1., 1., 1., 1.],. [1., 0., 1., 0., 1., 0., 0., 0., 0.],. [1., 1., 0., 1., 1., 1., 0., 0., 0.],. [1., 0., 1., 0., 0., 1., 0., 0., 0.],. [1., 1., 1., 0., 0., 0., 1., 1., 0.],. [1., 0., 1., 1., 0., 0., 0., 1., 1.],. [1., 0., 0., 0., 1., 0., 0., 1., 0.],. [1., 0., 0., 0., 1., 1., 1., 0., 1.],. [1., 0., 0., 0., 0., 1., 0., 1., 0.]]). a = ad.AnnData(arr). a.uns = {'spatial': {'connectivities_key': 'spatial_connectivities', 'distances_key': 'spatial_distances', 'params': {'n_neighbors': 8, 'coord_type': None, 'radius': 1.5}}}. a.obsp['spatial_connectivities'] = conn. a.obsm['coords'] = arr.copy(). a.obsm['spatial'] = arr.copy(). sc.pl.embedding(a, 'coords', edges=True, neighbors_key = 'spatial'). print('coords', a.obsm['coords']). sc.pl.embedding(a, 'spatial'). print('spatial no edges', a.obsm['spatial']). sc.pl.embedding(a, 'spatial', edges=True, neighbors_key = 'spatial'). print('spatial edges', a.obsm['spatial']). ```. produces following",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1534
https://github.com/scverse/scanpy/issues/1534:2064,usability,user,user-images,2064,".],. [1., 0., 1., 0., 1., 0., 0., 0., 0.],. [1., 1., 0., 1., 1., 1., 0., 0., 0.],. [1., 0., 1., 0., 0., 1., 0., 0., 0.],. [1., 1., 1., 0., 0., 0., 1., 1., 0.],. [1., 0., 1., 1., 0., 0., 0., 1., 1.],. [1., 0., 0., 0., 1., 0., 0., 1., 0.],. [1., 0., 0., 0., 1., 1., 1., 0., 1.],. [1., 0., 0., 0., 0., 1., 0., 1., 0.]]). a = ad.AnnData(arr). a.uns = {'spatial': {'connectivities_key': 'spatial_connectivities', 'distances_key': 'spatial_distances', 'params': {'n_neighbors': 8, 'coord_type': None, 'radius': 1.5}}}. a.obsp['spatial_connectivities'] = conn. a.obsm['coords'] = arr.copy(). a.obsm['spatial'] = arr.copy(). sc.pl.embedding(a, 'coords', edges=True, neighbors_key = 'spatial'). print('coords', a.obsm['coords']). sc.pl.embedding(a, 'spatial'). print('spatial no edges', a.obsm['spatial']). sc.pl.embedding(a, 'spatial', edges=True, neighbors_key = 'spatial'). print('spatial edges', a.obsm['spatial']). ```. produces following output:. - expected (when plotting ""coords""). ![image](https://user-images.githubusercontent.com/13350159/101187374-9206bd00-3654-11eb-9b7c-38b5870ab815.png). ```. coords [[96 55]. [95 54]. [96 54]. [97 54]. [95 55]. [97 55]. [95 56]. [96 56]. [97 56]]. ```. - when plotting ""spatial"" without edges (obsm is not modified). ![image](https://user-images.githubusercontent.com/13350159/101187899-40aafd80-3655-11eb-9738-9899efba9d52.png). ```. spatial no edges [[96 55]. [95 54]. [96 54]. [97 54]. [95 55]. [97 55]. [95 56]. [96 56]. [97 56]]. ```. - when plotting ""spatial"" with edges (obsm is modified). ![image](https://user-images.githubusercontent.com/13350159/101187963-5ae4db80-3655-11eb-9866-6824831b18a9.png). ```. spatial edges [[ 96 255]. [ 95 254]. [ 96 254]. [ 97 254]. [ 95 255]. [ 97 255]. [ 95 0]. [ 96 0]. [ 97 0]]. ```. #### Versions. <details>. scanpy==1.6.1.dev70+g7f15d22d anndata==0.7.5 umap==0.4.6 numpy==1.19.4 scipy==1.5.3 pandas==1.1.4 scikit-learn==0.23.2 statsmodels==0.12.1 python-igraph==0.8.3 louvain==0.6.1 leidenalg==0.8.3. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1534
https://github.com/scverse/scanpy/issues/1534:2341,usability,user,user-images,2341,".],. [1., 0., 1., 0., 1., 0., 0., 0., 0.],. [1., 1., 0., 1., 1., 1., 0., 0., 0.],. [1., 0., 1., 0., 0., 1., 0., 0., 0.],. [1., 1., 1., 0., 0., 0., 1., 1., 0.],. [1., 0., 1., 1., 0., 0., 0., 1., 1.],. [1., 0., 0., 0., 1., 0., 0., 1., 0.],. [1., 0., 0., 0., 1., 1., 1., 0., 1.],. [1., 0., 0., 0., 0., 1., 0., 1., 0.]]). a = ad.AnnData(arr). a.uns = {'spatial': {'connectivities_key': 'spatial_connectivities', 'distances_key': 'spatial_distances', 'params': {'n_neighbors': 8, 'coord_type': None, 'radius': 1.5}}}. a.obsp['spatial_connectivities'] = conn. a.obsm['coords'] = arr.copy(). a.obsm['spatial'] = arr.copy(). sc.pl.embedding(a, 'coords', edges=True, neighbors_key = 'spatial'). print('coords', a.obsm['coords']). sc.pl.embedding(a, 'spatial'). print('spatial no edges', a.obsm['spatial']). sc.pl.embedding(a, 'spatial', edges=True, neighbors_key = 'spatial'). print('spatial edges', a.obsm['spatial']). ```. produces following output:. - expected (when plotting ""coords""). ![image](https://user-images.githubusercontent.com/13350159/101187374-9206bd00-3654-11eb-9b7c-38b5870ab815.png). ```. coords [[96 55]. [95 54]. [96 54]. [97 54]. [95 55]. [97 55]. [95 56]. [96 56]. [97 56]]. ```. - when plotting ""spatial"" without edges (obsm is not modified). ![image](https://user-images.githubusercontent.com/13350159/101187899-40aafd80-3655-11eb-9738-9899efba9d52.png). ```. spatial no edges [[96 55]. [95 54]. [96 54]. [97 54]. [95 55]. [97 55]. [95 56]. [96 56]. [97 56]]. ```. - when plotting ""spatial"" with edges (obsm is modified). ![image](https://user-images.githubusercontent.com/13350159/101187963-5ae4db80-3655-11eb-9866-6824831b18a9.png). ```. spatial edges [[ 96 255]. [ 95 254]. [ 96 254]. [ 97 254]. [ 95 255]. [ 97 255]. [ 95 0]. [ 96 0]. [ 97 0]]. ```. #### Versions. <details>. scanpy==1.6.1.dev70+g7f15d22d anndata==0.7.5 umap==0.4.6 numpy==1.19.4 scipy==1.5.3 pandas==1.1.4 scikit-learn==0.23.2 statsmodels==0.12.1 python-igraph==0.8.3 louvain==0.6.1 leidenalg==0.8.3. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1534
https://github.com/scverse/scanpy/issues/1534:2621,usability,user,user-images,2621,".],. [1., 0., 1., 0., 1., 0., 0., 0., 0.],. [1., 1., 0., 1., 1., 1., 0., 0., 0.],. [1., 0., 1., 0., 0., 1., 0., 0., 0.],. [1., 1., 1., 0., 0., 0., 1., 1., 0.],. [1., 0., 1., 1., 0., 0., 0., 1., 1.],. [1., 0., 0., 0., 1., 0., 0., 1., 0.],. [1., 0., 0., 0., 1., 1., 1., 0., 1.],. [1., 0., 0., 0., 0., 1., 0., 1., 0.]]). a = ad.AnnData(arr). a.uns = {'spatial': {'connectivities_key': 'spatial_connectivities', 'distances_key': 'spatial_distances', 'params': {'n_neighbors': 8, 'coord_type': None, 'radius': 1.5}}}. a.obsp['spatial_connectivities'] = conn. a.obsm['coords'] = arr.copy(). a.obsm['spatial'] = arr.copy(). sc.pl.embedding(a, 'coords', edges=True, neighbors_key = 'spatial'). print('coords', a.obsm['coords']). sc.pl.embedding(a, 'spatial'). print('spatial no edges', a.obsm['spatial']). sc.pl.embedding(a, 'spatial', edges=True, neighbors_key = 'spatial'). print('spatial edges', a.obsm['spatial']). ```. produces following output:. - expected (when plotting ""coords""). ![image](https://user-images.githubusercontent.com/13350159/101187374-9206bd00-3654-11eb-9b7c-38b5870ab815.png). ```. coords [[96 55]. [95 54]. [96 54]. [97 54]. [95 55]. [97 55]. [95 56]. [96 56]. [97 56]]. ```. - when plotting ""spatial"" without edges (obsm is not modified). ![image](https://user-images.githubusercontent.com/13350159/101187899-40aafd80-3655-11eb-9738-9899efba9d52.png). ```. spatial no edges [[96 55]. [95 54]. [96 54]. [97 54]. [95 55]. [97 55]. [95 56]. [96 56]. [97 56]]. ```. - when plotting ""spatial"" with edges (obsm is modified). ![image](https://user-images.githubusercontent.com/13350159/101187963-5ae4db80-3655-11eb-9866-6824831b18a9.png). ```. spatial edges [[ 96 255]. [ 95 254]. [ 96 254]. [ 97 254]. [ 95 255]. [ 97 255]. [ 95 0]. [ 96 0]. [ 97 0]]. ```. #### Versions. <details>. scanpy==1.6.1.dev70+g7f15d22d anndata==0.7.5 umap==0.4.6 numpy==1.19.4 scipy==1.5.3 pandas==1.1.4 scikit-learn==0.23.2 statsmodels==0.12.1 python-igraph==0.8.3 louvain==0.6.1 leidenalg==0.8.3. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1534
https://github.com/scverse/scanpy/issues/1534:2967,usability,learn,learn,2967,".],. [1., 0., 1., 0., 1., 0., 0., 0., 0.],. [1., 1., 0., 1., 1., 1., 0., 0., 0.],. [1., 0., 1., 0., 0., 1., 0., 0., 0.],. [1., 1., 1., 0., 0., 0., 1., 1., 0.],. [1., 0., 1., 1., 0., 0., 0., 1., 1.],. [1., 0., 0., 0., 1., 0., 0., 1., 0.],. [1., 0., 0., 0., 1., 1., 1., 0., 1.],. [1., 0., 0., 0., 0., 1., 0., 1., 0.]]). a = ad.AnnData(arr). a.uns = {'spatial': {'connectivities_key': 'spatial_connectivities', 'distances_key': 'spatial_distances', 'params': {'n_neighbors': 8, 'coord_type': None, 'radius': 1.5}}}. a.obsp['spatial_connectivities'] = conn. a.obsm['coords'] = arr.copy(). a.obsm['spatial'] = arr.copy(). sc.pl.embedding(a, 'coords', edges=True, neighbors_key = 'spatial'). print('coords', a.obsm['coords']). sc.pl.embedding(a, 'spatial'). print('spatial no edges', a.obsm['spatial']). sc.pl.embedding(a, 'spatial', edges=True, neighbors_key = 'spatial'). print('spatial edges', a.obsm['spatial']). ```. produces following output:. - expected (when plotting ""coords""). ![image](https://user-images.githubusercontent.com/13350159/101187374-9206bd00-3654-11eb-9b7c-38b5870ab815.png). ```. coords [[96 55]. [95 54]. [96 54]. [97 54]. [95 55]. [97 55]. [95 56]. [96 56]. [97 56]]. ```. - when plotting ""spatial"" without edges (obsm is not modified). ![image](https://user-images.githubusercontent.com/13350159/101187899-40aafd80-3655-11eb-9738-9899efba9d52.png). ```. spatial no edges [[96 55]. [95 54]. [96 54]. [97 54]. [95 55]. [97 55]. [95 56]. [96 56]. [97 56]]. ```. - when plotting ""spatial"" with edges (obsm is modified). ![image](https://user-images.githubusercontent.com/13350159/101187963-5ae4db80-3655-11eb-9866-6824831b18a9.png). ```. spatial edges [[ 96 255]. [ 95 254]. [ 96 254]. [ 97 254]. [ 95 255]. [ 97 255]. [ 95 0]. [ 96 0]. [ 97 0]]. ```. #### Versions. <details>. scanpy==1.6.1.dev70+g7f15d22d anndata==0.7.5 umap==0.4.6 numpy==1.19.4 scipy==1.5.3 pandas==1.1.4 scikit-learn==0.23.2 statsmodels==0.12.1 python-igraph==0.8.3 louvain==0.6.1 leidenalg==0.8.3. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1534
https://github.com/scverse/scanpy/pull/1535:28,safety,test,test-backports,28,Backport PR #1384 on branch test-backports (Fix values_to_plot literal); Backport PR #1384: Fix values_to_plot literal,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1535
https://github.com/scverse/scanpy/pull/1535:28,testability,test,test-backports,28,Backport PR #1384 on branch test-backports (Fix values_to_plot literal); Backport PR #1384: Fix values_to_plot literal,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1535
https://github.com/scverse/scanpy/pull/1536:24,availability,error,error,24,Try continuing on black error;,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1536
https://github.com/scverse/scanpy/pull/1536:4,deployability,continu,continuing,4,Try continuing on black error;,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1536
https://github.com/scverse/scanpy/pull/1536:24,performance,error,error,24,Try continuing on black error;,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1536
https://github.com/scverse/scanpy/pull/1536:24,safety,error,error,24,Try continuing on black error;,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1536
https://github.com/scverse/scanpy/pull/1536:24,usability,error,error,24,Try continuing on black error;,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1536
https://github.com/scverse/scanpy/pull/1538:103,availability,consist,consists,103,"Simplify embeddings a bit; Some effort to simplify how the embedding plots are handled. Right now this consists of simplifying the `components` argument to `dimensions`. Dimensions is a list of collections of ints. Each element in this list has the length of the number of dimensions to be plotted. `components` is no longer used once it can be transformed into dimensions. What does this do? * Let's us delete `_get_data_points`, an awful function. * Get rid of `data_points` a list of coordinates that most code assumed would only ever have one element. * Move spatial specific code to spatial specific functions. * Gets rid of edge cases where `components` was either `None` or `[None]` (not sure how). Side note, also made a modification to a testing fixture that had been making tests fail when run out of order. ## Some questions:. ### Should `dimensions` be exposed? If so, should `components` be deprecated? I think it's weird to pass the dimensions as strings `""1,2""` as opposed to dimensions `(0, 1)`. * Why is it one indexed? * Isn't it the same amount of keystrokes? * How useful is `""all""`? I also think it's weird that the amount of plots generated is the product of `components` and `color`. This differs from every other ""vectorized"" argument to `embedding`. Changing arguments and deprecating `components` would be an opportunity to change this. ### If dimensions should be exposed, how many places does this need to be implemented? We use `components` as an argument in a number of places in the codebase. Should we think about doing a large-scale replacement? ### I broke a plotting test. I can't tell the difference. @giovp, does this look fine to you? It's the spatial plots with no image. <details>. <summary> </summary>. Expected. ![master_spatial_visium_empty_image](https://user-images.githubusercontent.com/8238804/101748159-4f475800-3b20-11eb-9007-5a987a881828.png). Actual. ![master_spatial_visium_empty_image](https://user-images.githubusercontent.com/8238804/101748219-6",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1538
https://github.com/scverse/scanpy/pull/1538:790,deployability,fail,fail,790,"Simplify embeddings a bit; Some effort to simplify how the embedding plots are handled. Right now this consists of simplifying the `components` argument to `dimensions`. Dimensions is a list of collections of ints. Each element in this list has the length of the number of dimensions to be plotted. `components` is no longer used once it can be transformed into dimensions. What does this do? * Let's us delete `_get_data_points`, an awful function. * Get rid of `data_points` a list of coordinates that most code assumed would only ever have one element. * Move spatial specific code to spatial specific functions. * Gets rid of edge cases where `components` was either `None` or `[None]` (not sure how). Side note, also made a modification to a testing fixture that had been making tests fail when run out of order. ## Some questions:. ### Should `dimensions` be exposed? If so, should `components` be deprecated? I think it's weird to pass the dimensions as strings `""1,2""` as opposed to dimensions `(0, 1)`. * Why is it one indexed? * Isn't it the same amount of keystrokes? * How useful is `""all""`? I also think it's weird that the amount of plots generated is the product of `components` and `color`. This differs from every other ""vectorized"" argument to `embedding`. Changing arguments and deprecating `components` would be an opportunity to change this. ### If dimensions should be exposed, how many places does this need to be implemented? We use `components` as an argument in a number of places in the codebase. Should we think about doing a large-scale replacement? ### I broke a plotting test. I can't tell the difference. @giovp, does this look fine to you? It's the spatial plots with no image. <details>. <summary> </summary>. Expected. ![master_spatial_visium_empty_image](https://user-images.githubusercontent.com/8238804/101748159-4f475800-3b20-11eb-9007-5a987a881828.png). Actual. ![master_spatial_visium_empty_image](https://user-images.githubusercontent.com/8238804/101748219-6",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1538
https://github.com/scverse/scanpy/pull/1538:1560,deployability,scale,scale,1560,". `components` is no longer used once it can be transformed into dimensions. What does this do? * Let's us delete `_get_data_points`, an awful function. * Get rid of `data_points` a list of coordinates that most code assumed would only ever have one element. * Move spatial specific code to spatial specific functions. * Gets rid of edge cases where `components` was either `None` or `[None]` (not sure how). Side note, also made a modification to a testing fixture that had been making tests fail when run out of order. ## Some questions:. ### Should `dimensions` be exposed? If so, should `components` be deprecated? I think it's weird to pass the dimensions as strings `""1,2""` as opposed to dimensions `(0, 1)`. * Why is it one indexed? * Isn't it the same amount of keystrokes? * How useful is `""all""`? I also think it's weird that the amount of plots generated is the product of `components` and `color`. This differs from every other ""vectorized"" argument to `embedding`. Changing arguments and deprecating `components` would be an opportunity to change this. ### If dimensions should be exposed, how many places does this need to be implemented? We use `components` as an argument in a number of places in the codebase. Should we think about doing a large-scale replacement? ### I broke a plotting test. I can't tell the difference. @giovp, does this look fine to you? It's the spatial plots with no image. <details>. <summary> </summary>. Expected. ![master_spatial_visium_empty_image](https://user-images.githubusercontent.com/8238804/101748159-4f475800-3b20-11eb-9007-5a987a881828.png). Actual. ![master_spatial_visium_empty_image](https://user-images.githubusercontent.com/8238804/101748219-64bc8200-3b20-11eb-9313-23c04a1c537f.png). Diff. ![master_spatial_visium_empty_image-failed-diff](https://user-images.githubusercontent.com/8238804/101748266-73a33480-3b20-11eb-9a92-2be5f45da300.png). </details>. TODO:. - [ ] Deprecate components repeated behaviour. - [x] Finalize `dimensions` arg",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1538
https://github.com/scverse/scanpy/pull/1538:2084,deployability,fail,failed-diff,2084,". `components` is no longer used once it can be transformed into dimensions. What does this do? * Let's us delete `_get_data_points`, an awful function. * Get rid of `data_points` a list of coordinates that most code assumed would only ever have one element. * Move spatial specific code to spatial specific functions. * Gets rid of edge cases where `components` was either `None` or `[None]` (not sure how). Side note, also made a modification to a testing fixture that had been making tests fail when run out of order. ## Some questions:. ### Should `dimensions` be exposed? If so, should `components` be deprecated? I think it's weird to pass the dimensions as strings `""1,2""` as opposed to dimensions `(0, 1)`. * Why is it one indexed? * Isn't it the same amount of keystrokes? * How useful is `""all""`? I also think it's weird that the amount of plots generated is the product of `components` and `color`. This differs from every other ""vectorized"" argument to `embedding`. Changing arguments and deprecating `components` would be an opportunity to change this. ### If dimensions should be exposed, how many places does this need to be implemented? We use `components` as an argument in a number of places in the codebase. Should we think about doing a large-scale replacement? ### I broke a plotting test. I can't tell the difference. @giovp, does this look fine to you? It's the spatial plots with no image. <details>. <summary> </summary>. Expected. ![master_spatial_visium_empty_image](https://user-images.githubusercontent.com/8238804/101748159-4f475800-3b20-11eb-9007-5a987a881828.png). Actual. ![master_spatial_visium_empty_image](https://user-images.githubusercontent.com/8238804/101748219-64bc8200-3b20-11eb-9313-23c04a1c537f.png). Diff. ![master_spatial_visium_empty_image-failed-diff](https://user-images.githubusercontent.com/8238804/101748266-73a33480-3b20-11eb-9a92-2be5f45da300.png). </details>. TODO:. - [ ] Deprecate components repeated behaviour. - [x] Finalize `dimensions` arg",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1538
https://github.com/scverse/scanpy/pull/1538:1560,energy efficiency,scale,scale,1560,". `components` is no longer used once it can be transformed into dimensions. What does this do? * Let's us delete `_get_data_points`, an awful function. * Get rid of `data_points` a list of coordinates that most code assumed would only ever have one element. * Move spatial specific code to spatial specific functions. * Gets rid of edge cases where `components` was either `None` or `[None]` (not sure how). Side note, also made a modification to a testing fixture that had been making tests fail when run out of order. ## Some questions:. ### Should `dimensions` be exposed? If so, should `components` be deprecated? I think it's weird to pass the dimensions as strings `""1,2""` as opposed to dimensions `(0, 1)`. * Why is it one indexed? * Isn't it the same amount of keystrokes? * How useful is `""all""`? I also think it's weird that the amount of plots generated is the product of `components` and `color`. This differs from every other ""vectorized"" argument to `embedding`. Changing arguments and deprecating `components` would be an opportunity to change this. ### If dimensions should be exposed, how many places does this need to be implemented? We use `components` as an argument in a number of places in the codebase. Should we think about doing a large-scale replacement? ### I broke a plotting test. I can't tell the difference. @giovp, does this look fine to you? It's the spatial plots with no image. <details>. <summary> </summary>. Expected. ![master_spatial_visium_empty_image](https://user-images.githubusercontent.com/8238804/101748159-4f475800-3b20-11eb-9007-5a987a881828.png). Actual. ![master_spatial_visium_empty_image](https://user-images.githubusercontent.com/8238804/101748219-64bc8200-3b20-11eb-9313-23c04a1c537f.png). Diff. ![master_spatial_visium_empty_image-failed-diff](https://user-images.githubusercontent.com/8238804/101748266-73a33480-3b20-11eb-9a92-2be5f45da300.png). </details>. TODO:. - [ ] Deprecate components repeated behaviour. - [x] Finalize `dimensions` arg",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1538
https://github.com/scverse/scanpy/pull/1538:132,integrability,compon,components,132,"Simplify embeddings a bit; Some effort to simplify how the embedding plots are handled. Right now this consists of simplifying the `components` argument to `dimensions`. Dimensions is a list of collections of ints. Each element in this list has the length of the number of dimensions to be plotted. `components` is no longer used once it can be transformed into dimensions. What does this do? * Let's us delete `_get_data_points`, an awful function. * Get rid of `data_points` a list of coordinates that most code assumed would only ever have one element. * Move spatial specific code to spatial specific functions. * Gets rid of edge cases where `components` was either `None` or `[None]` (not sure how). Side note, also made a modification to a testing fixture that had been making tests fail when run out of order. ## Some questions:. ### Should `dimensions` be exposed? If so, should `components` be deprecated? I think it's weird to pass the dimensions as strings `""1,2""` as opposed to dimensions `(0, 1)`. * Why is it one indexed? * Isn't it the same amount of keystrokes? * How useful is `""all""`? I also think it's weird that the amount of plots generated is the product of `components` and `color`. This differs from every other ""vectorized"" argument to `embedding`. Changing arguments and deprecating `components` would be an opportunity to change this. ### If dimensions should be exposed, how many places does this need to be implemented? We use `components` as an argument in a number of places in the codebase. Should we think about doing a large-scale replacement? ### I broke a plotting test. I can't tell the difference. @giovp, does this look fine to you? It's the spatial plots with no image. <details>. <summary> </summary>. Expected. ![master_spatial_visium_empty_image](https://user-images.githubusercontent.com/8238804/101748159-4f475800-3b20-11eb-9007-5a987a881828.png). Actual. ![master_spatial_visium_empty_image](https://user-images.githubusercontent.com/8238804/101748219-6",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1538
https://github.com/scverse/scanpy/pull/1538:300,integrability,compon,components,300,"Simplify embeddings a bit; Some effort to simplify how the embedding plots are handled. Right now this consists of simplifying the `components` argument to `dimensions`. Dimensions is a list of collections of ints. Each element in this list has the length of the number of dimensions to be plotted. `components` is no longer used once it can be transformed into dimensions. What does this do? * Let's us delete `_get_data_points`, an awful function. * Get rid of `data_points` a list of coordinates that most code assumed would only ever have one element. * Move spatial specific code to spatial specific functions. * Gets rid of edge cases where `components` was either `None` or `[None]` (not sure how). Side note, also made a modification to a testing fixture that had been making tests fail when run out of order. ## Some questions:. ### Should `dimensions` be exposed? If so, should `components` be deprecated? I think it's weird to pass the dimensions as strings `""1,2""` as opposed to dimensions `(0, 1)`. * Why is it one indexed? * Isn't it the same amount of keystrokes? * How useful is `""all""`? I also think it's weird that the amount of plots generated is the product of `components` and `color`. This differs from every other ""vectorized"" argument to `embedding`. Changing arguments and deprecating `components` would be an opportunity to change this. ### If dimensions should be exposed, how many places does this need to be implemented? We use `components` as an argument in a number of places in the codebase. Should we think about doing a large-scale replacement? ### I broke a plotting test. I can't tell the difference. @giovp, does this look fine to you? It's the spatial plots with no image. <details>. <summary> </summary>. Expected. ![master_spatial_visium_empty_image](https://user-images.githubusercontent.com/8238804/101748159-4f475800-3b20-11eb-9007-5a987a881828.png). Actual. ![master_spatial_visium_empty_image](https://user-images.githubusercontent.com/8238804/101748219-6",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1538
https://github.com/scverse/scanpy/pull/1538:345,integrability,transform,transformed,345,"Simplify embeddings a bit; Some effort to simplify how the embedding plots are handled. Right now this consists of simplifying the `components` argument to `dimensions`. Dimensions is a list of collections of ints. Each element in this list has the length of the number of dimensions to be plotted. `components` is no longer used once it can be transformed into dimensions. What does this do? * Let's us delete `_get_data_points`, an awful function. * Get rid of `data_points` a list of coordinates that most code assumed would only ever have one element. * Move spatial specific code to spatial specific functions. * Gets rid of edge cases where `components` was either `None` or `[None]` (not sure how). Side note, also made a modification to a testing fixture that had been making tests fail when run out of order. ## Some questions:. ### Should `dimensions` be exposed? If so, should `components` be deprecated? I think it's weird to pass the dimensions as strings `""1,2""` as opposed to dimensions `(0, 1)`. * Why is it one indexed? * Isn't it the same amount of keystrokes? * How useful is `""all""`? I also think it's weird that the amount of plots generated is the product of `components` and `color`. This differs from every other ""vectorized"" argument to `embedding`. Changing arguments and deprecating `components` would be an opportunity to change this. ### If dimensions should be exposed, how many places does this need to be implemented? We use `components` as an argument in a number of places in the codebase. Should we think about doing a large-scale replacement? ### I broke a plotting test. I can't tell the difference. @giovp, does this look fine to you? It's the spatial plots with no image. <details>. <summary> </summary>. Expected. ![master_spatial_visium_empty_image](https://user-images.githubusercontent.com/8238804/101748159-4f475800-3b20-11eb-9007-5a987a881828.png). Actual. ![master_spatial_visium_empty_image](https://user-images.githubusercontent.com/8238804/101748219-6",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1538
https://github.com/scverse/scanpy/pull/1538:648,integrability,compon,components,648,"Simplify embeddings a bit; Some effort to simplify how the embedding plots are handled. Right now this consists of simplifying the `components` argument to `dimensions`. Dimensions is a list of collections of ints. Each element in this list has the length of the number of dimensions to be plotted. `components` is no longer used once it can be transformed into dimensions. What does this do? * Let's us delete `_get_data_points`, an awful function. * Get rid of `data_points` a list of coordinates that most code assumed would only ever have one element. * Move spatial specific code to spatial specific functions. * Gets rid of edge cases where `components` was either `None` or `[None]` (not sure how). Side note, also made a modification to a testing fixture that had been making tests fail when run out of order. ## Some questions:. ### Should `dimensions` be exposed? If so, should `components` be deprecated? I think it's weird to pass the dimensions as strings `""1,2""` as opposed to dimensions `(0, 1)`. * Why is it one indexed? * Isn't it the same amount of keystrokes? * How useful is `""all""`? I also think it's weird that the amount of plots generated is the product of `components` and `color`. This differs from every other ""vectorized"" argument to `embedding`. Changing arguments and deprecating `components` would be an opportunity to change this. ### If dimensions should be exposed, how many places does this need to be implemented? We use `components` as an argument in a number of places in the codebase. Should we think about doing a large-scale replacement? ### I broke a plotting test. I can't tell the difference. @giovp, does this look fine to you? It's the spatial plots with no image. <details>. <summary> </summary>. Expected. ![master_spatial_visium_empty_image](https://user-images.githubusercontent.com/8238804/101748159-4f475800-3b20-11eb-9007-5a987a881828.png). Actual. ![master_spatial_visium_empty_image](https://user-images.githubusercontent.com/8238804/101748219-6",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1538
https://github.com/scverse/scanpy/pull/1538:889,integrability,compon,components,889,"Simplify embeddings a bit; Some effort to simplify how the embedding plots are handled. Right now this consists of simplifying the `components` argument to `dimensions`. Dimensions is a list of collections of ints. Each element in this list has the length of the number of dimensions to be plotted. `components` is no longer used once it can be transformed into dimensions. What does this do? * Let's us delete `_get_data_points`, an awful function. * Get rid of `data_points` a list of coordinates that most code assumed would only ever have one element. * Move spatial specific code to spatial specific functions. * Gets rid of edge cases where `components` was either `None` or `[None]` (not sure how). Side note, also made a modification to a testing fixture that had been making tests fail when run out of order. ## Some questions:. ### Should `dimensions` be exposed? If so, should `components` be deprecated? I think it's weird to pass the dimensions as strings `""1,2""` as opposed to dimensions `(0, 1)`. * Why is it one indexed? * Isn't it the same amount of keystrokes? * How useful is `""all""`? I also think it's weird that the amount of plots generated is the product of `components` and `color`. This differs from every other ""vectorized"" argument to `embedding`. Changing arguments and deprecating `components` would be an opportunity to change this. ### If dimensions should be exposed, how many places does this need to be implemented? We use `components` as an argument in a number of places in the codebase. Should we think about doing a large-scale replacement? ### I broke a plotting test. I can't tell the difference. @giovp, does this look fine to you? It's the spatial plots with no image. <details>. <summary> </summary>. Expected. ![master_spatial_visium_empty_image](https://user-images.githubusercontent.com/8238804/101748159-4f475800-3b20-11eb-9007-5a987a881828.png). Actual. ![master_spatial_visium_empty_image](https://user-images.githubusercontent.com/8238804/101748219-6",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1538
https://github.com/scverse/scanpy/pull/1538:1182,integrability,compon,components,1182,"ist of collections of ints. Each element in this list has the length of the number of dimensions to be plotted. `components` is no longer used once it can be transformed into dimensions. What does this do? * Let's us delete `_get_data_points`, an awful function. * Get rid of `data_points` a list of coordinates that most code assumed would only ever have one element. * Move spatial specific code to spatial specific functions. * Gets rid of edge cases where `components` was either `None` or `[None]` (not sure how). Side note, also made a modification to a testing fixture that had been making tests fail when run out of order. ## Some questions:. ### Should `dimensions` be exposed? If so, should `components` be deprecated? I think it's weird to pass the dimensions as strings `""1,2""` as opposed to dimensions `(0, 1)`. * Why is it one indexed? * Isn't it the same amount of keystrokes? * How useful is `""all""`? I also think it's weird that the amount of plots generated is the product of `components` and `color`. This differs from every other ""vectorized"" argument to `embedding`. Changing arguments and deprecating `components` would be an opportunity to change this. ### If dimensions should be exposed, how many places does this need to be implemented? We use `components` as an argument in a number of places in the codebase. Should we think about doing a large-scale replacement? ### I broke a plotting test. I can't tell the difference. @giovp, does this look fine to you? It's the spatial plots with no image. <details>. <summary> </summary>. Expected. ![master_spatial_visium_empty_image](https://user-images.githubusercontent.com/8238804/101748159-4f475800-3b20-11eb-9007-5a987a881828.png). Actual. ![master_spatial_visium_empty_image](https://user-images.githubusercontent.com/8238804/101748219-64bc8200-3b20-11eb-9313-23c04a1c537f.png). Diff. ![master_spatial_visium_empty_image-failed-diff](https://user-images.githubusercontent.com/8238804/101748266-73a33480-3b20-11eb-9a92-2be5f4",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1538
https://github.com/scverse/scanpy/pull/1538:1311,integrability,compon,components,1311,". `components` is no longer used once it can be transformed into dimensions. What does this do? * Let's us delete `_get_data_points`, an awful function. * Get rid of `data_points` a list of coordinates that most code assumed would only ever have one element. * Move spatial specific code to spatial specific functions. * Gets rid of edge cases where `components` was either `None` or `[None]` (not sure how). Side note, also made a modification to a testing fixture that had been making tests fail when run out of order. ## Some questions:. ### Should `dimensions` be exposed? If so, should `components` be deprecated? I think it's weird to pass the dimensions as strings `""1,2""` as opposed to dimensions `(0, 1)`. * Why is it one indexed? * Isn't it the same amount of keystrokes? * How useful is `""all""`? I also think it's weird that the amount of plots generated is the product of `components` and `color`. This differs from every other ""vectorized"" argument to `embedding`. Changing arguments and deprecating `components` would be an opportunity to change this. ### If dimensions should be exposed, how many places does this need to be implemented? We use `components` as an argument in a number of places in the codebase. Should we think about doing a large-scale replacement? ### I broke a plotting test. I can't tell the difference. @giovp, does this look fine to you? It's the spatial plots with no image. <details>. <summary> </summary>. Expected. ![master_spatial_visium_empty_image](https://user-images.githubusercontent.com/8238804/101748159-4f475800-3b20-11eb-9007-5a987a881828.png). Actual. ![master_spatial_visium_empty_image](https://user-images.githubusercontent.com/8238804/101748219-64bc8200-3b20-11eb-9313-23c04a1c537f.png). Diff. ![master_spatial_visium_empty_image-failed-diff](https://user-images.githubusercontent.com/8238804/101748266-73a33480-3b20-11eb-9a92-2be5f45da300.png). </details>. TODO:. - [ ] Deprecate components repeated behaviour. - [x] Finalize `dimensions` arg",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1538
https://github.com/scverse/scanpy/pull/1538:1458,integrability,compon,components,1458,". `components` is no longer used once it can be transformed into dimensions. What does this do? * Let's us delete `_get_data_points`, an awful function. * Get rid of `data_points` a list of coordinates that most code assumed would only ever have one element. * Move spatial specific code to spatial specific functions. * Gets rid of edge cases where `components` was either `None` or `[None]` (not sure how). Side note, also made a modification to a testing fixture that had been making tests fail when run out of order. ## Some questions:. ### Should `dimensions` be exposed? If so, should `components` be deprecated? I think it's weird to pass the dimensions as strings `""1,2""` as opposed to dimensions `(0, 1)`. * Why is it one indexed? * Isn't it the same amount of keystrokes? * How useful is `""all""`? I also think it's weird that the amount of plots generated is the product of `components` and `color`. This differs from every other ""vectorized"" argument to `embedding`. Changing arguments and deprecating `components` would be an opportunity to change this. ### If dimensions should be exposed, how many places does this need to be implemented? We use `components` as an argument in a number of places in the codebase. Should we think about doing a large-scale replacement? ### I broke a plotting test. I can't tell the difference. @giovp, does this look fine to you? It's the spatial plots with no image. <details>. <summary> </summary>. Expected. ![master_spatial_visium_empty_image](https://user-images.githubusercontent.com/8238804/101748159-4f475800-3b20-11eb-9007-5a987a881828.png). Actual. ![master_spatial_visium_empty_image](https://user-images.githubusercontent.com/8238804/101748219-64bc8200-3b20-11eb-9313-23c04a1c537f.png). Diff. ![master_spatial_visium_empty_image-failed-diff](https://user-images.githubusercontent.com/8238804/101748266-73a33480-3b20-11eb-9a92-2be5f45da300.png). </details>. TODO:. - [ ] Deprecate components repeated behaviour. - [x] Finalize `dimensions` arg",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1538
https://github.com/scverse/scanpy/pull/1538:2235,integrability,compon,components,2235,". `components` is no longer used once it can be transformed into dimensions. What does this do? * Let's us delete `_get_data_points`, an awful function. * Get rid of `data_points` a list of coordinates that most code assumed would only ever have one element. * Move spatial specific code to spatial specific functions. * Gets rid of edge cases where `components` was either `None` or `[None]` (not sure how). Side note, also made a modification to a testing fixture that had been making tests fail when run out of order. ## Some questions:. ### Should `dimensions` be exposed? If so, should `components` be deprecated? I think it's weird to pass the dimensions as strings `""1,2""` as opposed to dimensions `(0, 1)`. * Why is it one indexed? * Isn't it the same amount of keystrokes? * How useful is `""all""`? I also think it's weird that the amount of plots generated is the product of `components` and `color`. This differs from every other ""vectorized"" argument to `embedding`. Changing arguments and deprecating `components` would be an opportunity to change this. ### If dimensions should be exposed, how many places does this need to be implemented? We use `components` as an argument in a number of places in the codebase. Should we think about doing a large-scale replacement? ### I broke a plotting test. I can't tell the difference. @giovp, does this look fine to you? It's the spatial plots with no image. <details>. <summary> </summary>. Expected. ![master_spatial_visium_empty_image](https://user-images.githubusercontent.com/8238804/101748159-4f475800-3b20-11eb-9007-5a987a881828.png). Actual. ![master_spatial_visium_empty_image](https://user-images.githubusercontent.com/8238804/101748219-64bc8200-3b20-11eb-9313-23c04a1c537f.png). Diff. ![master_spatial_visium_empty_image-failed-diff](https://user-images.githubusercontent.com/8238804/101748266-73a33480-3b20-11eb-9a92-2be5f45da300.png). </details>. TODO:. - [ ] Deprecate components repeated behaviour. - [x] Finalize `dimensions` arg",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1538
https://github.com/scverse/scanpy/pull/1538:132,interoperability,compon,components,132,"Simplify embeddings a bit; Some effort to simplify how the embedding plots are handled. Right now this consists of simplifying the `components` argument to `dimensions`. Dimensions is a list of collections of ints. Each element in this list has the length of the number of dimensions to be plotted. `components` is no longer used once it can be transformed into dimensions. What does this do? * Let's us delete `_get_data_points`, an awful function. * Get rid of `data_points` a list of coordinates that most code assumed would only ever have one element. * Move spatial specific code to spatial specific functions. * Gets rid of edge cases where `components` was either `None` or `[None]` (not sure how). Side note, also made a modification to a testing fixture that had been making tests fail when run out of order. ## Some questions:. ### Should `dimensions` be exposed? If so, should `components` be deprecated? I think it's weird to pass the dimensions as strings `""1,2""` as opposed to dimensions `(0, 1)`. * Why is it one indexed? * Isn't it the same amount of keystrokes? * How useful is `""all""`? I also think it's weird that the amount of plots generated is the product of `components` and `color`. This differs from every other ""vectorized"" argument to `embedding`. Changing arguments and deprecating `components` would be an opportunity to change this. ### If dimensions should be exposed, how many places does this need to be implemented? We use `components` as an argument in a number of places in the codebase. Should we think about doing a large-scale replacement? ### I broke a plotting test. I can't tell the difference. @giovp, does this look fine to you? It's the spatial plots with no image. <details>. <summary> </summary>. Expected. ![master_spatial_visium_empty_image](https://user-images.githubusercontent.com/8238804/101748159-4f475800-3b20-11eb-9007-5a987a881828.png). Actual. ![master_spatial_visium_empty_image](https://user-images.githubusercontent.com/8238804/101748219-6",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1538
https://github.com/scverse/scanpy/pull/1538:300,interoperability,compon,components,300,"Simplify embeddings a bit; Some effort to simplify how the embedding plots are handled. Right now this consists of simplifying the `components` argument to `dimensions`. Dimensions is a list of collections of ints. Each element in this list has the length of the number of dimensions to be plotted. `components` is no longer used once it can be transformed into dimensions. What does this do? * Let's us delete `_get_data_points`, an awful function. * Get rid of `data_points` a list of coordinates that most code assumed would only ever have one element. * Move spatial specific code to spatial specific functions. * Gets rid of edge cases where `components` was either `None` or `[None]` (not sure how). Side note, also made a modification to a testing fixture that had been making tests fail when run out of order. ## Some questions:. ### Should `dimensions` be exposed? If so, should `components` be deprecated? I think it's weird to pass the dimensions as strings `""1,2""` as opposed to dimensions `(0, 1)`. * Why is it one indexed? * Isn't it the same amount of keystrokes? * How useful is `""all""`? I also think it's weird that the amount of plots generated is the product of `components` and `color`. This differs from every other ""vectorized"" argument to `embedding`. Changing arguments and deprecating `components` would be an opportunity to change this. ### If dimensions should be exposed, how many places does this need to be implemented? We use `components` as an argument in a number of places in the codebase. Should we think about doing a large-scale replacement? ### I broke a plotting test. I can't tell the difference. @giovp, does this look fine to you? It's the spatial plots with no image. <details>. <summary> </summary>. Expected. ![master_spatial_visium_empty_image](https://user-images.githubusercontent.com/8238804/101748159-4f475800-3b20-11eb-9007-5a987a881828.png). Actual. ![master_spatial_visium_empty_image](https://user-images.githubusercontent.com/8238804/101748219-6",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1538
https://github.com/scverse/scanpy/pull/1538:345,interoperability,transform,transformed,345,"Simplify embeddings a bit; Some effort to simplify how the embedding plots are handled. Right now this consists of simplifying the `components` argument to `dimensions`. Dimensions is a list of collections of ints. Each element in this list has the length of the number of dimensions to be plotted. `components` is no longer used once it can be transformed into dimensions. What does this do? * Let's us delete `_get_data_points`, an awful function. * Get rid of `data_points` a list of coordinates that most code assumed would only ever have one element. * Move spatial specific code to spatial specific functions. * Gets rid of edge cases where `components` was either `None` or `[None]` (not sure how). Side note, also made a modification to a testing fixture that had been making tests fail when run out of order. ## Some questions:. ### Should `dimensions` be exposed? If so, should `components` be deprecated? I think it's weird to pass the dimensions as strings `""1,2""` as opposed to dimensions `(0, 1)`. * Why is it one indexed? * Isn't it the same amount of keystrokes? * How useful is `""all""`? I also think it's weird that the amount of plots generated is the product of `components` and `color`. This differs from every other ""vectorized"" argument to `embedding`. Changing arguments and deprecating `components` would be an opportunity to change this. ### If dimensions should be exposed, how many places does this need to be implemented? We use `components` as an argument in a number of places in the codebase. Should we think about doing a large-scale replacement? ### I broke a plotting test. I can't tell the difference. @giovp, does this look fine to you? It's the spatial plots with no image. <details>. <summary> </summary>. Expected. ![master_spatial_visium_empty_image](https://user-images.githubusercontent.com/8238804/101748159-4f475800-3b20-11eb-9007-5a987a881828.png). Actual. ![master_spatial_visium_empty_image](https://user-images.githubusercontent.com/8238804/101748219-6",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1538
https://github.com/scverse/scanpy/pull/1538:487,interoperability,coordinat,coordinates,487,"Simplify embeddings a bit; Some effort to simplify how the embedding plots are handled. Right now this consists of simplifying the `components` argument to `dimensions`. Dimensions is a list of collections of ints. Each element in this list has the length of the number of dimensions to be plotted. `components` is no longer used once it can be transformed into dimensions. What does this do? * Let's us delete `_get_data_points`, an awful function. * Get rid of `data_points` a list of coordinates that most code assumed would only ever have one element. * Move spatial specific code to spatial specific functions. * Gets rid of edge cases where `components` was either `None` or `[None]` (not sure how). Side note, also made a modification to a testing fixture that had been making tests fail when run out of order. ## Some questions:. ### Should `dimensions` be exposed? If so, should `components` be deprecated? I think it's weird to pass the dimensions as strings `""1,2""` as opposed to dimensions `(0, 1)`. * Why is it one indexed? * Isn't it the same amount of keystrokes? * How useful is `""all""`? I also think it's weird that the amount of plots generated is the product of `components` and `color`. This differs from every other ""vectorized"" argument to `embedding`. Changing arguments and deprecating `components` would be an opportunity to change this. ### If dimensions should be exposed, how many places does this need to be implemented? We use `components` as an argument in a number of places in the codebase. Should we think about doing a large-scale replacement? ### I broke a plotting test. I can't tell the difference. @giovp, does this look fine to you? It's the spatial plots with no image. <details>. <summary> </summary>. Expected. ![master_spatial_visium_empty_image](https://user-images.githubusercontent.com/8238804/101748159-4f475800-3b20-11eb-9007-5a987a881828.png). Actual. ![master_spatial_visium_empty_image](https://user-images.githubusercontent.com/8238804/101748219-6",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1538
https://github.com/scverse/scanpy/pull/1538:571,interoperability,specif,specific,571,"Simplify embeddings a bit; Some effort to simplify how the embedding plots are handled. Right now this consists of simplifying the `components` argument to `dimensions`. Dimensions is a list of collections of ints. Each element in this list has the length of the number of dimensions to be plotted. `components` is no longer used once it can be transformed into dimensions. What does this do? * Let's us delete `_get_data_points`, an awful function. * Get rid of `data_points` a list of coordinates that most code assumed would only ever have one element. * Move spatial specific code to spatial specific functions. * Gets rid of edge cases where `components` was either `None` or `[None]` (not sure how). Side note, also made a modification to a testing fixture that had been making tests fail when run out of order. ## Some questions:. ### Should `dimensions` be exposed? If so, should `components` be deprecated? I think it's weird to pass the dimensions as strings `""1,2""` as opposed to dimensions `(0, 1)`. * Why is it one indexed? * Isn't it the same amount of keystrokes? * How useful is `""all""`? I also think it's weird that the amount of plots generated is the product of `components` and `color`. This differs from every other ""vectorized"" argument to `embedding`. Changing arguments and deprecating `components` would be an opportunity to change this. ### If dimensions should be exposed, how many places does this need to be implemented? We use `components` as an argument in a number of places in the codebase. Should we think about doing a large-scale replacement? ### I broke a plotting test. I can't tell the difference. @giovp, does this look fine to you? It's the spatial plots with no image. <details>. <summary> </summary>. Expected. ![master_spatial_visium_empty_image](https://user-images.githubusercontent.com/8238804/101748159-4f475800-3b20-11eb-9007-5a987a881828.png). Actual. ![master_spatial_visium_empty_image](https://user-images.githubusercontent.com/8238804/101748219-6",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1538
https://github.com/scverse/scanpy/pull/1538:596,interoperability,specif,specific,596,"Simplify embeddings a bit; Some effort to simplify how the embedding plots are handled. Right now this consists of simplifying the `components` argument to `dimensions`. Dimensions is a list of collections of ints. Each element in this list has the length of the number of dimensions to be plotted. `components` is no longer used once it can be transformed into dimensions. What does this do? * Let's us delete `_get_data_points`, an awful function. * Get rid of `data_points` a list of coordinates that most code assumed would only ever have one element. * Move spatial specific code to spatial specific functions. * Gets rid of edge cases where `components` was either `None` or `[None]` (not sure how). Side note, also made a modification to a testing fixture that had been making tests fail when run out of order. ## Some questions:. ### Should `dimensions` be exposed? If so, should `components` be deprecated? I think it's weird to pass the dimensions as strings `""1,2""` as opposed to dimensions `(0, 1)`. * Why is it one indexed? * Isn't it the same amount of keystrokes? * How useful is `""all""`? I also think it's weird that the amount of plots generated is the product of `components` and `color`. This differs from every other ""vectorized"" argument to `embedding`. Changing arguments and deprecating `components` would be an opportunity to change this. ### If dimensions should be exposed, how many places does this need to be implemented? We use `components` as an argument in a number of places in the codebase. Should we think about doing a large-scale replacement? ### I broke a plotting test. I can't tell the difference. @giovp, does this look fine to you? It's the spatial plots with no image. <details>. <summary> </summary>. Expected. ![master_spatial_visium_empty_image](https://user-images.githubusercontent.com/8238804/101748159-4f475800-3b20-11eb-9007-5a987a881828.png). Actual. ![master_spatial_visium_empty_image](https://user-images.githubusercontent.com/8238804/101748219-6",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1538
https://github.com/scverse/scanpy/pull/1538:648,interoperability,compon,components,648,"Simplify embeddings a bit; Some effort to simplify how the embedding plots are handled. Right now this consists of simplifying the `components` argument to `dimensions`. Dimensions is a list of collections of ints. Each element in this list has the length of the number of dimensions to be plotted. `components` is no longer used once it can be transformed into dimensions. What does this do? * Let's us delete `_get_data_points`, an awful function. * Get rid of `data_points` a list of coordinates that most code assumed would only ever have one element. * Move spatial specific code to spatial specific functions. * Gets rid of edge cases where `components` was either `None` or `[None]` (not sure how). Side note, also made a modification to a testing fixture that had been making tests fail when run out of order. ## Some questions:. ### Should `dimensions` be exposed? If so, should `components` be deprecated? I think it's weird to pass the dimensions as strings `""1,2""` as opposed to dimensions `(0, 1)`. * Why is it one indexed? * Isn't it the same amount of keystrokes? * How useful is `""all""`? I also think it's weird that the amount of plots generated is the product of `components` and `color`. This differs from every other ""vectorized"" argument to `embedding`. Changing arguments and deprecating `components` would be an opportunity to change this. ### If dimensions should be exposed, how many places does this need to be implemented? We use `components` as an argument in a number of places in the codebase. Should we think about doing a large-scale replacement? ### I broke a plotting test. I can't tell the difference. @giovp, does this look fine to you? It's the spatial plots with no image. <details>. <summary> </summary>. Expected. ![master_spatial_visium_empty_image](https://user-images.githubusercontent.com/8238804/101748159-4f475800-3b20-11eb-9007-5a987a881828.png). Actual. ![master_spatial_visium_empty_image](https://user-images.githubusercontent.com/8238804/101748219-6",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1538
https://github.com/scverse/scanpy/pull/1538:889,interoperability,compon,components,889,"Simplify embeddings a bit; Some effort to simplify how the embedding plots are handled. Right now this consists of simplifying the `components` argument to `dimensions`. Dimensions is a list of collections of ints. Each element in this list has the length of the number of dimensions to be plotted. `components` is no longer used once it can be transformed into dimensions. What does this do? * Let's us delete `_get_data_points`, an awful function. * Get rid of `data_points` a list of coordinates that most code assumed would only ever have one element. * Move spatial specific code to spatial specific functions. * Gets rid of edge cases where `components` was either `None` or `[None]` (not sure how). Side note, also made a modification to a testing fixture that had been making tests fail when run out of order. ## Some questions:. ### Should `dimensions` be exposed? If so, should `components` be deprecated? I think it's weird to pass the dimensions as strings `""1,2""` as opposed to dimensions `(0, 1)`. * Why is it one indexed? * Isn't it the same amount of keystrokes? * How useful is `""all""`? I also think it's weird that the amount of plots generated is the product of `components` and `color`. This differs from every other ""vectorized"" argument to `embedding`. Changing arguments and deprecating `components` would be an opportunity to change this. ### If dimensions should be exposed, how many places does this need to be implemented? We use `components` as an argument in a number of places in the codebase. Should we think about doing a large-scale replacement? ### I broke a plotting test. I can't tell the difference. @giovp, does this look fine to you? It's the spatial plots with no image. <details>. <summary> </summary>. Expected. ![master_spatial_visium_empty_image](https://user-images.githubusercontent.com/8238804/101748159-4f475800-3b20-11eb-9007-5a987a881828.png). Actual. ![master_spatial_visium_empty_image](https://user-images.githubusercontent.com/8238804/101748219-6",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1538
https://github.com/scverse/scanpy/pull/1538:1182,interoperability,compon,components,1182,"ist of collections of ints. Each element in this list has the length of the number of dimensions to be plotted. `components` is no longer used once it can be transformed into dimensions. What does this do? * Let's us delete `_get_data_points`, an awful function. * Get rid of `data_points` a list of coordinates that most code assumed would only ever have one element. * Move spatial specific code to spatial specific functions. * Gets rid of edge cases where `components` was either `None` or `[None]` (not sure how). Side note, also made a modification to a testing fixture that had been making tests fail when run out of order. ## Some questions:. ### Should `dimensions` be exposed? If so, should `components` be deprecated? I think it's weird to pass the dimensions as strings `""1,2""` as opposed to dimensions `(0, 1)`. * Why is it one indexed? * Isn't it the same amount of keystrokes? * How useful is `""all""`? I also think it's weird that the amount of plots generated is the product of `components` and `color`. This differs from every other ""vectorized"" argument to `embedding`. Changing arguments and deprecating `components` would be an opportunity to change this. ### If dimensions should be exposed, how many places does this need to be implemented? We use `components` as an argument in a number of places in the codebase. Should we think about doing a large-scale replacement? ### I broke a plotting test. I can't tell the difference. @giovp, does this look fine to you? It's the spatial plots with no image. <details>. <summary> </summary>. Expected. ![master_spatial_visium_empty_image](https://user-images.githubusercontent.com/8238804/101748159-4f475800-3b20-11eb-9007-5a987a881828.png). Actual. ![master_spatial_visium_empty_image](https://user-images.githubusercontent.com/8238804/101748219-64bc8200-3b20-11eb-9313-23c04a1c537f.png). Diff. ![master_spatial_visium_empty_image-failed-diff](https://user-images.githubusercontent.com/8238804/101748266-73a33480-3b20-11eb-9a92-2be5f4",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1538
https://github.com/scverse/scanpy/pull/1538:1311,interoperability,compon,components,1311,". `components` is no longer used once it can be transformed into dimensions. What does this do? * Let's us delete `_get_data_points`, an awful function. * Get rid of `data_points` a list of coordinates that most code assumed would only ever have one element. * Move spatial specific code to spatial specific functions. * Gets rid of edge cases where `components` was either `None` or `[None]` (not sure how). Side note, also made a modification to a testing fixture that had been making tests fail when run out of order. ## Some questions:. ### Should `dimensions` be exposed? If so, should `components` be deprecated? I think it's weird to pass the dimensions as strings `""1,2""` as opposed to dimensions `(0, 1)`. * Why is it one indexed? * Isn't it the same amount of keystrokes? * How useful is `""all""`? I also think it's weird that the amount of plots generated is the product of `components` and `color`. This differs from every other ""vectorized"" argument to `embedding`. Changing arguments and deprecating `components` would be an opportunity to change this. ### If dimensions should be exposed, how many places does this need to be implemented? We use `components` as an argument in a number of places in the codebase. Should we think about doing a large-scale replacement? ### I broke a plotting test. I can't tell the difference. @giovp, does this look fine to you? It's the spatial plots with no image. <details>. <summary> </summary>. Expected. ![master_spatial_visium_empty_image](https://user-images.githubusercontent.com/8238804/101748159-4f475800-3b20-11eb-9007-5a987a881828.png). Actual. ![master_spatial_visium_empty_image](https://user-images.githubusercontent.com/8238804/101748219-64bc8200-3b20-11eb-9313-23c04a1c537f.png). Diff. ![master_spatial_visium_empty_image-failed-diff](https://user-images.githubusercontent.com/8238804/101748266-73a33480-3b20-11eb-9a92-2be5f45da300.png). </details>. TODO:. - [ ] Deprecate components repeated behaviour. - [x] Finalize `dimensions` arg",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1538
https://github.com/scverse/scanpy/pull/1538:1458,interoperability,compon,components,1458,". `components` is no longer used once it can be transformed into dimensions. What does this do? * Let's us delete `_get_data_points`, an awful function. * Get rid of `data_points` a list of coordinates that most code assumed would only ever have one element. * Move spatial specific code to spatial specific functions. * Gets rid of edge cases where `components` was either `None` or `[None]` (not sure how). Side note, also made a modification to a testing fixture that had been making tests fail when run out of order. ## Some questions:. ### Should `dimensions` be exposed? If so, should `components` be deprecated? I think it's weird to pass the dimensions as strings `""1,2""` as opposed to dimensions `(0, 1)`. * Why is it one indexed? * Isn't it the same amount of keystrokes? * How useful is `""all""`? I also think it's weird that the amount of plots generated is the product of `components` and `color`. This differs from every other ""vectorized"" argument to `embedding`. Changing arguments and deprecating `components` would be an opportunity to change this. ### If dimensions should be exposed, how many places does this need to be implemented? We use `components` as an argument in a number of places in the codebase. Should we think about doing a large-scale replacement? ### I broke a plotting test. I can't tell the difference. @giovp, does this look fine to you? It's the spatial plots with no image. <details>. <summary> </summary>. Expected. ![master_spatial_visium_empty_image](https://user-images.githubusercontent.com/8238804/101748159-4f475800-3b20-11eb-9007-5a987a881828.png). Actual. ![master_spatial_visium_empty_image](https://user-images.githubusercontent.com/8238804/101748219-64bc8200-3b20-11eb-9313-23c04a1c537f.png). Diff. ![master_spatial_visium_empty_image-failed-diff](https://user-images.githubusercontent.com/8238804/101748266-73a33480-3b20-11eb-9a92-2be5f45da300.png). </details>. TODO:. - [ ] Deprecate components repeated behaviour. - [x] Finalize `dimensions` arg",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1538
https://github.com/scverse/scanpy/pull/1538:2235,interoperability,compon,components,2235,". `components` is no longer used once it can be transformed into dimensions. What does this do? * Let's us delete `_get_data_points`, an awful function. * Get rid of `data_points` a list of coordinates that most code assumed would only ever have one element. * Move spatial specific code to spatial specific functions. * Gets rid of edge cases where `components` was either `None` or `[None]` (not sure how). Side note, also made a modification to a testing fixture that had been making tests fail when run out of order. ## Some questions:. ### Should `dimensions` be exposed? If so, should `components` be deprecated? I think it's weird to pass the dimensions as strings `""1,2""` as opposed to dimensions `(0, 1)`. * Why is it one indexed? * Isn't it the same amount of keystrokes? * How useful is `""all""`? I also think it's weird that the amount of plots generated is the product of `components` and `color`. This differs from every other ""vectorized"" argument to `embedding`. Changing arguments and deprecating `components` would be an opportunity to change this. ### If dimensions should be exposed, how many places does this need to be implemented? We use `components` as an argument in a number of places in the codebase. Should we think about doing a large-scale replacement? ### I broke a plotting test. I can't tell the difference. @giovp, does this look fine to you? It's the spatial plots with no image. <details>. <summary> </summary>. Expected. ![master_spatial_visium_empty_image](https://user-images.githubusercontent.com/8238804/101748159-4f475800-3b20-11eb-9007-5a987a881828.png). Actual. ![master_spatial_visium_empty_image](https://user-images.githubusercontent.com/8238804/101748219-64bc8200-3b20-11eb-9313-23c04a1c537f.png). Diff. ![master_spatial_visium_empty_image-failed-diff](https://user-images.githubusercontent.com/8238804/101748266-73a33480-3b20-11eb-9a92-2be5f45da300.png). </details>. TODO:. - [ ] Deprecate components repeated behaviour. - [x] Finalize `dimensions` arg",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1538
https://github.com/scverse/scanpy/pull/1538:132,modifiability,compon,components,132,"Simplify embeddings a bit; Some effort to simplify how the embedding plots are handled. Right now this consists of simplifying the `components` argument to `dimensions`. Dimensions is a list of collections of ints. Each element in this list has the length of the number of dimensions to be plotted. `components` is no longer used once it can be transformed into dimensions. What does this do? * Let's us delete `_get_data_points`, an awful function. * Get rid of `data_points` a list of coordinates that most code assumed would only ever have one element. * Move spatial specific code to spatial specific functions. * Gets rid of edge cases where `components` was either `None` or `[None]` (not sure how). Side note, also made a modification to a testing fixture that had been making tests fail when run out of order. ## Some questions:. ### Should `dimensions` be exposed? If so, should `components` be deprecated? I think it's weird to pass the dimensions as strings `""1,2""` as opposed to dimensions `(0, 1)`. * Why is it one indexed? * Isn't it the same amount of keystrokes? * How useful is `""all""`? I also think it's weird that the amount of plots generated is the product of `components` and `color`. This differs from every other ""vectorized"" argument to `embedding`. Changing arguments and deprecating `components` would be an opportunity to change this. ### If dimensions should be exposed, how many places does this need to be implemented? We use `components` as an argument in a number of places in the codebase. Should we think about doing a large-scale replacement? ### I broke a plotting test. I can't tell the difference. @giovp, does this look fine to you? It's the spatial plots with no image. <details>. <summary> </summary>. Expected. ![master_spatial_visium_empty_image](https://user-images.githubusercontent.com/8238804/101748159-4f475800-3b20-11eb-9007-5a987a881828.png). Actual. ![master_spatial_visium_empty_image](https://user-images.githubusercontent.com/8238804/101748219-6",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1538
https://github.com/scverse/scanpy/pull/1538:300,modifiability,compon,components,300,"Simplify embeddings a bit; Some effort to simplify how the embedding plots are handled. Right now this consists of simplifying the `components` argument to `dimensions`. Dimensions is a list of collections of ints. Each element in this list has the length of the number of dimensions to be plotted. `components` is no longer used once it can be transformed into dimensions. What does this do? * Let's us delete `_get_data_points`, an awful function. * Get rid of `data_points` a list of coordinates that most code assumed would only ever have one element. * Move spatial specific code to spatial specific functions. * Gets rid of edge cases where `components` was either `None` or `[None]` (not sure how). Side note, also made a modification to a testing fixture that had been making tests fail when run out of order. ## Some questions:. ### Should `dimensions` be exposed? If so, should `components` be deprecated? I think it's weird to pass the dimensions as strings `""1,2""` as opposed to dimensions `(0, 1)`. * Why is it one indexed? * Isn't it the same amount of keystrokes? * How useful is `""all""`? I also think it's weird that the amount of plots generated is the product of `components` and `color`. This differs from every other ""vectorized"" argument to `embedding`. Changing arguments and deprecating `components` would be an opportunity to change this. ### If dimensions should be exposed, how many places does this need to be implemented? We use `components` as an argument in a number of places in the codebase. Should we think about doing a large-scale replacement? ### I broke a plotting test. I can't tell the difference. @giovp, does this look fine to you? It's the spatial plots with no image. <details>. <summary> </summary>. Expected. ![master_spatial_visium_empty_image](https://user-images.githubusercontent.com/8238804/101748159-4f475800-3b20-11eb-9007-5a987a881828.png). Actual. ![master_spatial_visium_empty_image](https://user-images.githubusercontent.com/8238804/101748219-6",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1538
https://github.com/scverse/scanpy/pull/1538:648,modifiability,compon,components,648,"Simplify embeddings a bit; Some effort to simplify how the embedding plots are handled. Right now this consists of simplifying the `components` argument to `dimensions`. Dimensions is a list of collections of ints. Each element in this list has the length of the number of dimensions to be plotted. `components` is no longer used once it can be transformed into dimensions. What does this do? * Let's us delete `_get_data_points`, an awful function. * Get rid of `data_points` a list of coordinates that most code assumed would only ever have one element. * Move spatial specific code to spatial specific functions. * Gets rid of edge cases where `components` was either `None` or `[None]` (not sure how). Side note, also made a modification to a testing fixture that had been making tests fail when run out of order. ## Some questions:. ### Should `dimensions` be exposed? If so, should `components` be deprecated? I think it's weird to pass the dimensions as strings `""1,2""` as opposed to dimensions `(0, 1)`. * Why is it one indexed? * Isn't it the same amount of keystrokes? * How useful is `""all""`? I also think it's weird that the amount of plots generated is the product of `components` and `color`. This differs from every other ""vectorized"" argument to `embedding`. Changing arguments and deprecating `components` would be an opportunity to change this. ### If dimensions should be exposed, how many places does this need to be implemented? We use `components` as an argument in a number of places in the codebase. Should we think about doing a large-scale replacement? ### I broke a plotting test. I can't tell the difference. @giovp, does this look fine to you? It's the spatial plots with no image. <details>. <summary> </summary>. Expected. ![master_spatial_visium_empty_image](https://user-images.githubusercontent.com/8238804/101748159-4f475800-3b20-11eb-9007-5a987a881828.png). Actual. ![master_spatial_visium_empty_image](https://user-images.githubusercontent.com/8238804/101748219-6",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1538
https://github.com/scverse/scanpy/pull/1538:889,modifiability,compon,components,889,"Simplify embeddings a bit; Some effort to simplify how the embedding plots are handled. Right now this consists of simplifying the `components` argument to `dimensions`. Dimensions is a list of collections of ints. Each element in this list has the length of the number of dimensions to be plotted. `components` is no longer used once it can be transformed into dimensions. What does this do? * Let's us delete `_get_data_points`, an awful function. * Get rid of `data_points` a list of coordinates that most code assumed would only ever have one element. * Move spatial specific code to spatial specific functions. * Gets rid of edge cases where `components` was either `None` or `[None]` (not sure how). Side note, also made a modification to a testing fixture that had been making tests fail when run out of order. ## Some questions:. ### Should `dimensions` be exposed? If so, should `components` be deprecated? I think it's weird to pass the dimensions as strings `""1,2""` as opposed to dimensions `(0, 1)`. * Why is it one indexed? * Isn't it the same amount of keystrokes? * How useful is `""all""`? I also think it's weird that the amount of plots generated is the product of `components` and `color`. This differs from every other ""vectorized"" argument to `embedding`. Changing arguments and deprecating `components` would be an opportunity to change this. ### If dimensions should be exposed, how many places does this need to be implemented? We use `components` as an argument in a number of places in the codebase. Should we think about doing a large-scale replacement? ### I broke a plotting test. I can't tell the difference. @giovp, does this look fine to you? It's the spatial plots with no image. <details>. <summary> </summary>. Expected. ![master_spatial_visium_empty_image](https://user-images.githubusercontent.com/8238804/101748159-4f475800-3b20-11eb-9007-5a987a881828.png). Actual. ![master_spatial_visium_empty_image](https://user-images.githubusercontent.com/8238804/101748219-6",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1538
https://github.com/scverse/scanpy/pull/1538:1182,modifiability,compon,components,1182,"ist of collections of ints. Each element in this list has the length of the number of dimensions to be plotted. `components` is no longer used once it can be transformed into dimensions. What does this do? * Let's us delete `_get_data_points`, an awful function. * Get rid of `data_points` a list of coordinates that most code assumed would only ever have one element. * Move spatial specific code to spatial specific functions. * Gets rid of edge cases where `components` was either `None` or `[None]` (not sure how). Side note, also made a modification to a testing fixture that had been making tests fail when run out of order. ## Some questions:. ### Should `dimensions` be exposed? If so, should `components` be deprecated? I think it's weird to pass the dimensions as strings `""1,2""` as opposed to dimensions `(0, 1)`. * Why is it one indexed? * Isn't it the same amount of keystrokes? * How useful is `""all""`? I also think it's weird that the amount of plots generated is the product of `components` and `color`. This differs from every other ""vectorized"" argument to `embedding`. Changing arguments and deprecating `components` would be an opportunity to change this. ### If dimensions should be exposed, how many places does this need to be implemented? We use `components` as an argument in a number of places in the codebase. Should we think about doing a large-scale replacement? ### I broke a plotting test. I can't tell the difference. @giovp, does this look fine to you? It's the spatial plots with no image. <details>. <summary> </summary>. Expected. ![master_spatial_visium_empty_image](https://user-images.githubusercontent.com/8238804/101748159-4f475800-3b20-11eb-9007-5a987a881828.png). Actual. ![master_spatial_visium_empty_image](https://user-images.githubusercontent.com/8238804/101748219-64bc8200-3b20-11eb-9313-23c04a1c537f.png). Diff. ![master_spatial_visium_empty_image-failed-diff](https://user-images.githubusercontent.com/8238804/101748266-73a33480-3b20-11eb-9a92-2be5f4",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1538
https://github.com/scverse/scanpy/pull/1538:1311,modifiability,compon,components,1311,". `components` is no longer used once it can be transformed into dimensions. What does this do? * Let's us delete `_get_data_points`, an awful function. * Get rid of `data_points` a list of coordinates that most code assumed would only ever have one element. * Move spatial specific code to spatial specific functions. * Gets rid of edge cases where `components` was either `None` or `[None]` (not sure how). Side note, also made a modification to a testing fixture that had been making tests fail when run out of order. ## Some questions:. ### Should `dimensions` be exposed? If so, should `components` be deprecated? I think it's weird to pass the dimensions as strings `""1,2""` as opposed to dimensions `(0, 1)`. * Why is it one indexed? * Isn't it the same amount of keystrokes? * How useful is `""all""`? I also think it's weird that the amount of plots generated is the product of `components` and `color`. This differs from every other ""vectorized"" argument to `embedding`. Changing arguments and deprecating `components` would be an opportunity to change this. ### If dimensions should be exposed, how many places does this need to be implemented? We use `components` as an argument in a number of places in the codebase. Should we think about doing a large-scale replacement? ### I broke a plotting test. I can't tell the difference. @giovp, does this look fine to you? It's the spatial plots with no image. <details>. <summary> </summary>. Expected. ![master_spatial_visium_empty_image](https://user-images.githubusercontent.com/8238804/101748159-4f475800-3b20-11eb-9007-5a987a881828.png). Actual. ![master_spatial_visium_empty_image](https://user-images.githubusercontent.com/8238804/101748219-64bc8200-3b20-11eb-9313-23c04a1c537f.png). Diff. ![master_spatial_visium_empty_image-failed-diff](https://user-images.githubusercontent.com/8238804/101748266-73a33480-3b20-11eb-9a92-2be5f45da300.png). </details>. TODO:. - [ ] Deprecate components repeated behaviour. - [x] Finalize `dimensions` arg",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1538
https://github.com/scverse/scanpy/pull/1538:1458,modifiability,compon,components,1458,". `components` is no longer used once it can be transformed into dimensions. What does this do? * Let's us delete `_get_data_points`, an awful function. * Get rid of `data_points` a list of coordinates that most code assumed would only ever have one element. * Move spatial specific code to spatial specific functions. * Gets rid of edge cases where `components` was either `None` or `[None]` (not sure how). Side note, also made a modification to a testing fixture that had been making tests fail when run out of order. ## Some questions:. ### Should `dimensions` be exposed? If so, should `components` be deprecated? I think it's weird to pass the dimensions as strings `""1,2""` as opposed to dimensions `(0, 1)`. * Why is it one indexed? * Isn't it the same amount of keystrokes? * How useful is `""all""`? I also think it's weird that the amount of plots generated is the product of `components` and `color`. This differs from every other ""vectorized"" argument to `embedding`. Changing arguments and deprecating `components` would be an opportunity to change this. ### If dimensions should be exposed, how many places does this need to be implemented? We use `components` as an argument in a number of places in the codebase. Should we think about doing a large-scale replacement? ### I broke a plotting test. I can't tell the difference. @giovp, does this look fine to you? It's the spatial plots with no image. <details>. <summary> </summary>. Expected. ![master_spatial_visium_empty_image](https://user-images.githubusercontent.com/8238804/101748159-4f475800-3b20-11eb-9007-5a987a881828.png). Actual. ![master_spatial_visium_empty_image](https://user-images.githubusercontent.com/8238804/101748219-64bc8200-3b20-11eb-9313-23c04a1c537f.png). Diff. ![master_spatial_visium_empty_image-failed-diff](https://user-images.githubusercontent.com/8238804/101748266-73a33480-3b20-11eb-9a92-2be5f45da300.png). </details>. TODO:. - [ ] Deprecate components repeated behaviour. - [x] Finalize `dimensions` arg",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1538
https://github.com/scverse/scanpy/pull/1538:1560,modifiability,scal,scale,1560,". `components` is no longer used once it can be transformed into dimensions. What does this do? * Let's us delete `_get_data_points`, an awful function. * Get rid of `data_points` a list of coordinates that most code assumed would only ever have one element. * Move spatial specific code to spatial specific functions. * Gets rid of edge cases where `components` was either `None` or `[None]` (not sure how). Side note, also made a modification to a testing fixture that had been making tests fail when run out of order. ## Some questions:. ### Should `dimensions` be exposed? If so, should `components` be deprecated? I think it's weird to pass the dimensions as strings `""1,2""` as opposed to dimensions `(0, 1)`. * Why is it one indexed? * Isn't it the same amount of keystrokes? * How useful is `""all""`? I also think it's weird that the amount of plots generated is the product of `components` and `color`. This differs from every other ""vectorized"" argument to `embedding`. Changing arguments and deprecating `components` would be an opportunity to change this. ### If dimensions should be exposed, how many places does this need to be implemented? We use `components` as an argument in a number of places in the codebase. Should we think about doing a large-scale replacement? ### I broke a plotting test. I can't tell the difference. @giovp, does this look fine to you? It's the spatial plots with no image. <details>. <summary> </summary>. Expected. ![master_spatial_visium_empty_image](https://user-images.githubusercontent.com/8238804/101748159-4f475800-3b20-11eb-9007-5a987a881828.png). Actual. ![master_spatial_visium_empty_image](https://user-images.githubusercontent.com/8238804/101748219-64bc8200-3b20-11eb-9313-23c04a1c537f.png). Diff. ![master_spatial_visium_empty_image-failed-diff](https://user-images.githubusercontent.com/8238804/101748266-73a33480-3b20-11eb-9a92-2be5f45da300.png). </details>. TODO:. - [ ] Deprecate components repeated behaviour. - [x] Finalize `dimensions` arg",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1538
https://github.com/scverse/scanpy/pull/1538:2235,modifiability,compon,components,2235,". `components` is no longer used once it can be transformed into dimensions. What does this do? * Let's us delete `_get_data_points`, an awful function. * Get rid of `data_points` a list of coordinates that most code assumed would only ever have one element. * Move spatial specific code to spatial specific functions. * Gets rid of edge cases where `components` was either `None` or `[None]` (not sure how). Side note, also made a modification to a testing fixture that had been making tests fail when run out of order. ## Some questions:. ### Should `dimensions` be exposed? If so, should `components` be deprecated? I think it's weird to pass the dimensions as strings `""1,2""` as opposed to dimensions `(0, 1)`. * Why is it one indexed? * Isn't it the same amount of keystrokes? * How useful is `""all""`? I also think it's weird that the amount of plots generated is the product of `components` and `color`. This differs from every other ""vectorized"" argument to `embedding`. Changing arguments and deprecating `components` would be an opportunity to change this. ### If dimensions should be exposed, how many places does this need to be implemented? We use `components` as an argument in a number of places in the codebase. Should we think about doing a large-scale replacement? ### I broke a plotting test. I can't tell the difference. @giovp, does this look fine to you? It's the spatial plots with no image. <details>. <summary> </summary>. Expected. ![master_spatial_visium_empty_image](https://user-images.githubusercontent.com/8238804/101748159-4f475800-3b20-11eb-9007-5a987a881828.png). Actual. ![master_spatial_visium_empty_image](https://user-images.githubusercontent.com/8238804/101748219-64bc8200-3b20-11eb-9313-23c04a1c537f.png). Diff. ![master_spatial_visium_empty_image-failed-diff](https://user-images.githubusercontent.com/8238804/101748266-73a33480-3b20-11eb-9a92-2be5f45da300.png). </details>. TODO:. - [ ] Deprecate components repeated behaviour. - [x] Finalize `dimensions` arg",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1538
https://github.com/scverse/scanpy/pull/1538:1560,performance,scale,scale,1560,". `components` is no longer used once it can be transformed into dimensions. What does this do? * Let's us delete `_get_data_points`, an awful function. * Get rid of `data_points` a list of coordinates that most code assumed would only ever have one element. * Move spatial specific code to spatial specific functions. * Gets rid of edge cases where `components` was either `None` or `[None]` (not sure how). Side note, also made a modification to a testing fixture that had been making tests fail when run out of order. ## Some questions:. ### Should `dimensions` be exposed? If so, should `components` be deprecated? I think it's weird to pass the dimensions as strings `""1,2""` as opposed to dimensions `(0, 1)`. * Why is it one indexed? * Isn't it the same amount of keystrokes? * How useful is `""all""`? I also think it's weird that the amount of plots generated is the product of `components` and `color`. This differs from every other ""vectorized"" argument to `embedding`. Changing arguments and deprecating `components` would be an opportunity to change this. ### If dimensions should be exposed, how many places does this need to be implemented? We use `components` as an argument in a number of places in the codebase. Should we think about doing a large-scale replacement? ### I broke a plotting test. I can't tell the difference. @giovp, does this look fine to you? It's the spatial plots with no image. <details>. <summary> </summary>. Expected. ![master_spatial_visium_empty_image](https://user-images.githubusercontent.com/8238804/101748159-4f475800-3b20-11eb-9007-5a987a881828.png). Actual. ![master_spatial_visium_empty_image](https://user-images.githubusercontent.com/8238804/101748219-64bc8200-3b20-11eb-9313-23c04a1c537f.png). Diff. ![master_spatial_visium_empty_image-failed-diff](https://user-images.githubusercontent.com/8238804/101748266-73a33480-3b20-11eb-9a92-2be5f45da300.png). </details>. TODO:. - [ ] Deprecate components repeated behaviour. - [x] Finalize `dimensions` arg",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1538
https://github.com/scverse/scanpy/pull/1538:379,reliability,doe,does,379,"Simplify embeddings a bit; Some effort to simplify how the embedding plots are handled. Right now this consists of simplifying the `components` argument to `dimensions`. Dimensions is a list of collections of ints. Each element in this list has the length of the number of dimensions to be plotted. `components` is no longer used once it can be transformed into dimensions. What does this do? * Let's us delete `_get_data_points`, an awful function. * Get rid of `data_points` a list of coordinates that most code assumed would only ever have one element. * Move spatial specific code to spatial specific functions. * Gets rid of edge cases where `components` was either `None` or `[None]` (not sure how). Side note, also made a modification to a testing fixture that had been making tests fail when run out of order. ## Some questions:. ### Should `dimensions` be exposed? If so, should `components` be deprecated? I think it's weird to pass the dimensions as strings `""1,2""` as opposed to dimensions `(0, 1)`. * Why is it one indexed? * Isn't it the same amount of keystrokes? * How useful is `""all""`? I also think it's weird that the amount of plots generated is the product of `components` and `color`. This differs from every other ""vectorized"" argument to `embedding`. Changing arguments and deprecating `components` would be an opportunity to change this. ### If dimensions should be exposed, how many places does this need to be implemented? We use `components` as an argument in a number of places in the codebase. Should we think about doing a large-scale replacement? ### I broke a plotting test. I can't tell the difference. @giovp, does this look fine to you? It's the spatial plots with no image. <details>. <summary> </summary>. Expected. ![master_spatial_visium_empty_image](https://user-images.githubusercontent.com/8238804/101748159-4f475800-3b20-11eb-9007-5a987a881828.png). Actual. ![master_spatial_visium_empty_image](https://user-images.githubusercontent.com/8238804/101748219-6",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1538
https://github.com/scverse/scanpy/pull/1538:790,reliability,fail,fail,790,"Simplify embeddings a bit; Some effort to simplify how the embedding plots are handled. Right now this consists of simplifying the `components` argument to `dimensions`. Dimensions is a list of collections of ints. Each element in this list has the length of the number of dimensions to be plotted. `components` is no longer used once it can be transformed into dimensions. What does this do? * Let's us delete `_get_data_points`, an awful function. * Get rid of `data_points` a list of coordinates that most code assumed would only ever have one element. * Move spatial specific code to spatial specific functions. * Gets rid of edge cases where `components` was either `None` or `[None]` (not sure how). Side note, also made a modification to a testing fixture that had been making tests fail when run out of order. ## Some questions:. ### Should `dimensions` be exposed? If so, should `components` be deprecated? I think it's weird to pass the dimensions as strings `""1,2""` as opposed to dimensions `(0, 1)`. * Why is it one indexed? * Isn't it the same amount of keystrokes? * How useful is `""all""`? I also think it's weird that the amount of plots generated is the product of `components` and `color`. This differs from every other ""vectorized"" argument to `embedding`. Changing arguments and deprecating `components` would be an opportunity to change this. ### If dimensions should be exposed, how many places does this need to be implemented? We use `components` as an argument in a number of places in the codebase. Should we think about doing a large-scale replacement? ### I broke a plotting test. I can't tell the difference. @giovp, does this look fine to you? It's the spatial plots with no image. <details>. <summary> </summary>. Expected. ![master_spatial_visium_empty_image](https://user-images.githubusercontent.com/8238804/101748159-4f475800-3b20-11eb-9007-5a987a881828.png). Actual. ![master_spatial_visium_empty_image](https://user-images.githubusercontent.com/8238804/101748219-6",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1538
https://github.com/scverse/scanpy/pull/1538:1416,reliability,doe,does,1416,". `components` is no longer used once it can be transformed into dimensions. What does this do? * Let's us delete `_get_data_points`, an awful function. * Get rid of `data_points` a list of coordinates that most code assumed would only ever have one element. * Move spatial specific code to spatial specific functions. * Gets rid of edge cases where `components` was either `None` or `[None]` (not sure how). Side note, also made a modification to a testing fixture that had been making tests fail when run out of order. ## Some questions:. ### Should `dimensions` be exposed? If so, should `components` be deprecated? I think it's weird to pass the dimensions as strings `""1,2""` as opposed to dimensions `(0, 1)`. * Why is it one indexed? * Isn't it the same amount of keystrokes? * How useful is `""all""`? I also think it's weird that the amount of plots generated is the product of `components` and `color`. This differs from every other ""vectorized"" argument to `embedding`. Changing arguments and deprecating `components` would be an opportunity to change this. ### If dimensions should be exposed, how many places does this need to be implemented? We use `components` as an argument in a number of places in the codebase. Should we think about doing a large-scale replacement? ### I broke a plotting test. I can't tell the difference. @giovp, does this look fine to you? It's the spatial plots with no image. <details>. <summary> </summary>. Expected. ![master_spatial_visium_empty_image](https://user-images.githubusercontent.com/8238804/101748159-4f475800-3b20-11eb-9007-5a987a881828.png). Actual. ![master_spatial_visium_empty_image](https://user-images.githubusercontent.com/8238804/101748219-64bc8200-3b20-11eb-9313-23c04a1c537f.png). Diff. ![master_spatial_visium_empty_image-failed-diff](https://user-images.githubusercontent.com/8238804/101748266-73a33480-3b20-11eb-9a92-2be5f45da300.png). </details>. TODO:. - [ ] Deprecate components repeated behaviour. - [x] Finalize `dimensions` arg",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1538
https://github.com/scverse/scanpy/pull/1538:1645,reliability,doe,does,1645,". `components` is no longer used once it can be transformed into dimensions. What does this do? * Let's us delete `_get_data_points`, an awful function. * Get rid of `data_points` a list of coordinates that most code assumed would only ever have one element. * Move spatial specific code to spatial specific functions. * Gets rid of edge cases where `components` was either `None` or `[None]` (not sure how). Side note, also made a modification to a testing fixture that had been making tests fail when run out of order. ## Some questions:. ### Should `dimensions` be exposed? If so, should `components` be deprecated? I think it's weird to pass the dimensions as strings `""1,2""` as opposed to dimensions `(0, 1)`. * Why is it one indexed? * Isn't it the same amount of keystrokes? * How useful is `""all""`? I also think it's weird that the amount of plots generated is the product of `components` and `color`. This differs from every other ""vectorized"" argument to `embedding`. Changing arguments and deprecating `components` would be an opportunity to change this. ### If dimensions should be exposed, how many places does this need to be implemented? We use `components` as an argument in a number of places in the codebase. Should we think about doing a large-scale replacement? ### I broke a plotting test. I can't tell the difference. @giovp, does this look fine to you? It's the spatial plots with no image. <details>. <summary> </summary>. Expected. ![master_spatial_visium_empty_image](https://user-images.githubusercontent.com/8238804/101748159-4f475800-3b20-11eb-9007-5a987a881828.png). Actual. ![master_spatial_visium_empty_image](https://user-images.githubusercontent.com/8238804/101748219-64bc8200-3b20-11eb-9313-23c04a1c537f.png). Diff. ![master_spatial_visium_empty_image-failed-diff](https://user-images.githubusercontent.com/8238804/101748266-73a33480-3b20-11eb-9a92-2be5f45da300.png). </details>. TODO:. - [ ] Deprecate components repeated behaviour. - [x] Finalize `dimensions` arg",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1538
https://github.com/scverse/scanpy/pull/1538:2084,reliability,fail,failed-diff,2084,". `components` is no longer used once it can be transformed into dimensions. What does this do? * Let's us delete `_get_data_points`, an awful function. * Get rid of `data_points` a list of coordinates that most code assumed would only ever have one element. * Move spatial specific code to spatial specific functions. * Gets rid of edge cases where `components` was either `None` or `[None]` (not sure how). Side note, also made a modification to a testing fixture that had been making tests fail when run out of order. ## Some questions:. ### Should `dimensions` be exposed? If so, should `components` be deprecated? I think it's weird to pass the dimensions as strings `""1,2""` as opposed to dimensions `(0, 1)`. * Why is it one indexed? * Isn't it the same amount of keystrokes? * How useful is `""all""`? I also think it's weird that the amount of plots generated is the product of `components` and `color`. This differs from every other ""vectorized"" argument to `embedding`. Changing arguments and deprecating `components` would be an opportunity to change this. ### If dimensions should be exposed, how many places does this need to be implemented? We use `components` as an argument in a number of places in the codebase. Should we think about doing a large-scale replacement? ### I broke a plotting test. I can't tell the difference. @giovp, does this look fine to you? It's the spatial plots with no image. <details>. <summary> </summary>. Expected. ![master_spatial_visium_empty_image](https://user-images.githubusercontent.com/8238804/101748159-4f475800-3b20-11eb-9007-5a987a881828.png). Actual. ![master_spatial_visium_empty_image](https://user-images.githubusercontent.com/8238804/101748219-64bc8200-3b20-11eb-9313-23c04a1c537f.png). Diff. ![master_spatial_visium_empty_image-failed-diff](https://user-images.githubusercontent.com/8238804/101748266-73a33480-3b20-11eb-9a92-2be5f45da300.png). </details>. TODO:. - [ ] Deprecate components repeated behaviour. - [x] Finalize `dimensions` arg",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1538
https://github.com/scverse/scanpy/pull/1538:747,safety,test,testing,747,"Simplify embeddings a bit; Some effort to simplify how the embedding plots are handled. Right now this consists of simplifying the `components` argument to `dimensions`. Dimensions is a list of collections of ints. Each element in this list has the length of the number of dimensions to be plotted. `components` is no longer used once it can be transformed into dimensions. What does this do? * Let's us delete `_get_data_points`, an awful function. * Get rid of `data_points` a list of coordinates that most code assumed would only ever have one element. * Move spatial specific code to spatial specific functions. * Gets rid of edge cases where `components` was either `None` or `[None]` (not sure how). Side note, also made a modification to a testing fixture that had been making tests fail when run out of order. ## Some questions:. ### Should `dimensions` be exposed? If so, should `components` be deprecated? I think it's weird to pass the dimensions as strings `""1,2""` as opposed to dimensions `(0, 1)`. * Why is it one indexed? * Isn't it the same amount of keystrokes? * How useful is `""all""`? I also think it's weird that the amount of plots generated is the product of `components` and `color`. This differs from every other ""vectorized"" argument to `embedding`. Changing arguments and deprecating `components` would be an opportunity to change this. ### If dimensions should be exposed, how many places does this need to be implemented? We use `components` as an argument in a number of places in the codebase. Should we think about doing a large-scale replacement? ### I broke a plotting test. I can't tell the difference. @giovp, does this look fine to you? It's the spatial plots with no image. <details>. <summary> </summary>. Expected. ![master_spatial_visium_empty_image](https://user-images.githubusercontent.com/8238804/101748159-4f475800-3b20-11eb-9007-5a987a881828.png). Actual. ![master_spatial_visium_empty_image](https://user-images.githubusercontent.com/8238804/101748219-6",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1538
https://github.com/scverse/scanpy/pull/1538:784,safety,test,tests,784,"Simplify embeddings a bit; Some effort to simplify how the embedding plots are handled. Right now this consists of simplifying the `components` argument to `dimensions`. Dimensions is a list of collections of ints. Each element in this list has the length of the number of dimensions to be plotted. `components` is no longer used once it can be transformed into dimensions. What does this do? * Let's us delete `_get_data_points`, an awful function. * Get rid of `data_points` a list of coordinates that most code assumed would only ever have one element. * Move spatial specific code to spatial specific functions. * Gets rid of edge cases where `components` was either `None` or `[None]` (not sure how). Side note, also made a modification to a testing fixture that had been making tests fail when run out of order. ## Some questions:. ### Should `dimensions` be exposed? If so, should `components` be deprecated? I think it's weird to pass the dimensions as strings `""1,2""` as opposed to dimensions `(0, 1)`. * Why is it one indexed? * Isn't it the same amount of keystrokes? * How useful is `""all""`? I also think it's weird that the amount of plots generated is the product of `components` and `color`. This differs from every other ""vectorized"" argument to `embedding`. Changing arguments and deprecating `components` would be an opportunity to change this. ### If dimensions should be exposed, how many places does this need to be implemented? We use `components` as an argument in a number of places in the codebase. Should we think about doing a large-scale replacement? ### I broke a plotting test. I can't tell the difference. @giovp, does this look fine to you? It's the spatial plots with no image. <details>. <summary> </summary>. Expected. ![master_spatial_visium_empty_image](https://user-images.githubusercontent.com/8238804/101748159-4f475800-3b20-11eb-9007-5a987a881828.png). Actual. ![master_spatial_visium_empty_image](https://user-images.githubusercontent.com/8238804/101748219-6",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1538
https://github.com/scverse/scanpy/pull/1538:1602,safety,test,test,1602,". `components` is no longer used once it can be transformed into dimensions. What does this do? * Let's us delete `_get_data_points`, an awful function. * Get rid of `data_points` a list of coordinates that most code assumed would only ever have one element. * Move spatial specific code to spatial specific functions. * Gets rid of edge cases where `components` was either `None` or `[None]` (not sure how). Side note, also made a modification to a testing fixture that had been making tests fail when run out of order. ## Some questions:. ### Should `dimensions` be exposed? If so, should `components` be deprecated? I think it's weird to pass the dimensions as strings `""1,2""` as opposed to dimensions `(0, 1)`. * Why is it one indexed? * Isn't it the same amount of keystrokes? * How useful is `""all""`? I also think it's weird that the amount of plots generated is the product of `components` and `color`. This differs from every other ""vectorized"" argument to `embedding`. Changing arguments and deprecating `components` would be an opportunity to change this. ### If dimensions should be exposed, how many places does this need to be implemented? We use `components` as an argument in a number of places in the codebase. Should we think about doing a large-scale replacement? ### I broke a plotting test. I can't tell the difference. @giovp, does this look fine to you? It's the spatial plots with no image. <details>. <summary> </summary>. Expected. ![master_spatial_visium_empty_image](https://user-images.githubusercontent.com/8238804/101748159-4f475800-3b20-11eb-9007-5a987a881828.png). Actual. ![master_spatial_visium_empty_image](https://user-images.githubusercontent.com/8238804/101748219-64bc8200-3b20-11eb-9313-23c04a1c537f.png). Diff. ![master_spatial_visium_empty_image-failed-diff](https://user-images.githubusercontent.com/8238804/101748266-73a33480-3b20-11eb-9a92-2be5f45da300.png). </details>. TODO:. - [ ] Deprecate components repeated behaviour. - [x] Finalize `dimensions` arg",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1538
https://github.com/scverse/scanpy/pull/1538:729,security,modif,modification,729,"Simplify embeddings a bit; Some effort to simplify how the embedding plots are handled. Right now this consists of simplifying the `components` argument to `dimensions`. Dimensions is a list of collections of ints. Each element in this list has the length of the number of dimensions to be plotted. `components` is no longer used once it can be transformed into dimensions. What does this do? * Let's us delete `_get_data_points`, an awful function. * Get rid of `data_points` a list of coordinates that most code assumed would only ever have one element. * Move spatial specific code to spatial specific functions. * Gets rid of edge cases where `components` was either `None` or `[None]` (not sure how). Side note, also made a modification to a testing fixture that had been making tests fail when run out of order. ## Some questions:. ### Should `dimensions` be exposed? If so, should `components` be deprecated? I think it's weird to pass the dimensions as strings `""1,2""` as opposed to dimensions `(0, 1)`. * Why is it one indexed? * Isn't it the same amount of keystrokes? * How useful is `""all""`? I also think it's weird that the amount of plots generated is the product of `components` and `color`. This differs from every other ""vectorized"" argument to `embedding`. Changing arguments and deprecating `components` would be an opportunity to change this. ### If dimensions should be exposed, how many places does this need to be implemented? We use `components` as an argument in a number of places in the codebase. Should we think about doing a large-scale replacement? ### I broke a plotting test. I can't tell the difference. @giovp, does this look fine to you? It's the spatial plots with no image. <details>. <summary> </summary>. Expected. ![master_spatial_visium_empty_image](https://user-images.githubusercontent.com/8238804/101748159-4f475800-3b20-11eb-9007-5a987a881828.png). Actual. ![master_spatial_visium_empty_image](https://user-images.githubusercontent.com/8238804/101748219-6",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1538
https://github.com/scverse/scanpy/pull/1538:865,security,expos,exposed,865,"Simplify embeddings a bit; Some effort to simplify how the embedding plots are handled. Right now this consists of simplifying the `components` argument to `dimensions`. Dimensions is a list of collections of ints. Each element in this list has the length of the number of dimensions to be plotted. `components` is no longer used once it can be transformed into dimensions. What does this do? * Let's us delete `_get_data_points`, an awful function. * Get rid of `data_points` a list of coordinates that most code assumed would only ever have one element. * Move spatial specific code to spatial specific functions. * Gets rid of edge cases where `components` was either `None` or `[None]` (not sure how). Side note, also made a modification to a testing fixture that had been making tests fail when run out of order. ## Some questions:. ### Should `dimensions` be exposed? If so, should `components` be deprecated? I think it's weird to pass the dimensions as strings `""1,2""` as opposed to dimensions `(0, 1)`. * Why is it one indexed? * Isn't it the same amount of keystrokes? * How useful is `""all""`? I also think it's weird that the amount of plots generated is the product of `components` and `color`. This differs from every other ""vectorized"" argument to `embedding`. Changing arguments and deprecating `components` would be an opportunity to change this. ### If dimensions should be exposed, how many places does this need to be implemented? We use `components` as an argument in a number of places in the codebase. Should we think about doing a large-scale replacement? ### I broke a plotting test. I can't tell the difference. @giovp, does this look fine to you? It's the spatial plots with no image. <details>. <summary> </summary>. Expected. ![master_spatial_visium_empty_image](https://user-images.githubusercontent.com/8238804/101748159-4f475800-3b20-11eb-9007-5a987a881828.png). Actual. ![master_spatial_visium_empty_image](https://user-images.githubusercontent.com/8238804/101748219-6",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1538
https://github.com/scverse/scanpy/pull/1538:1391,security,expos,exposed,1391,". `components` is no longer used once it can be transformed into dimensions. What does this do? * Let's us delete `_get_data_points`, an awful function. * Get rid of `data_points` a list of coordinates that most code assumed would only ever have one element. * Move spatial specific code to spatial specific functions. * Gets rid of edge cases where `components` was either `None` or `[None]` (not sure how). Side note, also made a modification to a testing fixture that had been making tests fail when run out of order. ## Some questions:. ### Should `dimensions` be exposed? If so, should `components` be deprecated? I think it's weird to pass the dimensions as strings `""1,2""` as opposed to dimensions `(0, 1)`. * Why is it one indexed? * Isn't it the same amount of keystrokes? * How useful is `""all""`? I also think it's weird that the amount of plots generated is the product of `components` and `color`. This differs from every other ""vectorized"" argument to `embedding`. Changing arguments and deprecating `components` would be an opportunity to change this. ### If dimensions should be exposed, how many places does this need to be implemented? We use `components` as an argument in a number of places in the codebase. Should we think about doing a large-scale replacement? ### I broke a plotting test. I can't tell the difference. @giovp, does this look fine to you? It's the spatial plots with no image. <details>. <summary> </summary>. Expected. ![master_spatial_visium_empty_image](https://user-images.githubusercontent.com/8238804/101748159-4f475800-3b20-11eb-9007-5a987a881828.png). Actual. ![master_spatial_visium_empty_image](https://user-images.githubusercontent.com/8238804/101748219-64bc8200-3b20-11eb-9313-23c04a1c537f.png). Diff. ![master_spatial_visium_empty_image-failed-diff](https://user-images.githubusercontent.com/8238804/101748266-73a33480-3b20-11eb-9a92-2be5f45da300.png). </details>. TODO:. - [ ] Deprecate components repeated behaviour. - [x] Finalize `dimensions` arg",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1538
https://github.com/scverse/scanpy/pull/1538:0,testability,Simpl,Simplify,0,"Simplify embeddings a bit; Some effort to simplify how the embedding plots are handled. Right now this consists of simplifying the `components` argument to `dimensions`. Dimensions is a list of collections of ints. Each element in this list has the length of the number of dimensions to be plotted. `components` is no longer used once it can be transformed into dimensions. What does this do? * Let's us delete `_get_data_points`, an awful function. * Get rid of `data_points` a list of coordinates that most code assumed would only ever have one element. * Move spatial specific code to spatial specific functions. * Gets rid of edge cases where `components` was either `None` or `[None]` (not sure how). Side note, also made a modification to a testing fixture that had been making tests fail when run out of order. ## Some questions:. ### Should `dimensions` be exposed? If so, should `components` be deprecated? I think it's weird to pass the dimensions as strings `""1,2""` as opposed to dimensions `(0, 1)`. * Why is it one indexed? * Isn't it the same amount of keystrokes? * How useful is `""all""`? I also think it's weird that the amount of plots generated is the product of `components` and `color`. This differs from every other ""vectorized"" argument to `embedding`. Changing arguments and deprecating `components` would be an opportunity to change this. ### If dimensions should be exposed, how many places does this need to be implemented? We use `components` as an argument in a number of places in the codebase. Should we think about doing a large-scale replacement? ### I broke a plotting test. I can't tell the difference. @giovp, does this look fine to you? It's the spatial plots with no image. <details>. <summary> </summary>. Expected. ![master_spatial_visium_empty_image](https://user-images.githubusercontent.com/8238804/101748159-4f475800-3b20-11eb-9007-5a987a881828.png). Actual. ![master_spatial_visium_empty_image](https://user-images.githubusercontent.com/8238804/101748219-6",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1538
https://github.com/scverse/scanpy/pull/1538:42,testability,simpl,simplify,42,"Simplify embeddings a bit; Some effort to simplify how the embedding plots are handled. Right now this consists of simplifying the `components` argument to `dimensions`. Dimensions is a list of collections of ints. Each element in this list has the length of the number of dimensions to be plotted. `components` is no longer used once it can be transformed into dimensions. What does this do? * Let's us delete `_get_data_points`, an awful function. * Get rid of `data_points` a list of coordinates that most code assumed would only ever have one element. * Move spatial specific code to spatial specific functions. * Gets rid of edge cases where `components` was either `None` or `[None]` (not sure how). Side note, also made a modification to a testing fixture that had been making tests fail when run out of order. ## Some questions:. ### Should `dimensions` be exposed? If so, should `components` be deprecated? I think it's weird to pass the dimensions as strings `""1,2""` as opposed to dimensions `(0, 1)`. * Why is it one indexed? * Isn't it the same amount of keystrokes? * How useful is `""all""`? I also think it's weird that the amount of plots generated is the product of `components` and `color`. This differs from every other ""vectorized"" argument to `embedding`. Changing arguments and deprecating `components` would be an opportunity to change this. ### If dimensions should be exposed, how many places does this need to be implemented? We use `components` as an argument in a number of places in the codebase. Should we think about doing a large-scale replacement? ### I broke a plotting test. I can't tell the difference. @giovp, does this look fine to you? It's the spatial plots with no image. <details>. <summary> </summary>. Expected. ![master_spatial_visium_empty_image](https://user-images.githubusercontent.com/8238804/101748159-4f475800-3b20-11eb-9007-5a987a881828.png). Actual. ![master_spatial_visium_empty_image](https://user-images.githubusercontent.com/8238804/101748219-6",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1538
https://github.com/scverse/scanpy/pull/1538:115,testability,simpl,simplifying,115,"Simplify embeddings a bit; Some effort to simplify how the embedding plots are handled. Right now this consists of simplifying the `components` argument to `dimensions`. Dimensions is a list of collections of ints. Each element in this list has the length of the number of dimensions to be plotted. `components` is no longer used once it can be transformed into dimensions. What does this do? * Let's us delete `_get_data_points`, an awful function. * Get rid of `data_points` a list of coordinates that most code assumed would only ever have one element. * Move spatial specific code to spatial specific functions. * Gets rid of edge cases where `components` was either `None` or `[None]` (not sure how). Side note, also made a modification to a testing fixture that had been making tests fail when run out of order. ## Some questions:. ### Should `dimensions` be exposed? If so, should `components` be deprecated? I think it's weird to pass the dimensions as strings `""1,2""` as opposed to dimensions `(0, 1)`. * Why is it one indexed? * Isn't it the same amount of keystrokes? * How useful is `""all""`? I also think it's weird that the amount of plots generated is the product of `components` and `color`. This differs from every other ""vectorized"" argument to `embedding`. Changing arguments and deprecating `components` would be an opportunity to change this. ### If dimensions should be exposed, how many places does this need to be implemented? We use `components` as an argument in a number of places in the codebase. Should we think about doing a large-scale replacement? ### I broke a plotting test. I can't tell the difference. @giovp, does this look fine to you? It's the spatial plots with no image. <details>. <summary> </summary>. Expected. ![master_spatial_visium_empty_image](https://user-images.githubusercontent.com/8238804/101748159-4f475800-3b20-11eb-9007-5a987a881828.png). Actual. ![master_spatial_visium_empty_image](https://user-images.githubusercontent.com/8238804/101748219-6",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1538
https://github.com/scverse/scanpy/pull/1538:747,testability,test,testing,747,"Simplify embeddings a bit; Some effort to simplify how the embedding plots are handled. Right now this consists of simplifying the `components` argument to `dimensions`. Dimensions is a list of collections of ints. Each element in this list has the length of the number of dimensions to be plotted. `components` is no longer used once it can be transformed into dimensions. What does this do? * Let's us delete `_get_data_points`, an awful function. * Get rid of `data_points` a list of coordinates that most code assumed would only ever have one element. * Move spatial specific code to spatial specific functions. * Gets rid of edge cases where `components` was either `None` or `[None]` (not sure how). Side note, also made a modification to a testing fixture that had been making tests fail when run out of order. ## Some questions:. ### Should `dimensions` be exposed? If so, should `components` be deprecated? I think it's weird to pass the dimensions as strings `""1,2""` as opposed to dimensions `(0, 1)`. * Why is it one indexed? * Isn't it the same amount of keystrokes? * How useful is `""all""`? I also think it's weird that the amount of plots generated is the product of `components` and `color`. This differs from every other ""vectorized"" argument to `embedding`. Changing arguments and deprecating `components` would be an opportunity to change this. ### If dimensions should be exposed, how many places does this need to be implemented? We use `components` as an argument in a number of places in the codebase. Should we think about doing a large-scale replacement? ### I broke a plotting test. I can't tell the difference. @giovp, does this look fine to you? It's the spatial plots with no image. <details>. <summary> </summary>. Expected. ![master_spatial_visium_empty_image](https://user-images.githubusercontent.com/8238804/101748159-4f475800-3b20-11eb-9007-5a987a881828.png). Actual. ![master_spatial_visium_empty_image](https://user-images.githubusercontent.com/8238804/101748219-6",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1538
https://github.com/scverse/scanpy/pull/1538:784,testability,test,tests,784,"Simplify embeddings a bit; Some effort to simplify how the embedding plots are handled. Right now this consists of simplifying the `components` argument to `dimensions`. Dimensions is a list of collections of ints. Each element in this list has the length of the number of dimensions to be plotted. `components` is no longer used once it can be transformed into dimensions. What does this do? * Let's us delete `_get_data_points`, an awful function. * Get rid of `data_points` a list of coordinates that most code assumed would only ever have one element. * Move spatial specific code to spatial specific functions. * Gets rid of edge cases where `components` was either `None` or `[None]` (not sure how). Side note, also made a modification to a testing fixture that had been making tests fail when run out of order. ## Some questions:. ### Should `dimensions` be exposed? If so, should `components` be deprecated? I think it's weird to pass the dimensions as strings `""1,2""` as opposed to dimensions `(0, 1)`. * Why is it one indexed? * Isn't it the same amount of keystrokes? * How useful is `""all""`? I also think it's weird that the amount of plots generated is the product of `components` and `color`. This differs from every other ""vectorized"" argument to `embedding`. Changing arguments and deprecating `components` would be an opportunity to change this. ### If dimensions should be exposed, how many places does this need to be implemented? We use `components` as an argument in a number of places in the codebase. Should we think about doing a large-scale replacement? ### I broke a plotting test. I can't tell the difference. @giovp, does this look fine to you? It's the spatial plots with no image. <details>. <summary> </summary>. Expected. ![master_spatial_visium_empty_image](https://user-images.githubusercontent.com/8238804/101748159-4f475800-3b20-11eb-9007-5a987a881828.png). Actual. ![master_spatial_visium_empty_image](https://user-images.githubusercontent.com/8238804/101748219-6",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1538
https://github.com/scverse/scanpy/pull/1538:1602,testability,test,test,1602,". `components` is no longer used once it can be transformed into dimensions. What does this do? * Let's us delete `_get_data_points`, an awful function. * Get rid of `data_points` a list of coordinates that most code assumed would only ever have one element. * Move spatial specific code to spatial specific functions. * Gets rid of edge cases where `components` was either `None` or `[None]` (not sure how). Side note, also made a modification to a testing fixture that had been making tests fail when run out of order. ## Some questions:. ### Should `dimensions` be exposed? If so, should `components` be deprecated? I think it's weird to pass the dimensions as strings `""1,2""` as opposed to dimensions `(0, 1)`. * Why is it one indexed? * Isn't it the same amount of keystrokes? * How useful is `""all""`? I also think it's weird that the amount of plots generated is the product of `components` and `color`. This differs from every other ""vectorized"" argument to `embedding`. Changing arguments and deprecating `components` would be an opportunity to change this. ### If dimensions should be exposed, how many places does this need to be implemented? We use `components` as an argument in a number of places in the codebase. Should we think about doing a large-scale replacement? ### I broke a plotting test. I can't tell the difference. @giovp, does this look fine to you? It's the spatial plots with no image. <details>. <summary> </summary>. Expected. ![master_spatial_visium_empty_image](https://user-images.githubusercontent.com/8238804/101748159-4f475800-3b20-11eb-9007-5a987a881828.png). Actual. ![master_spatial_visium_empty_image](https://user-images.githubusercontent.com/8238804/101748219-64bc8200-3b20-11eb-9313-23c04a1c537f.png). Diff. ![master_spatial_visium_empty_image-failed-diff](https://user-images.githubusercontent.com/8238804/101748266-73a33480-3b20-11eb-9a92-2be5f45da300.png). </details>. TODO:. - [ ] Deprecate components repeated behaviour. - [x] Finalize `dimensions` arg",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1538
https://github.com/scverse/scanpy/pull/1538:0,usability,Simpl,Simplify,0,"Simplify embeddings a bit; Some effort to simplify how the embedding plots are handled. Right now this consists of simplifying the `components` argument to `dimensions`. Dimensions is a list of collections of ints. Each element in this list has the length of the number of dimensions to be plotted. `components` is no longer used once it can be transformed into dimensions. What does this do? * Let's us delete `_get_data_points`, an awful function. * Get rid of `data_points` a list of coordinates that most code assumed would only ever have one element. * Move spatial specific code to spatial specific functions. * Gets rid of edge cases where `components` was either `None` or `[None]` (not sure how). Side note, also made a modification to a testing fixture that had been making tests fail when run out of order. ## Some questions:. ### Should `dimensions` be exposed? If so, should `components` be deprecated? I think it's weird to pass the dimensions as strings `""1,2""` as opposed to dimensions `(0, 1)`. * Why is it one indexed? * Isn't it the same amount of keystrokes? * How useful is `""all""`? I also think it's weird that the amount of plots generated is the product of `components` and `color`. This differs from every other ""vectorized"" argument to `embedding`. Changing arguments and deprecating `components` would be an opportunity to change this. ### If dimensions should be exposed, how many places does this need to be implemented? We use `components` as an argument in a number of places in the codebase. Should we think about doing a large-scale replacement? ### I broke a plotting test. I can't tell the difference. @giovp, does this look fine to you? It's the spatial plots with no image. <details>. <summary> </summary>. Expected. ![master_spatial_visium_empty_image](https://user-images.githubusercontent.com/8238804/101748159-4f475800-3b20-11eb-9007-5a987a881828.png). Actual. ![master_spatial_visium_empty_image](https://user-images.githubusercontent.com/8238804/101748219-6",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1538
https://github.com/scverse/scanpy/pull/1538:42,usability,simpl,simplify,42,"Simplify embeddings a bit; Some effort to simplify how the embedding plots are handled. Right now this consists of simplifying the `components` argument to `dimensions`. Dimensions is a list of collections of ints. Each element in this list has the length of the number of dimensions to be plotted. `components` is no longer used once it can be transformed into dimensions. What does this do? * Let's us delete `_get_data_points`, an awful function. * Get rid of `data_points` a list of coordinates that most code assumed would only ever have one element. * Move spatial specific code to spatial specific functions. * Gets rid of edge cases where `components` was either `None` or `[None]` (not sure how). Side note, also made a modification to a testing fixture that had been making tests fail when run out of order. ## Some questions:. ### Should `dimensions` be exposed? If so, should `components` be deprecated? I think it's weird to pass the dimensions as strings `""1,2""` as opposed to dimensions `(0, 1)`. * Why is it one indexed? * Isn't it the same amount of keystrokes? * How useful is `""all""`? I also think it's weird that the amount of plots generated is the product of `components` and `color`. This differs from every other ""vectorized"" argument to `embedding`. Changing arguments and deprecating `components` would be an opportunity to change this. ### If dimensions should be exposed, how many places does this need to be implemented? We use `components` as an argument in a number of places in the codebase. Should we think about doing a large-scale replacement? ### I broke a plotting test. I can't tell the difference. @giovp, does this look fine to you? It's the spatial plots with no image. <details>. <summary> </summary>. Expected. ![master_spatial_visium_empty_image](https://user-images.githubusercontent.com/8238804/101748159-4f475800-3b20-11eb-9007-5a987a881828.png). Actual. ![master_spatial_visium_empty_image](https://user-images.githubusercontent.com/8238804/101748219-6",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1538
https://github.com/scverse/scanpy/pull/1538:103,usability,consist,consists,103,"Simplify embeddings a bit; Some effort to simplify how the embedding plots are handled. Right now this consists of simplifying the `components` argument to `dimensions`. Dimensions is a list of collections of ints. Each element in this list has the length of the number of dimensions to be plotted. `components` is no longer used once it can be transformed into dimensions. What does this do? * Let's us delete `_get_data_points`, an awful function. * Get rid of `data_points` a list of coordinates that most code assumed would only ever have one element. * Move spatial specific code to spatial specific functions. * Gets rid of edge cases where `components` was either `None` or `[None]` (not sure how). Side note, also made a modification to a testing fixture that had been making tests fail when run out of order. ## Some questions:. ### Should `dimensions` be exposed? If so, should `components` be deprecated? I think it's weird to pass the dimensions as strings `""1,2""` as opposed to dimensions `(0, 1)`. * Why is it one indexed? * Isn't it the same amount of keystrokes? * How useful is `""all""`? I also think it's weird that the amount of plots generated is the product of `components` and `color`. This differs from every other ""vectorized"" argument to `embedding`. Changing arguments and deprecating `components` would be an opportunity to change this. ### If dimensions should be exposed, how many places does this need to be implemented? We use `components` as an argument in a number of places in the codebase. Should we think about doing a large-scale replacement? ### I broke a plotting test. I can't tell the difference. @giovp, does this look fine to you? It's the spatial plots with no image. <details>. <summary> </summary>. Expected. ![master_spatial_visium_empty_image](https://user-images.githubusercontent.com/8238804/101748159-4f475800-3b20-11eb-9007-5a987a881828.png). Actual. ![master_spatial_visium_empty_image](https://user-images.githubusercontent.com/8238804/101748219-6",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1538
https://github.com/scverse/scanpy/pull/1538:115,usability,simpl,simplifying,115,"Simplify embeddings a bit; Some effort to simplify how the embedding plots are handled. Right now this consists of simplifying the `components` argument to `dimensions`. Dimensions is a list of collections of ints. Each element in this list has the length of the number of dimensions to be plotted. `components` is no longer used once it can be transformed into dimensions. What does this do? * Let's us delete `_get_data_points`, an awful function. * Get rid of `data_points` a list of coordinates that most code assumed would only ever have one element. * Move spatial specific code to spatial specific functions. * Gets rid of edge cases where `components` was either `None` or `[None]` (not sure how). Side note, also made a modification to a testing fixture that had been making tests fail when run out of order. ## Some questions:. ### Should `dimensions` be exposed? If so, should `components` be deprecated? I think it's weird to pass the dimensions as strings `""1,2""` as opposed to dimensions `(0, 1)`. * Why is it one indexed? * Isn't it the same amount of keystrokes? * How useful is `""all""`? I also think it's weird that the amount of plots generated is the product of `components` and `color`. This differs from every other ""vectorized"" argument to `embedding`. Changing arguments and deprecating `components` would be an opportunity to change this. ### If dimensions should be exposed, how many places does this need to be implemented? We use `components` as an argument in a number of places in the codebase. Should we think about doing a large-scale replacement? ### I broke a plotting test. I can't tell the difference. @giovp, does this look fine to you? It's the spatial plots with no image. <details>. <summary> </summary>. Expected. ![master_spatial_visium_empty_image](https://user-images.githubusercontent.com/8238804/101748159-4f475800-3b20-11eb-9007-5a987a881828.png). Actual. ![master_spatial_visium_empty_image](https://user-images.githubusercontent.com/8238804/101748219-6",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1538
https://github.com/scverse/scanpy/pull/1538:1067,usability,keystrok,keystrokes,1067,"ts are handled. Right now this consists of simplifying the `components` argument to `dimensions`. Dimensions is a list of collections of ints. Each element in this list has the length of the number of dimensions to be plotted. `components` is no longer used once it can be transformed into dimensions. What does this do? * Let's us delete `_get_data_points`, an awful function. * Get rid of `data_points` a list of coordinates that most code assumed would only ever have one element. * Move spatial specific code to spatial specific functions. * Gets rid of edge cases where `components` was either `None` or `[None]` (not sure how). Side note, also made a modification to a testing fixture that had been making tests fail when run out of order. ## Some questions:. ### Should `dimensions` be exposed? If so, should `components` be deprecated? I think it's weird to pass the dimensions as strings `""1,2""` as opposed to dimensions `(0, 1)`. * Why is it one indexed? * Isn't it the same amount of keystrokes? * How useful is `""all""`? I also think it's weird that the amount of plots generated is the product of `components` and `color`. This differs from every other ""vectorized"" argument to `embedding`. Changing arguments and deprecating `components` would be an opportunity to change this. ### If dimensions should be exposed, how many places does this need to be implemented? We use `components` as an argument in a number of places in the codebase. Should we think about doing a large-scale replacement? ### I broke a plotting test. I can't tell the difference. @giovp, does this look fine to you? It's the spatial plots with no image. <details>. <summary> </summary>. Expected. ![master_spatial_visium_empty_image](https://user-images.githubusercontent.com/8238804/101748159-4f475800-3b20-11eb-9007-5a987a881828.png). Actual. ![master_spatial_visium_empty_image](https://user-images.githubusercontent.com/8238804/101748219-64bc8200-3b20-11eb-9313-23c04a1c537f.png). Diff. ![master_spatial_visium_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1538
https://github.com/scverse/scanpy/pull/1538:1799,usability,user,user-images,1799,". `components` is no longer used once it can be transformed into dimensions. What does this do? * Let's us delete `_get_data_points`, an awful function. * Get rid of `data_points` a list of coordinates that most code assumed would only ever have one element. * Move spatial specific code to spatial specific functions. * Gets rid of edge cases where `components` was either `None` or `[None]` (not sure how). Side note, also made a modification to a testing fixture that had been making tests fail when run out of order. ## Some questions:. ### Should `dimensions` be exposed? If so, should `components` be deprecated? I think it's weird to pass the dimensions as strings `""1,2""` as opposed to dimensions `(0, 1)`. * Why is it one indexed? * Isn't it the same amount of keystrokes? * How useful is `""all""`? I also think it's weird that the amount of plots generated is the product of `components` and `color`. This differs from every other ""vectorized"" argument to `embedding`. Changing arguments and deprecating `components` would be an opportunity to change this. ### If dimensions should be exposed, how many places does this need to be implemented? We use `components` as an argument in a number of places in the codebase. Should we think about doing a large-scale replacement? ### I broke a plotting test. I can't tell the difference. @giovp, does this look fine to you? It's the spatial plots with no image. <details>. <summary> </summary>. Expected. ![master_spatial_visium_empty_image](https://user-images.githubusercontent.com/8238804/101748159-4f475800-3b20-11eb-9007-5a987a881828.png). Actual. ![master_spatial_visium_empty_image](https://user-images.githubusercontent.com/8238804/101748219-64bc8200-3b20-11eb-9313-23c04a1c537f.png). Diff. ![master_spatial_visium_empty_image-failed-diff](https://user-images.githubusercontent.com/8238804/101748266-73a33480-3b20-11eb-9a92-2be5f45da300.png). </details>. TODO:. - [ ] Deprecate components repeated behaviour. - [x] Finalize `dimensions` arg",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1538
https://github.com/scverse/scanpy/pull/1538:1947,usability,user,user-images,1947,". `components` is no longer used once it can be transformed into dimensions. What does this do? * Let's us delete `_get_data_points`, an awful function. * Get rid of `data_points` a list of coordinates that most code assumed would only ever have one element. * Move spatial specific code to spatial specific functions. * Gets rid of edge cases where `components` was either `None` or `[None]` (not sure how). Side note, also made a modification to a testing fixture that had been making tests fail when run out of order. ## Some questions:. ### Should `dimensions` be exposed? If so, should `components` be deprecated? I think it's weird to pass the dimensions as strings `""1,2""` as opposed to dimensions `(0, 1)`. * Why is it one indexed? * Isn't it the same amount of keystrokes? * How useful is `""all""`? I also think it's weird that the amount of plots generated is the product of `components` and `color`. This differs from every other ""vectorized"" argument to `embedding`. Changing arguments and deprecating `components` would be an opportunity to change this. ### If dimensions should be exposed, how many places does this need to be implemented? We use `components` as an argument in a number of places in the codebase. Should we think about doing a large-scale replacement? ### I broke a plotting test. I can't tell the difference. @giovp, does this look fine to you? It's the spatial plots with no image. <details>. <summary> </summary>. Expected. ![master_spatial_visium_empty_image](https://user-images.githubusercontent.com/8238804/101748159-4f475800-3b20-11eb-9007-5a987a881828.png). Actual. ![master_spatial_visium_empty_image](https://user-images.githubusercontent.com/8238804/101748219-64bc8200-3b20-11eb-9313-23c04a1c537f.png). Diff. ![master_spatial_visium_empty_image-failed-diff](https://user-images.githubusercontent.com/8238804/101748266-73a33480-3b20-11eb-9a92-2be5f45da300.png). </details>. TODO:. - [ ] Deprecate components repeated behaviour. - [x] Finalize `dimensions` arg",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1538
https://github.com/scverse/scanpy/pull/1538:2105,usability,user,user-images,2105,". `components` is no longer used once it can be transformed into dimensions. What does this do? * Let's us delete `_get_data_points`, an awful function. * Get rid of `data_points` a list of coordinates that most code assumed would only ever have one element. * Move spatial specific code to spatial specific functions. * Gets rid of edge cases where `components` was either `None` or `[None]` (not sure how). Side note, also made a modification to a testing fixture that had been making tests fail when run out of order. ## Some questions:. ### Should `dimensions` be exposed? If so, should `components` be deprecated? I think it's weird to pass the dimensions as strings `""1,2""` as opposed to dimensions `(0, 1)`. * Why is it one indexed? * Isn't it the same amount of keystrokes? * How useful is `""all""`? I also think it's weird that the amount of plots generated is the product of `components` and `color`. This differs from every other ""vectorized"" argument to `embedding`. Changing arguments and deprecating `components` would be an opportunity to change this. ### If dimensions should be exposed, how many places does this need to be implemented? We use `components` as an argument in a number of places in the codebase. Should we think about doing a large-scale replacement? ### I broke a plotting test. I can't tell the difference. @giovp, does this look fine to you? It's the spatial plots with no image. <details>. <summary> </summary>. Expected. ![master_spatial_visium_empty_image](https://user-images.githubusercontent.com/8238804/101748159-4f475800-3b20-11eb-9007-5a987a881828.png). Actual. ![master_spatial_visium_empty_image](https://user-images.githubusercontent.com/8238804/101748219-64bc8200-3b20-11eb-9313-23c04a1c537f.png). Diff. ![master_spatial_visium_empty_image-failed-diff](https://user-images.githubusercontent.com/8238804/101748266-73a33480-3b20-11eb-9a92-2be5f45da300.png). </details>. TODO:. - [ ] Deprecate components repeated behaviour. - [x] Finalize `dimensions` arg",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1538
https://github.com/scverse/scanpy/pull/1538:2255,usability,behavi,behaviour,2255,". `components` is no longer used once it can be transformed into dimensions. What does this do? * Let's us delete `_get_data_points`, an awful function. * Get rid of `data_points` a list of coordinates that most code assumed would only ever have one element. * Move spatial specific code to spatial specific functions. * Gets rid of edge cases where `components` was either `None` or `[None]` (not sure how). Side note, also made a modification to a testing fixture that had been making tests fail when run out of order. ## Some questions:. ### Should `dimensions` be exposed? If so, should `components` be deprecated? I think it's weird to pass the dimensions as strings `""1,2""` as opposed to dimensions `(0, 1)`. * Why is it one indexed? * Isn't it the same amount of keystrokes? * How useful is `""all""`? I also think it's weird that the amount of plots generated is the product of `components` and `color`. This differs from every other ""vectorized"" argument to `embedding`. Changing arguments and deprecating `components` would be an opportunity to change this. ### If dimensions should be exposed, how many places does this need to be implemented? We use `components` as an argument in a number of places in the codebase. Should we think about doing a large-scale replacement? ### I broke a plotting test. I can't tell the difference. @giovp, does this look fine to you? It's the spatial plots with no image. <details>. <summary> </summary>. Expected. ![master_spatial_visium_empty_image](https://user-images.githubusercontent.com/8238804/101748159-4f475800-3b20-11eb-9007-5a987a881828.png). Actual. ![master_spatial_visium_empty_image](https://user-images.githubusercontent.com/8238804/101748219-64bc8200-3b20-11eb-9313-23c04a1c537f.png). Diff. ![master_spatial_visium_empty_image-failed-diff](https://user-images.githubusercontent.com/8238804/101748266-73a33480-3b20-11eb-9a92-2be5f45da300.png). </details>. TODO:. - [ ] Deprecate components repeated behaviour. - [x] Finalize `dimensions` arg",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1538
https://github.com/scverse/scanpy/issues/1539:11,integrability,transform,transform,11,"Can scanpy transform scATAC-seq peak matrix into ""Gene activity matrix""?; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... Sometimes we need to collapse the single cell ATAC-seq peak matrix to a ""gene activity matrix"", as same as in seurat, I wish the scanpy can also provide this function.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1539
https://github.com/scverse/scanpy/issues/1539:11,interoperability,transform,transform,11,"Can scanpy transform scATAC-seq peak matrix into ""Gene activity matrix""?; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... Sometimes we need to collapse the single cell ATAC-seq peak matrix to a ""gene activity matrix"", as same as in seurat, I wish the scanpy can also provide this function.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1539
https://github.com/scverse/scanpy/issues/1539:158,modifiability,paramet,parameters,158,"Can scanpy transform scATAC-seq peak matrix into ""Gene activity matrix""?; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... Sometimes we need to collapse the single cell ATAC-seq peak matrix to a ""gene activity matrix"", as same as in seurat, I wish the scanpy can also provide this function.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1539
https://github.com/scverse/scanpy/issues/1539:435,modifiability,pac,package,435,"Can scanpy transform scATAC-seq peak matrix into ""Gene activity matrix""?; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... Sometimes we need to collapse the single cell ATAC-seq peak matrix to a ""gene activity matrix"", as same as in seurat, I wish the scanpy can also provide this function.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1539
https://github.com/scverse/scanpy/issues/1539:240,testability,simpl,simple,240,"Can scanpy transform scATAC-seq peak matrix into ""Gene activity matrix""?; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... Sometimes we need to collapse the single cell ATAC-seq peak matrix to a ""gene activity matrix"", as same as in seurat, I wish the scanpy can also provide this function.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1539
https://github.com/scverse/scanpy/issues/1539:232,usability,tool,tool,232,"Can scanpy transform scATAC-seq peak matrix into ""Gene activity matrix""?; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... Sometimes we need to collapse the single cell ATAC-seq peak matrix to a ""gene activity matrix"", as same as in seurat, I wish the scanpy can also provide this function.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1539
https://github.com/scverse/scanpy/issues/1539:240,usability,simpl,simple,240,"Can scanpy transform scATAC-seq peak matrix into ""Gene activity matrix""?; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... Sometimes we need to collapse the single cell ATAC-seq peak matrix to a ""gene activity matrix"", as same as in seurat, I wish the scanpy can also provide this function.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1539
https://github.com/scverse/scanpy/issues/1539:256,usability,tool,tool,256,"Can scanpy transform scATAC-seq peak matrix into ""Gene activity matrix""?; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... Sometimes we need to collapse the single cell ATAC-seq peak matrix to a ""gene activity matrix"", as same as in seurat, I wish the scanpy can also provide this function.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1539
https://github.com/scverse/scanpy/issues/1539:304,usability,tool,tools,304,"Can scanpy transform scATAC-seq peak matrix into ""Gene activity matrix""?; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... Sometimes we need to collapse the single cell ATAC-seq peak matrix to a ""gene activity matrix"", as same as in seurat, I wish the scanpy can also provide this function.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1539
https://github.com/scverse/scanpy/issues/1539:404,usability,tool,tools,404,"Can scanpy transform scATAC-seq peak matrix into ""Gene activity matrix""?; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... Sometimes we need to collapse the single cell ATAC-seq peak matrix to a ""gene activity matrix"", as same as in seurat, I wish the scanpy can also provide this function.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1539
https://github.com/scverse/scanpy/pull/1540:5,deployability,Updat,Updated,5,"SAM: Updated default parameters to suit large datasets; The original set of default parameters used by SAM were geared more towards smaller datasets. As scRNAseq throughput is ever-increasing, I tweaked the default parameters to be better suited for large datasets.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1540
https://github.com/scverse/scanpy/pull/1540:21,modifiability,paramet,parameters,21,"SAM: Updated default parameters to suit large datasets; The original set of default parameters used by SAM were geared more towards smaller datasets. As scRNAseq throughput is ever-increasing, I tweaked the default parameters to be better suited for large datasets.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1540
https://github.com/scverse/scanpy/pull/1540:84,modifiability,paramet,parameters,84,"SAM: Updated default parameters to suit large datasets; The original set of default parameters used by SAM were geared more towards smaller datasets. As scRNAseq throughput is ever-increasing, I tweaked the default parameters to be better suited for large datasets.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1540
https://github.com/scverse/scanpy/pull/1540:215,modifiability,paramet,parameters,215,"SAM: Updated default parameters to suit large datasets; The original set of default parameters used by SAM were geared more towards smaller datasets. As scRNAseq throughput is ever-increasing, I tweaked the default parameters to be better suited for large datasets.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1540
https://github.com/scverse/scanpy/pull/1540:162,performance,throughput,throughput,162,"SAM: Updated default parameters to suit large datasets; The original set of default parameters used by SAM were geared more towards smaller datasets. As scRNAseq throughput is ever-increasing, I tweaked the default parameters to be better suited for large datasets.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1540
https://github.com/scverse/scanpy/pull/1540:5,safety,Updat,Updated,5,"SAM: Updated default parameters to suit large datasets; The original set of default parameters used by SAM were geared more towards smaller datasets. As scRNAseq throughput is ever-increasing, I tweaked the default parameters to be better suited for large datasets.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1540
https://github.com/scverse/scanpy/pull/1540:5,security,Updat,Updated,5,"SAM: Updated default parameters to suit large datasets; The original set of default parameters used by SAM were geared more towards smaller datasets. As scRNAseq throughput is ever-increasing, I tweaked the default parameters to be better suited for large datasets.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1540
https://github.com/scverse/scanpy/pull/1541:0,safety,Test,Test,0,Test hashsolo docs;,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1541
https://github.com/scverse/scanpy/pull/1541:5,security,hash,hashsolo,5,Test hashsolo docs;,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1541
https://github.com/scverse/scanpy/pull/1541:0,testability,Test,Test,0,Test hashsolo docs;,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1541
https://github.com/scverse/scanpy/pull/1542:0,deployability,Updat,Update,0,Update link for moignard15; Fixes #1515. A little worried this new URL looks more like something that would break.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1542
https://github.com/scverse/scanpy/pull/1542:0,safety,Updat,Update,0,Update link for moignard15; Fixes #1515. A little worried this new URL looks more like something that would break.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1542
https://github.com/scverse/scanpy/pull/1542:0,security,Updat,Update,0,Update link for moignard15; Fixes #1515. A little worried this new URL looks more like something that would break.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1542
https://github.com/scverse/scanpy/pull/1543:89,deployability,releas,released,89,Restrict umap to <0.5; Restricting umap to below `0.5` so we can fix changes before it's released (see #1509).,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1543
https://github.com/scverse/scanpy/pull/1544:24,deployability,contain,contains,24,"[WIP] dev docs; This PR contains a work in progress version of development docs. I would like to have an initial version of this in the next release. Right now we just have [CONTRIBUTING.md](), but this not particularly discoverable, complete, or up to date. The idea here is to be a useful resource both to first time developers and maintainers about development processes and how contributing works. Inspirational sources (which we can probably crib from with attribution):. * [Pandas development docs](https://pandas.pydata.org/pandas-docs/stable/development/contributing.html). * [mdanalysis contributing guide](https://userguide.mdanalysis.org/stable/contributing.html). ## Key features:. * Guidelines on external tools. * Guide for testing. * Guide for writing and building docs. * Release and merging guides",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1544
https://github.com/scverse/scanpy/pull/1544:52,deployability,version,version,52,"[WIP] dev docs; This PR contains a work in progress version of development docs. I would like to have an initial version of this in the next release. Right now we just have [CONTRIBUTING.md](), but this not particularly discoverable, complete, or up to date. The idea here is to be a useful resource both to first time developers and maintainers about development processes and how contributing works. Inspirational sources (which we can probably crib from with attribution):. * [Pandas development docs](https://pandas.pydata.org/pandas-docs/stable/development/contributing.html). * [mdanalysis contributing guide](https://userguide.mdanalysis.org/stable/contributing.html). ## Key features:. * Guidelines on external tools. * Guide for testing. * Guide for writing and building docs. * Release and merging guides",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1544
https://github.com/scverse/scanpy/pull/1544:113,deployability,version,version,113,"[WIP] dev docs; This PR contains a work in progress version of development docs. I would like to have an initial version of this in the next release. Right now we just have [CONTRIBUTING.md](), but this not particularly discoverable, complete, or up to date. The idea here is to be a useful resource both to first time developers and maintainers about development processes and how contributing works. Inspirational sources (which we can probably crib from with attribution):. * [Pandas development docs](https://pandas.pydata.org/pandas-docs/stable/development/contributing.html). * [mdanalysis contributing guide](https://userguide.mdanalysis.org/stable/contributing.html). ## Key features:. * Guidelines on external tools. * Guide for testing. * Guide for writing and building docs. * Release and merging guides",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1544
https://github.com/scverse/scanpy/pull/1544:141,deployability,releas,release,141,"[WIP] dev docs; This PR contains a work in progress version of development docs. I would like to have an initial version of this in the next release. Right now we just have [CONTRIBUTING.md](), but this not particularly discoverable, complete, or up to date. The idea here is to be a useful resource both to first time developers and maintainers about development processes and how contributing works. Inspirational sources (which we can probably crib from with attribution):. * [Pandas development docs](https://pandas.pydata.org/pandas-docs/stable/development/contributing.html). * [mdanalysis contributing guide](https://userguide.mdanalysis.org/stable/contributing.html). ## Key features:. * Guidelines on external tools. * Guide for testing. * Guide for writing and building docs. * Release and merging guides",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1544
https://github.com/scverse/scanpy/pull/1544:291,deployability,resourc,resource,291,"[WIP] dev docs; This PR contains a work in progress version of development docs. I would like to have an initial version of this in the next release. Right now we just have [CONTRIBUTING.md](), but this not particularly discoverable, complete, or up to date. The idea here is to be a useful resource both to first time developers and maintainers about development processes and how contributing works. Inspirational sources (which we can probably crib from with attribution):. * [Pandas development docs](https://pandas.pydata.org/pandas-docs/stable/development/contributing.html). * [mdanalysis contributing guide](https://userguide.mdanalysis.org/stable/contributing.html). ## Key features:. * Guidelines on external tools. * Guide for testing. * Guide for writing and building docs. * Release and merging guides",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1544
https://github.com/scverse/scanpy/pull/1544:771,deployability,build,building,771,"[WIP] dev docs; This PR contains a work in progress version of development docs. I would like to have an initial version of this in the next release. Right now we just have [CONTRIBUTING.md](), but this not particularly discoverable, complete, or up to date. The idea here is to be a useful resource both to first time developers and maintainers about development processes and how contributing works. Inspirational sources (which we can probably crib from with attribution):. * [Pandas development docs](https://pandas.pydata.org/pandas-docs/stable/development/contributing.html). * [mdanalysis contributing guide](https://userguide.mdanalysis.org/stable/contributing.html). ## Key features:. * Guidelines on external tools. * Guide for testing. * Guide for writing and building docs. * Release and merging guides",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1544
https://github.com/scverse/scanpy/pull/1544:788,deployability,Releas,Release,788,"[WIP] dev docs; This PR contains a work in progress version of development docs. I would like to have an initial version of this in the next release. Right now we just have [CONTRIBUTING.md](), but this not particularly discoverable, complete, or up to date. The idea here is to be a useful resource both to first time developers and maintainers about development processes and how contributing works. Inspirational sources (which we can probably crib from with attribution):. * [Pandas development docs](https://pandas.pydata.org/pandas-docs/stable/development/contributing.html). * [mdanalysis contributing guide](https://userguide.mdanalysis.org/stable/contributing.html). ## Key features:. * Guidelines on external tools. * Guide for testing. * Guide for writing and building docs. * Release and merging guides",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1544
https://github.com/scverse/scanpy/pull/1544:291,energy efficiency,resourc,resource,291,"[WIP] dev docs; This PR contains a work in progress version of development docs. I would like to have an initial version of this in the next release. Right now we just have [CONTRIBUTING.md](), but this not particularly discoverable, complete, or up to date. The idea here is to be a useful resource both to first time developers and maintainers about development processes and how contributing works. Inspirational sources (which we can probably crib from with attribution):. * [Pandas development docs](https://pandas.pydata.org/pandas-docs/stable/development/contributing.html). * [mdanalysis contributing guide](https://userguide.mdanalysis.org/stable/contributing.html). ## Key features:. * Guidelines on external tools. * Guide for testing. * Guide for writing and building docs. * Release and merging guides",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1544
https://github.com/scverse/scanpy/pull/1544:52,integrability,version,version,52,"[WIP] dev docs; This PR contains a work in progress version of development docs. I would like to have an initial version of this in the next release. Right now we just have [CONTRIBUTING.md](), but this not particularly discoverable, complete, or up to date. The idea here is to be a useful resource both to first time developers and maintainers about development processes and how contributing works. Inspirational sources (which we can probably crib from with attribution):. * [Pandas development docs](https://pandas.pydata.org/pandas-docs/stable/development/contributing.html). * [mdanalysis contributing guide](https://userguide.mdanalysis.org/stable/contributing.html). ## Key features:. * Guidelines on external tools. * Guide for testing. * Guide for writing and building docs. * Release and merging guides",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1544
https://github.com/scverse/scanpy/pull/1544:113,integrability,version,version,113,"[WIP] dev docs; This PR contains a work in progress version of development docs. I would like to have an initial version of this in the next release. Right now we just have [CONTRIBUTING.md](), but this not particularly discoverable, complete, or up to date. The idea here is to be a useful resource both to first time developers and maintainers about development processes and how contributing works. Inspirational sources (which we can probably crib from with attribution):. * [Pandas development docs](https://pandas.pydata.org/pandas-docs/stable/development/contributing.html). * [mdanalysis contributing guide](https://userguide.mdanalysis.org/stable/contributing.html). ## Key features:. * Guidelines on external tools. * Guide for testing. * Guide for writing and building docs. * Release and merging guides",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1544
https://github.com/scverse/scanpy/pull/1544:220,integrability,discover,discoverable,220,"[WIP] dev docs; This PR contains a work in progress version of development docs. I would like to have an initial version of this in the next release. Right now we just have [CONTRIBUTING.md](), but this not particularly discoverable, complete, or up to date. The idea here is to be a useful resource both to first time developers and maintainers about development processes and how contributing works. Inspirational sources (which we can probably crib from with attribution):. * [Pandas development docs](https://pandas.pydata.org/pandas-docs/stable/development/contributing.html). * [mdanalysis contributing guide](https://userguide.mdanalysis.org/stable/contributing.html). ## Key features:. * Guidelines on external tools. * Guide for testing. * Guide for writing and building docs. * Release and merging guides",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1544
https://github.com/scverse/scanpy/pull/1544:220,interoperability,discover,discoverable,220,"[WIP] dev docs; This PR contains a work in progress version of development docs. I would like to have an initial version of this in the next release. Right now we just have [CONTRIBUTING.md](), but this not particularly discoverable, complete, or up to date. The idea here is to be a useful resource both to first time developers and maintainers about development processes and how contributing works. Inspirational sources (which we can probably crib from with attribution):. * [Pandas development docs](https://pandas.pydata.org/pandas-docs/stable/development/contributing.html). * [mdanalysis contributing guide](https://userguide.mdanalysis.org/stable/contributing.html). ## Key features:. * Guidelines on external tools. * Guide for testing. * Guide for writing and building docs. * Release and merging guides",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1544
https://github.com/scverse/scanpy/pull/1544:52,modifiability,version,version,52,"[WIP] dev docs; This PR contains a work in progress version of development docs. I would like to have an initial version of this in the next release. Right now we just have [CONTRIBUTING.md](), but this not particularly discoverable, complete, or up to date. The idea here is to be a useful resource both to first time developers and maintainers about development processes and how contributing works. Inspirational sources (which we can probably crib from with attribution):. * [Pandas development docs](https://pandas.pydata.org/pandas-docs/stable/development/contributing.html). * [mdanalysis contributing guide](https://userguide.mdanalysis.org/stable/contributing.html). ## Key features:. * Guidelines on external tools. * Guide for testing. * Guide for writing and building docs. * Release and merging guides",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1544
https://github.com/scverse/scanpy/pull/1544:113,modifiability,version,version,113,"[WIP] dev docs; This PR contains a work in progress version of development docs. I would like to have an initial version of this in the next release. Right now we just have [CONTRIBUTING.md](), but this not particularly discoverable, complete, or up to date. The idea here is to be a useful resource both to first time developers and maintainers about development processes and how contributing works. Inspirational sources (which we can probably crib from with attribution):. * [Pandas development docs](https://pandas.pydata.org/pandas-docs/stable/development/contributing.html). * [mdanalysis contributing guide](https://userguide.mdanalysis.org/stable/contributing.html). ## Key features:. * Guidelines on external tools. * Guide for testing. * Guide for writing and building docs. * Release and merging guides",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1544
https://github.com/scverse/scanpy/pull/1544:334,modifiability,maintain,maintainers,334,"[WIP] dev docs; This PR contains a work in progress version of development docs. I would like to have an initial version of this in the next release. Right now we just have [CONTRIBUTING.md](), but this not particularly discoverable, complete, or up to date. The idea here is to be a useful resource both to first time developers and maintainers about development processes and how contributing works. Inspirational sources (which we can probably crib from with attribution):. * [Pandas development docs](https://pandas.pydata.org/pandas-docs/stable/development/contributing.html). * [mdanalysis contributing guide](https://userguide.mdanalysis.org/stable/contributing.html). ## Key features:. * Guidelines on external tools. * Guide for testing. * Guide for writing and building docs. * Release and merging guides",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1544
https://github.com/scverse/scanpy/pull/1544:291,performance,resourc,resource,291,"[WIP] dev docs; This PR contains a work in progress version of development docs. I would like to have an initial version of this in the next release. Right now we just have [CONTRIBUTING.md](), but this not particularly discoverable, complete, or up to date. The idea here is to be a useful resource both to first time developers and maintainers about development processes and how contributing works. Inspirational sources (which we can probably crib from with attribution):. * [Pandas development docs](https://pandas.pydata.org/pandas-docs/stable/development/contributing.html). * [mdanalysis contributing guide](https://userguide.mdanalysis.org/stable/contributing.html). ## Key features:. * Guidelines on external tools. * Guide for testing. * Guide for writing and building docs. * Release and merging guides",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1544
https://github.com/scverse/scanpy/pull/1544:314,performance,time,time,314,"[WIP] dev docs; This PR contains a work in progress version of development docs. I would like to have an initial version of this in the next release. Right now we just have [CONTRIBUTING.md](), but this not particularly discoverable, complete, or up to date. The idea here is to be a useful resource both to first time developers and maintainers about development processes and how contributing works. Inspirational sources (which we can probably crib from with attribution):. * [Pandas development docs](https://pandas.pydata.org/pandas-docs/stable/development/contributing.html). * [mdanalysis contributing guide](https://userguide.mdanalysis.org/stable/contributing.html). ## Key features:. * Guidelines on external tools. * Guide for testing. * Guide for writing and building docs. * Release and merging guides",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1544
https://github.com/scverse/scanpy/pull/1544:234,safety,compl,complete,234,"[WIP] dev docs; This PR contains a work in progress version of development docs. I would like to have an initial version of this in the next release. Right now we just have [CONTRIBUTING.md](), but this not particularly discoverable, complete, or up to date. The idea here is to be a useful resource both to first time developers and maintainers about development processes and how contributing works. Inspirational sources (which we can probably crib from with attribution):. * [Pandas development docs](https://pandas.pydata.org/pandas-docs/stable/development/contributing.html). * [mdanalysis contributing guide](https://userguide.mdanalysis.org/stable/contributing.html). ## Key features:. * Guidelines on external tools. * Guide for testing. * Guide for writing and building docs. * Release and merging guides",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1544
https://github.com/scverse/scanpy/pull/1544:291,safety,resourc,resource,291,"[WIP] dev docs; This PR contains a work in progress version of development docs. I would like to have an initial version of this in the next release. Right now we just have [CONTRIBUTING.md](), but this not particularly discoverable, complete, or up to date. The idea here is to be a useful resource both to first time developers and maintainers about development processes and how contributing works. Inspirational sources (which we can probably crib from with attribution):. * [Pandas development docs](https://pandas.pydata.org/pandas-docs/stable/development/contributing.html). * [mdanalysis contributing guide](https://userguide.mdanalysis.org/stable/contributing.html). ## Key features:. * Guidelines on external tools. * Guide for testing. * Guide for writing and building docs. * Release and merging guides",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1544
https://github.com/scverse/scanpy/pull/1544:334,safety,maintain,maintainers,334,"[WIP] dev docs; This PR contains a work in progress version of development docs. I would like to have an initial version of this in the next release. Right now we just have [CONTRIBUTING.md](), but this not particularly discoverable, complete, or up to date. The idea here is to be a useful resource both to first time developers and maintainers about development processes and how contributing works. Inspirational sources (which we can probably crib from with attribution):. * [Pandas development docs](https://pandas.pydata.org/pandas-docs/stable/development/contributing.html). * [mdanalysis contributing guide](https://userguide.mdanalysis.org/stable/contributing.html). ## Key features:. * Guidelines on external tools. * Guide for testing. * Guide for writing and building docs. * Release and merging guides",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1544
https://github.com/scverse/scanpy/pull/1544:738,safety,test,testing,738,"[WIP] dev docs; This PR contains a work in progress version of development docs. I would like to have an initial version of this in the next release. Right now we just have [CONTRIBUTING.md](), but this not particularly discoverable, complete, or up to date. The idea here is to be a useful resource both to first time developers and maintainers about development processes and how contributing works. Inspirational sources (which we can probably crib from with attribution):. * [Pandas development docs](https://pandas.pydata.org/pandas-docs/stable/development/contributing.html). * [mdanalysis contributing guide](https://userguide.mdanalysis.org/stable/contributing.html). ## Key features:. * Guidelines on external tools. * Guide for testing. * Guide for writing and building docs. * Release and merging guides",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1544
https://github.com/scverse/scanpy/pull/1544:234,security,compl,complete,234,"[WIP] dev docs; This PR contains a work in progress version of development docs. I would like to have an initial version of this in the next release. Right now we just have [CONTRIBUTING.md](), but this not particularly discoverable, complete, or up to date. The idea here is to be a useful resource both to first time developers and maintainers about development processes and how contributing works. Inspirational sources (which we can probably crib from with attribution):. * [Pandas development docs](https://pandas.pydata.org/pandas-docs/stable/development/contributing.html). * [mdanalysis contributing guide](https://userguide.mdanalysis.org/stable/contributing.html). ## Key features:. * Guidelines on external tools. * Guide for testing. * Guide for writing and building docs. * Release and merging guides",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1544
https://github.com/scverse/scanpy/pull/1544:291,testability,resourc,resource,291,"[WIP] dev docs; This PR contains a work in progress version of development docs. I would like to have an initial version of this in the next release. Right now we just have [CONTRIBUTING.md](), but this not particularly discoverable, complete, or up to date. The idea here is to be a useful resource both to first time developers and maintainers about development processes and how contributing works. Inspirational sources (which we can probably crib from with attribution):. * [Pandas development docs](https://pandas.pydata.org/pandas-docs/stable/development/contributing.html). * [mdanalysis contributing guide](https://userguide.mdanalysis.org/stable/contributing.html). ## Key features:. * Guidelines on external tools. * Guide for testing. * Guide for writing and building docs. * Release and merging guides",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1544
https://github.com/scverse/scanpy/pull/1544:738,testability,test,testing,738,"[WIP] dev docs; This PR contains a work in progress version of development docs. I would like to have an initial version of this in the next release. Right now we just have [CONTRIBUTING.md](), but this not particularly discoverable, complete, or up to date. The idea here is to be a useful resource both to first time developers and maintainers about development processes and how contributing works. Inspirational sources (which we can probably crib from with attribution):. * [Pandas development docs](https://pandas.pydata.org/pandas-docs/stable/development/contributing.html). * [mdanalysis contributing guide](https://userguide.mdanalysis.org/stable/contributing.html). ## Key features:. * Guidelines on external tools. * Guide for testing. * Guide for writing and building docs. * Release and merging guides",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1544
https://github.com/scverse/scanpy/pull/1544:43,usability,progress,progress,43,"[WIP] dev docs; This PR contains a work in progress version of development docs. I would like to have an initial version of this in the next release. Right now we just have [CONTRIBUTING.md](), but this not particularly discoverable, complete, or up to date. The idea here is to be a useful resource both to first time developers and maintainers about development processes and how contributing works. Inspirational sources (which we can probably crib from with attribution):. * [Pandas development docs](https://pandas.pydata.org/pandas-docs/stable/development/contributing.html). * [mdanalysis contributing guide](https://userguide.mdanalysis.org/stable/contributing.html). ## Key features:. * Guidelines on external tools. * Guide for testing. * Guide for writing and building docs. * Release and merging guides",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1544
https://github.com/scverse/scanpy/pull/1544:220,usability,discov,discoverable,220,"[WIP] dev docs; This PR contains a work in progress version of development docs. I would like to have an initial version of this in the next release. Right now we just have [CONTRIBUTING.md](), but this not particularly discoverable, complete, or up to date. The idea here is to be a useful resource both to first time developers and maintainers about development processes and how contributing works. Inspirational sources (which we can probably crib from with attribution):. * [Pandas development docs](https://pandas.pydata.org/pandas-docs/stable/development/contributing.html). * [mdanalysis contributing guide](https://userguide.mdanalysis.org/stable/contributing.html). ## Key features:. * Guidelines on external tools. * Guide for testing. * Guide for writing and building docs. * Release and merging guides",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1544
https://github.com/scverse/scanpy/pull/1544:609,usability,guid,guide,609,"[WIP] dev docs; This PR contains a work in progress version of development docs. I would like to have an initial version of this in the next release. Right now we just have [CONTRIBUTING.md](), but this not particularly discoverable, complete, or up to date. The idea here is to be a useful resource both to first time developers and maintainers about development processes and how contributing works. Inspirational sources (which we can probably crib from with attribution):. * [Pandas development docs](https://pandas.pydata.org/pandas-docs/stable/development/contributing.html). * [mdanalysis contributing guide](https://userguide.mdanalysis.org/stable/contributing.html). ## Key features:. * Guidelines on external tools. * Guide for testing. * Guide for writing and building docs. * Release and merging guides",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1544
https://github.com/scverse/scanpy/pull/1544:624,usability,user,userguide,624,"[WIP] dev docs; This PR contains a work in progress version of development docs. I would like to have an initial version of this in the next release. Right now we just have [CONTRIBUTING.md](), but this not particularly discoverable, complete, or up to date. The idea here is to be a useful resource both to first time developers and maintainers about development processes and how contributing works. Inspirational sources (which we can probably crib from with attribution):. * [Pandas development docs](https://pandas.pydata.org/pandas-docs/stable/development/contributing.html). * [mdanalysis contributing guide](https://userguide.mdanalysis.org/stable/contributing.html). ## Key features:. * Guidelines on external tools. * Guide for testing. * Guide for writing and building docs. * Release and merging guides",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1544
https://github.com/scverse/scanpy/pull/1544:696,usability,Guid,Guidelines,696,"[WIP] dev docs; This PR contains a work in progress version of development docs. I would like to have an initial version of this in the next release. Right now we just have [CONTRIBUTING.md](), but this not particularly discoverable, complete, or up to date. The idea here is to be a useful resource both to first time developers and maintainers about development processes and how contributing works. Inspirational sources (which we can probably crib from with attribution):. * [Pandas development docs](https://pandas.pydata.org/pandas-docs/stable/development/contributing.html). * [mdanalysis contributing guide](https://userguide.mdanalysis.org/stable/contributing.html). ## Key features:. * Guidelines on external tools. * Guide for testing. * Guide for writing and building docs. * Release and merging guides",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1544
https://github.com/scverse/scanpy/pull/1544:719,usability,tool,tools,719,"[WIP] dev docs; This PR contains a work in progress version of development docs. I would like to have an initial version of this in the next release. Right now we just have [CONTRIBUTING.md](), but this not particularly discoverable, complete, or up to date. The idea here is to be a useful resource both to first time developers and maintainers about development processes and how contributing works. Inspirational sources (which we can probably crib from with attribution):. * [Pandas development docs](https://pandas.pydata.org/pandas-docs/stable/development/contributing.html). * [mdanalysis contributing guide](https://userguide.mdanalysis.org/stable/contributing.html). ## Key features:. * Guidelines on external tools. * Guide for testing. * Guide for writing and building docs. * Release and merging guides",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1544
https://github.com/scverse/scanpy/pull/1544:728,usability,Guid,Guide,728,"[WIP] dev docs; This PR contains a work in progress version of development docs. I would like to have an initial version of this in the next release. Right now we just have [CONTRIBUTING.md](), but this not particularly discoverable, complete, or up to date. The idea here is to be a useful resource both to first time developers and maintainers about development processes and how contributing works. Inspirational sources (which we can probably crib from with attribution):. * [Pandas development docs](https://pandas.pydata.org/pandas-docs/stable/development/contributing.html). * [mdanalysis contributing guide](https://userguide.mdanalysis.org/stable/contributing.html). ## Key features:. * Guidelines on external tools. * Guide for testing. * Guide for writing and building docs. * Release and merging guides",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1544
https://github.com/scverse/scanpy/pull/1544:749,usability,Guid,Guide,749,"[WIP] dev docs; This PR contains a work in progress version of development docs. I would like to have an initial version of this in the next release. Right now we just have [CONTRIBUTING.md](), but this not particularly discoverable, complete, or up to date. The idea here is to be a useful resource both to first time developers and maintainers about development processes and how contributing works. Inspirational sources (which we can probably crib from with attribution):. * [Pandas development docs](https://pandas.pydata.org/pandas-docs/stable/development/contributing.html). * [mdanalysis contributing guide](https://userguide.mdanalysis.org/stable/contributing.html). ## Key features:. * Guidelines on external tools. * Guide for testing. * Guide for writing and building docs. * Release and merging guides",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1544
https://github.com/scverse/scanpy/pull/1544:808,usability,guid,guides,808,"[WIP] dev docs; This PR contains a work in progress version of development docs. I would like to have an initial version of this in the next release. Right now we just have [CONTRIBUTING.md](), but this not particularly discoverable, complete, or up to date. The idea here is to be a useful resource both to first time developers and maintainers about development processes and how contributing works. Inspirational sources (which we can probably crib from with attribution):. * [Pandas development docs](https://pandas.pydata.org/pandas-docs/stable/development/contributing.html). * [mdanalysis contributing guide](https://userguide.mdanalysis.org/stable/contributing.html). ## Key features:. * Guidelines on external tools. * Guide for testing. * Guide for writing and building docs. * Release and merging guides",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1544
https://github.com/scverse/scanpy/issues/1545:56,deployability,log,logarithmized,56,"cell_ranger flavor of highly_variable_genes expects non-logarithmized data?; - [X ] I have checked that this issue has not already been reported. - [ X] I have confirmed this bug exists on the latest version of scanpy. - [ X] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I believe this may be a bug in documentation. It says that scanpy.pp.highly_variable_genes expects logarithmized data, except when flavor='seurat_v3'. However, after reading the reference Zheng17 for the cellRanger method (in particular, Supplementary Figure 5c), it appears that non-logarithmized data was used for calculating the dispersion. And examining the highly_variable_genes source code, I note that for method='seurat', the data is transformed back out of logspace using X=np.expm1(X) before computing dispersions, but this is not done when method='cell_ranger'. My conclusion is that the documentation should be updated to reflect that when flavor='cell_ranger', non-logarithmized data is expected. But I would very much appreciate clarification on the issue, it has been a long-standing source of confusion in our lab. Thank you.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1545
https://github.com/scverse/scanpy/issues/1545:200,deployability,version,version,200,"cell_ranger flavor of highly_variable_genes expects non-logarithmized data?; - [X ] I have checked that this issue has not already been reported. - [ X] I have confirmed this bug exists on the latest version of scanpy. - [ X] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I believe this may be a bug in documentation. It says that scanpy.pp.highly_variable_genes expects logarithmized data, except when flavor='seurat_v3'. However, after reading the reference Zheng17 for the cellRanger method (in particular, Supplementary Figure 5c), it appears that non-logarithmized data was used for calculating the dispersion. And examining the highly_variable_genes source code, I note that for method='seurat', the data is transformed back out of logspace using X=np.expm1(X) before computing dispersions, but this is not done when method='cell_ranger'. My conclusion is that the documentation should be updated to reflect that when flavor='cell_ranger', non-logarithmized data is expected. But I would very much appreciate clarification on the issue, it has been a long-standing source of confusion in our lab. Thank you.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1545
https://github.com/scverse/scanpy/issues/1545:406,deployability,log,logarithmized,406,"cell_ranger flavor of highly_variable_genes expects non-logarithmized data?; - [X ] I have checked that this issue has not already been reported. - [ X] I have confirmed this bug exists on the latest version of scanpy. - [ X] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I believe this may be a bug in documentation. It says that scanpy.pp.highly_variable_genes expects logarithmized data, except when flavor='seurat_v3'. However, after reading the reference Zheng17 for the cellRanger method (in particular, Supplementary Figure 5c), it appears that non-logarithmized data was used for calculating the dispersion. And examining the highly_variable_genes source code, I note that for method='seurat', the data is transformed back out of logspace using X=np.expm1(X) before computing dispersions, but this is not done when method='cell_ranger'. My conclusion is that the documentation should be updated to reflect that when flavor='cell_ranger', non-logarithmized data is expected. But I would very much appreciate clarification on the issue, it has been a long-standing source of confusion in our lab. Thank you.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1545
https://github.com/scverse/scanpy/issues/1545:591,deployability,log,logarithmized,591,"cell_ranger flavor of highly_variable_genes expects non-logarithmized data?; - [X ] I have checked that this issue has not already been reported. - [ X] I have confirmed this bug exists on the latest version of scanpy. - [ X] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I believe this may be a bug in documentation. It says that scanpy.pp.highly_variable_genes expects logarithmized data, except when flavor='seurat_v3'. However, after reading the reference Zheng17 for the cellRanger method (in particular, Supplementary Figure 5c), it appears that non-logarithmized data was used for calculating the dispersion. And examining the highly_variable_genes source code, I note that for method='seurat', the data is transformed back out of logspace using X=np.expm1(X) before computing dispersions, but this is not done when method='cell_ranger'. My conclusion is that the documentation should be updated to reflect that when flavor='cell_ranger', non-logarithmized data is expected. But I would very much appreciate clarification on the issue, it has been a long-standing source of confusion in our lab. Thank you.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1545
https://github.com/scverse/scanpy/issues/1545:773,deployability,log,logspace,773,"cell_ranger flavor of highly_variable_genes expects non-logarithmized data?; - [X ] I have checked that this issue has not already been reported. - [ X] I have confirmed this bug exists on the latest version of scanpy. - [ X] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I believe this may be a bug in documentation. It says that scanpy.pp.highly_variable_genes expects logarithmized data, except when flavor='seurat_v3'. However, after reading the reference Zheng17 for the cellRanger method (in particular, Supplementary Figure 5c), it appears that non-logarithmized data was used for calculating the dispersion. And examining the highly_variable_genes source code, I note that for method='seurat', the data is transformed back out of logspace using X=np.expm1(X) before computing dispersions, but this is not done when method='cell_ranger'. My conclusion is that the documentation should be updated to reflect that when flavor='cell_ranger', non-logarithmized data is expected. But I would very much appreciate clarification on the issue, it has been a long-standing source of confusion in our lab. Thank you.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1545
https://github.com/scverse/scanpy/issues/1545:930,deployability,updat,updated,930,"cell_ranger flavor of highly_variable_genes expects non-logarithmized data?; - [X ] I have checked that this issue has not already been reported. - [ X] I have confirmed this bug exists on the latest version of scanpy. - [ X] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I believe this may be a bug in documentation. It says that scanpy.pp.highly_variable_genes expects logarithmized data, except when flavor='seurat_v3'. However, after reading the reference Zheng17 for the cellRanger method (in particular, Supplementary Figure 5c), it appears that non-logarithmized data was used for calculating the dispersion. And examining the highly_variable_genes source code, I note that for method='seurat', the data is transformed back out of logspace using X=np.expm1(X) before computing dispersions, but this is not done when method='cell_ranger'. My conclusion is that the documentation should be updated to reflect that when flavor='cell_ranger', non-logarithmized data is expected. But I would very much appreciate clarification on the issue, it has been a long-standing source of confusion in our lab. Thank you.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1545
https://github.com/scverse/scanpy/issues/1545:985,deployability,log,logarithmized,985,"cell_ranger flavor of highly_variable_genes expects non-logarithmized data?; - [X ] I have checked that this issue has not already been reported. - [ X] I have confirmed this bug exists on the latest version of scanpy. - [ X] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I believe this may be a bug in documentation. It says that scanpy.pp.highly_variable_genes expects logarithmized data, except when flavor='seurat_v3'. However, after reading the reference Zheng17 for the cellRanger method (in particular, Supplementary Figure 5c), it appears that non-logarithmized data was used for calculating the dispersion. And examining the highly_variable_genes source code, I note that for method='seurat', the data is transformed back out of logspace using X=np.expm1(X) before computing dispersions, but this is not done when method='cell_ranger'. My conclusion is that the documentation should be updated to reflect that when flavor='cell_ranger', non-logarithmized data is expected. But I would very much appreciate clarification on the issue, it has been a long-standing source of confusion in our lab. Thank you.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1545
https://github.com/scverse/scanpy/issues/1545:200,integrability,version,version,200,"cell_ranger flavor of highly_variable_genes expects non-logarithmized data?; - [X ] I have checked that this issue has not already been reported. - [ X] I have confirmed this bug exists on the latest version of scanpy. - [ X] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I believe this may be a bug in documentation. It says that scanpy.pp.highly_variable_genes expects logarithmized data, except when flavor='seurat_v3'. However, after reading the reference Zheng17 for the cellRanger method (in particular, Supplementary Figure 5c), it appears that non-logarithmized data was used for calculating the dispersion. And examining the highly_variable_genes source code, I note that for method='seurat', the data is transformed back out of logspace using X=np.expm1(X) before computing dispersions, but this is not done when method='cell_ranger'. My conclusion is that the documentation should be updated to reflect that when flavor='cell_ranger', non-logarithmized data is expected. But I would very much appreciate clarification on the issue, it has been a long-standing source of confusion in our lab. Thank you.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1545
https://github.com/scverse/scanpy/issues/1545:749,integrability,transform,transformed,749,"cell_ranger flavor of highly_variable_genes expects non-logarithmized data?; - [X ] I have checked that this issue has not already been reported. - [ X] I have confirmed this bug exists on the latest version of scanpy. - [ X] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I believe this may be a bug in documentation. It says that scanpy.pp.highly_variable_genes expects logarithmized data, except when flavor='seurat_v3'. However, after reading the reference Zheng17 for the cellRanger method (in particular, Supplementary Figure 5c), it appears that non-logarithmized data was used for calculating the dispersion. And examining the highly_variable_genes source code, I note that for method='seurat', the data is transformed back out of logspace using X=np.expm1(X) before computing dispersions, but this is not done when method='cell_ranger'. My conclusion is that the documentation should be updated to reflect that when flavor='cell_ranger', non-logarithmized data is expected. But I would very much appreciate clarification on the issue, it has been a long-standing source of confusion in our lab. Thank you.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1545
https://github.com/scverse/scanpy/issues/1545:749,interoperability,transform,transformed,749,"cell_ranger flavor of highly_variable_genes expects non-logarithmized data?; - [X ] I have checked that this issue has not already been reported. - [ X] I have confirmed this bug exists on the latest version of scanpy. - [ X] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I believe this may be a bug in documentation. It says that scanpy.pp.highly_variable_genes expects logarithmized data, except when flavor='seurat_v3'. However, after reading the reference Zheng17 for the cellRanger method (in particular, Supplementary Figure 5c), it appears that non-logarithmized data was used for calculating the dispersion. And examining the highly_variable_genes source code, I note that for method='seurat', the data is transformed back out of logspace using X=np.expm1(X) before computing dispersions, but this is not done when method='cell_ranger'. My conclusion is that the documentation should be updated to reflect that when flavor='cell_ranger', non-logarithmized data is expected. But I would very much appreciate clarification on the issue, it has been a long-standing source of confusion in our lab. Thank you.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1545
https://github.com/scverse/scanpy/issues/1545:200,modifiability,version,version,200,"cell_ranger flavor of highly_variable_genes expects non-logarithmized data?; - [X ] I have checked that this issue has not already been reported. - [ X] I have confirmed this bug exists on the latest version of scanpy. - [ X] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I believe this may be a bug in documentation. It says that scanpy.pp.highly_variable_genes expects logarithmized data, except when flavor='seurat_v3'. However, after reading the reference Zheng17 for the cellRanger method (in particular, Supplementary Figure 5c), it appears that non-logarithmized data was used for calculating the dispersion. And examining the highly_variable_genes source code, I note that for method='seurat', the data is transformed back out of logspace using X=np.expm1(X) before computing dispersions, but this is not done when method='cell_ranger'. My conclusion is that the documentation should be updated to reflect that when flavor='cell_ranger', non-logarithmized data is expected. But I would very much appreciate clarification on the issue, it has been a long-standing source of confusion in our lab. Thank you.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1545
https://github.com/scverse/scanpy/issues/1545:56,safety,log,logarithmized,56,"cell_ranger flavor of highly_variable_genes expects non-logarithmized data?; - [X ] I have checked that this issue has not already been reported. - [ X] I have confirmed this bug exists on the latest version of scanpy. - [ X] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I believe this may be a bug in documentation. It says that scanpy.pp.highly_variable_genes expects logarithmized data, except when flavor='seurat_v3'. However, after reading the reference Zheng17 for the cellRanger method (in particular, Supplementary Figure 5c), it appears that non-logarithmized data was used for calculating the dispersion. And examining the highly_variable_genes source code, I note that for method='seurat', the data is transformed back out of logspace using X=np.expm1(X) before computing dispersions, but this is not done when method='cell_ranger'. My conclusion is that the documentation should be updated to reflect that when flavor='cell_ranger', non-logarithmized data is expected. But I would very much appreciate clarification on the issue, it has been a long-standing source of confusion in our lab. Thank you.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1545
https://github.com/scverse/scanpy/issues/1545:406,safety,log,logarithmized,406,"cell_ranger flavor of highly_variable_genes expects non-logarithmized data?; - [X ] I have checked that this issue has not already been reported. - [ X] I have confirmed this bug exists on the latest version of scanpy. - [ X] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I believe this may be a bug in documentation. It says that scanpy.pp.highly_variable_genes expects logarithmized data, except when flavor='seurat_v3'. However, after reading the reference Zheng17 for the cellRanger method (in particular, Supplementary Figure 5c), it appears that non-logarithmized data was used for calculating the dispersion. And examining the highly_variable_genes source code, I note that for method='seurat', the data is transformed back out of logspace using X=np.expm1(X) before computing dispersions, but this is not done when method='cell_ranger'. My conclusion is that the documentation should be updated to reflect that when flavor='cell_ranger', non-logarithmized data is expected. But I would very much appreciate clarification on the issue, it has been a long-standing source of confusion in our lab. Thank you.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1545
https://github.com/scverse/scanpy/issues/1545:426,safety,except,except,426,"cell_ranger flavor of highly_variable_genes expects non-logarithmized data?; - [X ] I have checked that this issue has not already been reported. - [ X] I have confirmed this bug exists on the latest version of scanpy. - [ X] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I believe this may be a bug in documentation. It says that scanpy.pp.highly_variable_genes expects logarithmized data, except when flavor='seurat_v3'. However, after reading the reference Zheng17 for the cellRanger method (in particular, Supplementary Figure 5c), it appears that non-logarithmized data was used for calculating the dispersion. And examining the highly_variable_genes source code, I note that for method='seurat', the data is transformed back out of logspace using X=np.expm1(X) before computing dispersions, but this is not done when method='cell_ranger'. My conclusion is that the documentation should be updated to reflect that when flavor='cell_ranger', non-logarithmized data is expected. But I would very much appreciate clarification on the issue, it has been a long-standing source of confusion in our lab. Thank you.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1545
https://github.com/scverse/scanpy/issues/1545:591,safety,log,logarithmized,591,"cell_ranger flavor of highly_variable_genes expects non-logarithmized data?; - [X ] I have checked that this issue has not already been reported. - [ X] I have confirmed this bug exists on the latest version of scanpy. - [ X] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I believe this may be a bug in documentation. It says that scanpy.pp.highly_variable_genes expects logarithmized data, except when flavor='seurat_v3'. However, after reading the reference Zheng17 for the cellRanger method (in particular, Supplementary Figure 5c), it appears that non-logarithmized data was used for calculating the dispersion. And examining the highly_variable_genes source code, I note that for method='seurat', the data is transformed back out of logspace using X=np.expm1(X) before computing dispersions, but this is not done when method='cell_ranger'. My conclusion is that the documentation should be updated to reflect that when flavor='cell_ranger', non-logarithmized data is expected. But I would very much appreciate clarification on the issue, it has been a long-standing source of confusion in our lab. Thank you.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1545
https://github.com/scverse/scanpy/issues/1545:773,safety,log,logspace,773,"cell_ranger flavor of highly_variable_genes expects non-logarithmized data?; - [X ] I have checked that this issue has not already been reported. - [ X] I have confirmed this bug exists on the latest version of scanpy. - [ X] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I believe this may be a bug in documentation. It says that scanpy.pp.highly_variable_genes expects logarithmized data, except when flavor='seurat_v3'. However, after reading the reference Zheng17 for the cellRanger method (in particular, Supplementary Figure 5c), it appears that non-logarithmized data was used for calculating the dispersion. And examining the highly_variable_genes source code, I note that for method='seurat', the data is transformed back out of logspace using X=np.expm1(X) before computing dispersions, but this is not done when method='cell_ranger'. My conclusion is that the documentation should be updated to reflect that when flavor='cell_ranger', non-logarithmized data is expected. But I would very much appreciate clarification on the issue, it has been a long-standing source of confusion in our lab. Thank you.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1545
https://github.com/scverse/scanpy/issues/1545:930,safety,updat,updated,930,"cell_ranger flavor of highly_variable_genes expects non-logarithmized data?; - [X ] I have checked that this issue has not already been reported. - [ X] I have confirmed this bug exists on the latest version of scanpy. - [ X] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I believe this may be a bug in documentation. It says that scanpy.pp.highly_variable_genes expects logarithmized data, except when flavor='seurat_v3'. However, after reading the reference Zheng17 for the cellRanger method (in particular, Supplementary Figure 5c), it appears that non-logarithmized data was used for calculating the dispersion. And examining the highly_variable_genes source code, I note that for method='seurat', the data is transformed back out of logspace using X=np.expm1(X) before computing dispersions, but this is not done when method='cell_ranger'. My conclusion is that the documentation should be updated to reflect that when flavor='cell_ranger', non-logarithmized data is expected. But I would very much appreciate clarification on the issue, it has been a long-standing source of confusion in our lab. Thank you.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1545
https://github.com/scverse/scanpy/issues/1545:985,safety,log,logarithmized,985,"cell_ranger flavor of highly_variable_genes expects non-logarithmized data?; - [X ] I have checked that this issue has not already been reported. - [ X] I have confirmed this bug exists on the latest version of scanpy. - [ X] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I believe this may be a bug in documentation. It says that scanpy.pp.highly_variable_genes expects logarithmized data, except when flavor='seurat_v3'. However, after reading the reference Zheng17 for the cellRanger method (in particular, Supplementary Figure 5c), it appears that non-logarithmized data was used for calculating the dispersion. And examining the highly_variable_genes source code, I note that for method='seurat', the data is transformed back out of logspace using X=np.expm1(X) before computing dispersions, but this is not done when method='cell_ranger'. My conclusion is that the documentation should be updated to reflect that when flavor='cell_ranger', non-logarithmized data is expected. But I would very much appreciate clarification on the issue, it has been a long-standing source of confusion in our lab. Thank you.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1545
https://github.com/scverse/scanpy/issues/1545:56,security,log,logarithmized,56,"cell_ranger flavor of highly_variable_genes expects non-logarithmized data?; - [X ] I have checked that this issue has not already been reported. - [ X] I have confirmed this bug exists on the latest version of scanpy. - [ X] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I believe this may be a bug in documentation. It says that scanpy.pp.highly_variable_genes expects logarithmized data, except when flavor='seurat_v3'. However, after reading the reference Zheng17 for the cellRanger method (in particular, Supplementary Figure 5c), it appears that non-logarithmized data was used for calculating the dispersion. And examining the highly_variable_genes source code, I note that for method='seurat', the data is transformed back out of logspace using X=np.expm1(X) before computing dispersions, but this is not done when method='cell_ranger'. My conclusion is that the documentation should be updated to reflect that when flavor='cell_ranger', non-logarithmized data is expected. But I would very much appreciate clarification on the issue, it has been a long-standing source of confusion in our lab. Thank you.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1545
https://github.com/scverse/scanpy/issues/1545:406,security,log,logarithmized,406,"cell_ranger flavor of highly_variable_genes expects non-logarithmized data?; - [X ] I have checked that this issue has not already been reported. - [ X] I have confirmed this bug exists on the latest version of scanpy. - [ X] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I believe this may be a bug in documentation. It says that scanpy.pp.highly_variable_genes expects logarithmized data, except when flavor='seurat_v3'. However, after reading the reference Zheng17 for the cellRanger method (in particular, Supplementary Figure 5c), it appears that non-logarithmized data was used for calculating the dispersion. And examining the highly_variable_genes source code, I note that for method='seurat', the data is transformed back out of logspace using X=np.expm1(X) before computing dispersions, but this is not done when method='cell_ranger'. My conclusion is that the documentation should be updated to reflect that when flavor='cell_ranger', non-logarithmized data is expected. But I would very much appreciate clarification on the issue, it has been a long-standing source of confusion in our lab. Thank you.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1545
https://github.com/scverse/scanpy/issues/1545:591,security,log,logarithmized,591,"cell_ranger flavor of highly_variable_genes expects non-logarithmized data?; - [X ] I have checked that this issue has not already been reported. - [ X] I have confirmed this bug exists on the latest version of scanpy. - [ X] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I believe this may be a bug in documentation. It says that scanpy.pp.highly_variable_genes expects logarithmized data, except when flavor='seurat_v3'. However, after reading the reference Zheng17 for the cellRanger method (in particular, Supplementary Figure 5c), it appears that non-logarithmized data was used for calculating the dispersion. And examining the highly_variable_genes source code, I note that for method='seurat', the data is transformed back out of logspace using X=np.expm1(X) before computing dispersions, but this is not done when method='cell_ranger'. My conclusion is that the documentation should be updated to reflect that when flavor='cell_ranger', non-logarithmized data is expected. But I would very much appreciate clarification on the issue, it has been a long-standing source of confusion in our lab. Thank you.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1545
https://github.com/scverse/scanpy/issues/1545:773,security,log,logspace,773,"cell_ranger flavor of highly_variable_genes expects non-logarithmized data?; - [X ] I have checked that this issue has not already been reported. - [ X] I have confirmed this bug exists on the latest version of scanpy. - [ X] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I believe this may be a bug in documentation. It says that scanpy.pp.highly_variable_genes expects logarithmized data, except when flavor='seurat_v3'. However, after reading the reference Zheng17 for the cellRanger method (in particular, Supplementary Figure 5c), it appears that non-logarithmized data was used for calculating the dispersion. And examining the highly_variable_genes source code, I note that for method='seurat', the data is transformed back out of logspace using X=np.expm1(X) before computing dispersions, but this is not done when method='cell_ranger'. My conclusion is that the documentation should be updated to reflect that when flavor='cell_ranger', non-logarithmized data is expected. But I would very much appreciate clarification on the issue, it has been a long-standing source of confusion in our lab. Thank you.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1545
https://github.com/scverse/scanpy/issues/1545:930,security,updat,updated,930,"cell_ranger flavor of highly_variable_genes expects non-logarithmized data?; - [X ] I have checked that this issue has not already been reported. - [ X] I have confirmed this bug exists on the latest version of scanpy. - [ X] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I believe this may be a bug in documentation. It says that scanpy.pp.highly_variable_genes expects logarithmized data, except when flavor='seurat_v3'. However, after reading the reference Zheng17 for the cellRanger method (in particular, Supplementary Figure 5c), it appears that non-logarithmized data was used for calculating the dispersion. And examining the highly_variable_genes source code, I note that for method='seurat', the data is transformed back out of logspace using X=np.expm1(X) before computing dispersions, but this is not done when method='cell_ranger'. My conclusion is that the documentation should be updated to reflect that when flavor='cell_ranger', non-logarithmized data is expected. But I would very much appreciate clarification on the issue, it has been a long-standing source of confusion in our lab. Thank you.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1545
https://github.com/scverse/scanpy/issues/1545:985,security,log,logarithmized,985,"cell_ranger flavor of highly_variable_genes expects non-logarithmized data?; - [X ] I have checked that this issue has not already been reported. - [ X] I have confirmed this bug exists on the latest version of scanpy. - [ X] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I believe this may be a bug in documentation. It says that scanpy.pp.highly_variable_genes expects logarithmized data, except when flavor='seurat_v3'. However, after reading the reference Zheng17 for the cellRanger method (in particular, Supplementary Figure 5c), it appears that non-logarithmized data was used for calculating the dispersion. And examining the highly_variable_genes source code, I note that for method='seurat', the data is transformed back out of logspace using X=np.expm1(X) before computing dispersions, but this is not done when method='cell_ranger'. My conclusion is that the documentation should be updated to reflect that when flavor='cell_ranger', non-logarithmized data is expected. But I would very much appreciate clarification on the issue, it has been a long-standing source of confusion in our lab. Thank you.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1545
https://github.com/scverse/scanpy/issues/1545:56,testability,log,logarithmized,56,"cell_ranger flavor of highly_variable_genes expects non-logarithmized data?; - [X ] I have checked that this issue has not already been reported. - [ X] I have confirmed this bug exists on the latest version of scanpy. - [ X] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I believe this may be a bug in documentation. It says that scanpy.pp.highly_variable_genes expects logarithmized data, except when flavor='seurat_v3'. However, after reading the reference Zheng17 for the cellRanger method (in particular, Supplementary Figure 5c), it appears that non-logarithmized data was used for calculating the dispersion. And examining the highly_variable_genes source code, I note that for method='seurat', the data is transformed back out of logspace using X=np.expm1(X) before computing dispersions, but this is not done when method='cell_ranger'. My conclusion is that the documentation should be updated to reflect that when flavor='cell_ranger', non-logarithmized data is expected. But I would very much appreciate clarification on the issue, it has been a long-standing source of confusion in our lab. Thank you.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1545
https://github.com/scverse/scanpy/issues/1545:406,testability,log,logarithmized,406,"cell_ranger flavor of highly_variable_genes expects non-logarithmized data?; - [X ] I have checked that this issue has not already been reported. - [ X] I have confirmed this bug exists on the latest version of scanpy. - [ X] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I believe this may be a bug in documentation. It says that scanpy.pp.highly_variable_genes expects logarithmized data, except when flavor='seurat_v3'. However, after reading the reference Zheng17 for the cellRanger method (in particular, Supplementary Figure 5c), it appears that non-logarithmized data was used for calculating the dispersion. And examining the highly_variable_genes source code, I note that for method='seurat', the data is transformed back out of logspace using X=np.expm1(X) before computing dispersions, but this is not done when method='cell_ranger'. My conclusion is that the documentation should be updated to reflect that when flavor='cell_ranger', non-logarithmized data is expected. But I would very much appreciate clarification on the issue, it has been a long-standing source of confusion in our lab. Thank you.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1545
https://github.com/scverse/scanpy/issues/1545:591,testability,log,logarithmized,591,"cell_ranger flavor of highly_variable_genes expects non-logarithmized data?; - [X ] I have checked that this issue has not already been reported. - [ X] I have confirmed this bug exists on the latest version of scanpy. - [ X] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I believe this may be a bug in documentation. It says that scanpy.pp.highly_variable_genes expects logarithmized data, except when flavor='seurat_v3'. However, after reading the reference Zheng17 for the cellRanger method (in particular, Supplementary Figure 5c), it appears that non-logarithmized data was used for calculating the dispersion. And examining the highly_variable_genes source code, I note that for method='seurat', the data is transformed back out of logspace using X=np.expm1(X) before computing dispersions, but this is not done when method='cell_ranger'. My conclusion is that the documentation should be updated to reflect that when flavor='cell_ranger', non-logarithmized data is expected. But I would very much appreciate clarification on the issue, it has been a long-standing source of confusion in our lab. Thank you.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1545
https://github.com/scverse/scanpy/issues/1545:773,testability,log,logspace,773,"cell_ranger flavor of highly_variable_genes expects non-logarithmized data?; - [X ] I have checked that this issue has not already been reported. - [ X] I have confirmed this bug exists on the latest version of scanpy. - [ X] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I believe this may be a bug in documentation. It says that scanpy.pp.highly_variable_genes expects logarithmized data, except when flavor='seurat_v3'. However, after reading the reference Zheng17 for the cellRanger method (in particular, Supplementary Figure 5c), it appears that non-logarithmized data was used for calculating the dispersion. And examining the highly_variable_genes source code, I note that for method='seurat', the data is transformed back out of logspace using X=np.expm1(X) before computing dispersions, but this is not done when method='cell_ranger'. My conclusion is that the documentation should be updated to reflect that when flavor='cell_ranger', non-logarithmized data is expected. But I would very much appreciate clarification on the issue, it has been a long-standing source of confusion in our lab. Thank you.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1545
https://github.com/scverse/scanpy/issues/1545:985,testability,log,logarithmized,985,"cell_ranger flavor of highly_variable_genes expects non-logarithmized data?; - [X ] I have checked that this issue has not already been reported. - [ X] I have confirmed this bug exists on the latest version of scanpy. - [ X] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I believe this may be a bug in documentation. It says that scanpy.pp.highly_variable_genes expects logarithmized data, except when flavor='seurat_v3'. However, after reading the reference Zheng17 for the cellRanger method (in particular, Supplementary Figure 5c), it appears that non-logarithmized data was used for calculating the dispersion. And examining the highly_variable_genes source code, I note that for method='seurat', the data is transformed back out of logspace using X=np.expm1(X) before computing dispersions, but this is not done when method='cell_ranger'. My conclusion is that the documentation should be updated to reflect that when flavor='cell_ranger', non-logarithmized data is expected. But I would very much appreciate clarification on the issue, it has been a long-standing source of confusion in our lab. Thank you.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1545
https://github.com/scverse/scanpy/issues/1545:160,usability,confirm,confirmed,160,"cell_ranger flavor of highly_variable_genes expects non-logarithmized data?; - [X ] I have checked that this issue has not already been reported. - [ X] I have confirmed this bug exists on the latest version of scanpy. - [ X] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I believe this may be a bug in documentation. It says that scanpy.pp.highly_variable_genes expects logarithmized data, except when flavor='seurat_v3'. However, after reading the reference Zheng17 for the cellRanger method (in particular, Supplementary Figure 5c), it appears that non-logarithmized data was used for calculating the dispersion. And examining the highly_variable_genes source code, I note that for method='seurat', the data is transformed back out of logspace using X=np.expm1(X) before computing dispersions, but this is not done when method='cell_ranger'. My conclusion is that the documentation should be updated to reflect that when flavor='cell_ranger', non-logarithmized data is expected. But I would very much appreciate clarification on the issue, it has been a long-standing source of confusion in our lab. Thank you.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1545
https://github.com/scverse/scanpy/issues/1545:244,usability,confirm,confirmed,244,"cell_ranger flavor of highly_variable_genes expects non-logarithmized data?; - [X ] I have checked that this issue has not already been reported. - [ X] I have confirmed this bug exists on the latest version of scanpy. - [ X] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I believe this may be a bug in documentation. It says that scanpy.pp.highly_variable_genes expects logarithmized data, except when flavor='seurat_v3'. However, after reading the reference Zheng17 for the cellRanger method (in particular, Supplementary Figure 5c), it appears that non-logarithmized data was used for calculating the dispersion. And examining the highly_variable_genes source code, I note that for method='seurat', the data is transformed back out of logspace using X=np.expm1(X) before computing dispersions, but this is not done when method='cell_ranger'. My conclusion is that the documentation should be updated to reflect that when flavor='cell_ranger', non-logarithmized data is expected. But I would very much appreciate clarification on the issue, it has been a long-standing source of confusion in our lab. Thank you.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1545
https://github.com/scverse/scanpy/issues/1545:338,usability,document,documentation,338,"cell_ranger flavor of highly_variable_genes expects non-logarithmized data?; - [X ] I have checked that this issue has not already been reported. - [ X] I have confirmed this bug exists on the latest version of scanpy. - [ X] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I believe this may be a bug in documentation. It says that scanpy.pp.highly_variable_genes expects logarithmized data, except when flavor='seurat_v3'. However, after reading the reference Zheng17 for the cellRanger method (in particular, Supplementary Figure 5c), it appears that non-logarithmized data was used for calculating the dispersion. And examining the highly_variable_genes source code, I note that for method='seurat', the data is transformed back out of logspace using X=np.expm1(X) before computing dispersions, but this is not done when method='cell_ranger'. My conclusion is that the documentation should be updated to reflect that when flavor='cell_ranger', non-logarithmized data is expected. But I would very much appreciate clarification on the issue, it has been a long-standing source of confusion in our lab. Thank you.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1545
https://github.com/scverse/scanpy/issues/1545:906,usability,document,documentation,906,"cell_ranger flavor of highly_variable_genes expects non-logarithmized data?; - [X ] I have checked that this issue has not already been reported. - [ X] I have confirmed this bug exists on the latest version of scanpy. - [ X] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I believe this may be a bug in documentation. It says that scanpy.pp.highly_variable_genes expects logarithmized data, except when flavor='seurat_v3'. However, after reading the reference Zheng17 for the cellRanger method (in particular, Supplementary Figure 5c), it appears that non-logarithmized data was used for calculating the dispersion. And examining the highly_variable_genes source code, I note that for method='seurat', the data is transformed back out of logspace using X=np.expm1(X) before computing dispersions, but this is not done when method='cell_ranger'. My conclusion is that the documentation should be updated to reflect that when flavor='cell_ranger', non-logarithmized data is expected. But I would very much appreciate clarification on the issue, it has been a long-standing source of confusion in our lab. Thank you.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1545
https://github.com/scverse/scanpy/issues/1546:20,availability,error,error,20,"sc.pl.violin throws error if adata does not have .raw; Ping @fidelram. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc3k_processed().raw.to_adata(). sc.pl.violin(pbmc, ['CD79A', 'MS4A1'], groupby='louvain' ). ```. ```pytb. ---------------------------------------------------------------------------. AssertionError Traceback (most recent call last). <ipython-input-7-594171c15db1> in <module>. ----> 1 sc.pl.violin(pbmc, ['CD79A', 'MS4A1'], groupby='louvain' ). ~/github/scanpy/scanpy/plotting/_anndata.py in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 710 . 711 if groupby is not None:. --> 712 obs_df = get.obs_df(adata, keys=[groupby] + keys, layer=layer, use_raw=use_raw). 713 if kwds.get('palette', None) is None:. 714 if not is_categorical_dtype(adata.obs[groupby]):. ~/github/scanpy/scanpy/get.py in obs_df(adata, keys, obsm_keys, layer, gene_symbols, use_raw). 200 # add var values. 201 if len(var_names) > 0:. --> 202 X = _get_obs_rep(adata, layer=layer, use_raw=use_raw). 203 if use_raw:. 204 var_idx = adata.raw.var_names.get_indexer(var_names). ~/github/scanpy/scanpy/get.py in _get_obs_rep(adata, use_raw, layer, obsm, obsp). 341 return adata.obsp[obsp]. 342 else:. --> 343 assert False, (. 344 ""That was unexpected. Please report this bug at:\n\n\t"". 345 "" https://github.com/theislab/scanpy/issues"". AssertionError: That was unexpected. Please report this bug at:. 	 https://github.com/theislab/scanpy/issues. ```. The issue seems to be that `use_raw=None` is not handled by `_get_obs_rep`. I think this should error, but the error should just be that `None` isn't a valid value for this argument. The real issue is that `sc.pl.violin` is not handling `use_raw` correctly.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1546
https://github.com/scverse/scanpy/issues/1546:55,availability,Ping,Ping,55,"sc.pl.violin throws error if adata does not have .raw; Ping @fidelram. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc3k_processed().raw.to_adata(). sc.pl.violin(pbmc, ['CD79A', 'MS4A1'], groupby='louvain' ). ```. ```pytb. ---------------------------------------------------------------------------. AssertionError Traceback (most recent call last). <ipython-input-7-594171c15db1> in <module>. ----> 1 sc.pl.violin(pbmc, ['CD79A', 'MS4A1'], groupby='louvain' ). ~/github/scanpy/scanpy/plotting/_anndata.py in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 710 . 711 if groupby is not None:. --> 712 obs_df = get.obs_df(adata, keys=[groupby] + keys, layer=layer, use_raw=use_raw). 713 if kwds.get('palette', None) is None:. 714 if not is_categorical_dtype(adata.obs[groupby]):. ~/github/scanpy/scanpy/get.py in obs_df(adata, keys, obsm_keys, layer, gene_symbols, use_raw). 200 # add var values. 201 if len(var_names) > 0:. --> 202 X = _get_obs_rep(adata, layer=layer, use_raw=use_raw). 203 if use_raw:. 204 var_idx = adata.raw.var_names.get_indexer(var_names). ~/github/scanpy/scanpy/get.py in _get_obs_rep(adata, use_raw, layer, obsm, obsp). 341 return adata.obsp[obsp]. 342 else:. --> 343 assert False, (. 344 ""That was unexpected. Please report this bug at:\n\n\t"". 345 "" https://github.com/theislab/scanpy/issues"". AssertionError: That was unexpected. Please report this bug at:. 	 https://github.com/theislab/scanpy/issues. ```. The issue seems to be that `use_raw=None` is not handled by `_get_obs_rep`. I think this should error, but the error should just be that `None` isn't a valid value for this argument. The real issue is that `sc.pl.violin` is not handling `use_raw` correctly.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1546
https://github.com/scverse/scanpy/issues/1546:1643,availability,error,error,1643,"sc.pl.violin throws error if adata does not have .raw; Ping @fidelram. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc3k_processed().raw.to_adata(). sc.pl.violin(pbmc, ['CD79A', 'MS4A1'], groupby='louvain' ). ```. ```pytb. ---------------------------------------------------------------------------. AssertionError Traceback (most recent call last). <ipython-input-7-594171c15db1> in <module>. ----> 1 sc.pl.violin(pbmc, ['CD79A', 'MS4A1'], groupby='louvain' ). ~/github/scanpy/scanpy/plotting/_anndata.py in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 710 . 711 if groupby is not None:. --> 712 obs_df = get.obs_df(adata, keys=[groupby] + keys, layer=layer, use_raw=use_raw). 713 if kwds.get('palette', None) is None:. 714 if not is_categorical_dtype(adata.obs[groupby]):. ~/github/scanpy/scanpy/get.py in obs_df(adata, keys, obsm_keys, layer, gene_symbols, use_raw). 200 # add var values. 201 if len(var_names) > 0:. --> 202 X = _get_obs_rep(adata, layer=layer, use_raw=use_raw). 203 if use_raw:. 204 var_idx = adata.raw.var_names.get_indexer(var_names). ~/github/scanpy/scanpy/get.py in _get_obs_rep(adata, use_raw, layer, obsm, obsp). 341 return adata.obsp[obsp]. 342 else:. --> 343 assert False, (. 344 ""That was unexpected. Please report this bug at:\n\n\t"". 345 "" https://github.com/theislab/scanpy/issues"". AssertionError: That was unexpected. Please report this bug at:. 	 https://github.com/theislab/scanpy/issues. ```. The issue seems to be that `use_raw=None` is not handled by `_get_obs_rep`. I think this should error, but the error should just be that `None` isn't a valid value for this argument. The real issue is that `sc.pl.violin` is not handling `use_raw` correctly.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1546
https://github.com/scverse/scanpy/issues/1546:1658,availability,error,error,1658,"sc.pl.violin throws error if adata does not have .raw; Ping @fidelram. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc3k_processed().raw.to_adata(). sc.pl.violin(pbmc, ['CD79A', 'MS4A1'], groupby='louvain' ). ```. ```pytb. ---------------------------------------------------------------------------. AssertionError Traceback (most recent call last). <ipython-input-7-594171c15db1> in <module>. ----> 1 sc.pl.violin(pbmc, ['CD79A', 'MS4A1'], groupby='louvain' ). ~/github/scanpy/scanpy/plotting/_anndata.py in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 710 . 711 if groupby is not None:. --> 712 obs_df = get.obs_df(adata, keys=[groupby] + keys, layer=layer, use_raw=use_raw). 713 if kwds.get('palette', None) is None:. 714 if not is_categorical_dtype(adata.obs[groupby]):. ~/github/scanpy/scanpy/get.py in obs_df(adata, keys, obsm_keys, layer, gene_symbols, use_raw). 200 # add var values. 201 if len(var_names) > 0:. --> 202 X = _get_obs_rep(adata, layer=layer, use_raw=use_raw). 203 if use_raw:. 204 var_idx = adata.raw.var_names.get_indexer(var_names). ~/github/scanpy/scanpy/get.py in _get_obs_rep(adata, use_raw, layer, obsm, obsp). 341 return adata.obsp[obsp]. 342 else:. --> 343 assert False, (. 344 ""That was unexpected. Please report this bug at:\n\n\t"". 345 "" https://github.com/theislab/scanpy/issues"". AssertionError: That was unexpected. Please report this bug at:. 	 https://github.com/theislab/scanpy/issues. ```. The issue seems to be that `use_raw=None` is not handled by `_get_obs_rep`. I think this should error, but the error should just be that `None` isn't a valid value for this argument. The real issue is that `sc.pl.violin` is not handling `use_raw` correctly.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1546
https://github.com/scverse/scanpy/issues/1546:393,deployability,modul,module,393,"sc.pl.violin throws error if adata does not have .raw; Ping @fidelram. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc3k_processed().raw.to_adata(). sc.pl.violin(pbmc, ['CD79A', 'MS4A1'], groupby='louvain' ). ```. ```pytb. ---------------------------------------------------------------------------. AssertionError Traceback (most recent call last). <ipython-input-7-594171c15db1> in <module>. ----> 1 sc.pl.violin(pbmc, ['CD79A', 'MS4A1'], groupby='louvain' ). ~/github/scanpy/scanpy/plotting/_anndata.py in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 710 . 711 if groupby is not None:. --> 712 obs_df = get.obs_df(adata, keys=[groupby] + keys, layer=layer, use_raw=use_raw). 713 if kwds.get('palette', None) is None:. 714 if not is_categorical_dtype(adata.obs[groupby]):. ~/github/scanpy/scanpy/get.py in obs_df(adata, keys, obsm_keys, layer, gene_symbols, use_raw). 200 # add var values. 201 if len(var_names) > 0:. --> 202 X = _get_obs_rep(adata, layer=layer, use_raw=use_raw). 203 if use_raw:. 204 var_idx = adata.raw.var_names.get_indexer(var_names). ~/github/scanpy/scanpy/get.py in _get_obs_rep(adata, use_raw, layer, obsm, obsp). 341 return adata.obsp[obsp]. 342 else:. --> 343 assert False, (. 344 ""That was unexpected. Please report this bug at:\n\n\t"". 345 "" https://github.com/theislab/scanpy/issues"". AssertionError: That was unexpected. Please report this bug at:. 	 https://github.com/theislab/scanpy/issues. ```. The issue seems to be that `use_raw=None` is not handled by `_get_obs_rep`. I think this should error, but the error should just be that `None` isn't a valid value for this argument. The real issue is that `sc.pl.violin` is not handling `use_raw` correctly.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1546
https://github.com/scverse/scanpy/issues/1546:546,deployability,log,log,546,"sc.pl.violin throws error if adata does not have .raw; Ping @fidelram. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc3k_processed().raw.to_adata(). sc.pl.violin(pbmc, ['CD79A', 'MS4A1'], groupby='louvain' ). ```. ```pytb. ---------------------------------------------------------------------------. AssertionError Traceback (most recent call last). <ipython-input-7-594171c15db1> in <module>. ----> 1 sc.pl.violin(pbmc, ['CD79A', 'MS4A1'], groupby='louvain' ). ~/github/scanpy/scanpy/plotting/_anndata.py in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 710 . 711 if groupby is not None:. --> 712 obs_df = get.obs_df(adata, keys=[groupby] + keys, layer=layer, use_raw=use_raw). 713 if kwds.get('palette', None) is None:. 714 if not is_categorical_dtype(adata.obs[groupby]):. ~/github/scanpy/scanpy/get.py in obs_df(adata, keys, obsm_keys, layer, gene_symbols, use_raw). 200 # add var values. 201 if len(var_names) > 0:. --> 202 X = _get_obs_rep(adata, layer=layer, use_raw=use_raw). 203 if use_raw:. 204 var_idx = adata.raw.var_names.get_indexer(var_names). ~/github/scanpy/scanpy/get.py in _get_obs_rep(adata, use_raw, layer, obsm, obsp). 341 return adata.obsp[obsp]. 342 else:. --> 343 assert False, (. 344 ""That was unexpected. Please report this bug at:\n\n\t"". 345 "" https://github.com/theislab/scanpy/issues"". AssertionError: That was unexpected. Please report this bug at:. 	 https://github.com/theislab/scanpy/issues. ```. The issue seems to be that `use_raw=None` is not handled by `_get_obs_rep`. I think this should error, but the error should just be that `None` isn't a valid value for this argument. The real issue is that `sc.pl.violin` is not handling `use_raw` correctly.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1546
https://github.com/scverse/scanpy/issues/1546:592,deployability,scale,scale,592,"sc.pl.violin throws error if adata does not have .raw; Ping @fidelram. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc3k_processed().raw.to_adata(). sc.pl.violin(pbmc, ['CD79A', 'MS4A1'], groupby='louvain' ). ```. ```pytb. ---------------------------------------------------------------------------. AssertionError Traceback (most recent call last). <ipython-input-7-594171c15db1> in <module>. ----> 1 sc.pl.violin(pbmc, ['CD79A', 'MS4A1'], groupby='louvain' ). ~/github/scanpy/scanpy/plotting/_anndata.py in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 710 . 711 if groupby is not None:. --> 712 obs_df = get.obs_df(adata, keys=[groupby] + keys, layer=layer, use_raw=use_raw). 713 if kwds.get('palette', None) is None:. 714 if not is_categorical_dtype(adata.obs[groupby]):. ~/github/scanpy/scanpy/get.py in obs_df(adata, keys, obsm_keys, layer, gene_symbols, use_raw). 200 # add var values. 201 if len(var_names) > 0:. --> 202 X = _get_obs_rep(adata, layer=layer, use_raw=use_raw). 203 if use_raw:. 204 var_idx = adata.raw.var_names.get_indexer(var_names). ~/github/scanpy/scanpy/get.py in _get_obs_rep(adata, use_raw, layer, obsm, obsp). 341 return adata.obsp[obsp]. 342 else:. --> 343 assert False, (. 344 ""That was unexpected. Please report this bug at:\n\n\t"". 345 "" https://github.com/theislab/scanpy/issues"". AssertionError: That was unexpected. Please report this bug at:. 	 https://github.com/theislab/scanpy/issues. ```. The issue seems to be that `use_raw=None` is not handled by `_get_obs_rep`. I think this should error, but the error should just be that `None` isn't a valid value for this argument. The real issue is that `sc.pl.violin` is not handling `use_raw` correctly.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1546
https://github.com/scverse/scanpy/issues/1546:592,energy efficiency,scale,scale,592,"sc.pl.violin throws error if adata does not have .raw; Ping @fidelram. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc3k_processed().raw.to_adata(). sc.pl.violin(pbmc, ['CD79A', 'MS4A1'], groupby='louvain' ). ```. ```pytb. ---------------------------------------------------------------------------. AssertionError Traceback (most recent call last). <ipython-input-7-594171c15db1> in <module>. ----> 1 sc.pl.violin(pbmc, ['CD79A', 'MS4A1'], groupby='louvain' ). ~/github/scanpy/scanpy/plotting/_anndata.py in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 710 . 711 if groupby is not None:. --> 712 obs_df = get.obs_df(adata, keys=[groupby] + keys, layer=layer, use_raw=use_raw). 713 if kwds.get('palette', None) is None:. 714 if not is_categorical_dtype(adata.obs[groupby]):. ~/github/scanpy/scanpy/get.py in obs_df(adata, keys, obsm_keys, layer, gene_symbols, use_raw). 200 # add var values. 201 if len(var_names) > 0:. --> 202 X = _get_obs_rep(adata, layer=layer, use_raw=use_raw). 203 if use_raw:. 204 var_idx = adata.raw.var_names.get_indexer(var_names). ~/github/scanpy/scanpy/get.py in _get_obs_rep(adata, use_raw, layer, obsm, obsp). 341 return adata.obsp[obsp]. 342 else:. --> 343 assert False, (. 344 ""That was unexpected. Please report this bug at:\n\n\t"". 345 "" https://github.com/theislab/scanpy/issues"". AssertionError: That was unexpected. Please report this bug at:. 	 https://github.com/theislab/scanpy/issues. ```. The issue seems to be that `use_raw=None` is not handled by `_get_obs_rep`. I think this should error, but the error should just be that `None` isn't a valid value for this argument. The real issue is that `sc.pl.violin` is not handling `use_raw` correctly.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1546
https://github.com/scverse/scanpy/issues/1546:393,modifiability,modul,module,393,"sc.pl.violin throws error if adata does not have .raw; Ping @fidelram. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc3k_processed().raw.to_adata(). sc.pl.violin(pbmc, ['CD79A', 'MS4A1'], groupby='louvain' ). ```. ```pytb. ---------------------------------------------------------------------------. AssertionError Traceback (most recent call last). <ipython-input-7-594171c15db1> in <module>. ----> 1 sc.pl.violin(pbmc, ['CD79A', 'MS4A1'], groupby='louvain' ). ~/github/scanpy/scanpy/plotting/_anndata.py in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 710 . 711 if groupby is not None:. --> 712 obs_df = get.obs_df(adata, keys=[groupby] + keys, layer=layer, use_raw=use_raw). 713 if kwds.get('palette', None) is None:. 714 if not is_categorical_dtype(adata.obs[groupby]):. ~/github/scanpy/scanpy/get.py in obs_df(adata, keys, obsm_keys, layer, gene_symbols, use_raw). 200 # add var values. 201 if len(var_names) > 0:. --> 202 X = _get_obs_rep(adata, layer=layer, use_raw=use_raw). 203 if use_raw:. 204 var_idx = adata.raw.var_names.get_indexer(var_names). ~/github/scanpy/scanpy/get.py in _get_obs_rep(adata, use_raw, layer, obsm, obsp). 341 return adata.obsp[obsp]. 342 else:. --> 343 assert False, (. 344 ""That was unexpected. Please report this bug at:\n\n\t"". 345 "" https://github.com/theislab/scanpy/issues"". AssertionError: That was unexpected. Please report this bug at:. 	 https://github.com/theislab/scanpy/issues. ```. The issue seems to be that `use_raw=None` is not handled by `_get_obs_rep`. I think this should error, but the error should just be that `None` isn't a valid value for this argument. The real issue is that `sc.pl.violin` is not handling `use_raw` correctly.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1546
https://github.com/scverse/scanpy/issues/1546:585,modifiability,layer,layer,585,"sc.pl.violin throws error if adata does not have .raw; Ping @fidelram. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc3k_processed().raw.to_adata(). sc.pl.violin(pbmc, ['CD79A', 'MS4A1'], groupby='louvain' ). ```. ```pytb. ---------------------------------------------------------------------------. AssertionError Traceback (most recent call last). <ipython-input-7-594171c15db1> in <module>. ----> 1 sc.pl.violin(pbmc, ['CD79A', 'MS4A1'], groupby='louvain' ). ~/github/scanpy/scanpy/plotting/_anndata.py in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 710 . 711 if groupby is not None:. --> 712 obs_df = get.obs_df(adata, keys=[groupby] + keys, layer=layer, use_raw=use_raw). 713 if kwds.get('palette', None) is None:. 714 if not is_categorical_dtype(adata.obs[groupby]):. ~/github/scanpy/scanpy/get.py in obs_df(adata, keys, obsm_keys, layer, gene_symbols, use_raw). 200 # add var values. 201 if len(var_names) > 0:. --> 202 X = _get_obs_rep(adata, layer=layer, use_raw=use_raw). 203 if use_raw:. 204 var_idx = adata.raw.var_names.get_indexer(var_names). ~/github/scanpy/scanpy/get.py in _get_obs_rep(adata, use_raw, layer, obsm, obsp). 341 return adata.obsp[obsp]. 342 else:. --> 343 assert False, (. 344 ""That was unexpected. Please report this bug at:\n\n\t"". 345 "" https://github.com/theislab/scanpy/issues"". AssertionError: That was unexpected. Please report this bug at:. 	 https://github.com/theislab/scanpy/issues. ```. The issue seems to be that `use_raw=None` is not handled by `_get_obs_rep`. I think this should error, but the error should just be that `None` isn't a valid value for this argument. The real issue is that `sc.pl.violin` is not handling `use_raw` correctly.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1546
https://github.com/scverse/scanpy/issues/1546:592,modifiability,scal,scale,592,"sc.pl.violin throws error if adata does not have .raw; Ping @fidelram. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc3k_processed().raw.to_adata(). sc.pl.violin(pbmc, ['CD79A', 'MS4A1'], groupby='louvain' ). ```. ```pytb. ---------------------------------------------------------------------------. AssertionError Traceback (most recent call last). <ipython-input-7-594171c15db1> in <module>. ----> 1 sc.pl.violin(pbmc, ['CD79A', 'MS4A1'], groupby='louvain' ). ~/github/scanpy/scanpy/plotting/_anndata.py in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 710 . 711 if groupby is not None:. --> 712 obs_df = get.obs_df(adata, keys=[groupby] + keys, layer=layer, use_raw=use_raw). 713 if kwds.get('palette', None) is None:. 714 if not is_categorical_dtype(adata.obs[groupby]):. ~/github/scanpy/scanpy/get.py in obs_df(adata, keys, obsm_keys, layer, gene_symbols, use_raw). 200 # add var values. 201 if len(var_names) > 0:. --> 202 X = _get_obs_rep(adata, layer=layer, use_raw=use_raw). 203 if use_raw:. 204 var_idx = adata.raw.var_names.get_indexer(var_names). ~/github/scanpy/scanpy/get.py in _get_obs_rep(adata, use_raw, layer, obsm, obsp). 341 return adata.obsp[obsp]. 342 else:. --> 343 assert False, (. 344 ""That was unexpected. Please report this bug at:\n\n\t"". 345 "" https://github.com/theislab/scanpy/issues"". AssertionError: That was unexpected. Please report this bug at:. 	 https://github.com/theislab/scanpy/issues. ```. The issue seems to be that `use_raw=None` is not handled by `_get_obs_rep`. I think this should error, but the error should just be that `None` isn't a valid value for this argument. The real issue is that `sc.pl.violin` is not handling `use_raw` correctly.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1546
https://github.com/scverse/scanpy/issues/1546:763,modifiability,layer,layer,763,"sc.pl.violin throws error if adata does not have .raw; Ping @fidelram. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc3k_processed().raw.to_adata(). sc.pl.violin(pbmc, ['CD79A', 'MS4A1'], groupby='louvain' ). ```. ```pytb. ---------------------------------------------------------------------------. AssertionError Traceback (most recent call last). <ipython-input-7-594171c15db1> in <module>. ----> 1 sc.pl.violin(pbmc, ['CD79A', 'MS4A1'], groupby='louvain' ). ~/github/scanpy/scanpy/plotting/_anndata.py in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 710 . 711 if groupby is not None:. --> 712 obs_df = get.obs_df(adata, keys=[groupby] + keys, layer=layer, use_raw=use_raw). 713 if kwds.get('palette', None) is None:. 714 if not is_categorical_dtype(adata.obs[groupby]):. ~/github/scanpy/scanpy/get.py in obs_df(adata, keys, obsm_keys, layer, gene_symbols, use_raw). 200 # add var values. 201 if len(var_names) > 0:. --> 202 X = _get_obs_rep(adata, layer=layer, use_raw=use_raw). 203 if use_raw:. 204 var_idx = adata.raw.var_names.get_indexer(var_names). ~/github/scanpy/scanpy/get.py in _get_obs_rep(adata, use_raw, layer, obsm, obsp). 341 return adata.obsp[obsp]. 342 else:. --> 343 assert False, (. 344 ""That was unexpected. Please report this bug at:\n\n\t"". 345 "" https://github.com/theislab/scanpy/issues"". AssertionError: That was unexpected. Please report this bug at:. 	 https://github.com/theislab/scanpy/issues. ```. The issue seems to be that `use_raw=None` is not handled by `_get_obs_rep`. I think this should error, but the error should just be that `None` isn't a valid value for this argument. The real issue is that `sc.pl.violin` is not handling `use_raw` correctly.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1546
https://github.com/scverse/scanpy/issues/1546:769,modifiability,layer,layer,769,"sc.pl.violin throws error if adata does not have .raw; Ping @fidelram. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc3k_processed().raw.to_adata(). sc.pl.violin(pbmc, ['CD79A', 'MS4A1'], groupby='louvain' ). ```. ```pytb. ---------------------------------------------------------------------------. AssertionError Traceback (most recent call last). <ipython-input-7-594171c15db1> in <module>. ----> 1 sc.pl.violin(pbmc, ['CD79A', 'MS4A1'], groupby='louvain' ). ~/github/scanpy/scanpy/plotting/_anndata.py in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 710 . 711 if groupby is not None:. --> 712 obs_df = get.obs_df(adata, keys=[groupby] + keys, layer=layer, use_raw=use_raw). 713 if kwds.get('palette', None) is None:. 714 if not is_categorical_dtype(adata.obs[groupby]):. ~/github/scanpy/scanpy/get.py in obs_df(adata, keys, obsm_keys, layer, gene_symbols, use_raw). 200 # add var values. 201 if len(var_names) > 0:. --> 202 X = _get_obs_rep(adata, layer=layer, use_raw=use_raw). 203 if use_raw:. 204 var_idx = adata.raw.var_names.get_indexer(var_names). ~/github/scanpy/scanpy/get.py in _get_obs_rep(adata, use_raw, layer, obsm, obsp). 341 return adata.obsp[obsp]. 342 else:. --> 343 assert False, (. 344 ""That was unexpected. Please report this bug at:\n\n\t"". 345 "" https://github.com/theislab/scanpy/issues"". AssertionError: That was unexpected. Please report this bug at:. 	 https://github.com/theislab/scanpy/issues. ```. The issue seems to be that `use_raw=None` is not handled by `_get_obs_rep`. I think this should error, but the error should just be that `None` isn't a valid value for this argument. The real issue is that `sc.pl.violin` is not handling `use_raw` correctly.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1546
https://github.com/scverse/scanpy/issues/1546:955,modifiability,layer,layer,955,"sc.pl.violin throws error if adata does not have .raw; Ping @fidelram. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc3k_processed().raw.to_adata(). sc.pl.violin(pbmc, ['CD79A', 'MS4A1'], groupby='louvain' ). ```. ```pytb. ---------------------------------------------------------------------------. AssertionError Traceback (most recent call last). <ipython-input-7-594171c15db1> in <module>. ----> 1 sc.pl.violin(pbmc, ['CD79A', 'MS4A1'], groupby='louvain' ). ~/github/scanpy/scanpy/plotting/_anndata.py in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 710 . 711 if groupby is not None:. --> 712 obs_df = get.obs_df(adata, keys=[groupby] + keys, layer=layer, use_raw=use_raw). 713 if kwds.get('palette', None) is None:. 714 if not is_categorical_dtype(adata.obs[groupby]):. ~/github/scanpy/scanpy/get.py in obs_df(adata, keys, obsm_keys, layer, gene_symbols, use_raw). 200 # add var values. 201 if len(var_names) > 0:. --> 202 X = _get_obs_rep(adata, layer=layer, use_raw=use_raw). 203 if use_raw:. 204 var_idx = adata.raw.var_names.get_indexer(var_names). ~/github/scanpy/scanpy/get.py in _get_obs_rep(adata, use_raw, layer, obsm, obsp). 341 return adata.obsp[obsp]. 342 else:. --> 343 assert False, (. 344 ""That was unexpected. Please report this bug at:\n\n\t"". 345 "" https://github.com/theislab/scanpy/issues"". AssertionError: That was unexpected. Please report this bug at:. 	 https://github.com/theislab/scanpy/issues. ```. The issue seems to be that `use_raw=None` is not handled by `_get_obs_rep`. I think this should error, but the error should just be that `None` isn't a valid value for this argument. The real issue is that `sc.pl.violin` is not handling `use_raw` correctly.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1546
https://github.com/scverse/scanpy/issues/1546:1068,modifiability,layer,layer,1068,"sc.pl.violin throws error if adata does not have .raw; Ping @fidelram. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc3k_processed().raw.to_adata(). sc.pl.violin(pbmc, ['CD79A', 'MS4A1'], groupby='louvain' ). ```. ```pytb. ---------------------------------------------------------------------------. AssertionError Traceback (most recent call last). <ipython-input-7-594171c15db1> in <module>. ----> 1 sc.pl.violin(pbmc, ['CD79A', 'MS4A1'], groupby='louvain' ). ~/github/scanpy/scanpy/plotting/_anndata.py in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 710 . 711 if groupby is not None:. --> 712 obs_df = get.obs_df(adata, keys=[groupby] + keys, layer=layer, use_raw=use_raw). 713 if kwds.get('palette', None) is None:. 714 if not is_categorical_dtype(adata.obs[groupby]):. ~/github/scanpy/scanpy/get.py in obs_df(adata, keys, obsm_keys, layer, gene_symbols, use_raw). 200 # add var values. 201 if len(var_names) > 0:. --> 202 X = _get_obs_rep(adata, layer=layer, use_raw=use_raw). 203 if use_raw:. 204 var_idx = adata.raw.var_names.get_indexer(var_names). ~/github/scanpy/scanpy/get.py in _get_obs_rep(adata, use_raw, layer, obsm, obsp). 341 return adata.obsp[obsp]. 342 else:. --> 343 assert False, (. 344 ""That was unexpected. Please report this bug at:\n\n\t"". 345 "" https://github.com/theislab/scanpy/issues"". AssertionError: That was unexpected. Please report this bug at:. 	 https://github.com/theislab/scanpy/issues. ```. The issue seems to be that `use_raw=None` is not handled by `_get_obs_rep`. I think this should error, but the error should just be that `None` isn't a valid value for this argument. The real issue is that `sc.pl.violin` is not handling `use_raw` correctly.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1546
https://github.com/scverse/scanpy/issues/1546:1074,modifiability,layer,layer,1074,"sc.pl.violin throws error if adata does not have .raw; Ping @fidelram. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc3k_processed().raw.to_adata(). sc.pl.violin(pbmc, ['CD79A', 'MS4A1'], groupby='louvain' ). ```. ```pytb. ---------------------------------------------------------------------------. AssertionError Traceback (most recent call last). <ipython-input-7-594171c15db1> in <module>. ----> 1 sc.pl.violin(pbmc, ['CD79A', 'MS4A1'], groupby='louvain' ). ~/github/scanpy/scanpy/plotting/_anndata.py in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 710 . 711 if groupby is not None:. --> 712 obs_df = get.obs_df(adata, keys=[groupby] + keys, layer=layer, use_raw=use_raw). 713 if kwds.get('palette', None) is None:. 714 if not is_categorical_dtype(adata.obs[groupby]):. ~/github/scanpy/scanpy/get.py in obs_df(adata, keys, obsm_keys, layer, gene_symbols, use_raw). 200 # add var values. 201 if len(var_names) > 0:. --> 202 X = _get_obs_rep(adata, layer=layer, use_raw=use_raw). 203 if use_raw:. 204 var_idx = adata.raw.var_names.get_indexer(var_names). ~/github/scanpy/scanpy/get.py in _get_obs_rep(adata, use_raw, layer, obsm, obsp). 341 return adata.obsp[obsp]. 342 else:. --> 343 assert False, (. 344 ""That was unexpected. Please report this bug at:\n\n\t"". 345 "" https://github.com/theislab/scanpy/issues"". AssertionError: That was unexpected. Please report this bug at:. 	 https://github.com/theislab/scanpy/issues. ```. The issue seems to be that `use_raw=None` is not handled by `_get_obs_rep`. I think this should error, but the error should just be that `None` isn't a valid value for this argument. The real issue is that `sc.pl.violin` is not handling `use_raw` correctly.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1546
https://github.com/scverse/scanpy/issues/1546:1236,modifiability,layer,layer,1236,"sc.pl.violin throws error if adata does not have .raw; Ping @fidelram. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc3k_processed().raw.to_adata(). sc.pl.violin(pbmc, ['CD79A', 'MS4A1'], groupby='louvain' ). ```. ```pytb. ---------------------------------------------------------------------------. AssertionError Traceback (most recent call last). <ipython-input-7-594171c15db1> in <module>. ----> 1 sc.pl.violin(pbmc, ['CD79A', 'MS4A1'], groupby='louvain' ). ~/github/scanpy/scanpy/plotting/_anndata.py in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 710 . 711 if groupby is not None:. --> 712 obs_df = get.obs_df(adata, keys=[groupby] + keys, layer=layer, use_raw=use_raw). 713 if kwds.get('palette', None) is None:. 714 if not is_categorical_dtype(adata.obs[groupby]):. ~/github/scanpy/scanpy/get.py in obs_df(adata, keys, obsm_keys, layer, gene_symbols, use_raw). 200 # add var values. 201 if len(var_names) > 0:. --> 202 X = _get_obs_rep(adata, layer=layer, use_raw=use_raw). 203 if use_raw:. 204 var_idx = adata.raw.var_names.get_indexer(var_names). ~/github/scanpy/scanpy/get.py in _get_obs_rep(adata, use_raw, layer, obsm, obsp). 341 return adata.obsp[obsp]. 342 else:. --> 343 assert False, (. 344 ""That was unexpected. Please report this bug at:\n\n\t"". 345 "" https://github.com/theislab/scanpy/issues"". AssertionError: That was unexpected. Please report this bug at:. 	 https://github.com/theislab/scanpy/issues. ```. The issue seems to be that `use_raw=None` is not handled by `_get_obs_rep`. I think this should error, but the error should just be that `None` isn't a valid value for this argument. The real issue is that `sc.pl.violin` is not handling `use_raw` correctly.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1546
https://github.com/scverse/scanpy/issues/1546:20,performance,error,error,20,"sc.pl.violin throws error if adata does not have .raw; Ping @fidelram. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc3k_processed().raw.to_adata(). sc.pl.violin(pbmc, ['CD79A', 'MS4A1'], groupby='louvain' ). ```. ```pytb. ---------------------------------------------------------------------------. AssertionError Traceback (most recent call last). <ipython-input-7-594171c15db1> in <module>. ----> 1 sc.pl.violin(pbmc, ['CD79A', 'MS4A1'], groupby='louvain' ). ~/github/scanpy/scanpy/plotting/_anndata.py in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 710 . 711 if groupby is not None:. --> 712 obs_df = get.obs_df(adata, keys=[groupby] + keys, layer=layer, use_raw=use_raw). 713 if kwds.get('palette', None) is None:. 714 if not is_categorical_dtype(adata.obs[groupby]):. ~/github/scanpy/scanpy/get.py in obs_df(adata, keys, obsm_keys, layer, gene_symbols, use_raw). 200 # add var values. 201 if len(var_names) > 0:. --> 202 X = _get_obs_rep(adata, layer=layer, use_raw=use_raw). 203 if use_raw:. 204 var_idx = adata.raw.var_names.get_indexer(var_names). ~/github/scanpy/scanpy/get.py in _get_obs_rep(adata, use_raw, layer, obsm, obsp). 341 return adata.obsp[obsp]. 342 else:. --> 343 assert False, (. 344 ""That was unexpected. Please report this bug at:\n\n\t"". 345 "" https://github.com/theislab/scanpy/issues"". AssertionError: That was unexpected. Please report this bug at:. 	 https://github.com/theislab/scanpy/issues. ```. The issue seems to be that `use_raw=None` is not handled by `_get_obs_rep`. I think this should error, but the error should just be that `None` isn't a valid value for this argument. The real issue is that `sc.pl.violin` is not handling `use_raw` correctly.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1546
https://github.com/scverse/scanpy/issues/1546:592,performance,scale,scale,592,"sc.pl.violin throws error if adata does not have .raw; Ping @fidelram. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc3k_processed().raw.to_adata(). sc.pl.violin(pbmc, ['CD79A', 'MS4A1'], groupby='louvain' ). ```. ```pytb. ---------------------------------------------------------------------------. AssertionError Traceback (most recent call last). <ipython-input-7-594171c15db1> in <module>. ----> 1 sc.pl.violin(pbmc, ['CD79A', 'MS4A1'], groupby='louvain' ). ~/github/scanpy/scanpy/plotting/_anndata.py in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 710 . 711 if groupby is not None:. --> 712 obs_df = get.obs_df(adata, keys=[groupby] + keys, layer=layer, use_raw=use_raw). 713 if kwds.get('palette', None) is None:. 714 if not is_categorical_dtype(adata.obs[groupby]):. ~/github/scanpy/scanpy/get.py in obs_df(adata, keys, obsm_keys, layer, gene_symbols, use_raw). 200 # add var values. 201 if len(var_names) > 0:. --> 202 X = _get_obs_rep(adata, layer=layer, use_raw=use_raw). 203 if use_raw:. 204 var_idx = adata.raw.var_names.get_indexer(var_names). ~/github/scanpy/scanpy/get.py in _get_obs_rep(adata, use_raw, layer, obsm, obsp). 341 return adata.obsp[obsp]. 342 else:. --> 343 assert False, (. 344 ""That was unexpected. Please report this bug at:\n\n\t"". 345 "" https://github.com/theislab/scanpy/issues"". AssertionError: That was unexpected. Please report this bug at:. 	 https://github.com/theislab/scanpy/issues. ```. The issue seems to be that `use_raw=None` is not handled by `_get_obs_rep`. I think this should error, but the error should just be that `None` isn't a valid value for this argument. The real issue is that `sc.pl.violin` is not handling `use_raw` correctly.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1546
https://github.com/scverse/scanpy/issues/1546:1643,performance,error,error,1643,"sc.pl.violin throws error if adata does not have .raw; Ping @fidelram. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc3k_processed().raw.to_adata(). sc.pl.violin(pbmc, ['CD79A', 'MS4A1'], groupby='louvain' ). ```. ```pytb. ---------------------------------------------------------------------------. AssertionError Traceback (most recent call last). <ipython-input-7-594171c15db1> in <module>. ----> 1 sc.pl.violin(pbmc, ['CD79A', 'MS4A1'], groupby='louvain' ). ~/github/scanpy/scanpy/plotting/_anndata.py in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 710 . 711 if groupby is not None:. --> 712 obs_df = get.obs_df(adata, keys=[groupby] + keys, layer=layer, use_raw=use_raw). 713 if kwds.get('palette', None) is None:. 714 if not is_categorical_dtype(adata.obs[groupby]):. ~/github/scanpy/scanpy/get.py in obs_df(adata, keys, obsm_keys, layer, gene_symbols, use_raw). 200 # add var values. 201 if len(var_names) > 0:. --> 202 X = _get_obs_rep(adata, layer=layer, use_raw=use_raw). 203 if use_raw:. 204 var_idx = adata.raw.var_names.get_indexer(var_names). ~/github/scanpy/scanpy/get.py in _get_obs_rep(adata, use_raw, layer, obsm, obsp). 341 return adata.obsp[obsp]. 342 else:. --> 343 assert False, (. 344 ""That was unexpected. Please report this bug at:\n\n\t"". 345 "" https://github.com/theislab/scanpy/issues"". AssertionError: That was unexpected. Please report this bug at:. 	 https://github.com/theislab/scanpy/issues. ```. The issue seems to be that `use_raw=None` is not handled by `_get_obs_rep`. I think this should error, but the error should just be that `None` isn't a valid value for this argument. The real issue is that `sc.pl.violin` is not handling `use_raw` correctly.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1546
https://github.com/scverse/scanpy/issues/1546:1658,performance,error,error,1658,"sc.pl.violin throws error if adata does not have .raw; Ping @fidelram. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc3k_processed().raw.to_adata(). sc.pl.violin(pbmc, ['CD79A', 'MS4A1'], groupby='louvain' ). ```. ```pytb. ---------------------------------------------------------------------------. AssertionError Traceback (most recent call last). <ipython-input-7-594171c15db1> in <module>. ----> 1 sc.pl.violin(pbmc, ['CD79A', 'MS4A1'], groupby='louvain' ). ~/github/scanpy/scanpy/plotting/_anndata.py in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 710 . 711 if groupby is not None:. --> 712 obs_df = get.obs_df(adata, keys=[groupby] + keys, layer=layer, use_raw=use_raw). 713 if kwds.get('palette', None) is None:. 714 if not is_categorical_dtype(adata.obs[groupby]):. ~/github/scanpy/scanpy/get.py in obs_df(adata, keys, obsm_keys, layer, gene_symbols, use_raw). 200 # add var values. 201 if len(var_names) > 0:. --> 202 X = _get_obs_rep(adata, layer=layer, use_raw=use_raw). 203 if use_raw:. 204 var_idx = adata.raw.var_names.get_indexer(var_names). ~/github/scanpy/scanpy/get.py in _get_obs_rep(adata, use_raw, layer, obsm, obsp). 341 return adata.obsp[obsp]. 342 else:. --> 343 assert False, (. 344 ""That was unexpected. Please report this bug at:\n\n\t"". 345 "" https://github.com/theislab/scanpy/issues"". AssertionError: That was unexpected. Please report this bug at:. 	 https://github.com/theislab/scanpy/issues. ```. The issue seems to be that `use_raw=None` is not handled by `_get_obs_rep`. I think this should error, but the error should just be that `None` isn't a valid value for this argument. The real issue is that `sc.pl.violin` is not handling `use_raw` correctly.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1546
https://github.com/scverse/scanpy/issues/1546:35,reliability,doe,does,35,"sc.pl.violin throws error if adata does not have .raw; Ping @fidelram. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc3k_processed().raw.to_adata(). sc.pl.violin(pbmc, ['CD79A', 'MS4A1'], groupby='louvain' ). ```. ```pytb. ---------------------------------------------------------------------------. AssertionError Traceback (most recent call last). <ipython-input-7-594171c15db1> in <module>. ----> 1 sc.pl.violin(pbmc, ['CD79A', 'MS4A1'], groupby='louvain' ). ~/github/scanpy/scanpy/plotting/_anndata.py in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 710 . 711 if groupby is not None:. --> 712 obs_df = get.obs_df(adata, keys=[groupby] + keys, layer=layer, use_raw=use_raw). 713 if kwds.get('palette', None) is None:. 714 if not is_categorical_dtype(adata.obs[groupby]):. ~/github/scanpy/scanpy/get.py in obs_df(adata, keys, obsm_keys, layer, gene_symbols, use_raw). 200 # add var values. 201 if len(var_names) > 0:. --> 202 X = _get_obs_rep(adata, layer=layer, use_raw=use_raw). 203 if use_raw:. 204 var_idx = adata.raw.var_names.get_indexer(var_names). ~/github/scanpy/scanpy/get.py in _get_obs_rep(adata, use_raw, layer, obsm, obsp). 341 return adata.obsp[obsp]. 342 else:. --> 343 assert False, (. 344 ""That was unexpected. Please report this bug at:\n\n\t"". 345 "" https://github.com/theislab/scanpy/issues"". AssertionError: That was unexpected. Please report this bug at:. 	 https://github.com/theislab/scanpy/issues. ```. The issue seems to be that `use_raw=None` is not handled by `_get_obs_rep`. I think this should error, but the error should just be that `None` isn't a valid value for this argument. The real issue is that `sc.pl.violin` is not handling `use_raw` correctly.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1546
https://github.com/scverse/scanpy/issues/1546:20,safety,error,error,20,"sc.pl.violin throws error if adata does not have .raw; Ping @fidelram. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc3k_processed().raw.to_adata(). sc.pl.violin(pbmc, ['CD79A', 'MS4A1'], groupby='louvain' ). ```. ```pytb. ---------------------------------------------------------------------------. AssertionError Traceback (most recent call last). <ipython-input-7-594171c15db1> in <module>. ----> 1 sc.pl.violin(pbmc, ['CD79A', 'MS4A1'], groupby='louvain' ). ~/github/scanpy/scanpy/plotting/_anndata.py in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 710 . 711 if groupby is not None:. --> 712 obs_df = get.obs_df(adata, keys=[groupby] + keys, layer=layer, use_raw=use_raw). 713 if kwds.get('palette', None) is None:. 714 if not is_categorical_dtype(adata.obs[groupby]):. ~/github/scanpy/scanpy/get.py in obs_df(adata, keys, obsm_keys, layer, gene_symbols, use_raw). 200 # add var values. 201 if len(var_names) > 0:. --> 202 X = _get_obs_rep(adata, layer=layer, use_raw=use_raw). 203 if use_raw:. 204 var_idx = adata.raw.var_names.get_indexer(var_names). ~/github/scanpy/scanpy/get.py in _get_obs_rep(adata, use_raw, layer, obsm, obsp). 341 return adata.obsp[obsp]. 342 else:. --> 343 assert False, (. 344 ""That was unexpected. Please report this bug at:\n\n\t"". 345 "" https://github.com/theislab/scanpy/issues"". AssertionError: That was unexpected. Please report this bug at:. 	 https://github.com/theislab/scanpy/issues. ```. The issue seems to be that `use_raw=None` is not handled by `_get_obs_rep`. I think this should error, but the error should just be that `None` isn't a valid value for this argument. The real issue is that `sc.pl.violin` is not handling `use_raw` correctly.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1546
https://github.com/scverse/scanpy/issues/1546:367,safety,input,input-,367,"sc.pl.violin throws error if adata does not have .raw; Ping @fidelram. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc3k_processed().raw.to_adata(). sc.pl.violin(pbmc, ['CD79A', 'MS4A1'], groupby='louvain' ). ```. ```pytb. ---------------------------------------------------------------------------. AssertionError Traceback (most recent call last). <ipython-input-7-594171c15db1> in <module>. ----> 1 sc.pl.violin(pbmc, ['CD79A', 'MS4A1'], groupby='louvain' ). ~/github/scanpy/scanpy/plotting/_anndata.py in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 710 . 711 if groupby is not None:. --> 712 obs_df = get.obs_df(adata, keys=[groupby] + keys, layer=layer, use_raw=use_raw). 713 if kwds.get('palette', None) is None:. 714 if not is_categorical_dtype(adata.obs[groupby]):. ~/github/scanpy/scanpy/get.py in obs_df(adata, keys, obsm_keys, layer, gene_symbols, use_raw). 200 # add var values. 201 if len(var_names) > 0:. --> 202 X = _get_obs_rep(adata, layer=layer, use_raw=use_raw). 203 if use_raw:. 204 var_idx = adata.raw.var_names.get_indexer(var_names). ~/github/scanpy/scanpy/get.py in _get_obs_rep(adata, use_raw, layer, obsm, obsp). 341 return adata.obsp[obsp]. 342 else:. --> 343 assert False, (. 344 ""That was unexpected. Please report this bug at:\n\n\t"". 345 "" https://github.com/theislab/scanpy/issues"". AssertionError: That was unexpected. Please report this bug at:. 	 https://github.com/theislab/scanpy/issues. ```. The issue seems to be that `use_raw=None` is not handled by `_get_obs_rep`. I think this should error, but the error should just be that `None` isn't a valid value for this argument. The real issue is that `sc.pl.violin` is not handling `use_raw` correctly.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1546
https://github.com/scverse/scanpy/issues/1546:393,safety,modul,module,393,"sc.pl.violin throws error if adata does not have .raw; Ping @fidelram. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc3k_processed().raw.to_adata(). sc.pl.violin(pbmc, ['CD79A', 'MS4A1'], groupby='louvain' ). ```. ```pytb. ---------------------------------------------------------------------------. AssertionError Traceback (most recent call last). <ipython-input-7-594171c15db1> in <module>. ----> 1 sc.pl.violin(pbmc, ['CD79A', 'MS4A1'], groupby='louvain' ). ~/github/scanpy/scanpy/plotting/_anndata.py in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 710 . 711 if groupby is not None:. --> 712 obs_df = get.obs_df(adata, keys=[groupby] + keys, layer=layer, use_raw=use_raw). 713 if kwds.get('palette', None) is None:. 714 if not is_categorical_dtype(adata.obs[groupby]):. ~/github/scanpy/scanpy/get.py in obs_df(adata, keys, obsm_keys, layer, gene_symbols, use_raw). 200 # add var values. 201 if len(var_names) > 0:. --> 202 X = _get_obs_rep(adata, layer=layer, use_raw=use_raw). 203 if use_raw:. 204 var_idx = adata.raw.var_names.get_indexer(var_names). ~/github/scanpy/scanpy/get.py in _get_obs_rep(adata, use_raw, layer, obsm, obsp). 341 return adata.obsp[obsp]. 342 else:. --> 343 assert False, (. 344 ""That was unexpected. Please report this bug at:\n\n\t"". 345 "" https://github.com/theislab/scanpy/issues"". AssertionError: That was unexpected. Please report this bug at:. 	 https://github.com/theislab/scanpy/issues. ```. The issue seems to be that `use_raw=None` is not handled by `_get_obs_rep`. I think this should error, but the error should just be that `None` isn't a valid value for this argument. The real issue is that `sc.pl.violin` is not handling `use_raw` correctly.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1546
https://github.com/scverse/scanpy/issues/1546:546,safety,log,log,546,"sc.pl.violin throws error if adata does not have .raw; Ping @fidelram. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc3k_processed().raw.to_adata(). sc.pl.violin(pbmc, ['CD79A', 'MS4A1'], groupby='louvain' ). ```. ```pytb. ---------------------------------------------------------------------------. AssertionError Traceback (most recent call last). <ipython-input-7-594171c15db1> in <module>. ----> 1 sc.pl.violin(pbmc, ['CD79A', 'MS4A1'], groupby='louvain' ). ~/github/scanpy/scanpy/plotting/_anndata.py in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 710 . 711 if groupby is not None:. --> 712 obs_df = get.obs_df(adata, keys=[groupby] + keys, layer=layer, use_raw=use_raw). 713 if kwds.get('palette', None) is None:. 714 if not is_categorical_dtype(adata.obs[groupby]):. ~/github/scanpy/scanpy/get.py in obs_df(adata, keys, obsm_keys, layer, gene_symbols, use_raw). 200 # add var values. 201 if len(var_names) > 0:. --> 202 X = _get_obs_rep(adata, layer=layer, use_raw=use_raw). 203 if use_raw:. 204 var_idx = adata.raw.var_names.get_indexer(var_names). ~/github/scanpy/scanpy/get.py in _get_obs_rep(adata, use_raw, layer, obsm, obsp). 341 return adata.obsp[obsp]. 342 else:. --> 343 assert False, (. 344 ""That was unexpected. Please report this bug at:\n\n\t"". 345 "" https://github.com/theislab/scanpy/issues"". AssertionError: That was unexpected. Please report this bug at:. 	 https://github.com/theislab/scanpy/issues. ```. The issue seems to be that `use_raw=None` is not handled by `_get_obs_rep`. I think this should error, but the error should just be that `None` isn't a valid value for this argument. The real issue is that `sc.pl.violin` is not handling `use_raw` correctly.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1546
https://github.com/scverse/scanpy/issues/1546:1643,safety,error,error,1643,"sc.pl.violin throws error if adata does not have .raw; Ping @fidelram. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc3k_processed().raw.to_adata(). sc.pl.violin(pbmc, ['CD79A', 'MS4A1'], groupby='louvain' ). ```. ```pytb. ---------------------------------------------------------------------------. AssertionError Traceback (most recent call last). <ipython-input-7-594171c15db1> in <module>. ----> 1 sc.pl.violin(pbmc, ['CD79A', 'MS4A1'], groupby='louvain' ). ~/github/scanpy/scanpy/plotting/_anndata.py in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 710 . 711 if groupby is not None:. --> 712 obs_df = get.obs_df(adata, keys=[groupby] + keys, layer=layer, use_raw=use_raw). 713 if kwds.get('palette', None) is None:. 714 if not is_categorical_dtype(adata.obs[groupby]):. ~/github/scanpy/scanpy/get.py in obs_df(adata, keys, obsm_keys, layer, gene_symbols, use_raw). 200 # add var values. 201 if len(var_names) > 0:. --> 202 X = _get_obs_rep(adata, layer=layer, use_raw=use_raw). 203 if use_raw:. 204 var_idx = adata.raw.var_names.get_indexer(var_names). ~/github/scanpy/scanpy/get.py in _get_obs_rep(adata, use_raw, layer, obsm, obsp). 341 return adata.obsp[obsp]. 342 else:. --> 343 assert False, (. 344 ""That was unexpected. Please report this bug at:\n\n\t"". 345 "" https://github.com/theislab/scanpy/issues"". AssertionError: That was unexpected. Please report this bug at:. 	 https://github.com/theislab/scanpy/issues. ```. The issue seems to be that `use_raw=None` is not handled by `_get_obs_rep`. I think this should error, but the error should just be that `None` isn't a valid value for this argument. The real issue is that `sc.pl.violin` is not handling `use_raw` correctly.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1546
https://github.com/scverse/scanpy/issues/1546:1658,safety,error,error,1658,"sc.pl.violin throws error if adata does not have .raw; Ping @fidelram. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc3k_processed().raw.to_adata(). sc.pl.violin(pbmc, ['CD79A', 'MS4A1'], groupby='louvain' ). ```. ```pytb. ---------------------------------------------------------------------------. AssertionError Traceback (most recent call last). <ipython-input-7-594171c15db1> in <module>. ----> 1 sc.pl.violin(pbmc, ['CD79A', 'MS4A1'], groupby='louvain' ). ~/github/scanpy/scanpy/plotting/_anndata.py in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 710 . 711 if groupby is not None:. --> 712 obs_df = get.obs_df(adata, keys=[groupby] + keys, layer=layer, use_raw=use_raw). 713 if kwds.get('palette', None) is None:. 714 if not is_categorical_dtype(adata.obs[groupby]):. ~/github/scanpy/scanpy/get.py in obs_df(adata, keys, obsm_keys, layer, gene_symbols, use_raw). 200 # add var values. 201 if len(var_names) > 0:. --> 202 X = _get_obs_rep(adata, layer=layer, use_raw=use_raw). 203 if use_raw:. 204 var_idx = adata.raw.var_names.get_indexer(var_names). ~/github/scanpy/scanpy/get.py in _get_obs_rep(adata, use_raw, layer, obsm, obsp). 341 return adata.obsp[obsp]. 342 else:. --> 343 assert False, (. 344 ""That was unexpected. Please report this bug at:\n\n\t"". 345 "" https://github.com/theislab/scanpy/issues"". AssertionError: That was unexpected. Please report this bug at:. 	 https://github.com/theislab/scanpy/issues. ```. The issue seems to be that `use_raw=None` is not handled by `_get_obs_rep`. I think this should error, but the error should just be that `None` isn't a valid value for this argument. The real issue is that `sc.pl.violin` is not handling `use_raw` correctly.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1546
https://github.com/scverse/scanpy/issues/1546:1699,safety,valid,valid,1699,"sc.pl.violin throws error if adata does not have .raw; Ping @fidelram. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc3k_processed().raw.to_adata(). sc.pl.violin(pbmc, ['CD79A', 'MS4A1'], groupby='louvain' ). ```. ```pytb. ---------------------------------------------------------------------------. AssertionError Traceback (most recent call last). <ipython-input-7-594171c15db1> in <module>. ----> 1 sc.pl.violin(pbmc, ['CD79A', 'MS4A1'], groupby='louvain' ). ~/github/scanpy/scanpy/plotting/_anndata.py in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 710 . 711 if groupby is not None:. --> 712 obs_df = get.obs_df(adata, keys=[groupby] + keys, layer=layer, use_raw=use_raw). 713 if kwds.get('palette', None) is None:. 714 if not is_categorical_dtype(adata.obs[groupby]):. ~/github/scanpy/scanpy/get.py in obs_df(adata, keys, obsm_keys, layer, gene_symbols, use_raw). 200 # add var values. 201 if len(var_names) > 0:. --> 202 X = _get_obs_rep(adata, layer=layer, use_raw=use_raw). 203 if use_raw:. 204 var_idx = adata.raw.var_names.get_indexer(var_names). ~/github/scanpy/scanpy/get.py in _get_obs_rep(adata, use_raw, layer, obsm, obsp). 341 return adata.obsp[obsp]. 342 else:. --> 343 assert False, (. 344 ""That was unexpected. Please report this bug at:\n\n\t"". 345 "" https://github.com/theislab/scanpy/issues"". AssertionError: That was unexpected. Please report this bug at:. 	 https://github.com/theislab/scanpy/issues. ```. The issue seems to be that `use_raw=None` is not handled by `_get_obs_rep`. I think this should error, but the error should just be that `None` isn't a valid value for this argument. The real issue is that `sc.pl.violin` is not handling `use_raw` correctly.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1546
https://github.com/scverse/scanpy/issues/1546:546,security,log,log,546,"sc.pl.violin throws error if adata does not have .raw; Ping @fidelram. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc3k_processed().raw.to_adata(). sc.pl.violin(pbmc, ['CD79A', 'MS4A1'], groupby='louvain' ). ```. ```pytb. ---------------------------------------------------------------------------. AssertionError Traceback (most recent call last). <ipython-input-7-594171c15db1> in <module>. ----> 1 sc.pl.violin(pbmc, ['CD79A', 'MS4A1'], groupby='louvain' ). ~/github/scanpy/scanpy/plotting/_anndata.py in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 710 . 711 if groupby is not None:. --> 712 obs_df = get.obs_df(adata, keys=[groupby] + keys, layer=layer, use_raw=use_raw). 713 if kwds.get('palette', None) is None:. 714 if not is_categorical_dtype(adata.obs[groupby]):. ~/github/scanpy/scanpy/get.py in obs_df(adata, keys, obsm_keys, layer, gene_symbols, use_raw). 200 # add var values. 201 if len(var_names) > 0:. --> 202 X = _get_obs_rep(adata, layer=layer, use_raw=use_raw). 203 if use_raw:. 204 var_idx = adata.raw.var_names.get_indexer(var_names). ~/github/scanpy/scanpy/get.py in _get_obs_rep(adata, use_raw, layer, obsm, obsp). 341 return adata.obsp[obsp]. 342 else:. --> 343 assert False, (. 344 ""That was unexpected. Please report this bug at:\n\n\t"". 345 "" https://github.com/theislab/scanpy/issues"". AssertionError: That was unexpected. Please report this bug at:. 	 https://github.com/theislab/scanpy/issues. ```. The issue seems to be that `use_raw=None` is not handled by `_get_obs_rep`. I think this should error, but the error should just be that `None` isn't a valid value for this argument. The real issue is that `sc.pl.violin` is not handling `use_raw` correctly.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1546
https://github.com/scverse/scanpy/issues/1546:635,security,rotat,rotation,635,"sc.pl.violin throws error if adata does not have .raw; Ping @fidelram. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc3k_processed().raw.to_adata(). sc.pl.violin(pbmc, ['CD79A', 'MS4A1'], groupby='louvain' ). ```. ```pytb. ---------------------------------------------------------------------------. AssertionError Traceback (most recent call last). <ipython-input-7-594171c15db1> in <module>. ----> 1 sc.pl.violin(pbmc, ['CD79A', 'MS4A1'], groupby='louvain' ). ~/github/scanpy/scanpy/plotting/_anndata.py in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 710 . 711 if groupby is not None:. --> 712 obs_df = get.obs_df(adata, keys=[groupby] + keys, layer=layer, use_raw=use_raw). 713 if kwds.get('palette', None) is None:. 714 if not is_categorical_dtype(adata.obs[groupby]):. ~/github/scanpy/scanpy/get.py in obs_df(adata, keys, obsm_keys, layer, gene_symbols, use_raw). 200 # add var values. 201 if len(var_names) > 0:. --> 202 X = _get_obs_rep(adata, layer=layer, use_raw=use_raw). 203 if use_raw:. 204 var_idx = adata.raw.var_names.get_indexer(var_names). ~/github/scanpy/scanpy/get.py in _get_obs_rep(adata, use_raw, layer, obsm, obsp). 341 return adata.obsp[obsp]. 342 else:. --> 343 assert False, (. 344 ""That was unexpected. Please report this bug at:\n\n\t"". 345 "" https://github.com/theislab/scanpy/issues"". AssertionError: That was unexpected. Please report this bug at:. 	 https://github.com/theislab/scanpy/issues. ```. The issue seems to be that `use_raw=None` is not handled by `_get_obs_rep`. I think this should error, but the error should just be that `None` isn't a valid value for this argument. The real issue is that `sc.pl.violin` is not handling `use_raw` correctly.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1546
https://github.com/scverse/scanpy/issues/1546:308,testability,Assert,AssertionError,308,"sc.pl.violin throws error if adata does not have .raw; Ping @fidelram. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc3k_processed().raw.to_adata(). sc.pl.violin(pbmc, ['CD79A', 'MS4A1'], groupby='louvain' ). ```. ```pytb. ---------------------------------------------------------------------------. AssertionError Traceback (most recent call last). <ipython-input-7-594171c15db1> in <module>. ----> 1 sc.pl.violin(pbmc, ['CD79A', 'MS4A1'], groupby='louvain' ). ~/github/scanpy/scanpy/plotting/_anndata.py in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 710 . 711 if groupby is not None:. --> 712 obs_df = get.obs_df(adata, keys=[groupby] + keys, layer=layer, use_raw=use_raw). 713 if kwds.get('palette', None) is None:. 714 if not is_categorical_dtype(adata.obs[groupby]):. ~/github/scanpy/scanpy/get.py in obs_df(adata, keys, obsm_keys, layer, gene_symbols, use_raw). 200 # add var values. 201 if len(var_names) > 0:. --> 202 X = _get_obs_rep(adata, layer=layer, use_raw=use_raw). 203 if use_raw:. 204 var_idx = adata.raw.var_names.get_indexer(var_names). ~/github/scanpy/scanpy/get.py in _get_obs_rep(adata, use_raw, layer, obsm, obsp). 341 return adata.obsp[obsp]. 342 else:. --> 343 assert False, (. 344 ""That was unexpected. Please report this bug at:\n\n\t"". 345 "" https://github.com/theislab/scanpy/issues"". AssertionError: That was unexpected. Please report this bug at:. 	 https://github.com/theislab/scanpy/issues. ```. The issue seems to be that `use_raw=None` is not handled by `_get_obs_rep`. I think this should error, but the error should just be that `None` isn't a valid value for this argument. The real issue is that `sc.pl.violin` is not handling `use_raw` correctly.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1546
https://github.com/scverse/scanpy/issues/1546:323,testability,Trace,Traceback,323,"sc.pl.violin throws error if adata does not have .raw; Ping @fidelram. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc3k_processed().raw.to_adata(). sc.pl.violin(pbmc, ['CD79A', 'MS4A1'], groupby='louvain' ). ```. ```pytb. ---------------------------------------------------------------------------. AssertionError Traceback (most recent call last). <ipython-input-7-594171c15db1> in <module>. ----> 1 sc.pl.violin(pbmc, ['CD79A', 'MS4A1'], groupby='louvain' ). ~/github/scanpy/scanpy/plotting/_anndata.py in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 710 . 711 if groupby is not None:. --> 712 obs_df = get.obs_df(adata, keys=[groupby] + keys, layer=layer, use_raw=use_raw). 713 if kwds.get('palette', None) is None:. 714 if not is_categorical_dtype(adata.obs[groupby]):. ~/github/scanpy/scanpy/get.py in obs_df(adata, keys, obsm_keys, layer, gene_symbols, use_raw). 200 # add var values. 201 if len(var_names) > 0:. --> 202 X = _get_obs_rep(adata, layer=layer, use_raw=use_raw). 203 if use_raw:. 204 var_idx = adata.raw.var_names.get_indexer(var_names). ~/github/scanpy/scanpy/get.py in _get_obs_rep(adata, use_raw, layer, obsm, obsp). 341 return adata.obsp[obsp]. 342 else:. --> 343 assert False, (. 344 ""That was unexpected. Please report this bug at:\n\n\t"". 345 "" https://github.com/theislab/scanpy/issues"". AssertionError: That was unexpected. Please report this bug at:. 	 https://github.com/theislab/scanpy/issues. ```. The issue seems to be that `use_raw=None` is not handled by `_get_obs_rep`. I think this should error, but the error should just be that `None` isn't a valid value for this argument. The real issue is that `sc.pl.violin` is not handling `use_raw` correctly.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1546
https://github.com/scverse/scanpy/issues/1546:546,testability,log,log,546,"sc.pl.violin throws error if adata does not have .raw; Ping @fidelram. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc3k_processed().raw.to_adata(). sc.pl.violin(pbmc, ['CD79A', 'MS4A1'], groupby='louvain' ). ```. ```pytb. ---------------------------------------------------------------------------. AssertionError Traceback (most recent call last). <ipython-input-7-594171c15db1> in <module>. ----> 1 sc.pl.violin(pbmc, ['CD79A', 'MS4A1'], groupby='louvain' ). ~/github/scanpy/scanpy/plotting/_anndata.py in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 710 . 711 if groupby is not None:. --> 712 obs_df = get.obs_df(adata, keys=[groupby] + keys, layer=layer, use_raw=use_raw). 713 if kwds.get('palette', None) is None:. 714 if not is_categorical_dtype(adata.obs[groupby]):. ~/github/scanpy/scanpy/get.py in obs_df(adata, keys, obsm_keys, layer, gene_symbols, use_raw). 200 # add var values. 201 if len(var_names) > 0:. --> 202 X = _get_obs_rep(adata, layer=layer, use_raw=use_raw). 203 if use_raw:. 204 var_idx = adata.raw.var_names.get_indexer(var_names). ~/github/scanpy/scanpy/get.py in _get_obs_rep(adata, use_raw, layer, obsm, obsp). 341 return adata.obsp[obsp]. 342 else:. --> 343 assert False, (. 344 ""That was unexpected. Please report this bug at:\n\n\t"". 345 "" https://github.com/theislab/scanpy/issues"". AssertionError: That was unexpected. Please report this bug at:. 	 https://github.com/theislab/scanpy/issues. ```. The issue seems to be that `use_raw=None` is not handled by `_get_obs_rep`. I think this should error, but the error should just be that `None` isn't a valid value for this argument. The real issue is that `sc.pl.violin` is not handling `use_raw` correctly.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1546
https://github.com/scverse/scanpy/issues/1546:1304,testability,assert,assert,1304,"sc.pl.violin throws error if adata does not have .raw; Ping @fidelram. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc3k_processed().raw.to_adata(). sc.pl.violin(pbmc, ['CD79A', 'MS4A1'], groupby='louvain' ). ```. ```pytb. ---------------------------------------------------------------------------. AssertionError Traceback (most recent call last). <ipython-input-7-594171c15db1> in <module>. ----> 1 sc.pl.violin(pbmc, ['CD79A', 'MS4A1'], groupby='louvain' ). ~/github/scanpy/scanpy/plotting/_anndata.py in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 710 . 711 if groupby is not None:. --> 712 obs_df = get.obs_df(adata, keys=[groupby] + keys, layer=layer, use_raw=use_raw). 713 if kwds.get('palette', None) is None:. 714 if not is_categorical_dtype(adata.obs[groupby]):. ~/github/scanpy/scanpy/get.py in obs_df(adata, keys, obsm_keys, layer, gene_symbols, use_raw). 200 # add var values. 201 if len(var_names) > 0:. --> 202 X = _get_obs_rep(adata, layer=layer, use_raw=use_raw). 203 if use_raw:. 204 var_idx = adata.raw.var_names.get_indexer(var_names). ~/github/scanpy/scanpy/get.py in _get_obs_rep(adata, use_raw, layer, obsm, obsp). 341 return adata.obsp[obsp]. 342 else:. --> 343 assert False, (. 344 ""That was unexpected. Please report this bug at:\n\n\t"". 345 "" https://github.com/theislab/scanpy/issues"". AssertionError: That was unexpected. Please report this bug at:. 	 https://github.com/theislab/scanpy/issues. ```. The issue seems to be that `use_raw=None` is not handled by `_get_obs_rep`. I think this should error, but the error should just be that `None` isn't a valid value for this argument. The real issue is that `sc.pl.violin` is not handling `use_raw` correctly.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1546
https://github.com/scverse/scanpy/issues/1546:1432,testability,Assert,AssertionError,1432,"sc.pl.violin throws error if adata does not have .raw; Ping @fidelram. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc3k_processed().raw.to_adata(). sc.pl.violin(pbmc, ['CD79A', 'MS4A1'], groupby='louvain' ). ```. ```pytb. ---------------------------------------------------------------------------. AssertionError Traceback (most recent call last). <ipython-input-7-594171c15db1> in <module>. ----> 1 sc.pl.violin(pbmc, ['CD79A', 'MS4A1'], groupby='louvain' ). ~/github/scanpy/scanpy/plotting/_anndata.py in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 710 . 711 if groupby is not None:. --> 712 obs_df = get.obs_df(adata, keys=[groupby] + keys, layer=layer, use_raw=use_raw). 713 if kwds.get('palette', None) is None:. 714 if not is_categorical_dtype(adata.obs[groupby]):. ~/github/scanpy/scanpy/get.py in obs_df(adata, keys, obsm_keys, layer, gene_symbols, use_raw). 200 # add var values. 201 if len(var_names) > 0:. --> 202 X = _get_obs_rep(adata, layer=layer, use_raw=use_raw). 203 if use_raw:. 204 var_idx = adata.raw.var_names.get_indexer(var_names). ~/github/scanpy/scanpy/get.py in _get_obs_rep(adata, use_raw, layer, obsm, obsp). 341 return adata.obsp[obsp]. 342 else:. --> 343 assert False, (. 344 ""That was unexpected. Please report this bug at:\n\n\t"". 345 "" https://github.com/theislab/scanpy/issues"". AssertionError: That was unexpected. Please report this bug at:. 	 https://github.com/theislab/scanpy/issues. ```. The issue seems to be that `use_raw=None` is not handled by `_get_obs_rep`. I think this should error, but the error should just be that `None` isn't a valid value for this argument. The real issue is that `sc.pl.violin` is not handling `use_raw` correctly.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1546
https://github.com/scverse/scanpy/issues/1546:20,usability,error,error,20,"sc.pl.violin throws error if adata does not have .raw; Ping @fidelram. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc3k_processed().raw.to_adata(). sc.pl.violin(pbmc, ['CD79A', 'MS4A1'], groupby='louvain' ). ```. ```pytb. ---------------------------------------------------------------------------. AssertionError Traceback (most recent call last). <ipython-input-7-594171c15db1> in <module>. ----> 1 sc.pl.violin(pbmc, ['CD79A', 'MS4A1'], groupby='louvain' ). ~/github/scanpy/scanpy/plotting/_anndata.py in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 710 . 711 if groupby is not None:. --> 712 obs_df = get.obs_df(adata, keys=[groupby] + keys, layer=layer, use_raw=use_raw). 713 if kwds.get('palette', None) is None:. 714 if not is_categorical_dtype(adata.obs[groupby]):. ~/github/scanpy/scanpy/get.py in obs_df(adata, keys, obsm_keys, layer, gene_symbols, use_raw). 200 # add var values. 201 if len(var_names) > 0:. --> 202 X = _get_obs_rep(adata, layer=layer, use_raw=use_raw). 203 if use_raw:. 204 var_idx = adata.raw.var_names.get_indexer(var_names). ~/github/scanpy/scanpy/get.py in _get_obs_rep(adata, use_raw, layer, obsm, obsp). 341 return adata.obsp[obsp]. 342 else:. --> 343 assert False, (. 344 ""That was unexpected. Please report this bug at:\n\n\t"". 345 "" https://github.com/theislab/scanpy/issues"". AssertionError: That was unexpected. Please report this bug at:. 	 https://github.com/theislab/scanpy/issues. ```. The issue seems to be that `use_raw=None` is not handled by `_get_obs_rep`. I think this should error, but the error should just be that `None` isn't a valid value for this argument. The real issue is that `sc.pl.violin` is not handling `use_raw` correctly.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1546
https://github.com/scverse/scanpy/issues/1546:367,usability,input,input-,367,"sc.pl.violin throws error if adata does not have .raw; Ping @fidelram. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc3k_processed().raw.to_adata(). sc.pl.violin(pbmc, ['CD79A', 'MS4A1'], groupby='louvain' ). ```. ```pytb. ---------------------------------------------------------------------------. AssertionError Traceback (most recent call last). <ipython-input-7-594171c15db1> in <module>. ----> 1 sc.pl.violin(pbmc, ['CD79A', 'MS4A1'], groupby='louvain' ). ~/github/scanpy/scanpy/plotting/_anndata.py in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 710 . 711 if groupby is not None:. --> 712 obs_df = get.obs_df(adata, keys=[groupby] + keys, layer=layer, use_raw=use_raw). 713 if kwds.get('palette', None) is None:. 714 if not is_categorical_dtype(adata.obs[groupby]):. ~/github/scanpy/scanpy/get.py in obs_df(adata, keys, obsm_keys, layer, gene_symbols, use_raw). 200 # add var values. 201 if len(var_names) > 0:. --> 202 X = _get_obs_rep(adata, layer=layer, use_raw=use_raw). 203 if use_raw:. 204 var_idx = adata.raw.var_names.get_indexer(var_names). ~/github/scanpy/scanpy/get.py in _get_obs_rep(adata, use_raw, layer, obsm, obsp). 341 return adata.obsp[obsp]. 342 else:. --> 343 assert False, (. 344 ""That was unexpected. Please report this bug at:\n\n\t"". 345 "" https://github.com/theislab/scanpy/issues"". AssertionError: That was unexpected. Please report this bug at:. 	 https://github.com/theislab/scanpy/issues. ```. The issue seems to be that `use_raw=None` is not handled by `_get_obs_rep`. I think this should error, but the error should just be that `None` isn't a valid value for this argument. The real issue is that `sc.pl.violin` is not handling `use_raw` correctly.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1546
https://github.com/scverse/scanpy/issues/1546:1643,usability,error,error,1643,"sc.pl.violin throws error if adata does not have .raw; Ping @fidelram. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc3k_processed().raw.to_adata(). sc.pl.violin(pbmc, ['CD79A', 'MS4A1'], groupby='louvain' ). ```. ```pytb. ---------------------------------------------------------------------------. AssertionError Traceback (most recent call last). <ipython-input-7-594171c15db1> in <module>. ----> 1 sc.pl.violin(pbmc, ['CD79A', 'MS4A1'], groupby='louvain' ). ~/github/scanpy/scanpy/plotting/_anndata.py in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 710 . 711 if groupby is not None:. --> 712 obs_df = get.obs_df(adata, keys=[groupby] + keys, layer=layer, use_raw=use_raw). 713 if kwds.get('palette', None) is None:. 714 if not is_categorical_dtype(adata.obs[groupby]):. ~/github/scanpy/scanpy/get.py in obs_df(adata, keys, obsm_keys, layer, gene_symbols, use_raw). 200 # add var values. 201 if len(var_names) > 0:. --> 202 X = _get_obs_rep(adata, layer=layer, use_raw=use_raw). 203 if use_raw:. 204 var_idx = adata.raw.var_names.get_indexer(var_names). ~/github/scanpy/scanpy/get.py in _get_obs_rep(adata, use_raw, layer, obsm, obsp). 341 return adata.obsp[obsp]. 342 else:. --> 343 assert False, (. 344 ""That was unexpected. Please report this bug at:\n\n\t"". 345 "" https://github.com/theislab/scanpy/issues"". AssertionError: That was unexpected. Please report this bug at:. 	 https://github.com/theislab/scanpy/issues. ```. The issue seems to be that `use_raw=None` is not handled by `_get_obs_rep`. I think this should error, but the error should just be that `None` isn't a valid value for this argument. The real issue is that `sc.pl.violin` is not handling `use_raw` correctly.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1546
https://github.com/scverse/scanpy/issues/1546:1658,usability,error,error,1658,"sc.pl.violin throws error if adata does not have .raw; Ping @fidelram. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc3k_processed().raw.to_adata(). sc.pl.violin(pbmc, ['CD79A', 'MS4A1'], groupby='louvain' ). ```. ```pytb. ---------------------------------------------------------------------------. AssertionError Traceback (most recent call last). <ipython-input-7-594171c15db1> in <module>. ----> 1 sc.pl.violin(pbmc, ['CD79A', 'MS4A1'], groupby='louvain' ). ~/github/scanpy/scanpy/plotting/_anndata.py in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 710 . 711 if groupby is not None:. --> 712 obs_df = get.obs_df(adata, keys=[groupby] + keys, layer=layer, use_raw=use_raw). 713 if kwds.get('palette', None) is None:. 714 if not is_categorical_dtype(adata.obs[groupby]):. ~/github/scanpy/scanpy/get.py in obs_df(adata, keys, obsm_keys, layer, gene_symbols, use_raw). 200 # add var values. 201 if len(var_names) > 0:. --> 202 X = _get_obs_rep(adata, layer=layer, use_raw=use_raw). 203 if use_raw:. 204 var_idx = adata.raw.var_names.get_indexer(var_names). ~/github/scanpy/scanpy/get.py in _get_obs_rep(adata, use_raw, layer, obsm, obsp). 341 return adata.obsp[obsp]. 342 else:. --> 343 assert False, (. 344 ""That was unexpected. Please report this bug at:\n\n\t"". 345 "" https://github.com/theislab/scanpy/issues"". AssertionError: That was unexpected. Please report this bug at:. 	 https://github.com/theislab/scanpy/issues. ```. The issue seems to be that `use_raw=None` is not handled by `_get_obs_rep`. I think this should error, but the error should just be that `None` isn't a valid value for this argument. The real issue is that `sc.pl.violin` is not handling `use_raw` correctly.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1546
https://github.com/scverse/scanpy/pull/1547:32,interoperability,format,format,32,Fix ipython check in settings + format; Fixes #1477. Also formatted `_settings.py`,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1547
https://github.com/scverse/scanpy/pull/1547:58,interoperability,format,formatted,58,Fix ipython check in settings + format; Fixes #1477. Also formatted `_settings.py`,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1547
https://github.com/scverse/scanpy/pull/1548:179,availability,error,error,179,"Fix sc.pl.violin when use_raw=None; Fixes #1546. I've done a couple things here:. 1. I've fixed the bug (`sc.pl.violin` being called on an `AnnData` without `.raw` would throw an error), and added a regression test. 2. I've tried to normalize how we choose what to do when `use_raw=None`, basically this is just a new utility `_check_use_raw`. The benefit of having a single function for this is that it makes it easy to globally change how we handle this argument (e.g. deprecate the `None` case). 3. Reworded the docs for functions where `use_raw=None` can become `use_raw=True`",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1548
https://github.com/scverse/scanpy/pull/1548:61,integrability,coupl,couple,61,"Fix sc.pl.violin when use_raw=None; Fixes #1546. I've done a couple things here:. 1. I've fixed the bug (`sc.pl.violin` being called on an `AnnData` without `.raw` would throw an error), and added a regression test. 2. I've tried to normalize how we choose what to do when `use_raw=None`, basically this is just a new utility `_check_use_raw`. The benefit of having a single function for this is that it makes it easy to globally change how we handle this argument (e.g. deprecate the `None` case). 3. Reworded the docs for functions where `use_raw=None` can become `use_raw=True`",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1548
https://github.com/scverse/scanpy/pull/1548:61,modifiability,coupl,couple,61,"Fix sc.pl.violin when use_raw=None; Fixes #1546. I've done a couple things here:. 1. I've fixed the bug (`sc.pl.violin` being called on an `AnnData` without `.raw` would throw an error), and added a regression test. 2. I've tried to normalize how we choose what to do when `use_raw=None`, basically this is just a new utility `_check_use_raw`. The benefit of having a single function for this is that it makes it easy to globally change how we handle this argument (e.g. deprecate the `None` case). 3. Reworded the docs for functions where `use_raw=None` can become `use_raw=True`",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1548
https://github.com/scverse/scanpy/pull/1548:179,performance,error,error,179,"Fix sc.pl.violin when use_raw=None; Fixes #1546. I've done a couple things here:. 1. I've fixed the bug (`sc.pl.violin` being called on an `AnnData` without `.raw` would throw an error), and added a regression test. 2. I've tried to normalize how we choose what to do when `use_raw=None`, basically this is just a new utility `_check_use_raw`. The benefit of having a single function for this is that it makes it easy to globally change how we handle this argument (e.g. deprecate the `None` case). 3. Reworded the docs for functions where `use_raw=None` can become `use_raw=True`",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1548
https://github.com/scverse/scanpy/pull/1548:179,safety,error,error,179,"Fix sc.pl.violin when use_raw=None; Fixes #1546. I've done a couple things here:. 1. I've fixed the bug (`sc.pl.violin` being called on an `AnnData` without `.raw` would throw an error), and added a regression test. 2. I've tried to normalize how we choose what to do when `use_raw=None`, basically this is just a new utility `_check_use_raw`. The benefit of having a single function for this is that it makes it easy to globally change how we handle this argument (e.g. deprecate the `None` case). 3. Reworded the docs for functions where `use_raw=None` can become `use_raw=True`",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1548
https://github.com/scverse/scanpy/pull/1548:210,safety,test,test,210,"Fix sc.pl.violin when use_raw=None; Fixes #1546. I've done a couple things here:. 1. I've fixed the bug (`sc.pl.violin` being called on an `AnnData` without `.raw` would throw an error), and added a regression test. 2. I've tried to normalize how we choose what to do when `use_raw=None`, basically this is just a new utility `_check_use_raw`. The benefit of having a single function for this is that it makes it easy to globally change how we handle this argument (e.g. deprecate the `None` case). 3. Reworded the docs for functions where `use_raw=None` can become `use_raw=True`",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1548
https://github.com/scverse/scanpy/pull/1548:61,testability,coupl,couple,61,"Fix sc.pl.violin when use_raw=None; Fixes #1546. I've done a couple things here:. 1. I've fixed the bug (`sc.pl.violin` being called on an `AnnData` without `.raw` would throw an error), and added a regression test. 2. I've tried to normalize how we choose what to do when `use_raw=None`, basically this is just a new utility `_check_use_raw`. The benefit of having a single function for this is that it makes it easy to globally change how we handle this argument (e.g. deprecate the `None` case). 3. Reworded the docs for functions where `use_raw=None` can become `use_raw=True`",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1548
https://github.com/scverse/scanpy/pull/1548:199,testability,regress,regression,199,"Fix sc.pl.violin when use_raw=None; Fixes #1546. I've done a couple things here:. 1. I've fixed the bug (`sc.pl.violin` being called on an `AnnData` without `.raw` would throw an error), and added a regression test. 2. I've tried to normalize how we choose what to do when `use_raw=None`, basically this is just a new utility `_check_use_raw`. The benefit of having a single function for this is that it makes it easy to globally change how we handle this argument (e.g. deprecate the `None` case). 3. Reworded the docs for functions where `use_raw=None` can become `use_raw=True`",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1548
https://github.com/scverse/scanpy/pull/1548:210,testability,test,test,210,"Fix sc.pl.violin when use_raw=None; Fixes #1546. I've done a couple things here:. 1. I've fixed the bug (`sc.pl.violin` being called on an `AnnData` without `.raw` would throw an error), and added a regression test. 2. I've tried to normalize how we choose what to do when `use_raw=None`, basically this is just a new utility `_check_use_raw`. The benefit of having a single function for this is that it makes it easy to globally change how we handle this argument (e.g. deprecate the `None` case). 3. Reworded the docs for functions where `use_raw=None` can become `use_raw=True`",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1548
https://github.com/scverse/scanpy/pull/1548:179,usability,error,error,179,"Fix sc.pl.violin when use_raw=None; Fixes #1546. I've done a couple things here:. 1. I've fixed the bug (`sc.pl.violin` being called on an `AnnData` without `.raw` would throw an error), and added a regression test. 2. I've tried to normalize how we choose what to do when `use_raw=None`, basically this is just a new utility `_check_use_raw`. The benefit of having a single function for this is that it makes it easy to globally change how we handle this argument (e.g. deprecate the `None` case). 3. Reworded the docs for functions where `use_raw=None` can become `use_raw=True`",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1548
https://github.com/scverse/scanpy/issues/1549:162,deployability,version,version,162,"sc.tl.dendrogram doesn't use var_names ; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. Latest on pip at least scanpy-1.6.0. ---. I'm using the sc.pl.dendrogram multiple times different lists of genes on my dataset (incrementing number of highly variable genes basically). The outputted dendrogram is alway the same (I guess it's taking into account all the genes because it's using something like 32go of ram....). ### Minimal code sample (that we can copy&paste without having any data). ```python. hvegene_sets = [sc.pp.highly_variable_genes(adata, inplace=False, subset=False, n_top_genes=nhvg)[""highly_variable""] for nhvg in [500,1000,2000, 3000,4000, 5000]]. ```. then. ```python. [sum(hvgene) for hvgene in hvegene_sets]. ```. outputs:. [499, 1000, 1999, 2999, 4000, 4999] (so i have my different genesets). then . ```python. dendro1 = sc.tl.dendrogram(adata, . var_names=adata.var_names[hvegene_sets[1]].values, . optimal_ordering=True,. cor_method=""spearman"", linkage_method=""complete"", inplace=False,. groupby=""Annotation""). dendro2 = sc.tl.dendrogram(adata, . var_names=adata.var_names[hvegene_sets[5]].values, . optimal_ordering=True,. cor_method=""spearman"", linkage_method=""complete"", inplace=False,. groupby=""Annotation""). [dendro1[key] ==dendro2[key] for key in dendro1.keys()] . ```. outputs: . ```code. [array([[ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, T",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1549
https://github.com/scverse/scanpy/issues/1549:5357,deployability,Version,Versions,5357,"True, True, True, True,. True, True, True, True, True, True, True, True, True,. True, True],. [ True, True, True, True, True, True, True, True, True,. True, True, True, True, True, True, True, True, True,. True, True],. [ True, True, True, True, True, True, True, True, True,. True, True, True, True, True, True, True, True, True,. True, True],. [ True, True, True, True, True, True, True, True, True,. True, True, True, True, True, True, True, True, True,. True, True],. [ True, True, True, True, True, True, True, True, True,. True, True, True, True, True, True, True, True, True,. True, True],. [ True, True, True, True, True, True, True, True, True,. True, True, True, True, True, True, True, True, True,. True, True],. [ True, True, True, True, True, True, True, True, True,. True, True, True, True, True, True, True, True, True,. True, True],. [ True, True, True, True, True, True, True, True, True,. True, True, True, True, True, True, True, True, True,. True, True],. [ True, True, True, True, True, True, True, True, True,. True, True, True, True, True, True, True, True, True,. True, True],. [ True, True, True, True, True, True, True, True, True,. True, True, True, True, True, True, True, True, True,. True, True]])]. ```. At first I was creating all dendrograms in a list comprehension and it did the same. . I also directly inputted a list of my own and I obtained the same result.... I guess dendrogram don't detect the genes. When running functions such as . ```python . ## Testing with creating the dendro manually. def do_corr_mat(adata, var_names, groupby, method = ""spearman"") :. categories, obs_tidy = _prepare_dataframe(adata, var_names=var_names, groupby=groupby). mean_df = obs_tidy.groupby(level=0).mean(). . return mean_df.T.corr(method=method). def do_dendro(corr_matrix, method=""ward"") :. z_var = linkage(corr_matrix, method=linkage). return dendrogram(z_var, labels=mean_df.index). ``` . Everything works fine ! . Thanks by advance, . C. #### Versions. 1.6.0. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1549
https://github.com/scverse/scanpy/issues/1549:162,integrability,version,version,162,"sc.tl.dendrogram doesn't use var_names ; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. Latest on pip at least scanpy-1.6.0. ---. I'm using the sc.pl.dendrogram multiple times different lists of genes on my dataset (incrementing number of highly variable genes basically). The outputted dendrogram is alway the same (I guess it's taking into account all the genes because it's using something like 32go of ram....). ### Minimal code sample (that we can copy&paste without having any data). ```python. hvegene_sets = [sc.pp.highly_variable_genes(adata, inplace=False, subset=False, n_top_genes=nhvg)[""highly_variable""] for nhvg in [500,1000,2000, 3000,4000, 5000]]. ```. then. ```python. [sum(hvgene) for hvgene in hvegene_sets]. ```. outputs:. [499, 1000, 1999, 2999, 4000, 4999] (so i have my different genesets). then . ```python. dendro1 = sc.tl.dendrogram(adata, . var_names=adata.var_names[hvegene_sets[1]].values, . optimal_ordering=True,. cor_method=""spearman"", linkage_method=""complete"", inplace=False,. groupby=""Annotation""). dendro2 = sc.tl.dendrogram(adata, . var_names=adata.var_names[hvegene_sets[5]].values, . optimal_ordering=True,. cor_method=""spearman"", linkage_method=""complete"", inplace=False,. groupby=""Annotation""). [dendro1[key] ==dendro2[key] for key in dendro1.keys()] . ```. outputs: . ```code. [array([[ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, T",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1549
https://github.com/scverse/scanpy/issues/1549:742,integrability,sub,subset,742,"sc.tl.dendrogram doesn't use var_names ; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. Latest on pip at least scanpy-1.6.0. ---. I'm using the sc.pl.dendrogram multiple times different lists of genes on my dataset (incrementing number of highly variable genes basically). The outputted dendrogram is alway the same (I guess it's taking into account all the genes because it's using something like 32go of ram....). ### Minimal code sample (that we can copy&paste without having any data). ```python. hvegene_sets = [sc.pp.highly_variable_genes(adata, inplace=False, subset=False, n_top_genes=nhvg)[""highly_variable""] for nhvg in [500,1000,2000, 3000,4000, 5000]]. ```. then. ```python. [sum(hvgene) for hvgene in hvegene_sets]. ```. outputs:. [499, 1000, 1999, 2999, 4000, 4999] (so i have my different genesets). then . ```python. dendro1 = sc.tl.dendrogram(adata, . var_names=adata.var_names[hvegene_sets[1]].values, . optimal_ordering=True,. cor_method=""spearman"", linkage_method=""complete"", inplace=False,. groupby=""Annotation""). dendro2 = sc.tl.dendrogram(adata, . var_names=adata.var_names[hvegene_sets[5]].values, . optimal_ordering=True,. cor_method=""spearman"", linkage_method=""complete"", inplace=False,. groupby=""Annotation""). [dendro1[key] ==dendro2[key] for key in dendro1.keys()] . ```. outputs: . ```code. [array([[ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, T",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1549
https://github.com/scverse/scanpy/issues/1549:5357,integrability,Version,Versions,5357,"True, True, True, True,. True, True, True, True, True, True, True, True, True,. True, True],. [ True, True, True, True, True, True, True, True, True,. True, True, True, True, True, True, True, True, True,. True, True],. [ True, True, True, True, True, True, True, True, True,. True, True, True, True, True, True, True, True, True,. True, True],. [ True, True, True, True, True, True, True, True, True,. True, True, True, True, True, True, True, True, True,. True, True],. [ True, True, True, True, True, True, True, True, True,. True, True, True, True, True, True, True, True, True,. True, True],. [ True, True, True, True, True, True, True, True, True,. True, True, True, True, True, True, True, True, True,. True, True],. [ True, True, True, True, True, True, True, True, True,. True, True, True, True, True, True, True, True, True,. True, True],. [ True, True, True, True, True, True, True, True, True,. True, True, True, True, True, True, True, True, True,. True, True],. [ True, True, True, True, True, True, True, True, True,. True, True, True, True, True, True, True, True, True,. True, True],. [ True, True, True, True, True, True, True, True, True,. True, True, True, True, True, True, True, True, True,. True, True]])]. ```. At first I was creating all dendrograms in a list comprehension and it did the same. . I also directly inputted a list of my own and I obtained the same result.... I guess dendrogram don't detect the genes. When running functions such as . ```python . ## Testing with creating the dendro manually. def do_corr_mat(adata, var_names, groupby, method = ""spearman"") :. categories, obs_tidy = _prepare_dataframe(adata, var_names=var_names, groupby=groupby). mean_df = obs_tidy.groupby(level=0).mean(). . return mean_df.T.corr(method=method). def do_dendro(corr_matrix, method=""ward"") :. z_var = linkage(corr_matrix, method=linkage). return dendrogram(z_var, labels=mean_df.index). ``` . Everything works fine ! . Thanks by advance, . C. #### Versions. 1.6.0. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1549
https://github.com/scverse/scanpy/issues/1549:162,modifiability,version,version,162,"sc.tl.dendrogram doesn't use var_names ; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. Latest on pip at least scanpy-1.6.0. ---. I'm using the sc.pl.dendrogram multiple times different lists of genes on my dataset (incrementing number of highly variable genes basically). The outputted dendrogram is alway the same (I guess it's taking into account all the genes because it's using something like 32go of ram....). ### Minimal code sample (that we can copy&paste without having any data). ```python. hvegene_sets = [sc.pp.highly_variable_genes(adata, inplace=False, subset=False, n_top_genes=nhvg)[""highly_variable""] for nhvg in [500,1000,2000, 3000,4000, 5000]]. ```. then. ```python. [sum(hvgene) for hvgene in hvegene_sets]. ```. outputs:. [499, 1000, 1999, 2999, 4000, 4999] (so i have my different genesets). then . ```python. dendro1 = sc.tl.dendrogram(adata, . var_names=adata.var_names[hvegene_sets[1]].values, . optimal_ordering=True,. cor_method=""spearman"", linkage_method=""complete"", inplace=False,. groupby=""Annotation""). dendro2 = sc.tl.dendrogram(adata, . var_names=adata.var_names[hvegene_sets[5]].values, . optimal_ordering=True,. cor_method=""spearman"", linkage_method=""complete"", inplace=False,. groupby=""Annotation""). [dendro1[key] ==dendro2[key] for key in dendro1.keys()] . ```. outputs: . ```code. [array([[ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, T",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1549
https://github.com/scverse/scanpy/issues/1549:421,modifiability,variab,variable,421,"sc.tl.dendrogram doesn't use var_names ; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. Latest on pip at least scanpy-1.6.0. ---. I'm using the sc.pl.dendrogram multiple times different lists of genes on my dataset (incrementing number of highly variable genes basically). The outputted dendrogram is alway the same (I guess it's taking into account all the genes because it's using something like 32go of ram....). ### Minimal code sample (that we can copy&paste without having any data). ```python. hvegene_sets = [sc.pp.highly_variable_genes(adata, inplace=False, subset=False, n_top_genes=nhvg)[""highly_variable""] for nhvg in [500,1000,2000, 3000,4000, 5000]]. ```. then. ```python. [sum(hvgene) for hvgene in hvegene_sets]. ```. outputs:. [499, 1000, 1999, 2999, 4000, 4999] (so i have my different genesets). then . ```python. dendro1 = sc.tl.dendrogram(adata, . var_names=adata.var_names[hvegene_sets[1]].values, . optimal_ordering=True,. cor_method=""spearman"", linkage_method=""complete"", inplace=False,. groupby=""Annotation""). dendro2 = sc.tl.dendrogram(adata, . var_names=adata.var_names[hvegene_sets[5]].values, . optimal_ordering=True,. cor_method=""spearman"", linkage_method=""complete"", inplace=False,. groupby=""Annotation""). [dendro1[key] ==dendro2[key] for key in dendro1.keys()] . ```. outputs: . ```code. [array([[ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, T",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1549
https://github.com/scverse/scanpy/issues/1549:5357,modifiability,Version,Versions,5357,"True, True, True, True,. True, True, True, True, True, True, True, True, True,. True, True],. [ True, True, True, True, True, True, True, True, True,. True, True, True, True, True, True, True, True, True,. True, True],. [ True, True, True, True, True, True, True, True, True,. True, True, True, True, True, True, True, True, True,. True, True],. [ True, True, True, True, True, True, True, True, True,. True, True, True, True, True, True, True, True, True,. True, True],. [ True, True, True, True, True, True, True, True, True,. True, True, True, True, True, True, True, True, True,. True, True],. [ True, True, True, True, True, True, True, True, True,. True, True, True, True, True, True, True, True, True,. True, True],. [ True, True, True, True, True, True, True, True, True,. True, True, True, True, True, True, True, True, True,. True, True],. [ True, True, True, True, True, True, True, True, True,. True, True, True, True, True, True, True, True, True,. True, True],. [ True, True, True, True, True, True, True, True, True,. True, True, True, True, True, True, True, True, True,. True, True],. [ True, True, True, True, True, True, True, True, True,. True, True, True, True, True, True, True, True, True,. True, True]])]. ```. At first I was creating all dendrograms in a list comprehension and it did the same. . I also directly inputted a list of my own and I obtained the same result.... I guess dendrogram don't detect the genes. When running functions such as . ```python . ## Testing with creating the dendro manually. def do_corr_mat(adata, var_names, groupby, method = ""spearman"") :. categories, obs_tidy = _prepare_dataframe(adata, var_names=var_names, groupby=groupby). mean_df = obs_tidy.groupby(level=0).mean(). . return mean_df.T.corr(method=method). def do_dendro(corr_matrix, method=""ward"") :. z_var = linkage(corr_matrix, method=linkage). return dendrogram(z_var, labels=mean_df.index). ``` . Everything works fine ! . Thanks by advance, . C. #### Versions. 1.6.0. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1549
https://github.com/scverse/scanpy/issues/1549:345,performance,time,times,345,"sc.tl.dendrogram doesn't use var_names ; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. Latest on pip at least scanpy-1.6.0. ---. I'm using the sc.pl.dendrogram multiple times different lists of genes on my dataset (incrementing number of highly variable genes basically). The outputted dendrogram is alway the same (I guess it's taking into account all the genes because it's using something like 32go of ram....). ### Minimal code sample (that we can copy&paste without having any data). ```python. hvegene_sets = [sc.pp.highly_variable_genes(adata, inplace=False, subset=False, n_top_genes=nhvg)[""highly_variable""] for nhvg in [500,1000,2000, 3000,4000, 5000]]. ```. then. ```python. [sum(hvgene) for hvgene in hvegene_sets]. ```. outputs:. [499, 1000, 1999, 2999, 4000, 4999] (so i have my different genesets). then . ```python. dendro1 = sc.tl.dendrogram(adata, . var_names=adata.var_names[hvegene_sets[1]].values, . optimal_ordering=True,. cor_method=""spearman"", linkage_method=""complete"", inplace=False,. groupby=""Annotation""). dendro2 = sc.tl.dendrogram(adata, . var_names=adata.var_names[hvegene_sets[5]].values, . optimal_ordering=True,. cor_method=""spearman"", linkage_method=""complete"", inplace=False,. groupby=""Annotation""). [dendro1[key] ==dendro2[key] for key in dendro1.keys()] . ```. outputs: . ```code. [array([[ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, T",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1549
https://github.com/scverse/scanpy/issues/1549:17,reliability,doe,doesn,17,"sc.tl.dendrogram doesn't use var_names ; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. Latest on pip at least scanpy-1.6.0. ---. I'm using the sc.pl.dendrogram multiple times different lists of genes on my dataset (incrementing number of highly variable genes basically). The outputted dendrogram is alway the same (I guess it's taking into account all the genes because it's using something like 32go of ram....). ### Minimal code sample (that we can copy&paste without having any data). ```python. hvegene_sets = [sc.pp.highly_variable_genes(adata, inplace=False, subset=False, n_top_genes=nhvg)[""highly_variable""] for nhvg in [500,1000,2000, 3000,4000, 5000]]. ```. then. ```python. [sum(hvgene) for hvgene in hvegene_sets]. ```. outputs:. [499, 1000, 1999, 2999, 4000, 4999] (so i have my different genesets). then . ```python. dendro1 = sc.tl.dendrogram(adata, . var_names=adata.var_names[hvegene_sets[1]].values, . optimal_ordering=True,. cor_method=""spearman"", linkage_method=""complete"", inplace=False,. groupby=""Annotation""). dendro2 = sc.tl.dendrogram(adata, . var_names=adata.var_names[hvegene_sets[5]].values, . optimal_ordering=True,. cor_method=""spearman"", linkage_method=""complete"", inplace=False,. groupby=""Annotation""). [dendro1[key] ==dendro2[key] for key in dendro1.keys()] . ```. outputs: . ```code. [array([[ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, T",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1549
https://github.com/scverse/scanpy/issues/1549:1160,safety,compl,complete,1160,"rsion of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. Latest on pip at least scanpy-1.6.0. ---. I'm using the sc.pl.dendrogram multiple times different lists of genes on my dataset (incrementing number of highly variable genes basically). The outputted dendrogram is alway the same (I guess it's taking into account all the genes because it's using something like 32go of ram....). ### Minimal code sample (that we can copy&paste without having any data). ```python. hvegene_sets = [sc.pp.highly_variable_genes(adata, inplace=False, subset=False, n_top_genes=nhvg)[""highly_variable""] for nhvg in [500,1000,2000, 3000,4000, 5000]]. ```. then. ```python. [sum(hvgene) for hvgene in hvegene_sets]. ```. outputs:. [499, 1000, 1999, 2999, 4000, 4999] (so i have my different genesets). then . ```python. dendro1 = sc.tl.dendrogram(adata, . var_names=adata.var_names[hvegene_sets[1]].values, . optimal_ordering=True,. cor_method=""spearman"", linkage_method=""complete"", inplace=False,. groupby=""Annotation""). dendro2 = sc.tl.dendrogram(adata, . var_names=adata.var_names[hvegene_sets[5]].values, . optimal_ordering=True,. cor_method=""spearman"", linkage_method=""complete"", inplace=False,. groupby=""Annotation""). [dendro1[key] ==dendro2[key] for key in dendro1.keys()] . ```. outputs: . ```code. [array([[ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True]]),. True,. True,. True,. True,. True,. True,. True,. array([[ True, True, True, True, True, True, True, True, True,. True, True, Tr",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1549
https://github.com/scverse/scanpy/issues/1549:1362,safety,compl,complete,1362," of genes on my dataset (incrementing number of highly variable genes basically). The outputted dendrogram is alway the same (I guess it's taking into account all the genes because it's using something like 32go of ram....). ### Minimal code sample (that we can copy&paste without having any data). ```python. hvegene_sets = [sc.pp.highly_variable_genes(adata, inplace=False, subset=False, n_top_genes=nhvg)[""highly_variable""] for nhvg in [500,1000,2000, 3000,4000, 5000]]. ```. then. ```python. [sum(hvgene) for hvgene in hvegene_sets]. ```. outputs:. [499, 1000, 1999, 2999, 4000, 4999] (so i have my different genesets). then . ```python. dendro1 = sc.tl.dendrogram(adata, . var_names=adata.var_names[hvegene_sets[1]].values, . optimal_ordering=True,. cor_method=""spearman"", linkage_method=""complete"", inplace=False,. groupby=""Annotation""). dendro2 = sc.tl.dendrogram(adata, . var_names=adata.var_names[hvegene_sets[5]].values, . optimal_ordering=True,. cor_method=""spearman"", linkage_method=""complete"", inplace=False,. groupby=""Annotation""). [dendro1[key] ==dendro2[key] for key in dendro1.keys()] . ```. outputs: . ```code. [array([[ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True]]),. True,. True,. True,. True,. True,. True,. True,. array([[ True, True, True, True, True, True, True, True, True,. True, True, True, True, True, True, True, True, True,. True, True],. [ True, True, True, True, True, True, True, True, True,. True, True, True, True, True, True, True, True, True,. True, True],. [ True, True, True, T",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1549
https://github.com/scverse/scanpy/issues/1549:4723,safety,input,inputted,4723,"True, True, True, True,. True, True, True, True, True, True, True, True, True,. True, True],. [ True, True, True, True, True, True, True, True, True,. True, True, True, True, True, True, True, True, True,. True, True],. [ True, True, True, True, True, True, True, True, True,. True, True, True, True, True, True, True, True, True,. True, True],. [ True, True, True, True, True, True, True, True, True,. True, True, True, True, True, True, True, True, True,. True, True],. [ True, True, True, True, True, True, True, True, True,. True, True, True, True, True, True, True, True, True,. True, True],. [ True, True, True, True, True, True, True, True, True,. True, True, True, True, True, True, True, True, True,. True, True],. [ True, True, True, True, True, True, True, True, True,. True, True, True, True, True, True, True, True, True,. True, True],. [ True, True, True, True, True, True, True, True, True,. True, True, True, True, True, True, True, True, True,. True, True],. [ True, True, True, True, True, True, True, True, True,. True, True, True, True, True, True, True, True, True,. True, True],. [ True, True, True, True, True, True, True, True, True,. True, True, True, True, True, True, True, True, True,. True, True]])]. ```. At first I was creating all dendrograms in a list comprehension and it did the same. . I also directly inputted a list of my own and I obtained the same result.... I guess dendrogram don't detect the genes. When running functions such as . ```python . ## Testing with creating the dendro manually. def do_corr_mat(adata, var_names, groupby, method = ""spearman"") :. categories, obs_tidy = _prepare_dataframe(adata, var_names=var_names, groupby=groupby). mean_df = obs_tidy.groupby(level=0).mean(). . return mean_df.T.corr(method=method). def do_dendro(corr_matrix, method=""ward"") :. z_var = linkage(corr_matrix, method=linkage). return dendrogram(z_var, labels=mean_df.index). ``` . Everything works fine ! . Thanks by advance, . C. #### Versions. 1.6.0. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1549
https://github.com/scverse/scanpy/issues/1549:4809,safety,detect,detect,4809,"True, True, True, True,. True, True, True, True, True, True, True, True, True,. True, True],. [ True, True, True, True, True, True, True, True, True,. True, True, True, True, True, True, True, True, True,. True, True],. [ True, True, True, True, True, True, True, True, True,. True, True, True, True, True, True, True, True, True,. True, True],. [ True, True, True, True, True, True, True, True, True,. True, True, True, True, True, True, True, True, True,. True, True],. [ True, True, True, True, True, True, True, True, True,. True, True, True, True, True, True, True, True, True,. True, True],. [ True, True, True, True, True, True, True, True, True,. True, True, True, True, True, True, True, True, True,. True, True],. [ True, True, True, True, True, True, True, True, True,. True, True, True, True, True, True, True, True, True,. True, True],. [ True, True, True, True, True, True, True, True, True,. True, True, True, True, True, True, True, True, True,. True, True],. [ True, True, True, True, True, True, True, True, True,. True, True, True, True, True, True, True, True, True,. True, True],. [ True, True, True, True, True, True, True, True, True,. True, True, True, True, True, True, True, True, True,. True, True]])]. ```. At first I was creating all dendrograms in a list comprehension and it did the same. . I also directly inputted a list of my own and I obtained the same result.... I guess dendrogram don't detect the genes. When running functions such as . ```python . ## Testing with creating the dendro manually. def do_corr_mat(adata, var_names, groupby, method = ""spearman"") :. categories, obs_tidy = _prepare_dataframe(adata, var_names=var_names, groupby=groupby). mean_df = obs_tidy.groupby(level=0).mean(). . return mean_df.T.corr(method=method). def do_dendro(corr_matrix, method=""ward"") :. z_var = linkage(corr_matrix, method=linkage). return dendrogram(z_var, labels=mean_df.index). ``` . Everything works fine ! . Thanks by advance, . C. #### Versions. 1.6.0. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1549
https://github.com/scverse/scanpy/issues/1549:4875,safety,Test,Testing,4875,"True, True, True, True,. True, True, True, True, True, True, True, True, True,. True, True],. [ True, True, True, True, True, True, True, True, True,. True, True, True, True, True, True, True, True, True,. True, True],. [ True, True, True, True, True, True, True, True, True,. True, True, True, True, True, True, True, True, True,. True, True],. [ True, True, True, True, True, True, True, True, True,. True, True, True, True, True, True, True, True, True,. True, True],. [ True, True, True, True, True, True, True, True, True,. True, True, True, True, True, True, True, True, True,. True, True],. [ True, True, True, True, True, True, True, True, True,. True, True, True, True, True, True, True, True, True,. True, True],. [ True, True, True, True, True, True, True, True, True,. True, True, True, True, True, True, True, True, True,. True, True],. [ True, True, True, True, True, True, True, True, True,. True, True, True, True, True, True, True, True, True,. True, True],. [ True, True, True, True, True, True, True, True, True,. True, True, True, True, True, True, True, True, True,. True, True],. [ True, True, True, True, True, True, True, True, True,. True, True, True, True, True, True, True, True, True,. True, True]])]. ```. At first I was creating all dendrograms in a list comprehension and it did the same. . I also directly inputted a list of my own and I obtained the same result.... I guess dendrogram don't detect the genes. When running functions such as . ```python . ## Testing with creating the dendro manually. def do_corr_mat(adata, var_names, groupby, method = ""spearman"") :. categories, obs_tidy = _prepare_dataframe(adata, var_names=var_names, groupby=groupby). mean_df = obs_tidy.groupby(level=0).mean(). . return mean_df.T.corr(method=method). def do_dendro(corr_matrix, method=""ward"") :. z_var = linkage(corr_matrix, method=linkage). return dendrogram(z_var, labels=mean_df.index). ``` . Everything works fine ! . Thanks by advance, . C. #### Versions. 1.6.0. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1549
https://github.com/scverse/scanpy/issues/1549:1160,security,compl,complete,1160,"rsion of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. Latest on pip at least scanpy-1.6.0. ---. I'm using the sc.pl.dendrogram multiple times different lists of genes on my dataset (incrementing number of highly variable genes basically). The outputted dendrogram is alway the same (I guess it's taking into account all the genes because it's using something like 32go of ram....). ### Minimal code sample (that we can copy&paste without having any data). ```python. hvegene_sets = [sc.pp.highly_variable_genes(adata, inplace=False, subset=False, n_top_genes=nhvg)[""highly_variable""] for nhvg in [500,1000,2000, 3000,4000, 5000]]. ```. then. ```python. [sum(hvgene) for hvgene in hvegene_sets]. ```. outputs:. [499, 1000, 1999, 2999, 4000, 4999] (so i have my different genesets). then . ```python. dendro1 = sc.tl.dendrogram(adata, . var_names=adata.var_names[hvegene_sets[1]].values, . optimal_ordering=True,. cor_method=""spearman"", linkage_method=""complete"", inplace=False,. groupby=""Annotation""). dendro2 = sc.tl.dendrogram(adata, . var_names=adata.var_names[hvegene_sets[5]].values, . optimal_ordering=True,. cor_method=""spearman"", linkage_method=""complete"", inplace=False,. groupby=""Annotation""). [dendro1[key] ==dendro2[key] for key in dendro1.keys()] . ```. outputs: . ```code. [array([[ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True]]),. True,. True,. True,. True,. True,. True,. True,. array([[ True, True, True, True, True, True, True, True, True,. True, True, Tr",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1549
https://github.com/scverse/scanpy/issues/1549:1362,security,compl,complete,1362," of genes on my dataset (incrementing number of highly variable genes basically). The outputted dendrogram is alway the same (I guess it's taking into account all the genes because it's using something like 32go of ram....). ### Minimal code sample (that we can copy&paste without having any data). ```python. hvegene_sets = [sc.pp.highly_variable_genes(adata, inplace=False, subset=False, n_top_genes=nhvg)[""highly_variable""] for nhvg in [500,1000,2000, 3000,4000, 5000]]. ```. then. ```python. [sum(hvgene) for hvgene in hvegene_sets]. ```. outputs:. [499, 1000, 1999, 2999, 4000, 4999] (so i have my different genesets). then . ```python. dendro1 = sc.tl.dendrogram(adata, . var_names=adata.var_names[hvegene_sets[1]].values, . optimal_ordering=True,. cor_method=""spearman"", linkage_method=""complete"", inplace=False,. groupby=""Annotation""). dendro2 = sc.tl.dendrogram(adata, . var_names=adata.var_names[hvegene_sets[5]].values, . optimal_ordering=True,. cor_method=""spearman"", linkage_method=""complete"", inplace=False,. groupby=""Annotation""). [dendro1[key] ==dendro2[key] for key in dendro1.keys()] . ```. outputs: . ```code. [array([[ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True]]),. True,. True,. True,. True,. True,. True,. True,. array([[ True, True, True, True, True, True, True, True, True,. True, True, True, True, True, True, True, True, True,. True, True],. [ True, True, True, True, True, True, True, True, True,. True, True, True, True, True, True, True, True, True,. True, True],. [ True, True, True, T",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1549
https://github.com/scverse/scanpy/issues/1549:4809,security,detect,detect,4809,"True, True, True, True,. True, True, True, True, True, True, True, True, True,. True, True],. [ True, True, True, True, True, True, True, True, True,. True, True, True, True, True, True, True, True, True,. True, True],. [ True, True, True, True, True, True, True, True, True,. True, True, True, True, True, True, True, True, True,. True, True],. [ True, True, True, True, True, True, True, True, True,. True, True, True, True, True, True, True, True, True,. True, True],. [ True, True, True, True, True, True, True, True, True,. True, True, True, True, True, True, True, True, True,. True, True],. [ True, True, True, True, True, True, True, True, True,. True, True, True, True, True, True, True, True, True,. True, True],. [ True, True, True, True, True, True, True, True, True,. True, True, True, True, True, True, True, True, True,. True, True],. [ True, True, True, True, True, True, True, True, True,. True, True, True, True, True, True, True, True, True,. True, True],. [ True, True, True, True, True, True, True, True, True,. True, True, True, True, True, True, True, True, True,. True, True],. [ True, True, True, True, True, True, True, True, True,. True, True, True, True, True, True, True, True, True,. True, True]])]. ```. At first I was creating all dendrograms in a list comprehension and it did the same. . I also directly inputted a list of my own and I obtained the same result.... I guess dendrogram don't detect the genes. When running functions such as . ```python . ## Testing with creating the dendro manually. def do_corr_mat(adata, var_names, groupby, method = ""spearman"") :. categories, obs_tidy = _prepare_dataframe(adata, var_names=var_names, groupby=groupby). mean_df = obs_tidy.groupby(level=0).mean(). . return mean_df.T.corr(method=method). def do_dendro(corr_matrix, method=""ward"") :. z_var = linkage(corr_matrix, method=linkage). return dendrogram(z_var, labels=mean_df.index). ``` . Everything works fine ! . Thanks by advance, . C. #### Versions. 1.6.0. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1549
https://github.com/scverse/scanpy/issues/1549:4875,testability,Test,Testing,4875,"True, True, True, True,. True, True, True, True, True, True, True, True, True,. True, True],. [ True, True, True, True, True, True, True, True, True,. True, True, True, True, True, True, True, True, True,. True, True],. [ True, True, True, True, True, True, True, True, True,. True, True, True, True, True, True, True, True, True,. True, True],. [ True, True, True, True, True, True, True, True, True,. True, True, True, True, True, True, True, True, True,. True, True],. [ True, True, True, True, True, True, True, True, True,. True, True, True, True, True, True, True, True, True,. True, True],. [ True, True, True, True, True, True, True, True, True,. True, True, True, True, True, True, True, True, True,. True, True],. [ True, True, True, True, True, True, True, True, True,. True, True, True, True, True, True, True, True, True,. True, True],. [ True, True, True, True, True, True, True, True, True,. True, True, True, True, True, True, True, True, True,. True, True],. [ True, True, True, True, True, True, True, True, True,. True, True, True, True, True, True, True, True, True,. True, True],. [ True, True, True, True, True, True, True, True, True,. True, True, True, True, True, True, True, True, True,. True, True]])]. ```. At first I was creating all dendrograms in a list comprehension and it did the same. . I also directly inputted a list of my own and I obtained the same result.... I guess dendrogram don't detect the genes. When running functions such as . ```python . ## Testing with creating the dendro manually. def do_corr_mat(adata, var_names, groupby, method = ""spearman"") :. categories, obs_tidy = _prepare_dataframe(adata, var_names=var_names, groupby=groupby). mean_df = obs_tidy.groupby(level=0).mean(). . return mean_df.T.corr(method=method). def do_dendro(corr_matrix, method=""ward"") :. z_var = linkage(corr_matrix, method=linkage). return dendrogram(z_var, labels=mean_df.index). ``` . Everything works fine ! . Thanks by advance, . C. #### Versions. 1.6.0. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1549
https://github.com/scverse/scanpy/issues/1549:122,usability,confirm,confirmed,122,"sc.tl.dendrogram doesn't use var_names ; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. Latest on pip at least scanpy-1.6.0. ---. I'm using the sc.pl.dendrogram multiple times different lists of genes on my dataset (incrementing number of highly variable genes basically). The outputted dendrogram is alway the same (I guess it's taking into account all the genes because it's using something like 32go of ram....). ### Minimal code sample (that we can copy&paste without having any data). ```python. hvegene_sets = [sc.pp.highly_variable_genes(adata, inplace=False, subset=False, n_top_genes=nhvg)[""highly_variable""] for nhvg in [500,1000,2000, 3000,4000, 5000]]. ```. then. ```python. [sum(hvgene) for hvgene in hvegene_sets]. ```. outputs:. [499, 1000, 1999, 2999, 4000, 4999] (so i have my different genesets). then . ```python. dendro1 = sc.tl.dendrogram(adata, . var_names=adata.var_names[hvegene_sets[1]].values, . optimal_ordering=True,. cor_method=""spearman"", linkage_method=""complete"", inplace=False,. groupby=""Annotation""). dendro2 = sc.tl.dendrogram(adata, . var_names=adata.var_names[hvegene_sets[5]].values, . optimal_ordering=True,. cor_method=""spearman"", linkage_method=""complete"", inplace=False,. groupby=""Annotation""). [dendro1[key] ==dendro2[key] for key in dendro1.keys()] . ```. outputs: . ```code. [array([[ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, T",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1549
https://github.com/scverse/scanpy/issues/1549:205,usability,confirm,confirmed,205,"sc.tl.dendrogram doesn't use var_names ; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. Latest on pip at least scanpy-1.6.0. ---. I'm using the sc.pl.dendrogram multiple times different lists of genes on my dataset (incrementing number of highly variable genes basically). The outputted dendrogram is alway the same (I guess it's taking into account all the genes because it's using something like 32go of ram....). ### Minimal code sample (that we can copy&paste without having any data). ```python. hvegene_sets = [sc.pp.highly_variable_genes(adata, inplace=False, subset=False, n_top_genes=nhvg)[""highly_variable""] for nhvg in [500,1000,2000, 3000,4000, 5000]]. ```. then. ```python. [sum(hvgene) for hvgene in hvegene_sets]. ```. outputs:. [499, 1000, 1999, 2999, 4000, 4999] (so i have my different genesets). then . ```python. dendro1 = sc.tl.dendrogram(adata, . var_names=adata.var_names[hvegene_sets[1]].values, . optimal_ordering=True,. cor_method=""spearman"", linkage_method=""complete"", inplace=False,. groupby=""Annotation""). dendro2 = sc.tl.dendrogram(adata, . var_names=adata.var_names[hvegene_sets[5]].values, . optimal_ordering=True,. cor_method=""spearman"", linkage_method=""complete"", inplace=False,. groupby=""Annotation""). [dendro1[key] ==dendro2[key] for key in dendro1.keys()] . ```. outputs: . ```code. [array([[ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, T",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1549
https://github.com/scverse/scanpy/issues/1549:595,usability,Minim,Minimal,595,"sc.tl.dendrogram doesn't use var_names ; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. Latest on pip at least scanpy-1.6.0. ---. I'm using the sc.pl.dendrogram multiple times different lists of genes on my dataset (incrementing number of highly variable genes basically). The outputted dendrogram is alway the same (I guess it's taking into account all the genes because it's using something like 32go of ram....). ### Minimal code sample (that we can copy&paste without having any data). ```python. hvegene_sets = [sc.pp.highly_variable_genes(adata, inplace=False, subset=False, n_top_genes=nhvg)[""highly_variable""] for nhvg in [500,1000,2000, 3000,4000, 5000]]. ```. then. ```python. [sum(hvgene) for hvgene in hvegene_sets]. ```. outputs:. [499, 1000, 1999, 2999, 4000, 4999] (so i have my different genesets). then . ```python. dendro1 = sc.tl.dendrogram(adata, . var_names=adata.var_names[hvegene_sets[1]].values, . optimal_ordering=True,. cor_method=""spearman"", linkage_method=""complete"", inplace=False,. groupby=""Annotation""). dendro2 = sc.tl.dendrogram(adata, . var_names=adata.var_names[hvegene_sets[5]].values, . optimal_ordering=True,. cor_method=""spearman"", linkage_method=""complete"", inplace=False,. groupby=""Annotation""). [dendro1[key] ==dendro2[key] for key in dendro1.keys()] . ```. outputs: . ```code. [array([[ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, True],. [ True, True, True, T",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1549
https://github.com/scverse/scanpy/issues/1549:4723,usability,input,inputted,4723,"True, True, True, True,. True, True, True, True, True, True, True, True, True,. True, True],. [ True, True, True, True, True, True, True, True, True,. True, True, True, True, True, True, True, True, True,. True, True],. [ True, True, True, True, True, True, True, True, True,. True, True, True, True, True, True, True, True, True,. True, True],. [ True, True, True, True, True, True, True, True, True,. True, True, True, True, True, True, True, True, True,. True, True],. [ True, True, True, True, True, True, True, True, True,. True, True, True, True, True, True, True, True, True,. True, True],. [ True, True, True, True, True, True, True, True, True,. True, True, True, True, True, True, True, True, True,. True, True],. [ True, True, True, True, True, True, True, True, True,. True, True, True, True, True, True, True, True, True,. True, True],. [ True, True, True, True, True, True, True, True, True,. True, True, True, True, True, True, True, True, True,. True, True],. [ True, True, True, True, True, True, True, True, True,. True, True, True, True, True, True, True, True, True,. True, True],. [ True, True, True, True, True, True, True, True, True,. True, True, True, True, True, True, True, True, True,. True, True]])]. ```. At first I was creating all dendrograms in a list comprehension and it did the same. . I also directly inputted a list of my own and I obtained the same result.... I guess dendrogram don't detect the genes. When running functions such as . ```python . ## Testing with creating the dendro manually. def do_corr_mat(adata, var_names, groupby, method = ""spearman"") :. categories, obs_tidy = _prepare_dataframe(adata, var_names=var_names, groupby=groupby). mean_df = obs_tidy.groupby(level=0).mean(). . return mean_df.T.corr(method=method). def do_dendro(corr_matrix, method=""ward"") :. z_var = linkage(corr_matrix, method=linkage). return dendrogram(z_var, labels=mean_df.index). ``` . Everything works fine ! . Thanks by advance, . C. #### Versions. 1.6.0. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1549
https://github.com/scverse/scanpy/issues/1550:0,deployability,continu,continuous,0,"continuous color map; Hi,. When plotting gene expression profile on tsne/umap, Cellranger and Seurat can display the zero-expression cells in gray color, while scanpy doesn't display those cells. such as:. Seurat featureplot:. ![image](https://user-images.githubusercontent.com/29703450/102605221-f1d68b00-415f-11eb-9bc2-797a25db897e.png). . And cellranger:. ![image](https://user-images.githubusercontent.com/29703450/102605354-1df20c00-4160-11eb-9a16-501da6d951d4.png). It's useful to show all cells (including zero-expression cells), because we can estimate the percentage of cells that expressing some markers at a glance. It seems that all cells are in gray color, then red/blue color are overlaid on the bottom color (namely the gray color) according to the gene expression value . In addition to Scanpy, cellranger and seurat are also very popular, many students ask me to adopt this style on their plot, because they read some papers and see this style on the papers, then they were influenced a lot by cellranger and seurat. I don't know how to fulfill it with scany. I cannot find the corresponding colormap in scanpy and matplotlib, Is there a way to add this feature ?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1550
https://github.com/scverse/scanpy/issues/1550:57,energy efficiency,profil,profile,57,"continuous color map; Hi,. When plotting gene expression profile on tsne/umap, Cellranger and Seurat can display the zero-expression cells in gray color, while scanpy doesn't display those cells. such as:. Seurat featureplot:. ![image](https://user-images.githubusercontent.com/29703450/102605221-f1d68b00-415f-11eb-9bc2-797a25db897e.png). . And cellranger:. ![image](https://user-images.githubusercontent.com/29703450/102605354-1df20c00-4160-11eb-9a16-501da6d951d4.png). It's useful to show all cells (including zero-expression cells), because we can estimate the percentage of cells that expressing some markers at a glance. It seems that all cells are in gray color, then red/blue color are overlaid on the bottom color (namely the gray color) according to the gene expression value . In addition to Scanpy, cellranger and seurat are also very popular, many students ask me to adopt this style on their plot, because they read some papers and see this style on the papers, then they were influenced a lot by cellranger and seurat. I don't know how to fulfill it with scany. I cannot find the corresponding colormap in scanpy and matplotlib, Is there a way to add this feature ?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1550
https://github.com/scverse/scanpy/issues/1550:552,energy efficiency,estimat,estimate,552,"continuous color map; Hi,. When plotting gene expression profile on tsne/umap, Cellranger and Seurat can display the zero-expression cells in gray color, while scanpy doesn't display those cells. such as:. Seurat featureplot:. ![image](https://user-images.githubusercontent.com/29703450/102605221-f1d68b00-415f-11eb-9bc2-797a25db897e.png). . And cellranger:. ![image](https://user-images.githubusercontent.com/29703450/102605354-1df20c00-4160-11eb-9a16-501da6d951d4.png). It's useful to show all cells (including zero-expression cells), because we can estimate the percentage of cells that expressing some markers at a glance. It seems that all cells are in gray color, then red/blue color are overlaid on the bottom color (namely the gray color) according to the gene expression value . In addition to Scanpy, cellranger and seurat are also very popular, many students ask me to adopt this style on their plot, because they read some papers and see this style on the papers, then they were influenced a lot by cellranger and seurat. I don't know how to fulfill it with scany. I cannot find the corresponding colormap in scanpy and matplotlib, Is there a way to add this feature ?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1550
https://github.com/scverse/scanpy/issues/1550:57,performance,profil,profile,57,"continuous color map; Hi,. When plotting gene expression profile on tsne/umap, Cellranger and Seurat can display the zero-expression cells in gray color, while scanpy doesn't display those cells. such as:. Seurat featureplot:. ![image](https://user-images.githubusercontent.com/29703450/102605221-f1d68b00-415f-11eb-9bc2-797a25db897e.png). . And cellranger:. ![image](https://user-images.githubusercontent.com/29703450/102605354-1df20c00-4160-11eb-9a16-501da6d951d4.png). It's useful to show all cells (including zero-expression cells), because we can estimate the percentage of cells that expressing some markers at a glance. It seems that all cells are in gray color, then red/blue color are overlaid on the bottom color (namely the gray color) according to the gene expression value . In addition to Scanpy, cellranger and seurat are also very popular, many students ask me to adopt this style on their plot, because they read some papers and see this style on the papers, then they were influenced a lot by cellranger and seurat. I don't know how to fulfill it with scany. I cannot find the corresponding colormap in scanpy and matplotlib, Is there a way to add this feature ?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1550
https://github.com/scverse/scanpy/issues/1550:167,reliability,doe,doesn,167,"continuous color map; Hi,. When plotting gene expression profile on tsne/umap, Cellranger and Seurat can display the zero-expression cells in gray color, while scanpy doesn't display those cells. such as:. Seurat featureplot:. ![image](https://user-images.githubusercontent.com/29703450/102605221-f1d68b00-415f-11eb-9bc2-797a25db897e.png). . And cellranger:. ![image](https://user-images.githubusercontent.com/29703450/102605354-1df20c00-4160-11eb-9a16-501da6d951d4.png). It's useful to show all cells (including zero-expression cells), because we can estimate the percentage of cells that expressing some markers at a glance. It seems that all cells are in gray color, then red/blue color are overlaid on the bottom color (namely the gray color) according to the gene expression value . In addition to Scanpy, cellranger and seurat are also very popular, many students ask me to adopt this style on their plot, because they read some papers and see this style on the papers, then they were influenced a lot by cellranger and seurat. I don't know how to fulfill it with scany. I cannot find the corresponding colormap in scanpy and matplotlib, Is there a way to add this feature ?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1550
https://github.com/scverse/scanpy/issues/1550:244,usability,user,user-images,244,"continuous color map; Hi,. When plotting gene expression profile on tsne/umap, Cellranger and Seurat can display the zero-expression cells in gray color, while scanpy doesn't display those cells. such as:. Seurat featureplot:. ![image](https://user-images.githubusercontent.com/29703450/102605221-f1d68b00-415f-11eb-9bc2-797a25db897e.png). . And cellranger:. ![image](https://user-images.githubusercontent.com/29703450/102605354-1df20c00-4160-11eb-9a16-501da6d951d4.png). It's useful to show all cells (including zero-expression cells), because we can estimate the percentage of cells that expressing some markers at a glance. It seems that all cells are in gray color, then red/blue color are overlaid on the bottom color (namely the gray color) according to the gene expression value . In addition to Scanpy, cellranger and seurat are also very popular, many students ask me to adopt this style on their plot, because they read some papers and see this style on the papers, then they were influenced a lot by cellranger and seurat. I don't know how to fulfill it with scany. I cannot find the corresponding colormap in scanpy and matplotlib, Is there a way to add this feature ?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1550
https://github.com/scverse/scanpy/issues/1550:376,usability,user,user-images,376,"continuous color map; Hi,. When plotting gene expression profile on tsne/umap, Cellranger and Seurat can display the zero-expression cells in gray color, while scanpy doesn't display those cells. such as:. Seurat featureplot:. ![image](https://user-images.githubusercontent.com/29703450/102605221-f1d68b00-415f-11eb-9bc2-797a25db897e.png). . And cellranger:. ![image](https://user-images.githubusercontent.com/29703450/102605354-1df20c00-4160-11eb-9a16-501da6d951d4.png). It's useful to show all cells (including zero-expression cells), because we can estimate the percentage of cells that expressing some markers at a glance. It seems that all cells are in gray color, then red/blue color are overlaid on the bottom color (namely the gray color) according to the gene expression value . In addition to Scanpy, cellranger and seurat are also very popular, many students ask me to adopt this style on their plot, because they read some papers and see this style on the papers, then they were influenced a lot by cellranger and seurat. I don't know how to fulfill it with scany. I cannot find the corresponding colormap in scanpy and matplotlib, Is there a way to add this feature ?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1550
https://github.com/scverse/scanpy/pull/1551:263,deployability,scale,scale,263,"Asymmetrical diverging colormaps and vcenter; Hi,. I started playing around with `vcenter` and adding support for it in plotting functions. This allows us to do things like:. ```python. import scanpy as sc. adata = sc.datasets.paul15(). sc.pp.log1p(adata). sc.pp.scale(adata). genes = ['Cst3', 'Car1', 'Cd34', 'Apoe', 'Top2a', 'Ccl5', 'Ctsw']. sc.pl.matrixplot(adata, genes, groupby='paul15_clusters', vmin=-2, vmax=5, vcenter=0, cmap='RdBu_r'). ```. ![image](https://user-images.githubusercontent.com/1140359/102667661-ebdcac00-4157-11eb-9aac-d610283511e2.png). I haven't gone further before asking you if it makes sense at all, or not. If yes, I can try to write tests too. What do you think?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1551
https://github.com/scverse/scanpy/pull/1551:263,energy efficiency,scale,scale,263,"Asymmetrical diverging colormaps and vcenter; Hi,. I started playing around with `vcenter` and adding support for it in plotting functions. This allows us to do things like:. ```python. import scanpy as sc. adata = sc.datasets.paul15(). sc.pp.log1p(adata). sc.pp.scale(adata). genes = ['Cst3', 'Car1', 'Cd34', 'Apoe', 'Top2a', 'Ccl5', 'Ctsw']. sc.pl.matrixplot(adata, genes, groupby='paul15_clusters', vmin=-2, vmax=5, vcenter=0, cmap='RdBu_r'). ```. ![image](https://user-images.githubusercontent.com/1140359/102667661-ebdcac00-4157-11eb-9aac-d610283511e2.png). I haven't gone further before asking you if it makes sense at all, or not. If yes, I can try to write tests too. What do you think?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1551
https://github.com/scverse/scanpy/pull/1551:263,modifiability,scal,scale,263,"Asymmetrical diverging colormaps and vcenter; Hi,. I started playing around with `vcenter` and adding support for it in plotting functions. This allows us to do things like:. ```python. import scanpy as sc. adata = sc.datasets.paul15(). sc.pp.log1p(adata). sc.pp.scale(adata). genes = ['Cst3', 'Car1', 'Cd34', 'Apoe', 'Top2a', 'Ccl5', 'Ctsw']. sc.pl.matrixplot(adata, genes, groupby='paul15_clusters', vmin=-2, vmax=5, vcenter=0, cmap='RdBu_r'). ```. ![image](https://user-images.githubusercontent.com/1140359/102667661-ebdcac00-4157-11eb-9aac-d610283511e2.png). I haven't gone further before asking you if it makes sense at all, or not. If yes, I can try to write tests too. What do you think?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1551
https://github.com/scverse/scanpy/pull/1551:263,performance,scale,scale,263,"Asymmetrical diverging colormaps and vcenter; Hi,. I started playing around with `vcenter` and adding support for it in plotting functions. This allows us to do things like:. ```python. import scanpy as sc. adata = sc.datasets.paul15(). sc.pp.log1p(adata). sc.pp.scale(adata). genes = ['Cst3', 'Car1', 'Cd34', 'Apoe', 'Top2a', 'Ccl5', 'Ctsw']. sc.pl.matrixplot(adata, genes, groupby='paul15_clusters', vmin=-2, vmax=5, vcenter=0, cmap='RdBu_r'). ```. ![image](https://user-images.githubusercontent.com/1140359/102667661-ebdcac00-4157-11eb-9aac-d610283511e2.png). I haven't gone further before asking you if it makes sense at all, or not. If yes, I can try to write tests too. What do you think?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1551
https://github.com/scverse/scanpy/pull/1551:665,safety,test,tests,665,"Asymmetrical diverging colormaps and vcenter; Hi,. I started playing around with `vcenter` and adding support for it in plotting functions. This allows us to do things like:. ```python. import scanpy as sc. adata = sc.datasets.paul15(). sc.pp.log1p(adata). sc.pp.scale(adata). genes = ['Cst3', 'Car1', 'Cd34', 'Apoe', 'Top2a', 'Ccl5', 'Ctsw']. sc.pl.matrixplot(adata, genes, groupby='paul15_clusters', vmin=-2, vmax=5, vcenter=0, cmap='RdBu_r'). ```. ![image](https://user-images.githubusercontent.com/1140359/102667661-ebdcac00-4157-11eb-9aac-d610283511e2.png). I haven't gone further before asking you if it makes sense at all, or not. If yes, I can try to write tests too. What do you think?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1551
https://github.com/scverse/scanpy/pull/1551:665,testability,test,tests,665,"Asymmetrical diverging colormaps and vcenter; Hi,. I started playing around with `vcenter` and adding support for it in plotting functions. This allows us to do things like:. ```python. import scanpy as sc. adata = sc.datasets.paul15(). sc.pp.log1p(adata). sc.pp.scale(adata). genes = ['Cst3', 'Car1', 'Cd34', 'Apoe', 'Top2a', 'Ccl5', 'Ctsw']. sc.pl.matrixplot(adata, genes, groupby='paul15_clusters', vmin=-2, vmax=5, vcenter=0, cmap='RdBu_r'). ```. ![image](https://user-images.githubusercontent.com/1140359/102667661-ebdcac00-4157-11eb-9aac-d610283511e2.png). I haven't gone further before asking you if it makes sense at all, or not. If yes, I can try to write tests too. What do you think?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1551
https://github.com/scverse/scanpy/pull/1551:102,usability,support,support,102,"Asymmetrical diverging colormaps and vcenter; Hi,. I started playing around with `vcenter` and adding support for it in plotting functions. This allows us to do things like:. ```python. import scanpy as sc. adata = sc.datasets.paul15(). sc.pp.log1p(adata). sc.pp.scale(adata). genes = ['Cst3', 'Car1', 'Cd34', 'Apoe', 'Top2a', 'Ccl5', 'Ctsw']. sc.pl.matrixplot(adata, genes, groupby='paul15_clusters', vmin=-2, vmax=5, vcenter=0, cmap='RdBu_r'). ```. ![image](https://user-images.githubusercontent.com/1140359/102667661-ebdcac00-4157-11eb-9aac-d610283511e2.png). I haven't gone further before asking you if it makes sense at all, or not. If yes, I can try to write tests too. What do you think?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1551
https://github.com/scverse/scanpy/pull/1551:468,usability,user,user-images,468,"Asymmetrical diverging colormaps and vcenter; Hi,. I started playing around with `vcenter` and adding support for it in plotting functions. This allows us to do things like:. ```python. import scanpy as sc. adata = sc.datasets.paul15(). sc.pp.log1p(adata). sc.pp.scale(adata). genes = ['Cst3', 'Car1', 'Cd34', 'Apoe', 'Top2a', 'Ccl5', 'Ctsw']. sc.pl.matrixplot(adata, genes, groupby='paul15_clusters', vmin=-2, vmax=5, vcenter=0, cmap='RdBu_r'). ```. ![image](https://user-images.githubusercontent.com/1140359/102667661-ebdcac00-4157-11eb-9aac-d610283511e2.png). I haven't gone further before asking you if it makes sense at all, or not. If yes, I can try to write tests too. What do you think?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1551
https://github.com/scverse/scanpy/issues/1552:132,interoperability,specif,specific,132,"requesting ncols parameter in sc.pl.violin(); It would be nice to have a way to split the violin plots from `sc.pl.violin()` into a specific number of rows, similar to the `ncols` parameter in `scanpy.pl.umap()`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1552
https://github.com/scverse/scanpy/issues/1552:17,modifiability,paramet,parameter,17,"requesting ncols parameter in sc.pl.violin(); It would be nice to have a way to split the violin plots from `sc.pl.violin()` into a specific number of rows, similar to the `ncols` parameter in `scanpy.pl.umap()`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1552
https://github.com/scverse/scanpy/issues/1552:180,modifiability,paramet,parameter,180,"requesting ncols parameter in sc.pl.violin(); It would be nice to have a way to split the violin plots from `sc.pl.violin()` into a specific number of rows, similar to the `ncols` parameter in `scanpy.pl.umap()`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1552
https://github.com/scverse/scanpy/pull/1553:56,energy efficiency,heat,heatmap,56,"Allow `groupby` adata.obs.index in dotplot, matrixplot, heatmap and stacked_violin plots; This PRadds the option to use `adata.obs.index` as groupby. To allow this change some changes were required to `sc.get.obs_df` to handle non unique adata.obs.index and duplicated obs column names and var_names.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1553
https://github.com/scverse/scanpy/pull/1553:95,reliability,PRa,PRadds,95,"Allow `groupby` adata.obs.index in dotplot, matrixplot, heatmap and stacked_violin plots; This PRadds the option to use `adata.obs.index` as groupby. To allow this change some changes were required to `sc.get.obs_df` to handle non unique adata.obs.index and duplicated obs column names and var_names.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1553
https://github.com/scverse/scanpy/pull/1554:41,deployability,version,version,41,add deprecation warning for scvi and pin version; fixes #1443,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1554
https://github.com/scverse/scanpy/pull/1554:41,integrability,version,version,41,add deprecation warning for scvi and pin version; fixes #1443,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1554
https://github.com/scverse/scanpy/pull/1554:41,modifiability,version,version,41,add deprecation warning for scvi and pin version; fixes #1443,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1554
https://github.com/scverse/scanpy/pull/1555:104,security,modif,modifying,104,Add scrublet to external; Having some trouble pushing to the branch from the original PR (#1476) so I'm modifying and merging through this PR.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1555
https://github.com/scverse/scanpy/issues/1556:609,availability,error,error,609,"ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all(); - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). I am getting this error and although i downgraded the scipy to 1.4.1 as per one recommendation here but still didn't solve it! ```python. import numpy as np. import pandas as pd. from sklearn.datasets import load_iris. from sklearn.pipeline import make_pipeline. from sklearn.preprocessing import StandardScaler, Normalizer. from scipy.cluster.hierarchy import linkage, dendrogram. df_euro = pd.read_csv('https://assets.datacamp.com/production/repositories/655/datasets/2a1f3ab7bcc76eef1b8e1eb29afbd54c4ebf86f2/eurovision-2016.csv'). samples = df.iloc[:, 2:7].values[:42]. country_names = df.iloc[:, 1].values[:42]. mergings = linkage(samples, method='single'). # Plot the dendrogram. plt.figure(figsize=(15, 5)). dendrogram(mergings,. labels=country_names,. leaf_rotation=90, . leaf_font_size=6);. ```. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-185-e360a70857f0> in <module>. 9 # Plot the dendrogram. 10 plt.figure(figsize=(15, 5)). ---> 11 dendrogram(mergings, . 12 labels=companies,. 13 leaf_rotation=90,. C:\ProgramData\Anaconda3\lib\site-packages\scipy\cluster\hierarchy.py in dendrogram(Z, p, truncate_mode, color_threshold, get_leaves, orientation, labels, count_sort, distance_sort, show_leaf_counts, no_plot, no_labels, leaf_font_size, leaf_rotation, leaf_label_func, show_contracted, link_color",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1556
https://github.com/scverse/scanpy/issues/1556:630,availability,down,downgraded,630,"ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all(); - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). I am getting this error and although i downgraded the scipy to 1.4.1 as per one recommendation here but still didn't solve it! ```python. import numpy as np. import pandas as pd. from sklearn.datasets import load_iris. from sklearn.pipeline import make_pipeline. from sklearn.preprocessing import StandardScaler, Normalizer. from scipy.cluster.hierarchy import linkage, dendrogram. df_euro = pd.read_csv('https://assets.datacamp.com/production/repositories/655/datasets/2a1f3ab7bcc76eef1b8e1eb29afbd54c4ebf86f2/eurovision-2016.csv'). samples = df.iloc[:, 2:7].values[:42]. country_names = df.iloc[:, 1].values[:42]. mergings = linkage(samples, method='single'). # Plot the dendrogram. plt.figure(figsize=(15, 5)). dendrogram(mergings,. labels=country_names,. leaf_rotation=90, . leaf_font_size=6);. ```. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-185-e360a70857f0> in <module>. 9 # Plot the dendrogram. 10 plt.figure(figsize=(15, 5)). ---> 11 dendrogram(mergings, . 12 labels=companies,. 13 leaf_rotation=90,. C:\ProgramData\Anaconda3\lib\site-packages\scipy\cluster\hierarchy.py in dendrogram(Z, p, truncate_mode, color_threshold, get_leaves, orientation, labels, count_sort, distance_sort, show_leaf_counts, no_plot, no_labels, leaf_font_size, leaf_rotation, leaf_label_func, show_contracted, link_color",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1556
https://github.com/scverse/scanpy/issues/1556:927,availability,cluster,cluster,927,"ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all(); - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). I am getting this error and although i downgraded the scipy to 1.4.1 as per one recommendation here but still didn't solve it! ```python. import numpy as np. import pandas as pd. from sklearn.datasets import load_iris. from sklearn.pipeline import make_pipeline. from sklearn.preprocessing import StandardScaler, Normalizer. from scipy.cluster.hierarchy import linkage, dendrogram. df_euro = pd.read_csv('https://assets.datacamp.com/production/repositories/655/datasets/2a1f3ab7bcc76eef1b8e1eb29afbd54c4ebf86f2/eurovision-2016.csv'). samples = df.iloc[:, 2:7].values[:42]. country_names = df.iloc[:, 1].values[:42]. mergings = linkage(samples, method='single'). # Plot the dendrogram. plt.figure(figsize=(15, 5)). dendrogram(mergings,. labels=country_names,. leaf_rotation=90, . leaf_font_size=6);. ```. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-185-e360a70857f0> in <module>. 9 # Plot the dendrogram. 10 plt.figure(figsize=(15, 5)). ---> 11 dendrogram(mergings, . 12 labels=companies,. 13 leaf_rotation=90,. C:\ProgramData\Anaconda3\lib\site-packages\scipy\cluster\hierarchy.py in dendrogram(Z, p, truncate_mode, color_threshold, get_leaves, orientation, labels, count_sort, distance_sort, show_leaf_counts, no_plot, no_labels, leaf_font_size, leaf_rotation, leaf_label_func, show_contracted, link_color",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1556
https://github.com/scverse/scanpy/issues/1556:1754,availability,cluster,cluster,1754,"com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). I am getting this error and although i downgraded the scipy to 1.4.1 as per one recommendation here but still didn't solve it! ```python. import numpy as np. import pandas as pd. from sklearn.datasets import load_iris. from sklearn.pipeline import make_pipeline. from sklearn.preprocessing import StandardScaler, Normalizer. from scipy.cluster.hierarchy import linkage, dendrogram. df_euro = pd.read_csv('https://assets.datacamp.com/production/repositories/655/datasets/2a1f3ab7bcc76eef1b8e1eb29afbd54c4ebf86f2/eurovision-2016.csv'). samples = df.iloc[:, 2:7].values[:42]. country_names = df.iloc[:, 1].values[:42]. mergings = linkage(samples, method='single'). # Plot the dendrogram. plt.figure(figsize=(15, 5)). dendrogram(mergings,. labels=country_names,. leaf_rotation=90, . leaf_font_size=6);. ```. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-185-e360a70857f0> in <module>. 9 # Plot the dendrogram. 10 plt.figure(figsize=(15, 5)). ---> 11 dendrogram(mergings, . 12 labels=companies,. 13 leaf_rotation=90,. C:\ProgramData\Anaconda3\lib\site-packages\scipy\cluster\hierarchy.py in dendrogram(Z, p, truncate_mode, color_threshold, get_leaves, orientation, labels, count_sort, distance_sort, show_leaf_counts, no_plot, no_labels, leaf_font_size, leaf_rotation, leaf_label_func, show_contracted, link_color_func, ax, above_threshold_color). 3275 ""'bottom', or 'right'""). 3276 . -> 3277 if labels and Z.shape[0] + 1 != len(labels):. 3278 raise ValueError(""Dimensions of Z and labels must be consistent.""). 3279 . ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all(). ```. #### Versions. Python: 3.8.6. Numpy: 1.18.5. scipy: 1.4.1. pandas : 1.0.5.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1556
https://github.com/scverse/scanpy/issues/1556:2184,availability,consist,consistent,2184,"com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). I am getting this error and although i downgraded the scipy to 1.4.1 as per one recommendation here but still didn't solve it! ```python. import numpy as np. import pandas as pd. from sklearn.datasets import load_iris. from sklearn.pipeline import make_pipeline. from sklearn.preprocessing import StandardScaler, Normalizer. from scipy.cluster.hierarchy import linkage, dendrogram. df_euro = pd.read_csv('https://assets.datacamp.com/production/repositories/655/datasets/2a1f3ab7bcc76eef1b8e1eb29afbd54c4ebf86f2/eurovision-2016.csv'). samples = df.iloc[:, 2:7].values[:42]. country_names = df.iloc[:, 1].values[:42]. mergings = linkage(samples, method='single'). # Plot the dendrogram. plt.figure(figsize=(15, 5)). dendrogram(mergings,. labels=country_names,. leaf_rotation=90, . leaf_font_size=6);. ```. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-185-e360a70857f0> in <module>. 9 # Plot the dendrogram. 10 plt.figure(figsize=(15, 5)). ---> 11 dendrogram(mergings, . 12 labels=companies,. 13 leaf_rotation=90,. C:\ProgramData\Anaconda3\lib\site-packages\scipy\cluster\hierarchy.py in dendrogram(Z, p, truncate_mode, color_threshold, get_leaves, orientation, labels, count_sort, distance_sort, show_leaf_counts, no_plot, no_labels, leaf_font_size, leaf_rotation, leaf_label_func, show_contracted, link_color_func, ax, above_threshold_color). 3275 ""'bottom', or 'right'""). 3276 . -> 3277 if labels and Z.shape[0] + 1 != len(labels):. 3278 raise ValueError(""Dimensions of Z and labels must be consistent.""). 3279 . ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all(). ```. #### Versions. Python: 3.8.6. Numpy: 1.18.5. scipy: 1.4.1. pandas : 1.0.5.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1556
https://github.com/scverse/scanpy/issues/1556:226,deployability,version,version,226,"ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all(); - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). I am getting this error and although i downgraded the scipy to 1.4.1 as per one recommendation here but still didn't solve it! ```python. import numpy as np. import pandas as pd. from sklearn.datasets import load_iris. from sklearn.pipeline import make_pipeline. from sklearn.preprocessing import StandardScaler, Normalizer. from scipy.cluster.hierarchy import linkage, dendrogram. df_euro = pd.read_csv('https://assets.datacamp.com/production/repositories/655/datasets/2a1f3ab7bcc76eef1b8e1eb29afbd54c4ebf86f2/eurovision-2016.csv'). samples = df.iloc[:, 2:7].values[:42]. country_names = df.iloc[:, 1].values[:42]. mergings = linkage(samples, method='single'). # Plot the dendrogram. plt.figure(figsize=(15, 5)). dendrogram(mergings,. labels=country_names,. leaf_rotation=90, . leaf_font_size=6);. ```. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-185-e360a70857f0> in <module>. 9 # Plot the dendrogram. 10 plt.figure(figsize=(15, 5)). ---> 11 dendrogram(mergings, . 12 labels=companies,. 13 leaf_rotation=90,. C:\ProgramData\Anaconda3\lib\site-packages\scipy\cluster\hierarchy.py in dendrogram(Z, p, truncate_mode, color_threshold, get_leaves, orientation, labels, count_sort, distance_sort, show_leaf_counts, no_plot, no_labels, leaf_font_size, leaf_rotation, leaf_label_func, show_contracted, link_color",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1556
https://github.com/scverse/scanpy/issues/1556:823,deployability,pipelin,pipeline,823,"ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all(); - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). I am getting this error and although i downgraded the scipy to 1.4.1 as per one recommendation here but still didn't solve it! ```python. import numpy as np. import pandas as pd. from sklearn.datasets import load_iris. from sklearn.pipeline import make_pipeline. from sklearn.preprocessing import StandardScaler, Normalizer. from scipy.cluster.hierarchy import linkage, dendrogram. df_euro = pd.read_csv('https://assets.datacamp.com/production/repositories/655/datasets/2a1f3ab7bcc76eef1b8e1eb29afbd54c4ebf86f2/eurovision-2016.csv'). samples = df.iloc[:, 2:7].values[:42]. country_names = df.iloc[:, 1].values[:42]. mergings = linkage(samples, method='single'). # Plot the dendrogram. plt.figure(figsize=(15, 5)). dendrogram(mergings,. labels=country_names,. leaf_rotation=90, . leaf_font_size=6);. ```. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-185-e360a70857f0> in <module>. 9 # Plot the dendrogram. 10 plt.figure(figsize=(15, 5)). ---> 11 dendrogram(mergings, . 12 labels=companies,. 13 leaf_rotation=90,. C:\ProgramData\Anaconda3\lib\site-packages\scipy\cluster\hierarchy.py in dendrogram(Z, p, truncate_mode, color_threshold, get_leaves, orientation, labels, count_sort, distance_sort, show_leaf_counts, no_plot, no_labels, leaf_font_size, leaf_rotation, leaf_label_func, show_contracted, link_color",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1556
https://github.com/scverse/scanpy/issues/1556:927,deployability,cluster,cluster,927,"ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all(); - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). I am getting this error and although i downgraded the scipy to 1.4.1 as per one recommendation here but still didn't solve it! ```python. import numpy as np. import pandas as pd. from sklearn.datasets import load_iris. from sklearn.pipeline import make_pipeline. from sklearn.preprocessing import StandardScaler, Normalizer. from scipy.cluster.hierarchy import linkage, dendrogram. df_euro = pd.read_csv('https://assets.datacamp.com/production/repositories/655/datasets/2a1f3ab7bcc76eef1b8e1eb29afbd54c4ebf86f2/eurovision-2016.csv'). samples = df.iloc[:, 2:7].values[:42]. country_names = df.iloc[:, 1].values[:42]. mergings = linkage(samples, method='single'). # Plot the dendrogram. plt.figure(figsize=(15, 5)). dendrogram(mergings,. labels=country_names,. leaf_rotation=90, . leaf_font_size=6);. ```. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-185-e360a70857f0> in <module>. 9 # Plot the dendrogram. 10 plt.figure(figsize=(15, 5)). ---> 11 dendrogram(mergings, . 12 labels=companies,. 13 leaf_rotation=90,. C:\ProgramData\Anaconda3\lib\site-packages\scipy\cluster\hierarchy.py in dendrogram(Z, p, truncate_mode, color_threshold, get_leaves, orientation, labels, count_sort, distance_sort, show_leaf_counts, no_plot, no_labels, leaf_font_size, leaf_rotation, leaf_label_func, show_contracted, link_color",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1556
https://github.com/scverse/scanpy/issues/1556:1564,deployability,modul,module,1564,"com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). I am getting this error and although i downgraded the scipy to 1.4.1 as per one recommendation here but still didn't solve it! ```python. import numpy as np. import pandas as pd. from sklearn.datasets import load_iris. from sklearn.pipeline import make_pipeline. from sklearn.preprocessing import StandardScaler, Normalizer. from scipy.cluster.hierarchy import linkage, dendrogram. df_euro = pd.read_csv('https://assets.datacamp.com/production/repositories/655/datasets/2a1f3ab7bcc76eef1b8e1eb29afbd54c4ebf86f2/eurovision-2016.csv'). samples = df.iloc[:, 2:7].values[:42]. country_names = df.iloc[:, 1].values[:42]. mergings = linkage(samples, method='single'). # Plot the dendrogram. plt.figure(figsize=(15, 5)). dendrogram(mergings,. labels=country_names,. leaf_rotation=90, . leaf_font_size=6);. ```. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-185-e360a70857f0> in <module>. 9 # Plot the dendrogram. 10 plt.figure(figsize=(15, 5)). ---> 11 dendrogram(mergings, . 12 labels=companies,. 13 leaf_rotation=90,. C:\ProgramData\Anaconda3\lib\site-packages\scipy\cluster\hierarchy.py in dendrogram(Z, p, truncate_mode, color_threshold, get_leaves, orientation, labels, count_sort, distance_sort, show_leaf_counts, no_plot, no_labels, leaf_font_size, leaf_rotation, leaf_label_func, show_contracted, link_color_func, ax, above_threshold_color). 3275 ""'bottom', or 'right'""). 3276 . -> 3277 if labels and Z.shape[0] + 1 != len(labels):. 3278 raise ValueError(""Dimensions of Z and labels must be consistent.""). 3279 . ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all(). ```. #### Versions. Python: 3.8.6. Numpy: 1.18.5. scipy: 1.4.1. pandas : 1.0.5.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1556
https://github.com/scverse/scanpy/issues/1556:1754,deployability,cluster,cluster,1754,"com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). I am getting this error and although i downgraded the scipy to 1.4.1 as per one recommendation here but still didn't solve it! ```python. import numpy as np. import pandas as pd. from sklearn.datasets import load_iris. from sklearn.pipeline import make_pipeline. from sklearn.preprocessing import StandardScaler, Normalizer. from scipy.cluster.hierarchy import linkage, dendrogram. df_euro = pd.read_csv('https://assets.datacamp.com/production/repositories/655/datasets/2a1f3ab7bcc76eef1b8e1eb29afbd54c4ebf86f2/eurovision-2016.csv'). samples = df.iloc[:, 2:7].values[:42]. country_names = df.iloc[:, 1].values[:42]. mergings = linkage(samples, method='single'). # Plot the dendrogram. plt.figure(figsize=(15, 5)). dendrogram(mergings,. labels=country_names,. leaf_rotation=90, . leaf_font_size=6);. ```. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-185-e360a70857f0> in <module>. 9 # Plot the dendrogram. 10 plt.figure(figsize=(15, 5)). ---> 11 dendrogram(mergings, . 12 labels=companies,. 13 leaf_rotation=90,. C:\ProgramData\Anaconda3\lib\site-packages\scipy\cluster\hierarchy.py in dendrogram(Z, p, truncate_mode, color_threshold, get_leaves, orientation, labels, count_sort, distance_sort, show_leaf_counts, no_plot, no_labels, leaf_font_size, leaf_rotation, leaf_label_func, show_contracted, link_color_func, ax, above_threshold_color). 3275 ""'bottom', or 'right'""). 3276 . -> 3277 if labels and Z.shape[0] + 1 != len(labels):. 3278 raise ValueError(""Dimensions of Z and labels must be consistent.""). 3279 . ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all(). ```. #### Versions. Python: 3.8.6. Numpy: 1.18.5. scipy: 1.4.1. pandas : 1.0.5.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1556
https://github.com/scverse/scanpy/issues/1556:2321,deployability,Version,Versions,2321,"com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). I am getting this error and although i downgraded the scipy to 1.4.1 as per one recommendation here but still didn't solve it! ```python. import numpy as np. import pandas as pd. from sklearn.datasets import load_iris. from sklearn.pipeline import make_pipeline. from sklearn.preprocessing import StandardScaler, Normalizer. from scipy.cluster.hierarchy import linkage, dendrogram. df_euro = pd.read_csv('https://assets.datacamp.com/production/repositories/655/datasets/2a1f3ab7bcc76eef1b8e1eb29afbd54c4ebf86f2/eurovision-2016.csv'). samples = df.iloc[:, 2:7].values[:42]. country_names = df.iloc[:, 1].values[:42]. mergings = linkage(samples, method='single'). # Plot the dendrogram. plt.figure(figsize=(15, 5)). dendrogram(mergings,. labels=country_names,. leaf_rotation=90, . leaf_font_size=6);. ```. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-185-e360a70857f0> in <module>. 9 # Plot the dendrogram. 10 plt.figure(figsize=(15, 5)). ---> 11 dendrogram(mergings, . 12 labels=companies,. 13 leaf_rotation=90,. C:\ProgramData\Anaconda3\lib\site-packages\scipy\cluster\hierarchy.py in dendrogram(Z, p, truncate_mode, color_threshold, get_leaves, orientation, labels, count_sort, distance_sort, show_leaf_counts, no_plot, no_labels, leaf_font_size, leaf_rotation, leaf_label_func, show_contracted, link_color_func, ax, above_threshold_color). 3275 ""'bottom', or 'right'""). 3276 . -> 3277 if labels and Z.shape[0] + 1 != len(labels):. 3278 raise ValueError(""Dimensions of Z and labels must be consistent.""). 3279 . ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all(). ```. #### Versions. Python: 3.8.6. Numpy: 1.18.5. scipy: 1.4.1. pandas : 1.0.5.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1556
https://github.com/scverse/scanpy/issues/1556:226,integrability,version,version,226,"ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all(); - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). I am getting this error and although i downgraded the scipy to 1.4.1 as per one recommendation here but still didn't solve it! ```python. import numpy as np. import pandas as pd. from sklearn.datasets import load_iris. from sklearn.pipeline import make_pipeline. from sklearn.preprocessing import StandardScaler, Normalizer. from scipy.cluster.hierarchy import linkage, dendrogram. df_euro = pd.read_csv('https://assets.datacamp.com/production/repositories/655/datasets/2a1f3ab7bcc76eef1b8e1eb29afbd54c4ebf86f2/eurovision-2016.csv'). samples = df.iloc[:, 2:7].values[:42]. country_names = df.iloc[:, 1].values[:42]. mergings = linkage(samples, method='single'). # Plot the dendrogram. plt.figure(figsize=(15, 5)). dendrogram(mergings,. labels=country_names,. leaf_rotation=90, . leaf_font_size=6);. ```. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-185-e360a70857f0> in <module>. 9 # Plot the dendrogram. 10 plt.figure(figsize=(15, 5)). ---> 11 dendrogram(mergings, . 12 labels=companies,. 13 leaf_rotation=90,. C:\ProgramData\Anaconda3\lib\site-packages\scipy\cluster\hierarchy.py in dendrogram(Z, p, truncate_mode, color_threshold, get_leaves, orientation, labels, count_sort, distance_sort, show_leaf_counts, no_plot, no_labels, leaf_font_size, leaf_rotation, leaf_label_func, show_contracted, link_color",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1556
https://github.com/scverse/scanpy/issues/1556:823,integrability,pipelin,pipeline,823,"ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all(); - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). I am getting this error and although i downgraded the scipy to 1.4.1 as per one recommendation here but still didn't solve it! ```python. import numpy as np. import pandas as pd. from sklearn.datasets import load_iris. from sklearn.pipeline import make_pipeline. from sklearn.preprocessing import StandardScaler, Normalizer. from scipy.cluster.hierarchy import linkage, dendrogram. df_euro = pd.read_csv('https://assets.datacamp.com/production/repositories/655/datasets/2a1f3ab7bcc76eef1b8e1eb29afbd54c4ebf86f2/eurovision-2016.csv'). samples = df.iloc[:, 2:7].values[:42]. country_names = df.iloc[:, 1].values[:42]. mergings = linkage(samples, method='single'). # Plot the dendrogram. plt.figure(figsize=(15, 5)). dendrogram(mergings,. labels=country_names,. leaf_rotation=90, . leaf_font_size=6);. ```. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-185-e360a70857f0> in <module>. 9 # Plot the dendrogram. 10 plt.figure(figsize=(15, 5)). ---> 11 dendrogram(mergings, . 12 labels=companies,. 13 leaf_rotation=90,. C:\ProgramData\Anaconda3\lib\site-packages\scipy\cluster\hierarchy.py in dendrogram(Z, p, truncate_mode, color_threshold, get_leaves, orientation, labels, count_sort, distance_sort, show_leaf_counts, no_plot, no_labels, leaf_font_size, leaf_rotation, leaf_label_func, show_contracted, link_color",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1556
https://github.com/scverse/scanpy/issues/1556:1035,integrability,repositor,repositories,1035,"ith more than one element is ambiguous. Use a.any() or a.all(); - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). I am getting this error and although i downgraded the scipy to 1.4.1 as per one recommendation here but still didn't solve it! ```python. import numpy as np. import pandas as pd. from sklearn.datasets import load_iris. from sklearn.pipeline import make_pipeline. from sklearn.preprocessing import StandardScaler, Normalizer. from scipy.cluster.hierarchy import linkage, dendrogram. df_euro = pd.read_csv('https://assets.datacamp.com/production/repositories/655/datasets/2a1f3ab7bcc76eef1b8e1eb29afbd54c4ebf86f2/eurovision-2016.csv'). samples = df.iloc[:, 2:7].values[:42]. country_names = df.iloc[:, 1].values[:42]. mergings = linkage(samples, method='single'). # Plot the dendrogram. plt.figure(figsize=(15, 5)). dendrogram(mergings,. labels=country_names,. leaf_rotation=90, . leaf_font_size=6);. ```. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-185-e360a70857f0> in <module>. 9 # Plot the dendrogram. 10 plt.figure(figsize=(15, 5)). ---> 11 dendrogram(mergings, . 12 labels=companies,. 13 leaf_rotation=90,. C:\ProgramData\Anaconda3\lib\site-packages\scipy\cluster\hierarchy.py in dendrogram(Z, p, truncate_mode, color_threshold, get_leaves, orientation, labels, count_sort, distance_sort, show_leaf_counts, no_plot, no_labels, leaf_font_size, leaf_rotation, leaf_label_func, show_contracted, link_color_func, ax, above_threshold_color). 3275 """,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1556
https://github.com/scverse/scanpy/issues/1556:2321,integrability,Version,Versions,2321,"com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). I am getting this error and although i downgraded the scipy to 1.4.1 as per one recommendation here but still didn't solve it! ```python. import numpy as np. import pandas as pd. from sklearn.datasets import load_iris. from sklearn.pipeline import make_pipeline. from sklearn.preprocessing import StandardScaler, Normalizer. from scipy.cluster.hierarchy import linkage, dendrogram. df_euro = pd.read_csv('https://assets.datacamp.com/production/repositories/655/datasets/2a1f3ab7bcc76eef1b8e1eb29afbd54c4ebf86f2/eurovision-2016.csv'). samples = df.iloc[:, 2:7].values[:42]. country_names = df.iloc[:, 1].values[:42]. mergings = linkage(samples, method='single'). # Plot the dendrogram. plt.figure(figsize=(15, 5)). dendrogram(mergings,. labels=country_names,. leaf_rotation=90, . leaf_font_size=6);. ```. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-185-e360a70857f0> in <module>. 9 # Plot the dendrogram. 10 plt.figure(figsize=(15, 5)). ---> 11 dendrogram(mergings, . 12 labels=companies,. 13 leaf_rotation=90,. C:\ProgramData\Anaconda3\lib\site-packages\scipy\cluster\hierarchy.py in dendrogram(Z, p, truncate_mode, color_threshold, get_leaves, orientation, labels, count_sort, distance_sort, show_leaf_counts, no_plot, no_labels, leaf_font_size, leaf_rotation, leaf_label_func, show_contracted, link_color_func, ax, above_threshold_color). 3275 ""'bottom', or 'right'""). 3276 . -> 3277 if labels and Z.shape[0] + 1 != len(labels):. 3278 raise ValueError(""Dimensions of Z and labels must be consistent.""). 3279 . ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all(). ```. #### Versions. Python: 3.8.6. Numpy: 1.18.5. scipy: 1.4.1. pandas : 1.0.5.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1556
https://github.com/scverse/scanpy/issues/1556:888,interoperability,Standard,StandardScaler,888,"ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all(); - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). I am getting this error and although i downgraded the scipy to 1.4.1 as per one recommendation here but still didn't solve it! ```python. import numpy as np. import pandas as pd. from sklearn.datasets import load_iris. from sklearn.pipeline import make_pipeline. from sklearn.preprocessing import StandardScaler, Normalizer. from scipy.cluster.hierarchy import linkage, dendrogram. df_euro = pd.read_csv('https://assets.datacamp.com/production/repositories/655/datasets/2a1f3ab7bcc76eef1b8e1eb29afbd54c4ebf86f2/eurovision-2016.csv'). samples = df.iloc[:, 2:7].values[:42]. country_names = df.iloc[:, 1].values[:42]. mergings = linkage(samples, method='single'). # Plot the dendrogram. plt.figure(figsize=(15, 5)). dendrogram(mergings,. labels=country_names,. leaf_rotation=90, . leaf_font_size=6);. ```. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-185-e360a70857f0> in <module>. 9 # Plot the dendrogram. 10 plt.figure(figsize=(15, 5)). ---> 11 dendrogram(mergings, . 12 labels=companies,. 13 leaf_rotation=90,. C:\ProgramData\Anaconda3\lib\site-packages\scipy\cluster\hierarchy.py in dendrogram(Z, p, truncate_mode, color_threshold, get_leaves, orientation, labels, count_sort, distance_sort, show_leaf_counts, no_plot, no_labels, leaf_font_size, leaf_rotation, leaf_label_func, show_contracted, link_color",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1556
https://github.com/scverse/scanpy/issues/1556:1035,interoperability,repositor,repositories,1035,"ith more than one element is ambiguous. Use a.any() or a.all(); - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). I am getting this error and although i downgraded the scipy to 1.4.1 as per one recommendation here but still didn't solve it! ```python. import numpy as np. import pandas as pd. from sklearn.datasets import load_iris. from sklearn.pipeline import make_pipeline. from sklearn.preprocessing import StandardScaler, Normalizer. from scipy.cluster.hierarchy import linkage, dendrogram. df_euro = pd.read_csv('https://assets.datacamp.com/production/repositories/655/datasets/2a1f3ab7bcc76eef1b8e1eb29afbd54c4ebf86f2/eurovision-2016.csv'). samples = df.iloc[:, 2:7].values[:42]. country_names = df.iloc[:, 1].values[:42]. mergings = linkage(samples, method='single'). # Plot the dendrogram. plt.figure(figsize=(15, 5)). dendrogram(mergings,. labels=country_names,. leaf_rotation=90, . leaf_font_size=6);. ```. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-185-e360a70857f0> in <module>. 9 # Plot the dendrogram. 10 plt.figure(figsize=(15, 5)). ---> 11 dendrogram(mergings, . 12 labels=companies,. 13 leaf_rotation=90,. C:\ProgramData\Anaconda3\lib\site-packages\scipy\cluster\hierarchy.py in dendrogram(Z, p, truncate_mode, color_threshold, get_leaves, orientation, labels, count_sort, distance_sort, show_leaf_counts, no_plot, no_labels, leaf_font_size, leaf_rotation, leaf_label_func, show_contracted, link_color_func, ax, above_threshold_color). 3275 """,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1556
https://github.com/scverse/scanpy/issues/1556:226,modifiability,version,version,226,"ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all(); - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). I am getting this error and although i downgraded the scipy to 1.4.1 as per one recommendation here but still didn't solve it! ```python. import numpy as np. import pandas as pd. from sklearn.datasets import load_iris. from sklearn.pipeline import make_pipeline. from sklearn.preprocessing import StandardScaler, Normalizer. from scipy.cluster.hierarchy import linkage, dendrogram. df_euro = pd.read_csv('https://assets.datacamp.com/production/repositories/655/datasets/2a1f3ab7bcc76eef1b8e1eb29afbd54c4ebf86f2/eurovision-2016.csv'). samples = df.iloc[:, 2:7].values[:42]. country_names = df.iloc[:, 1].values[:42]. mergings = linkage(samples, method='single'). # Plot the dendrogram. plt.figure(figsize=(15, 5)). dendrogram(mergings,. labels=country_names,. leaf_rotation=90, . leaf_font_size=6);. ```. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-185-e360a70857f0> in <module>. 9 # Plot the dendrogram. 10 plt.figure(figsize=(15, 5)). ---> 11 dendrogram(mergings, . 12 labels=companies,. 13 leaf_rotation=90,. C:\ProgramData\Anaconda3\lib\site-packages\scipy\cluster\hierarchy.py in dendrogram(Z, p, truncate_mode, color_threshold, get_leaves, orientation, labels, count_sort, distance_sort, show_leaf_counts, no_plot, no_labels, leaf_font_size, leaf_rotation, leaf_label_func, show_contracted, link_color",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1556
https://github.com/scverse/scanpy/issues/1556:1564,modifiability,modul,module,1564,"com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). I am getting this error and although i downgraded the scipy to 1.4.1 as per one recommendation here but still didn't solve it! ```python. import numpy as np. import pandas as pd. from sklearn.datasets import load_iris. from sklearn.pipeline import make_pipeline. from sklearn.preprocessing import StandardScaler, Normalizer. from scipy.cluster.hierarchy import linkage, dendrogram. df_euro = pd.read_csv('https://assets.datacamp.com/production/repositories/655/datasets/2a1f3ab7bcc76eef1b8e1eb29afbd54c4ebf86f2/eurovision-2016.csv'). samples = df.iloc[:, 2:7].values[:42]. country_names = df.iloc[:, 1].values[:42]. mergings = linkage(samples, method='single'). # Plot the dendrogram. plt.figure(figsize=(15, 5)). dendrogram(mergings,. labels=country_names,. leaf_rotation=90, . leaf_font_size=6);. ```. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-185-e360a70857f0> in <module>. 9 # Plot the dendrogram. 10 plt.figure(figsize=(15, 5)). ---> 11 dendrogram(mergings, . 12 labels=companies,. 13 leaf_rotation=90,. C:\ProgramData\Anaconda3\lib\site-packages\scipy\cluster\hierarchy.py in dendrogram(Z, p, truncate_mode, color_threshold, get_leaves, orientation, labels, count_sort, distance_sort, show_leaf_counts, no_plot, no_labels, leaf_font_size, leaf_rotation, leaf_label_func, show_contracted, link_color_func, ax, above_threshold_color). 3275 ""'bottom', or 'right'""). 3276 . -> 3277 if labels and Z.shape[0] + 1 != len(labels):. 3278 raise ValueError(""Dimensions of Z and labels must be consistent.""). 3279 . ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all(). ```. #### Versions. Python: 3.8.6. Numpy: 1.18.5. scipy: 1.4.1. pandas : 1.0.5.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1556
https://github.com/scverse/scanpy/issues/1556:1739,modifiability,pac,packages,1739,"com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). I am getting this error and although i downgraded the scipy to 1.4.1 as per one recommendation here but still didn't solve it! ```python. import numpy as np. import pandas as pd. from sklearn.datasets import load_iris. from sklearn.pipeline import make_pipeline. from sklearn.preprocessing import StandardScaler, Normalizer. from scipy.cluster.hierarchy import linkage, dendrogram. df_euro = pd.read_csv('https://assets.datacamp.com/production/repositories/655/datasets/2a1f3ab7bcc76eef1b8e1eb29afbd54c4ebf86f2/eurovision-2016.csv'). samples = df.iloc[:, 2:7].values[:42]. country_names = df.iloc[:, 1].values[:42]. mergings = linkage(samples, method='single'). # Plot the dendrogram. plt.figure(figsize=(15, 5)). dendrogram(mergings,. labels=country_names,. leaf_rotation=90, . leaf_font_size=6);. ```. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-185-e360a70857f0> in <module>. 9 # Plot the dendrogram. 10 plt.figure(figsize=(15, 5)). ---> 11 dendrogram(mergings, . 12 labels=companies,. 13 leaf_rotation=90,. C:\ProgramData\Anaconda3\lib\site-packages\scipy\cluster\hierarchy.py in dendrogram(Z, p, truncate_mode, color_threshold, get_leaves, orientation, labels, count_sort, distance_sort, show_leaf_counts, no_plot, no_labels, leaf_font_size, leaf_rotation, leaf_label_func, show_contracted, link_color_func, ax, above_threshold_color). 3275 ""'bottom', or 'right'""). 3276 . -> 3277 if labels and Z.shape[0] + 1 != len(labels):. 3278 raise ValueError(""Dimensions of Z and labels must be consistent.""). 3279 . ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all(). ```. #### Versions. Python: 3.8.6. Numpy: 1.18.5. scipy: 1.4.1. pandas : 1.0.5.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1556
https://github.com/scverse/scanpy/issues/1556:2321,modifiability,Version,Versions,2321,"com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). I am getting this error and although i downgraded the scipy to 1.4.1 as per one recommendation here but still didn't solve it! ```python. import numpy as np. import pandas as pd. from sklearn.datasets import load_iris. from sklearn.pipeline import make_pipeline. from sklearn.preprocessing import StandardScaler, Normalizer. from scipy.cluster.hierarchy import linkage, dendrogram. df_euro = pd.read_csv('https://assets.datacamp.com/production/repositories/655/datasets/2a1f3ab7bcc76eef1b8e1eb29afbd54c4ebf86f2/eurovision-2016.csv'). samples = df.iloc[:, 2:7].values[:42]. country_names = df.iloc[:, 1].values[:42]. mergings = linkage(samples, method='single'). # Plot the dendrogram. plt.figure(figsize=(15, 5)). dendrogram(mergings,. labels=country_names,. leaf_rotation=90, . leaf_font_size=6);. ```. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-185-e360a70857f0> in <module>. 9 # Plot the dendrogram. 10 plt.figure(figsize=(15, 5)). ---> 11 dendrogram(mergings, . 12 labels=companies,. 13 leaf_rotation=90,. C:\ProgramData\Anaconda3\lib\site-packages\scipy\cluster\hierarchy.py in dendrogram(Z, p, truncate_mode, color_threshold, get_leaves, orientation, labels, count_sort, distance_sort, show_leaf_counts, no_plot, no_labels, leaf_font_size, leaf_rotation, leaf_label_func, show_contracted, link_color_func, ax, above_threshold_color). 3275 ""'bottom', or 'right'""). 3276 . -> 3277 if labels and Z.shape[0] + 1 != len(labels):. 3278 raise ValueError(""Dimensions of Z and labels must be consistent.""). 3279 . ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all(). ```. #### Versions. Python: 3.8.6. Numpy: 1.18.5. scipy: 1.4.1. pandas : 1.0.5.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1556
https://github.com/scverse/scanpy/issues/1556:609,performance,error,error,609,"ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all(); - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). I am getting this error and although i downgraded the scipy to 1.4.1 as per one recommendation here but still didn't solve it! ```python. import numpy as np. import pandas as pd. from sklearn.datasets import load_iris. from sklearn.pipeline import make_pipeline. from sklearn.preprocessing import StandardScaler, Normalizer. from scipy.cluster.hierarchy import linkage, dendrogram. df_euro = pd.read_csv('https://assets.datacamp.com/production/repositories/655/datasets/2a1f3ab7bcc76eef1b8e1eb29afbd54c4ebf86f2/eurovision-2016.csv'). samples = df.iloc[:, 2:7].values[:42]. country_names = df.iloc[:, 1].values[:42]. mergings = linkage(samples, method='single'). # Plot the dendrogram. plt.figure(figsize=(15, 5)). dendrogram(mergings,. labels=country_names,. leaf_rotation=90, . leaf_font_size=6);. ```. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-185-e360a70857f0> in <module>. 9 # Plot the dendrogram. 10 plt.figure(figsize=(15, 5)). ---> 11 dendrogram(mergings, . 12 labels=companies,. 13 leaf_rotation=90,. C:\ProgramData\Anaconda3\lib\site-packages\scipy\cluster\hierarchy.py in dendrogram(Z, p, truncate_mode, color_threshold, get_leaves, orientation, labels, count_sort, distance_sort, show_leaf_counts, no_plot, no_labels, leaf_font_size, leaf_rotation, leaf_label_func, show_contracted, link_color",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1556
https://github.com/scverse/scanpy/issues/1556:609,safety,error,error,609,"ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all(); - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). I am getting this error and although i downgraded the scipy to 1.4.1 as per one recommendation here but still didn't solve it! ```python. import numpy as np. import pandas as pd. from sklearn.datasets import load_iris. from sklearn.pipeline import make_pipeline. from sklearn.preprocessing import StandardScaler, Normalizer. from scipy.cluster.hierarchy import linkage, dendrogram. df_euro = pd.read_csv('https://assets.datacamp.com/production/repositories/655/datasets/2a1f3ab7bcc76eef1b8e1eb29afbd54c4ebf86f2/eurovision-2016.csv'). samples = df.iloc[:, 2:7].values[:42]. country_names = df.iloc[:, 1].values[:42]. mergings = linkage(samples, method='single'). # Plot the dendrogram. plt.figure(figsize=(15, 5)). dendrogram(mergings,. labels=country_names,. leaf_rotation=90, . leaf_font_size=6);. ```. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-185-e360a70857f0> in <module>. 9 # Plot the dendrogram. 10 plt.figure(figsize=(15, 5)). ---> 11 dendrogram(mergings, . 12 labels=companies,. 13 leaf_rotation=90,. C:\ProgramData\Anaconda3\lib\site-packages\scipy\cluster\hierarchy.py in dendrogram(Z, p, truncate_mode, color_threshold, get_leaves, orientation, labels, count_sort, distance_sort, show_leaf_counts, no_plot, no_labels, leaf_font_size, leaf_rotation, leaf_label_func, show_contracted, link_color",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1556
https://github.com/scverse/scanpy/issues/1556:1536,safety,input,input-,1536,"com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). I am getting this error and although i downgraded the scipy to 1.4.1 as per one recommendation here but still didn't solve it! ```python. import numpy as np. import pandas as pd. from sklearn.datasets import load_iris. from sklearn.pipeline import make_pipeline. from sklearn.preprocessing import StandardScaler, Normalizer. from scipy.cluster.hierarchy import linkage, dendrogram. df_euro = pd.read_csv('https://assets.datacamp.com/production/repositories/655/datasets/2a1f3ab7bcc76eef1b8e1eb29afbd54c4ebf86f2/eurovision-2016.csv'). samples = df.iloc[:, 2:7].values[:42]. country_names = df.iloc[:, 1].values[:42]. mergings = linkage(samples, method='single'). # Plot the dendrogram. plt.figure(figsize=(15, 5)). dendrogram(mergings,. labels=country_names,. leaf_rotation=90, . leaf_font_size=6);. ```. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-185-e360a70857f0> in <module>. 9 # Plot the dendrogram. 10 plt.figure(figsize=(15, 5)). ---> 11 dendrogram(mergings, . 12 labels=companies,. 13 leaf_rotation=90,. C:\ProgramData\Anaconda3\lib\site-packages\scipy\cluster\hierarchy.py in dendrogram(Z, p, truncate_mode, color_threshold, get_leaves, orientation, labels, count_sort, distance_sort, show_leaf_counts, no_plot, no_labels, leaf_font_size, leaf_rotation, leaf_label_func, show_contracted, link_color_func, ax, above_threshold_color). 3275 ""'bottom', or 'right'""). 3276 . -> 3277 if labels and Z.shape[0] + 1 != len(labels):. 3278 raise ValueError(""Dimensions of Z and labels must be consistent.""). 3279 . ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all(). ```. #### Versions. Python: 3.8.6. Numpy: 1.18.5. scipy: 1.4.1. pandas : 1.0.5.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1556
https://github.com/scverse/scanpy/issues/1556:1564,safety,modul,module,1564,"com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). I am getting this error and although i downgraded the scipy to 1.4.1 as per one recommendation here but still didn't solve it! ```python. import numpy as np. import pandas as pd. from sklearn.datasets import load_iris. from sklearn.pipeline import make_pipeline. from sklearn.preprocessing import StandardScaler, Normalizer. from scipy.cluster.hierarchy import linkage, dendrogram. df_euro = pd.read_csv('https://assets.datacamp.com/production/repositories/655/datasets/2a1f3ab7bcc76eef1b8e1eb29afbd54c4ebf86f2/eurovision-2016.csv'). samples = df.iloc[:, 2:7].values[:42]. country_names = df.iloc[:, 1].values[:42]. mergings = linkage(samples, method='single'). # Plot the dendrogram. plt.figure(figsize=(15, 5)). dendrogram(mergings,. labels=country_names,. leaf_rotation=90, . leaf_font_size=6);. ```. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-185-e360a70857f0> in <module>. 9 # Plot the dendrogram. 10 plt.figure(figsize=(15, 5)). ---> 11 dendrogram(mergings, . 12 labels=companies,. 13 leaf_rotation=90,. C:\ProgramData\Anaconda3\lib\site-packages\scipy\cluster\hierarchy.py in dendrogram(Z, p, truncate_mode, color_threshold, get_leaves, orientation, labels, count_sort, distance_sort, show_leaf_counts, no_plot, no_labels, leaf_font_size, leaf_rotation, leaf_label_func, show_contracted, link_color_func, ax, above_threshold_color). 3275 ""'bottom', or 'right'""). 3276 . -> 3277 if labels and Z.shape[0] + 1 != len(labels):. 3278 raise ValueError(""Dimensions of Z and labels must be consistent.""). 3279 . ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all(). ```. #### Versions. Python: 3.8.6. Numpy: 1.18.5. scipy: 1.4.1. pandas : 1.0.5.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1556
https://github.com/scverse/scanpy/issues/1556:1492,testability,Trace,Traceback,1492,"com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). I am getting this error and although i downgraded the scipy to 1.4.1 as per one recommendation here but still didn't solve it! ```python. import numpy as np. import pandas as pd. from sklearn.datasets import load_iris. from sklearn.pipeline import make_pipeline. from sklearn.preprocessing import StandardScaler, Normalizer. from scipy.cluster.hierarchy import linkage, dendrogram. df_euro = pd.read_csv('https://assets.datacamp.com/production/repositories/655/datasets/2a1f3ab7bcc76eef1b8e1eb29afbd54c4ebf86f2/eurovision-2016.csv'). samples = df.iloc[:, 2:7].values[:42]. country_names = df.iloc[:, 1].values[:42]. mergings = linkage(samples, method='single'). # Plot the dendrogram. plt.figure(figsize=(15, 5)). dendrogram(mergings,. labels=country_names,. leaf_rotation=90, . leaf_font_size=6);. ```. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-185-e360a70857f0> in <module>. 9 # Plot the dendrogram. 10 plt.figure(figsize=(15, 5)). ---> 11 dendrogram(mergings, . 12 labels=companies,. 13 leaf_rotation=90,. C:\ProgramData\Anaconda3\lib\site-packages\scipy\cluster\hierarchy.py in dendrogram(Z, p, truncate_mode, color_threshold, get_leaves, orientation, labels, count_sort, distance_sort, show_leaf_counts, no_plot, no_labels, leaf_font_size, leaf_rotation, leaf_label_func, show_contracted, link_color_func, ax, above_threshold_color). 3275 ""'bottom', or 'right'""). 3276 . -> 3277 if labels and Z.shape[0] + 1 != len(labels):. 3278 raise ValueError(""Dimensions of Z and labels must be consistent.""). 3279 . ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all(). ```. #### Versions. Python: 3.8.6. Numpy: 1.18.5. scipy: 1.4.1. pandas : 1.0.5.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1556
https://github.com/scverse/scanpy/issues/1556:186,usability,confirm,confirmed,186,"ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all(); - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). I am getting this error and although i downgraded the scipy to 1.4.1 as per one recommendation here but still didn't solve it! ```python. import numpy as np. import pandas as pd. from sklearn.datasets import load_iris. from sklearn.pipeline import make_pipeline. from sklearn.preprocessing import StandardScaler, Normalizer. from scipy.cluster.hierarchy import linkage, dendrogram. df_euro = pd.read_csv('https://assets.datacamp.com/production/repositories/655/datasets/2a1f3ab7bcc76eef1b8e1eb29afbd54c4ebf86f2/eurovision-2016.csv'). samples = df.iloc[:, 2:7].values[:42]. country_names = df.iloc[:, 1].values[:42]. mergings = linkage(samples, method='single'). # Plot the dendrogram. plt.figure(figsize=(15, 5)). dendrogram(mergings,. labels=country_names,. leaf_rotation=90, . leaf_font_size=6);. ```. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-185-e360a70857f0> in <module>. 9 # Plot the dendrogram. 10 plt.figure(figsize=(15, 5)). ---> 11 dendrogram(mergings, . 12 labels=companies,. 13 leaf_rotation=90,. C:\ProgramData\Anaconda3\lib\site-packages\scipy\cluster\hierarchy.py in dendrogram(Z, p, truncate_mode, color_threshold, get_leaves, orientation, labels, count_sort, distance_sort, show_leaf_counts, no_plot, no_labels, leaf_font_size, leaf_rotation, leaf_label_func, show_contracted, link_color",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1556
https://github.com/scverse/scanpy/issues/1556:269,usability,confirm,confirmed,269,"ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all(); - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). I am getting this error and although i downgraded the scipy to 1.4.1 as per one recommendation here but still didn't solve it! ```python. import numpy as np. import pandas as pd. from sklearn.datasets import load_iris. from sklearn.pipeline import make_pipeline. from sklearn.preprocessing import StandardScaler, Normalizer. from scipy.cluster.hierarchy import linkage, dendrogram. df_euro = pd.read_csv('https://assets.datacamp.com/production/repositories/655/datasets/2a1f3ab7bcc76eef1b8e1eb29afbd54c4ebf86f2/eurovision-2016.csv'). samples = df.iloc[:, 2:7].values[:42]. country_names = df.iloc[:, 1].values[:42]. mergings = linkage(samples, method='single'). # Plot the dendrogram. plt.figure(figsize=(15, 5)). dendrogram(mergings,. labels=country_names,. leaf_rotation=90, . leaf_font_size=6);. ```. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-185-e360a70857f0> in <module>. 9 # Plot the dendrogram. 10 plt.figure(figsize=(15, 5)). ---> 11 dendrogram(mergings, . 12 labels=companies,. 13 leaf_rotation=90,. C:\ProgramData\Anaconda3\lib\site-packages\scipy\cluster\hierarchy.py in dendrogram(Z, p, truncate_mode, color_threshold, get_leaves, orientation, labels, count_sort, distance_sort, show_leaf_counts, no_plot, no_labels, leaf_font_size, leaf_rotation, leaf_label_func, show_contracted, link_color",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1556
https://github.com/scverse/scanpy/issues/1556:360,usability,guid,guide,360,"ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all(); - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). I am getting this error and although i downgraded the scipy to 1.4.1 as per one recommendation here but still didn't solve it! ```python. import numpy as np. import pandas as pd. from sklearn.datasets import load_iris. from sklearn.pipeline import make_pipeline. from sklearn.preprocessing import StandardScaler, Normalizer. from scipy.cluster.hierarchy import linkage, dendrogram. df_euro = pd.read_csv('https://assets.datacamp.com/production/repositories/655/datasets/2a1f3ab7bcc76eef1b8e1eb29afbd54c4ebf86f2/eurovision-2016.csv'). samples = df.iloc[:, 2:7].values[:42]. country_names = df.iloc[:, 1].values[:42]. mergings = linkage(samples, method='single'). # Plot the dendrogram. plt.figure(figsize=(15, 5)). dendrogram(mergings,. labels=country_names,. leaf_rotation=90, . leaf_font_size=6);. ```. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-185-e360a70857f0> in <module>. 9 # Plot the dendrogram. 10 plt.figure(figsize=(15, 5)). ---> 11 dendrogram(mergings, . 12 labels=companies,. 13 leaf_rotation=90,. C:\ProgramData\Anaconda3\lib\site-packages\scipy\cluster\hierarchy.py in dendrogram(Z, p, truncate_mode, color_threshold, get_leaves, orientation, labels, count_sort, distance_sort, show_leaf_counts, no_plot, no_labels, leaf_font_size, leaf_rotation, leaf_label_func, show_contracted, link_color",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1556
https://github.com/scverse/scanpy/issues/1556:415,usability,minim,minimal-bug-reports,415,"ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all(); - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). I am getting this error and although i downgraded the scipy to 1.4.1 as per one recommendation here but still didn't solve it! ```python. import numpy as np. import pandas as pd. from sklearn.datasets import load_iris. from sklearn.pipeline import make_pipeline. from sklearn.preprocessing import StandardScaler, Normalizer. from scipy.cluster.hierarchy import linkage, dendrogram. df_euro = pd.read_csv('https://assets.datacamp.com/production/repositories/655/datasets/2a1f3ab7bcc76eef1b8e1eb29afbd54c4ebf86f2/eurovision-2016.csv'). samples = df.iloc[:, 2:7].values[:42]. country_names = df.iloc[:, 1].values[:42]. mergings = linkage(samples, method='single'). # Plot the dendrogram. plt.figure(figsize=(15, 5)). dendrogram(mergings,. labels=country_names,. leaf_rotation=90, . leaf_font_size=6);. ```. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-185-e360a70857f0> in <module>. 9 # Plot the dendrogram. 10 plt.figure(figsize=(15, 5)). ---> 11 dendrogram(mergings, . 12 labels=companies,. 13 leaf_rotation=90,. C:\ProgramData\Anaconda3\lib\site-packages\scipy\cluster\hierarchy.py in dendrogram(Z, p, truncate_mode, color_threshold, get_leaves, orientation, labels, count_sort, distance_sort, show_leaf_counts, no_plot, no_labels, leaf_font_size, leaf_rotation, leaf_label_func, show_contracted, link_color",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1556
https://github.com/scverse/scanpy/issues/1556:521,usability,Minim,Minimal,521,"ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all(); - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). I am getting this error and although i downgraded the scipy to 1.4.1 as per one recommendation here but still didn't solve it! ```python. import numpy as np. import pandas as pd. from sklearn.datasets import load_iris. from sklearn.pipeline import make_pipeline. from sklearn.preprocessing import StandardScaler, Normalizer. from scipy.cluster.hierarchy import linkage, dendrogram. df_euro = pd.read_csv('https://assets.datacamp.com/production/repositories/655/datasets/2a1f3ab7bcc76eef1b8e1eb29afbd54c4ebf86f2/eurovision-2016.csv'). samples = df.iloc[:, 2:7].values[:42]. country_names = df.iloc[:, 1].values[:42]. mergings = linkage(samples, method='single'). # Plot the dendrogram. plt.figure(figsize=(15, 5)). dendrogram(mergings,. labels=country_names,. leaf_rotation=90, . leaf_font_size=6);. ```. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-185-e360a70857f0> in <module>. 9 # Plot the dendrogram. 10 plt.figure(figsize=(15, 5)). ---> 11 dendrogram(mergings, . 12 labels=companies,. 13 leaf_rotation=90,. C:\ProgramData\Anaconda3\lib\site-packages\scipy\cluster\hierarchy.py in dendrogram(Z, p, truncate_mode, color_threshold, get_leaves, orientation, labels, count_sort, distance_sort, show_leaf_counts, no_plot, no_labels, leaf_font_size, leaf_rotation, leaf_label_func, show_contracted, link_color",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1556
https://github.com/scverse/scanpy/issues/1556:609,usability,error,error,609,"ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all(); - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). I am getting this error and although i downgraded the scipy to 1.4.1 as per one recommendation here but still didn't solve it! ```python. import numpy as np. import pandas as pd. from sklearn.datasets import load_iris. from sklearn.pipeline import make_pipeline. from sklearn.preprocessing import StandardScaler, Normalizer. from scipy.cluster.hierarchy import linkage, dendrogram. df_euro = pd.read_csv('https://assets.datacamp.com/production/repositories/655/datasets/2a1f3ab7bcc76eef1b8e1eb29afbd54c4ebf86f2/eurovision-2016.csv'). samples = df.iloc[:, 2:7].values[:42]. country_names = df.iloc[:, 1].values[:42]. mergings = linkage(samples, method='single'). # Plot the dendrogram. plt.figure(figsize=(15, 5)). dendrogram(mergings,. labels=country_names,. leaf_rotation=90, . leaf_font_size=6);. ```. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-185-e360a70857f0> in <module>. 9 # Plot the dendrogram. 10 plt.figure(figsize=(15, 5)). ---> 11 dendrogram(mergings, . 12 labels=companies,. 13 leaf_rotation=90,. C:\ProgramData\Anaconda3\lib\site-packages\scipy\cluster\hierarchy.py in dendrogram(Z, p, truncate_mode, color_threshold, get_leaves, orientation, labels, count_sort, distance_sort, show_leaf_counts, no_plot, no_labels, leaf_font_size, leaf_rotation, leaf_label_func, show_contracted, link_color",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1556
https://github.com/scverse/scanpy/issues/1556:1536,usability,input,input-,1536,"com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). I am getting this error and although i downgraded the scipy to 1.4.1 as per one recommendation here but still didn't solve it! ```python. import numpy as np. import pandas as pd. from sklearn.datasets import load_iris. from sklearn.pipeline import make_pipeline. from sklearn.preprocessing import StandardScaler, Normalizer. from scipy.cluster.hierarchy import linkage, dendrogram. df_euro = pd.read_csv('https://assets.datacamp.com/production/repositories/655/datasets/2a1f3ab7bcc76eef1b8e1eb29afbd54c4ebf86f2/eurovision-2016.csv'). samples = df.iloc[:, 2:7].values[:42]. country_names = df.iloc[:, 1].values[:42]. mergings = linkage(samples, method='single'). # Plot the dendrogram. plt.figure(figsize=(15, 5)). dendrogram(mergings,. labels=country_names,. leaf_rotation=90, . leaf_font_size=6);. ```. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-185-e360a70857f0> in <module>. 9 # Plot the dendrogram. 10 plt.figure(figsize=(15, 5)). ---> 11 dendrogram(mergings, . 12 labels=companies,. 13 leaf_rotation=90,. C:\ProgramData\Anaconda3\lib\site-packages\scipy\cluster\hierarchy.py in dendrogram(Z, p, truncate_mode, color_threshold, get_leaves, orientation, labels, count_sort, distance_sort, show_leaf_counts, no_plot, no_labels, leaf_font_size, leaf_rotation, leaf_label_func, show_contracted, link_color_func, ax, above_threshold_color). 3275 ""'bottom', or 'right'""). 3276 . -> 3277 if labels and Z.shape[0] + 1 != len(labels):. 3278 raise ValueError(""Dimensions of Z and labels must be consistent.""). 3279 . ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all(). ```. #### Versions. Python: 3.8.6. Numpy: 1.18.5. scipy: 1.4.1. pandas : 1.0.5.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1556
