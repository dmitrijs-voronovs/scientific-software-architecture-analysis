id,quality_attribute,keyword,matched_word,match_idx,sentence,source,author,repo,version,wiki,url
https://github.com/google/deepvariant/issues/89:14888,deployability,upgrad,upgrade,14888,"ping upgrade: httplib2<1dev,>=0.9.2 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.11.3). Requirement already satisfied, skipping upgrade: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (3.0.0). Requirement already satisfied, skipping upgrade: google-auth-httplib2>=0.0.3 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.0.3). Requirement already satisfied, skipping upgrade: six<2dev,>=1.6.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.11.0). Requirement already satisfied, skipping upgrade: google-auth>=1.4.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.5.1). Requirement already satisfied, skipping upgrade: rsa>=3.1.4 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (3.4.2). Requirement already satisfied, skipping upgrade: cachetools>=2.0.0 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (2.1.0). Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (0.2.2). Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /usr/local/lib/python2.7/dist-packages (from rsa>=3.1.4->google-auth>=1.4.1->google-api-python-client) (0.4.4). ========== [2018年 08月 28日 星期二 10:55:17 CST] Stage 'Install TensorFlow pip package' starting. Skipping tf-nightly as it is not installed. Skipping tensorflow as it is not installed. Skipping tf-nightly-gpu as it is not installed. Skipping tensorflow-gpu as it is not installed. Installing Google Cloud Platform optimized CPU-only TensorFlow wheel. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 0 0 0 0 0 0 0 0 --:--:-- 0:02:09 --:--:-- 0curl: (7) Failed to connect to storage.googleapis.com port 443: Connection timed out.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:14904,deployability,modul,modules,14904,"ping upgrade: httplib2<1dev,>=0.9.2 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.11.3). Requirement already satisfied, skipping upgrade: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (3.0.0). Requirement already satisfied, skipping upgrade: google-auth-httplib2>=0.0.3 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.0.3). Requirement already satisfied, skipping upgrade: six<2dev,>=1.6.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.11.0). Requirement already satisfied, skipping upgrade: google-auth>=1.4.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.5.1). Requirement already satisfied, skipping upgrade: rsa>=3.1.4 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (3.4.2). Requirement already satisfied, skipping upgrade: cachetools>=2.0.0 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (2.1.0). Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (0.2.2). Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /usr/local/lib/python2.7/dist-packages (from rsa>=3.1.4->google-auth>=1.4.1->google-api-python-client) (0.4.4). ========== [2018年 08月 28日 星期二 10:55:17 CST] Stage 'Install TensorFlow pip package' starting. Skipping tf-nightly as it is not installed. Skipping tensorflow as it is not installed. Skipping tf-nightly-gpu as it is not installed. Skipping tensorflow-gpu as it is not installed. Installing Google Cloud Platform optimized CPU-only TensorFlow wheel. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 0 0 0 0 0 0 0 0 --:--:-- 0:02:09 --:--:-- 0curl: (7) Failed to connect to storage.googleapis.com port 443: Connection timed out.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:14994,deployability,api,api-python-client,14994,"ping upgrade: httplib2<1dev,>=0.9.2 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.11.3). Requirement already satisfied, skipping upgrade: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (3.0.0). Requirement already satisfied, skipping upgrade: google-auth-httplib2>=0.0.3 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.0.3). Requirement already satisfied, skipping upgrade: six<2dev,>=1.6.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.11.0). Requirement already satisfied, skipping upgrade: google-auth>=1.4.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.5.1). Requirement already satisfied, skipping upgrade: rsa>=3.1.4 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (3.4.2). Requirement already satisfied, skipping upgrade: cachetools>=2.0.0 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (2.1.0). Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (0.2.2). Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /usr/local/lib/python2.7/dist-packages (from rsa>=3.1.4->google-auth>=1.4.1->google-api-python-client) (0.4.4). ========== [2018年 08月 28日 星期二 10:55:17 CST] Stage 'Install TensorFlow pip package' starting. Skipping tf-nightly as it is not installed. Skipping tensorflow as it is not installed. Skipping tf-nightly-gpu as it is not installed. Skipping tensorflow-gpu as it is not installed. Installing Google Cloud Platform optimized CPU-only TensorFlow wheel. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 0 0 0 0 0 0 0 0 --:--:-- 0:02:09 --:--:-- 0curl: (7) Failed to connect to storage.googleapis.com port 443: Connection timed out.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:15062,deployability,upgrad,upgrade,15062,"ping upgrade: httplib2<1dev,>=0.9.2 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.11.3). Requirement already satisfied, skipping upgrade: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (3.0.0). Requirement already satisfied, skipping upgrade: google-auth-httplib2>=0.0.3 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.0.3). Requirement already satisfied, skipping upgrade: six<2dev,>=1.6.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.11.0). Requirement already satisfied, skipping upgrade: google-auth>=1.4.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.5.1). Requirement already satisfied, skipping upgrade: rsa>=3.1.4 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (3.4.2). Requirement already satisfied, skipping upgrade: cachetools>=2.0.0 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (2.1.0). Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (0.2.2). Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /usr/local/lib/python2.7/dist-packages (from rsa>=3.1.4->google-auth>=1.4.1->google-api-python-client) (0.4.4). ========== [2018年 08月 28日 星期二 10:55:17 CST] Stage 'Install TensorFlow pip package' starting. Skipping tf-nightly as it is not installed. Skipping tensorflow as it is not installed. Skipping tf-nightly-gpu as it is not installed. Skipping tensorflow-gpu as it is not installed. Installing Google Cloud Platform optimized CPU-only TensorFlow wheel. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 0 0 0 0 0 0 0 0 --:--:-- 0:02:09 --:--:-- 0curl: (7) Failed to connect to storage.googleapis.com port 443: Connection timed out.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:15172,deployability,api,api-python-client,15172,"ping upgrade: httplib2<1dev,>=0.9.2 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.11.3). Requirement already satisfied, skipping upgrade: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (3.0.0). Requirement already satisfied, skipping upgrade: google-auth-httplib2>=0.0.3 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.0.3). Requirement already satisfied, skipping upgrade: six<2dev,>=1.6.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.11.0). Requirement already satisfied, skipping upgrade: google-auth>=1.4.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.5.1). Requirement already satisfied, skipping upgrade: rsa>=3.1.4 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (3.4.2). Requirement already satisfied, skipping upgrade: cachetools>=2.0.0 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (2.1.0). Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (0.2.2). Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /usr/local/lib/python2.7/dist-packages (from rsa>=3.1.4->google-auth>=1.4.1->google-api-python-client) (0.4.4). ========== [2018年 08月 28日 星期二 10:55:17 CST] Stage 'Install TensorFlow pip package' starting. Skipping tf-nightly as it is not installed. Skipping tensorflow as it is not installed. Skipping tf-nightly-gpu as it is not installed. Skipping tensorflow-gpu as it is not installed. Installing Google Cloud Platform optimized CPU-only TensorFlow wheel. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 0 0 0 0 0 0 0 0 --:--:-- 0:02:09 --:--:-- 0curl: (7) Failed to connect to storage.googleapis.com port 443: Connection timed out.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:15244,deployability,Stage,Stage,15244,"ping upgrade: httplib2<1dev,>=0.9.2 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.11.3). Requirement already satisfied, skipping upgrade: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (3.0.0). Requirement already satisfied, skipping upgrade: google-auth-httplib2>=0.0.3 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.0.3). Requirement already satisfied, skipping upgrade: six<2dev,>=1.6.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.11.0). Requirement already satisfied, skipping upgrade: google-auth>=1.4.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.5.1). Requirement already satisfied, skipping upgrade: rsa>=3.1.4 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (3.4.2). Requirement already satisfied, skipping upgrade: cachetools>=2.0.0 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (2.1.0). Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (0.2.2). Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /usr/local/lib/python2.7/dist-packages (from rsa>=3.1.4->google-auth>=1.4.1->google-api-python-client) (0.4.4). ========== [2018年 08月 28日 星期二 10:55:17 CST] Stage 'Install TensorFlow pip package' starting. Skipping tf-nightly as it is not installed. Skipping tensorflow as it is not installed. Skipping tf-nightly-gpu as it is not installed. Skipping tensorflow-gpu as it is not installed. Installing Google Cloud Platform optimized CPU-only TensorFlow wheel. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 0 0 0 0 0 0 0 0 --:--:-- 0:02:09 --:--:-- 0curl: (7) Failed to connect to storage.googleapis.com port 443: Connection timed out.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:15251,deployability,Instal,Install,15251,"ping upgrade: httplib2<1dev,>=0.9.2 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.11.3). Requirement already satisfied, skipping upgrade: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (3.0.0). Requirement already satisfied, skipping upgrade: google-auth-httplib2>=0.0.3 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.0.3). Requirement already satisfied, skipping upgrade: six<2dev,>=1.6.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.11.0). Requirement already satisfied, skipping upgrade: google-auth>=1.4.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.5.1). Requirement already satisfied, skipping upgrade: rsa>=3.1.4 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (3.4.2). Requirement already satisfied, skipping upgrade: cachetools>=2.0.0 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (2.1.0). Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (0.2.2). Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /usr/local/lib/python2.7/dist-packages (from rsa>=3.1.4->google-auth>=1.4.1->google-api-python-client) (0.4.4). ========== [2018年 08月 28日 星期二 10:55:17 CST] Stage 'Install TensorFlow pip package' starting. Skipping tf-nightly as it is not installed. Skipping tensorflow as it is not installed. Skipping tf-nightly-gpu as it is not installed. Skipping tensorflow-gpu as it is not installed. Installing Google Cloud Platform optimized CPU-only TensorFlow wheel. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 0 0 0 0 0 0 0 0 --:--:-- 0:02:09 --:--:-- 0curl: (7) Failed to connect to storage.googleapis.com port 443: Connection timed out.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:15326,deployability,instal,installed,15326,"ping upgrade: httplib2<1dev,>=0.9.2 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.11.3). Requirement already satisfied, skipping upgrade: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (3.0.0). Requirement already satisfied, skipping upgrade: google-auth-httplib2>=0.0.3 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.0.3). Requirement already satisfied, skipping upgrade: six<2dev,>=1.6.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.11.0). Requirement already satisfied, skipping upgrade: google-auth>=1.4.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.5.1). Requirement already satisfied, skipping upgrade: rsa>=3.1.4 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (3.4.2). Requirement already satisfied, skipping upgrade: cachetools>=2.0.0 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (2.1.0). Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (0.2.2). Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /usr/local/lib/python2.7/dist-packages (from rsa>=3.1.4->google-auth>=1.4.1->google-api-python-client) (0.4.4). ========== [2018年 08月 28日 星期二 10:55:17 CST] Stage 'Install TensorFlow pip package' starting. Skipping tf-nightly as it is not installed. Skipping tensorflow as it is not installed. Skipping tf-nightly-gpu as it is not installed. Skipping tensorflow-gpu as it is not installed. Installing Google Cloud Platform optimized CPU-only TensorFlow wheel. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 0 0 0 0 0 0 0 0 --:--:-- 0:02:09 --:--:-- 0curl: (7) Failed to connect to storage.googleapis.com port 443: Connection timed out.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:15370,deployability,instal,installed,15370,"ping upgrade: httplib2<1dev,>=0.9.2 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.11.3). Requirement already satisfied, skipping upgrade: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (3.0.0). Requirement already satisfied, skipping upgrade: google-auth-httplib2>=0.0.3 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.0.3). Requirement already satisfied, skipping upgrade: six<2dev,>=1.6.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.11.0). Requirement already satisfied, skipping upgrade: google-auth>=1.4.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.5.1). Requirement already satisfied, skipping upgrade: rsa>=3.1.4 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (3.4.2). Requirement already satisfied, skipping upgrade: cachetools>=2.0.0 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (2.1.0). Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (0.2.2). Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /usr/local/lib/python2.7/dist-packages (from rsa>=3.1.4->google-auth>=1.4.1->google-api-python-client) (0.4.4). ========== [2018年 08月 28日 星期二 10:55:17 CST] Stage 'Install TensorFlow pip package' starting. Skipping tf-nightly as it is not installed. Skipping tensorflow as it is not installed. Skipping tf-nightly-gpu as it is not installed. Skipping tensorflow-gpu as it is not installed. Installing Google Cloud Platform optimized CPU-only TensorFlow wheel. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 0 0 0 0 0 0 0 0 --:--:-- 0:02:09 --:--:-- 0curl: (7) Failed to connect to storage.googleapis.com port 443: Connection timed out.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:15418,deployability,instal,installed,15418,"ping upgrade: httplib2<1dev,>=0.9.2 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.11.3). Requirement already satisfied, skipping upgrade: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (3.0.0). Requirement already satisfied, skipping upgrade: google-auth-httplib2>=0.0.3 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.0.3). Requirement already satisfied, skipping upgrade: six<2dev,>=1.6.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.11.0). Requirement already satisfied, skipping upgrade: google-auth>=1.4.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.5.1). Requirement already satisfied, skipping upgrade: rsa>=3.1.4 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (3.4.2). Requirement already satisfied, skipping upgrade: cachetools>=2.0.0 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (2.1.0). Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (0.2.2). Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /usr/local/lib/python2.7/dist-packages (from rsa>=3.1.4->google-auth>=1.4.1->google-api-python-client) (0.4.4). ========== [2018年 08月 28日 星期二 10:55:17 CST] Stage 'Install TensorFlow pip package' starting. Skipping tf-nightly as it is not installed. Skipping tensorflow as it is not installed. Skipping tf-nightly-gpu as it is not installed. Skipping tensorflow-gpu as it is not installed. Installing Google Cloud Platform optimized CPU-only TensorFlow wheel. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 0 0 0 0 0 0 0 0 --:--:-- 0:02:09 --:--:-- 0curl: (7) Failed to connect to storage.googleapis.com port 443: Connection timed out.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:15466,deployability,instal,installed,15466,"ping upgrade: httplib2<1dev,>=0.9.2 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.11.3). Requirement already satisfied, skipping upgrade: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (3.0.0). Requirement already satisfied, skipping upgrade: google-auth-httplib2>=0.0.3 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.0.3). Requirement already satisfied, skipping upgrade: six<2dev,>=1.6.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.11.0). Requirement already satisfied, skipping upgrade: google-auth>=1.4.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.5.1). Requirement already satisfied, skipping upgrade: rsa>=3.1.4 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (3.4.2). Requirement already satisfied, skipping upgrade: cachetools>=2.0.0 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (2.1.0). Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (0.2.2). Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /usr/local/lib/python2.7/dist-packages (from rsa>=3.1.4->google-auth>=1.4.1->google-api-python-client) (0.4.4). ========== [2018年 08月 28日 星期二 10:55:17 CST] Stage 'Install TensorFlow pip package' starting. Skipping tf-nightly as it is not installed. Skipping tensorflow as it is not installed. Skipping tf-nightly-gpu as it is not installed. Skipping tensorflow-gpu as it is not installed. Installing Google Cloud Platform optimized CPU-only TensorFlow wheel. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 0 0 0 0 0 0 0 0 --:--:-- 0:02:09 --:--:-- 0curl: (7) Failed to connect to storage.googleapis.com port 443: Connection timed out.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:15477,deployability,Instal,Installing,15477,"ping upgrade: httplib2<1dev,>=0.9.2 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.11.3). Requirement already satisfied, skipping upgrade: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (3.0.0). Requirement already satisfied, skipping upgrade: google-auth-httplib2>=0.0.3 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.0.3). Requirement already satisfied, skipping upgrade: six<2dev,>=1.6.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.11.0). Requirement already satisfied, skipping upgrade: google-auth>=1.4.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.5.1). Requirement already satisfied, skipping upgrade: rsa>=3.1.4 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (3.4.2). Requirement already satisfied, skipping upgrade: cachetools>=2.0.0 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (2.1.0). Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (0.2.2). Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /usr/local/lib/python2.7/dist-packages (from rsa>=3.1.4->google-auth>=1.4.1->google-api-python-client) (0.4.4). ========== [2018年 08月 28日 星期二 10:55:17 CST] Stage 'Install TensorFlow pip package' starting. Skipping tf-nightly as it is not installed. Skipping tensorflow as it is not installed. Skipping tf-nightly-gpu as it is not installed. Skipping tensorflow-gpu as it is not installed. Installing Google Cloud Platform optimized CPU-only TensorFlow wheel. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 0 0 0 0 0 0 0 0 --:--:-- 0:02:09 --:--:-- 0curl: (7) Failed to connect to storage.googleapis.com port 443: Connection timed out.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:15702,deployability,Fail,Failed,15702,"ping upgrade: httplib2<1dev,>=0.9.2 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.11.3). Requirement already satisfied, skipping upgrade: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (3.0.0). Requirement already satisfied, skipping upgrade: google-auth-httplib2>=0.0.3 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.0.3). Requirement already satisfied, skipping upgrade: six<2dev,>=1.6.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.11.0). Requirement already satisfied, skipping upgrade: google-auth>=1.4.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.5.1). Requirement already satisfied, skipping upgrade: rsa>=3.1.4 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (3.4.2). Requirement already satisfied, skipping upgrade: cachetools>=2.0.0 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (2.1.0). Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (0.2.2). Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /usr/local/lib/python2.7/dist-packages (from rsa>=3.1.4->google-auth>=1.4.1->google-api-python-client) (0.4.4). ========== [2018年 08月 28日 星期二 10:55:17 CST] Stage 'Install TensorFlow pip package' starting. Skipping tf-nightly as it is not installed. Skipping tensorflow as it is not installed. Skipping tf-nightly-gpu as it is not installed. Skipping tensorflow-gpu as it is not installed. Installing Google Cloud Platform optimized CPU-only TensorFlow wheel. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 0 0 0 0 0 0 0 0 --:--:-- 0:02:09 --:--:-- 0curl: (7) Failed to connect to storage.googleapis.com port 443: Connection timed out.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:218,energy efficiency,Load,Load,218,"@pichuan hi, i got the zip file and ra run-prereq.sh and this was the output:. solokopi@solokopi-All-Series:~/Desktop/DeepVariant-0.7.0+cl-208818123$ sudo bash run-prereq.sh. [sudo] password for solokopi: . ========== Load config settings. ========== [2018年 08月 28日 星期二 10:31:05 CST] Stage 'Misc setup' starting. Ign:1 http://dl.google.com/linux/chrome/deb stable InRelease. Hit:2 http://mirrors.aliyun.com/ubuntu xenial InRelease . Hit:3 http://dl.google.com/linux/chrome/deb stable Release . Hit:4 http://mirrors.aliyun.com/ubuntu xenial-updates InRelease . Get:6 http://mirrors.aliyun.com/ubuntu xenial-backports InRelease [107 kB] . Hit:7 http://mirrors.aliyun.com/ubuntu xenial-security InRelease . Hit:8 http://ppa.launchpad.net/webupd8team/java/ubuntu xenial InRelease . Err:9 http://storage.googleapis.com/bazel-apt stable InRelease . Cannot initiate the connection to storage.googleapis.com:80 (2404:6800:4012:1::2010). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::2010 80]. Err:10 http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease . Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4008:803::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4008:803::200e 80]. Fetched 107 kB in 12min 0s (148 B/s) . Reading package lists... Done. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:1025,energy efficiency,cloud,cloud,1025,ile and ra run-prereq.sh and this was the output:. solokopi@solokopi-All-Series:~/Desktop/DeepVariant-0.7.0+cl-208818123$ sudo bash run-prereq.sh. [sudo] password for solokopi: . ========== Load config settings. ========== [2018年 08月 28日 星期二 10:31:05 CST] Stage 'Misc setup' starting. Ign:1 http://dl.google.com/linux/chrome/deb stable InRelease. Hit:2 http://mirrors.aliyun.com/ubuntu xenial InRelease . Hit:3 http://dl.google.com/linux/chrome/deb stable Release . Hit:4 http://mirrors.aliyun.com/ubuntu xenial-updates InRelease . Get:6 http://mirrors.aliyun.com/ubuntu xenial-backports InRelease [107 kB] . Hit:7 http://mirrors.aliyun.com/ubuntu xenial-security InRelease . Hit:8 http://ppa.launchpad.net/webupd8team/java/ubuntu xenial InRelease . Err:9 http://storage.googleapis.com/bazel-apt stable InRelease . Cannot initiate the connection to storage.googleapis.com:80 (2404:6800:4012:1::2010). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::2010 80]. Err:10 http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease . Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4008:803::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4008:803::200e 80]. Fetched 107 kB in 12min 0s (148 B/s) . Reading package lists... Done. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is ,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:1046,energy efficiency,cloud,cloud-sdk-xenial,1046,nd this was the output:. solokopi@solokopi-All-Series:~/Desktop/DeepVariant-0.7.0+cl-208818123$ sudo bash run-prereq.sh. [sudo] password for solokopi: . ========== Load config settings. ========== [2018年 08月 28日 星期二 10:31:05 CST] Stage 'Misc setup' starting. Ign:1 http://dl.google.com/linux/chrome/deb stable InRelease. Hit:2 http://mirrors.aliyun.com/ubuntu xenial InRelease . Hit:3 http://dl.google.com/linux/chrome/deb stable Release . Hit:4 http://mirrors.aliyun.com/ubuntu xenial-updates InRelease . Get:6 http://mirrors.aliyun.com/ubuntu xenial-backports InRelease [107 kB] . Hit:7 http://mirrors.aliyun.com/ubuntu xenial-security InRelease . Hit:8 http://ppa.launchpad.net/webupd8team/java/ubuntu xenial InRelease . Err:9 http://storage.googleapis.com/bazel-apt stable InRelease . Cannot initiate the connection to storage.googleapis.com:80 (2404:6800:4012:1::2010). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::2010 80]. Err:10 http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease . Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4008:803::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4008:803::200e 80]. Fetched 107 kB in 12min 0s (148 B/s) . Reading package lists... Done. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times ,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:1118,energy efficiency,cloud,cloud,1118,pVariant-0.7.0+cl-208818123$ sudo bash run-prereq.sh. [sudo] password for solokopi: . ========== Load config settings. ========== [2018年 08月 28日 星期二 10:31:05 CST] Stage 'Misc setup' starting. Ign:1 http://dl.google.com/linux/chrome/deb stable InRelease. Hit:2 http://mirrors.aliyun.com/ubuntu xenial InRelease . Hit:3 http://dl.google.com/linux/chrome/deb stable Release . Hit:4 http://mirrors.aliyun.com/ubuntu xenial-updates InRelease . Get:6 http://mirrors.aliyun.com/ubuntu xenial-backports InRelease [107 kB] . Hit:7 http://mirrors.aliyun.com/ubuntu xenial-security InRelease . Hit:8 http://ppa.launchpad.net/webupd8team/java/ubuntu xenial InRelease . Err:9 http://storage.googleapis.com/bazel-apt stable InRelease . Cannot initiate the connection to storage.googleapis.com:80 (2404:6800:4012:1::2010). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::2010 80]. Err:10 http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease . Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4008:803::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4008:803::200e 80]. Fetched 107 kB in 12min 0s (148 B/s) . Reading package lists... Done. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sou,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:1543,energy efficiency,cloud,cloud-sdk,1543,InRelease . Get:6 http://mirrors.aliyun.com/ubuntu xenial-backports InRelease [107 kB] . Hit:7 http://mirrors.aliyun.com/ubuntu xenial-security InRelease . Hit:8 http://ppa.launchpad.net/webupd8team/java/ubuntu xenial InRelease . Err:9 http://storage.googleapis.com/bazel-apt stable InRelease . Cannot initiate the connection to storage.googleapis.com:80 (2404:6800:4012:1::2010). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::2010 80]. Err:10 http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease . Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4008:803::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4008:803::200e 80]. Fetched 107 kB in 12min 0s (148 B/s) . Reading package lists... Done. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons ,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:1595,energy efficiency,cloud,cloud-sdk,1595,enial-backports InRelease [107 kB] . Hit:7 http://mirrors.aliyun.com/ubuntu xenial-security InRelease . Hit:8 http://ppa.launchpad.net/webupd8team/java/ubuntu xenial InRelease . Err:9 http://storage.googleapis.com/bazel-apt stable InRelease . Cannot initiate the connection to storage.googleapis.com:80 (2404:6800:4012:1::2010). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::2010 80]. Err:10 http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease . Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4008:803::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4008:803::200e 80]. Fetched 107 kB in 12min 0s (148 B/s) . Reading package lists... Done. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple ,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:1723,energy efficiency,cloud,cloud-sdk,1723,ad.net/webupd8team/java/ubuntu xenial InRelease . Err:9 http://storage.googleapis.com/bazel-apt stable InRelease . Cannot initiate the connection to storage.googleapis.com:80 (2404:6800:4012:1::2010). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::2010 80]. Err:10 http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease . Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4008:803::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4008:803::200e 80]. Fetched 107 kB in 12min 0s (148 B/s) . Reading package lists... Done. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:1775,energy efficiency,cloud,cloud-sdk,1775,r:9 http://storage.googleapis.com/bazel-apt stable InRelease . Cannot initiate the connection to storage.googleapis.com:80 (2404:6800:4012:1::2010). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::2010 80]. Err:10 http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease . Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4008:803::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4008:803::200e 80]. Fetched 107 kB in 12min 0s (148 B/s) . Reading package lists... Done. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://storage.googleapis.com/bazel-apt/dists/stabl,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:1902,energy efficiency,cloud,cloud-sdk,1902,4:6800:4012:1::2010). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::2010 80]. Err:10 http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease . Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4008:803::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4008:803::200e 80]. Fetched 107 kB in 12min 0s (148 B/s) . Reading package lists... Done. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://storage.googleapis.com/bazel-apt/dists/stable/InRelease Cannot initiate the connection to storage.googleapis.com:80 (2404:6800:4012:1::2010). - connect (101: Network is un,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:1954,energy efficiency,cloud,cloud-sdk,1954,eachable) [IP: 2404:6800:4012:1::2010 80]. Err:10 http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease . Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4008:803::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4008:803::200e 80]. Fetched 107 kB in 12min 0s (148 B/s) . Reading package lists... Done. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://storage.googleapis.com/bazel-apt/dists/stable/InRelease Cannot initiate the connection to storage.googleapis.com:80 (2404:6800:4012:1::2010). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::2010 80]. W: Faile,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:2088,energy efficiency,cloud,cloud-sdk,2088,e connection to packages.cloud.google.com:80 (2404:6800:4008:803::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4008:803::200e 80]. Fetched 107 kB in 12min 0s (148 B/s) . Reading package lists... Done. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://storage.googleapis.com/bazel-apt/dists/stable/InRelease Cannot initiate the connection to storage.googleapis.com:80 (2404:6800:4012:1::2010). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::2010 80]. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.goog,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:2140,energy efficiency,cloud,cloud-sdk,2140,800:4008:803::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4008:803::200e 80]. Fetched 107 kB in 12min 0s (148 B/s) . Reading package lists... Done. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://storage.googleapis.com/bazel-apt/dists/stable/InRelease Cannot initiate the connection to storage.googleapis.com:80 (2404:6800:4012:1::2010). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::2010 80]. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4008:803::200e). - connect (101,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:2271,energy efficiency,cloud,cloud-sdk,2271,") . Reading package lists... Done. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://storage.googleapis.com/bazel-apt/dists/stable/InRelease Cannot initiate the connection to storage.googleapis.com:80 (2404:6800:4012:1::2010). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::2010 80]. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4008:803::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4008:803::200e 80]. W: Some index files failed to download. They have been ignored, or old",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:2323,energy efficiency,cloud,cloud-sdk,2323,"'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://storage.googleapis.com/bazel-apt/dists/stable/InRelease Cannot initiate the connection to storage.googleapis.com:80 (2404:6800:4012:1::2010). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::2010 80]. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4008:803::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4008:803::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:2455,energy efficiency,cloud,cloud-sdk,2455,"ary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://storage.googleapis.com/bazel-apt/dists/stable/InRelease Cannot initiate the connection to storage.googleapis.com:80 (2404:6800:4012:1::2010). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::2010 80]. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4008:803::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4008:803::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-c",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:2507,energy efficiency,cloud,cloud-sdk,2507,"/etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://storage.googleapis.com/bazel-apt/dists/stable/InRelease Cannot initiate the connection to storage.googleapis.com:80 (2404:6800:4012:1::2010). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::2010 80]. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4008:803::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4008:803::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i38",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:2640,energy efficiency,cloud,cloud-sdk,2640,"i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://storage.googleapis.com/bazel-apt/dists/stable/InRelease Cannot initiate the connection to storage.googleapis.com:80 (2404:6800:4012:1::2010). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::2010 80]. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4008:803::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4008:803::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:2692,energy efficiency,cloud,cloud-sdk,2692,"apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://storage.googleapis.com/bazel-apt/dists/stable/InRelease Cannot initiate the connection to storage.googleapis.com:80 (2404:6800:4012:1::2010). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::2010 80]. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4008:803::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4008:803::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Pack",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:2986,energy efficiency,cloud,cloud,2986,"tions (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://storage.googleapis.com/bazel-apt/dists/stable/InRelease Cannot initiate the connection to storage.googleapis.com:80 (2404:6800:4012:1::2010). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::2010 80]. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4008:803::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4008:803::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:3013,energy efficiency,cloud,cloud-sdk-xenial,3013,"US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://storage.googleapis.com/bazel-apt/dists/stable/InRelease Cannot initiate the connection to storage.googleapis.com:80 (2404:6800:4012:1::2010). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::2010 80]. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4008:803::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4008:803::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:3083,energy efficiency,cloud,cloud,3083,"e-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://storage.googleapis.com/bazel-apt/dists/stable/InRelease Cannot initiate the connection to storage.googleapis.com:80 (2404:6800:4012:1::2010). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::2010 80]. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4008:803::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4008:803::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:3407,energy efficiency,cloud,cloud-sdk,3407,"le times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://storage.googleapis.com/bazel-apt/dists/stable/InRelease Cannot initiate the connection to storage.googleapis.com:80 (2404:6800:4012:1::2010). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::2010 80]. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4008:803::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4008:803::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:3459,energy efficiency,cloud,cloud-sdk,3459,".list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://storage.googleapis.com/bazel-apt/dists/stable/InRelease Cannot initiate the connection to storage.googleapis.com:80 (2404:6800:4012:1::2010). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::2010 80]. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4008:803::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4008:803::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:3587,energy efficiency,cloud,cloud-sdk,3587,"ultiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://storage.googleapis.com/bazel-apt/dists/stable/InRelease Cannot initiate the connection to storage.googleapis.com:80 (2404:6800:4012:1::2010). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::2010 80]. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4008:803::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4008:803::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. Reading package li",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:3639,energy efficiency,cloud,cloud-sdk,3639,"d-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://storage.googleapis.com/bazel-apt/dists/stable/InRelease Cannot initiate the connection to storage.googleapis.com:80 (2404:6800:4012:1::2010). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::2010 80]. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4008:803::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4008:803::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. Reading package lists... Done. Building dependency tree . Reading stat",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:3766,energy efficiency,cloud,cloud-sdk,3766,"sts/stable/InRelease Cannot initiate the connection to storage.googleapis.com:80 (2404:6800:4012:1::2010). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::2010 80]. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4008:803::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4008:803::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. Reading package lists... Done. Building dependency tree . Reading state information... Done. sudo is already the newest version (1.8.16-0ubuntu1.5). The following packages were automatically instal",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:3818,energy efficiency,cloud,cloud-sdk,3818,"to storage.googleapis.com:80 (2404:6800:4012:1::2010). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::2010 80]. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4008:803::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4008:803::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. Reading package lists... Done. Building dependency tree . Reading state information... Done. sudo is already the newest version (1.8.16-0ubuntu1.5). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-he",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:3952,energy efficiency,cloud,cloud-sdk,3952,"led to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4008:803::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4008:803::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. Reading package lists... Done. Building dependency tree . Reading state information... Done. sudo is already the newest version (1.8.16-0ubuntu1.5). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt auto",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:4004,energy efficiency,cloud,cloud-sdk,4004,"sts/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4008:803::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4008:803::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. Reading package lists... Done. Building dependency tree . Reading state information... Done. sudo is already the newest version (1.8.16-0ubuntu1.5). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installe",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:4135,energy efficiency,cloud,cloud-sdk,4135," (101: Network is unreachable) [IP: 2404:6800:4008:803::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. Reading package lists... Done. Building dependency tree . Reading state information... Done. sudo is already the newest version (1.8.16-0ubuntu1.5). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an inv",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:4187,energy efficiency,cloud,cloud-sdk,4187,"03::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. Reading package lists... Done. Building dependency tree . Reading state information... Done. sudo is already the newest version (1.8.16-0ubuntu1.5). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:4319,energy efficiency,cloud,cloud-sdk,4319,"ary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. Reading package lists... Done. Building dependency tree . Reading state information... Done. sudo is already the newest version (1.8.16-0ubuntu1.5). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:43:08 CST] Stage 'Update package list' starting. W: Target Packages (main/binary-amd64/Packages) is configured multiple times ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:4371,energy efficiency,cloud,cloud-sdk,4371,"/etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. Reading package lists... Done. Building dependency tree . Reading state information... Done. sudo is already the newest version (1.8.16-0ubuntu1.5). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:43:08 CST] Stage 'Update package list' starting. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 a",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:4504,energy efficiency,cloud,cloud-sdk,4504,"i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. Reading package lists... Done. Building dependency tree . Reading state information... Done. sudo is already the newest version (1.8.16-0ubuntu1.5). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:43:08 CST] Stage 'Update package list' starting. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /e",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:4556,energy efficiency,cloud,cloud-sdk,4556,"apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. Reading package lists... Done. Building dependency tree . Reading state information... Done. sudo is already the newest version (1.8.16-0ubuntu1.5). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:43:08 CST] Stage 'Update package list' starting. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /e",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:5358,energy efficiency,cloud,cloud-sdk,5358,"/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. Reading package lists... Done. Building dependency tree . Reading state information... Done. sudo is already the newest version (1.8.16-0ubuntu1.5). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:43:08 CST] Stage 'Update package list' starting. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:5410,energy efficiency,cloud,cloud-sdk,5410,"in/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. Reading package lists... Done. Building dependency tree . Reading state information... Done. sudo is already the newest version (1.8.16-0ubuntu1.5). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:43:08 CST] Stage 'Update package list' starting. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:5538,energy efficiency,cloud,cloud-sdk,5538,"ist.d/google-cloud-sdk.list:2. Reading package lists... Done. Building dependency tree . Reading state information... Done. sudo is already the newest version (1.8.16-0ubuntu1.5). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:43:08 CST] Stage 'Update package list' starting. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:5590,energy efficiency,cloud,cloud-sdk,5590,"... Done. Building dependency tree . Reading state information... Done. sudo is already the newest version (1.8.16-0ubuntu1.5). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:43:08 CST] Stage 'Update package list' starting. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sd",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:5717,energy efficiency,cloud,cloud-sdk,5717," The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:43:08 CST] Stage 'Update package list' starting. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4012:1::200e). - connect (101: Net",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:5769,energy efficiency,cloud,cloud-sdk,5769," and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:43:08 CST] Stage 'Update package list' starting. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4012:1::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::200e 80]",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:5903,energy efficiency,cloud,cloud-sdk,5903,"image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:43:08 CST] Stage 'Update package list' starting. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4012:1::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Pack",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:5955,energy efficiency,cloud,cloud-sdk,5955,"ove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:43:08 CST] Stage 'Update package list' starting. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4012:1::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sourc",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:6086,energy efficiency,cloud,cloud-sdk,6086,"ctory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:43:08 CST] Stage 'Update package list' starting. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4012:1::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Package",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:6138,energy efficiency,cloud,cloud-sdk,6138,"d filename extension. ========== [2018年 08月 28日 星期二 10:43:08 CST] Stage 'Update package list' starting. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4012:1::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:6270,energy efficiency,cloud,cloud-sdk,6270,"ary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4012:1::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:6322,energy efficiency,cloud,cloud-sdk,6322,"/etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4012:1::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:6455,energy efficiency,cloud,cloud-sdk,6455,"i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4012:1::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) i",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:6507,energy efficiency,cloud,cloud-sdk,6507,"apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4012:1::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:6560,energy efficiency,cloud,cloud,6560,"/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4012:1::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.lis",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:6587,energy efficiency,cloud,cloud-sdk-xenial,6587,"-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4012:1::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:6657,energy efficiency,cloud,cloud,6657,"figured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4012:1::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured mult",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:6977,energy efficiency,cloud,cloud-sdk,6977," Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4012:1::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:7029,energy efficiency,cloud,cloud-sdk,7029,"ed multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4012:1::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:7157,energy efficiency,cloud,cloud-sdk,7157,"get DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4012:1::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. ========== [2018年 ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:7209,energy efficiency,cloud,cloud-sdk,7209,"igured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4012:1::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install development",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:7336,energy efficiency,cloud,cloud-sdk,7336,": Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4012:1::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install development packages' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. pkg-config is",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:7388,energy efficiency,cloud,cloud-sdk,7388,"s configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4012:1::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install development packages' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. pkg-config is already the newest version (0.29.1-0ubuntu1). unzip",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:7522,energy efficiency,cloud,cloud-sdk,7522," Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4012:1::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install development packages' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. pkg-config is already the newest version (0.29.1-0ubuntu1). unzip is already the newest version (6.0-20ubuntu1). zip is already the newest version (3.0-11). curl is already the newest version (7.47.0",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:7574,energy efficiency,cloud,cloud-sdk,7574,"t/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4012:1::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install development packages' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. pkg-config is already the newest version (0.29.1-0ubuntu1). unzip is already the newest version (6.0-20ubuntu1). zip is already the newest version (3.0-11). curl is already the newest version (7.47.0-1ubuntu2.8). zlib1g-dev is already the newest versi",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:7705,energy efficiency,cloud,cloud-sdk,7705,"ct (101: Network is unreachable) [IP: 2404:6800:4012:1::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install development packages' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. pkg-config is already the newest version (0.29.1-0ubuntu1). unzip is already the newest version (6.0-20ubuntu1). zip is already the newest version (3.0-11). curl is already the newest version (7.47.0-1ubuntu2.8). zlib1g-dev is already the newest version (1:1.2.8.dfsg-2ubuntu4.1). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-hea",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:7757,energy efficiency,cloud,cloud-sdk,7757,":1::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install development packages' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. pkg-config is already the newest version (0.29.1-0ubuntu1). unzip is already the newest version (6.0-20ubuntu1). zip is already the newest version (3.0-11). curl is already the newest version (7.47.0-1ubuntu2.8). zlib1g-dev is already the newest version (1:1.2.8.dfsg-2ubuntu4.1). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linu",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:7889,energy efficiency,cloud,cloud-sdk,7889,"ary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install development packages' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. pkg-config is already the newest version (0.29.1-0ubuntu1). unzip is already the newest version (6.0-20ubuntu1). zip is already the newest version (3.0-11). curl is already the newest version (7.47.0-1ubuntu2.8). zlib1g-dev is already the newest version (1:1.2.8.dfsg-2ubuntu4.1). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly install",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:7941,energy efficiency,cloud,cloud-sdk,7941,"/etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install development packages' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. pkg-config is already the newest version (0.29.1-0ubuntu1). unzip is already the newest version (6.0-20ubuntu1). zip is already the newest version (3.0-11). curl is already the newest version (7.47.0-1ubuntu2.8). zlib1g-dev is already the newest version (1:1.2.8.dfsg-2ubuntu4.1). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:8074,energy efficiency,cloud,cloud-sdk,8074,"i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install development packages' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. pkg-config is already the newest version (0.29.1-0ubuntu1). unzip is already the newest version (6.0-20ubuntu1). zip is already the newest version (3.0-11). curl is already the newest version (7.47.0-1ubuntu2.8). zlib1g-dev is already the newest version (1:1.2.8.dfsg-2ubuntu4.1). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:8126,energy efficiency,cloud,cloud-sdk,8126,"apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install development packages' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. pkg-config is already the newest version (0.29.1-0ubuntu1). unzip is already the newest version (6.0-20ubuntu1). zip is already the newest version (3.0-11). curl is already the newest version (7.47.0-1ubuntu2.8). zlib1g-dev is already the newest version (1:1.2.8.dfsg-2ubuntu4.1). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install python packaging infr",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:15401,energy efficiency,gpu,gpu,15401,"ping upgrade: httplib2<1dev,>=0.9.2 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.11.3). Requirement already satisfied, skipping upgrade: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (3.0.0). Requirement already satisfied, skipping upgrade: google-auth-httplib2>=0.0.3 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.0.3). Requirement already satisfied, skipping upgrade: six<2dev,>=1.6.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.11.0). Requirement already satisfied, skipping upgrade: google-auth>=1.4.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.5.1). Requirement already satisfied, skipping upgrade: rsa>=3.1.4 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (3.4.2). Requirement already satisfied, skipping upgrade: cachetools>=2.0.0 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (2.1.0). Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (0.2.2). Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /usr/local/lib/python2.7/dist-packages (from rsa>=3.1.4->google-auth>=1.4.1->google-api-python-client) (0.4.4). ========== [2018年 08月 28日 星期二 10:55:17 CST] Stage 'Install TensorFlow pip package' starting. Skipping tf-nightly as it is not installed. Skipping tensorflow as it is not installed. Skipping tf-nightly-gpu as it is not installed. Skipping tensorflow-gpu as it is not installed. Installing Google Cloud Platform optimized CPU-only TensorFlow wheel. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 0 0 0 0 0 0 0 0 --:--:-- 0:02:09 --:--:-- 0curl: (7) Failed to connect to storage.googleapis.com port 443: Connection timed out.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:15449,energy efficiency,gpu,gpu,15449,"ping upgrade: httplib2<1dev,>=0.9.2 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.11.3). Requirement already satisfied, skipping upgrade: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (3.0.0). Requirement already satisfied, skipping upgrade: google-auth-httplib2>=0.0.3 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.0.3). Requirement already satisfied, skipping upgrade: six<2dev,>=1.6.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.11.0). Requirement already satisfied, skipping upgrade: google-auth>=1.4.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.5.1). Requirement already satisfied, skipping upgrade: rsa>=3.1.4 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (3.4.2). Requirement already satisfied, skipping upgrade: cachetools>=2.0.0 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (2.1.0). Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (0.2.2). Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /usr/local/lib/python2.7/dist-packages (from rsa>=3.1.4->google-auth>=1.4.1->google-api-python-client) (0.4.4). ========== [2018年 08月 28日 星期二 10:55:17 CST] Stage 'Install TensorFlow pip package' starting. Skipping tf-nightly as it is not installed. Skipping tensorflow as it is not installed. Skipping tf-nightly-gpu as it is not installed. Skipping tensorflow-gpu as it is not installed. Installing Google Cloud Platform optimized CPU-only TensorFlow wheel. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 0 0 0 0 0 0 0 0 --:--:-- 0:02:09 --:--:-- 0curl: (7) Failed to connect to storage.googleapis.com port 443: Connection timed out.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:15495,energy efficiency,Cloud,Cloud,15495,"ping upgrade: httplib2<1dev,>=0.9.2 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.11.3). Requirement already satisfied, skipping upgrade: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (3.0.0). Requirement already satisfied, skipping upgrade: google-auth-httplib2>=0.0.3 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.0.3). Requirement already satisfied, skipping upgrade: six<2dev,>=1.6.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.11.0). Requirement already satisfied, skipping upgrade: google-auth>=1.4.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.5.1). Requirement already satisfied, skipping upgrade: rsa>=3.1.4 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (3.4.2). Requirement already satisfied, skipping upgrade: cachetools>=2.0.0 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (2.1.0). Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (0.2.2). Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /usr/local/lib/python2.7/dist-packages (from rsa>=3.1.4->google-auth>=1.4.1->google-api-python-client) (0.4.4). ========== [2018年 08月 28日 星期二 10:55:17 CST] Stage 'Install TensorFlow pip package' starting. Skipping tf-nightly as it is not installed. Skipping tensorflow as it is not installed. Skipping tf-nightly-gpu as it is not installed. Skipping tensorflow-gpu as it is not installed. Installing Google Cloud Platform optimized CPU-only TensorFlow wheel. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 0 0 0 0 0 0 0 0 --:--:-- 0:02:09 --:--:-- 0curl: (7) Failed to connect to storage.googleapis.com port 443: Connection timed out.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:15510,energy efficiency,optim,optimized,15510,"ping upgrade: httplib2<1dev,>=0.9.2 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.11.3). Requirement already satisfied, skipping upgrade: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (3.0.0). Requirement already satisfied, skipping upgrade: google-auth-httplib2>=0.0.3 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.0.3). Requirement already satisfied, skipping upgrade: six<2dev,>=1.6.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.11.0). Requirement already satisfied, skipping upgrade: google-auth>=1.4.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.5.1). Requirement already satisfied, skipping upgrade: rsa>=3.1.4 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (3.4.2). Requirement already satisfied, skipping upgrade: cachetools>=2.0.0 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (2.1.0). Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (0.2.2). Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /usr/local/lib/python2.7/dist-packages (from rsa>=3.1.4->google-auth>=1.4.1->google-api-python-client) (0.4.4). ========== [2018年 08月 28日 星期二 10:55:17 CST] Stage 'Install TensorFlow pip package' starting. Skipping tf-nightly as it is not installed. Skipping tensorflow as it is not installed. Skipping tf-nightly-gpu as it is not installed. Skipping tensorflow-gpu as it is not installed. Installing Google Cloud Platform optimized CPU-only TensorFlow wheel. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 0 0 0 0 0 0 0 0 --:--:-- 0:02:09 --:--:-- 0curl: (7) Failed to connect to storage.googleapis.com port 443: Connection timed out.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:15520,energy efficiency,CPU,CPU-only,15520,"ping upgrade: httplib2<1dev,>=0.9.2 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.11.3). Requirement already satisfied, skipping upgrade: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (3.0.0). Requirement already satisfied, skipping upgrade: google-auth-httplib2>=0.0.3 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.0.3). Requirement already satisfied, skipping upgrade: six<2dev,>=1.6.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.11.0). Requirement already satisfied, skipping upgrade: google-auth>=1.4.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.5.1). Requirement already satisfied, skipping upgrade: rsa>=3.1.4 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (3.4.2). Requirement already satisfied, skipping upgrade: cachetools>=2.0.0 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (2.1.0). Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (0.2.2). Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /usr/local/lib/python2.7/dist-packages (from rsa>=3.1.4->google-auth>=1.4.1->google-api-python-client) (0.4.4). ========== [2018年 08月 28日 星期二 10:55:17 CST] Stage 'Install TensorFlow pip package' starting. Skipping tf-nightly as it is not installed. Skipping tensorflow as it is not installed. Skipping tf-nightly-gpu as it is not installed. Skipping tensorflow-gpu as it is not installed. Installing Google Cloud Platform optimized CPU-only TensorFlow wheel. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 0 0 0 0 0 0 0 0 --:--:-- 0:02:09 --:--:-- 0curl: (7) Failed to connect to storage.googleapis.com port 443: Connection timed out.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:15603,energy efficiency,Current,Current,15603,"ping upgrade: httplib2<1dev,>=0.9.2 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.11.3). Requirement already satisfied, skipping upgrade: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (3.0.0). Requirement already satisfied, skipping upgrade: google-auth-httplib2>=0.0.3 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.0.3). Requirement already satisfied, skipping upgrade: six<2dev,>=1.6.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.11.0). Requirement already satisfied, skipping upgrade: google-auth>=1.4.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.5.1). Requirement already satisfied, skipping upgrade: rsa>=3.1.4 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (3.4.2). Requirement already satisfied, skipping upgrade: cachetools>=2.0.0 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (2.1.0). Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (0.2.2). Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /usr/local/lib/python2.7/dist-packages (from rsa>=3.1.4->google-auth>=1.4.1->google-api-python-client) (0.4.4). ========== [2018年 08月 28日 星期二 10:55:17 CST] Stage 'Install TensorFlow pip package' starting. Skipping tf-nightly as it is not installed. Skipping tensorflow as it is not installed. Skipping tf-nightly-gpu as it is not installed. Skipping tensorflow-gpu as it is not installed. Installing Google Cloud Platform optimized CPU-only TensorFlow wheel. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 0 0 0 0 0 0 0 0 --:--:-- 0:02:09 --:--:-- 0curl: (7) Failed to connect to storage.googleapis.com port 443: Connection timed out.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:1483,integrability,configur,configured,1483,ase . Hit:4 http://mirrors.aliyun.com/ubuntu xenial-updates InRelease . Get:6 http://mirrors.aliyun.com/ubuntu xenial-backports InRelease [107 kB] . Hit:7 http://mirrors.aliyun.com/ubuntu xenial-security InRelease . Hit:8 http://ppa.launchpad.net/webupd8team/java/ubuntu xenial InRelease . Err:9 http://storage.googleapis.com/bazel-apt stable InRelease . Cannot initiate the connection to storage.googleapis.com:80 (2404:6800:4012:1::2010). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::2010 80]. Err:10 http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease . Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4008:803::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4008:803::200e 80]. Fetched 107 kB in 12min 0s (148 B/s) . Reading package lists... Done. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sou,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:1663,integrability,configur,configured,1663,/ubuntu xenial-security InRelease . Hit:8 http://ppa.launchpad.net/webupd8team/java/ubuntu xenial InRelease . Err:9 http://storage.googleapis.com/bazel-apt stable InRelease . Cannot initiate the connection to storage.googleapis.com:80 (2404:6800:4012:1::2010). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::2010 80]. Err:10 http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease . Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4008:803::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4008:803::200e 80]. Fetched 107 kB in 12min 0s (148 B/s) . Reading package lists... Done. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/ap,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:1842,integrability,configur,configured,1842,ot initiate the connection to storage.googleapis.com:80 (2404:6800:4012:1::2010). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::2010 80]. Err:10 http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease . Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4008:803::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4008:803::200e 80]. Fetched 107 kB in 12min 0s (148 B/s) . Reading package lists... Done. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://storage.googleapis.com/bazel-apt/dists/stable/InRelease Cannot initiate the connection to storage.googleapis.co,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:1982,integrability,Translat,Translations,1982,:1::2010 80]. Err:10 http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease . Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4008:803::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4008:803::200e 80]. Fetched 107 kB in 12min 0s (148 B/s) . Reading package lists... Done. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://storage.googleapis.com/bazel-apt/dists/stable/InRelease Cannot initiate the connection to storage.googleapis.com:80 (2404:6800:4012:1::2010). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::2010 80]. W: Failed to fetch http://packages.cl,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:2006,integrability,Translat,Translation-,2006,p://packages.cloud.google.com/apt cloud-sdk-xenial InRelease . Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4008:803::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4008:803::200e 80]. Fetched 107 kB in 12min 0s (148 B/s) . Reading package lists... Done. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://storage.googleapis.com/bazel-apt/dists/stable/InRelease Cannot initiate the connection to storage.googleapis.com:80 (2404:6800:4012:1::2010). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::2010 80]. W: Failed to fetch http://packages.cloud.google.com/apt/dists,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:2028,integrability,configur,configured,2028,ogle.com/apt cloud-sdk-xenial InRelease . Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4008:803::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4008:803::200e 80]. Fetched 107 kB in 12min 0s (148 B/s) . Reading package lists... Done. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://storage.googleapis.com/bazel-apt/dists/stable/InRelease Cannot initiate the connection to storage.googleapis.com:80 (2404:6800:4012:1::2010). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::2010 80]. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InR,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:2168,integrability,Translat,Translations,2168,t (101: Network is unreachable) [IP: 2404:6800:4008:803::200e 80]. Fetched 107 kB in 12min 0s (148 B/s) . Reading package lists... Done. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://storage.googleapis.com/bazel-apt/dists/stable/InRelease Cannot initiate the connection to storage.googleapis.com:80 (2404:6800:4012:1::2010). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::2010 80]. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4008:803::200e). - connect (101: Network is unreachable) [IP,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:2192,integrability,Translat,Translation-en,2192,hable) [IP: 2404:6800:4008:803::200e 80]. Fetched 107 kB in 12min 0s (148 B/s) . Reading package lists... Done. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://storage.googleapis.com/bazel-apt/dists/stable/InRelease Cannot initiate the connection to storage.googleapis.com:80 (2404:6800:4012:1::2010). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::2010 80]. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4008:803::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4008:803::200,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:2211,integrability,configur,configured,2211,6800:4008:803::200e 80]. Fetched 107 kB in 12min 0s (148 B/s) . Reading package lists... Done. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://storage.googleapis.com/bazel-apt/dists/stable/InRelease Cannot initiate the connection to storage.googleapis.com:80 (2404:6800:4012:1::2010). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::2010 80]. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4008:803::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4008:803::200e 80]. W: Some in,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:2370,integrability,Compon,Components-,2370,"urces.list.d/' as it has an invalid filename extension. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://storage.googleapis.com/bazel-apt/dists/stable/InRelease Cannot initiate the connection to storage.googleapis.com:80 (2404:6800:4012:1::2010). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::2010 80]. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4008:803::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4008:803::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:2395,integrability,configur,configured,2395," an invalid filename extension. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://storage.googleapis.com/bazel-apt/dists/stable/InRelease Cannot initiate the connection to storage.googleapis.com:80 (2404:6800:4012:1::2010). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::2010 80]. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4008:803::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4008:803::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:2580,integrability,configur,configured,2580,".d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://storage.googleapis.com/bazel-apt/dists/stable/InRelease Cannot initiate the connection to storage.googleapis.com:80 (2404:6800:4012:1::2010). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::2010 80]. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4008:803::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4008:803::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/googl",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:3347,integrability,configur,configured,3347,"EP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://storage.googleapis.com/bazel-apt/dists/stable/InRelease Cannot initiate the connection to storage.googleapis.com:80 (2404:6800:4012:1::2010). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::2010 80]. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4008:803::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4008:803::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sou",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:3527,integrability,configur,configured,3527,"et DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://storage.googleapis.com/bazel-apt/dists/stable/InRelease Cannot initiate the connection to storage.googleapis.com:80 (2404:6800:4012:1::2010). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::2010 80]. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4008:803::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4008:803::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/ap",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:3706,integrability,configur,configured,3706,": Failed to fetch http://storage.googleapis.com/bazel-apt/dists/stable/InRelease Cannot initiate the connection to storage.googleapis.com:80 (2404:6800:4012:1::2010). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::2010 80]. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4008:803::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4008:803::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. Reading package lists... Done. Building dependency tree . Reading state information... Done. sudo is already the newest version (1.8.16-0",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:3846,integrability,Translat,Translations,3846,"(2404:6800:4012:1::2010). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::2010 80]. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4008:803::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4008:803::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. Reading package lists... Done. Building dependency tree . Reading state information... Done. sudo is already the newest version (1.8.16-0ubuntu1.5). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:3870,integrability,Translat,Translation-,3870,". - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::2010 80]. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4008:803::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4008:803::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. Reading package lists... Done. Building dependency tree . Reading state information... Done. sudo is already the newest version (1.8.16-0ubuntu1.5). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linu",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:3892,integrability,configur,configured,3892,"work is unreachable) [IP: 2404:6800:4012:1::2010 80]. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4008:803::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4008:803::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. Reading package lists... Done. Building dependency tree . Reading state information... Done. sudo is already the newest version (1.8.16-0ubuntu1.5). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-gen",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:4032,integrability,Translat,Translations,4032,"e Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4008:803::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4008:803::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. Reading package lists... Done. Building dependency tree . Reading state information... Done. sudo is already the newest version (1.8.16-0ubuntu1.5). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgr",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:4056,integrability,Translat,Translation-en,4056,"nection to packages.cloud.google.com:80 (2404:6800:4008:803::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4008:803::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. Reading package lists... Done. Building dependency tree . Reading state information... Done. sudo is already the newest version (1.8.16-0ubuntu1.5). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'g",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:4075,integrability,configur,configured,4075,"es.cloud.google.com:80 (2404:6800:4008:803::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4008:803::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. Reading package lists... Done. Building dependency tree . Reading state information... Done. sudo is already the newest version (1.8.16-0ubuntu1.5). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:4234,integrability,Compon,Components-,4234,"load. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. Reading package lists... Done. Building dependency tree . Reading state information... Done. sudo is already the newest version (1.8.16-0ubuntu1.5). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:43:08 CST] Stage 'Update package list' sta",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:4259,integrability,configur,configured,4259,"ored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. Reading package lists... Done. Building dependency tree . Reading state information... Done. sudo is already the newest version (1.8.16-0ubuntu1.5). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:43:08 CST] Stage 'Update package list' starting. W: Target Package",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:4444,integrability,configur,configured,4444,".d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. Reading package lists... Done. Building dependency tree . Reading state information... Done. sudo is already the newest version (1.8.16-0ubuntu1.5). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:43:08 CST] Stage 'Update package list' starting. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (m",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:4614,integrability,depend,dependency,4614,"urces.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. Reading package lists... Done. Building dependency tree . Reading state information... Done. sudo is already the newest version (1.8.16-0ubuntu1.5). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:43:08 CST] Stage 'Update package list' starting. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target P",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:4640,integrability,state,state,4640,"d-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. Reading package lists... Done. Building dependency tree . Reading state information... Done. sudo is already the newest version (1.8.16-0ubuntu1.5). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:43:08 CST] Stage 'Update package list' starting. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:4694,integrability,version,version,4694,"ges) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. Reading package lists... Done. Building dependency tree . Reading state information... Done. sudo is already the newest version (1.8.16-0ubuntu1.5). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:43:08 CST] Stage 'Update package list' starting. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sou",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:5298,integrability,configur,configured,5298,"s.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. Reading package lists... Done. Building dependency tree . Reading state information... Done. sudo is already the newest version (1.8.16-0ubuntu1.5). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:43:08 CST] Stage 'Update package list' starting. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sou",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:5478,integrability,configur,configured,5478,"ources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. Reading package lists... Done. Building dependency tree . Reading state information... Done. sudo is already the newest version (1.8.16-0ubuntu1.5). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:43:08 CST] Stage 'Update package list' starting. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/ap",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:5657,integrability,configur,configured,5657,"one. sudo is already the newest version (1.8.16-0ubuntu1.5). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:43:08 CST] Stage 'Update package list' starting. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:5797,integrability,Translat,Translations,5797," libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:43:08 CST] Stage 'Update package list' starting. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4012:1::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::200e 80]. W: Some index files failed ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:5821,integrability,Translat,Translation-,5821,"s-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:43:08 CST] Stage 'Update package list' starting. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4012:1::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::200e 80]. W: Some index files failed to download. They have b",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:5843,integrability,configur,configured,5843,"ders-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:43:08 CST] Stage 'Update package list' starting. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4012:1::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::200e 80]. W: Some index files failed to download. They have been ignored, or old o",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:5983,integrability,Translat,Translations,5983,"ed, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:43:08 CST] Stage 'Update package list' starting. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4012:1::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.li",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:6007,integrability,Translat,Translation-en,6007,"to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:43:08 CST] Stage 'Update package list' starting. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4012:1::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:6026,integrability,configur,configured,6026,"ot upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:43:08 CST] Stage 'Update package list' starting. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4012:1::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cl",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:6185,integrability,Compon,Components-,6185,"星期二 10:43:08 CST] Stage 'Update package list' starting. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4012:1::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sour",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:6210,integrability,configur,configured,6210,"'Update package list' starting. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4012:1::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:6395,integrability,configur,configured,6395,".d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4012:1::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.li",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:6917,integrability,configur,configured,6917,"d /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4012:1::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sou",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:7097,integrability,configur,configured,7097," and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4012:1::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/ap",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:7276,integrability,configur,configured,7276,"ist:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4012:1::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install development packages' starting. Reading package lists... Done. Building depend",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:7416,integrability,Translat,Translations,7416,"n /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4012:1::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install development packages' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. pkg-config is already the newest version (0.29.1-0ubuntu1). unzip is already the newest versio",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:7440,integrability,Translat,Translation-,7440,"d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4012:1::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install development packages' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. pkg-config is already the newest version (0.29.1-0ubuntu1). unzip is already the newest version (6.0-20ubuntu1). zip i",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:7462,integrability,configur,configured,7462,"st:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4012:1::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install development packages' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. pkg-config is already the newest version (0.29.1-0ubuntu1). unzip is already the newest version (6.0-20ubuntu1). zip is already the newest ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:7602,integrability,Translat,Translations,7602,"lease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4012:1::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install development packages' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. pkg-config is already the newest version (0.29.1-0ubuntu1). unzip is already the newest version (6.0-20ubuntu1). zip is already the newest version (3.0-11). curl is already the newest version (7.47.0-1ubuntu2.8). zlib1g-dev is already the newest version (1:1.2.8.dfsg-2ubuntu4.1).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:7626,integrability,Translat,Translation-en,7626," connection to packages.cloud.google.com:80 (2404:6800:4012:1::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install development packages' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. pkg-config is already the newest version (0.29.1-0ubuntu1). unzip is already the newest version (6.0-20ubuntu1). zip is already the newest version (3.0-11). curl is already the newest version (7.47.0-1ubuntu2.8). zlib1g-dev is already the newest version (1:1.2.8.dfsg-2ubuntu4.1). The following packages w",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:7645,integrability,configur,configured,7645,"ckages.cloud.google.com:80 (2404:6800:4012:1::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install development packages' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. pkg-config is already the newest version (0.29.1-0ubuntu1). unzip is already the newest version (6.0-20ubuntu1). zip is already the newest version (3.0-11). curl is already the newest version (7.47.0-1ubuntu2.8). zlib1g-dev is already the newest version (1:1.2.8.dfsg-2ubuntu4.1). The following packages were automatically",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:7804,integrability,Compon,Components-,7804,"load. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install development packages' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. pkg-config is already the newest version (0.29.1-0ubuntu1). unzip is already the newest version (6.0-20ubuntu1). zip is already the newest version (3.0-11). curl is already the newest version (7.47.0-1ubuntu2.8). zlib1g-dev is already the newest version (1:1.2.8.dfsg-2ubuntu4.1). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:7829,integrability,configur,configured,7829,"ored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install development packages' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. pkg-config is already the newest version (0.29.1-0ubuntu1). unzip is already the newest version (6.0-20ubuntu1). zip is already the newest version (3.0-11). curl is already the newest version (7.47.0-1ubuntu2.8). zlib1g-dev is already the newest version (1:1.2.8.dfsg-2ubuntu4.1). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:8014,integrability,configur,configured,8014,".d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install development packages' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. pkg-config is already the newest version (0.29.1-0ubuntu1). unzip is already the newest version (6.0-20ubuntu1). zip is already the newest version (3.0-11). curl is already the newest version (7.47.0-1ubuntu2.8). zlib1g-dev is already the newest version (1:1.2.8.dfsg-2ubuntu4.1). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:8275,integrability,depend,dependency,8275,"igured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install development packages' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. pkg-config is already the newest version (0.29.1-0ubuntu1). unzip is already the newest version (6.0-20ubuntu1). zip is already the newest version (3.0-11). curl is already the newest version (7.47.0-1ubuntu2.8). zlib1g-dev is already the newest version (1:1.2.8.dfsg-2ubuntu4.1). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install python packaging infrastructure' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. python-wheel is already the newest",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:8301,integrability,state,state,8301," /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install development packages' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. pkg-config is already the newest version (0.29.1-0ubuntu1). unzip is already the newest version (6.0-20ubuntu1). zip is already the newest version (3.0-11). curl is already the newest version (7.47.0-1ubuntu2.8). zlib1g-dev is already the newest version (1:1.2.8.dfsg-2ubuntu4.1). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install python packaging infrastructure' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. python-wheel is already the newest version (0.29.0-1). pyt",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:8361,integrability,version,version,8361,"/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install development packages' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. pkg-config is already the newest version (0.29.1-0ubuntu1). unzip is already the newest version (6.0-20ubuntu1). zip is already the newest version (3.0-11). curl is already the newest version (7.47.0-1ubuntu2.8). zlib1g-dev is already the newest version (1:1.2.8.dfsg-2ubuntu4.1). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install python packaging infrastructure' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. python-wheel is already the newest version (0.29.0-1). python-dev is already the newest version (2.7.12-1~16.04). pytho",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:8416,integrability,version,version,8416,"slations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install development packages' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. pkg-config is already the newest version (0.29.1-0ubuntu1). unzip is already the newest version (6.0-20ubuntu1). zip is already the newest version (3.0-11). curl is already the newest version (7.47.0-1ubuntu2.8). zlib1g-dev is already the newest version (1:1.2.8.dfsg-2ubuntu4.1). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install python packaging infrastructure' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. python-wheel is already the newest version (0.29.0-1). python-dev is already the newest version (2.7.12-1~16.04). python-pip is already the newest version (8.1.1-2ubuntu0.4).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:8467,integrability,version,version,8467,"d multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install development packages' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. pkg-config is already the newest version (0.29.1-0ubuntu1). unzip is already the newest version (6.0-20ubuntu1). zip is already the newest version (3.0-11). curl is already the newest version (7.47.0-1ubuntu2.8). zlib1g-dev is already the newest version (1:1.2.8.dfsg-2ubuntu4.1). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install python packaging infrastructure' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. python-wheel is already the newest version (0.29.0-1). python-dev is already the newest version (2.7.12-1~16.04). python-pip is already the newest version (8.1.1-2ubuntu0.4). The following packages were automatically installe",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:8512,integrability,version,version,8512,"oogle-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install development packages' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. pkg-config is already the newest version (0.29.1-0ubuntu1). unzip is already the newest version (6.0-20ubuntu1). zip is already the newest version (3.0-11). curl is already the newest version (7.47.0-1ubuntu2.8). zlib1g-dev is already the newest version (1:1.2.8.dfsg-2ubuntu4.1). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install python packaging infrastructure' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. python-wheel is already the newest version (0.29.0-1). python-dev is already the newest version (2.7.12-1~16.04). python-pip is already the newest version (8.1.1-2ubuntu0.4). The following packages were automatically installed and are no longer required:. libllvm5.0 lin",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:8574,integrability,version,version,8574,"d-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install development packages' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. pkg-config is already the newest version (0.29.1-0ubuntu1). unzip is already the newest version (6.0-20ubuntu1). zip is already the newest version (3.0-11). curl is already the newest version (7.47.0-1ubuntu2.8). zlib1g-dev is already the newest version (1:1.2.8.dfsg-2ubuntu4.1). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install python packaging infrastructure' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. python-wheel is already the newest version (0.29.0-1). python-dev is already the newest version (2.7.12-1~16.04). python-pip is already the newest version (8.1.1-2ubuntu0.4). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-im",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:9193,integrability,depend,dependency,9193,"tall development packages' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. pkg-config is already the newest version (0.29.1-0ubuntu1). unzip is already the newest version (6.0-20ubuntu1). zip is already the newest version (3.0-11). curl is already the newest version (7.47.0-1ubuntu2.8). zlib1g-dev is already the newest version (1:1.2.8.dfsg-2ubuntu4.1). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install python packaging infrastructure' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. python-wheel is already the newest version (0.29.0-1). python-dev is already the newest version (2.7.12-1~16.04). python-pip is already the newest version (8.1.1-2ubuntu0.4). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. Requirement already up-to-date: pip in /usr/local/lib/python2.7/dist-packages (18.0). ========== [2018年 08月 28日 星期二 10:55:12 CST] Stage 'Install python packages' starting. Requirement already satisfied: contextlib2 in /usr/local/lib/python2.7/dist-packages (0.5.5). Requirement already satisfied: enum34 in /usr/local/lib/python2.7/dis",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:9219,integrability,state,state,9219,"s' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. pkg-config is already the newest version (0.29.1-0ubuntu1). unzip is already the newest version (6.0-20ubuntu1). zip is already the newest version (3.0-11). curl is already the newest version (7.47.0-1ubuntu2.8). zlib1g-dev is already the newest version (1:1.2.8.dfsg-2ubuntu4.1). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install python packaging infrastructure' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. python-wheel is already the newest version (0.29.0-1). python-dev is already the newest version (2.7.12-1~16.04). python-pip is already the newest version (8.1.1-2ubuntu0.4). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. Requirement already up-to-date: pip in /usr/local/lib/python2.7/dist-packages (18.0). ========== [2018年 08月 28日 星期二 10:55:12 CST] Stage 'Install python packages' starting. Requirement already satisfied: contextlib2 in /usr/local/lib/python2.7/dist-packages (0.5.5). Requirement already satisfied: enum34 in /usr/local/lib/python2.7/dist-packages (1.1.6). Requ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:9281,integrability,version,version,9281," tree . Reading state information... Done. pkg-config is already the newest version (0.29.1-0ubuntu1). unzip is already the newest version (6.0-20ubuntu1). zip is already the newest version (3.0-11). curl is already the newest version (7.47.0-1ubuntu2.8). zlib1g-dev is already the newest version (1:1.2.8.dfsg-2ubuntu4.1). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install python packaging infrastructure' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. python-wheel is already the newest version (0.29.0-1). python-dev is already the newest version (2.7.12-1~16.04). python-pip is already the newest version (8.1.1-2ubuntu0.4). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. Requirement already up-to-date: pip in /usr/local/lib/python2.7/dist-packages (18.0). ========== [2018年 08月 28日 星期二 10:55:12 CST] Stage 'Install python packages' starting. Requirement already satisfied: contextlib2 in /usr/local/lib/python2.7/dist-packages (0.5.5). Requirement already satisfied: enum34 in /usr/local/lib/python2.7/dist-packages (1.1.6). Requirement already satisfied: sortedcontainers==1.5.3 in /usr/loca",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:9334,integrability,version,version,9334," is already the newest version (0.29.1-0ubuntu1). unzip is already the newest version (6.0-20ubuntu1). zip is already the newest version (3.0-11). curl is already the newest version (7.47.0-1ubuntu2.8). zlib1g-dev is already the newest version (1:1.2.8.dfsg-2ubuntu4.1). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install python packaging infrastructure' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. python-wheel is already the newest version (0.29.0-1). python-dev is already the newest version (2.7.12-1~16.04). python-pip is already the newest version (8.1.1-2ubuntu0.4). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. Requirement already up-to-date: pip in /usr/local/lib/python2.7/dist-packages (18.0). ========== [2018年 08月 28日 星期二 10:55:12 CST] Stage 'Install python packages' starting. Requirement already satisfied: contextlib2 in /usr/local/lib/python2.7/dist-packages (0.5.5). Requirement already satisfied: enum34 in /usr/local/lib/python2.7/dist-packages (1.1.6). Requirement already satisfied: sortedcontainers==1.5.3 in /usr/local/lib/python2.7/dist-packages (1.5.3). Requirement al",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:9393,integrability,version,version,9393,"already the newest version (6.0-20ubuntu1). zip is already the newest version (3.0-11). curl is already the newest version (7.47.0-1ubuntu2.8). zlib1g-dev is already the newest version (1:1.2.8.dfsg-2ubuntu4.1). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install python packaging infrastructure' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. python-wheel is already the newest version (0.29.0-1). python-dev is already the newest version (2.7.12-1~16.04). python-pip is already the newest version (8.1.1-2ubuntu0.4). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. Requirement already up-to-date: pip in /usr/local/lib/python2.7/dist-packages (18.0). ========== [2018年 08月 28日 星期二 10:55:12 CST] Stage 'Install python packages' starting. Requirement already satisfied: contextlib2 in /usr/local/lib/python2.7/dist-packages (0.5.5). Requirement already satisfied: enum34 in /usr/local/lib/python2.7/dist-packages (1.1.6). Requirement already satisfied: sortedcontainers==1.5.3 in /usr/local/lib/python2.7/dist-packages (1.5.3). Requirement already satisfied: intervaltree in /usr/local/lib/python2.7/d",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:13673,integrability,api,api-python-client,13673,"st-packages (1.7). Requirement already satisfied: six in /usr/local/lib/python2.7/dist-packages (1.11.0). Requirement already satisfied: sklearn in /usr/local/lib/python2.7/dist-packages (0.0). Requirement already satisfied: scikit-learn in /usr/local/lib/python2.7/dist-packages (from sklearn) (0.19.2). Requirement already satisfied: pandas in /usr/local/lib/python2.7/dist-packages (0.23.4). Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python2.7/dist-packages (from pandas) (1.14.0). Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python2.7/dist-packages (from pandas) (2.7.3). Requirement already satisfied: pytz>=2011k in /usr/local/lib/python2.7/dist-packages (from pandas) (2018.5). Requirement already satisfied: six>=1.5 in /usr/local/lib/python2.7/dist-packages (from python-dateutil>=2.5.0->pandas) (1.11.0). Requirement already satisfied: psutil in /usr/local/lib/python2.7/dist-packages (5.4.7). Requirement already up-to-date: google-api-python-client in /usr/local/lib/python2.7/dist-packages (1.7.4). Requirement already satisfied, skipping upgrade: httplib2<1dev,>=0.9.2 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.11.3). Requirement already satisfied, skipping upgrade: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (3.0.0). Requirement already satisfied, skipping upgrade: google-auth-httplib2>=0.0.3 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.0.3). Requirement already satisfied, skipping upgrade: six<2dev,>=1.6.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.11.0). Requirement already satisfied, skipping upgrade: google-auth>=1.4.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.5.1). Requirement already satisfied, skipping upgrade: rsa>=3.1.4 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (3.4.2). Requ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:13868,integrability,api,api-python-client,13868,"equirement already satisfied: scikit-learn in /usr/local/lib/python2.7/dist-packages (from sklearn) (0.19.2). Requirement already satisfied: pandas in /usr/local/lib/python2.7/dist-packages (0.23.4). Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python2.7/dist-packages (from pandas) (1.14.0). Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python2.7/dist-packages (from pandas) (2.7.3). Requirement already satisfied: pytz>=2011k in /usr/local/lib/python2.7/dist-packages (from pandas) (2018.5). Requirement already satisfied: six>=1.5 in /usr/local/lib/python2.7/dist-packages (from python-dateutil>=2.5.0->pandas) (1.11.0). Requirement already satisfied: psutil in /usr/local/lib/python2.7/dist-packages (5.4.7). Requirement already up-to-date: google-api-python-client in /usr/local/lib/python2.7/dist-packages (1.7.4). Requirement already satisfied, skipping upgrade: httplib2<1dev,>=0.9.2 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.11.3). Requirement already satisfied, skipping upgrade: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (3.0.0). Requirement already satisfied, skipping upgrade: google-auth-httplib2>=0.0.3 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.0.3). Requirement already satisfied, skipping upgrade: six<2dev,>=1.6.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.11.0). Requirement already satisfied, skipping upgrade: google-auth>=1.4.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.5.1). Requirement already satisfied, skipping upgrade: rsa>=3.1.4 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (3.4.2). Requirement already satisfied, skipping upgrade: cachetools>=2.0.0 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (2.1.0). Requirement already satisfied",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:14026,integrability,api,api-python-client,14026,"cal/lib/python2.7/dist-packages (0.23.4). Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python2.7/dist-packages (from pandas) (1.14.0). Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python2.7/dist-packages (from pandas) (2.7.3). Requirement already satisfied: pytz>=2011k in /usr/local/lib/python2.7/dist-packages (from pandas) (2018.5). Requirement already satisfied: six>=1.5 in /usr/local/lib/python2.7/dist-packages (from python-dateutil>=2.5.0->pandas) (1.11.0). Requirement already satisfied: psutil in /usr/local/lib/python2.7/dist-packages (5.4.7). Requirement already up-to-date: google-api-python-client in /usr/local/lib/python2.7/dist-packages (1.7.4). Requirement already satisfied, skipping upgrade: httplib2<1dev,>=0.9.2 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.11.3). Requirement already satisfied, skipping upgrade: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (3.0.0). Requirement already satisfied, skipping upgrade: google-auth-httplib2>=0.0.3 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.0.3). Requirement already satisfied, skipping upgrade: six<2dev,>=1.6.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.11.0). Requirement already satisfied, skipping upgrade: google-auth>=1.4.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.5.1). Requirement already satisfied, skipping upgrade: rsa>=3.1.4 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (3.4.2). Requirement already satisfied, skipping upgrade: cachetools>=2.0.0 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (2.1.0). Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (0.2.2). Requirement a",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:14186,integrability,api,api-python-client,14186,"ent already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python2.7/dist-packages (from pandas) (2.7.3). Requirement already satisfied: pytz>=2011k in /usr/local/lib/python2.7/dist-packages (from pandas) (2018.5). Requirement already satisfied: six>=1.5 in /usr/local/lib/python2.7/dist-packages (from python-dateutil>=2.5.0->pandas) (1.11.0). Requirement already satisfied: psutil in /usr/local/lib/python2.7/dist-packages (5.4.7). Requirement already up-to-date: google-api-python-client in /usr/local/lib/python2.7/dist-packages (1.7.4). Requirement already satisfied, skipping upgrade: httplib2<1dev,>=0.9.2 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.11.3). Requirement already satisfied, skipping upgrade: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (3.0.0). Requirement already satisfied, skipping upgrade: google-auth-httplib2>=0.0.3 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.0.3). Requirement already satisfied, skipping upgrade: six<2dev,>=1.6.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.11.0). Requirement already satisfied, skipping upgrade: google-auth>=1.4.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.5.1). Requirement already satisfied, skipping upgrade: rsa>=3.1.4 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (3.4.2). Requirement already satisfied, skipping upgrade: cachetools>=2.0.0 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (2.1.0). Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (0.2.2). Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /usr/local/lib/python2.7/dist-packages (from rsa>=3.1.4->google-auth>=1.4.1->google-api-python-client) (0.4",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:14335,integrability,api,api-python-client,14335,"011k in /usr/local/lib/python2.7/dist-packages (from pandas) (2018.5). Requirement already satisfied: six>=1.5 in /usr/local/lib/python2.7/dist-packages (from python-dateutil>=2.5.0->pandas) (1.11.0). Requirement already satisfied: psutil in /usr/local/lib/python2.7/dist-packages (5.4.7). Requirement already up-to-date: google-api-python-client in /usr/local/lib/python2.7/dist-packages (1.7.4). Requirement already satisfied, skipping upgrade: httplib2<1dev,>=0.9.2 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.11.3). Requirement already satisfied, skipping upgrade: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (3.0.0). Requirement already satisfied, skipping upgrade: google-auth-httplib2>=0.0.3 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.0.3). Requirement already satisfied, skipping upgrade: six<2dev,>=1.6.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.11.0). Requirement already satisfied, skipping upgrade: google-auth>=1.4.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.5.1). Requirement already satisfied, skipping upgrade: rsa>=3.1.4 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (3.4.2). Requirement already satisfied, skipping upgrade: cachetools>=2.0.0 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (2.1.0). Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (0.2.2). Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /usr/local/lib/python2.7/dist-packages (from rsa>=3.1.4->google-auth>=1.4.1->google-api-python-client) (0.4.4). ========== [2018年 08月 28日 星期二 10:55:17 CST] Stage 'Install TensorFlow pip package' starting. Skipping tf-nightly as it is not installed. Skippin",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:14487,integrability,api,api-python-client,14487," (from python-dateutil>=2.5.0->pandas) (1.11.0). Requirement already satisfied: psutil in /usr/local/lib/python2.7/dist-packages (5.4.7). Requirement already up-to-date: google-api-python-client in /usr/local/lib/python2.7/dist-packages (1.7.4). Requirement already satisfied, skipping upgrade: httplib2<1dev,>=0.9.2 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.11.3). Requirement already satisfied, skipping upgrade: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (3.0.0). Requirement already satisfied, skipping upgrade: google-auth-httplib2>=0.0.3 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.0.3). Requirement already satisfied, skipping upgrade: six<2dev,>=1.6.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.11.0). Requirement already satisfied, skipping upgrade: google-auth>=1.4.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.5.1). Requirement already satisfied, skipping upgrade: rsa>=3.1.4 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (3.4.2). Requirement already satisfied, skipping upgrade: cachetools>=2.0.0 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (2.1.0). Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (0.2.2). Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /usr/local/lib/python2.7/dist-packages (from rsa>=3.1.4->google-auth>=1.4.1->google-api-python-client) (0.4.4). ========== [2018年 08月 28日 星期二 10:55:17 CST] Stage 'Install TensorFlow pip package' starting. Skipping tf-nightly as it is not installed. Skipping tensorflow as it is not installed. Skipping tf-nightly-gpu as it is not installed. Skipping tensorflow-gpu as it is not installed. Installing Google C",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:14650,integrability,api,api-python-client,14650,"-date: google-api-python-client in /usr/local/lib/python2.7/dist-packages (1.7.4). Requirement already satisfied, skipping upgrade: httplib2<1dev,>=0.9.2 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.11.3). Requirement already satisfied, skipping upgrade: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (3.0.0). Requirement already satisfied, skipping upgrade: google-auth-httplib2>=0.0.3 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.0.3). Requirement already satisfied, skipping upgrade: six<2dev,>=1.6.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.11.0). Requirement already satisfied, skipping upgrade: google-auth>=1.4.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.5.1). Requirement already satisfied, skipping upgrade: rsa>=3.1.4 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (3.4.2). Requirement already satisfied, skipping upgrade: cachetools>=2.0.0 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (2.1.0). Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (0.2.2). Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /usr/local/lib/python2.7/dist-packages (from rsa>=3.1.4->google-auth>=1.4.1->google-api-python-client) (0.4.4). ========== [2018年 08月 28日 星期二 10:55:17 CST] Stage 'Install TensorFlow pip package' starting. Skipping tf-nightly as it is not installed. Skipping tensorflow as it is not installed. Skipping tf-nightly-gpu as it is not installed. Skipping tensorflow-gpu as it is not installed. Installing Google Cloud Platform optimized CPU-only TensorFlow wheel. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 0 0 0 0 0 ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:14820,integrability,api,api-python-client,14820,"ping upgrade: httplib2<1dev,>=0.9.2 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.11.3). Requirement already satisfied, skipping upgrade: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (3.0.0). Requirement already satisfied, skipping upgrade: google-auth-httplib2>=0.0.3 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.0.3). Requirement already satisfied, skipping upgrade: six<2dev,>=1.6.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.11.0). Requirement already satisfied, skipping upgrade: google-auth>=1.4.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.5.1). Requirement already satisfied, skipping upgrade: rsa>=3.1.4 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (3.4.2). Requirement already satisfied, skipping upgrade: cachetools>=2.0.0 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (2.1.0). Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (0.2.2). Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /usr/local/lib/python2.7/dist-packages (from rsa>=3.1.4->google-auth>=1.4.1->google-api-python-client) (0.4.4). ========== [2018年 08月 28日 星期二 10:55:17 CST] Stage 'Install TensorFlow pip package' starting. Skipping tf-nightly as it is not installed. Skipping tensorflow as it is not installed. Skipping tf-nightly-gpu as it is not installed. Skipping tensorflow-gpu as it is not installed. Installing Google Cloud Platform optimized CPU-only TensorFlow wheel. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 0 0 0 0 0 0 0 0 --:--:-- 0:02:09 --:--:-- 0curl: (7) Failed to connect to storage.googleapis.com port 443: Connection timed out.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:14994,integrability,api,api-python-client,14994,"ping upgrade: httplib2<1dev,>=0.9.2 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.11.3). Requirement already satisfied, skipping upgrade: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (3.0.0). Requirement already satisfied, skipping upgrade: google-auth-httplib2>=0.0.3 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.0.3). Requirement already satisfied, skipping upgrade: six<2dev,>=1.6.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.11.0). Requirement already satisfied, skipping upgrade: google-auth>=1.4.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.5.1). Requirement already satisfied, skipping upgrade: rsa>=3.1.4 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (3.4.2). Requirement already satisfied, skipping upgrade: cachetools>=2.0.0 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (2.1.0). Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (0.2.2). Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /usr/local/lib/python2.7/dist-packages (from rsa>=3.1.4->google-auth>=1.4.1->google-api-python-client) (0.4.4). ========== [2018年 08月 28日 星期二 10:55:17 CST] Stage 'Install TensorFlow pip package' starting. Skipping tf-nightly as it is not installed. Skipping tensorflow as it is not installed. Skipping tf-nightly-gpu as it is not installed. Skipping tensorflow-gpu as it is not installed. Installing Google Cloud Platform optimized CPU-only TensorFlow wheel. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 0 0 0 0 0 0 0 0 --:--:-- 0:02:09 --:--:-- 0curl: (7) Failed to connect to storage.googleapis.com port 443: Connection timed out.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:15172,integrability,api,api-python-client,15172,"ping upgrade: httplib2<1dev,>=0.9.2 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.11.3). Requirement already satisfied, skipping upgrade: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (3.0.0). Requirement already satisfied, skipping upgrade: google-auth-httplib2>=0.0.3 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.0.3). Requirement already satisfied, skipping upgrade: six<2dev,>=1.6.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.11.0). Requirement already satisfied, skipping upgrade: google-auth>=1.4.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.5.1). Requirement already satisfied, skipping upgrade: rsa>=3.1.4 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (3.4.2). Requirement already satisfied, skipping upgrade: cachetools>=2.0.0 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (2.1.0). Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (0.2.2). Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /usr/local/lib/python2.7/dist-packages (from rsa>=3.1.4->google-auth>=1.4.1->google-api-python-client) (0.4.4). ========== [2018年 08月 28日 星期二 10:55:17 CST] Stage 'Install TensorFlow pip package' starting. Skipping tf-nightly as it is not installed. Skipping tensorflow as it is not installed. Skipping tf-nightly-gpu as it is not installed. Skipping tensorflow-gpu as it is not installed. Installing Google Cloud Platform optimized CPU-only TensorFlow wheel. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 0 0 0 0 0 0 0 0 --:--:-- 0:02:09 --:--:-- 0curl: (7) Failed to connect to storage.googleapis.com port 443: Connection timed out.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:1982,interoperability,Translat,Translations,1982,:1::2010 80]. Err:10 http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease . Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4008:803::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4008:803::200e 80]. Fetched 107 kB in 12min 0s (148 B/s) . Reading package lists... Done. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://storage.googleapis.com/bazel-apt/dists/stable/InRelease Cannot initiate the connection to storage.googleapis.com:80 (2404:6800:4012:1::2010). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::2010 80]. W: Failed to fetch http://packages.cl,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:2006,interoperability,Translat,Translation-,2006,p://packages.cloud.google.com/apt cloud-sdk-xenial InRelease . Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4008:803::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4008:803::200e 80]. Fetched 107 kB in 12min 0s (148 B/s) . Reading package lists... Done. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://storage.googleapis.com/bazel-apt/dists/stable/InRelease Cannot initiate the connection to storage.googleapis.com:80 (2404:6800:4012:1::2010). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::2010 80]. W: Failed to fetch http://packages.cloud.google.com/apt/dists,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:2168,interoperability,Translat,Translations,2168,t (101: Network is unreachable) [IP: 2404:6800:4008:803::200e 80]. Fetched 107 kB in 12min 0s (148 B/s) . Reading package lists... Done. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://storage.googleapis.com/bazel-apt/dists/stable/InRelease Cannot initiate the connection to storage.googleapis.com:80 (2404:6800:4012:1::2010). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::2010 80]. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4008:803::200e). - connect (101: Network is unreachable) [IP,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:2192,interoperability,Translat,Translation-en,2192,hable) [IP: 2404:6800:4008:803::200e 80]. Fetched 107 kB in 12min 0s (148 B/s) . Reading package lists... Done. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://storage.googleapis.com/bazel-apt/dists/stable/InRelease Cannot initiate the connection to storage.googleapis.com:80 (2404:6800:4012:1::2010). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::2010 80]. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4008:803::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4008:803::200,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:2370,interoperability,Compon,Components-,2370,"urces.list.d/' as it has an invalid filename extension. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://storage.googleapis.com/bazel-apt/dists/stable/InRelease Cannot initiate the connection to storage.googleapis.com:80 (2404:6800:4012:1::2010). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::2010 80]. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4008:803::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4008:803::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:3846,interoperability,Translat,Translations,3846,"(2404:6800:4012:1::2010). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::2010 80]. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4008:803::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4008:803::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. Reading package lists... Done. Building dependency tree . Reading state information... Done. sudo is already the newest version (1.8.16-0ubuntu1.5). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:3870,interoperability,Translat,Translation-,3870,". - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::2010 80]. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4008:803::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4008:803::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. Reading package lists... Done. Building dependency tree . Reading state information... Done. sudo is already the newest version (1.8.16-0ubuntu1.5). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linu",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:4032,interoperability,Translat,Translations,4032,"e Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4008:803::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4008:803::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. Reading package lists... Done. Building dependency tree . Reading state information... Done. sudo is already the newest version (1.8.16-0ubuntu1.5). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgr",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:4056,interoperability,Translat,Translation-en,4056,"nection to packages.cloud.google.com:80 (2404:6800:4008:803::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4008:803::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. Reading package lists... Done. Building dependency tree . Reading state information... Done. sudo is already the newest version (1.8.16-0ubuntu1.5). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'g",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:4234,interoperability,Compon,Components-,4234,"load. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. Reading package lists... Done. Building dependency tree . Reading state information... Done. sudo is already the newest version (1.8.16-0ubuntu1.5). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:43:08 CST] Stage 'Update package list' sta",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:5797,interoperability,Translat,Translations,5797," libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:43:08 CST] Stage 'Update package list' starting. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4012:1::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::200e 80]. W: Some index files failed ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:5821,interoperability,Translat,Translation-,5821,"s-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:43:08 CST] Stage 'Update package list' starting. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4012:1::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::200e 80]. W: Some index files failed to download. They have b",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:5983,interoperability,Translat,Translations,5983,"ed, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:43:08 CST] Stage 'Update package list' starting. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4012:1::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.li",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:6007,interoperability,Translat,Translation-en,6007,"to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:43:08 CST] Stage 'Update package list' starting. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4012:1::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:6185,interoperability,Compon,Components-,6185,"星期二 10:43:08 CST] Stage 'Update package list' starting. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4012:1::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sour",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:7416,interoperability,Translat,Translations,7416,"n /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4012:1::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install development packages' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. pkg-config is already the newest version (0.29.1-0ubuntu1). unzip is already the newest versio",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:7440,interoperability,Translat,Translation-,7440,"d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4012:1::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install development packages' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. pkg-config is already the newest version (0.29.1-0ubuntu1). unzip is already the newest version (6.0-20ubuntu1). zip i",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:7602,interoperability,Translat,Translations,7602,"lease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4012:1::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install development packages' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. pkg-config is already the newest version (0.29.1-0ubuntu1). unzip is already the newest version (6.0-20ubuntu1). zip is already the newest version (3.0-11). curl is already the newest version (7.47.0-1ubuntu2.8). zlib1g-dev is already the newest version (1:1.2.8.dfsg-2ubuntu4.1).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:7626,interoperability,Translat,Translation-en,7626," connection to packages.cloud.google.com:80 (2404:6800:4012:1::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install development packages' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. pkg-config is already the newest version (0.29.1-0ubuntu1). unzip is already the newest version (6.0-20ubuntu1). zip is already the newest version (3.0-11). curl is already the newest version (7.47.0-1ubuntu2.8). zlib1g-dev is already the newest version (1:1.2.8.dfsg-2ubuntu4.1). The following packages w",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:7804,interoperability,Compon,Components-,7804,"load. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install development packages' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. pkg-config is already the newest version (0.29.1-0ubuntu1). unzip is already the newest version (6.0-20ubuntu1). zip is already the newest version (3.0-11). curl is already the newest version (7.47.0-1ubuntu2.8). zlib1g-dev is already the newest version (1:1.2.8.dfsg-2ubuntu4.1). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:13673,interoperability,api,api-python-client,13673,"st-packages (1.7). Requirement already satisfied: six in /usr/local/lib/python2.7/dist-packages (1.11.0). Requirement already satisfied: sklearn in /usr/local/lib/python2.7/dist-packages (0.0). Requirement already satisfied: scikit-learn in /usr/local/lib/python2.7/dist-packages (from sklearn) (0.19.2). Requirement already satisfied: pandas in /usr/local/lib/python2.7/dist-packages (0.23.4). Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python2.7/dist-packages (from pandas) (1.14.0). Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python2.7/dist-packages (from pandas) (2.7.3). Requirement already satisfied: pytz>=2011k in /usr/local/lib/python2.7/dist-packages (from pandas) (2018.5). Requirement already satisfied: six>=1.5 in /usr/local/lib/python2.7/dist-packages (from python-dateutil>=2.5.0->pandas) (1.11.0). Requirement already satisfied: psutil in /usr/local/lib/python2.7/dist-packages (5.4.7). Requirement already up-to-date: google-api-python-client in /usr/local/lib/python2.7/dist-packages (1.7.4). Requirement already satisfied, skipping upgrade: httplib2<1dev,>=0.9.2 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.11.3). Requirement already satisfied, skipping upgrade: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (3.0.0). Requirement already satisfied, skipping upgrade: google-auth-httplib2>=0.0.3 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.0.3). Requirement already satisfied, skipping upgrade: six<2dev,>=1.6.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.11.0). Requirement already satisfied, skipping upgrade: google-auth>=1.4.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.5.1). Requirement already satisfied, skipping upgrade: rsa>=3.1.4 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (3.4.2). Requ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:13868,interoperability,api,api-python-client,13868,"equirement already satisfied: scikit-learn in /usr/local/lib/python2.7/dist-packages (from sklearn) (0.19.2). Requirement already satisfied: pandas in /usr/local/lib/python2.7/dist-packages (0.23.4). Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python2.7/dist-packages (from pandas) (1.14.0). Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python2.7/dist-packages (from pandas) (2.7.3). Requirement already satisfied: pytz>=2011k in /usr/local/lib/python2.7/dist-packages (from pandas) (2018.5). Requirement already satisfied: six>=1.5 in /usr/local/lib/python2.7/dist-packages (from python-dateutil>=2.5.0->pandas) (1.11.0). Requirement already satisfied: psutil in /usr/local/lib/python2.7/dist-packages (5.4.7). Requirement already up-to-date: google-api-python-client in /usr/local/lib/python2.7/dist-packages (1.7.4). Requirement already satisfied, skipping upgrade: httplib2<1dev,>=0.9.2 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.11.3). Requirement already satisfied, skipping upgrade: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (3.0.0). Requirement already satisfied, skipping upgrade: google-auth-httplib2>=0.0.3 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.0.3). Requirement already satisfied, skipping upgrade: six<2dev,>=1.6.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.11.0). Requirement already satisfied, skipping upgrade: google-auth>=1.4.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.5.1). Requirement already satisfied, skipping upgrade: rsa>=3.1.4 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (3.4.2). Requirement already satisfied, skipping upgrade: cachetools>=2.0.0 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (2.1.0). Requirement already satisfied",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:14026,interoperability,api,api-python-client,14026,"cal/lib/python2.7/dist-packages (0.23.4). Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python2.7/dist-packages (from pandas) (1.14.0). Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python2.7/dist-packages (from pandas) (2.7.3). Requirement already satisfied: pytz>=2011k in /usr/local/lib/python2.7/dist-packages (from pandas) (2018.5). Requirement already satisfied: six>=1.5 in /usr/local/lib/python2.7/dist-packages (from python-dateutil>=2.5.0->pandas) (1.11.0). Requirement already satisfied: psutil in /usr/local/lib/python2.7/dist-packages (5.4.7). Requirement already up-to-date: google-api-python-client in /usr/local/lib/python2.7/dist-packages (1.7.4). Requirement already satisfied, skipping upgrade: httplib2<1dev,>=0.9.2 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.11.3). Requirement already satisfied, skipping upgrade: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (3.0.0). Requirement already satisfied, skipping upgrade: google-auth-httplib2>=0.0.3 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.0.3). Requirement already satisfied, skipping upgrade: six<2dev,>=1.6.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.11.0). Requirement already satisfied, skipping upgrade: google-auth>=1.4.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.5.1). Requirement already satisfied, skipping upgrade: rsa>=3.1.4 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (3.4.2). Requirement already satisfied, skipping upgrade: cachetools>=2.0.0 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (2.1.0). Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (0.2.2). Requirement a",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:14186,interoperability,api,api-python-client,14186,"ent already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python2.7/dist-packages (from pandas) (2.7.3). Requirement already satisfied: pytz>=2011k in /usr/local/lib/python2.7/dist-packages (from pandas) (2018.5). Requirement already satisfied: six>=1.5 in /usr/local/lib/python2.7/dist-packages (from python-dateutil>=2.5.0->pandas) (1.11.0). Requirement already satisfied: psutil in /usr/local/lib/python2.7/dist-packages (5.4.7). Requirement already up-to-date: google-api-python-client in /usr/local/lib/python2.7/dist-packages (1.7.4). Requirement already satisfied, skipping upgrade: httplib2<1dev,>=0.9.2 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.11.3). Requirement already satisfied, skipping upgrade: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (3.0.0). Requirement already satisfied, skipping upgrade: google-auth-httplib2>=0.0.3 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.0.3). Requirement already satisfied, skipping upgrade: six<2dev,>=1.6.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.11.0). Requirement already satisfied, skipping upgrade: google-auth>=1.4.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.5.1). Requirement already satisfied, skipping upgrade: rsa>=3.1.4 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (3.4.2). Requirement already satisfied, skipping upgrade: cachetools>=2.0.0 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (2.1.0). Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (0.2.2). Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /usr/local/lib/python2.7/dist-packages (from rsa>=3.1.4->google-auth>=1.4.1->google-api-python-client) (0.4",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:14335,interoperability,api,api-python-client,14335,"011k in /usr/local/lib/python2.7/dist-packages (from pandas) (2018.5). Requirement already satisfied: six>=1.5 in /usr/local/lib/python2.7/dist-packages (from python-dateutil>=2.5.0->pandas) (1.11.0). Requirement already satisfied: psutil in /usr/local/lib/python2.7/dist-packages (5.4.7). Requirement already up-to-date: google-api-python-client in /usr/local/lib/python2.7/dist-packages (1.7.4). Requirement already satisfied, skipping upgrade: httplib2<1dev,>=0.9.2 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.11.3). Requirement already satisfied, skipping upgrade: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (3.0.0). Requirement already satisfied, skipping upgrade: google-auth-httplib2>=0.0.3 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.0.3). Requirement already satisfied, skipping upgrade: six<2dev,>=1.6.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.11.0). Requirement already satisfied, skipping upgrade: google-auth>=1.4.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.5.1). Requirement already satisfied, skipping upgrade: rsa>=3.1.4 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (3.4.2). Requirement already satisfied, skipping upgrade: cachetools>=2.0.0 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (2.1.0). Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (0.2.2). Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /usr/local/lib/python2.7/dist-packages (from rsa>=3.1.4->google-auth>=1.4.1->google-api-python-client) (0.4.4). ========== [2018年 08月 28日 星期二 10:55:17 CST] Stage 'Install TensorFlow pip package' starting. Skipping tf-nightly as it is not installed. Skippin",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:14487,interoperability,api,api-python-client,14487," (from python-dateutil>=2.5.0->pandas) (1.11.0). Requirement already satisfied: psutil in /usr/local/lib/python2.7/dist-packages (5.4.7). Requirement already up-to-date: google-api-python-client in /usr/local/lib/python2.7/dist-packages (1.7.4). Requirement already satisfied, skipping upgrade: httplib2<1dev,>=0.9.2 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.11.3). Requirement already satisfied, skipping upgrade: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (3.0.0). Requirement already satisfied, skipping upgrade: google-auth-httplib2>=0.0.3 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.0.3). Requirement already satisfied, skipping upgrade: six<2dev,>=1.6.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.11.0). Requirement already satisfied, skipping upgrade: google-auth>=1.4.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.5.1). Requirement already satisfied, skipping upgrade: rsa>=3.1.4 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (3.4.2). Requirement already satisfied, skipping upgrade: cachetools>=2.0.0 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (2.1.0). Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (0.2.2). Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /usr/local/lib/python2.7/dist-packages (from rsa>=3.1.4->google-auth>=1.4.1->google-api-python-client) (0.4.4). ========== [2018年 08月 28日 星期二 10:55:17 CST] Stage 'Install TensorFlow pip package' starting. Skipping tf-nightly as it is not installed. Skipping tensorflow as it is not installed. Skipping tf-nightly-gpu as it is not installed. Skipping tensorflow-gpu as it is not installed. Installing Google C",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:14650,interoperability,api,api-python-client,14650,"-date: google-api-python-client in /usr/local/lib/python2.7/dist-packages (1.7.4). Requirement already satisfied, skipping upgrade: httplib2<1dev,>=0.9.2 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.11.3). Requirement already satisfied, skipping upgrade: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (3.0.0). Requirement already satisfied, skipping upgrade: google-auth-httplib2>=0.0.3 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.0.3). Requirement already satisfied, skipping upgrade: six<2dev,>=1.6.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.11.0). Requirement already satisfied, skipping upgrade: google-auth>=1.4.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.5.1). Requirement already satisfied, skipping upgrade: rsa>=3.1.4 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (3.4.2). Requirement already satisfied, skipping upgrade: cachetools>=2.0.0 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (2.1.0). Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (0.2.2). Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /usr/local/lib/python2.7/dist-packages (from rsa>=3.1.4->google-auth>=1.4.1->google-api-python-client) (0.4.4). ========== [2018年 08月 28日 星期二 10:55:17 CST] Stage 'Install TensorFlow pip package' starting. Skipping tf-nightly as it is not installed. Skipping tensorflow as it is not installed. Skipping tf-nightly-gpu as it is not installed. Skipping tensorflow-gpu as it is not installed. Installing Google Cloud Platform optimized CPU-only TensorFlow wheel. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 0 0 0 0 0 ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:14820,interoperability,api,api-python-client,14820,"ping upgrade: httplib2<1dev,>=0.9.2 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.11.3). Requirement already satisfied, skipping upgrade: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (3.0.0). Requirement already satisfied, skipping upgrade: google-auth-httplib2>=0.0.3 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.0.3). Requirement already satisfied, skipping upgrade: six<2dev,>=1.6.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.11.0). Requirement already satisfied, skipping upgrade: google-auth>=1.4.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.5.1). Requirement already satisfied, skipping upgrade: rsa>=3.1.4 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (3.4.2). Requirement already satisfied, skipping upgrade: cachetools>=2.0.0 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (2.1.0). Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (0.2.2). Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /usr/local/lib/python2.7/dist-packages (from rsa>=3.1.4->google-auth>=1.4.1->google-api-python-client) (0.4.4). ========== [2018年 08月 28日 星期二 10:55:17 CST] Stage 'Install TensorFlow pip package' starting. Skipping tf-nightly as it is not installed. Skipping tensorflow as it is not installed. Skipping tf-nightly-gpu as it is not installed. Skipping tensorflow-gpu as it is not installed. Installing Google Cloud Platform optimized CPU-only TensorFlow wheel. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 0 0 0 0 0 0 0 0 --:--:-- 0:02:09 --:--:-- 0curl: (7) Failed to connect to storage.googleapis.com port 443: Connection timed out.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:14994,interoperability,api,api-python-client,14994,"ping upgrade: httplib2<1dev,>=0.9.2 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.11.3). Requirement already satisfied, skipping upgrade: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (3.0.0). Requirement already satisfied, skipping upgrade: google-auth-httplib2>=0.0.3 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.0.3). Requirement already satisfied, skipping upgrade: six<2dev,>=1.6.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.11.0). Requirement already satisfied, skipping upgrade: google-auth>=1.4.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.5.1). Requirement already satisfied, skipping upgrade: rsa>=3.1.4 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (3.4.2). Requirement already satisfied, skipping upgrade: cachetools>=2.0.0 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (2.1.0). Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (0.2.2). Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /usr/local/lib/python2.7/dist-packages (from rsa>=3.1.4->google-auth>=1.4.1->google-api-python-client) (0.4.4). ========== [2018年 08月 28日 星期二 10:55:17 CST] Stage 'Install TensorFlow pip package' starting. Skipping tf-nightly as it is not installed. Skipping tensorflow as it is not installed. Skipping tf-nightly-gpu as it is not installed. Skipping tensorflow-gpu as it is not installed. Installing Google Cloud Platform optimized CPU-only TensorFlow wheel. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 0 0 0 0 0 0 0 0 --:--:-- 0:02:09 --:--:-- 0curl: (7) Failed to connect to storage.googleapis.com port 443: Connection timed out.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:15172,interoperability,api,api-python-client,15172,"ping upgrade: httplib2<1dev,>=0.9.2 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.11.3). Requirement already satisfied, skipping upgrade: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (3.0.0). Requirement already satisfied, skipping upgrade: google-auth-httplib2>=0.0.3 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.0.3). Requirement already satisfied, skipping upgrade: six<2dev,>=1.6.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.11.0). Requirement already satisfied, skipping upgrade: google-auth>=1.4.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.5.1). Requirement already satisfied, skipping upgrade: rsa>=3.1.4 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (3.4.2). Requirement already satisfied, skipping upgrade: cachetools>=2.0.0 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (2.1.0). Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (0.2.2). Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /usr/local/lib/python2.7/dist-packages (from rsa>=3.1.4->google-auth>=1.4.1->google-api-python-client) (0.4.4). ========== [2018年 08月 28日 星期二 10:55:17 CST] Stage 'Install TensorFlow pip package' starting. Skipping tf-nightly as it is not installed. Skipping tensorflow as it is not installed. Skipping tf-nightly-gpu as it is not installed. Skipping tensorflow-gpu as it is not installed. Installing Google Cloud Platform optimized CPU-only TensorFlow wheel. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 0 0 0 0 0 0 0 0 --:--:-- 0:02:09 --:--:-- 0curl: (7) Failed to connect to storage.googleapis.com port 443: Connection timed out.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:15501,interoperability,Platform,Platform,15501,"ping upgrade: httplib2<1dev,>=0.9.2 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.11.3). Requirement already satisfied, skipping upgrade: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (3.0.0). Requirement already satisfied, skipping upgrade: google-auth-httplib2>=0.0.3 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.0.3). Requirement already satisfied, skipping upgrade: six<2dev,>=1.6.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.11.0). Requirement already satisfied, skipping upgrade: google-auth>=1.4.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.5.1). Requirement already satisfied, skipping upgrade: rsa>=3.1.4 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (3.4.2). Requirement already satisfied, skipping upgrade: cachetools>=2.0.0 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (2.1.0). Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (0.2.2). Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /usr/local/lib/python2.7/dist-packages (from rsa>=3.1.4->google-auth>=1.4.1->google-api-python-client) (0.4.4). ========== [2018年 08月 28日 星期二 10:55:17 CST] Stage 'Install TensorFlow pip package' starting. Skipping tf-nightly as it is not installed. Skipping tensorflow as it is not installed. Skipping tf-nightly-gpu as it is not installed. Skipping tensorflow-gpu as it is not installed. Installing Google Cloud Platform optimized CPU-only TensorFlow wheel. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 0 0 0 0 0 0 0 0 --:--:-- 0:02:09 --:--:-- 0curl: (7) Failed to connect to storage.googleapis.com port 443: Connection timed out.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:1016,modifiability,pac,packages,1016,he zip file and ra run-prereq.sh and this was the output:. solokopi@solokopi-All-Series:~/Desktop/DeepVariant-0.7.0+cl-208818123$ sudo bash run-prereq.sh. [sudo] password for solokopi: . ========== Load config settings. ========== [2018年 08月 28日 星期二 10:31:05 CST] Stage 'Misc setup' starting. Ign:1 http://dl.google.com/linux/chrome/deb stable InRelease. Hit:2 http://mirrors.aliyun.com/ubuntu xenial InRelease . Hit:3 http://dl.google.com/linux/chrome/deb stable Release . Hit:4 http://mirrors.aliyun.com/ubuntu xenial-updates InRelease . Get:6 http://mirrors.aliyun.com/ubuntu xenial-backports InRelease [107 kB] . Hit:7 http://mirrors.aliyun.com/ubuntu xenial-security InRelease . Hit:8 http://ppa.launchpad.net/webupd8team/java/ubuntu xenial InRelease . Err:9 http://storage.googleapis.com/bazel-apt stable InRelease . Cannot initiate the connection to storage.googleapis.com:80 (2404:6800:4012:1::2010). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::2010 80]. Err:10 http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease . Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4008:803::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4008:803::200e 80]. Fetched 107 kB in 12min 0s (148 B/s) . Reading package lists... Done. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:1109,modifiability,pac,packages,1109,ktop/DeepVariant-0.7.0+cl-208818123$ sudo bash run-prereq.sh. [sudo] password for solokopi: . ========== Load config settings. ========== [2018年 08月 28日 星期二 10:31:05 CST] Stage 'Misc setup' starting. Ign:1 http://dl.google.com/linux/chrome/deb stable InRelease. Hit:2 http://mirrors.aliyun.com/ubuntu xenial InRelease . Hit:3 http://dl.google.com/linux/chrome/deb stable Release . Hit:4 http://mirrors.aliyun.com/ubuntu xenial-updates InRelease . Get:6 http://mirrors.aliyun.com/ubuntu xenial-backports InRelease [107 kB] . Hit:7 http://mirrors.aliyun.com/ubuntu xenial-security InRelease . Hit:8 http://ppa.launchpad.net/webupd8team/java/ubuntu xenial InRelease . Err:9 http://storage.googleapis.com/bazel-apt stable InRelease . Cannot initiate the connection to storage.googleapis.com:80 (2404:6800:4012:1::2010). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::2010 80]. Err:10 http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease . Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4008:803::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4008:803::200e 80]. Fetched 107 kB in 12min 0s (148 B/s) . Reading package lists... Done. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:1288,modifiability,pac,package,1288,isc setup' starting. Ign:1 http://dl.google.com/linux/chrome/deb stable InRelease. Hit:2 http://mirrors.aliyun.com/ubuntu xenial InRelease . Hit:3 http://dl.google.com/linux/chrome/deb stable Release . Hit:4 http://mirrors.aliyun.com/ubuntu xenial-updates InRelease . Get:6 http://mirrors.aliyun.com/ubuntu xenial-backports InRelease [107 kB] . Hit:7 http://mirrors.aliyun.com/ubuntu xenial-security InRelease . Hit:8 http://ppa.launchpad.net/webupd8team/java/ubuntu xenial InRelease . Err:9 http://storage.googleapis.com/bazel-apt stable InRelease . Cannot initiate the connection to storage.googleapis.com:80 (2404:6800:4012:1::2010). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::2010 80]. Err:10 http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease . Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4008:803::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4008:803::200e 80]. Fetched 107 kB in 12min 0s (148 B/s) . Reading package lists... Done. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and ,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:1421,modifiability,extens,extension,1421,ease . Hit:3 http://dl.google.com/linux/chrome/deb stable Release . Hit:4 http://mirrors.aliyun.com/ubuntu xenial-updates InRelease . Get:6 http://mirrors.aliyun.com/ubuntu xenial-backports InRelease [107 kB] . Hit:7 http://mirrors.aliyun.com/ubuntu xenial-security InRelease . Hit:8 http://ppa.launchpad.net/webupd8team/java/ubuntu xenial InRelease . Err:9 http://storage.googleapis.com/bazel-apt stable InRelease . Cannot initiate the connection to storage.googleapis.com:80 (2404:6800:4012:1::2010). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::2010 80]. Err:10 http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease . Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4008:803::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4008:803::200e 80]. Fetched 107 kB in 12min 0s (148 B/s) . Reading package lists... Done. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /e,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:1442,modifiability,Pac,Packages,1442,dl.google.com/linux/chrome/deb stable Release . Hit:4 http://mirrors.aliyun.com/ubuntu xenial-updates InRelease . Get:6 http://mirrors.aliyun.com/ubuntu xenial-backports InRelease [107 kB] . Hit:7 http://mirrors.aliyun.com/ubuntu xenial-security InRelease . Hit:8 http://ppa.launchpad.net/webupd8team/java/ubuntu xenial InRelease . Err:9 http://storage.googleapis.com/bazel-apt stable InRelease . Cannot initiate the connection to storage.googleapis.com:80 (2404:6800:4012:1::2010). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::2010 80]. Err:10 http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease . Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4008:803::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4008:803::200e 80]. Fetched 107 kB in 12min 0s (148 B/s) . Reading package lists... Done. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:1470,modifiability,Pac,Packages,1470,eb stable Release . Hit:4 http://mirrors.aliyun.com/ubuntu xenial-updates InRelease . Get:6 http://mirrors.aliyun.com/ubuntu xenial-backports InRelease [107 kB] . Hit:7 http://mirrors.aliyun.com/ubuntu xenial-security InRelease . Hit:8 http://ppa.launchpad.net/webupd8team/java/ubuntu xenial InRelease . Err:9 http://storage.googleapis.com/bazel-apt stable InRelease . Cannot initiate the connection to storage.googleapis.com:80 (2404:6800:4012:1::2010). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::2010 80]. Err:10 http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease . Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4008:803::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4008:803::200e 80]. Fetched 107 kB in 12min 0s (148 B/s) . Reading package lists... Done. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 an,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:1483,modifiability,configur,configured,1483,ase . Hit:4 http://mirrors.aliyun.com/ubuntu xenial-updates InRelease . Get:6 http://mirrors.aliyun.com/ubuntu xenial-backports InRelease [107 kB] . Hit:7 http://mirrors.aliyun.com/ubuntu xenial-security InRelease . Hit:8 http://ppa.launchpad.net/webupd8team/java/ubuntu xenial InRelease . Err:9 http://storage.googleapis.com/bazel-apt stable InRelease . Cannot initiate the connection to storage.googleapis.com:80 (2404:6800:4012:1::2010). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::2010 80]. Err:10 http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease . Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4008:803::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4008:803::200e 80]. Fetched 107 kB in 12min 0s (148 B/s) . Reading package lists... Done. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sou,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:1623,modifiability,Pac,Packages,1623,107 kB] . Hit:7 http://mirrors.aliyun.com/ubuntu xenial-security InRelease . Hit:8 http://ppa.launchpad.net/webupd8team/java/ubuntu xenial InRelease . Err:9 http://storage.googleapis.com/bazel-apt stable InRelease . Cannot initiate the connection to storage.googleapis.com:80 (2404:6800:4012:1::2010). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::2010 80]. Err:10 http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease . Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4008:803::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4008:803::200e 80]. Fetched 107 kB in 12min 0s (148 B/s) . Reading package lists... Done. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.l,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:1650,modifiability,Pac,Packages,1650,ors.aliyun.com/ubuntu xenial-security InRelease . Hit:8 http://ppa.launchpad.net/webupd8team/java/ubuntu xenial InRelease . Err:9 http://storage.googleapis.com/bazel-apt stable InRelease . Cannot initiate the connection to storage.googleapis.com:80 (2404:6800:4012:1::2010). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::2010 80]. Err:10 http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease . Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4008:803::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4008:803::200e 80]. Fetched 107 kB in 12min 0s (148 B/s) . Reading package lists... Done. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:1663,modifiability,configur,configured,1663,/ubuntu xenial-security InRelease . Hit:8 http://ppa.launchpad.net/webupd8team/java/ubuntu xenial InRelease . Err:9 http://storage.googleapis.com/bazel-apt stable InRelease . Cannot initiate the connection to storage.googleapis.com:80 (2404:6800:4012:1::2010). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::2010 80]. Err:10 http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease . Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4008:803::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4008:803::200e 80]. Fetched 107 kB in 12min 0s (148 B/s) . Reading package lists... Done. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/ap,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:1803,modifiability,Pac,Packages,1803,is.com/bazel-apt stable InRelease . Cannot initiate the connection to storage.googleapis.com:80 (2404:6800:4012:1::2010). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::2010 80]. Err:10 http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease . Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4008:803::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4008:803::200e 80]. Fetched 107 kB in 12min 0s (148 B/s) . Reading package lists... Done. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://storage.googleapis.com/bazel-apt/dists/stable/InRelease Cannot initiate,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:1829,modifiability,Pac,Packages,1829,Release . Cannot initiate the connection to storage.googleapis.com:80 (2404:6800:4012:1::2010). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::2010 80]. Err:10 http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease . Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4008:803::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4008:803::200e 80]. Fetched 107 kB in 12min 0s (148 B/s) . Reading package lists... Done. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://storage.googleapis.com/bazel-apt/dists/stable/InRelease Cannot initiate the connection to storage,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:1842,modifiability,configur,configured,1842,ot initiate the connection to storage.googleapis.com:80 (2404:6800:4012:1::2010). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::2010 80]. Err:10 http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease . Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4008:803::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4008:803::200e 80]. Fetched 107 kB in 12min 0s (148 B/s) . Reading package lists... Done. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://storage.googleapis.com/bazel-apt/dists/stable/InRelease Cannot initiate the connection to storage.googleapis.co,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:2028,modifiability,configur,configured,2028,ogle.com/apt cloud-sdk-xenial InRelease . Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4008:803::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4008:803::200e 80]. Fetched 107 kB in 12min 0s (148 B/s) . Reading package lists... Done. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://storage.googleapis.com/bazel-apt/dists/stable/InRelease Cannot initiate the connection to storage.googleapis.com:80 (2404:6800:4012:1::2010). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::2010 80]. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InR,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:2211,modifiability,configur,configured,2211,6800:4008:803::200e 80]. Fetched 107 kB in 12min 0s (148 B/s) . Reading package lists... Done. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://storage.googleapis.com/bazel-apt/dists/stable/InRelease Cannot initiate the connection to storage.googleapis.com:80 (2404:6800:4012:1::2010). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::2010 80]. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4008:803::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4008:803::200e 80]. W: Some in,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:2370,modifiability,Compon,Components-,2370,"urces.list.d/' as it has an invalid filename extension. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://storage.googleapis.com/bazel-apt/dists/stable/InRelease Cannot initiate the connection to storage.googleapis.com:80 (2404:6800:4012:1::2010). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::2010 80]. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4008:803::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4008:803::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:2395,modifiability,configur,configured,2395," an invalid filename extension. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://storage.googleapis.com/bazel-apt/dists/stable/InRelease Cannot initiate the connection to storage.googleapis.com:80 (2404:6800:4012:1::2010). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::2010 80]. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4008:803::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4008:803::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:2580,modifiability,configur,configured,2580,".d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://storage.googleapis.com/bazel-apt/dists/stable/InRelease Cannot initiate the connection to storage.googleapis.com:80 (2404:6800:4012:1::2010). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::2010 80]. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4008:803::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4008:803::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/googl",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:2977,modifiability,pac,packages,2977," Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://storage.googleapis.com/bazel-apt/dists/stable/InRelease Cannot initiate the connection to storage.googleapis.com:80 (2404:6800:4012:1::2010). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::2010 80]. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4008:803::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4008:803::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:3074,modifiability,pac,packages,3074,".d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://storage.googleapis.com/bazel-apt/dists/stable/InRelease Cannot initiate the connection to storage.googleapis.com:80 (2404:6800:4012:1::2010). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::2010 80]. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4008:803::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4008:803::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is con",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:3306,modifiability,Pac,Packages,3306,"ist.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://storage.googleapis.com/bazel-apt/dists/stable/InRelease Cannot initiate the connection to storage.googleapis.com:80 (2404:6800:4012:1::2010). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::2010 80]. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4008:803::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4008:803::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:3334,modifiability,Pac,Packages,3334,"2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://storage.googleapis.com/bazel-apt/dists/stable/InRelease Cannot initiate the connection to storage.googleapis.com:80 (2404:6800:4012:1::2010). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::2010 80]. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4008:803::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4008:803::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 an",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:3347,modifiability,configur,configured,3347,"EP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://storage.googleapis.com/bazel-apt/dists/stable/InRelease Cannot initiate the connection to storage.googleapis.com:80 (2404:6800:4012:1::2010). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::2010 80]. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4008:803::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4008:803::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sou",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:3487,modifiability,Pac,Packages,3487,"s.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://storage.googleapis.com/bazel-apt/dists/stable/InRelease Cannot initiate the connection to storage.googleapis.com:80 (2404:6800:4012:1::2010). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::2010 80]. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4008:803::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4008:803::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.l",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:3514,modifiability,Pac,Packages,3514,"ist:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://storage.googleapis.com/bazel-apt/dists/stable/InRelease Cannot initiate the connection to storage.googleapis.com:80 (2404:6800:4012:1::2010). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::2010 80]. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4008:803::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4008:803::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:3527,modifiability,configur,configured,3527,"et DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://storage.googleapis.com/bazel-apt/dists/stable/InRelease Cannot initiate the connection to storage.googleapis.com:80 (2404:6800:4012:1::2010). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::2010 80]. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4008:803::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4008:803::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/ap",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:3667,modifiability,Pac,Packages,3667,"ources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://storage.googleapis.com/bazel-apt/dists/stable/InRelease Cannot initiate the connection to storage.googleapis.com:80 (2404:6800:4012:1::2010). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::2010 80]. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4008:803::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4008:803::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. Reading package lists... Done. Building dependency tree . Reading state information... Done. sudo",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:3693,modifiability,Pac,Packages,3693,"-sdk.list:2. W: Failed to fetch http://storage.googleapis.com/bazel-apt/dists/stable/InRelease Cannot initiate the connection to storage.googleapis.com:80 (2404:6800:4012:1::2010). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::2010 80]. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4008:803::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4008:803::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. Reading package lists... Done. Building dependency tree . Reading state information... Done. sudo is already the newest ver",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:3706,modifiability,configur,configured,3706,": Failed to fetch http://storage.googleapis.com/bazel-apt/dists/stable/InRelease Cannot initiate the connection to storage.googleapis.com:80 (2404:6800:4012:1::2010). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::2010 80]. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4008:803::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4008:803::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. Reading package lists... Done. Building dependency tree . Reading state information... Done. sudo is already the newest version (1.8.16-0",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:3892,modifiability,configur,configured,3892,"work is unreachable) [IP: 2404:6800:4012:1::2010 80]. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4008:803::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4008:803::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. Reading package lists... Done. Building dependency tree . Reading state information... Done. sudo is already the newest version (1.8.16-0ubuntu1.5). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-gen",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:4075,modifiability,configur,configured,4075,"es.cloud.google.com:80 (2404:6800:4008:803::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4008:803::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. Reading package lists... Done. Building dependency tree . Reading state information... Done. sudo is already the newest version (1.8.16-0ubuntu1.5). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:4234,modifiability,Compon,Components-,4234,"load. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. Reading package lists... Done. Building dependency tree . Reading state information... Done. sudo is already the newest version (1.8.16-0ubuntu1.5). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:43:08 CST] Stage 'Update package list' sta",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:4259,modifiability,configur,configured,4259,"ored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. Reading package lists... Done. Building dependency tree . Reading state information... Done. sudo is already the newest version (1.8.16-0ubuntu1.5). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:43:08 CST] Stage 'Update package list' starting. W: Target Package",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:4444,modifiability,configur,configured,4444,".d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. Reading package lists... Done. Building dependency tree . Reading state information... Done. sudo is already the newest version (1.8.16-0ubuntu1.5). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:43:08 CST] Stage 'Update package list' starting. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (m",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:4582,modifiability,pac,package,4582,"-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. Reading package lists... Done. Building dependency tree . Reading state information... Done. sudo is already the newest version (1.8.16-0ubuntu1.5). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:43:08 CST] Stage 'Update package list' starting. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/goo",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:4614,modifiability,depend,dependency,4614,"urces.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. Reading package lists... Done. Building dependency tree . Reading state information... Done. sudo is already the newest version (1.8.16-0ubuntu1.5). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:43:08 CST] Stage 'Update package list' starting. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target P",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:4694,modifiability,version,version,4694,"ges) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. Reading package lists... Done. Building dependency tree . Reading state information... Done. sudo is already the newest version (1.8.16-0ubuntu1.5). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:43:08 CST] Stage 'Update package list' starting. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sou",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:4737,modifiability,pac,packages,4737,"pt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. Reading package lists... Done. Building dependency tree . Reading state information... Done. sudo is already the newest version (1.8.16-0ubuntu1.5). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:43:08 CST] Stage 'Update package list' starting. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /et",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:4983,modifiability,upgrad,upgraded,4983,"es.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. Reading package lists... Done. Building dependency tree . Reading state information... Done. sudo is already the newest version (1.8.16-0ubuntu1.5). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:43:08 CST] Stage 'Update package list' starting. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Tran",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:5034,modifiability,upgrad,upgraded,5034,"ations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. Reading package lists... Done. Building dependency tree . Reading state information... Done. sudo is already the newest version (1.8.16-0ubuntu1.5). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:43:08 CST] Stage 'Update package list' starting. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured m",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:5154,modifiability,extens,extension,5154,"c/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. Reading package lists... Done. Building dependency tree . Reading state information... Done. sudo is already the newest version (1.8.16-0ubuntu1.5). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:43:08 CST] Stage 'Update package list' starting. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:5223,modifiability,pac,package,5223,"/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. Reading package lists... Done. Building dependency tree . Reading state information... Done. sudo is already the newest version (1.8.16-0ubuntu1.5). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:43:08 CST] Stage 'Update package list' starting. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multip",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:5257,modifiability,Pac,Packages,5257,"nfigured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. Reading package lists... Done. Building dependency tree . Reading state information... Done. sudo is already the newest version (1.8.16-0ubuntu1.5). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:43:08 CST] Stage 'Update package list' starting. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:5285,modifiability,Pac,Packages,5285,"etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. Reading package lists... Done. Building dependency tree . Reading state information... Done. sudo is already the newest version (1.8.16-0ubuntu1.5). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:43:08 CST] Stage 'Update package list' starting. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 an",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:5298,modifiability,configur,configured,5298,"s.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. Reading package lists... Done. Building dependency tree . Reading state information... Done. sudo is already the newest version (1.8.16-0ubuntu1.5). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:43:08 CST] Stage 'Update package list' starting. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sou",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:5438,modifiability,Pac,Packages,5438,"s configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. Reading package lists... Done. Building dependency tree . Reading state information... Done. sudo is already the newest version (1.8.16-0ubuntu1.5). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:43:08 CST] Stage 'Update package list' starting. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.l",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:5465,modifiability,Pac,Packages,5465," in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. Reading package lists... Done. Building dependency tree . Reading state information... Done. sudo is already the newest version (1.8.16-0ubuntu1.5). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:43:08 CST] Stage 'Update package list' starting. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:5478,modifiability,configur,configured,5478,"ources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. Reading package lists... Done. Building dependency tree . Reading state information... Done. sudo is already the newest version (1.8.16-0ubuntu1.5). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:43:08 CST] Stage 'Update package list' starting. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/ap",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:5618,modifiability,Pac,Packages,5618,"cy tree . Reading state information... Done. sudo is already the newest version (1.8.16-0ubuntu1.5). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:43:08 CST] Stage 'Update package list' starting. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot i",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:5644,modifiability,Pac,Packages,5644,"formation... Done. sudo is already the newest version (1.8.16-0ubuntu1.5). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:43:08 CST] Stage 'Update package list' starting. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:5657,modifiability,configur,configured,5657,"one. sudo is already the newest version (1.8.16-0ubuntu1.5). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:43:08 CST] Stage 'Update package list' starting. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:5843,modifiability,configur,configured,5843,"ders-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:43:08 CST] Stage 'Update package list' starting. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4012:1::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::200e 80]. W: Some index files failed to download. They have been ignored, or old o",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:6026,modifiability,configur,configured,6026,"ot upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:43:08 CST] Stage 'Update package list' starting. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4012:1::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cl",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:6185,modifiability,Compon,Components-,6185,"星期二 10:43:08 CST] Stage 'Update package list' starting. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4012:1::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sour",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:6210,modifiability,configur,configured,6210,"'Update package list' starting. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4012:1::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:6395,modifiability,configur,configured,6395,".d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4012:1::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.li",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:6551,modifiability,pac,packages,6551,"and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4012:1::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sou",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:6648,modifiability,pac,packages,6648,") is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4012:1::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configu",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:6876,modifiability,Pac,Packages,6876,"/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4012:1::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:6904,modifiability,Pac,Packages,6904,"-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4012:1::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 an",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:6917,modifiability,configur,configured,6917,"d /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4012:1::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sou",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:7057,modifiability,Pac,Packages,7057,"pt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4012:1::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.l",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:7084,modifiability,Pac,Packages,7084,"oud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4012:1::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:7097,modifiability,configur,configured,7097," and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4012:1::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/ap",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:7237,modifiability,Pac,Packages,7237,"tc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4012:1::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install development packages' starting. Readin",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:7263,modifiability,Pac,Packages,7263,"le-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4012:1::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install development packages' starting. Reading package lists... Done. B",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:7276,modifiability,configur,configured,7276,"ist:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4012:1::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install development packages' starting. Reading package lists... Done. Building depend",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:7462,modifiability,configur,configured,7462,"st:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4012:1::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install development packages' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. pkg-config is already the newest version (0.29.1-0ubuntu1). unzip is already the newest version (6.0-20ubuntu1). zip is already the newest ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:7645,modifiability,configur,configured,7645,"ckages.cloud.google.com:80 (2404:6800:4012:1::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install development packages' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. pkg-config is already the newest version (0.29.1-0ubuntu1). unzip is already the newest version (6.0-20ubuntu1). zip is already the newest version (3.0-11). curl is already the newest version (7.47.0-1ubuntu2.8). zlib1g-dev is already the newest version (1:1.2.8.dfsg-2ubuntu4.1). The following packages were automatically",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:7804,modifiability,Compon,Components-,7804,"load. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install development packages' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. pkg-config is already the newest version (0.29.1-0ubuntu1). unzip is already the newest version (6.0-20ubuntu1). zip is already the newest version (3.0-11). curl is already the newest version (7.47.0-1ubuntu2.8). zlib1g-dev is already the newest version (1:1.2.8.dfsg-2ubuntu4.1). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:7829,modifiability,configur,configured,7829,"ored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install development packages' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. pkg-config is already the newest version (0.29.1-0ubuntu1). unzip is already the newest version (6.0-20ubuntu1). zip is already the newest version (3.0-11). curl is already the newest version (7.47.0-1ubuntu2.8). zlib1g-dev is already the newest version (1:1.2.8.dfsg-2ubuntu4.1). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:8014,modifiability,configur,configured,8014,".d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install development packages' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. pkg-config is already the newest version (0.29.1-0ubuntu1). unzip is already the newest version (6.0-20ubuntu1). zip is already the newest version (3.0-11). curl is already the newest version (7.47.0-1ubuntu2.8). zlib1g-dev is already the newest version (1:1.2.8.dfsg-2ubuntu4.1). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:8215,modifiability,pac,packages,8215,"list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install development packages' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. pkg-config is already the newest version (0.29.1-0ubuntu1). unzip is already the newest version (6.0-20ubuntu1). zip is already the newest version (3.0-11). curl is already the newest version (7.47.0-1ubuntu2.8). zlib1g-dev is already the newest version (1:1.2.8.dfsg-2ubuntu4.1). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install python packaging infrastructure' starting. Reading package lists... Done. Building dependency tree . Reading ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:8243,modifiability,pac,package,8243,"main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install development packages' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. pkg-config is already the newest version (0.29.1-0ubuntu1). unzip is already the newest version (6.0-20ubuntu1). zip is already the newest version (3.0-11). curl is already the newest version (7.47.0-1ubuntu2.8). zlib1g-dev is already the newest version (1:1.2.8.dfsg-2ubuntu4.1). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install python packaging infrastructure' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:8275,modifiability,depend,dependency,8275,"igured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install development packages' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. pkg-config is already the newest version (0.29.1-0ubuntu1). unzip is already the newest version (6.0-20ubuntu1). zip is already the newest version (3.0-11). curl is already the newest version (7.47.0-1ubuntu2.8). zlib1g-dev is already the newest version (1:1.2.8.dfsg-2ubuntu4.1). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install python packaging infrastructure' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. python-wheel is already the newest",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:8361,modifiability,version,version,8361,"/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install development packages' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. pkg-config is already the newest version (0.29.1-0ubuntu1). unzip is already the newest version (6.0-20ubuntu1). zip is already the newest version (3.0-11). curl is already the newest version (7.47.0-1ubuntu2.8). zlib1g-dev is already the newest version (1:1.2.8.dfsg-2ubuntu4.1). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install python packaging infrastructure' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. python-wheel is already the newest version (0.29.0-1). python-dev is already the newest version (2.7.12-1~16.04). pytho",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:8416,modifiability,version,version,8416,"slations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install development packages' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. pkg-config is already the newest version (0.29.1-0ubuntu1). unzip is already the newest version (6.0-20ubuntu1). zip is already the newest version (3.0-11). curl is already the newest version (7.47.0-1ubuntu2.8). zlib1g-dev is already the newest version (1:1.2.8.dfsg-2ubuntu4.1). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install python packaging infrastructure' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. python-wheel is already the newest version (0.29.0-1). python-dev is already the newest version (2.7.12-1~16.04). python-pip is already the newest version (8.1.1-2ubuntu0.4).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:8467,modifiability,version,version,8467,"d multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install development packages' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. pkg-config is already the newest version (0.29.1-0ubuntu1). unzip is already the newest version (6.0-20ubuntu1). zip is already the newest version (3.0-11). curl is already the newest version (7.47.0-1ubuntu2.8). zlib1g-dev is already the newest version (1:1.2.8.dfsg-2ubuntu4.1). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install python packaging infrastructure' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. python-wheel is already the newest version (0.29.0-1). python-dev is already the newest version (2.7.12-1~16.04). python-pip is already the newest version (8.1.1-2ubuntu0.4). The following packages were automatically installe",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:8512,modifiability,version,version,8512,"oogle-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install development packages' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. pkg-config is already the newest version (0.29.1-0ubuntu1). unzip is already the newest version (6.0-20ubuntu1). zip is already the newest version (3.0-11). curl is already the newest version (7.47.0-1ubuntu2.8). zlib1g-dev is already the newest version (1:1.2.8.dfsg-2ubuntu4.1). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install python packaging infrastructure' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. python-wheel is already the newest version (0.29.0-1). python-dev is already the newest version (2.7.12-1~16.04). python-pip is already the newest version (8.1.1-2ubuntu0.4). The following packages were automatically installed and are no longer required:. libllvm5.0 lin",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:8574,modifiability,version,version,8574,"d-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install development packages' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. pkg-config is already the newest version (0.29.1-0ubuntu1). unzip is already the newest version (6.0-20ubuntu1). zip is already the newest version (3.0-11). curl is already the newest version (7.47.0-1ubuntu2.8). zlib1g-dev is already the newest version (1:1.2.8.dfsg-2ubuntu4.1). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install python packaging infrastructure' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. python-wheel is already the newest version (0.29.0-1). python-dev is already the newest version (2.7.12-1~16.04). python-pip is already the newest version (8.1.1-2ubuntu0.4). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-im",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:8623,modifiability,pac,packages,8623,"ranslation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install development packages' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. pkg-config is already the newest version (0.29.1-0ubuntu1). unzip is already the newest version (6.0-20ubuntu1). zip is already the newest version (3.0-11). curl is already the newest version (7.47.0-1ubuntu2.8). zlib1g-dev is already the newest version (1:1.2.8.dfsg-2ubuntu4.1). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install python packaging infrastructure' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. python-wheel is already the newest version (0.29.0-1). python-dev is already the newest version (2.7.12-1~16.04). python-pip is already the newest version (8.1.1-2ubuntu0.4). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:8869,modifiability,upgrad,upgraded,8869,"s.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install development packages' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. pkg-config is already the newest version (0.29.1-0ubuntu1). unzip is already the newest version (6.0-20ubuntu1). zip is already the newest version (3.0-11). curl is already the newest version (7.47.0-1ubuntu2.8). zlib1g-dev is already the newest version (1:1.2.8.dfsg-2ubuntu4.1). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install python packaging infrastructure' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. python-wheel is already the newest version (0.29.0-1). python-dev is already the newest version (2.7.12-1~16.04). python-pip is already the newest version (8.1.1-2ubuntu0.4). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. Requiremen",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:8920,modifiability,upgrad,upgraded,8920,"es.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install development packages' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. pkg-config is already the newest version (0.29.1-0ubuntu1). unzip is already the newest version (6.0-20ubuntu1). zip is already the newest version (3.0-11). curl is already the newest version (7.47.0-1ubuntu2.8). zlib1g-dev is already the newest version (1:1.2.8.dfsg-2ubuntu4.1). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install python packaging infrastructure' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. python-wheel is already the newest version (0.29.0-1). python-dev is already the newest version (2.7.12-1~16.04). python-pip is already the newest version (8.1.1-2ubuntu0.4). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. Requirement already up-to-date: pip in /usr/local/lib/python2",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:9040,modifiability,extens,extension,9040,"tc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install development packages' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. pkg-config is already the newest version (0.29.1-0ubuntu1). unzip is already the newest version (6.0-20ubuntu1). zip is already the newest version (3.0-11). curl is already the newest version (7.47.0-1ubuntu2.8). zlib1g-dev is already the newest version (1:1.2.8.dfsg-2ubuntu4.1). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install python packaging infrastructure' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. python-wheel is already the newest version (0.29.0-1). python-dev is already the newest version (2.7.12-1~16.04). python-pip is already the newest version (8.1.1-2ubuntu0.4). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. Requirement already up-to-date: pip in /usr/local/lib/python2.7/dist-packages (18.0). ========== [2018年 08月 28日 星期二 10:55:12 CST] Stage 'Install python packages' starting. Requiremen",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:9117,modifiability,pac,packaging,9117,"gle-cloud-sdk.list:2. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install development packages' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. pkg-config is already the newest version (0.29.1-0ubuntu1). unzip is already the newest version (6.0-20ubuntu1). zip is already the newest version (3.0-11). curl is already the newest version (7.47.0-1ubuntu2.8). zlib1g-dev is already the newest version (1:1.2.8.dfsg-2ubuntu4.1). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install python packaging infrastructure' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. python-wheel is already the newest version (0.29.0-1). python-dev is already the newest version (2.7.12-1~16.04). python-pip is already the newest version (8.1.1-2ubuntu0.4). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. Requirement already up-to-date: pip in /usr/local/lib/python2.7/dist-packages (18.0). ========== [2018年 08月 28日 星期二 10:55:12 CST] Stage 'Install python packages' starting. Requirement already satisfied: contextlib2 in /usr/local/lib/python2.7/dist-packages (0",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:9161,modifiability,pac,package,9161," 28日 星期二 10:55:10 CST] Stage 'Install development packages' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. pkg-config is already the newest version (0.29.1-0ubuntu1). unzip is already the newest version (6.0-20ubuntu1). zip is already the newest version (3.0-11). curl is already the newest version (7.47.0-1ubuntu2.8). zlib1g-dev is already the newest version (1:1.2.8.dfsg-2ubuntu4.1). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install python packaging infrastructure' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. python-wheel is already the newest version (0.29.0-1). python-dev is already the newest version (2.7.12-1~16.04). python-pip is already the newest version (8.1.1-2ubuntu0.4). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. Requirement already up-to-date: pip in /usr/local/lib/python2.7/dist-packages (18.0). ========== [2018年 08月 28日 星期二 10:55:12 CST] Stage 'Install python packages' starting. Requirement already satisfied: contextlib2 in /usr/local/lib/python2.7/dist-packages (0.5.5). Requirement already satisfied: enum3",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:9193,modifiability,depend,dependency,9193,"tall development packages' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. pkg-config is already the newest version (0.29.1-0ubuntu1). unzip is already the newest version (6.0-20ubuntu1). zip is already the newest version (3.0-11). curl is already the newest version (7.47.0-1ubuntu2.8). zlib1g-dev is already the newest version (1:1.2.8.dfsg-2ubuntu4.1). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install python packaging infrastructure' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. python-wheel is already the newest version (0.29.0-1). python-dev is already the newest version (2.7.12-1~16.04). python-pip is already the newest version (8.1.1-2ubuntu0.4). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. Requirement already up-to-date: pip in /usr/local/lib/python2.7/dist-packages (18.0). ========== [2018年 08月 28日 星期二 10:55:12 CST] Stage 'Install python packages' starting. Requirement already satisfied: contextlib2 in /usr/local/lib/python2.7/dist-packages (0.5.5). Requirement already satisfied: enum34 in /usr/local/lib/python2.7/dis",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:9281,modifiability,version,version,9281," tree . Reading state information... Done. pkg-config is already the newest version (0.29.1-0ubuntu1). unzip is already the newest version (6.0-20ubuntu1). zip is already the newest version (3.0-11). curl is already the newest version (7.47.0-1ubuntu2.8). zlib1g-dev is already the newest version (1:1.2.8.dfsg-2ubuntu4.1). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install python packaging infrastructure' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. python-wheel is already the newest version (0.29.0-1). python-dev is already the newest version (2.7.12-1~16.04). python-pip is already the newest version (8.1.1-2ubuntu0.4). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. Requirement already up-to-date: pip in /usr/local/lib/python2.7/dist-packages (18.0). ========== [2018年 08月 28日 星期二 10:55:12 CST] Stage 'Install python packages' starting. Requirement already satisfied: contextlib2 in /usr/local/lib/python2.7/dist-packages (0.5.5). Requirement already satisfied: enum34 in /usr/local/lib/python2.7/dist-packages (1.1.6). Requirement already satisfied: sortedcontainers==1.5.3 in /usr/loca",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:9334,modifiability,version,version,9334," is already the newest version (0.29.1-0ubuntu1). unzip is already the newest version (6.0-20ubuntu1). zip is already the newest version (3.0-11). curl is already the newest version (7.47.0-1ubuntu2.8). zlib1g-dev is already the newest version (1:1.2.8.dfsg-2ubuntu4.1). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install python packaging infrastructure' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. python-wheel is already the newest version (0.29.0-1). python-dev is already the newest version (2.7.12-1~16.04). python-pip is already the newest version (8.1.1-2ubuntu0.4). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. Requirement already up-to-date: pip in /usr/local/lib/python2.7/dist-packages (18.0). ========== [2018年 08月 28日 星期二 10:55:12 CST] Stage 'Install python packages' starting. Requirement already satisfied: contextlib2 in /usr/local/lib/python2.7/dist-packages (0.5.5). Requirement already satisfied: enum34 in /usr/local/lib/python2.7/dist-packages (1.1.6). Requirement already satisfied: sortedcontainers==1.5.3 in /usr/local/lib/python2.7/dist-packages (1.5.3). Requirement al",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:9393,modifiability,version,version,9393,"already the newest version (6.0-20ubuntu1). zip is already the newest version (3.0-11). curl is already the newest version (7.47.0-1ubuntu2.8). zlib1g-dev is already the newest version (1:1.2.8.dfsg-2ubuntu4.1). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install python packaging infrastructure' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. python-wheel is already the newest version (0.29.0-1). python-dev is already the newest version (2.7.12-1~16.04). python-pip is already the newest version (8.1.1-2ubuntu0.4). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. Requirement already up-to-date: pip in /usr/local/lib/python2.7/dist-packages (18.0). ========== [2018年 08月 28日 星期二 10:55:12 CST] Stage 'Install python packages' starting. Requirement already satisfied: contextlib2 in /usr/local/lib/python2.7/dist-packages (0.5.5). Requirement already satisfied: enum34 in /usr/local/lib/python2.7/dist-packages (1.1.6). Requirement already satisfied: sortedcontainers==1.5.3 in /usr/local/lib/python2.7/dist-packages (1.5.3). Requirement already satisfied: intervaltree in /usr/local/lib/python2.7/d",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:9435,modifiability,pac,packages,9435,". zip is already the newest version (3.0-11). curl is already the newest version (7.47.0-1ubuntu2.8). zlib1g-dev is already the newest version (1:1.2.8.dfsg-2ubuntu4.1). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install python packaging infrastructure' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. python-wheel is already the newest version (0.29.0-1). python-dev is already the newest version (2.7.12-1~16.04). python-pip is already the newest version (8.1.1-2ubuntu0.4). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. Requirement already up-to-date: pip in /usr/local/lib/python2.7/dist-packages (18.0). ========== [2018年 08月 28日 星期二 10:55:12 CST] Stage 'Install python packages' starting. Requirement already satisfied: contextlib2 in /usr/local/lib/python2.7/dist-packages (0.5.5). Requirement already satisfied: enum34 in /usr/local/lib/python2.7/dist-packages (1.1.6). Requirement already satisfied: sortedcontainers==1.5.3 in /usr/local/lib/python2.7/dist-packages (1.5.3). Requirement already satisfied: intervaltree in /usr/local/lib/python2.7/dist-packages (2.1.0). Requirement already ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:9681,modifiability,upgrad,upgraded,9681,"ed:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install python packaging infrastructure' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. python-wheel is already the newest version (0.29.0-1). python-dev is already the newest version (2.7.12-1~16.04). python-pip is already the newest version (8.1.1-2ubuntu0.4). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. Requirement already up-to-date: pip in /usr/local/lib/python2.7/dist-packages (18.0). ========== [2018年 08月 28日 星期二 10:55:12 CST] Stage 'Install python packages' starting. Requirement already satisfied: contextlib2 in /usr/local/lib/python2.7/dist-packages (0.5.5). Requirement already satisfied: enum34 in /usr/local/lib/python2.7/dist-packages (1.1.6). Requirement already satisfied: sortedcontainers==1.5.3 in /usr/local/lib/python2.7/dist-packages (1.5.3). Requirement already satisfied: intervaltree in /usr/local/lib/python2.7/dist-packages (2.1.0). Requirement already satisfied: sortedcontainers in /usr/local/lib/python2.7/dist-packages (from intervaltree) (1.5.3). Requirement already satisfied: mock>=2.0.0 in /usr/local/lib/python2.7/dist-packages (2.0.0). Requirement already satisfied: pbr>=0.11 in /usr/loca",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:9732,modifiability,upgrad,upgraded,9732,"rs-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install python packaging infrastructure' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. python-wheel is already the newest version (0.29.0-1). python-dev is already the newest version (2.7.12-1~16.04). python-pip is already the newest version (8.1.1-2ubuntu0.4). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. Requirement already up-to-date: pip in /usr/local/lib/python2.7/dist-packages (18.0). ========== [2018年 08月 28日 星期二 10:55:12 CST] Stage 'Install python packages' starting. Requirement already satisfied: contextlib2 in /usr/local/lib/python2.7/dist-packages (0.5.5). Requirement already satisfied: enum34 in /usr/local/lib/python2.7/dist-packages (1.1.6). Requirement already satisfied: sortedcontainers==1.5.3 in /usr/local/lib/python2.7/dist-packages (1.5.3). Requirement already satisfied: intervaltree in /usr/local/lib/python2.7/dist-packages (2.1.0). Requirement already satisfied: sortedcontainers in /usr/local/lib/python2.7/dist-packages (from intervaltree) (1.5.3). Requirement already satisfied: mock>=2.0.0 in /usr/local/lib/python2.7/dist-packages (2.0.0). Requirement already satisfied: pbr>=0.11 in /usr/local/lib/python2.7/dist-packages (from mock>=2.0.0) (4",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:9852,modifiability,extens,extension,9852,"ove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install python packaging infrastructure' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. python-wheel is already the newest version (0.29.0-1). python-dev is already the newest version (2.7.12-1~16.04). python-pip is already the newest version (8.1.1-2ubuntu0.4). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. Requirement already up-to-date: pip in /usr/local/lib/python2.7/dist-packages (18.0). ========== [2018年 08月 28日 星期二 10:55:12 CST] Stage 'Install python packages' starting. Requirement already satisfied: contextlib2 in /usr/local/lib/python2.7/dist-packages (0.5.5). Requirement already satisfied: enum34 in /usr/local/lib/python2.7/dist-packages (1.1.6). Requirement already satisfied: sortedcontainers==1.5.3 in /usr/local/lib/python2.7/dist-packages (1.5.3). Requirement already satisfied: intervaltree in /usr/local/lib/python2.7/dist-packages (2.1.0). Requirement already satisfied: sortedcontainers in /usr/local/lib/python2.7/dist-packages (from intervaltree) (1.5.3). Requirement already satisfied: mock>=2.0.0 in /usr/local/lib/python2.7/dist-packages (2.0.0). Requirement already satisfied: pbr>=0.11 in /usr/local/lib/python2.7/dist-packages (from mock>=2.0.0) (4.2.0). Requirement already satisfied: funcsigs>=1; python_version < ""3.3"" in /usr/local/lib/python2.7/dist-packages (from",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:9932,modifiability,pac,packages,9932,"oring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install python packaging infrastructure' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. python-wheel is already the newest version (0.29.0-1). python-dev is already the newest version (2.7.12-1~16.04). python-pip is already the newest version (8.1.1-2ubuntu0.4). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. Requirement already up-to-date: pip in /usr/local/lib/python2.7/dist-packages (18.0). ========== [2018年 08月 28日 星期二 10:55:12 CST] Stage 'Install python packages' starting. Requirement already satisfied: contextlib2 in /usr/local/lib/python2.7/dist-packages (0.5.5). Requirement already satisfied: enum34 in /usr/local/lib/python2.7/dist-packages (1.1.6). Requirement already satisfied: sortedcontainers==1.5.3 in /usr/local/lib/python2.7/dist-packages (1.5.3). Requirement already satisfied: intervaltree in /usr/local/lib/python2.7/dist-packages (2.1.0). Requirement already satisfied: sortedcontainers in /usr/local/lib/python2.7/dist-packages (from intervaltree) (1.5.3). Requirement already satisfied: mock>=2.0.0 in /usr/local/lib/python2.7/dist-packages (2.0.0). Requirement already satisfied: pbr>=0.11 in /usr/local/lib/python2.7/dist-packages (from mock>=2.0.0) (4.2.0). Requirement already satisfied: funcsigs>=1; python_version < ""3.3"" in /usr/local/lib/python2.7/dist-packages (from mock>=2.0.0) (1.0.2). Requirement already satisfied: six>=1.9 in /usr/local/li",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:10015,modifiability,pac,packages,10015," an invalid filename extension. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install python packaging infrastructure' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. python-wheel is already the newest version (0.29.0-1). python-dev is already the newest version (2.7.12-1~16.04). python-pip is already the newest version (8.1.1-2ubuntu0.4). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. Requirement already up-to-date: pip in /usr/local/lib/python2.7/dist-packages (18.0). ========== [2018年 08月 28日 星期二 10:55:12 CST] Stage 'Install python packages' starting. Requirement already satisfied: contextlib2 in /usr/local/lib/python2.7/dist-packages (0.5.5). Requirement already satisfied: enum34 in /usr/local/lib/python2.7/dist-packages (1.1.6). Requirement already satisfied: sortedcontainers==1.5.3 in /usr/local/lib/python2.7/dist-packages (1.5.3). Requirement already satisfied: intervaltree in /usr/local/lib/python2.7/dist-packages (2.1.0). Requirement already satisfied: sortedcontainers in /usr/local/lib/python2.7/dist-packages (from intervaltree) (1.5.3). Requirement already satisfied: mock>=2.0.0 in /usr/local/lib/python2.7/dist-packages (2.0.0). Requirement already satisfied: pbr>=0.11 in /usr/local/lib/python2.7/dist-packages (from mock>=2.0.0) (4.2.0). Requirement already satisfied: funcsigs>=1; python_version < ""3.3"" in /usr/local/lib/python2.7/dist-packages (from mock>=2.0.0) (1.0.2). Requirement already satisfied: six>=1.9 in /usr/local/lib/python2.7/dist-packages (from mock>=2.0.0) (1.11.0). Requirement already satisfie",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:10111,modifiability,pac,packages,10111,"n packaging infrastructure' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. python-wheel is already the newest version (0.29.0-1). python-dev is already the newest version (2.7.12-1~16.04). python-pip is already the newest version (8.1.1-2ubuntu0.4). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. Requirement already up-to-date: pip in /usr/local/lib/python2.7/dist-packages (18.0). ========== [2018年 08月 28日 星期二 10:55:12 CST] Stage 'Install python packages' starting. Requirement already satisfied: contextlib2 in /usr/local/lib/python2.7/dist-packages (0.5.5). Requirement already satisfied: enum34 in /usr/local/lib/python2.7/dist-packages (1.1.6). Requirement already satisfied: sortedcontainers==1.5.3 in /usr/local/lib/python2.7/dist-packages (1.5.3). Requirement already satisfied: intervaltree in /usr/local/lib/python2.7/dist-packages (2.1.0). Requirement already satisfied: sortedcontainers in /usr/local/lib/python2.7/dist-packages (from intervaltree) (1.5.3). Requirement already satisfied: mock>=2.0.0 in /usr/local/lib/python2.7/dist-packages (2.0.0). Requirement already satisfied: pbr>=0.11 in /usr/local/lib/python2.7/dist-packages (from mock>=2.0.0) (4.2.0). Requirement already satisfied: funcsigs>=1; python_version < ""3.3"" in /usr/local/lib/python2.7/dist-packages (from mock>=2.0.0) (1.0.2). Requirement already satisfied: six>=1.9 in /usr/local/lib/python2.7/dist-packages (from mock>=2.0.0) (1.11.0). Requirement already satisfied: numpy==1.14 in /usr/local/lib/python2.7/dist-packages (1.14.0). Requirement already satisfied",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:10200,modifiability,pac,packages,10200,"tree . Reading state information... Done. python-wheel is already the newest version (0.29.0-1). python-dev is already the newest version (2.7.12-1~16.04). python-pip is already the newest version (8.1.1-2ubuntu0.4). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. Requirement already up-to-date: pip in /usr/local/lib/python2.7/dist-packages (18.0). ========== [2018年 08月 28日 星期二 10:55:12 CST] Stage 'Install python packages' starting. Requirement already satisfied: contextlib2 in /usr/local/lib/python2.7/dist-packages (0.5.5). Requirement already satisfied: enum34 in /usr/local/lib/python2.7/dist-packages (1.1.6). Requirement already satisfied: sortedcontainers==1.5.3 in /usr/local/lib/python2.7/dist-packages (1.5.3). Requirement already satisfied: intervaltree in /usr/local/lib/python2.7/dist-packages (2.1.0). Requirement already satisfied: sortedcontainers in /usr/local/lib/python2.7/dist-packages (from intervaltree) (1.5.3). Requirement already satisfied: mock>=2.0.0 in /usr/local/lib/python2.7/dist-packages (2.0.0). Requirement already satisfied: pbr>=0.11 in /usr/local/lib/python2.7/dist-packages (from mock>=2.0.0) (4.2.0). Requirement already satisfied: funcsigs>=1; python_version < ""3.3"" in /usr/local/lib/python2.7/dist-packages (from mock>=2.0.0) (1.0.2). Requirement already satisfied: six>=1.9 in /usr/local/lib/python2.7/dist-packages (from mock>=2.0.0) (1.11.0). Requirement already satisfied: numpy==1.14 in /usr/local/lib/python2.7/dist-packages (1.14.0). Requirement already satisfied: requests>=2.18 in /usr/local/lib/python2.7/dist-packages (2.19.1). Requirement already ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:10306,modifiability,pac,packages,10306,"v is already the newest version (2.7.12-1~16.04). python-pip is already the newest version (8.1.1-2ubuntu0.4). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. Requirement already up-to-date: pip in /usr/local/lib/python2.7/dist-packages (18.0). ========== [2018年 08月 28日 星期二 10:55:12 CST] Stage 'Install python packages' starting. Requirement already satisfied: contextlib2 in /usr/local/lib/python2.7/dist-packages (0.5.5). Requirement already satisfied: enum34 in /usr/local/lib/python2.7/dist-packages (1.1.6). Requirement already satisfied: sortedcontainers==1.5.3 in /usr/local/lib/python2.7/dist-packages (1.5.3). Requirement already satisfied: intervaltree in /usr/local/lib/python2.7/dist-packages (2.1.0). Requirement already satisfied: sortedcontainers in /usr/local/lib/python2.7/dist-packages (from intervaltree) (1.5.3). Requirement already satisfied: mock>=2.0.0 in /usr/local/lib/python2.7/dist-packages (2.0.0). Requirement already satisfied: pbr>=0.11 in /usr/local/lib/python2.7/dist-packages (from mock>=2.0.0) (4.2.0). Requirement already satisfied: funcsigs>=1; python_version < ""3.3"" in /usr/local/lib/python2.7/dist-packages (from mock>=2.0.0) (1.0.2). Requirement already satisfied: six>=1.9 in /usr/local/lib/python2.7/dist-packages (from mock>=2.0.0) (1.11.0). Requirement already satisfied: numpy==1.14 in /usr/local/lib/python2.7/dist-packages (1.14.0). Requirement already satisfied: requests>=2.18 in /usr/local/lib/python2.7/dist-packages (2.19.1). Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python2.7/dist-packages (from requests>=2.18) (2018.8.13).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:10401,modifiability,pac,packages,10401,".1-2ubuntu0.4). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. Requirement already up-to-date: pip in /usr/local/lib/python2.7/dist-packages (18.0). ========== [2018年 08月 28日 星期二 10:55:12 CST] Stage 'Install python packages' starting. Requirement already satisfied: contextlib2 in /usr/local/lib/python2.7/dist-packages (0.5.5). Requirement already satisfied: enum34 in /usr/local/lib/python2.7/dist-packages (1.1.6). Requirement already satisfied: sortedcontainers==1.5.3 in /usr/local/lib/python2.7/dist-packages (1.5.3). Requirement already satisfied: intervaltree in /usr/local/lib/python2.7/dist-packages (2.1.0). Requirement already satisfied: sortedcontainers in /usr/local/lib/python2.7/dist-packages (from intervaltree) (1.5.3). Requirement already satisfied: mock>=2.0.0 in /usr/local/lib/python2.7/dist-packages (2.0.0). Requirement already satisfied: pbr>=0.11 in /usr/local/lib/python2.7/dist-packages (from mock>=2.0.0) (4.2.0). Requirement already satisfied: funcsigs>=1; python_version < ""3.3"" in /usr/local/lib/python2.7/dist-packages (from mock>=2.0.0) (1.0.2). Requirement already satisfied: six>=1.9 in /usr/local/lib/python2.7/dist-packages (from mock>=2.0.0) (1.11.0). Requirement already satisfied: numpy==1.14 in /usr/local/lib/python2.7/dist-packages (1.14.0). Requirement already satisfied: requests>=2.18 in /usr/local/lib/python2.7/dist-packages (2.19.1). Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python2.7/dist-packages (from requests>=2.18) (2018.8.13). Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python2.7/dist-packages",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:10500,modifiability,pac,packages,10500,"bllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. Requirement already up-to-date: pip in /usr/local/lib/python2.7/dist-packages (18.0). ========== [2018年 08月 28日 星期二 10:55:12 CST] Stage 'Install python packages' starting. Requirement already satisfied: contextlib2 in /usr/local/lib/python2.7/dist-packages (0.5.5). Requirement already satisfied: enum34 in /usr/local/lib/python2.7/dist-packages (1.1.6). Requirement already satisfied: sortedcontainers==1.5.3 in /usr/local/lib/python2.7/dist-packages (1.5.3). Requirement already satisfied: intervaltree in /usr/local/lib/python2.7/dist-packages (2.1.0). Requirement already satisfied: sortedcontainers in /usr/local/lib/python2.7/dist-packages (from intervaltree) (1.5.3). Requirement already satisfied: mock>=2.0.0 in /usr/local/lib/python2.7/dist-packages (2.0.0). Requirement already satisfied: pbr>=0.11 in /usr/local/lib/python2.7/dist-packages (from mock>=2.0.0) (4.2.0). Requirement already satisfied: funcsigs>=1; python_version < ""3.3"" in /usr/local/lib/python2.7/dist-packages (from mock>=2.0.0) (1.0.2). Requirement already satisfied: six>=1.9 in /usr/local/lib/python2.7/dist-packages (from mock>=2.0.0) (1.11.0). Requirement already satisfied: numpy==1.14 in /usr/local/lib/python2.7/dist-packages (1.14.0). Requirement already satisfied: requests>=2.18 in /usr/local/lib/python2.7/dist-packages (2.19.1). Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python2.7/dist-packages (from requests>=2.18) (2018.8.13). Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python2.7/dist-packages (from requests>=2.18) (3.0.4). Requirement already satisfied: urllib3<1.24,>=1.21.1 in /usr/local/",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:10614,modifiability,pac,packages,10614,"4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. Requirement already up-to-date: pip in /usr/local/lib/python2.7/dist-packages (18.0). ========== [2018年 08月 28日 星期二 10:55:12 CST] Stage 'Install python packages' starting. Requirement already satisfied: contextlib2 in /usr/local/lib/python2.7/dist-packages (0.5.5). Requirement already satisfied: enum34 in /usr/local/lib/python2.7/dist-packages (1.1.6). Requirement already satisfied: sortedcontainers==1.5.3 in /usr/local/lib/python2.7/dist-packages (1.5.3). Requirement already satisfied: intervaltree in /usr/local/lib/python2.7/dist-packages (2.1.0). Requirement already satisfied: sortedcontainers in /usr/local/lib/python2.7/dist-packages (from intervaltree) (1.5.3). Requirement already satisfied: mock>=2.0.0 in /usr/local/lib/python2.7/dist-packages (2.0.0). Requirement already satisfied: pbr>=0.11 in /usr/local/lib/python2.7/dist-packages (from mock>=2.0.0) (4.2.0). Requirement already satisfied: funcsigs>=1; python_version < ""3.3"" in /usr/local/lib/python2.7/dist-packages (from mock>=2.0.0) (1.0.2). Requirement already satisfied: six>=1.9 in /usr/local/lib/python2.7/dist-packages (from mock>=2.0.0) (1.11.0). Requirement already satisfied: numpy==1.14 in /usr/local/lib/python2.7/dist-packages (1.14.0). Requirement already satisfied: requests>=2.18 in /usr/local/lib/python2.7/dist-packages (2.19.1). Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python2.7/dist-packages (from requests>=2.18) (2018.8.13). Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python2.7/dist-packages (from requests>=2.18) (3.0.4). Requirement already satisfied: urllib3<1.24,>=1.21.1 in /usr/local/lib/python2.7/dist-packages (from requests>=2.18) (1.23). Requirement already satisfied: idna<2.8,>=2.5 in /usr/lo",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:10706,modifiability,pac,packages,10706,"0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. Requirement already up-to-date: pip in /usr/local/lib/python2.7/dist-packages (18.0). ========== [2018年 08月 28日 星期二 10:55:12 CST] Stage 'Install python packages' starting. Requirement already satisfied: contextlib2 in /usr/local/lib/python2.7/dist-packages (0.5.5). Requirement already satisfied: enum34 in /usr/local/lib/python2.7/dist-packages (1.1.6). Requirement already satisfied: sortedcontainers==1.5.3 in /usr/local/lib/python2.7/dist-packages (1.5.3). Requirement already satisfied: intervaltree in /usr/local/lib/python2.7/dist-packages (2.1.0). Requirement already satisfied: sortedcontainers in /usr/local/lib/python2.7/dist-packages (from intervaltree) (1.5.3). Requirement already satisfied: mock>=2.0.0 in /usr/local/lib/python2.7/dist-packages (2.0.0). Requirement already satisfied: pbr>=0.11 in /usr/local/lib/python2.7/dist-packages (from mock>=2.0.0) (4.2.0). Requirement already satisfied: funcsigs>=1; python_version < ""3.3"" in /usr/local/lib/python2.7/dist-packages (from mock>=2.0.0) (1.0.2). Requirement already satisfied: six>=1.9 in /usr/local/lib/python2.7/dist-packages (from mock>=2.0.0) (1.11.0). Requirement already satisfied: numpy==1.14 in /usr/local/lib/python2.7/dist-packages (1.14.0). Requirement already satisfied: requests>=2.18 in /usr/local/lib/python2.7/dist-packages (2.19.1). Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python2.7/dist-packages (from requests>=2.18) (2018.8.13). Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python2.7/dist-packages (from requests>=2.18) (3.0.4). Requirement already satisfied: urllib3<1.24,>=1.21.1 in /usr/local/lib/python2.7/dist-packages (from requests>=2.18) (1.23). Requirement already satisfied: idna<2.8,>=2.5 in /usr/local/lib/python2.7/dist-packages (from requests>=2.18) (2.7). Requirement already satisfied: ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:10843,modifiability,pac,packages,10843,"name extension. Requirement already up-to-date: pip in /usr/local/lib/python2.7/dist-packages (18.0). ========== [2018年 08月 28日 星期二 10:55:12 CST] Stage 'Install python packages' starting. Requirement already satisfied: contextlib2 in /usr/local/lib/python2.7/dist-packages (0.5.5). Requirement already satisfied: enum34 in /usr/local/lib/python2.7/dist-packages (1.1.6). Requirement already satisfied: sortedcontainers==1.5.3 in /usr/local/lib/python2.7/dist-packages (1.5.3). Requirement already satisfied: intervaltree in /usr/local/lib/python2.7/dist-packages (2.1.0). Requirement already satisfied: sortedcontainers in /usr/local/lib/python2.7/dist-packages (from intervaltree) (1.5.3). Requirement already satisfied: mock>=2.0.0 in /usr/local/lib/python2.7/dist-packages (2.0.0). Requirement already satisfied: pbr>=0.11 in /usr/local/lib/python2.7/dist-packages (from mock>=2.0.0) (4.2.0). Requirement already satisfied: funcsigs>=1; python_version < ""3.3"" in /usr/local/lib/python2.7/dist-packages (from mock>=2.0.0) (1.0.2). Requirement already satisfied: six>=1.9 in /usr/local/lib/python2.7/dist-packages (from mock>=2.0.0) (1.11.0). Requirement already satisfied: numpy==1.14 in /usr/local/lib/python2.7/dist-packages (1.14.0). Requirement already satisfied: requests>=2.18 in /usr/local/lib/python2.7/dist-packages (2.19.1). Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python2.7/dist-packages (from requests>=2.18) (2018.8.13). Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python2.7/dist-packages (from requests>=2.18) (3.0.4). Requirement already satisfied: urllib3<1.24,>=1.21.1 in /usr/local/lib/python2.7/dist-packages (from requests>=2.18) (1.23). Requirement already satisfied: idna<2.8,>=2.5 in /usr/local/lib/python2.7/dist-packages (from requests>=2.18) (2.7). Requirement already satisfied: scipy==1.0 in /usr/local/lib/python2.7/dist-packages (1.0.0). Requirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python2.7/dis",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:10953,modifiability,pac,packages,10953,"== [2018年 08月 28日 星期二 10:55:12 CST] Stage 'Install python packages' starting. Requirement already satisfied: contextlib2 in /usr/local/lib/python2.7/dist-packages (0.5.5). Requirement already satisfied: enum34 in /usr/local/lib/python2.7/dist-packages (1.1.6). Requirement already satisfied: sortedcontainers==1.5.3 in /usr/local/lib/python2.7/dist-packages (1.5.3). Requirement already satisfied: intervaltree in /usr/local/lib/python2.7/dist-packages (2.1.0). Requirement already satisfied: sortedcontainers in /usr/local/lib/python2.7/dist-packages (from intervaltree) (1.5.3). Requirement already satisfied: mock>=2.0.0 in /usr/local/lib/python2.7/dist-packages (2.0.0). Requirement already satisfied: pbr>=0.11 in /usr/local/lib/python2.7/dist-packages (from mock>=2.0.0) (4.2.0). Requirement already satisfied: funcsigs>=1; python_version < ""3.3"" in /usr/local/lib/python2.7/dist-packages (from mock>=2.0.0) (1.0.2). Requirement already satisfied: six>=1.9 in /usr/local/lib/python2.7/dist-packages (from mock>=2.0.0) (1.11.0). Requirement already satisfied: numpy==1.14 in /usr/local/lib/python2.7/dist-packages (1.14.0). Requirement already satisfied: requests>=2.18 in /usr/local/lib/python2.7/dist-packages (2.19.1). Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python2.7/dist-packages (from requests>=2.18) (2018.8.13). Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python2.7/dist-packages (from requests>=2.18) (3.0.4). Requirement already satisfied: urllib3<1.24,>=1.21.1 in /usr/local/lib/python2.7/dist-packages (from requests>=2.18) (1.23). Requirement already satisfied: idna<2.8,>=2.5 in /usr/local/lib/python2.7/dist-packages (from requests>=2.18) (2.7). Requirement already satisfied: scipy==1.0 in /usr/local/lib/python2.7/dist-packages (1.0.0). Requirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python2.7/dist-packages (from scipy==1.0) (1.14.0). Requirement already satisfied: oauth2client>=4.0.0 in /usr/local/lib/py",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:11067,modifiability,pac,packages,11067,"xtlib2 in /usr/local/lib/python2.7/dist-packages (0.5.5). Requirement already satisfied: enum34 in /usr/local/lib/python2.7/dist-packages (1.1.6). Requirement already satisfied: sortedcontainers==1.5.3 in /usr/local/lib/python2.7/dist-packages (1.5.3). Requirement already satisfied: intervaltree in /usr/local/lib/python2.7/dist-packages (2.1.0). Requirement already satisfied: sortedcontainers in /usr/local/lib/python2.7/dist-packages (from intervaltree) (1.5.3). Requirement already satisfied: mock>=2.0.0 in /usr/local/lib/python2.7/dist-packages (2.0.0). Requirement already satisfied: pbr>=0.11 in /usr/local/lib/python2.7/dist-packages (from mock>=2.0.0) (4.2.0). Requirement already satisfied: funcsigs>=1; python_version < ""3.3"" in /usr/local/lib/python2.7/dist-packages (from mock>=2.0.0) (1.0.2). Requirement already satisfied: six>=1.9 in /usr/local/lib/python2.7/dist-packages (from mock>=2.0.0) (1.11.0). Requirement already satisfied: numpy==1.14 in /usr/local/lib/python2.7/dist-packages (1.14.0). Requirement already satisfied: requests>=2.18 in /usr/local/lib/python2.7/dist-packages (2.19.1). Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python2.7/dist-packages (from requests>=2.18) (2018.8.13). Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python2.7/dist-packages (from requests>=2.18) (3.0.4). Requirement already satisfied: urllib3<1.24,>=1.21.1 in /usr/local/lib/python2.7/dist-packages (from requests>=2.18) (1.23). Requirement already satisfied: idna<2.8,>=2.5 in /usr/local/lib/python2.7/dist-packages (from requests>=2.18) (2.7). Requirement already satisfied: scipy==1.0 in /usr/local/lib/python2.7/dist-packages (1.0.0). Requirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python2.7/dist-packages (from scipy==1.0) (1.14.0). Requirement already satisfied: oauth2client>=4.0.0 in /usr/local/lib/python2.7/dist-packages (4.1.2). Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python2.7/dist-packa",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:11165,modifiability,pac,packages,11165," /usr/local/lib/python2.7/dist-packages (1.1.6). Requirement already satisfied: sortedcontainers==1.5.3 in /usr/local/lib/python2.7/dist-packages (1.5.3). Requirement already satisfied: intervaltree in /usr/local/lib/python2.7/dist-packages (2.1.0). Requirement already satisfied: sortedcontainers in /usr/local/lib/python2.7/dist-packages (from intervaltree) (1.5.3). Requirement already satisfied: mock>=2.0.0 in /usr/local/lib/python2.7/dist-packages (2.0.0). Requirement already satisfied: pbr>=0.11 in /usr/local/lib/python2.7/dist-packages (from mock>=2.0.0) (4.2.0). Requirement already satisfied: funcsigs>=1; python_version < ""3.3"" in /usr/local/lib/python2.7/dist-packages (from mock>=2.0.0) (1.0.2). Requirement already satisfied: six>=1.9 in /usr/local/lib/python2.7/dist-packages (from mock>=2.0.0) (1.11.0). Requirement already satisfied: numpy==1.14 in /usr/local/lib/python2.7/dist-packages (1.14.0). Requirement already satisfied: requests>=2.18 in /usr/local/lib/python2.7/dist-packages (2.19.1). Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python2.7/dist-packages (from requests>=2.18) (2018.8.13). Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python2.7/dist-packages (from requests>=2.18) (3.0.4). Requirement already satisfied: urllib3<1.24,>=1.21.1 in /usr/local/lib/python2.7/dist-packages (from requests>=2.18) (1.23). Requirement already satisfied: idna<2.8,>=2.5 in /usr/local/lib/python2.7/dist-packages (from requests>=2.18) (2.7). Requirement already satisfied: scipy==1.0 in /usr/local/lib/python2.7/dist-packages (1.0.0). Requirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python2.7/dist-packages (from scipy==1.0) (1.14.0). Requirement already satisfied: oauth2client>=4.0.0 in /usr/local/lib/python2.7/dist-packages (4.1.2). Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python2.7/dist-packages (from oauth2client>=4.0.0) (0.4.4). Requirement already satisfied: pyasn1-modules>=0.0.5 in /u",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:11267,modifiability,pac,packages,11267,"3 in /usr/local/lib/python2.7/dist-packages (1.5.3). Requirement already satisfied: intervaltree in /usr/local/lib/python2.7/dist-packages (2.1.0). Requirement already satisfied: sortedcontainers in /usr/local/lib/python2.7/dist-packages (from intervaltree) (1.5.3). Requirement already satisfied: mock>=2.0.0 in /usr/local/lib/python2.7/dist-packages (2.0.0). Requirement already satisfied: pbr>=0.11 in /usr/local/lib/python2.7/dist-packages (from mock>=2.0.0) (4.2.0). Requirement already satisfied: funcsigs>=1; python_version < ""3.3"" in /usr/local/lib/python2.7/dist-packages (from mock>=2.0.0) (1.0.2). Requirement already satisfied: six>=1.9 in /usr/local/lib/python2.7/dist-packages (from mock>=2.0.0) (1.11.0). Requirement already satisfied: numpy==1.14 in /usr/local/lib/python2.7/dist-packages (1.14.0). Requirement already satisfied: requests>=2.18 in /usr/local/lib/python2.7/dist-packages (2.19.1). Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python2.7/dist-packages (from requests>=2.18) (2018.8.13). Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python2.7/dist-packages (from requests>=2.18) (3.0.4). Requirement already satisfied: urllib3<1.24,>=1.21.1 in /usr/local/lib/python2.7/dist-packages (from requests>=2.18) (1.23). Requirement already satisfied: idna<2.8,>=2.5 in /usr/local/lib/python2.7/dist-packages (from requests>=2.18) (2.7). Requirement already satisfied: scipy==1.0 in /usr/local/lib/python2.7/dist-packages (1.0.0). Requirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python2.7/dist-packages (from scipy==1.0) (1.14.0). Requirement already satisfied: oauth2client>=4.0.0 in /usr/local/lib/python2.7/dist-packages (4.1.2). Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python2.7/dist-packages (from oauth2client>=4.0.0) (0.4.4). Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python2.7/dist-packages (from oauth2client>=4.0.0) (0.2.2). Requirement already satisfied",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:11397,modifiability,pac,packages,11397,"packages (2.1.0). Requirement already satisfied: sortedcontainers in /usr/local/lib/python2.7/dist-packages (from intervaltree) (1.5.3). Requirement already satisfied: mock>=2.0.0 in /usr/local/lib/python2.7/dist-packages (2.0.0). Requirement already satisfied: pbr>=0.11 in /usr/local/lib/python2.7/dist-packages (from mock>=2.0.0) (4.2.0). Requirement already satisfied: funcsigs>=1; python_version < ""3.3"" in /usr/local/lib/python2.7/dist-packages (from mock>=2.0.0) (1.0.2). Requirement already satisfied: six>=1.9 in /usr/local/lib/python2.7/dist-packages (from mock>=2.0.0) (1.11.0). Requirement already satisfied: numpy==1.14 in /usr/local/lib/python2.7/dist-packages (1.14.0). Requirement already satisfied: requests>=2.18 in /usr/local/lib/python2.7/dist-packages (2.19.1). Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python2.7/dist-packages (from requests>=2.18) (2018.8.13). Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python2.7/dist-packages (from requests>=2.18) (3.0.4). Requirement already satisfied: urllib3<1.24,>=1.21.1 in /usr/local/lib/python2.7/dist-packages (from requests>=2.18) (1.23). Requirement already satisfied: idna<2.8,>=2.5 in /usr/local/lib/python2.7/dist-packages (from requests>=2.18) (2.7). Requirement already satisfied: scipy==1.0 in /usr/local/lib/python2.7/dist-packages (1.0.0). Requirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python2.7/dist-packages (from scipy==1.0) (1.14.0). Requirement already satisfied: oauth2client>=4.0.0 in /usr/local/lib/python2.7/dist-packages (4.1.2). Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python2.7/dist-packages (from oauth2client>=4.0.0) (0.4.4). Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python2.7/dist-packages (from oauth2client>=4.0.0) (0.2.2). Requirement already satisfied: six>=1.6.1 in /usr/local/lib/python2.7/dist-packages (from oauth2client>=4.0.0) (1.11.0). Requirement already satisfied: httplib",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:11523,modifiability,pac,packages,11523,") (1.5.3). Requirement already satisfied: mock>=2.0.0 in /usr/local/lib/python2.7/dist-packages (2.0.0). Requirement already satisfied: pbr>=0.11 in /usr/local/lib/python2.7/dist-packages (from mock>=2.0.0) (4.2.0). Requirement already satisfied: funcsigs>=1; python_version < ""3.3"" in /usr/local/lib/python2.7/dist-packages (from mock>=2.0.0) (1.0.2). Requirement already satisfied: six>=1.9 in /usr/local/lib/python2.7/dist-packages (from mock>=2.0.0) (1.11.0). Requirement already satisfied: numpy==1.14 in /usr/local/lib/python2.7/dist-packages (1.14.0). Requirement already satisfied: requests>=2.18 in /usr/local/lib/python2.7/dist-packages (2.19.1). Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python2.7/dist-packages (from requests>=2.18) (2018.8.13). Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python2.7/dist-packages (from requests>=2.18) (3.0.4). Requirement already satisfied: urllib3<1.24,>=1.21.1 in /usr/local/lib/python2.7/dist-packages (from requests>=2.18) (1.23). Requirement already satisfied: idna<2.8,>=2.5 in /usr/local/lib/python2.7/dist-packages (from requests>=2.18) (2.7). Requirement already satisfied: scipy==1.0 in /usr/local/lib/python2.7/dist-packages (1.0.0). Requirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python2.7/dist-packages (from scipy==1.0) (1.14.0). Requirement already satisfied: oauth2client>=4.0.0 in /usr/local/lib/python2.7/dist-packages (4.1.2). Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python2.7/dist-packages (from oauth2client>=4.0.0) (0.4.4). Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python2.7/dist-packages (from oauth2client>=4.0.0) (0.2.2). Requirement already satisfied: six>=1.6.1 in /usr/local/lib/python2.7/dist-packages (from oauth2client>=4.0.0) (1.11.0). Requirement already satisfied: httplib2>=0.9.1 in /usr/local/lib/python2.7/dist-packages (from oauth2client>=4.0.0) (0.11.3). Requirement already satisfied: rsa>=3.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:11641,modifiability,pac,packages,11641,"lready satisfied: pbr>=0.11 in /usr/local/lib/python2.7/dist-packages (from mock>=2.0.0) (4.2.0). Requirement already satisfied: funcsigs>=1; python_version < ""3.3"" in /usr/local/lib/python2.7/dist-packages (from mock>=2.0.0) (1.0.2). Requirement already satisfied: six>=1.9 in /usr/local/lib/python2.7/dist-packages (from mock>=2.0.0) (1.11.0). Requirement already satisfied: numpy==1.14 in /usr/local/lib/python2.7/dist-packages (1.14.0). Requirement already satisfied: requests>=2.18 in /usr/local/lib/python2.7/dist-packages (2.19.1). Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python2.7/dist-packages (from requests>=2.18) (2018.8.13). Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python2.7/dist-packages (from requests>=2.18) (3.0.4). Requirement already satisfied: urllib3<1.24,>=1.21.1 in /usr/local/lib/python2.7/dist-packages (from requests>=2.18) (1.23). Requirement already satisfied: idna<2.8,>=2.5 in /usr/local/lib/python2.7/dist-packages (from requests>=2.18) (2.7). Requirement already satisfied: scipy==1.0 in /usr/local/lib/python2.7/dist-packages (1.0.0). Requirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python2.7/dist-packages (from scipy==1.0) (1.14.0). Requirement already satisfied: oauth2client>=4.0.0 in /usr/local/lib/python2.7/dist-packages (4.1.2). Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python2.7/dist-packages (from oauth2client>=4.0.0) (0.4.4). Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python2.7/dist-packages (from oauth2client>=4.0.0) (0.2.2). Requirement already satisfied: six>=1.6.1 in /usr/local/lib/python2.7/dist-packages (from oauth2client>=4.0.0) (1.11.0). Requirement already satisfied: httplib2>=0.9.1 in /usr/local/lib/python2.7/dist-packages (from oauth2client>=4.0.0) (0.11.3). Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python2.7/dist-packages (from oauth2client>=4.0.0) (3.4.2). Requirement already satisfied: crcmo",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:11754,modifiability,pac,packages,11754,"eady satisfied: funcsigs>=1; python_version < ""3.3"" in /usr/local/lib/python2.7/dist-packages (from mock>=2.0.0) (1.0.2). Requirement already satisfied: six>=1.9 in /usr/local/lib/python2.7/dist-packages (from mock>=2.0.0) (1.11.0). Requirement already satisfied: numpy==1.14 in /usr/local/lib/python2.7/dist-packages (1.14.0). Requirement already satisfied: requests>=2.18 in /usr/local/lib/python2.7/dist-packages (2.19.1). Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python2.7/dist-packages (from requests>=2.18) (2018.8.13). Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python2.7/dist-packages (from requests>=2.18) (3.0.4). Requirement already satisfied: urllib3<1.24,>=1.21.1 in /usr/local/lib/python2.7/dist-packages (from requests>=2.18) (1.23). Requirement already satisfied: idna<2.8,>=2.5 in /usr/local/lib/python2.7/dist-packages (from requests>=2.18) (2.7). Requirement already satisfied: scipy==1.0 in /usr/local/lib/python2.7/dist-packages (1.0.0). Requirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python2.7/dist-packages (from scipy==1.0) (1.14.0). Requirement already satisfied: oauth2client>=4.0.0 in /usr/local/lib/python2.7/dist-packages (4.1.2). Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python2.7/dist-packages (from oauth2client>=4.0.0) (0.4.4). Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python2.7/dist-packages (from oauth2client>=4.0.0) (0.2.2). Requirement already satisfied: six>=1.6.1 in /usr/local/lib/python2.7/dist-packages (from oauth2client>=4.0.0) (1.11.0). Requirement already satisfied: httplib2>=0.9.1 in /usr/local/lib/python2.7/dist-packages (from oauth2client>=4.0.0) (0.11.3). Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python2.7/dist-packages (from oauth2client>=4.0.0) (3.4.2). Requirement already satisfied: crcmod>=1.7 in /usr/local/lib/python2.7/dist-packages (1.7). Requirement already satisfied: six in /usr/local/lib/pyth",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:11849,modifiability,pac,packages,11849,"from mock>=2.0.0) (1.0.2). Requirement already satisfied: six>=1.9 in /usr/local/lib/python2.7/dist-packages (from mock>=2.0.0) (1.11.0). Requirement already satisfied: numpy==1.14 in /usr/local/lib/python2.7/dist-packages (1.14.0). Requirement already satisfied: requests>=2.18 in /usr/local/lib/python2.7/dist-packages (2.19.1). Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python2.7/dist-packages (from requests>=2.18) (2018.8.13). Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python2.7/dist-packages (from requests>=2.18) (3.0.4). Requirement already satisfied: urllib3<1.24,>=1.21.1 in /usr/local/lib/python2.7/dist-packages (from requests>=2.18) (1.23). Requirement already satisfied: idna<2.8,>=2.5 in /usr/local/lib/python2.7/dist-packages (from requests>=2.18) (2.7). Requirement already satisfied: scipy==1.0 in /usr/local/lib/python2.7/dist-packages (1.0.0). Requirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python2.7/dist-packages (from scipy==1.0) (1.14.0). Requirement already satisfied: oauth2client>=4.0.0 in /usr/local/lib/python2.7/dist-packages (4.1.2). Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python2.7/dist-packages (from oauth2client>=4.0.0) (0.4.4). Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python2.7/dist-packages (from oauth2client>=4.0.0) (0.2.2). Requirement already satisfied: six>=1.6.1 in /usr/local/lib/python2.7/dist-packages (from oauth2client>=4.0.0) (1.11.0). Requirement already satisfied: httplib2>=0.9.1 in /usr/local/lib/python2.7/dist-packages (from oauth2client>=4.0.0) (0.11.3). Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python2.7/dist-packages (from oauth2client>=4.0.0) (3.4.2). Requirement already satisfied: crcmod>=1.7 in /usr/local/lib/python2.7/dist-packages (1.7). Requirement already satisfied: six in /usr/local/lib/python2.7/dist-packages (1.11.0). Requirement already satisfied: sklearn in /usr/local/lib/python2.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:11970,modifiability,pac,packages,11970,"2.0.0) (1.11.0). Requirement already satisfied: numpy==1.14 in /usr/local/lib/python2.7/dist-packages (1.14.0). Requirement already satisfied: requests>=2.18 in /usr/local/lib/python2.7/dist-packages (2.19.1). Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python2.7/dist-packages (from requests>=2.18) (2018.8.13). Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python2.7/dist-packages (from requests>=2.18) (3.0.4). Requirement already satisfied: urllib3<1.24,>=1.21.1 in /usr/local/lib/python2.7/dist-packages (from requests>=2.18) (1.23). Requirement already satisfied: idna<2.8,>=2.5 in /usr/local/lib/python2.7/dist-packages (from requests>=2.18) (2.7). Requirement already satisfied: scipy==1.0 in /usr/local/lib/python2.7/dist-packages (1.0.0). Requirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python2.7/dist-packages (from scipy==1.0) (1.14.0). Requirement already satisfied: oauth2client>=4.0.0 in /usr/local/lib/python2.7/dist-packages (4.1.2). Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python2.7/dist-packages (from oauth2client>=4.0.0) (0.4.4). Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python2.7/dist-packages (from oauth2client>=4.0.0) (0.2.2). Requirement already satisfied: six>=1.6.1 in /usr/local/lib/python2.7/dist-packages (from oauth2client>=4.0.0) (1.11.0). Requirement already satisfied: httplib2>=0.9.1 in /usr/local/lib/python2.7/dist-packages (from oauth2client>=4.0.0) (0.11.3). Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python2.7/dist-packages (from oauth2client>=4.0.0) (3.4.2). Requirement already satisfied: crcmod>=1.7 in /usr/local/lib/python2.7/dist-packages (1.7). Requirement already satisfied: six in /usr/local/lib/python2.7/dist-packages (1.11.0). Requirement already satisfied: sklearn in /usr/local/lib/python2.7/dist-packages (0.0). Requirement already satisfied: scikit-learn in /usr/local/lib/python2.7/dist-packages (from sklear",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:12066,modifiability,pac,packages,12066,"kages (1.14.0). Requirement already satisfied: requests>=2.18 in /usr/local/lib/python2.7/dist-packages (2.19.1). Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python2.7/dist-packages (from requests>=2.18) (2018.8.13). Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python2.7/dist-packages (from requests>=2.18) (3.0.4). Requirement already satisfied: urllib3<1.24,>=1.21.1 in /usr/local/lib/python2.7/dist-packages (from requests>=2.18) (1.23). Requirement already satisfied: idna<2.8,>=2.5 in /usr/local/lib/python2.7/dist-packages (from requests>=2.18) (2.7). Requirement already satisfied: scipy==1.0 in /usr/local/lib/python2.7/dist-packages (1.0.0). Requirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python2.7/dist-packages (from scipy==1.0) (1.14.0). Requirement already satisfied: oauth2client>=4.0.0 in /usr/local/lib/python2.7/dist-packages (4.1.2). Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python2.7/dist-packages (from oauth2client>=4.0.0) (0.4.4). Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python2.7/dist-packages (from oauth2client>=4.0.0) (0.2.2). Requirement already satisfied: six>=1.6.1 in /usr/local/lib/python2.7/dist-packages (from oauth2client>=4.0.0) (1.11.0). Requirement already satisfied: httplib2>=0.9.1 in /usr/local/lib/python2.7/dist-packages (from oauth2client>=4.0.0) (0.11.3). Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python2.7/dist-packages (from oauth2client>=4.0.0) (3.4.2). Requirement already satisfied: crcmod>=1.7 in /usr/local/lib/python2.7/dist-packages (1.7). Requirement already satisfied: six in /usr/local/lib/python2.7/dist-packages (1.11.0). Requirement already satisfied: sklearn in /usr/local/lib/python2.7/dist-packages (0.0). Requirement already satisfied: scikit-learn in /usr/local/lib/python2.7/dist-packages (from sklearn) (0.19.2). Requirement already satisfied: pandas in /usr/local/lib/python2.7/dist-packages (0.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:12149,modifiability,modul,modules,12149,"hon2.7/dist-packages (2.19.1). Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python2.7/dist-packages (from requests>=2.18) (2018.8.13). Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python2.7/dist-packages (from requests>=2.18) (3.0.4). Requirement already satisfied: urllib3<1.24,>=1.21.1 in /usr/local/lib/python2.7/dist-packages (from requests>=2.18) (1.23). Requirement already satisfied: idna<2.8,>=2.5 in /usr/local/lib/python2.7/dist-packages (from requests>=2.18) (2.7). Requirement already satisfied: scipy==1.0 in /usr/local/lib/python2.7/dist-packages (1.0.0). Requirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python2.7/dist-packages (from scipy==1.0) (1.14.0). Requirement already satisfied: oauth2client>=4.0.0 in /usr/local/lib/python2.7/dist-packages (4.1.2). Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python2.7/dist-packages (from oauth2client>=4.0.0) (0.4.4). Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python2.7/dist-packages (from oauth2client>=4.0.0) (0.2.2). Requirement already satisfied: six>=1.6.1 in /usr/local/lib/python2.7/dist-packages (from oauth2client>=4.0.0) (1.11.0). Requirement already satisfied: httplib2>=0.9.1 in /usr/local/lib/python2.7/dist-packages (from oauth2client>=4.0.0) (0.11.3). Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python2.7/dist-packages (from oauth2client>=4.0.0) (3.4.2). Requirement already satisfied: crcmod>=1.7 in /usr/local/lib/python2.7/dist-packages (1.7). Requirement already satisfied: six in /usr/local/lib/python2.7/dist-packages (1.11.0). Requirement already satisfied: sklearn in /usr/local/lib/python2.7/dist-packages (0.0). Requirement already satisfied: scikit-learn in /usr/local/lib/python2.7/dist-packages (from sklearn) (0.19.2). Requirement already satisfied: pandas in /usr/local/lib/python2.7/dist-packages (0.23.4). Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python2.7/dist",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:12197,modifiability,pac,packages,12197,"dy satisfied: certifi>=2017.4.17 in /usr/local/lib/python2.7/dist-packages (from requests>=2.18) (2018.8.13). Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python2.7/dist-packages (from requests>=2.18) (3.0.4). Requirement already satisfied: urllib3<1.24,>=1.21.1 in /usr/local/lib/python2.7/dist-packages (from requests>=2.18) (1.23). Requirement already satisfied: idna<2.8,>=2.5 in /usr/local/lib/python2.7/dist-packages (from requests>=2.18) (2.7). Requirement already satisfied: scipy==1.0 in /usr/local/lib/python2.7/dist-packages (1.0.0). Requirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python2.7/dist-packages (from scipy==1.0) (1.14.0). Requirement already satisfied: oauth2client>=4.0.0 in /usr/local/lib/python2.7/dist-packages (4.1.2). Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python2.7/dist-packages (from oauth2client>=4.0.0) (0.4.4). Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python2.7/dist-packages (from oauth2client>=4.0.0) (0.2.2). Requirement already satisfied: six>=1.6.1 in /usr/local/lib/python2.7/dist-packages (from oauth2client>=4.0.0) (1.11.0). Requirement already satisfied: httplib2>=0.9.1 in /usr/local/lib/python2.7/dist-packages (from oauth2client>=4.0.0) (0.11.3). Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python2.7/dist-packages (from oauth2client>=4.0.0) (3.4.2). Requirement already satisfied: crcmod>=1.7 in /usr/local/lib/python2.7/dist-packages (1.7). Requirement already satisfied: six in /usr/local/lib/python2.7/dist-packages (1.11.0). Requirement already satisfied: sklearn in /usr/local/lib/python2.7/dist-packages (0.0). Requirement already satisfied: scikit-learn in /usr/local/lib/python2.7/dist-packages (from sklearn) (0.19.2). Requirement already satisfied: pandas in /usr/local/lib/python2.7/dist-packages (0.23.4). Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python2.7/dist-packages (from pandas) (1.14.0). Requirement al",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:12317,modifiability,pac,packages,12317,"t already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python2.7/dist-packages (from requests>=2.18) (3.0.4). Requirement already satisfied: urllib3<1.24,>=1.21.1 in /usr/local/lib/python2.7/dist-packages (from requests>=2.18) (1.23). Requirement already satisfied: idna<2.8,>=2.5 in /usr/local/lib/python2.7/dist-packages (from requests>=2.18) (2.7). Requirement already satisfied: scipy==1.0 in /usr/local/lib/python2.7/dist-packages (1.0.0). Requirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python2.7/dist-packages (from scipy==1.0) (1.14.0). Requirement already satisfied: oauth2client>=4.0.0 in /usr/local/lib/python2.7/dist-packages (4.1.2). Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python2.7/dist-packages (from oauth2client>=4.0.0) (0.4.4). Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python2.7/dist-packages (from oauth2client>=4.0.0) (0.2.2). Requirement already satisfied: six>=1.6.1 in /usr/local/lib/python2.7/dist-packages (from oauth2client>=4.0.0) (1.11.0). Requirement already satisfied: httplib2>=0.9.1 in /usr/local/lib/python2.7/dist-packages (from oauth2client>=4.0.0) (0.11.3). Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python2.7/dist-packages (from oauth2client>=4.0.0) (3.4.2). Requirement already satisfied: crcmod>=1.7 in /usr/local/lib/python2.7/dist-packages (1.7). Requirement already satisfied: six in /usr/local/lib/python2.7/dist-packages (1.11.0). Requirement already satisfied: sklearn in /usr/local/lib/python2.7/dist-packages (0.0). Requirement already satisfied: scikit-learn in /usr/local/lib/python2.7/dist-packages (from sklearn) (0.19.2). Requirement already satisfied: pandas in /usr/local/lib/python2.7/dist-packages (0.23.4). Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python2.7/dist-packages (from pandas) (1.14.0). Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python2.7/dist-packages (from pandas) (2.7.3). Requirement alr",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:12443,modifiability,pac,packages,12443,"t already satisfied: urllib3<1.24,>=1.21.1 in /usr/local/lib/python2.7/dist-packages (from requests>=2.18) (1.23). Requirement already satisfied: idna<2.8,>=2.5 in /usr/local/lib/python2.7/dist-packages (from requests>=2.18) (2.7). Requirement already satisfied: scipy==1.0 in /usr/local/lib/python2.7/dist-packages (1.0.0). Requirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python2.7/dist-packages (from scipy==1.0) (1.14.0). Requirement already satisfied: oauth2client>=4.0.0 in /usr/local/lib/python2.7/dist-packages (4.1.2). Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python2.7/dist-packages (from oauth2client>=4.0.0) (0.4.4). Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python2.7/dist-packages (from oauth2client>=4.0.0) (0.2.2). Requirement already satisfied: six>=1.6.1 in /usr/local/lib/python2.7/dist-packages (from oauth2client>=4.0.0) (1.11.0). Requirement already satisfied: httplib2>=0.9.1 in /usr/local/lib/python2.7/dist-packages (from oauth2client>=4.0.0) (0.11.3). Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python2.7/dist-packages (from oauth2client>=4.0.0) (3.4.2). Requirement already satisfied: crcmod>=1.7 in /usr/local/lib/python2.7/dist-packages (1.7). Requirement already satisfied: six in /usr/local/lib/python2.7/dist-packages (1.11.0). Requirement already satisfied: sklearn in /usr/local/lib/python2.7/dist-packages (0.0). Requirement already satisfied: scikit-learn in /usr/local/lib/python2.7/dist-packages (from sklearn) (0.19.2). Requirement already satisfied: pandas in /usr/local/lib/python2.7/dist-packages (0.23.4). Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python2.7/dist-packages (from pandas) (1.14.0). Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python2.7/dist-packages (from pandas) (2.7.3). Requirement already satisfied: pytz>=2011k in /usr/local/lib/python2.7/dist-packages (from pandas) (2018.5). Requirement already satisfied: s",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:12564,modifiability,pac,packages,12564,"ement already satisfied: idna<2.8,>=2.5 in /usr/local/lib/python2.7/dist-packages (from requests>=2.18) (2.7). Requirement already satisfied: scipy==1.0 in /usr/local/lib/python2.7/dist-packages (1.0.0). Requirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python2.7/dist-packages (from scipy==1.0) (1.14.0). Requirement already satisfied: oauth2client>=4.0.0 in /usr/local/lib/python2.7/dist-packages (4.1.2). Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python2.7/dist-packages (from oauth2client>=4.0.0) (0.4.4). Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python2.7/dist-packages (from oauth2client>=4.0.0) (0.2.2). Requirement already satisfied: six>=1.6.1 in /usr/local/lib/python2.7/dist-packages (from oauth2client>=4.0.0) (1.11.0). Requirement already satisfied: httplib2>=0.9.1 in /usr/local/lib/python2.7/dist-packages (from oauth2client>=4.0.0) (0.11.3). Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python2.7/dist-packages (from oauth2client>=4.0.0) (3.4.2). Requirement already satisfied: crcmod>=1.7 in /usr/local/lib/python2.7/dist-packages (1.7). Requirement already satisfied: six in /usr/local/lib/python2.7/dist-packages (1.11.0). Requirement already satisfied: sklearn in /usr/local/lib/python2.7/dist-packages (0.0). Requirement already satisfied: scikit-learn in /usr/local/lib/python2.7/dist-packages (from sklearn) (0.19.2). Requirement already satisfied: pandas in /usr/local/lib/python2.7/dist-packages (0.23.4). Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python2.7/dist-packages (from pandas) (1.14.0). Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python2.7/dist-packages (from pandas) (2.7.3). Requirement already satisfied: pytz>=2011k in /usr/local/lib/python2.7/dist-packages (from pandas) (2018.5). Requirement already satisfied: six>=1.5 in /usr/local/lib/python2.7/dist-packages (from python-dateutil>=2.5.0->pandas) (1.11.0). Requirement already sat",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:12685,modifiability,pac,packages,12685,t already satisfied: scipy==1.0 in /usr/local/lib/python2.7/dist-packages (1.0.0). Requirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python2.7/dist-packages (from scipy==1.0) (1.14.0). Requirement already satisfied: oauth2client>=4.0.0 in /usr/local/lib/python2.7/dist-packages (4.1.2). Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python2.7/dist-packages (from oauth2client>=4.0.0) (0.4.4). Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python2.7/dist-packages (from oauth2client>=4.0.0) (0.2.2). Requirement already satisfied: six>=1.6.1 in /usr/local/lib/python2.7/dist-packages (from oauth2client>=4.0.0) (1.11.0). Requirement already satisfied: httplib2>=0.9.1 in /usr/local/lib/python2.7/dist-packages (from oauth2client>=4.0.0) (0.11.3). Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python2.7/dist-packages (from oauth2client>=4.0.0) (3.4.2). Requirement already satisfied: crcmod>=1.7 in /usr/local/lib/python2.7/dist-packages (1.7). Requirement already satisfied: six in /usr/local/lib/python2.7/dist-packages (1.11.0). Requirement already satisfied: sklearn in /usr/local/lib/python2.7/dist-packages (0.0). Requirement already satisfied: scikit-learn in /usr/local/lib/python2.7/dist-packages (from sklearn) (0.19.2). Requirement already satisfied: pandas in /usr/local/lib/python2.7/dist-packages (0.23.4). Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python2.7/dist-packages (from pandas) (1.14.0). Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python2.7/dist-packages (from pandas) (2.7.3). Requirement already satisfied: pytz>=2011k in /usr/local/lib/python2.7/dist-packages (from pandas) (2018.5). Requirement already satisfied: six>=1.5 in /usr/local/lib/python2.7/dist-packages (from python-dateutil>=2.5.0->pandas) (1.11.0). Requirement already satisfied: psutil in /usr/local/lib/python2.7/dist-packages (5.4.7). Requirement already up-to-date: google-api-python-clien,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:12769,modifiability,pac,packages,12769,"equirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python2.7/dist-packages (from scipy==1.0) (1.14.0). Requirement already satisfied: oauth2client>=4.0.0 in /usr/local/lib/python2.7/dist-packages (4.1.2). Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python2.7/dist-packages (from oauth2client>=4.0.0) (0.4.4). Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python2.7/dist-packages (from oauth2client>=4.0.0) (0.2.2). Requirement already satisfied: six>=1.6.1 in /usr/local/lib/python2.7/dist-packages (from oauth2client>=4.0.0) (1.11.0). Requirement already satisfied: httplib2>=0.9.1 in /usr/local/lib/python2.7/dist-packages (from oauth2client>=4.0.0) (0.11.3). Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python2.7/dist-packages (from oauth2client>=4.0.0) (3.4.2). Requirement already satisfied: crcmod>=1.7 in /usr/local/lib/python2.7/dist-packages (1.7). Requirement already satisfied: six in /usr/local/lib/python2.7/dist-packages (1.11.0). Requirement already satisfied: sklearn in /usr/local/lib/python2.7/dist-packages (0.0). Requirement already satisfied: scikit-learn in /usr/local/lib/python2.7/dist-packages (from sklearn) (0.19.2). Requirement already satisfied: pandas in /usr/local/lib/python2.7/dist-packages (0.23.4). Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python2.7/dist-packages (from pandas) (1.14.0). Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python2.7/dist-packages (from pandas) (2.7.3). Requirement already satisfied: pytz>=2011k in /usr/local/lib/python2.7/dist-packages (from pandas) (2018.5). Requirement already satisfied: six>=1.5 in /usr/local/lib/python2.7/dist-packages (from python-dateutil>=2.5.0->pandas) (1.11.0). Requirement already satisfied: psutil in /usr/local/lib/python2.7/dist-packages (5.4.7). Requirement already up-to-date: google-api-python-client in /usr/local/lib/python2.7/dist-packages (1.7.4). Requirement already satisfied, ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:12860,modifiability,pac,packages,12860,"scipy==1.0) (1.14.0). Requirement already satisfied: oauth2client>=4.0.0 in /usr/local/lib/python2.7/dist-packages (4.1.2). Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python2.7/dist-packages (from oauth2client>=4.0.0) (0.4.4). Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python2.7/dist-packages (from oauth2client>=4.0.0) (0.2.2). Requirement already satisfied: six>=1.6.1 in /usr/local/lib/python2.7/dist-packages (from oauth2client>=4.0.0) (1.11.0). Requirement already satisfied: httplib2>=0.9.1 in /usr/local/lib/python2.7/dist-packages (from oauth2client>=4.0.0) (0.11.3). Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python2.7/dist-packages (from oauth2client>=4.0.0) (3.4.2). Requirement already satisfied: crcmod>=1.7 in /usr/local/lib/python2.7/dist-packages (1.7). Requirement already satisfied: six in /usr/local/lib/python2.7/dist-packages (1.11.0). Requirement already satisfied: sklearn in /usr/local/lib/python2.7/dist-packages (0.0). Requirement already satisfied: scikit-learn in /usr/local/lib/python2.7/dist-packages (from sklearn) (0.19.2). Requirement already satisfied: pandas in /usr/local/lib/python2.7/dist-packages (0.23.4). Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python2.7/dist-packages (from pandas) (1.14.0). Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python2.7/dist-packages (from pandas) (2.7.3). Requirement already satisfied: pytz>=2011k in /usr/local/lib/python2.7/dist-packages (from pandas) (2018.5). Requirement already satisfied: six>=1.5 in /usr/local/lib/python2.7/dist-packages (from python-dateutil>=2.5.0->pandas) (1.11.0). Requirement already satisfied: psutil in /usr/local/lib/python2.7/dist-packages (5.4.7). Requirement already up-to-date: google-api-python-client in /usr/local/lib/python2.7/dist-packages (1.7.4). Requirement already satisfied, skipping upgrade: httplib2<1dev,>=0.9.2 in /usr/local/lib/python2.7/dist-packages (from goo",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:12953,modifiability,pac,packages,12953,"thon2.7/dist-packages (4.1.2). Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python2.7/dist-packages (from oauth2client>=4.0.0) (0.4.4). Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python2.7/dist-packages (from oauth2client>=4.0.0) (0.2.2). Requirement already satisfied: six>=1.6.1 in /usr/local/lib/python2.7/dist-packages (from oauth2client>=4.0.0) (1.11.0). Requirement already satisfied: httplib2>=0.9.1 in /usr/local/lib/python2.7/dist-packages (from oauth2client>=4.0.0) (0.11.3). Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python2.7/dist-packages (from oauth2client>=4.0.0) (3.4.2). Requirement already satisfied: crcmod>=1.7 in /usr/local/lib/python2.7/dist-packages (1.7). Requirement already satisfied: six in /usr/local/lib/python2.7/dist-packages (1.11.0). Requirement already satisfied: sklearn in /usr/local/lib/python2.7/dist-packages (0.0). Requirement already satisfied: scikit-learn in /usr/local/lib/python2.7/dist-packages (from sklearn) (0.19.2). Requirement already satisfied: pandas in /usr/local/lib/python2.7/dist-packages (0.23.4). Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python2.7/dist-packages (from pandas) (1.14.0). Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python2.7/dist-packages (from pandas) (2.7.3). Requirement already satisfied: pytz>=2011k in /usr/local/lib/python2.7/dist-packages (from pandas) (2018.5). Requirement already satisfied: six>=1.5 in /usr/local/lib/python2.7/dist-packages (from python-dateutil>=2.5.0->pandas) (1.11.0). Requirement already satisfied: psutil in /usr/local/lib/python2.7/dist-packages (5.4.7). Requirement already up-to-date: google-api-python-client in /usr/local/lib/python2.7/dist-packages (1.7.4). Requirement already satisfied, skipping upgrade: httplib2<1dev,>=0.9.2 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.11.3). Requirement already satisfied, skipping upgrade: uritemplate",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:13058,modifiability,pac,packages,13058,"ist-packages (from oauth2client>=4.0.0) (0.4.4). Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python2.7/dist-packages (from oauth2client>=4.0.0) (0.2.2). Requirement already satisfied: six>=1.6.1 in /usr/local/lib/python2.7/dist-packages (from oauth2client>=4.0.0) (1.11.0). Requirement already satisfied: httplib2>=0.9.1 in /usr/local/lib/python2.7/dist-packages (from oauth2client>=4.0.0) (0.11.3). Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python2.7/dist-packages (from oauth2client>=4.0.0) (3.4.2). Requirement already satisfied: crcmod>=1.7 in /usr/local/lib/python2.7/dist-packages (1.7). Requirement already satisfied: six in /usr/local/lib/python2.7/dist-packages (1.11.0). Requirement already satisfied: sklearn in /usr/local/lib/python2.7/dist-packages (0.0). Requirement already satisfied: scikit-learn in /usr/local/lib/python2.7/dist-packages (from sklearn) (0.19.2). Requirement already satisfied: pandas in /usr/local/lib/python2.7/dist-packages (0.23.4). Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python2.7/dist-packages (from pandas) (1.14.0). Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python2.7/dist-packages (from pandas) (2.7.3). Requirement already satisfied: pytz>=2011k in /usr/local/lib/python2.7/dist-packages (from pandas) (2018.5). Requirement already satisfied: six>=1.5 in /usr/local/lib/python2.7/dist-packages (from python-dateutil>=2.5.0->pandas) (1.11.0). Requirement already satisfied: psutil in /usr/local/lib/python2.7/dist-packages (5.4.7). Requirement already up-to-date: google-api-python-client in /usr/local/lib/python2.7/dist-packages (1.7.4). Requirement already satisfied, skipping upgrade: httplib2<1dev,>=0.9.2 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.11.3). Requirement already satisfied, skipping upgrade: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (3.0.0). Requirem",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:13154,modifiability,pac,packages,13154,"0.0.5 in /usr/local/lib/python2.7/dist-packages (from oauth2client>=4.0.0) (0.2.2). Requirement already satisfied: six>=1.6.1 in /usr/local/lib/python2.7/dist-packages (from oauth2client>=4.0.0) (1.11.0). Requirement already satisfied: httplib2>=0.9.1 in /usr/local/lib/python2.7/dist-packages (from oauth2client>=4.0.0) (0.11.3). Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python2.7/dist-packages (from oauth2client>=4.0.0) (3.4.2). Requirement already satisfied: crcmod>=1.7 in /usr/local/lib/python2.7/dist-packages (1.7). Requirement already satisfied: six in /usr/local/lib/python2.7/dist-packages (1.11.0). Requirement already satisfied: sklearn in /usr/local/lib/python2.7/dist-packages (0.0). Requirement already satisfied: scikit-learn in /usr/local/lib/python2.7/dist-packages (from sklearn) (0.19.2). Requirement already satisfied: pandas in /usr/local/lib/python2.7/dist-packages (0.23.4). Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python2.7/dist-packages (from pandas) (1.14.0). Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python2.7/dist-packages (from pandas) (2.7.3). Requirement already satisfied: pytz>=2011k in /usr/local/lib/python2.7/dist-packages (from pandas) (2018.5). Requirement already satisfied: six>=1.5 in /usr/local/lib/python2.7/dist-packages (from python-dateutil>=2.5.0->pandas) (1.11.0). Requirement already satisfied: psutil in /usr/local/lib/python2.7/dist-packages (5.4.7). Requirement already up-to-date: google-api-python-client in /usr/local/lib/python2.7/dist-packages (1.7.4). Requirement already satisfied, skipping upgrade: httplib2<1dev,>=0.9.2 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.11.3). Requirement already satisfied, skipping upgrade: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (3.0.0). Requirement already satisfied, skipping upgrade: google-auth-httplib2>=0.0.3 in /usr/local/lib/python2.7",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:13274,modifiability,pac,packages,13274,"1.6.1 in /usr/local/lib/python2.7/dist-packages (from oauth2client>=4.0.0) (1.11.0). Requirement already satisfied: httplib2>=0.9.1 in /usr/local/lib/python2.7/dist-packages (from oauth2client>=4.0.0) (0.11.3). Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python2.7/dist-packages (from oauth2client>=4.0.0) (3.4.2). Requirement already satisfied: crcmod>=1.7 in /usr/local/lib/python2.7/dist-packages (1.7). Requirement already satisfied: six in /usr/local/lib/python2.7/dist-packages (1.11.0). Requirement already satisfied: sklearn in /usr/local/lib/python2.7/dist-packages (0.0). Requirement already satisfied: scikit-learn in /usr/local/lib/python2.7/dist-packages (from sklearn) (0.19.2). Requirement already satisfied: pandas in /usr/local/lib/python2.7/dist-packages (0.23.4). Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python2.7/dist-packages (from pandas) (1.14.0). Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python2.7/dist-packages (from pandas) (2.7.3). Requirement already satisfied: pytz>=2011k in /usr/local/lib/python2.7/dist-packages (from pandas) (2018.5). Requirement already satisfied: six>=1.5 in /usr/local/lib/python2.7/dist-packages (from python-dateutil>=2.5.0->pandas) (1.11.0). Requirement already satisfied: psutil in /usr/local/lib/python2.7/dist-packages (5.4.7). Requirement already up-to-date: google-api-python-client in /usr/local/lib/python2.7/dist-packages (1.7.4). Requirement already satisfied, skipping upgrade: httplib2<1dev,>=0.9.2 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.11.3). Requirement already satisfied, skipping upgrade: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (3.0.0). Requirement already satisfied, skipping upgrade: google-auth-httplib2>=0.0.3 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.0.3). Requirement already satisfied, skipping upgrade: six<2dev,>=1.6.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:13382,modifiability,pac,packages,13382,"isfied: httplib2>=0.9.1 in /usr/local/lib/python2.7/dist-packages (from oauth2client>=4.0.0) (0.11.3). Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python2.7/dist-packages (from oauth2client>=4.0.0) (3.4.2). Requirement already satisfied: crcmod>=1.7 in /usr/local/lib/python2.7/dist-packages (1.7). Requirement already satisfied: six in /usr/local/lib/python2.7/dist-packages (1.11.0). Requirement already satisfied: sklearn in /usr/local/lib/python2.7/dist-packages (0.0). Requirement already satisfied: scikit-learn in /usr/local/lib/python2.7/dist-packages (from sklearn) (0.19.2). Requirement already satisfied: pandas in /usr/local/lib/python2.7/dist-packages (0.23.4). Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python2.7/dist-packages (from pandas) (1.14.0). Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python2.7/dist-packages (from pandas) (2.7.3). Requirement already satisfied: pytz>=2011k in /usr/local/lib/python2.7/dist-packages (from pandas) (2018.5). Requirement already satisfied: six>=1.5 in /usr/local/lib/python2.7/dist-packages (from python-dateutil>=2.5.0->pandas) (1.11.0). Requirement already satisfied: psutil in /usr/local/lib/python2.7/dist-packages (5.4.7). Requirement already up-to-date: google-api-python-client in /usr/local/lib/python2.7/dist-packages (1.7.4). Requirement already satisfied, skipping upgrade: httplib2<1dev,>=0.9.2 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.11.3). Requirement already satisfied, skipping upgrade: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (3.0.0). Requirement already satisfied, skipping upgrade: google-auth-httplib2>=0.0.3 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.0.3). Requirement already satisfied, skipping upgrade: six<2dev,>=1.6.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.11.0). Requirement already sa",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:13488,modifiability,pac,packages,13488,"uirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python2.7/dist-packages (from oauth2client>=4.0.0) (3.4.2). Requirement already satisfied: crcmod>=1.7 in /usr/local/lib/python2.7/dist-packages (1.7). Requirement already satisfied: six in /usr/local/lib/python2.7/dist-packages (1.11.0). Requirement already satisfied: sklearn in /usr/local/lib/python2.7/dist-packages (0.0). Requirement already satisfied: scikit-learn in /usr/local/lib/python2.7/dist-packages (from sklearn) (0.19.2). Requirement already satisfied: pandas in /usr/local/lib/python2.7/dist-packages (0.23.4). Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python2.7/dist-packages (from pandas) (1.14.0). Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python2.7/dist-packages (from pandas) (2.7.3). Requirement already satisfied: pytz>=2011k in /usr/local/lib/python2.7/dist-packages (from pandas) (2018.5). Requirement already satisfied: six>=1.5 in /usr/local/lib/python2.7/dist-packages (from python-dateutil>=2.5.0->pandas) (1.11.0). Requirement already satisfied: psutil in /usr/local/lib/python2.7/dist-packages (5.4.7). Requirement already up-to-date: google-api-python-client in /usr/local/lib/python2.7/dist-packages (1.7.4). Requirement already satisfied, skipping upgrade: httplib2<1dev,>=0.9.2 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.11.3). Requirement already satisfied, skipping upgrade: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (3.0.0). Requirement already satisfied, skipping upgrade: google-auth-httplib2>=0.0.3 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.0.3). Requirement already satisfied, skipping upgrade: six<2dev,>=1.6.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.11.0). Requirement already satisfied, skipping upgrade: google-auth>=1.4.1 in /usr/local/lib/python2.7/dist-packages (from google-api-p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:13616,modifiability,pac,packages,13616," already satisfied: crcmod>=1.7 in /usr/local/lib/python2.7/dist-packages (1.7). Requirement already satisfied: six in /usr/local/lib/python2.7/dist-packages (1.11.0). Requirement already satisfied: sklearn in /usr/local/lib/python2.7/dist-packages (0.0). Requirement already satisfied: scikit-learn in /usr/local/lib/python2.7/dist-packages (from sklearn) (0.19.2). Requirement already satisfied: pandas in /usr/local/lib/python2.7/dist-packages (0.23.4). Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python2.7/dist-packages (from pandas) (1.14.0). Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python2.7/dist-packages (from pandas) (2.7.3). Requirement already satisfied: pytz>=2011k in /usr/local/lib/python2.7/dist-packages (from pandas) (2018.5). Requirement already satisfied: six>=1.5 in /usr/local/lib/python2.7/dist-packages (from python-dateutil>=2.5.0->pandas) (1.11.0). Requirement already satisfied: psutil in /usr/local/lib/python2.7/dist-packages (5.4.7). Requirement already up-to-date: google-api-python-client in /usr/local/lib/python2.7/dist-packages (1.7.4). Requirement already satisfied, skipping upgrade: httplib2<1dev,>=0.9.2 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.11.3). Requirement already satisfied, skipping upgrade: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (3.0.0). Requirement already satisfied, skipping upgrade: google-auth-httplib2>=0.0.3 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.0.3). Requirement already satisfied, skipping upgrade: six<2dev,>=1.6.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.11.0). Requirement already satisfied, skipping upgrade: google-auth>=1.4.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.5.1). Requirement already satisfied, skipping upgrade: rsa>=3.1.4 in /usr/local/lib/python2.7/dist-packages (fr",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:13724,modifiability,pac,packages,13724,"ed: six in /usr/local/lib/python2.7/dist-packages (1.11.0). Requirement already satisfied: sklearn in /usr/local/lib/python2.7/dist-packages (0.0). Requirement already satisfied: scikit-learn in /usr/local/lib/python2.7/dist-packages (from sklearn) (0.19.2). Requirement already satisfied: pandas in /usr/local/lib/python2.7/dist-packages (0.23.4). Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python2.7/dist-packages (from pandas) (1.14.0). Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python2.7/dist-packages (from pandas) (2.7.3). Requirement already satisfied: pytz>=2011k in /usr/local/lib/python2.7/dist-packages (from pandas) (2018.5). Requirement already satisfied: six>=1.5 in /usr/local/lib/python2.7/dist-packages (from python-dateutil>=2.5.0->pandas) (1.11.0). Requirement already satisfied: psutil in /usr/local/lib/python2.7/dist-packages (5.4.7). Requirement already up-to-date: google-api-python-client in /usr/local/lib/python2.7/dist-packages (1.7.4). Requirement already satisfied, skipping upgrade: httplib2<1dev,>=0.9.2 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.11.3). Requirement already satisfied, skipping upgrade: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (3.0.0). Requirement already satisfied, skipping upgrade: google-auth-httplib2>=0.0.3 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.0.3). Requirement already satisfied, skipping upgrade: six<2dev,>=1.6.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.11.0). Requirement already satisfied, skipping upgrade: google-auth>=1.4.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.5.1). Requirement already satisfied, skipping upgrade: rsa>=3.1.4 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (3.4.2). Requirement already satisfied, skipping upgrade: c",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:13782,modifiability,upgrad,upgrade,13782,". Requirement already satisfied: sklearn in /usr/local/lib/python2.7/dist-packages (0.0). Requirement already satisfied: scikit-learn in /usr/local/lib/python2.7/dist-packages (from sklearn) (0.19.2). Requirement already satisfied: pandas in /usr/local/lib/python2.7/dist-packages (0.23.4). Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python2.7/dist-packages (from pandas) (1.14.0). Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python2.7/dist-packages (from pandas) (2.7.3). Requirement already satisfied: pytz>=2011k in /usr/local/lib/python2.7/dist-packages (from pandas) (2018.5). Requirement already satisfied: six>=1.5 in /usr/local/lib/python2.7/dist-packages (from python-dateutil>=2.5.0->pandas) (1.11.0). Requirement already satisfied: psutil in /usr/local/lib/python2.7/dist-packages (5.4.7). Requirement already up-to-date: google-api-python-client in /usr/local/lib/python2.7/dist-packages (1.7.4). Requirement already satisfied, skipping upgrade: httplib2<1dev,>=0.9.2 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.11.3). Requirement already satisfied, skipping upgrade: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (3.0.0). Requirement already satisfied, skipping upgrade: google-auth-httplib2>=0.0.3 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.0.3). Requirement already satisfied, skipping upgrade: six<2dev,>=1.6.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.11.0). Requirement already satisfied, skipping upgrade: google-auth>=1.4.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.5.1). Requirement already satisfied, skipping upgrade: rsa>=3.1.4 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (3.4.2). Requirement already satisfied, skipping upgrade: cachetools>=2.0.0 in /usr/local/lib/python2.7/dist-packages",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:13846,modifiability,pac,packages,13846,"n2.7/dist-packages (0.0). Requirement already satisfied: scikit-learn in /usr/local/lib/python2.7/dist-packages (from sklearn) (0.19.2). Requirement already satisfied: pandas in /usr/local/lib/python2.7/dist-packages (0.23.4). Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python2.7/dist-packages (from pandas) (1.14.0). Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python2.7/dist-packages (from pandas) (2.7.3). Requirement already satisfied: pytz>=2011k in /usr/local/lib/python2.7/dist-packages (from pandas) (2018.5). Requirement already satisfied: six>=1.5 in /usr/local/lib/python2.7/dist-packages (from python-dateutil>=2.5.0->pandas) (1.11.0). Requirement already satisfied: psutil in /usr/local/lib/python2.7/dist-packages (5.4.7). Requirement already up-to-date: google-api-python-client in /usr/local/lib/python2.7/dist-packages (1.7.4). Requirement already satisfied, skipping upgrade: httplib2<1dev,>=0.9.2 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.11.3). Requirement already satisfied, skipping upgrade: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (3.0.0). Requirement already satisfied, skipping upgrade: google-auth-httplib2>=0.0.3 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.0.3). Requirement already satisfied, skipping upgrade: six<2dev,>=1.6.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.11.0). Requirement already satisfied, skipping upgrade: google-auth>=1.4.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.5.1). Requirement already satisfied, skipping upgrade: rsa>=3.1.4 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (3.4.2). Requirement already satisfied, skipping upgrade: cachetools>=2.0.0 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (2.1.0). Re",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:13937,modifiability,upgrad,upgrade,13937,"hon2.7/dist-packages (from sklearn) (0.19.2). Requirement already satisfied: pandas in /usr/local/lib/python2.7/dist-packages (0.23.4). Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python2.7/dist-packages (from pandas) (1.14.0). Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python2.7/dist-packages (from pandas) (2.7.3). Requirement already satisfied: pytz>=2011k in /usr/local/lib/python2.7/dist-packages (from pandas) (2018.5). Requirement already satisfied: six>=1.5 in /usr/local/lib/python2.7/dist-packages (from python-dateutil>=2.5.0->pandas) (1.11.0). Requirement already satisfied: psutil in /usr/local/lib/python2.7/dist-packages (5.4.7). Requirement already up-to-date: google-api-python-client in /usr/local/lib/python2.7/dist-packages (1.7.4). Requirement already satisfied, skipping upgrade: httplib2<1dev,>=0.9.2 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.11.3). Requirement already satisfied, skipping upgrade: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (3.0.0). Requirement already satisfied, skipping upgrade: google-auth-httplib2>=0.0.3 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.0.3). Requirement already satisfied, skipping upgrade: six<2dev,>=1.6.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.11.0). Requirement already satisfied, skipping upgrade: google-auth>=1.4.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.5.1). Requirement already satisfied, skipping upgrade: rsa>=3.1.4 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (3.4.2). Requirement already satisfied, skipping upgrade: cachetools>=2.0.0 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (2.1.0). Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/pyth",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:14004,modifiability,pac,packages,14004,"atisfied: pandas in /usr/local/lib/python2.7/dist-packages (0.23.4). Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python2.7/dist-packages (from pandas) (1.14.0). Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python2.7/dist-packages (from pandas) (2.7.3). Requirement already satisfied: pytz>=2011k in /usr/local/lib/python2.7/dist-packages (from pandas) (2018.5). Requirement already satisfied: six>=1.5 in /usr/local/lib/python2.7/dist-packages (from python-dateutil>=2.5.0->pandas) (1.11.0). Requirement already satisfied: psutil in /usr/local/lib/python2.7/dist-packages (5.4.7). Requirement already up-to-date: google-api-python-client in /usr/local/lib/python2.7/dist-packages (1.7.4). Requirement already satisfied, skipping upgrade: httplib2<1dev,>=0.9.2 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.11.3). Requirement already satisfied, skipping upgrade: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (3.0.0). Requirement already satisfied, skipping upgrade: google-auth-httplib2>=0.0.3 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.0.3). Requirement already satisfied, skipping upgrade: six<2dev,>=1.6.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.11.0). Requirement already satisfied, skipping upgrade: google-auth>=1.4.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.5.1). Requirement already satisfied, skipping upgrade: rsa>=3.1.4 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (3.4.2). Requirement already satisfied, skipping upgrade: cachetools>=2.0.0 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (2.1.0). Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-cli",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:14094,modifiability,upgrad,upgrade,14094,"atisfied: numpy>=1.9.0 in /usr/local/lib/python2.7/dist-packages (from pandas) (1.14.0). Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python2.7/dist-packages (from pandas) (2.7.3). Requirement already satisfied: pytz>=2011k in /usr/local/lib/python2.7/dist-packages (from pandas) (2018.5). Requirement already satisfied: six>=1.5 in /usr/local/lib/python2.7/dist-packages (from python-dateutil>=2.5.0->pandas) (1.11.0). Requirement already satisfied: psutil in /usr/local/lib/python2.7/dist-packages (5.4.7). Requirement already up-to-date: google-api-python-client in /usr/local/lib/python2.7/dist-packages (1.7.4). Requirement already satisfied, skipping upgrade: httplib2<1dev,>=0.9.2 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.11.3). Requirement already satisfied, skipping upgrade: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (3.0.0). Requirement already satisfied, skipping upgrade: google-auth-httplib2>=0.0.3 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.0.3). Requirement already satisfied, skipping upgrade: six<2dev,>=1.6.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.11.0). Requirement already satisfied, skipping upgrade: google-auth>=1.4.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.5.1). Requirement already satisfied, skipping upgrade: rsa>=3.1.4 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (3.4.2). Requirement already satisfied, skipping upgrade: cachetools>=2.0.0 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (2.1.0). Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (0.2.2). Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /usr/local",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:14164,modifiability,pac,packages,14164," pandas) (1.14.0). Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python2.7/dist-packages (from pandas) (2.7.3). Requirement already satisfied: pytz>=2011k in /usr/local/lib/python2.7/dist-packages (from pandas) (2018.5). Requirement already satisfied: six>=1.5 in /usr/local/lib/python2.7/dist-packages (from python-dateutil>=2.5.0->pandas) (1.11.0). Requirement already satisfied: psutil in /usr/local/lib/python2.7/dist-packages (5.4.7). Requirement already up-to-date: google-api-python-client in /usr/local/lib/python2.7/dist-packages (1.7.4). Requirement already satisfied, skipping upgrade: httplib2<1dev,>=0.9.2 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.11.3). Requirement already satisfied, skipping upgrade: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (3.0.0). Requirement already satisfied, skipping upgrade: google-auth-httplib2>=0.0.3 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.0.3). Requirement already satisfied, skipping upgrade: six<2dev,>=1.6.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.11.0). Requirement already satisfied, skipping upgrade: google-auth>=1.4.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.5.1). Requirement already satisfied, skipping upgrade: rsa>=3.1.4 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (3.4.2). Requirement already satisfied, skipping upgrade: cachetools>=2.0.0 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (2.1.0). Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (0.2.2). Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /usr/local/lib/python2.7/dist-packages (from rsa>=3.1.4->google-auth>=1.4.1->goo",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:14254,modifiability,upgrad,upgrade,14254,"/python2.7/dist-packages (from pandas) (2.7.3). Requirement already satisfied: pytz>=2011k in /usr/local/lib/python2.7/dist-packages (from pandas) (2018.5). Requirement already satisfied: six>=1.5 in /usr/local/lib/python2.7/dist-packages (from python-dateutil>=2.5.0->pandas) (1.11.0). Requirement already satisfied: psutil in /usr/local/lib/python2.7/dist-packages (5.4.7). Requirement already up-to-date: google-api-python-client in /usr/local/lib/python2.7/dist-packages (1.7.4). Requirement already satisfied, skipping upgrade: httplib2<1dev,>=0.9.2 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.11.3). Requirement already satisfied, skipping upgrade: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (3.0.0). Requirement already satisfied, skipping upgrade: google-auth-httplib2>=0.0.3 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.0.3). Requirement already satisfied, skipping upgrade: six<2dev,>=1.6.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.11.0). Requirement already satisfied, skipping upgrade: google-auth>=1.4.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.5.1). Requirement already satisfied, skipping upgrade: rsa>=3.1.4 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (3.4.2). Requirement already satisfied, skipping upgrade: cachetools>=2.0.0 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (2.1.0). Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (0.2.2). Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /usr/local/lib/python2.7/dist-packages (from rsa>=3.1.4->google-auth>=1.4.1->google-api-python-client) (0.4.4). ========== [2018年 08月 28日 星期二 10:55:17 CST] Stage 'Install",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:14313,modifiability,pac,packages,14313," already satisfied: pytz>=2011k in /usr/local/lib/python2.7/dist-packages (from pandas) (2018.5). Requirement already satisfied: six>=1.5 in /usr/local/lib/python2.7/dist-packages (from python-dateutil>=2.5.0->pandas) (1.11.0). Requirement already satisfied: psutil in /usr/local/lib/python2.7/dist-packages (5.4.7). Requirement already up-to-date: google-api-python-client in /usr/local/lib/python2.7/dist-packages (1.7.4). Requirement already satisfied, skipping upgrade: httplib2<1dev,>=0.9.2 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.11.3). Requirement already satisfied, skipping upgrade: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (3.0.0). Requirement already satisfied, skipping upgrade: google-auth-httplib2>=0.0.3 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.0.3). Requirement already satisfied, skipping upgrade: six<2dev,>=1.6.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.11.0). Requirement already satisfied, skipping upgrade: google-auth>=1.4.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.5.1). Requirement already satisfied, skipping upgrade: rsa>=3.1.4 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (3.4.2). Requirement already satisfied, skipping upgrade: cachetools>=2.0.0 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (2.1.0). Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (0.2.2). Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /usr/local/lib/python2.7/dist-packages (from rsa>=3.1.4->google-auth>=1.4.1->google-api-python-client) (0.4.4). ========== [2018年 08月 28日 星期二 10:55:17 CST] Stage 'Install TensorFlow pip package' starting. Skipping tf-nightly as i",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:14404,modifiability,upgrad,upgrade,14404,"18.5). Requirement already satisfied: six>=1.5 in /usr/local/lib/python2.7/dist-packages (from python-dateutil>=2.5.0->pandas) (1.11.0). Requirement already satisfied: psutil in /usr/local/lib/python2.7/dist-packages (5.4.7). Requirement already up-to-date: google-api-python-client in /usr/local/lib/python2.7/dist-packages (1.7.4). Requirement already satisfied, skipping upgrade: httplib2<1dev,>=0.9.2 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.11.3). Requirement already satisfied, skipping upgrade: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (3.0.0). Requirement already satisfied, skipping upgrade: google-auth-httplib2>=0.0.3 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.0.3). Requirement already satisfied, skipping upgrade: six<2dev,>=1.6.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.11.0). Requirement already satisfied, skipping upgrade: google-auth>=1.4.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.5.1). Requirement already satisfied, skipping upgrade: rsa>=3.1.4 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (3.4.2). Requirement already satisfied, skipping upgrade: cachetools>=2.0.0 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (2.1.0). Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (0.2.2). Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /usr/local/lib/python2.7/dist-packages (from rsa>=3.1.4->google-auth>=1.4.1->google-api-python-client) (0.4.4). ========== [2018年 08月 28日 星期二 10:55:17 CST] Stage 'Install TensorFlow pip package' starting. Skipping tf-nightly as it is not installed. Skipping tensorflow as it is not installed. Skipping tf-nightly-gpu as ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:14465,modifiability,pac,packages,14465,"lib/python2.7/dist-packages (from python-dateutil>=2.5.0->pandas) (1.11.0). Requirement already satisfied: psutil in /usr/local/lib/python2.7/dist-packages (5.4.7). Requirement already up-to-date: google-api-python-client in /usr/local/lib/python2.7/dist-packages (1.7.4). Requirement already satisfied, skipping upgrade: httplib2<1dev,>=0.9.2 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.11.3). Requirement already satisfied, skipping upgrade: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (3.0.0). Requirement already satisfied, skipping upgrade: google-auth-httplib2>=0.0.3 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.0.3). Requirement already satisfied, skipping upgrade: six<2dev,>=1.6.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.11.0). Requirement already satisfied, skipping upgrade: google-auth>=1.4.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.5.1). Requirement already satisfied, skipping upgrade: rsa>=3.1.4 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (3.4.2). Requirement already satisfied, skipping upgrade: cachetools>=2.0.0 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (2.1.0). Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (0.2.2). Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /usr/local/lib/python2.7/dist-packages (from rsa>=3.1.4->google-auth>=1.4.1->google-api-python-client) (0.4.4). ========== [2018年 08月 28日 星期二 10:55:17 CST] Stage 'Install TensorFlow pip package' starting. Skipping tf-nightly as it is not installed. Skipping tensorflow as it is not installed. Skipping tf-nightly-gpu as it is not installed. Skipping tensorflow-gpu as it is not ins",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:14555,modifiability,upgrad,upgrade,14555,"ready satisfied: psutil in /usr/local/lib/python2.7/dist-packages (5.4.7). Requirement already up-to-date: google-api-python-client in /usr/local/lib/python2.7/dist-packages (1.7.4). Requirement already satisfied, skipping upgrade: httplib2<1dev,>=0.9.2 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.11.3). Requirement already satisfied, skipping upgrade: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (3.0.0). Requirement already satisfied, skipping upgrade: google-auth-httplib2>=0.0.3 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.0.3). Requirement already satisfied, skipping upgrade: six<2dev,>=1.6.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.11.0). Requirement already satisfied, skipping upgrade: google-auth>=1.4.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.5.1). Requirement already satisfied, skipping upgrade: rsa>=3.1.4 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (3.4.2). Requirement already satisfied, skipping upgrade: cachetools>=2.0.0 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (2.1.0). Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (0.2.2). Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /usr/local/lib/python2.7/dist-packages (from rsa>=3.1.4->google-auth>=1.4.1->google-api-python-client) (0.4.4). ========== [2018年 08月 28日 星期二 10:55:17 CST] Stage 'Install TensorFlow pip package' starting. Skipping tf-nightly as it is not installed. Skipping tensorflow as it is not installed. Skipping tf-nightly-gpu as it is not installed. Skipping tensorflow-gpu as it is not installed. Installing Google Cloud Platform optimized CPU-only TensorFlow wheel. % Total % Re",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:14608,modifiability,pac,packages,14608,"ist-packages (5.4.7). Requirement already up-to-date: google-api-python-client in /usr/local/lib/python2.7/dist-packages (1.7.4). Requirement already satisfied, skipping upgrade: httplib2<1dev,>=0.9.2 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.11.3). Requirement already satisfied, skipping upgrade: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (3.0.0). Requirement already satisfied, skipping upgrade: google-auth-httplib2>=0.0.3 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.0.3). Requirement already satisfied, skipping upgrade: six<2dev,>=1.6.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.11.0). Requirement already satisfied, skipping upgrade: google-auth>=1.4.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.5.1). Requirement already satisfied, skipping upgrade: rsa>=3.1.4 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (3.4.2). Requirement already satisfied, skipping upgrade: cachetools>=2.0.0 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (2.1.0). Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (0.2.2). Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /usr/local/lib/python2.7/dist-packages (from rsa>=3.1.4->google-auth>=1.4.1->google-api-python-client) (0.4.4). ========== [2018年 08月 28日 星期二 10:55:17 CST] Stage 'Install TensorFlow pip package' starting. Skipping tf-nightly as it is not installed. Skipping tensorflow as it is not installed. Skipping tf-nightly-gpu as it is not installed. Skipping tensorflow-gpu as it is not installed. Installing Google Cloud Platform optimized CPU-only TensorFlow wheel. % Total % Received % Xferd Average Speed Time Time Time Current. ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:14718,modifiability,upgrad,upgrade,14718,"t-packages (1.7.4). Requirement already satisfied, skipping upgrade: httplib2<1dev,>=0.9.2 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.11.3). Requirement already satisfied, skipping upgrade: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (3.0.0). Requirement already satisfied, skipping upgrade: google-auth-httplib2>=0.0.3 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.0.3). Requirement already satisfied, skipping upgrade: six<2dev,>=1.6.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.11.0). Requirement already satisfied, skipping upgrade: google-auth>=1.4.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.5.1). Requirement already satisfied, skipping upgrade: rsa>=3.1.4 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (3.4.2). Requirement already satisfied, skipping upgrade: cachetools>=2.0.0 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (2.1.0). Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (0.2.2). Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /usr/local/lib/python2.7/dist-packages (from rsa>=3.1.4->google-auth>=1.4.1->google-api-python-client) (0.4.4). ========== [2018年 08月 28日 星期二 10:55:17 CST] Stage 'Install TensorFlow pip package' starting. Skipping tf-nightly as it is not installed. Skipping tensorflow as it is not installed. Skipping tf-nightly-gpu as it is not installed. Skipping tensorflow-gpu as it is not installed. Installing Google Cloud Platform optimized CPU-only TensorFlow wheel. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 0 0 0 0 0 0 0 0 --:--:-- 0:02:09 --:--:-- 0curl: (7) Failed to connect to",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:14778,modifiability,pac,packages,14778,"ping upgrade: httplib2<1dev,>=0.9.2 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.11.3). Requirement already satisfied, skipping upgrade: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (3.0.0). Requirement already satisfied, skipping upgrade: google-auth-httplib2>=0.0.3 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.0.3). Requirement already satisfied, skipping upgrade: six<2dev,>=1.6.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.11.0). Requirement already satisfied, skipping upgrade: google-auth>=1.4.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.5.1). Requirement already satisfied, skipping upgrade: rsa>=3.1.4 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (3.4.2). Requirement already satisfied, skipping upgrade: cachetools>=2.0.0 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (2.1.0). Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (0.2.2). Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /usr/local/lib/python2.7/dist-packages (from rsa>=3.1.4->google-auth>=1.4.1->google-api-python-client) (0.4.4). ========== [2018年 08月 28日 星期二 10:55:17 CST] Stage 'Install TensorFlow pip package' starting. Skipping tf-nightly as it is not installed. Skipping tensorflow as it is not installed. Skipping tf-nightly-gpu as it is not installed. Skipping tensorflow-gpu as it is not installed. Installing Google Cloud Platform optimized CPU-only TensorFlow wheel. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 0 0 0 0 0 0 0 0 --:--:-- 0:02:09 --:--:-- 0curl: (7) Failed to connect to storage.googleapis.com port 443: Connection timed out.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:14888,modifiability,upgrad,upgrade,14888,"ping upgrade: httplib2<1dev,>=0.9.2 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.11.3). Requirement already satisfied, skipping upgrade: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (3.0.0). Requirement already satisfied, skipping upgrade: google-auth-httplib2>=0.0.3 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.0.3). Requirement already satisfied, skipping upgrade: six<2dev,>=1.6.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.11.0). Requirement already satisfied, skipping upgrade: google-auth>=1.4.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.5.1). Requirement already satisfied, skipping upgrade: rsa>=3.1.4 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (3.4.2). Requirement already satisfied, skipping upgrade: cachetools>=2.0.0 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (2.1.0). Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (0.2.2). Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /usr/local/lib/python2.7/dist-packages (from rsa>=3.1.4->google-auth>=1.4.1->google-api-python-client) (0.4.4). ========== [2018年 08月 28日 星期二 10:55:17 CST] Stage 'Install TensorFlow pip package' starting. Skipping tf-nightly as it is not installed. Skipping tensorflow as it is not installed. Skipping tf-nightly-gpu as it is not installed. Skipping tensorflow-gpu as it is not installed. Installing Google Cloud Platform optimized CPU-only TensorFlow wheel. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 0 0 0 0 0 0 0 0 --:--:-- 0:02:09 --:--:-- 0curl: (7) Failed to connect to storage.googleapis.com port 443: Connection timed out.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:14904,modifiability,modul,modules,14904,"ping upgrade: httplib2<1dev,>=0.9.2 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.11.3). Requirement already satisfied, skipping upgrade: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (3.0.0). Requirement already satisfied, skipping upgrade: google-auth-httplib2>=0.0.3 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.0.3). Requirement already satisfied, skipping upgrade: six<2dev,>=1.6.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.11.0). Requirement already satisfied, skipping upgrade: google-auth>=1.4.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.5.1). Requirement already satisfied, skipping upgrade: rsa>=3.1.4 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (3.4.2). Requirement already satisfied, skipping upgrade: cachetools>=2.0.0 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (2.1.0). Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (0.2.2). Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /usr/local/lib/python2.7/dist-packages (from rsa>=3.1.4->google-auth>=1.4.1->google-api-python-client) (0.4.4). ========== [2018年 08月 28日 星期二 10:55:17 CST] Stage 'Install TensorFlow pip package' starting. Skipping tf-nightly as it is not installed. Skipping tensorflow as it is not installed. Skipping tf-nightly-gpu as it is not installed. Skipping tensorflow-gpu as it is not installed. Installing Google Cloud Platform optimized CPU-only TensorFlow wheel. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 0 0 0 0 0 0 0 0 --:--:-- 0:02:09 --:--:-- 0curl: (7) Failed to connect to storage.googleapis.com port 443: Connection timed out.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:14952,modifiability,pac,packages,14952,"ping upgrade: httplib2<1dev,>=0.9.2 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.11.3). Requirement already satisfied, skipping upgrade: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (3.0.0). Requirement already satisfied, skipping upgrade: google-auth-httplib2>=0.0.3 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.0.3). Requirement already satisfied, skipping upgrade: six<2dev,>=1.6.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.11.0). Requirement already satisfied, skipping upgrade: google-auth>=1.4.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.5.1). Requirement already satisfied, skipping upgrade: rsa>=3.1.4 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (3.4.2). Requirement already satisfied, skipping upgrade: cachetools>=2.0.0 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (2.1.0). Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (0.2.2). Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /usr/local/lib/python2.7/dist-packages (from rsa>=3.1.4->google-auth>=1.4.1->google-api-python-client) (0.4.4). ========== [2018年 08月 28日 星期二 10:55:17 CST] Stage 'Install TensorFlow pip package' starting. Skipping tf-nightly as it is not installed. Skipping tensorflow as it is not installed. Skipping tf-nightly-gpu as it is not installed. Skipping tensorflow-gpu as it is not installed. Installing Google Cloud Platform optimized CPU-only TensorFlow wheel. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 0 0 0 0 0 0 0 0 --:--:-- 0:02:09 --:--:-- 0curl: (7) Failed to connect to storage.googleapis.com port 443: Connection timed out.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:15062,modifiability,upgrad,upgrade,15062,"ping upgrade: httplib2<1dev,>=0.9.2 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.11.3). Requirement already satisfied, skipping upgrade: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (3.0.0). Requirement already satisfied, skipping upgrade: google-auth-httplib2>=0.0.3 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.0.3). Requirement already satisfied, skipping upgrade: six<2dev,>=1.6.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.11.0). Requirement already satisfied, skipping upgrade: google-auth>=1.4.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.5.1). Requirement already satisfied, skipping upgrade: rsa>=3.1.4 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (3.4.2). Requirement already satisfied, skipping upgrade: cachetools>=2.0.0 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (2.1.0). Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (0.2.2). Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /usr/local/lib/python2.7/dist-packages (from rsa>=3.1.4->google-auth>=1.4.1->google-api-python-client) (0.4.4). ========== [2018年 08月 28日 星期二 10:55:17 CST] Stage 'Install TensorFlow pip package' starting. Skipping tf-nightly as it is not installed. Skipping tensorflow as it is not installed. Skipping tf-nightly-gpu as it is not installed. Skipping tensorflow-gpu as it is not installed. Installing Google Cloud Platform optimized CPU-only TensorFlow wheel. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 0 0 0 0 0 0 0 0 --:--:-- 0:02:09 --:--:-- 0curl: (7) Failed to connect to storage.googleapis.com port 443: Connection timed out.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:15118,modifiability,pac,packages,15118,"ping upgrade: httplib2<1dev,>=0.9.2 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.11.3). Requirement already satisfied, skipping upgrade: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (3.0.0). Requirement already satisfied, skipping upgrade: google-auth-httplib2>=0.0.3 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.0.3). Requirement already satisfied, skipping upgrade: six<2dev,>=1.6.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.11.0). Requirement already satisfied, skipping upgrade: google-auth>=1.4.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.5.1). Requirement already satisfied, skipping upgrade: rsa>=3.1.4 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (3.4.2). Requirement already satisfied, skipping upgrade: cachetools>=2.0.0 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (2.1.0). Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (0.2.2). Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /usr/local/lib/python2.7/dist-packages (from rsa>=3.1.4->google-auth>=1.4.1->google-api-python-client) (0.4.4). ========== [2018年 08月 28日 星期二 10:55:17 CST] Stage 'Install TensorFlow pip package' starting. Skipping tf-nightly as it is not installed. Skipping tensorflow as it is not installed. Skipping tf-nightly-gpu as it is not installed. Skipping tensorflow-gpu as it is not installed. Installing Google Cloud Platform optimized CPU-only TensorFlow wheel. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 0 0 0 0 0 0 0 0 --:--:-- 0:02:09 --:--:-- 0curl: (7) Failed to connect to storage.googleapis.com port 443: Connection timed out.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:15274,modifiability,pac,package,15274,"ping upgrade: httplib2<1dev,>=0.9.2 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.11.3). Requirement already satisfied, skipping upgrade: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (3.0.0). Requirement already satisfied, skipping upgrade: google-auth-httplib2>=0.0.3 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.0.3). Requirement already satisfied, skipping upgrade: six<2dev,>=1.6.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.11.0). Requirement already satisfied, skipping upgrade: google-auth>=1.4.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.5.1). Requirement already satisfied, skipping upgrade: rsa>=3.1.4 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (3.4.2). Requirement already satisfied, skipping upgrade: cachetools>=2.0.0 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (2.1.0). Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (0.2.2). Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /usr/local/lib/python2.7/dist-packages (from rsa>=3.1.4->google-auth>=1.4.1->google-api-python-client) (0.4.4). ========== [2018年 08月 28日 星期二 10:55:17 CST] Stage 'Install TensorFlow pip package' starting. Skipping tf-nightly as it is not installed. Skipping tensorflow as it is not installed. Skipping tf-nightly-gpu as it is not installed. Skipping tensorflow-gpu as it is not installed. Installing Google Cloud Platform optimized CPU-only TensorFlow wheel. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 0 0 0 0 0 0 0 0 --:--:-- 0:02:09 --:--:-- 0curl: (7) Failed to connect to storage.googleapis.com port 443: Connection timed out.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:218,performance,Load,Load,218,"@pichuan hi, i got the zip file and ra run-prereq.sh and this was the output:. solokopi@solokopi-All-Series:~/Desktop/DeepVariant-0.7.0+cl-208818123$ sudo bash run-prereq.sh. [sudo] password for solokopi: . ========== Load config settings. ========== [2018年 08月 28日 星期二 10:31:05 CST] Stage 'Misc setup' starting. Ign:1 http://dl.google.com/linux/chrome/deb stable InRelease. Hit:2 http://mirrors.aliyun.com/ubuntu xenial InRelease . Hit:3 http://dl.google.com/linux/chrome/deb stable Release . Hit:4 http://mirrors.aliyun.com/ubuntu xenial-updates InRelease . Get:6 http://mirrors.aliyun.com/ubuntu xenial-backports InRelease [107 kB] . Hit:7 http://mirrors.aliyun.com/ubuntu xenial-security InRelease . Hit:8 http://ppa.launchpad.net/webupd8team/java/ubuntu xenial InRelease . Err:9 http://storage.googleapis.com/bazel-apt stable InRelease . Cannot initiate the connection to storage.googleapis.com:80 (2404:6800:4012:1::2010). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::2010 80]. Err:10 http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease . Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4008:803::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4008:803::200e 80]. Fetched 107 kB in 12min 0s (148 B/s) . Reading package lists... Done. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:945,performance,Network,Network,945,"@pichuan hi, i got the zip file and ra run-prereq.sh and this was the output:. solokopi@solokopi-All-Series:~/Desktop/DeepVariant-0.7.0+cl-208818123$ sudo bash run-prereq.sh. [sudo] password for solokopi: . ========== Load config settings. ========== [2018年 08月 28日 星期二 10:31:05 CST] Stage 'Misc setup' starting. Ign:1 http://dl.google.com/linux/chrome/deb stable InRelease. Hit:2 http://mirrors.aliyun.com/ubuntu xenial InRelease . Hit:3 http://dl.google.com/linux/chrome/deb stable Release . Hit:4 http://mirrors.aliyun.com/ubuntu xenial-updates InRelease . Get:6 http://mirrors.aliyun.com/ubuntu xenial-backports InRelease [107 kB] . Hit:7 http://mirrors.aliyun.com/ubuntu xenial-security InRelease . Hit:8 http://ppa.launchpad.net/webupd8team/java/ubuntu xenial InRelease . Err:9 http://storage.googleapis.com/bazel-apt stable InRelease . Cannot initiate the connection to storage.googleapis.com:80 (2404:6800:4012:1::2010). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::2010 80]. Err:10 http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease . Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4008:803::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4008:803::200e 80]. Fetched 107 kB in 12min 0s (148 B/s) . Reading package lists... Done. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:1182,performance,Network,Network,1182,word for solokopi: . ========== Load config settings. ========== [2018年 08月 28日 星期二 10:31:05 CST] Stage 'Misc setup' starting. Ign:1 http://dl.google.com/linux/chrome/deb stable InRelease. Hit:2 http://mirrors.aliyun.com/ubuntu xenial InRelease . Hit:3 http://dl.google.com/linux/chrome/deb stable Release . Hit:4 http://mirrors.aliyun.com/ubuntu xenial-updates InRelease . Get:6 http://mirrors.aliyun.com/ubuntu xenial-backports InRelease [107 kB] . Hit:7 http://mirrors.aliyun.com/ubuntu xenial-security InRelease . Hit:8 http://ppa.launchpad.net/webupd8team/java/ubuntu xenial InRelease . Err:9 http://storage.googleapis.com/bazel-apt stable InRelease . Cannot initiate the connection to storage.googleapis.com:80 (2404:6800:4012:1::2010). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::2010 80]. Err:10 http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease . Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4008:803::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4008:803::200e 80]. Fetched 107 kB in 12min 0s (148 B/s) . Reading package lists... Done. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:1503,performance,time,times,1503,/mirrors.aliyun.com/ubuntu xenial-updates InRelease . Get:6 http://mirrors.aliyun.com/ubuntu xenial-backports InRelease [107 kB] . Hit:7 http://mirrors.aliyun.com/ubuntu xenial-security InRelease . Hit:8 http://ppa.launchpad.net/webupd8team/java/ubuntu xenial InRelease . Err:9 http://storage.googleapis.com/bazel-apt stable InRelease . Cannot initiate the connection to storage.googleapis.com:80 (2404:6800:4012:1::2010). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::2010 80]. Err:10 http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease . Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4008:803::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4008:803::200e 80]. Fetched 107 kB in 12min 0s (148 B/s) . Reading package lists... Done. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:1683,performance,time,times,1683,urity InRelease . Hit:8 http://ppa.launchpad.net/webupd8team/java/ubuntu xenial InRelease . Err:9 http://storage.googleapis.com/bazel-apt stable InRelease . Cannot initiate the connection to storage.googleapis.com:80 (2404:6800:4012:1::2010). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::2010 80]. Err:10 http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease . Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4008:803::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4008:803::200e 80]. Fetched 107 kB in 12min 0s (148 B/s) . Reading package lists... Done. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/g,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:1862,performance,time,times,1862,nnection to storage.googleapis.com:80 (2404:6800:4012:1::2010). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::2010 80]. Err:10 http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease . Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4008:803::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4008:803::200e 80]. Fetched 107 kB in 12min 0s (148 B/s) . Reading package lists... Done. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://storage.googleapis.com/bazel-apt/dists/stable/InRelease Cannot initiate the connection to storage.googleapis.com:80 (2404:6800:40,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:2048,performance,time,times,2048,-sdk-xenial InRelease . Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4008:803::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4008:803::200e 80]. Fetched 107 kB in 12min 0s (148 B/s) . Reading package lists... Done. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://storage.googleapis.com/bazel-apt/dists/stable/InRelease Cannot initiate the connection to storage.googleapis.com:80 (2404:6800:4012:1::2010). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::2010 80]. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot init,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:2231,performance,time,times,2231,e 80]. Fetched 107 kB in 12min 0s (148 B/s) . Reading package lists... Done. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://storage.googleapis.com/bazel-apt/dists/stable/InRelease Cannot initiate the connection to storage.googleapis.com:80 (2404:6800:4012:1::2010). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::2010 80]. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4008:803::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4008:803::200e 80]. W: Some index files failed t,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:2415,performance,time,times,2415,"me extension. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://storage.googleapis.com/bazel-apt/dists/stable/InRelease Cannot initiate the connection to storage.googleapis.com:80 (2404:6800:4012:1::2010). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::2010 80]. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4008:803::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4008:803::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.l",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:2600,performance,time,times,2600,"k.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://storage.googleapis.com/bazel-apt/dists/stable/InRelease Cannot initiate the connection to storage.googleapis.com:80 (2404:6800:4012:1::2010). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::2010 80]. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4008:803::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4008:803::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:2894,performance,Network,Network,2894,"gle-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://storage.googleapis.com/bazel-apt/dists/stable/InRelease Cannot initiate the connection to storage.googleapis.com:80 (2404:6800:4012:1::2010). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::2010 80]. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4008:803::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4008:803::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is config",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:3147,performance,Network,Network,3147,"ist:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://storage.googleapis.com/bazel-apt/dists/stable/InRelease Cannot initiate the connection to storage.googleapis.com:80 (2404:6800:4012:1::2010). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::2010 80]. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4008:803::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4008:803::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:3367,performance,time,times,3367,"Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://storage.googleapis.com/bazel-apt/dists/stable/InRelease Cannot initiate the connection to storage.googleapis.com:80 (2404:6800:4012:1::2010). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::2010 80]. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4008:803::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4008:803::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:3547,performance,time,times,3547,"ain/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://storage.googleapis.com/bazel-apt/dists/stable/InRelease Cannot initiate the connection to storage.googleapis.com:80 (2404:6800:4012:1::2010). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::2010 80]. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4008:803::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4008:803::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/g",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:3726,performance,time,times,3726,"http://storage.googleapis.com/bazel-apt/dists/stable/InRelease Cannot initiate the connection to storage.googleapis.com:80 (2404:6800:4012:1::2010). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::2010 80]. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4008:803::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4008:803::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. Reading package lists... Done. Building dependency tree . Reading state information... Done. sudo is already the newest version (1.8.16-0ubuntu1.5). The fo",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:3912,performance,time,times,3912,"e) [IP: 2404:6800:4012:1::2010 80]. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4008:803::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4008:803::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. Reading package lists... Done. Building dependency tree . Reading state information... Done. sudo is already the newest version (1.8.16-0ubuntu1.5). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-e",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:4095,performance,time,times,4095,"m:80 (2404:6800:4008:803::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4008:803::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. Reading package lists... Done. Building dependency tree . Reading state information... Done. sudo is already the newest version (1.8.16-0ubuntu1.5). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:4279,performance,time,times,4279,"used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. Reading package lists... Done. Building dependency tree . Reading state information... Done. sudo is already the newest version (1.8.16-0ubuntu1.5). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:43:08 CST] Stage 'Update package list' starting. W: Target Packages (main/binary-amd",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:4464,performance,time,times,4464,"k.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. Reading package lists... Done. Building dependency tree . Reading state information... Done. sudo is already the newest version (1.8.16-0ubuntu1.5). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:43:08 CST] Stage 'Update package list' starting. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Pa",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:5318,performance,time,times,5318,"oud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. Reading package lists... Done. Building dependency tree . Reading state information... Done. sudo is already the newest version (1.8.16-0ubuntu1.5). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:43:08 CST] Stage 'Update package list' starting. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:5498,performance,time,times,5498,"le-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. Reading package lists... Done. Building dependency tree . Reading state information... Done. sudo is already the newest version (1.8.16-0ubuntu1.5). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:43:08 CST] Stage 'Update package list' starting. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/g",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:5677,performance,time,times,5677,"dy the newest version (1.8.16-0ubuntu1.5). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:43:08 CST] Stage 'Update package list' starting. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (24",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:5863,performance,time,times,5863,"eric. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:43:08 CST] Stage 'Update package list' starting. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4012:1::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:6046,performance,time,times,6046,"noring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:43:08 CST] Stage 'Update package list' starting. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4012:1::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W:",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:6230,performance,time,times,6230,"st' starting. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4012:1::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Tar",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:6415,performance,time,times,6415,"k.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4012:1::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Tr",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:6719,performance,Network,Network,6719,"sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4012:1::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 a",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:6937,performance,time,times,6937,".list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4012:1::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:7117,performance,time,times,7117,"ces.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4012:1::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/g",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:7296,performance,time,times,7296,"/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4012:1::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install development packages' starting. Reading package lists... Done. Building dependency tree . Readin",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:7482,performance,time,times,7482,"sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4012:1::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install development packages' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. pkg-config is already the newest version (0.29.1-0ubuntu1). unzip is already the newest version (6.0-20ubuntu1). zip is already the newest version (3.0-11). ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:7665,performance,time,times,7665,"e.com:80 (2404:6800:4012:1::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install development packages' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. pkg-config is already the newest version (0.29.1-0ubuntu1). unzip is already the newest version (6.0-20ubuntu1). zip is already the newest version (3.0-11). curl is already the newest version (7.47.0-1ubuntu2.8). zlib1g-dev is already the newest version (1:1.2.8.dfsg-2ubuntu4.1). The following packages were automatically installed and are",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:7849,performance,time,times,7849,used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install development packages' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. pkg-config is already the newest version (0.29.1-0ubuntu1). unzip is already the newest version (6.0-20ubuntu1). zip is already the newest version (3.0-11). curl is already the newest version (7.47.0-1ubuntu2.8). zlib1g-dev is already the newest version (1:1.2.8.dfsg-2ubuntu4.1). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' t,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:8034,performance,time,times,8034,"k.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install development packages' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. pkg-config is already the newest version (0.29.1-0ubuntu1). unzip is already the newest version (6.0-20ubuntu1). zip is already the newest version (3.0-11). curl is already the newest version (7.47.0-1ubuntu2.8). zlib1g-dev is already the newest version (1:1.2.8.dfsg-2ubuntu4.1). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filena",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:14727,performance,cach,cachetools,14727," (1.7.4). Requirement already satisfied, skipping upgrade: httplib2<1dev,>=0.9.2 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.11.3). Requirement already satisfied, skipping upgrade: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (3.0.0). Requirement already satisfied, skipping upgrade: google-auth-httplib2>=0.0.3 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.0.3). Requirement already satisfied, skipping upgrade: six<2dev,>=1.6.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.11.0). Requirement already satisfied, skipping upgrade: google-auth>=1.4.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.5.1). Requirement already satisfied, skipping upgrade: rsa>=3.1.4 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (3.4.2). Requirement already satisfied, skipping upgrade: cachetools>=2.0.0 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (2.1.0). Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (0.2.2). Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /usr/local/lib/python2.7/dist-packages (from rsa>=3.1.4->google-auth>=1.4.1->google-api-python-client) (0.4.4). ========== [2018年 08月 28日 星期二 10:55:17 CST] Stage 'Install TensorFlow pip package' starting. Skipping tf-nightly as it is not installed. Skipping tensorflow as it is not installed. Skipping tf-nightly-gpu as it is not installed. Skipping tensorflow-gpu as it is not installed. Installing Google Cloud Platform optimized CPU-only TensorFlow wheel. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 0 0 0 0 0 0 0 0 --:--:-- 0:02:09 --:--:-- 0curl: (7) Failed to connect to storage.g",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:15401,performance,gpu,gpu,15401,"ping upgrade: httplib2<1dev,>=0.9.2 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.11.3). Requirement already satisfied, skipping upgrade: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (3.0.0). Requirement already satisfied, skipping upgrade: google-auth-httplib2>=0.0.3 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.0.3). Requirement already satisfied, skipping upgrade: six<2dev,>=1.6.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.11.0). Requirement already satisfied, skipping upgrade: google-auth>=1.4.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.5.1). Requirement already satisfied, skipping upgrade: rsa>=3.1.4 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (3.4.2). Requirement already satisfied, skipping upgrade: cachetools>=2.0.0 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (2.1.0). Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (0.2.2). Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /usr/local/lib/python2.7/dist-packages (from rsa>=3.1.4->google-auth>=1.4.1->google-api-python-client) (0.4.4). ========== [2018年 08月 28日 星期二 10:55:17 CST] Stage 'Install TensorFlow pip package' starting. Skipping tf-nightly as it is not installed. Skipping tensorflow as it is not installed. Skipping tf-nightly-gpu as it is not installed. Skipping tensorflow-gpu as it is not installed. Installing Google Cloud Platform optimized CPU-only TensorFlow wheel. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 0 0 0 0 0 0 0 0 --:--:-- 0:02:09 --:--:-- 0curl: (7) Failed to connect to storage.googleapis.com port 443: Connection timed out.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:15449,performance,gpu,gpu,15449,"ping upgrade: httplib2<1dev,>=0.9.2 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.11.3). Requirement already satisfied, skipping upgrade: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (3.0.0). Requirement already satisfied, skipping upgrade: google-auth-httplib2>=0.0.3 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.0.3). Requirement already satisfied, skipping upgrade: six<2dev,>=1.6.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.11.0). Requirement already satisfied, skipping upgrade: google-auth>=1.4.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.5.1). Requirement already satisfied, skipping upgrade: rsa>=3.1.4 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (3.4.2). Requirement already satisfied, skipping upgrade: cachetools>=2.0.0 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (2.1.0). Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (0.2.2). Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /usr/local/lib/python2.7/dist-packages (from rsa>=3.1.4->google-auth>=1.4.1->google-api-python-client) (0.4.4). ========== [2018年 08月 28日 星期二 10:55:17 CST] Stage 'Install TensorFlow pip package' starting. Skipping tf-nightly as it is not installed. Skipping tensorflow as it is not installed. Skipping tf-nightly-gpu as it is not installed. Skipping tensorflow-gpu as it is not installed. Installing Google Cloud Platform optimized CPU-only TensorFlow wheel. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 0 0 0 0 0 0 0 0 --:--:-- 0:02:09 --:--:-- 0curl: (7) Failed to connect to storage.googleapis.com port 443: Connection timed out.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:15510,performance,optimiz,optimized,15510,"ping upgrade: httplib2<1dev,>=0.9.2 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.11.3). Requirement already satisfied, skipping upgrade: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (3.0.0). Requirement already satisfied, skipping upgrade: google-auth-httplib2>=0.0.3 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.0.3). Requirement already satisfied, skipping upgrade: six<2dev,>=1.6.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.11.0). Requirement already satisfied, skipping upgrade: google-auth>=1.4.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.5.1). Requirement already satisfied, skipping upgrade: rsa>=3.1.4 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (3.4.2). Requirement already satisfied, skipping upgrade: cachetools>=2.0.0 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (2.1.0). Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (0.2.2). Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /usr/local/lib/python2.7/dist-packages (from rsa>=3.1.4->google-auth>=1.4.1->google-api-python-client) (0.4.4). ========== [2018年 08月 28日 星期二 10:55:17 CST] Stage 'Install TensorFlow pip package' starting. Skipping tf-nightly as it is not installed. Skipping tensorflow as it is not installed. Skipping tf-nightly-gpu as it is not installed. Skipping tensorflow-gpu as it is not installed. Installing Google Cloud Platform optimized CPU-only TensorFlow wheel. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 0 0 0 0 0 0 0 0 --:--:-- 0:02:09 --:--:-- 0curl: (7) Failed to connect to storage.googleapis.com port 443: Connection timed out.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:15520,performance,CPU,CPU-only,15520,"ping upgrade: httplib2<1dev,>=0.9.2 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.11.3). Requirement already satisfied, skipping upgrade: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (3.0.0). Requirement already satisfied, skipping upgrade: google-auth-httplib2>=0.0.3 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.0.3). Requirement already satisfied, skipping upgrade: six<2dev,>=1.6.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.11.0). Requirement already satisfied, skipping upgrade: google-auth>=1.4.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.5.1). Requirement already satisfied, skipping upgrade: rsa>=3.1.4 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (3.4.2). Requirement already satisfied, skipping upgrade: cachetools>=2.0.0 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (2.1.0). Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (0.2.2). Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /usr/local/lib/python2.7/dist-packages (from rsa>=3.1.4->google-auth>=1.4.1->google-api-python-client) (0.4.4). ========== [2018年 08月 28日 星期二 10:55:17 CST] Stage 'Install TensorFlow pip package' starting. Skipping tf-nightly as it is not installed. Skipping tensorflow as it is not installed. Skipping tf-nightly-gpu as it is not installed. Skipping tensorflow-gpu as it is not installed. Installing Google Cloud Platform optimized CPU-only TensorFlow wheel. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 0 0 0 0 0 0 0 0 --:--:-- 0:02:09 --:--:-- 0curl: (7) Failed to connect to storage.googleapis.com port 443: Connection timed out.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:15588,performance,Time,Time,15588,"ping upgrade: httplib2<1dev,>=0.9.2 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.11.3). Requirement already satisfied, skipping upgrade: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (3.0.0). Requirement already satisfied, skipping upgrade: google-auth-httplib2>=0.0.3 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.0.3). Requirement already satisfied, skipping upgrade: six<2dev,>=1.6.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.11.0). Requirement already satisfied, skipping upgrade: google-auth>=1.4.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.5.1). Requirement already satisfied, skipping upgrade: rsa>=3.1.4 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (3.4.2). Requirement already satisfied, skipping upgrade: cachetools>=2.0.0 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (2.1.0). Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (0.2.2). Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /usr/local/lib/python2.7/dist-packages (from rsa>=3.1.4->google-auth>=1.4.1->google-api-python-client) (0.4.4). ========== [2018年 08月 28日 星期二 10:55:17 CST] Stage 'Install TensorFlow pip package' starting. Skipping tf-nightly as it is not installed. Skipping tensorflow as it is not installed. Skipping tf-nightly-gpu as it is not installed. Skipping tensorflow-gpu as it is not installed. Installing Google Cloud Platform optimized CPU-only TensorFlow wheel. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 0 0 0 0 0 0 0 0 --:--:-- 0:02:09 --:--:-- 0curl: (7) Failed to connect to storage.googleapis.com port 443: Connection timed out.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:15593,performance,Time,Time,15593,"ping upgrade: httplib2<1dev,>=0.9.2 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.11.3). Requirement already satisfied, skipping upgrade: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (3.0.0). Requirement already satisfied, skipping upgrade: google-auth-httplib2>=0.0.3 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.0.3). Requirement already satisfied, skipping upgrade: six<2dev,>=1.6.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.11.0). Requirement already satisfied, skipping upgrade: google-auth>=1.4.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.5.1). Requirement already satisfied, skipping upgrade: rsa>=3.1.4 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (3.4.2). Requirement already satisfied, skipping upgrade: cachetools>=2.0.0 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (2.1.0). Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (0.2.2). Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /usr/local/lib/python2.7/dist-packages (from rsa>=3.1.4->google-auth>=1.4.1->google-api-python-client) (0.4.4). ========== [2018年 08月 28日 星期二 10:55:17 CST] Stage 'Install TensorFlow pip package' starting. Skipping tf-nightly as it is not installed. Skipping tensorflow as it is not installed. Skipping tf-nightly-gpu as it is not installed. Skipping tensorflow-gpu as it is not installed. Installing Google Cloud Platform optimized CPU-only TensorFlow wheel. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 0 0 0 0 0 0 0 0 --:--:-- 0:02:09 --:--:-- 0curl: (7) Failed to connect to storage.googleapis.com port 443: Connection timed out.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:15598,performance,Time,Time,15598,"ping upgrade: httplib2<1dev,>=0.9.2 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.11.3). Requirement already satisfied, skipping upgrade: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (3.0.0). Requirement already satisfied, skipping upgrade: google-auth-httplib2>=0.0.3 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.0.3). Requirement already satisfied, skipping upgrade: six<2dev,>=1.6.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.11.0). Requirement already satisfied, skipping upgrade: google-auth>=1.4.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.5.1). Requirement already satisfied, skipping upgrade: rsa>=3.1.4 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (3.4.2). Requirement already satisfied, skipping upgrade: cachetools>=2.0.0 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (2.1.0). Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (0.2.2). Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /usr/local/lib/python2.7/dist-packages (from rsa>=3.1.4->google-auth>=1.4.1->google-api-python-client) (0.4.4). ========== [2018年 08月 28日 星期二 10:55:17 CST] Stage 'Install TensorFlow pip package' starting. Skipping tf-nightly as it is not installed. Skipping tensorflow as it is not installed. Skipping tf-nightly-gpu as it is not installed. Skipping tensorflow-gpu as it is not installed. Installing Google Cloud Platform optimized CPU-only TensorFlow wheel. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 0 0 0 0 0 0 0 0 --:--:-- 0:02:09 --:--:-- 0curl: (7) Failed to connect to storage.googleapis.com port 443: Connection timed out.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:15767,performance,time,timed,15767,"ping upgrade: httplib2<1dev,>=0.9.2 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.11.3). Requirement already satisfied, skipping upgrade: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (3.0.0). Requirement already satisfied, skipping upgrade: google-auth-httplib2>=0.0.3 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.0.3). Requirement already satisfied, skipping upgrade: six<2dev,>=1.6.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.11.0). Requirement already satisfied, skipping upgrade: google-auth>=1.4.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.5.1). Requirement already satisfied, skipping upgrade: rsa>=3.1.4 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (3.4.2). Requirement already satisfied, skipping upgrade: cachetools>=2.0.0 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (2.1.0). Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (0.2.2). Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /usr/local/lib/python2.7/dist-packages (from rsa>=3.1.4->google-auth>=1.4.1->google-api-python-client) (0.4.4). ========== [2018年 08月 28日 星期二 10:55:17 CST] Stage 'Install TensorFlow pip package' starting. Skipping tf-nightly as it is not installed. Skipping tensorflow as it is not installed. Skipping tf-nightly-gpu as it is not installed. Skipping tensorflow-gpu as it is not installed. Installing Google Cloud Platform optimized CPU-only TensorFlow wheel. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 0 0 0 0 0 0 0 0 --:--:-- 0:02:09 --:--:-- 0curl: (7) Failed to connect to storage.googleapis.com port 443: Connection timed out.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:2713,reliability,Fail,Failed,2713,"google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://storage.googleapis.com/bazel-apt/dists/stable/InRelease Cannot initiate the connection to storage.googleapis.com:80 (2404:6800:4012:1::2010). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::2010 80]. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4008:803::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4008:803::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:2954,reliability,Fail,Failed,2954,"ud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://storage.googleapis.com/bazel-apt/dists/stable/InRelease Cannot initiate the connection to storage.googleapis.com:80 (2404:6800:4012:1::2010). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::2010 80]. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4008:803::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4008:803::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:3226,reliability,fail,failed,3226,"e times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://storage.googleapis.com/bazel-apt/dists/stable/InRelease Cannot initiate the connection to storage.googleapis.com:80 (2404:6800:4012:1::2010). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::2010 80]. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4008:803::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4008:803::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/d",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:6528,reliability,Fail,Failed,6528,"google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4012:1::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:6796,reliability,fail,failed,6796,"anslations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4012:1::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/d",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:15702,reliability,Fail,Failed,15702,"ping upgrade: httplib2<1dev,>=0.9.2 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.11.3). Requirement already satisfied, skipping upgrade: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (3.0.0). Requirement already satisfied, skipping upgrade: google-auth-httplib2>=0.0.3 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.0.3). Requirement already satisfied, skipping upgrade: six<2dev,>=1.6.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.11.0). Requirement already satisfied, skipping upgrade: google-auth>=1.4.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.5.1). Requirement already satisfied, skipping upgrade: rsa>=3.1.4 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (3.4.2). Requirement already satisfied, skipping upgrade: cachetools>=2.0.0 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (2.1.0). Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (0.2.2). Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /usr/local/lib/python2.7/dist-packages (from rsa>=3.1.4->google-auth>=1.4.1->google-api-python-client) (0.4.4). ========== [2018年 08月 28日 星期二 10:55:17 CST] Stage 'Install TensorFlow pip package' starting. Skipping tf-nightly as it is not installed. Skipping tensorflow as it is not installed. Skipping tf-nightly-gpu as it is not installed. Skipping tensorflow-gpu as it is not installed. Installing Google Cloud Platform optimized CPU-only TensorFlow wheel. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 0 0 0 0 0 0 0 0 --:--:-- 0:02:09 --:--:-- 0curl: (7) Failed to connect to storage.googleapis.com port 443: Connection timed out.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:540,safety,updat,updates,540,"@pichuan hi, i got the zip file and ra run-prereq.sh and this was the output:. solokopi@solokopi-All-Series:~/Desktop/DeepVariant-0.7.0+cl-208818123$ sudo bash run-prereq.sh. [sudo] password for solokopi: . ========== Load config settings. ========== [2018年 08月 28日 星期二 10:31:05 CST] Stage 'Misc setup' starting. Ign:1 http://dl.google.com/linux/chrome/deb stable InRelease. Hit:2 http://mirrors.aliyun.com/ubuntu xenial InRelease . Hit:3 http://dl.google.com/linux/chrome/deb stable Release . Hit:4 http://mirrors.aliyun.com/ubuntu xenial-updates InRelease . Get:6 http://mirrors.aliyun.com/ubuntu xenial-backports InRelease [107 kB] . Hit:7 http://mirrors.aliyun.com/ubuntu xenial-security InRelease . Hit:8 http://ppa.launchpad.net/webupd8team/java/ubuntu xenial InRelease . Err:9 http://storage.googleapis.com/bazel-apt stable InRelease . Cannot initiate the connection to storage.googleapis.com:80 (2404:6800:4012:1::2010). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::2010 80]. Err:10 http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease . Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4008:803::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4008:803::200e 80]. Fetched 107 kB in 12min 0s (148 B/s) . Reading package lists... Done. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:4614,safety,depend,dependency,4614,"urces.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. Reading package lists... Done. Building dependency tree . Reading state information... Done. sudo is already the newest version (1.8.16-0ubuntu1.5). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:43:08 CST] Stage 'Update package list' starting. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target P",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:5216,safety,Updat,Update,5216,"11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. Reading package lists... Done. Building dependency tree . Reading state information... Done. sudo is already the newest version (1.8.16-0ubuntu1.5). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:43:08 CST] Stage 'Update package list' starting. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configure",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:8275,safety,depend,dependency,8275,"igured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install development packages' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. pkg-config is already the newest version (0.29.1-0ubuntu1). unzip is already the newest version (6.0-20ubuntu1). zip is already the newest version (3.0-11). curl is already the newest version (7.47.0-1ubuntu2.8). zlib1g-dev is already the newest version (1:1.2.8.dfsg-2ubuntu4.1). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install python packaging infrastructure' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. python-wheel is already the newest",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:9193,safety,depend,dependency,9193,"tall development packages' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. pkg-config is already the newest version (0.29.1-0ubuntu1). unzip is already the newest version (6.0-20ubuntu1). zip is already the newest version (3.0-11). curl is already the newest version (7.47.0-1ubuntu2.8). zlib1g-dev is already the newest version (1:1.2.8.dfsg-2ubuntu4.1). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install python packaging infrastructure' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. python-wheel is already the newest version (0.29.0-1). python-dev is already the newest version (2.7.12-1~16.04). python-pip is already the newest version (8.1.1-2ubuntu0.4). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. Requirement already up-to-date: pip in /usr/local/lib/python2.7/dist-packages (18.0). ========== [2018年 08月 28日 星期二 10:55:12 CST] Stage 'Install python packages' starting. Requirement already satisfied: contextlib2 in /usr/local/lib/python2.7/dist-packages (0.5.5). Requirement already satisfied: enum34 in /usr/local/lib/python2.7/dis",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:12149,safety,modul,modules,12149,"hon2.7/dist-packages (2.19.1). Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python2.7/dist-packages (from requests>=2.18) (2018.8.13). Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python2.7/dist-packages (from requests>=2.18) (3.0.4). Requirement already satisfied: urllib3<1.24,>=1.21.1 in /usr/local/lib/python2.7/dist-packages (from requests>=2.18) (1.23). Requirement already satisfied: idna<2.8,>=2.5 in /usr/local/lib/python2.7/dist-packages (from requests>=2.18) (2.7). Requirement already satisfied: scipy==1.0 in /usr/local/lib/python2.7/dist-packages (1.0.0). Requirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python2.7/dist-packages (from scipy==1.0) (1.14.0). Requirement already satisfied: oauth2client>=4.0.0 in /usr/local/lib/python2.7/dist-packages (4.1.2). Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python2.7/dist-packages (from oauth2client>=4.0.0) (0.4.4). Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python2.7/dist-packages (from oauth2client>=4.0.0) (0.2.2). Requirement already satisfied: six>=1.6.1 in /usr/local/lib/python2.7/dist-packages (from oauth2client>=4.0.0) (1.11.0). Requirement already satisfied: httplib2>=0.9.1 in /usr/local/lib/python2.7/dist-packages (from oauth2client>=4.0.0) (0.11.3). Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python2.7/dist-packages (from oauth2client>=4.0.0) (3.4.2). Requirement already satisfied: crcmod>=1.7 in /usr/local/lib/python2.7/dist-packages (1.7). Requirement already satisfied: six in /usr/local/lib/python2.7/dist-packages (1.11.0). Requirement already satisfied: sklearn in /usr/local/lib/python2.7/dist-packages (0.0). Requirement already satisfied: scikit-learn in /usr/local/lib/python2.7/dist-packages (from sklearn) (0.19.2). Requirement already satisfied: pandas in /usr/local/lib/python2.7/dist-packages (0.23.4). Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python2.7/dist",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:14904,safety,modul,modules,14904,"ping upgrade: httplib2<1dev,>=0.9.2 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.11.3). Requirement already satisfied, skipping upgrade: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (3.0.0). Requirement already satisfied, skipping upgrade: google-auth-httplib2>=0.0.3 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.0.3). Requirement already satisfied, skipping upgrade: six<2dev,>=1.6.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.11.0). Requirement already satisfied, skipping upgrade: google-auth>=1.4.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.5.1). Requirement already satisfied, skipping upgrade: rsa>=3.1.4 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (3.4.2). Requirement already satisfied, skipping upgrade: cachetools>=2.0.0 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (2.1.0). Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (0.2.2). Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /usr/local/lib/python2.7/dist-packages (from rsa>=3.1.4->google-auth>=1.4.1->google-api-python-client) (0.4.4). ========== [2018年 08月 28日 星期二 10:55:17 CST] Stage 'Install TensorFlow pip package' starting. Skipping tf-nightly as it is not installed. Skipping tensorflow as it is not installed. Skipping tf-nightly-gpu as it is not installed. Skipping tensorflow-gpu as it is not installed. Installing Google Cloud Platform optimized CPU-only TensorFlow wheel. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 0 0 0 0 0 0 0 0 --:--:-- 0:02:09 --:--:-- 0curl: (7) Failed to connect to storage.googleapis.com port 443: Connection timed out.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:182,security,password,password,182,"@pichuan hi, i got the zip file and ra run-prereq.sh and this was the output:. solokopi@solokopi-All-Series:~/Desktop/DeepVariant-0.7.0+cl-208818123$ sudo bash run-prereq.sh. [sudo] password for solokopi: . ========== Load config settings. ========== [2018年 08月 28日 星期二 10:31:05 CST] Stage 'Misc setup' starting. Ign:1 http://dl.google.com/linux/chrome/deb stable InRelease. Hit:2 http://mirrors.aliyun.com/ubuntu xenial InRelease . Hit:3 http://dl.google.com/linux/chrome/deb stable Release . Hit:4 http://mirrors.aliyun.com/ubuntu xenial-updates InRelease . Get:6 http://mirrors.aliyun.com/ubuntu xenial-backports InRelease [107 kB] . Hit:7 http://mirrors.aliyun.com/ubuntu xenial-security InRelease . Hit:8 http://ppa.launchpad.net/webupd8team/java/ubuntu xenial InRelease . Err:9 http://storage.googleapis.com/bazel-apt stable InRelease . Cannot initiate the connection to storage.googleapis.com:80 (2404:6800:4012:1::2010). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::2010 80]. Err:10 http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease . Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4008:803::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4008:803::200e 80]. Fetched 107 kB in 12min 0s (148 B/s) . Reading package lists... Done. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:540,security,updat,updates,540,"@pichuan hi, i got the zip file and ra run-prereq.sh and this was the output:. solokopi@solokopi-All-Series:~/Desktop/DeepVariant-0.7.0+cl-208818123$ sudo bash run-prereq.sh. [sudo] password for solokopi: . ========== Load config settings. ========== [2018年 08月 28日 星期二 10:31:05 CST] Stage 'Misc setup' starting. Ign:1 http://dl.google.com/linux/chrome/deb stable InRelease. Hit:2 http://mirrors.aliyun.com/ubuntu xenial InRelease . Hit:3 http://dl.google.com/linux/chrome/deb stable Release . Hit:4 http://mirrors.aliyun.com/ubuntu xenial-updates InRelease . Get:6 http://mirrors.aliyun.com/ubuntu xenial-backports InRelease [107 kB] . Hit:7 http://mirrors.aliyun.com/ubuntu xenial-security InRelease . Hit:8 http://ppa.launchpad.net/webupd8team/java/ubuntu xenial InRelease . Err:9 http://storage.googleapis.com/bazel-apt stable InRelease . Cannot initiate the connection to storage.googleapis.com:80 (2404:6800:4012:1::2010). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::2010 80]. Err:10 http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease . Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4008:803::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4008:803::200e 80]. Fetched 107 kB in 12min 0s (148 B/s) . Reading package lists... Done. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:683,security,secur,security,683,"@pichuan hi, i got the zip file and ra run-prereq.sh and this was the output:. solokopi@solokopi-All-Series:~/Desktop/DeepVariant-0.7.0+cl-208818123$ sudo bash run-prereq.sh. [sudo] password for solokopi: . ========== Load config settings. ========== [2018年 08月 28日 星期二 10:31:05 CST] Stage 'Misc setup' starting. Ign:1 http://dl.google.com/linux/chrome/deb stable InRelease. Hit:2 http://mirrors.aliyun.com/ubuntu xenial InRelease . Hit:3 http://dl.google.com/linux/chrome/deb stable Release . Hit:4 http://mirrors.aliyun.com/ubuntu xenial-updates InRelease . Get:6 http://mirrors.aliyun.com/ubuntu xenial-backports InRelease [107 kB] . Hit:7 http://mirrors.aliyun.com/ubuntu xenial-security InRelease . Hit:8 http://ppa.launchpad.net/webupd8team/java/ubuntu xenial InRelease . Err:9 http://storage.googleapis.com/bazel-apt stable InRelease . Cannot initiate the connection to storage.googleapis.com:80 (2404:6800:4012:1::2010). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::2010 80]. Err:10 http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease . Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4008:803::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4008:803::200e 80]. Fetched 107 kB in 12min 0s (148 B/s) . Reading package lists... Done. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:820,security,apt,apt,820,"@pichuan hi, i got the zip file and ra run-prereq.sh and this was the output:. solokopi@solokopi-All-Series:~/Desktop/DeepVariant-0.7.0+cl-208818123$ sudo bash run-prereq.sh. [sudo] password for solokopi: . ========== Load config settings. ========== [2018年 08月 28日 星期二 10:31:05 CST] Stage 'Misc setup' starting. Ign:1 http://dl.google.com/linux/chrome/deb stable InRelease. Hit:2 http://mirrors.aliyun.com/ubuntu xenial InRelease . Hit:3 http://dl.google.com/linux/chrome/deb stable Release . Hit:4 http://mirrors.aliyun.com/ubuntu xenial-updates InRelease . Get:6 http://mirrors.aliyun.com/ubuntu xenial-backports InRelease [107 kB] . Hit:7 http://mirrors.aliyun.com/ubuntu xenial-security InRelease . Hit:8 http://ppa.launchpad.net/webupd8team/java/ubuntu xenial InRelease . Err:9 http://storage.googleapis.com/bazel-apt stable InRelease . Cannot initiate the connection to storage.googleapis.com:80 (2404:6800:4012:1::2010). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::2010 80]. Err:10 http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease . Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4008:803::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4008:803::200e 80]. Fetched 107 kB in 12min 0s (148 B/s) . Reading package lists... Done. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:945,security,Network,Network,945,"@pichuan hi, i got the zip file and ra run-prereq.sh and this was the output:. solokopi@solokopi-All-Series:~/Desktop/DeepVariant-0.7.0+cl-208818123$ sudo bash run-prereq.sh. [sudo] password for solokopi: . ========== Load config settings. ========== [2018年 08月 28日 星期二 10:31:05 CST] Stage 'Misc setup' starting. Ign:1 http://dl.google.com/linux/chrome/deb stable InRelease. Hit:2 http://mirrors.aliyun.com/ubuntu xenial InRelease . Hit:3 http://dl.google.com/linux/chrome/deb stable Release . Hit:4 http://mirrors.aliyun.com/ubuntu xenial-updates InRelease . Get:6 http://mirrors.aliyun.com/ubuntu xenial-backports InRelease [107 kB] . Hit:7 http://mirrors.aliyun.com/ubuntu xenial-security InRelease . Hit:8 http://ppa.launchpad.net/webupd8team/java/ubuntu xenial InRelease . Err:9 http://storage.googleapis.com/bazel-apt stable InRelease . Cannot initiate the connection to storage.googleapis.com:80 (2404:6800:4012:1::2010). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::2010 80]. Err:10 http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease . Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4008:803::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4008:803::200e 80]. Fetched 107 kB in 12min 0s (148 B/s) . Reading package lists... Done. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:1042,security,apt,apt,1042,rereq.sh and this was the output:. solokopi@solokopi-All-Series:~/Desktop/DeepVariant-0.7.0+cl-208818123$ sudo bash run-prereq.sh. [sudo] password for solokopi: . ========== Load config settings. ========== [2018年 08月 28日 星期二 10:31:05 CST] Stage 'Misc setup' starting. Ign:1 http://dl.google.com/linux/chrome/deb stable InRelease. Hit:2 http://mirrors.aliyun.com/ubuntu xenial InRelease . Hit:3 http://dl.google.com/linux/chrome/deb stable Release . Hit:4 http://mirrors.aliyun.com/ubuntu xenial-updates InRelease . Get:6 http://mirrors.aliyun.com/ubuntu xenial-backports InRelease [107 kB] . Hit:7 http://mirrors.aliyun.com/ubuntu xenial-security InRelease . Hit:8 http://ppa.launchpad.net/webupd8team/java/ubuntu xenial InRelease . Err:9 http://storage.googleapis.com/bazel-apt stable InRelease . Cannot initiate the connection to storage.googleapis.com:80 (2404:6800:4012:1::2010). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::2010 80]. Err:10 http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease . Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4008:803::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4008:803::200e 80]. Fetched 107 kB in 12min 0s (148 B/s) . Reading package lists... Done. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multi,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:1182,security,Network,Network,1182,word for solokopi: . ========== Load config settings. ========== [2018年 08月 28日 星期二 10:31:05 CST] Stage 'Misc setup' starting. Ign:1 http://dl.google.com/linux/chrome/deb stable InRelease. Hit:2 http://mirrors.aliyun.com/ubuntu xenial InRelease . Hit:3 http://dl.google.com/linux/chrome/deb stable Release . Hit:4 http://mirrors.aliyun.com/ubuntu xenial-updates InRelease . Get:6 http://mirrors.aliyun.com/ubuntu xenial-backports InRelease [107 kB] . Hit:7 http://mirrors.aliyun.com/ubuntu xenial-security InRelease . Hit:8 http://ppa.launchpad.net/webupd8team/java/ubuntu xenial InRelease . Err:9 http://storage.googleapis.com/bazel-apt stable InRelease . Cannot initiate the connection to storage.googleapis.com:80 (2404:6800:4012:1::2010). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::2010 80]. Err:10 http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease . Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4008:803::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4008:803::200e 80]. Fetched 107 kB in 12min 0s (148 B/s) . Reading package lists... Done. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:1370,security,apt,apt,1370,e. Hit:2 http://mirrors.aliyun.com/ubuntu xenial InRelease . Hit:3 http://dl.google.com/linux/chrome/deb stable Release . Hit:4 http://mirrors.aliyun.com/ubuntu xenial-updates InRelease . Get:6 http://mirrors.aliyun.com/ubuntu xenial-backports InRelease [107 kB] . Hit:7 http://mirrors.aliyun.com/ubuntu xenial-security InRelease . Hit:8 http://ppa.launchpad.net/webupd8team/java/ubuntu xenial InRelease . Err:9 http://storage.googleapis.com/bazel-apt stable InRelease . Cannot initiate the connection to storage.googleapis.com:80 (2404:6800:4012:1::2010). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::2010 80]. Err:10 http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease . Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4008:803::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4008:803::200e 80]. Fetched 107 kB in 12min 0s (148 B/s) . Reading package lists... Done. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Co,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:1483,security,configur,configured,1483,ase . Hit:4 http://mirrors.aliyun.com/ubuntu xenial-updates InRelease . Get:6 http://mirrors.aliyun.com/ubuntu xenial-backports InRelease [107 kB] . Hit:7 http://mirrors.aliyun.com/ubuntu xenial-security InRelease . Hit:8 http://ppa.launchpad.net/webupd8team/java/ubuntu xenial InRelease . Err:9 http://storage.googleapis.com/bazel-apt stable InRelease . Cannot initiate the connection to storage.googleapis.com:80 (2404:6800:4012:1::2010). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::2010 80]. Err:10 http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease . Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4008:803::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4008:803::200e 80]. Fetched 107 kB in 12min 0s (148 B/s) . Reading package lists... Done. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sou,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:1517,security,apt,apt,1517,un.com/ubuntu xenial-updates InRelease . Get:6 http://mirrors.aliyun.com/ubuntu xenial-backports InRelease [107 kB] . Hit:7 http://mirrors.aliyun.com/ubuntu xenial-security InRelease . Hit:8 http://ppa.launchpad.net/webupd8team/java/ubuntu xenial InRelease . Err:9 http://storage.googleapis.com/bazel-apt stable InRelease . Cannot initiate the connection to storage.googleapis.com:80 (2404:6800:4012:1::2010). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::2010 80]. Err:10 http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease . Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4008:803::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4008:803::200e 80]. Fetched 107 kB in 12min 0s (148 B/s) . Reading package lists... Done. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.li,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:1569,security,apt,apt,1569,//mirrors.aliyun.com/ubuntu xenial-backports InRelease [107 kB] . Hit:7 http://mirrors.aliyun.com/ubuntu xenial-security InRelease . Hit:8 http://ppa.launchpad.net/webupd8team/java/ubuntu xenial InRelease . Err:9 http://storage.googleapis.com/bazel-apt stable InRelease . Cannot initiate the connection to storage.googleapis.com:80 (2404:6800:4012:1::2010). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::2010 80]. Err:10 http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease . Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4008:803::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4008:803::200e 80]. Fetched 107 kB in 12min 0s (148 B/s) . Reading package lists... Done. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:1663,security,configur,configured,1663,/ubuntu xenial-security InRelease . Hit:8 http://ppa.launchpad.net/webupd8team/java/ubuntu xenial InRelease . Err:9 http://storage.googleapis.com/bazel-apt stable InRelease . Cannot initiate the connection to storage.googleapis.com:80 (2404:6800:4012:1::2010). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::2010 80]. Err:10 http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease . Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4008:803::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4008:803::200e 80]. Fetched 107 kB in 12min 0s (148 B/s) . Reading package lists... Done. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/ap,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:1697,security,apt,apt,1697,se . Hit:8 http://ppa.launchpad.net/webupd8team/java/ubuntu xenial InRelease . Err:9 http://storage.googleapis.com/bazel-apt stable InRelease . Cannot initiate the connection to storage.googleapis.com:80 (2404:6800:4012:1::2010). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::2010 80]. Err:10 http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease . Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4008:803::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4008:803::200e 80]. Fetched 107 kB in 12min 0s (148 B/s) . Reading package lists... Done. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-s,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:1749,security,apt,apt,1749,/ubuntu xenial InRelease . Err:9 http://storage.googleapis.com/bazel-apt stable InRelease . Cannot initiate the connection to storage.googleapis.com:80 (2404:6800:4012:1::2010). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::2010 80]. Err:10 http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease . Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4008:803::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4008:803::200e 80]. Fetched 107 kB in 12min 0s (148 B/s) . Reading package lists... Done. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://storage.googlea,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:1842,security,configur,configured,1842,ot initiate the connection to storage.googleapis.com:80 (2404:6800:4012:1::2010). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::2010 80]. Err:10 http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease . Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4008:803::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4008:803::200e 80]. Fetched 107 kB in 12min 0s (148 B/s) . Reading package lists... Done. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://storage.googleapis.com/bazel-apt/dists/stable/InRelease Cannot initiate the connection to storage.googleapis.co,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:1876,security,apt,apt,1876,torage.googleapis.com:80 (2404:6800:4012:1::2010). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::2010 80]. Err:10 http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease . Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4008:803::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4008:803::200e 80]. Fetched 107 kB in 12min 0s (148 B/s) . Reading package lists... Done. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://storage.googleapis.com/bazel-apt/dists/stable/InRelease Cannot initiate the connection to storage.googleapis.com:80 (2404:6800:4012:1::2010). ,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:1928,security,apt,apt,1928, connect (101: Network is unreachable) [IP: 2404:6800:4012:1::2010 80]. Err:10 http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease . Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4008:803::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4008:803::200e 80]. Fetched 107 kB in 12min 0s (148 B/s) . Reading package lists... Done. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://storage.googleapis.com/bazel-apt/dists/stable/InRelease Cannot initiate the connection to storage.googleapis.com:80 (2404:6800:4012:1::2010). - connect (101: Network is unreachable) [IP: 2404:68,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:2028,security,configur,configured,2028,ogle.com/apt cloud-sdk-xenial InRelease . Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4008:803::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4008:803::200e 80]. Fetched 107 kB in 12min 0s (148 B/s) . Reading package lists... Done. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://storage.googleapis.com/bazel-apt/dists/stable/InRelease Cannot initiate the connection to storage.googleapis.com:80 (2404:6800:4012:1::2010). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::2010 80]. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InR,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:2062,security,apt,apt,2062,nRelease . Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4008:803::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4008:803::200e 80]. Fetched 107 kB in 12min 0s (148 B/s) . Reading package lists... Done. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://storage.googleapis.com/bazel-apt/dists/stable/InRelease Cannot initiate the connection to storage.googleapis.com:80 (2404:6800:4012:1::2010). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::2010 80]. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the conn,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:2114,security,apt,apt,2114,s.cloud.google.com:80 (2404:6800:4008:803::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4008:803::200e 80]. Fetched 107 kB in 12min 0s (148 B/s) . Reading package lists... Done. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://storage.googleapis.com/bazel-apt/dists/stable/InRelease Cannot initiate the connection to storage.googleapis.com:80 (2404:6800:4012:1::2010). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::2010 80]. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:40,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:2211,security,configur,configured,2211,6800:4008:803::200e 80]. Fetched 107 kB in 12min 0s (148 B/s) . Reading package lists... Done. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://storage.googleapis.com/bazel-apt/dists/stable/InRelease Cannot initiate the connection to storage.googleapis.com:80 (2404:6800:4012:1::2010). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::2010 80]. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4008:803::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4008:803::200e 80]. W: Some in,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:2245,security,apt,apt,2245,d 107 kB in 12min 0s (148 B/s) . Reading package lists... Done. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://storage.googleapis.com/bazel-apt/dists/stable/InRelease Cannot initiate the connection to storage.googleapis.com:80 (2404:6800:4012:1::2010). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::2010 80]. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4008:803::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4008:803::200e 80]. W: Some index files failed to download. T,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:2297,security,apt,apt,2297,"ts... Done. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://storage.googleapis.com/bazel-apt/dists/stable/InRelease Cannot initiate the connection to storage.googleapis.com:80 (2404:6800:4012:1::2010). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::2010 80]. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4008:803::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4008:803::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:2395,security,configur,configured,2395," an invalid filename extension. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://storage.googleapis.com/bazel-apt/dists/stable/InRelease Cannot initiate the connection to storage.googleapis.com:80 (2404:6800:4012:1::2010). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::2010 80]. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4008:803::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4008:803::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:2429,security,apt,apt,2429," W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://storage.googleapis.com/bazel-apt/dists/stable/InRelease Cannot initiate the connection to storage.googleapis.com:80 (2404:6800:4012:1::2010). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::2010 80]. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4008:803::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4008:803::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /et",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:2481,security,apt,apt,2481,"configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://storage.googleapis.com/bazel-apt/dists/stable/InRelease Cannot initiate the connection to storage.googleapis.com:80 (2404:6800:4012:1::2010). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::2010 80]. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4008:803::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4008:803::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Tar",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:2580,security,configur,configured,2580,".d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://storage.googleapis.com/bazel-apt/dists/stable/InRelease Cannot initiate the connection to storage.googleapis.com:80 (2404:6800:4012:1::2010). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::2010 80]. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4008:803::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4008:803::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/googl",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:2614,security,apt,apt,2614,"Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://storage.googleapis.com/bazel-apt/dists/stable/InRelease Cannot initiate the connection to storage.googleapis.com:80 (2404:6800:4012:1::2010). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::2010 80]. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4008:803::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4008:803::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:2666,security,apt,apt,2666,"gured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://storage.googleapis.com/bazel-apt/dists/stable/InRelease Cannot initiate the connection to storage.googleapis.com:80 (2404:6800:4012:1::2010). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::2010 80]. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4008:803::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4008:803::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target P",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:2765,security,apt,apt,2765,"/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://storage.googleapis.com/bazel-apt/dists/stable/InRelease Cannot initiate the connection to storage.googleapis.com:80 (2404:6800:4012:1::2010). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::2010 80]. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4008:803::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4008:803::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-c",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:2894,security,Network,Network,2894,"gle-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://storage.googleapis.com/bazel-apt/dists/stable/InRelease Cannot initiate the connection to storage.googleapis.com:80 (2404:6800:4012:1::2010). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::2010 80]. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4008:803::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4008:803::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is config",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:3003,security,apt,apt,3003,"/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://storage.googleapis.com/bazel-apt/dists/stable/InRelease Cannot initiate the connection to storage.googleapis.com:80 (2404:6800:4012:1::2010). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::2010 80]. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4008:803::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4008:803::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-c",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:3147,security,Network,Network,3147,"ist:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://storage.googleapis.com/bazel-apt/dists/stable/InRelease Cannot initiate the connection to storage.googleapis.com:80 (2404:6800:4012:1::2010). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::2010 80]. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4008:803::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4008:803::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:3347,security,configur,configured,3347,"EP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://storage.googleapis.com/bazel-apt/dists/stable/InRelease Cannot initiate the connection to storage.googleapis.com:80 (2404:6800:4012:1::2010). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::2010 80]. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4008:803::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4008:803::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sou",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:3381,security,apt,apt,3381,"d64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://storage.googleapis.com/bazel-apt/dists/stable/InRelease Cannot initiate the connection to storage.googleapis.com:80 (2404:6800:4012:1::2010). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::2010 80]. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4008:803::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4008:803::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.li",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:3433,security,apt,apt,3433,"urces.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://storage.googleapis.com/bazel-apt/dists/stable/InRelease Cannot initiate the connection to storage.googleapis.com:80 (2404:6800:4012:1::2010). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::2010 80]. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4008:803::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4008:803::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:3527,security,configur,configured,3527,"et DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://storage.googleapis.com/bazel-apt/dists/stable/InRelease Cannot initiate the connection to storage.googleapis.com:80 (2404:6800:4012:1::2010). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::2010 80]. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4008:803::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4008:803::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/ap",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:3561,security,apt,apt,3561,"ns-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://storage.googleapis.com/bazel-apt/dists/stable/InRelease Cannot initiate the connection to storage.googleapis.com:80 (2404:6800:4012:1::2010). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::2010 80]. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4008:803::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4008:803::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-s",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:3613,security,apt,apt,3613,"pt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://storage.googleapis.com/bazel-apt/dists/stable/InRelease Cannot initiate the connection to storage.googleapis.com:80 (2404:6800:4012:1::2010). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::2010 80]. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4008:803::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4008:803::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. Reading package lists... Done. Building d",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:3706,security,configur,configured,3706,": Failed to fetch http://storage.googleapis.com/bazel-apt/dists/stable/InRelease Cannot initiate the connection to storage.googleapis.com:80 (2404:6800:4012:1::2010). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::2010 80]. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4008:803::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4008:803::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. Reading package lists... Done. Building dependency tree . Reading state information... Done. sudo is already the newest version (1.8.16-0",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:3740,security,apt,apt,3740,"e.googleapis.com/bazel-apt/dists/stable/InRelease Cannot initiate the connection to storage.googleapis.com:80 (2404:6800:4012:1::2010). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::2010 80]. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4008:803::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4008:803::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. Reading package lists... Done. Building dependency tree . Reading state information... Done. sudo is already the newest version (1.8.16-0ubuntu1.5). The following packa",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:3792,security,apt,apt,3792,"nnot initiate the connection to storage.googleapis.com:80 (2404:6800:4012:1::2010). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::2010 80]. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4008:803::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4008:803::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. Reading package lists... Done. Building dependency tree . Reading state information... Done. sudo is already the newest version (1.8.16-0ubuntu1.5). The following packages were automatically installed and are no longer r",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:3892,security,configur,configured,3892,"work is unreachable) [IP: 2404:6800:4012:1::2010 80]. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4008:803::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4008:803::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. Reading package lists... Done. Building dependency tree . Reading state information... Done. sudo is already the newest version (1.8.16-0ubuntu1.5). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-gen",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:3926,security,apt,apt,3926,"6800:4012:1::2010 80]. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4008:803::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4008:803::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. Reading package lists... Done. Building dependency tree . Reading state information... Done. sudo is already the newest version (1.8.16-0ubuntu1.5). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-3",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:3978,security,apt,apt,3978,"kages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4008:803::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4008:803::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. Reading package lists... Done. Building dependency tree . Reading state information... Done. sudo is already the newest version (1.8.16-0ubuntu1.5). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:4075,security,configur,configured,4075,"es.cloud.google.com:80 (2404:6800:4008:803::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4008:803::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. Reading package lists... Done. Building dependency tree . Reading state information... Done. sudo is already the newest version (1.8.16-0ubuntu1.5). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:4109,security,apt,apt,4109,"00:4008:803::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4008:803::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. Reading package lists... Done. Building dependency tree . Reading state information... Done. sudo is already the newest version (1.8.16-0ubuntu1.5). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sour",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:4161,security,apt,apt,4161,"chable) [IP: 2404:6800:4008:803::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. Reading package lists... Done. Building dependency tree . Reading state information... Done. sudo is already the newest version (1.8.16-0ubuntu1.5). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:4259,security,configur,configured,4259,"ored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. Reading package lists... Done. Building dependency tree . Reading state information... Done. sudo is already the newest version (1.8.16-0ubuntu1.5). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:43:08 CST] Stage 'Update package list' starting. W: Target Package",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:4293,security,apt,apt,4293," W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. Reading package lists... Done. Building dependency tree . Reading state information... Done. sudo is already the newest version (1.8.16-0ubuntu1.5). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:43:08 CST] Stage 'Update package list' starting. W: Target Packages (main/binary-amd64/Packages) ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:4345,security,apt,apt,4345,"configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. Reading package lists... Done. Building dependency tree . Reading state information... Done. sudo is already the newest version (1.8.16-0ubuntu1.5). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:43:08 CST] Stage 'Update package list' starting. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.lis",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:4444,security,configur,configured,4444,".d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. Reading package lists... Done. Building dependency tree . Reading state information... Done. sudo is already the newest version (1.8.16-0ubuntu1.5). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:43:08 CST] Stage 'Update package list' starting. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (m",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:4478,security,apt,apt,4478,"Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. Reading package lists... Done. Building dependency tree . Reading state information... Done. sudo is already the newest version (1.8.16-0ubuntu1.5). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:43:08 CST] Stage 'Update package list' starting. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is co",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:4530,security,apt,apt,4530,"gured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. Reading package lists... Done. Building dependency tree . Reading state information... Done. sudo is already the newest version (1.8.16-0ubuntu1.5). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:43:08 CST] Stage 'Update package list' starting. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/g",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:4949,security,apt,apt,4949,"-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. Reading package lists... Done. Building dependency tree . Reading state information... Done. sudo is already the newest version (1.8.16-0ubuntu1.5). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:43:08 CST] Stage 'Update package list' starting. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/goo",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:5103,security,apt,apt,5103,"etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. Reading package lists... Done. Building dependency tree . Reading state information... Done. sudo is already the newest version (1.8.16-0ubuntu1.5). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:43:08 CST] Stage 'Update package list' starting. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 an",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:5216,security,Updat,Update,5216,"11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. Reading package lists... Done. Building dependency tree . Reading state information... Done. sudo is already the newest version (1.8.16-0ubuntu1.5). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:43:08 CST] Stage 'Update package list' starting. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configure",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:5298,security,configur,configured,5298,"s.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. Reading package lists... Done. Building dependency tree . Reading state information... Done. sudo is already the newest version (1.8.16-0ubuntu1.5). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:43:08 CST] Stage 'Update package list' starting. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sou",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:5332,security,apt,apt,5332,"1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. Reading package lists... Done. Building dependency tree . Reading state information... Done. sudo is already the newest version (1.8.16-0ubuntu1.5). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:43:08 CST] Stage 'Update package list' starting. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.li",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:5384,security,apt,apt,5384,"2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. Reading package lists... Done. Building dependency tree . Reading state information... Done. sudo is already the newest version (1.8.16-0ubuntu1.5). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:43:08 CST] Stage 'Update package list' starting. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:5478,security,configur,configured,5478,"ources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. Reading package lists... Done. Building dependency tree . Reading state information... Done. sudo is already the newest version (1.8.16-0ubuntu1.5). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:43:08 CST] Stage 'Update package list' starting. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/ap",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:5512,security,apt,apt,5512,"list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. Reading package lists... Done. Building dependency tree . Reading state information... Done. sudo is already the newest version (1.8.16-0ubuntu1.5). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:43:08 CST] Stage 'Update package list' starting. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-s",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:5564,security,apt,apt,5564,"list:2. Reading package lists... Done. Building dependency tree . Reading state information... Done. sudo is already the newest version (1.8.16-0ubuntu1.5). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:43:08 CST] Stage 'Update package list' starting. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://packages.cloud.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:5657,security,configur,configured,5657,"one. sudo is already the newest version (1.8.16-0ubuntu1.5). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:43:08 CST] Stage 'Update package list' starting. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:5691,security,apt,apt,5691," version (1.8.16-0ubuntu1.5). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:43:08 CST] Stage 'Update package list' starting. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4012:",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:5743,security,apt,apt,5743," were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:43:08 CST] Stage 'Update package list' starting. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4012:1::200e). - connect (101: Network is unreachable) [I",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:5843,security,configur,configured,5843,"ders-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:43:08 CST] Stage 'Update package list' starting. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4012:1::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::200e 80]. W: Some index files failed to download. They have been ignored, or old o",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:5877,security,apt,apt,5877,"mage-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:43:08 CST] Stage 'Update package list' starting. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4012:1::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Pac",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:5929,security,apt,apt,5929,"eneric. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:43:08 CST] Stage 'Update package list' starting. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4012:1::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured mul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:6026,security,configur,configured,6026,"ot upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:43:08 CST] Stage 'Update package list' starting. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4012:1::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cl",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:6060,security,apt,apt,6060,"google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:43:08 CST] Stage 'Update package list' starting. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4012:1::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packa",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:6112,security,apt,apt,6112,".list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:43:08 CST] Stage 'Update package list' starting. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4012:1::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multip",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:6210,security,configur,configured,6210,"'Update package list' starting. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4012:1::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:6244,security,apt,apt,6244," W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4012:1::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:6296,security,apt,apt,6296,"configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4012:1::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple ti",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:6395,security,configur,configured,6395,".d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4012:1::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.li",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:6429,security,apt,apt,6429,"Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4012:1::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (m",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:6481,security,apt,apt,6481,"gured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4012:1::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple t",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:6577,security,apt,apt,6577,"t.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4012:1::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:6719,security,Network,Network,6719,"sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4012:1::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 a",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:6917,security,configur,configured,6917,"d /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4012:1::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sou",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:6951,security,apt,apt,6951,"e-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4012:1::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.li",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:7003,security,apt,apt,7003,"n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4012:1::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:7097,security,configur,configured,7097," and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4012:1::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/ap",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:7131,security,apt,apt,7131,"ogle-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4012:1::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-s",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:7183,security,apt,apt,7183,"Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4012:1::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. ========== [2018年 08月 28日 星期二 10:55:10 CS",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:7276,security,configur,configured,7276,"ist:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4012:1::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install development packages' starting. Reading package lists... Done. Building depend",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:7310,security,apt,apt,7310,".d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4012:1::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install development packages' starting. Reading package lists... Done. Building dependency tree . Reading state infor",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:7362,security,apt,apt,7362,"main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4012:1::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install development packages' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. pkg-config is already the newest ver",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:7462,security,configur,configured,7462,"st:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4012:1::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install development packages' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. pkg-config is already the newest version (0.29.1-0ubuntu1). unzip is already the newest version (6.0-20ubuntu1). zip is already the newest ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:7496,security,apt,apt,7496,"d/google-cloud-sdk.list:2. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4012:1::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install development packages' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. pkg-config is already the newest version (0.29.1-0ubuntu1). unzip is already the newest version (6.0-20ubuntu1). zip is already the newest version (3.0-11). curl is alrea",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:7548,security,apt,apt,7548,"/packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4012:1::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install development packages' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. pkg-config is already the newest version (0.29.1-0ubuntu1). unzip is already the newest version (6.0-20ubuntu1). zip is already the newest version (3.0-11). curl is already the newest version (7.47.0-1ubuntu2.8). zlib1g-de",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:7645,security,configur,configured,7645,"ckages.cloud.google.com:80 (2404:6800:4012:1::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install development packages' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. pkg-config is already the newest version (0.29.1-0ubuntu1). unzip is already the newest version (6.0-20ubuntu1). zip is already the newest version (3.0-11). curl is already the newest version (7.47.0-1ubuntu2.8). zlib1g-dev is already the newest version (1:1.2.8.dfsg-2ubuntu4.1). The following packages were automatically",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:7679,security,apt,apt,7679,"4:6800:4012:1::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install development packages' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. pkg-config is already the newest version (0.29.1-0ubuntu1). unzip is already the newest version (6.0-20ubuntu1). zip is already the newest version (3.0-11). curl is already the newest version (7.47.0-1ubuntu2.8). zlib1g-dev is already the newest version (1:1.2.8.dfsg-2ubuntu4.1). The following packages were automatically installed and are no longer re",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:7731,security,apt,apt,7731,"eachable) [IP: 2404:6800:4012:1::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install development packages' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. pkg-config is already the newest version (0.29.1-0ubuntu1). unzip is already the newest version (6.0-20ubuntu1). zip is already the newest version (3.0-11). curl is already the newest version (7.47.0-1ubuntu2.8). zlib1g-dev is already the newest version (1:1.2.8.dfsg-2ubuntu4.1). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-he",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:7829,security,configur,configured,7829,"ored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install development packages' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. pkg-config is already the newest version (0.29.1-0ubuntu1). unzip is already the newest version (6.0-20ubuntu1). zip is already the newest version (3.0-11). curl is already the newest version (7.47.0-1ubuntu2.8). zlib1g-dev is already the newest version (1:1.2.8.dfsg-2ubuntu4.1). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:7863,security,apt,apt,7863, W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install development packages' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. pkg-config is already the newest version (0.29.1-0ubuntu1). unzip is already the newest version (6.0-20ubuntu1). zip is already the newest version (3.0-11). curl is already the newest version (7.47.0-1ubuntu2.8). zlib1g-dev is already the newest version (1:1.2.8.dfsg-2ubuntu4.1). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:7915,security,apt,apt,7915,"configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install development packages' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. pkg-config is already the newest version (0.29.1-0ubuntu1). unzip is already the newest version (6.0-20ubuntu1). zip is already the newest version (3.0-11). curl is already the newest version (7.47.0-1ubuntu2.8). zlib1g-dev is already the newest version (1:1.2.8.dfsg-2ubuntu4.1). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 n",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:8014,security,configur,configured,8014,".d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install development packages' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. pkg-config is already the newest version (0.29.1-0ubuntu1). unzip is already the newest version (6.0-20ubuntu1). zip is already the newest version (3.0-11). curl is already the newest version (7.47.0-1ubuntu2.8). zlib1g-dev is already the newest version (1:1.2.8.dfsg-2ubuntu4.1). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:8048,security,apt,apt,8048,"Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install development packages' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. pkg-config is already the newest version (0.29.1-0ubuntu1). unzip is already the newest version (6.0-20ubuntu1). zip is already the newest version (3.0-11). curl is already the newest version (7.47.0-1ubuntu2.8). zlib1g-dev is already the newest version (1:1.2.8.dfsg-2ubuntu4.1). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:8100,security,apt,apt,8100,"gured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install development packages' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. pkg-config is already the newest version (0.29.1-0ubuntu1). unzip is already the newest version (6.0-20ubuntu1). zip is already the newest version (3.0-11). curl is already the newest version (7.47.0-1ubuntu2.8). zlib1g-dev is already the newest version (1:1.2.8.dfsg-2ubuntu4.1). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage '",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:8835,security,apt,apt,8835,"ed multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install development packages' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. pkg-config is already the newest version (0.29.1-0ubuntu1). unzip is already the newest version (6.0-20ubuntu1). zip is already the newest version (3.0-11). curl is already the newest version (7.47.0-1ubuntu2.8). zlib1g-dev is already the newest version (1:1.2.8.dfsg-2ubuntu4.1). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install python packaging infrastructure' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. python-wheel is already the newest version (0.29.0-1). python-dev is already the newest version (2.7.12-1~16.04). python-pip is already the newest version (8.1.1-2ubuntu0.4). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an in",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:8989,security,apt,apt,8989,"11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install development packages' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. pkg-config is already the newest version (0.29.1-0ubuntu1). unzip is already the newest version (6.0-20ubuntu1). zip is already the newest version (3.0-11). curl is already the newest version (7.47.0-1ubuntu2.8). zlib1g-dev is already the newest version (1:1.2.8.dfsg-2ubuntu4.1). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install python packaging infrastructure' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. python-wheel is already the newest version (0.29.0-1). python-dev is already the newest version (2.7.12-1~16.04). python-pip is already the newest version (8.1.1-2ubuntu0.4). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. Requirement already up-to-date: pip in /usr/local/lib/python2.7/dist-packages (18.0). ========== [2018年 08月 28日 星期二 10:55:12 CST",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:9647,security,apt,apt,9647,"y installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install python packaging infrastructure' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. python-wheel is already the newest version (0.29.0-1). python-dev is already the newest version (2.7.12-1~16.04). python-pip is already the newest version (8.1.1-2ubuntu0.4). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. Requirement already up-to-date: pip in /usr/local/lib/python2.7/dist-packages (18.0). ========== [2018年 08月 28日 星期二 10:55:12 CST] Stage 'Install python packages' starting. Requirement already satisfied: contextlib2 in /usr/local/lib/python2.7/dist-packages (0.5.5). Requirement already satisfied: enum34 in /usr/local/lib/python2.7/dist-packages (1.1.6). Requirement already satisfied: sortedcontainers==1.5.3 in /usr/local/lib/python2.7/dist-packages (1.5.3). Requirement already satisfied: intervaltree in /usr/local/lib/python2.7/dist-packages (2.1.0). Requirement already satisfied: sortedcontainers in /usr/local/lib/python2.7/dist-packages (from intervaltree) (1.5.3). Requirement already satisfied: mock>=2.0.0 in /usr/local/lib/python2.7/dist-packages (2.0.0). Requirement alrea",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:9801,security,apt,apt,9801,"ra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install python packaging infrastructure' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. python-wheel is already the newest version (0.29.0-1). python-dev is already the newest version (2.7.12-1~16.04). python-pip is already the newest version (8.1.1-2ubuntu0.4). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. Requirement already up-to-date: pip in /usr/local/lib/python2.7/dist-packages (18.0). ========== [2018年 08月 28日 星期二 10:55:12 CST] Stage 'Install python packages' starting. Requirement already satisfied: contextlib2 in /usr/local/lib/python2.7/dist-packages (0.5.5). Requirement already satisfied: enum34 in /usr/local/lib/python2.7/dist-packages (1.1.6). Requirement already satisfied: sortedcontainers==1.5.3 in /usr/local/lib/python2.7/dist-packages (1.5.3). Requirement already satisfied: intervaltree in /usr/local/lib/python2.7/dist-packages (2.1.0). Requirement already satisfied: sortedcontainers in /usr/local/lib/python2.7/dist-packages (from intervaltree) (1.5.3). Requirement already satisfied: mock>=2.0.0 in /usr/local/lib/python2.7/dist-packages (2.0.0). Requirement already satisfied: pbr>=0.11 in /usr/local/lib/python2.7/dist-packages (from mock>=2.0.0) (4.2.0). Requirement already satisfied: funcsigs>=1; python_version <",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:11215,security,certif,certifi,11215,"equirement already satisfied: sortedcontainers==1.5.3 in /usr/local/lib/python2.7/dist-packages (1.5.3). Requirement already satisfied: intervaltree in /usr/local/lib/python2.7/dist-packages (2.1.0). Requirement already satisfied: sortedcontainers in /usr/local/lib/python2.7/dist-packages (from intervaltree) (1.5.3). Requirement already satisfied: mock>=2.0.0 in /usr/local/lib/python2.7/dist-packages (2.0.0). Requirement already satisfied: pbr>=0.11 in /usr/local/lib/python2.7/dist-packages (from mock>=2.0.0) (4.2.0). Requirement already satisfied: funcsigs>=1; python_version < ""3.3"" in /usr/local/lib/python2.7/dist-packages (from mock>=2.0.0) (1.0.2). Requirement already satisfied: six>=1.9 in /usr/local/lib/python2.7/dist-packages (from mock>=2.0.0) (1.11.0). Requirement already satisfied: numpy==1.14 in /usr/local/lib/python2.7/dist-packages (1.14.0). Requirement already satisfied: requests>=2.18 in /usr/local/lib/python2.7/dist-packages (2.19.1). Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python2.7/dist-packages (from requests>=2.18) (2018.8.13). Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python2.7/dist-packages (from requests>=2.18) (3.0.4). Requirement already satisfied: urllib3<1.24,>=1.21.1 in /usr/local/lib/python2.7/dist-packages (from requests>=2.18) (1.23). Requirement already satisfied: idna<2.8,>=2.5 in /usr/local/lib/python2.7/dist-packages (from requests>=2.18) (2.7). Requirement already satisfied: scipy==1.0 in /usr/local/lib/python2.7/dist-packages (1.0.0). Requirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python2.7/dist-packages (from scipy==1.0) (1.14.0). Requirement already satisfied: oauth2client>=4.0.0 in /usr/local/lib/python2.7/dist-packages (4.1.2). Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python2.7/dist-packages (from oauth2client>=4.0.0) (0.4.4). Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python2.7/dist-packages (from oauth2c",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:12520,security,rsa,rsa,12520,"-packages (from requests>=2.18) (1.23). Requirement already satisfied: idna<2.8,>=2.5 in /usr/local/lib/python2.7/dist-packages (from requests>=2.18) (2.7). Requirement already satisfied: scipy==1.0 in /usr/local/lib/python2.7/dist-packages (1.0.0). Requirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python2.7/dist-packages (from scipy==1.0) (1.14.0). Requirement already satisfied: oauth2client>=4.0.0 in /usr/local/lib/python2.7/dist-packages (4.1.2). Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python2.7/dist-packages (from oauth2client>=4.0.0) (0.4.4). Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python2.7/dist-packages (from oauth2client>=4.0.0) (0.2.2). Requirement already satisfied: six>=1.6.1 in /usr/local/lib/python2.7/dist-packages (from oauth2client>=4.0.0) (1.11.0). Requirement already satisfied: httplib2>=0.9.1 in /usr/local/lib/python2.7/dist-packages (from oauth2client>=4.0.0) (0.11.3). Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python2.7/dist-packages (from oauth2client>=4.0.0) (3.4.2). Requirement already satisfied: crcmod>=1.7 in /usr/local/lib/python2.7/dist-packages (1.7). Requirement already satisfied: six in /usr/local/lib/python2.7/dist-packages (1.11.0). Requirement already satisfied: sklearn in /usr/local/lib/python2.7/dist-packages (0.0). Requirement already satisfied: scikit-learn in /usr/local/lib/python2.7/dist-packages (from sklearn) (0.19.2). Requirement already satisfied: pandas in /usr/local/lib/python2.7/dist-packages (0.23.4). Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python2.7/dist-packages (from pandas) (1.14.0). Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python2.7/dist-packages (from pandas) (2.7.3). Requirement already satisfied: pytz>=2011k in /usr/local/lib/python2.7/dist-packages (from pandas) (2018.5). Requirement already satisfied: six>=1.5 in /usr/local/lib/python2.7/dist-packages (from python-dateutil>=2.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:14110,security,auth,auth-,14110,">=1.9.0 in /usr/local/lib/python2.7/dist-packages (from pandas) (1.14.0). Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python2.7/dist-packages (from pandas) (2.7.3). Requirement already satisfied: pytz>=2011k in /usr/local/lib/python2.7/dist-packages (from pandas) (2018.5). Requirement already satisfied: six>=1.5 in /usr/local/lib/python2.7/dist-packages (from python-dateutil>=2.5.0->pandas) (1.11.0). Requirement already satisfied: psutil in /usr/local/lib/python2.7/dist-packages (5.4.7). Requirement already up-to-date: google-api-python-client in /usr/local/lib/python2.7/dist-packages (1.7.4). Requirement already satisfied, skipping upgrade: httplib2<1dev,>=0.9.2 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.11.3). Requirement already satisfied, skipping upgrade: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (3.0.0). Requirement already satisfied, skipping upgrade: google-auth-httplib2>=0.0.3 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.0.3). Requirement already satisfied, skipping upgrade: six<2dev,>=1.6.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.11.0). Requirement already satisfied, skipping upgrade: google-auth>=1.4.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.5.1). Requirement already satisfied, skipping upgrade: rsa>=3.1.4 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (3.4.2). Requirement already satisfied, skipping upgrade: cachetools>=2.0.0 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (2.1.0). Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (0.2.2). Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /usr/local/lib/python2.7/",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:14420,security,auth,auth,14420,"ment already satisfied: six>=1.5 in /usr/local/lib/python2.7/dist-packages (from python-dateutil>=2.5.0->pandas) (1.11.0). Requirement already satisfied: psutil in /usr/local/lib/python2.7/dist-packages (5.4.7). Requirement already up-to-date: google-api-python-client in /usr/local/lib/python2.7/dist-packages (1.7.4). Requirement already satisfied, skipping upgrade: httplib2<1dev,>=0.9.2 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.11.3). Requirement already satisfied, skipping upgrade: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (3.0.0). Requirement already satisfied, skipping upgrade: google-auth-httplib2>=0.0.3 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.0.3). Requirement already satisfied, skipping upgrade: six<2dev,>=1.6.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.11.0). Requirement already satisfied, skipping upgrade: google-auth>=1.4.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.5.1). Requirement already satisfied, skipping upgrade: rsa>=3.1.4 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (3.4.2). Requirement already satisfied, skipping upgrade: cachetools>=2.0.0 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (2.1.0). Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (0.2.2). Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /usr/local/lib/python2.7/dist-packages (from rsa>=3.1.4->google-auth>=1.4.1->google-api-python-client) (0.4.4). ========== [2018年 08月 28日 星期二 10:55:17 CST] Stage 'Install TensorFlow pip package' starting. Skipping tf-nightly as it is not installed. Skipping tensorflow as it is not installed. Skipping tf-nightly-gpu as it is not inst",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:14564,security,rsa,rsa,14564,"atisfied: psutil in /usr/local/lib/python2.7/dist-packages (5.4.7). Requirement already up-to-date: google-api-python-client in /usr/local/lib/python2.7/dist-packages (1.7.4). Requirement already satisfied, skipping upgrade: httplib2<1dev,>=0.9.2 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.11.3). Requirement already satisfied, skipping upgrade: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (3.0.0). Requirement already satisfied, skipping upgrade: google-auth-httplib2>=0.0.3 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.0.3). Requirement already satisfied, skipping upgrade: six<2dev,>=1.6.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.11.0). Requirement already satisfied, skipping upgrade: google-auth>=1.4.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.5.1). Requirement already satisfied, skipping upgrade: rsa>=3.1.4 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (3.4.2). Requirement already satisfied, skipping upgrade: cachetools>=2.0.0 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (2.1.0). Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (0.2.2). Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /usr/local/lib/python2.7/dist-packages (from rsa>=3.1.4->google-auth>=1.4.1->google-api-python-client) (0.4.4). ========== [2018年 08月 28日 星期二 10:55:17 CST] Stage 'Install TensorFlow pip package' starting. Skipping tf-nightly as it is not installed. Skipping tensorflow as it is not installed. Skipping tf-nightly-gpu as it is not installed. Skipping tensorflow-gpu as it is not installed. Installing Google Cloud Platform optimized CPU-only TensorFlow wheel. % Total % Received ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:14630,security,auth,auth,14630,". Requirement already up-to-date: google-api-python-client in /usr/local/lib/python2.7/dist-packages (1.7.4). Requirement already satisfied, skipping upgrade: httplib2<1dev,>=0.9.2 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.11.3). Requirement already satisfied, skipping upgrade: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (3.0.0). Requirement already satisfied, skipping upgrade: google-auth-httplib2>=0.0.3 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.0.3). Requirement already satisfied, skipping upgrade: six<2dev,>=1.6.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.11.0). Requirement already satisfied, skipping upgrade: google-auth>=1.4.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.5.1). Requirement already satisfied, skipping upgrade: rsa>=3.1.4 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (3.4.2). Requirement already satisfied, skipping upgrade: cachetools>=2.0.0 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (2.1.0). Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (0.2.2). Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /usr/local/lib/python2.7/dist-packages (from rsa>=3.1.4->google-auth>=1.4.1->google-api-python-client) (0.4.4). ========== [2018年 08月 28日 星期二 10:55:17 CST] Stage 'Install TensorFlow pip package' starting. Skipping tf-nightly as it is not installed. Skipping tensorflow as it is not installed. Skipping tf-nightly-gpu as it is not installed. Skipping tensorflow-gpu as it is not installed. Installing Google Cloud Platform optimized CPU-only TensorFlow wheel. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total S",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:14800,security,auth,auth,14800,"ping upgrade: httplib2<1dev,>=0.9.2 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.11.3). Requirement already satisfied, skipping upgrade: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (3.0.0). Requirement already satisfied, skipping upgrade: google-auth-httplib2>=0.0.3 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.0.3). Requirement already satisfied, skipping upgrade: six<2dev,>=1.6.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.11.0). Requirement already satisfied, skipping upgrade: google-auth>=1.4.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.5.1). Requirement already satisfied, skipping upgrade: rsa>=3.1.4 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (3.4.2). Requirement already satisfied, skipping upgrade: cachetools>=2.0.0 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (2.1.0). Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (0.2.2). Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /usr/local/lib/python2.7/dist-packages (from rsa>=3.1.4->google-auth>=1.4.1->google-api-python-client) (0.4.4). ========== [2018年 08月 28日 星期二 10:55:17 CST] Stage 'Install TensorFlow pip package' starting. Skipping tf-nightly as it is not installed. Skipping tensorflow as it is not installed. Skipping tf-nightly-gpu as it is not installed. Skipping tensorflow-gpu as it is not installed. Installing Google Cloud Platform optimized CPU-only TensorFlow wheel. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 0 0 0 0 0 0 0 0 --:--:-- 0:02:09 --:--:-- 0curl: (7) Failed to connect to storage.googleapis.com port 443: Connection timed out.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:14974,security,auth,auth,14974,"ping upgrade: httplib2<1dev,>=0.9.2 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.11.3). Requirement already satisfied, skipping upgrade: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (3.0.0). Requirement already satisfied, skipping upgrade: google-auth-httplib2>=0.0.3 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.0.3). Requirement already satisfied, skipping upgrade: six<2dev,>=1.6.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.11.0). Requirement already satisfied, skipping upgrade: google-auth>=1.4.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.5.1). Requirement already satisfied, skipping upgrade: rsa>=3.1.4 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (3.4.2). Requirement already satisfied, skipping upgrade: cachetools>=2.0.0 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (2.1.0). Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (0.2.2). Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /usr/local/lib/python2.7/dist-packages (from rsa>=3.1.4->google-auth>=1.4.1->google-api-python-client) (0.4.4). ========== [2018年 08月 28日 星期二 10:55:17 CST] Stage 'Install TensorFlow pip package' starting. Skipping tf-nightly as it is not installed. Skipping tensorflow as it is not installed. Skipping tf-nightly-gpu as it is not installed. Skipping tensorflow-gpu as it is not installed. Installing Google Cloud Platform optimized CPU-only TensorFlow wheel. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 0 0 0 0 0 0 0 0 --:--:-- 0:02:09 --:--:-- 0curl: (7) Failed to connect to storage.googleapis.com port 443: Connection timed out.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:15133,security,rsa,rsa,15133,"ping upgrade: httplib2<1dev,>=0.9.2 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.11.3). Requirement already satisfied, skipping upgrade: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (3.0.0). Requirement already satisfied, skipping upgrade: google-auth-httplib2>=0.0.3 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.0.3). Requirement already satisfied, skipping upgrade: six<2dev,>=1.6.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.11.0). Requirement already satisfied, skipping upgrade: google-auth>=1.4.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.5.1). Requirement already satisfied, skipping upgrade: rsa>=3.1.4 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (3.4.2). Requirement already satisfied, skipping upgrade: cachetools>=2.0.0 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (2.1.0). Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (0.2.2). Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /usr/local/lib/python2.7/dist-packages (from rsa>=3.1.4->google-auth>=1.4.1->google-api-python-client) (0.4.4). ========== [2018年 08月 28日 星期二 10:55:17 CST] Stage 'Install TensorFlow pip package' starting. Skipping tf-nightly as it is not installed. Skipping tensorflow as it is not installed. Skipping tf-nightly-gpu as it is not installed. Skipping tensorflow-gpu as it is not installed. Installing Google Cloud Platform optimized CPU-only TensorFlow wheel. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 0 0 0 0 0 0 0 0 --:--:-- 0:02:09 --:--:-- 0curl: (7) Failed to connect to storage.googleapis.com port 443: Connection timed out.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:15152,security,auth,auth,15152,"ping upgrade: httplib2<1dev,>=0.9.2 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.11.3). Requirement already satisfied, skipping upgrade: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (3.0.0). Requirement already satisfied, skipping upgrade: google-auth-httplib2>=0.0.3 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.0.3). Requirement already satisfied, skipping upgrade: six<2dev,>=1.6.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.11.0). Requirement already satisfied, skipping upgrade: google-auth>=1.4.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.5.1). Requirement already satisfied, skipping upgrade: rsa>=3.1.4 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (3.4.2). Requirement already satisfied, skipping upgrade: cachetools>=2.0.0 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (2.1.0). Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (0.2.2). Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /usr/local/lib/python2.7/dist-packages (from rsa>=3.1.4->google-auth>=1.4.1->google-api-python-client) (0.4.4). ========== [2018年 08月 28日 星期二 10:55:17 CST] Stage 'Install TensorFlow pip package' starting. Skipping tf-nightly as it is not installed. Skipping tensorflow as it is not installed. Skipping tf-nightly-gpu as it is not installed. Skipping tensorflow-gpu as it is not installed. Installing Google Cloud Platform optimized CPU-only TensorFlow wheel. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 0 0 0 0 0 0 0 0 --:--:-- 0:02:09 --:--:-- 0curl: (7) Failed to connect to storage.googleapis.com port 443: Connection timed out.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:4614,testability,depend,dependency,4614,"urces.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. Reading package lists... Done. Building dependency tree . Reading state information... Done. sudo is already the newest version (1.8.16-0ubuntu1.5). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:43:08 CST] Stage 'Update package list' starting. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target P",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:4751,testability,automat,automatically,4751,"/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. Reading package lists... Done. Building dependency tree . Reading state information... Done. sudo is already the newest version (1.8.16-0ubuntu1.5). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:43:08 CST] Stage 'Update package list' starting. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.lis",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:8275,testability,depend,dependency,8275,"igured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install development packages' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. pkg-config is already the newest version (0.29.1-0ubuntu1). unzip is already the newest version (6.0-20ubuntu1). zip is already the newest version (3.0-11). curl is already the newest version (7.47.0-1ubuntu2.8). zlib1g-dev is already the newest version (1:1.2.8.dfsg-2ubuntu4.1). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install python packaging infrastructure' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. python-wheel is already the newest",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:8637,testability,automat,automatically,8637," configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install development packages' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. pkg-config is already the newest version (0.29.1-0ubuntu1). unzip is already the newest version (6.0-20ubuntu1). zip is already the newest version (3.0-11). curl is already the newest version (7.47.0-1ubuntu2.8). zlib1g-dev is already the newest version (1:1.2.8.dfsg-2ubuntu4.1). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install python packaging infrastructure' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. python-wheel is already the newest version (0.29.0-1). python-dev is already the newest version (2.7.12-1~16.04). python-pip is already the newest version (8.1.1-2ubuntu0.4). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'su",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:9193,testability,depend,dependency,9193,"tall development packages' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. pkg-config is already the newest version (0.29.1-0ubuntu1). unzip is already the newest version (6.0-20ubuntu1). zip is already the newest version (3.0-11). curl is already the newest version (7.47.0-1ubuntu2.8). zlib1g-dev is already the newest version (1:1.2.8.dfsg-2ubuntu4.1). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install python packaging infrastructure' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. python-wheel is already the newest version (0.29.0-1). python-dev is already the newest version (2.7.12-1~16.04). python-pip is already the newest version (8.1.1-2ubuntu0.4). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. Requirement already up-to-date: pip in /usr/local/lib/python2.7/dist-packages (18.0). ========== [2018年 08月 28日 星期二 10:55:12 CST] Stage 'Install python packages' starting. Requirement already satisfied: contextlib2 in /usr/local/lib/python2.7/dist-packages (0.5.5). Requirement already satisfied: enum34 in /usr/local/lib/python2.7/dis",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:9449,testability,automat,automatically,9449,"the newest version (3.0-11). curl is already the newest version (7.47.0-1ubuntu2.8). zlib1g-dev is already the newest version (1:1.2.8.dfsg-2ubuntu4.1). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install python packaging infrastructure' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. python-wheel is already the newest version (0.29.0-1). python-dev is already the newest version (2.7.12-1~16.04). python-pip is already the newest version (8.1.1-2ubuntu0.4). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. Requirement already up-to-date: pip in /usr/local/lib/python2.7/dist-packages (18.0). ========== [2018年 08月 28日 星期二 10:55:12 CST] Stage 'Install python packages' starting. Requirement already satisfied: contextlib2 in /usr/local/lib/python2.7/dist-packages (0.5.5). Requirement already satisfied: enum34 in /usr/local/lib/python2.7/dist-packages (1.1.6). Requirement already satisfied: sortedcontainers==1.5.3 in /usr/local/lib/python2.7/dist-packages (1.5.3). Requirement already satisfied: intervaltree in /usr/local/lib/python2.7/dist-packages (2.1.0). Requirement already satisfied: sorted",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:10569,testability,mock,mock,10569,"inux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. Requirement already up-to-date: pip in /usr/local/lib/python2.7/dist-packages (18.0). ========== [2018年 08月 28日 星期二 10:55:12 CST] Stage 'Install python packages' starting. Requirement already satisfied: contextlib2 in /usr/local/lib/python2.7/dist-packages (0.5.5). Requirement already satisfied: enum34 in /usr/local/lib/python2.7/dist-packages (1.1.6). Requirement already satisfied: sortedcontainers==1.5.3 in /usr/local/lib/python2.7/dist-packages (1.5.3). Requirement already satisfied: intervaltree in /usr/local/lib/python2.7/dist-packages (2.1.0). Requirement already satisfied: sortedcontainers in /usr/local/lib/python2.7/dist-packages (from intervaltree) (1.5.3). Requirement already satisfied: mock>=2.0.0 in /usr/local/lib/python2.7/dist-packages (2.0.0). Requirement already satisfied: pbr>=0.11 in /usr/local/lib/python2.7/dist-packages (from mock>=2.0.0) (4.2.0). Requirement already satisfied: funcsigs>=1; python_version < ""3.3"" in /usr/local/lib/python2.7/dist-packages (from mock>=2.0.0) (1.0.2). Requirement already satisfied: six>=1.9 in /usr/local/lib/python2.7/dist-packages (from mock>=2.0.0) (1.11.0). Requirement already satisfied: numpy==1.14 in /usr/local/lib/python2.7/dist-packages (1.14.0). Requirement already satisfied: requests>=2.18 in /usr/local/lib/python2.7/dist-packages (2.19.1). Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python2.7/dist-packages (from requests>=2.18) (2018.8.13). Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python2.7/dist-packages (from requests>=2.18) (3.0.4). Requirement already satisfied: urllib3<1.24,>=1.21.1 in /usr/local/lib/python2.7/dist-packages (from requests>=2.18) (1.23). Requireme",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:10721,testability,mock,mock,10721,"nd 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. Requirement already up-to-date: pip in /usr/local/lib/python2.7/dist-packages (18.0). ========== [2018年 08月 28日 星期二 10:55:12 CST] Stage 'Install python packages' starting. Requirement already satisfied: contextlib2 in /usr/local/lib/python2.7/dist-packages (0.5.5). Requirement already satisfied: enum34 in /usr/local/lib/python2.7/dist-packages (1.1.6). Requirement already satisfied: sortedcontainers==1.5.3 in /usr/local/lib/python2.7/dist-packages (1.5.3). Requirement already satisfied: intervaltree in /usr/local/lib/python2.7/dist-packages (2.1.0). Requirement already satisfied: sortedcontainers in /usr/local/lib/python2.7/dist-packages (from intervaltree) (1.5.3). Requirement already satisfied: mock>=2.0.0 in /usr/local/lib/python2.7/dist-packages (2.0.0). Requirement already satisfied: pbr>=0.11 in /usr/local/lib/python2.7/dist-packages (from mock>=2.0.0) (4.2.0). Requirement already satisfied: funcsigs>=1; python_version < ""3.3"" in /usr/local/lib/python2.7/dist-packages (from mock>=2.0.0) (1.0.2). Requirement already satisfied: six>=1.9 in /usr/local/lib/python2.7/dist-packages (from mock>=2.0.0) (1.11.0). Requirement already satisfied: numpy==1.14 in /usr/local/lib/python2.7/dist-packages (1.14.0). Requirement already satisfied: requests>=2.18 in /usr/local/lib/python2.7/dist-packages (2.19.1). Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python2.7/dist-packages (from requests>=2.18) (2018.8.13). Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python2.7/dist-packages (from requests>=2.18) (3.0.4). Requirement already satisfied: urllib3<1.24,>=1.21.1 in /usr/local/lib/python2.7/dist-packages (from requests>=2.18) (1.23). Requirement already satisfied: idna<2.8,>=2.5 in /usr/local/lib/python2.7/dist-packages (from requests>=2.18) (2.7). Requirement already satisfied: scipy==1.0 in",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:10858,testability,mock,mock,10858,"n. Requirement already up-to-date: pip in /usr/local/lib/python2.7/dist-packages (18.0). ========== [2018年 08月 28日 星期二 10:55:12 CST] Stage 'Install python packages' starting. Requirement already satisfied: contextlib2 in /usr/local/lib/python2.7/dist-packages (0.5.5). Requirement already satisfied: enum34 in /usr/local/lib/python2.7/dist-packages (1.1.6). Requirement already satisfied: sortedcontainers==1.5.3 in /usr/local/lib/python2.7/dist-packages (1.5.3). Requirement already satisfied: intervaltree in /usr/local/lib/python2.7/dist-packages (2.1.0). Requirement already satisfied: sortedcontainers in /usr/local/lib/python2.7/dist-packages (from intervaltree) (1.5.3). Requirement already satisfied: mock>=2.0.0 in /usr/local/lib/python2.7/dist-packages (2.0.0). Requirement already satisfied: pbr>=0.11 in /usr/local/lib/python2.7/dist-packages (from mock>=2.0.0) (4.2.0). Requirement already satisfied: funcsigs>=1; python_version < ""3.3"" in /usr/local/lib/python2.7/dist-packages (from mock>=2.0.0) (1.0.2). Requirement already satisfied: six>=1.9 in /usr/local/lib/python2.7/dist-packages (from mock>=2.0.0) (1.11.0). Requirement already satisfied: numpy==1.14 in /usr/local/lib/python2.7/dist-packages (1.14.0). Requirement already satisfied: requests>=2.18 in /usr/local/lib/python2.7/dist-packages (2.19.1). Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python2.7/dist-packages (from requests>=2.18) (2018.8.13). Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python2.7/dist-packages (from requests>=2.18) (3.0.4). Requirement already satisfied: urllib3<1.24,>=1.21.1 in /usr/local/lib/python2.7/dist-packages (from requests>=2.18) (1.23). Requirement already satisfied: idna<2.8,>=2.5 in /usr/local/lib/python2.7/dist-packages (from requests>=2.18) (2.7). Requirement already satisfied: scipy==1.0 in /usr/local/lib/python2.7/dist-packages (1.0.0). Requirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python2.7/dist-packages (f",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:10968,testability,mock,mock,10968," 28日 星期二 10:55:12 CST] Stage 'Install python packages' starting. Requirement already satisfied: contextlib2 in /usr/local/lib/python2.7/dist-packages (0.5.5). Requirement already satisfied: enum34 in /usr/local/lib/python2.7/dist-packages (1.1.6). Requirement already satisfied: sortedcontainers==1.5.3 in /usr/local/lib/python2.7/dist-packages (1.5.3). Requirement already satisfied: intervaltree in /usr/local/lib/python2.7/dist-packages (2.1.0). Requirement already satisfied: sortedcontainers in /usr/local/lib/python2.7/dist-packages (from intervaltree) (1.5.3). Requirement already satisfied: mock>=2.0.0 in /usr/local/lib/python2.7/dist-packages (2.0.0). Requirement already satisfied: pbr>=0.11 in /usr/local/lib/python2.7/dist-packages (from mock>=2.0.0) (4.2.0). Requirement already satisfied: funcsigs>=1; python_version < ""3.3"" in /usr/local/lib/python2.7/dist-packages (from mock>=2.0.0) (1.0.2). Requirement already satisfied: six>=1.9 in /usr/local/lib/python2.7/dist-packages (from mock>=2.0.0) (1.11.0). Requirement already satisfied: numpy==1.14 in /usr/local/lib/python2.7/dist-packages (1.14.0). Requirement already satisfied: requests>=2.18 in /usr/local/lib/python2.7/dist-packages (2.19.1). Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python2.7/dist-packages (from requests>=2.18) (2018.8.13). Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python2.7/dist-packages (from requests>=2.18) (3.0.4). Requirement already satisfied: urllib3<1.24,>=1.21.1 in /usr/local/lib/python2.7/dist-packages (from requests>=2.18) (1.23). Requirement already satisfied: idna<2.8,>=2.5 in /usr/local/lib/python2.7/dist-packages (from requests>=2.18) (2.7). Requirement already satisfied: scipy==1.0 in /usr/local/lib/python2.7/dist-packages (1.0.0). Requirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python2.7/dist-packages (from scipy==1.0) (1.14.0). Requirement already satisfied: oauth2client>=4.0.0 in /usr/local/lib/python2.7/dist-",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:12914,usability,learn,learn,12914,"oauth2client>=4.0.0 in /usr/local/lib/python2.7/dist-packages (4.1.2). Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python2.7/dist-packages (from oauth2client>=4.0.0) (0.4.4). Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python2.7/dist-packages (from oauth2client>=4.0.0) (0.2.2). Requirement already satisfied: six>=1.6.1 in /usr/local/lib/python2.7/dist-packages (from oauth2client>=4.0.0) (1.11.0). Requirement already satisfied: httplib2>=0.9.1 in /usr/local/lib/python2.7/dist-packages (from oauth2client>=4.0.0) (0.11.3). Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python2.7/dist-packages (from oauth2client>=4.0.0) (3.4.2). Requirement already satisfied: crcmod>=1.7 in /usr/local/lib/python2.7/dist-packages (1.7). Requirement already satisfied: six in /usr/local/lib/python2.7/dist-packages (1.11.0). Requirement already satisfied: sklearn in /usr/local/lib/python2.7/dist-packages (0.0). Requirement already satisfied: scikit-learn in /usr/local/lib/python2.7/dist-packages (from sklearn) (0.19.2). Requirement already satisfied: pandas in /usr/local/lib/python2.7/dist-packages (0.23.4). Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python2.7/dist-packages (from pandas) (1.14.0). Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python2.7/dist-packages (from pandas) (2.7.3). Requirement already satisfied: pytz>=2011k in /usr/local/lib/python2.7/dist-packages (from pandas) (2018.5). Requirement already satisfied: six>=1.5 in /usr/local/lib/python2.7/dist-packages (from python-dateutil>=2.5.0->pandas) (1.11.0). Requirement already satisfied: psutil in /usr/local/lib/python2.7/dist-packages (5.4.7). Requirement already up-to-date: google-api-python-client in /usr/local/lib/python2.7/dist-packages (1.7.4). Requirement already satisfied, skipping upgrade: httplib2<1dev,>=0.9.2 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.11.3). Requirement already ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:118,energy efficiency,optim,optimized,118,"It seems like not having connection to ""storage.googleapis.com"" is the issue. And it seems like it's trying to get an optimized tensorflow wheel. What if you try with `DV_USE_GCP_OPTIMIZED_TF_WHL=0` ?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:118,performance,optimiz,optimized,118,"It seems like not having connection to ""storage.googleapis.com"" is the issue. And it seems like it's trying to get an optimized tensorflow wheel. What if you try with `DV_USE_GCP_OPTIMIZED_TF_WHL=0` ?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:30,availability,error,errors,30,i still get the same previous errors.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:30,performance,error,errors,30,i still get the same previous errors.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:30,safety,error,errors,30,i still get the same previous errors.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:30,usability,error,errors,30,i still get the same previous errors.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:75,security,access,access,75,"@solokopi What country is the `solokopi-All-Series` host are you trying to access the `storage.googleapis.com` domain from? Do you have root access on that machine? If you cannot access the domain, try to get some VPN access on your machine that would allow you access to the `storage.googleapis.com` domain.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:141,security,access,access,141,"@solokopi What country is the `solokopi-All-Series` host are you trying to access the `storage.googleapis.com` domain from? Do you have root access on that machine? If you cannot access the domain, try to get some VPN access on your machine that would allow you access to the `storage.googleapis.com` domain.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:179,security,access,access,179,"@solokopi What country is the `solokopi-All-Series` host are you trying to access the `storage.googleapis.com` domain from? Do you have root access on that machine? If you cannot access the domain, try to get some VPN access on your machine that would allow you access to the `storage.googleapis.com` domain.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:214,security,VPN,VPN,214,"@solokopi What country is the `solokopi-All-Series` host are you trying to access the `storage.googleapis.com` domain from? Do you have root access on that machine? If you cannot access the domain, try to get some VPN access on your machine that would allow you access to the `storage.googleapis.com` domain.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:218,security,access,access,218,"@solokopi What country is the `solokopi-All-Series` host are you trying to access the `storage.googleapis.com` domain from? Do you have root access on that machine? If you cannot access the domain, try to get some VPN access on your machine that would allow you access to the `storage.googleapis.com` domain.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:262,security,access,access,262,"@solokopi What country is the `solokopi-All-Series` host are you trying to access the `storage.googleapis.com` domain from? Do you have root access on that machine? If you cannot access the domain, try to get some VPN access on your machine that would allow you access to the `storage.googleapis.com` domain.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:94,availability,Error,Error,94,thank you @pgrosu please could it had been same vpn problem with this docker pulling command? Error response from daemon: Get https://gcr.io/v1/_ping: dial tcp 64.233.187.82:443: i/o timeout.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:94,performance,Error,Error,94,thank you @pgrosu please could it had been same vpn problem with this docker pulling command? Error response from daemon: Get https://gcr.io/v1/_ping: dial tcp 64.233.187.82:443: i/o timeout.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:179,performance,i/o,i/o,179,thank you @pgrosu please could it had been same vpn problem with this docker pulling command? Error response from daemon: Get https://gcr.io/v1/_ping: dial tcp 64.233.187.82:443: i/o timeout.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:183,performance,time,timeout,183,thank you @pgrosu please could it had been same vpn problem with this docker pulling command? Error response from daemon: Get https://gcr.io/v1/_ping: dial tcp 64.233.187.82:443: i/o timeout.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:94,safety,Error,Error,94,thank you @pgrosu please could it had been same vpn problem with this docker pulling command? Error response from daemon: Get https://gcr.io/v1/_ping: dial tcp 64.233.187.82:443: i/o timeout.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:183,safety,timeout,timeout,183,thank you @pgrosu please could it had been same vpn problem with this docker pulling command? Error response from daemon: Get https://gcr.io/v1/_ping: dial tcp 64.233.187.82:443: i/o timeout.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:48,security,vpn,vpn,48,thank you @pgrosu please could it had been same vpn problem with this docker pulling command? Error response from daemon: Get https://gcr.io/v1/_ping: dial tcp 64.233.187.82:443: i/o timeout.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:85,usability,command,command,85,thank you @pgrosu please could it had been same vpn problem with this docker pulling command? Error response from daemon: Get https://gcr.io/v1/_ping: dial tcp 64.233.187.82:443: i/o timeout.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:94,usability,Error,Error,94,thank you @pgrosu please could it had been same vpn problem with this docker pulling command? Error response from daemon: Get https://gcr.io/v1/_ping: dial tcp 64.233.187.82:443: i/o timeout.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/90:537,reliability,doe,doesn,537,"Also try to modify source to let call_variants to be a single thread as follows:. [https://github.com/google/deepvariant/blob/r0.7/deepvariant/data_providers.py#L55](https://github.com/google/deepvariant/blob/r0.7/deepvariant/data_providers.py#L55). _DEFAULT_INPUT_READ_THREADS = 1. _DEFAULT_INPUT_MAP_THREADS = 1. and [https://github.com/google/deepvariant/blob/r0.7/deepvariant/call_variants.py#L87](https://github.com/google/deepvariant/blob/r0.7/deepvariant/call_variants.py#L87). flags.DEFINE_integer('num_readers', 1,. However, it doesn't work, too.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:12,security,modif,modify,12,"Also try to modify source to let call_variants to be a single thread as follows:. [https://github.com/google/deepvariant/blob/r0.7/deepvariant/data_providers.py#L55](https://github.com/google/deepvariant/blob/r0.7/deepvariant/data_providers.py#L55). _DEFAULT_INPUT_READ_THREADS = 1. _DEFAULT_INPUT_MAP_THREADS = 1. and [https://github.com/google/deepvariant/blob/r0.7/deepvariant/call_variants.py#L87](https://github.com/google/deepvariant/blob/r0.7/deepvariant/call_variants.py#L87). flags.DEFINE_integer('num_readers', 1,. However, it doesn't work, too.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:230,deployability,Stack,Stack,230,"Did you try the change in https://github.com/google/deepvariant/issues/42#issuecomment-360510853 , which also includes `device_count` which limits the number of CPUs being used? I have not tried this myself, but it's mentioned in Stack Overflow discussions like this one: https://stackoverflow.com/questions/38187808/how-can-i-run-tensorflow-on-one-single-core",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:280,deployability,stack,stackoverflow,280,"Did you try the change in https://github.com/google/deepvariant/issues/42#issuecomment-360510853 , which also includes `device_count` which limits the number of CPUs being used? I have not tried this myself, but it's mentioned in Stack Overflow discussions like this one: https://stackoverflow.com/questions/38187808/how-can-i-run-tensorflow-on-one-single-core",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:161,energy efficiency,CPU,CPUs,161,"Did you try the change in https://github.com/google/deepvariant/issues/42#issuecomment-360510853 , which also includes `device_count` which limits the number of CPUs being used? I have not tried this myself, but it's mentioned in Stack Overflow discussions like this one: https://stackoverflow.com/questions/38187808/how-can-i-run-tensorflow-on-one-single-core",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:356,energy efficiency,core,core,356,"Did you try the change in https://github.com/google/deepvariant/issues/42#issuecomment-360510853 , which also includes `device_count` which limits the number of CPUs being used? I have not tried this myself, but it's mentioned in Stack Overflow discussions like this one: https://stackoverflow.com/questions/38187808/how-can-i-run-tensorflow-on-one-single-core",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:161,performance,CPU,CPUs,161,"Did you try the change in https://github.com/google/deepvariant/issues/42#issuecomment-360510853 , which also includes `device_count` which limits the number of CPUs being used? I have not tried this myself, but it's mentioned in Stack Overflow discussions like this one: https://stackoverflow.com/questions/38187808/how-can-i-run-tensorflow-on-one-single-core",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:114,energy efficiency,GPU,GPU,114,"@pichuan : Yes, I did try to set device_count as the both following examples but it didn't work. device_count = {'GPU': 0, 'TPU': 0, 'CPU': 1} . and . device_count = {'CPU': 1} .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:134,energy efficiency,CPU,CPU,134,"@pichuan : Yes, I did try to set device_count as the both following examples but it didn't work. device_count = {'GPU': 0, 'TPU': 0, 'CPU': 1} . and . device_count = {'CPU': 1} .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:168,energy efficiency,CPU,CPU,168,"@pichuan : Yes, I did try to set device_count as the both following examples but it didn't work. device_count = {'GPU': 0, 'TPU': 0, 'CPU': 1} . and . device_count = {'CPU': 1} .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:114,performance,GPU,GPU,114,"@pichuan : Yes, I did try to set device_count as the both following examples but it didn't work. device_count = {'GPU': 0, 'TPU': 0, 'CPU': 1} . and . device_count = {'CPU': 1} .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:134,performance,CPU,CPU,134,"@pichuan : Yes, I did try to set device_count as the both following examples but it didn't work. device_count = {'GPU': 0, 'TPU': 0, 'CPU': 1} . and . device_count = {'CPU': 1} .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:168,performance,CPU,CPU,168,"@pichuan : Yes, I did try to set device_count as the both following examples but it didn't work. device_count = {'GPU': 0, 'TPU': 0, 'CPU': 1} . and . device_count = {'CPU': 1} .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:152,availability,state,state,152,"@A-Tsai Try using `taskset` to assign which cores your process should go to, where the logical cores as enabled by hyperthreading keep an architectural state of your running process. Here's a link to the `taskset` manpage:. https://linux.die.net/man/1/taskset",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:87,deployability,log,logical,87,"@A-Tsai Try using `taskset` to assign which cores your process should go to, where the logical cores as enabled by hyperthreading keep an architectural state of your running process. Here's a link to the `taskset` manpage:. https://linux.die.net/man/1/taskset",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:44,energy efficiency,core,cores,44,"@A-Tsai Try using `taskset` to assign which cores your process should go to, where the logical cores as enabled by hyperthreading keep an architectural state of your running process. Here's a link to the `taskset` manpage:. https://linux.die.net/man/1/taskset",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:95,energy efficiency,core,cores,95,"@A-Tsai Try using `taskset` to assign which cores your process should go to, where the logical cores as enabled by hyperthreading keep an architectural state of your running process. Here's a link to the `taskset` manpage:. https://linux.die.net/man/1/taskset",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:152,integrability,state,state,152,"@A-Tsai Try using `taskset` to assign which cores your process should go to, where the logical cores as enabled by hyperthreading keep an architectural state of your running process. Here's a link to the `taskset` manpage:. https://linux.die.net/man/1/taskset",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:138,interoperability,architectur,architectural,138,"@A-Tsai Try using `taskset` to assign which cores your process should go to, where the logical cores as enabled by hyperthreading keep an architectural state of your running process. Here's a link to the `taskset` manpage:. https://linux.die.net/man/1/taskset",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:87,safety,log,logical,87,"@A-Tsai Try using `taskset` to assign which cores your process should go to, where the logical cores as enabled by hyperthreading keep an architectural state of your running process. Here's a link to the `taskset` manpage:. https://linux.die.net/man/1/taskset",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:87,security,log,logical,87,"@A-Tsai Try using `taskset` to assign which cores your process should go to, where the logical cores as enabled by hyperthreading keep an architectural state of your running process. Here's a link to the `taskset` manpage:. https://linux.die.net/man/1/taskset",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:87,testability,log,logical,87,"@A-Tsai Try using `taskset` to assign which cores your process should go to, where the logical cores as enabled by hyperthreading keep an architectural state of your running process. Here's a link to the `taskset` manpage:. https://linux.die.net/man/1/taskset",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:318,deployability,resourc,resource,318,"@pgrosu Yes, I can use taskset to assign the specific cpu cores for call_variants, but it doesn't fit my use case. . I'm trying to port DeepVariant on Spark by using pipe() function. There is no way to find a mapping between a task(partition) and a cpu cores of a computing node, so I can't use taskset to specify the resource on Spark framework.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:54,energy efficiency,cpu,cpu,54,"@pgrosu Yes, I can use taskset to assign the specific cpu cores for call_variants, but it doesn't fit my use case. . I'm trying to port DeepVariant on Spark by using pipe() function. There is no way to find a mapping between a task(partition) and a cpu cores of a computing node, so I can't use taskset to specify the resource on Spark framework.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:58,energy efficiency,core,cores,58,"@pgrosu Yes, I can use taskset to assign the specific cpu cores for call_variants, but it doesn't fit my use case. . I'm trying to port DeepVariant on Spark by using pipe() function. There is no way to find a mapping between a task(partition) and a cpu cores of a computing node, so I can't use taskset to specify the resource on Spark framework.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:249,energy efficiency,cpu,cpu,249,"@pgrosu Yes, I can use taskset to assign the specific cpu cores for call_variants, but it doesn't fit my use case. . I'm trying to port DeepVariant on Spark by using pipe() function. There is no way to find a mapping between a task(partition) and a cpu cores of a computing node, so I can't use taskset to specify the resource on Spark framework.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:253,energy efficiency,core,cores,253,"@pgrosu Yes, I can use taskset to assign the specific cpu cores for call_variants, but it doesn't fit my use case. . I'm trying to port DeepVariant on Spark by using pipe() function. There is no way to find a mapping between a task(partition) and a cpu cores of a computing node, so I can't use taskset to specify the resource on Spark framework.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:318,energy efficiency,resourc,resource,318,"@pgrosu Yes, I can use taskset to assign the specific cpu cores for call_variants, but it doesn't fit my use case. . I'm trying to port DeepVariant on Spark by using pipe() function. There is no way to find a mapping between a task(partition) and a cpu cores of a computing node, so I can't use taskset to specify the resource on Spark framework.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:45,interoperability,specif,specific,45,"@pgrosu Yes, I can use taskset to assign the specific cpu cores for call_variants, but it doesn't fit my use case. . I'm trying to port DeepVariant on Spark by using pipe() function. There is no way to find a mapping between a task(partition) and a cpu cores of a computing node, so I can't use taskset to specify the resource on Spark framework.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:306,interoperability,specif,specify,306,"@pgrosu Yes, I can use taskset to assign the specific cpu cores for call_variants, but it doesn't fit my use case. . I'm trying to port DeepVariant on Spark by using pipe() function. There is no way to find a mapping between a task(partition) and a cpu cores of a computing node, so I can't use taskset to specify the resource on Spark framework.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:54,performance,cpu,cpu,54,"@pgrosu Yes, I can use taskset to assign the specific cpu cores for call_variants, but it doesn't fit my use case. . I'm trying to port DeepVariant on Spark by using pipe() function. There is no way to find a mapping between a task(partition) and a cpu cores of a computing node, so I can't use taskset to specify the resource on Spark framework.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:249,performance,cpu,cpu,249,"@pgrosu Yes, I can use taskset to assign the specific cpu cores for call_variants, but it doesn't fit my use case. . I'm trying to port DeepVariant on Spark by using pipe() function. There is no way to find a mapping between a task(partition) and a cpu cores of a computing node, so I can't use taskset to specify the resource on Spark framework.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:318,performance,resourc,resource,318,"@pgrosu Yes, I can use taskset to assign the specific cpu cores for call_variants, but it doesn't fit my use case. . I'm trying to port DeepVariant on Spark by using pipe() function. There is no way to find a mapping between a task(partition) and a cpu cores of a computing node, so I can't use taskset to specify the resource on Spark framework.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:90,reliability,doe,doesn,90,"@pgrosu Yes, I can use taskset to assign the specific cpu cores for call_variants, but it doesn't fit my use case. . I'm trying to port DeepVariant on Spark by using pipe() function. There is no way to find a mapping between a task(partition) and a cpu cores of a computing node, so I can't use taskset to specify the resource on Spark framework.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:318,safety,resourc,resource,318,"@pgrosu Yes, I can use taskset to assign the specific cpu cores for call_variants, but it doesn't fit my use case. . I'm trying to port DeepVariant on Spark by using pipe() function. There is no way to find a mapping between a task(partition) and a cpu cores of a computing node, so I can't use taskset to specify the resource on Spark framework.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:318,testability,resourc,resource,318,"@pgrosu Yes, I can use taskset to assign the specific cpu cores for call_variants, but it doesn't fit my use case. . I'm trying to port DeepVariant on Spark by using pipe() function. There is no way to find a mapping between a task(partition) and a cpu cores of a computing node, so I can't use taskset to specify the resource on Spark framework.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:400,availability,mask,mask,400,"@A-Tsai Of course you can especially with `pipe()`, which can take a script/command as input. At the least, you have the following two options to play with:. 1. If you use pipe to launch a script, then you can launch the application through `taskset` to limit the number of cores at launch-time. Here's the options for launching with an example: . _*Options to launch a program*_: `taskset [options] mask command [argument...]`. _*Example to use only 2 specific cores*_: `taskset -c 0,2 python ~/loop.py`. The `pipe(...)` command [as defined in the RDD base-class](https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.rdd.RDD) takes an external command, which in this case would be `taskset -c core-list your-program`:. ![rdd-pipe](https://user-images.githubusercontent.com/6555937/44763439-4c73f500-ab19-11e8-99d7-99adac28c913.png). 2. In Spark, you can also limit the number of cores per task in Spark through the `spark.task.cpus` setting. You probably want to set `spark.cores.max`, and not change the `spark.executor.cores` and `spark.driver.cores`. The Spark config page explains everything in more detail here: . https://spark.apache.org/docs/latest/configuration.html. Hope it helps,. ~p.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:602,deployability,api,api,602,"@A-Tsai Of course you can especially with `pipe()`, which can take a script/command as input. At the least, you have the following two options to play with:. 1. If you use pipe to launch a script, then you can launch the application through `taskset` to limit the number of cores at launch-time. Here's the options for launching with an example: . _*Options to launch a program*_: `taskset [options] mask command [argument...]`. _*Example to use only 2 specific cores*_: `taskset -c 0,2 python ~/loop.py`. The `pipe(...)` command [as defined in the RDD base-class](https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.rdd.RDD) takes an external command, which in this case would be `taskset -c core-list your-program`:. ![rdd-pipe](https://user-images.githubusercontent.com/6555937/44763439-4c73f500-ab19-11e8-99d7-99adac28c913.png). 2. In Spark, you can also limit the number of cores per task in Spark through the `spark.task.cpus` setting. You probably want to set `spark.cores.max`, and not change the `spark.executor.cores` and `spark.driver.cores`. The Spark config page explains everything in more detail here: . https://spark.apache.org/docs/latest/configuration.html. Hope it helps,. ~p.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:1179,deployability,configurat,configuration,1179,"@A-Tsai Of course you can especially with `pipe()`, which can take a script/command as input. At the least, you have the following two options to play with:. 1. If you use pipe to launch a script, then you can launch the application through `taskset` to limit the number of cores at launch-time. Here's the options for launching with an example: . _*Options to launch a program*_: `taskset [options] mask command [argument...]`. _*Example to use only 2 specific cores*_: `taskset -c 0,2 python ~/loop.py`. The `pipe(...)` command [as defined in the RDD base-class](https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.rdd.RDD) takes an external command, which in this case would be `taskset -c core-list your-program`:. ![rdd-pipe](https://user-images.githubusercontent.com/6555937/44763439-4c73f500-ab19-11e8-99d7-99adac28c913.png). 2. In Spark, you can also limit the number of cores per task in Spark through the `spark.task.cpus` setting. You probably want to set `spark.cores.max`, and not change the `spark.executor.cores` and `spark.driver.cores`. The Spark config page explains everything in more detail here: . https://spark.apache.org/docs/latest/configuration.html. Hope it helps,. ~p.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:274,energy efficiency,core,cores,274,"@A-Tsai Of course you can especially with `pipe()`, which can take a script/command as input. At the least, you have the following two options to play with:. 1. If you use pipe to launch a script, then you can launch the application through `taskset` to limit the number of cores at launch-time. Here's the options for launching with an example: . _*Options to launch a program*_: `taskset [options] mask command [argument...]`. _*Example to use only 2 specific cores*_: `taskset -c 0,2 python ~/loop.py`. The `pipe(...)` command [as defined in the RDD base-class](https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.rdd.RDD) takes an external command, which in this case would be `taskset -c core-list your-program`:. ![rdd-pipe](https://user-images.githubusercontent.com/6555937/44763439-4c73f500-ab19-11e8-99d7-99adac28c913.png). 2. In Spark, you can also limit the number of cores per task in Spark through the `spark.task.cpus` setting. You probably want to set `spark.cores.max`, and not change the `spark.executor.cores` and `spark.driver.cores`. The Spark config page explains everything in more detail here: . https://spark.apache.org/docs/latest/configuration.html. Hope it helps,. ~p.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:462,energy efficiency,core,cores,462,"@A-Tsai Of course you can especially with `pipe()`, which can take a script/command as input. At the least, you have the following two options to play with:. 1. If you use pipe to launch a script, then you can launch the application through `taskset` to limit the number of cores at launch-time. Here's the options for launching with an example: . _*Options to launch a program*_: `taskset [options] mask command [argument...]`. _*Example to use only 2 specific cores*_: `taskset -c 0,2 python ~/loop.py`. The `pipe(...)` command [as defined in the RDD base-class](https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.rdd.RDD) takes an external command, which in this case would be `taskset -c core-list your-program`:. ![rdd-pipe](https://user-images.githubusercontent.com/6555937/44763439-4c73f500-ab19-11e8-99d7-99adac28c913.png). 2. In Spark, you can also limit the number of cores per task in Spark through the `spark.task.cpus` setting. You probably want to set `spark.cores.max`, and not change the `spark.executor.cores` and `spark.driver.cores`. The Spark config page explains everything in more detail here: . https://spark.apache.org/docs/latest/configuration.html. Hope it helps,. ~p.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:716,energy efficiency,core,core-list,716,"@A-Tsai Of course you can especially with `pipe()`, which can take a script/command as input. At the least, you have the following two options to play with:. 1. If you use pipe to launch a script, then you can launch the application through `taskset` to limit the number of cores at launch-time. Here's the options for launching with an example: . _*Options to launch a program*_: `taskset [options] mask command [argument...]`. _*Example to use only 2 specific cores*_: `taskset -c 0,2 python ~/loop.py`. The `pipe(...)` command [as defined in the RDD base-class](https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.rdd.RDD) takes an external command, which in this case would be `taskset -c core-list your-program`:. ![rdd-pipe](https://user-images.githubusercontent.com/6555937/44763439-4c73f500-ab19-11e8-99d7-99adac28c913.png). 2. In Spark, you can also limit the number of cores per task in Spark through the `spark.task.cpus` setting. You probably want to set `spark.cores.max`, and not change the `spark.executor.cores` and `spark.driver.cores`. The Spark config page explains everything in more detail here: . https://spark.apache.org/docs/latest/configuration.html. Hope it helps,. ~p.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:902,energy efficiency,core,cores,902,"@A-Tsai Of course you can especially with `pipe()`, which can take a script/command as input. At the least, you have the following two options to play with:. 1. If you use pipe to launch a script, then you can launch the application through `taskset` to limit the number of cores at launch-time. Here's the options for launching with an example: . _*Options to launch a program*_: `taskset [options] mask command [argument...]`. _*Example to use only 2 specific cores*_: `taskset -c 0,2 python ~/loop.py`. The `pipe(...)` command [as defined in the RDD base-class](https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.rdd.RDD) takes an external command, which in this case would be `taskset -c core-list your-program`:. ![rdd-pipe](https://user-images.githubusercontent.com/6555937/44763439-4c73f500-ab19-11e8-99d7-99adac28c913.png). 2. In Spark, you can also limit the number of cores per task in Spark through the `spark.task.cpus` setting. You probably want to set `spark.cores.max`, and not change the `spark.executor.cores` and `spark.driver.cores`. The Spark config page explains everything in more detail here: . https://spark.apache.org/docs/latest/configuration.html. Hope it helps,. ~p.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:950,energy efficiency,cpu,cpus,950,"@A-Tsai Of course you can especially with `pipe()`, which can take a script/command as input. At the least, you have the following two options to play with:. 1. If you use pipe to launch a script, then you can launch the application through `taskset` to limit the number of cores at launch-time. Here's the options for launching with an example: . _*Options to launch a program*_: `taskset [options] mask command [argument...]`. _*Example to use only 2 specific cores*_: `taskset -c 0,2 python ~/loop.py`. The `pipe(...)` command [as defined in the RDD base-class](https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.rdd.RDD) takes an external command, which in this case would be `taskset -c core-list your-program`:. ![rdd-pipe](https://user-images.githubusercontent.com/6555937/44763439-4c73f500-ab19-11e8-99d7-99adac28c913.png). 2. In Spark, you can also limit the number of cores per task in Spark through the `spark.task.cpus` setting. You probably want to set `spark.cores.max`, and not change the `spark.executor.cores` and `spark.driver.cores`. The Spark config page explains everything in more detail here: . https://spark.apache.org/docs/latest/configuration.html. Hope it helps,. ~p.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:997,energy efficiency,core,cores,997,"@A-Tsai Of course you can especially with `pipe()`, which can take a script/command as input. At the least, you have the following two options to play with:. 1. If you use pipe to launch a script, then you can launch the application through `taskset` to limit the number of cores at launch-time. Here's the options for launching with an example: . _*Options to launch a program*_: `taskset [options] mask command [argument...]`. _*Example to use only 2 specific cores*_: `taskset -c 0,2 python ~/loop.py`. The `pipe(...)` command [as defined in the RDD base-class](https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.rdd.RDD) takes an external command, which in this case would be `taskset -c core-list your-program`:. ![rdd-pipe](https://user-images.githubusercontent.com/6555937/44763439-4c73f500-ab19-11e8-99d7-99adac28c913.png). 2. In Spark, you can also limit the number of cores per task in Spark through the `spark.task.cpus` setting. You probably want to set `spark.cores.max`, and not change the `spark.executor.cores` and `spark.driver.cores`. The Spark config page explains everything in more detail here: . https://spark.apache.org/docs/latest/configuration.html. Hope it helps,. ~p.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:1044,energy efficiency,core,cores,1044,"@A-Tsai Of course you can especially with `pipe()`, which can take a script/command as input. At the least, you have the following two options to play with:. 1. If you use pipe to launch a script, then you can launch the application through `taskset` to limit the number of cores at launch-time. Here's the options for launching with an example: . _*Options to launch a program*_: `taskset [options] mask command [argument...]`. _*Example to use only 2 specific cores*_: `taskset -c 0,2 python ~/loop.py`. The `pipe(...)` command [as defined in the RDD base-class](https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.rdd.RDD) takes an external command, which in this case would be `taskset -c core-list your-program`:. ![rdd-pipe](https://user-images.githubusercontent.com/6555937/44763439-4c73f500-ab19-11e8-99d7-99adac28c913.png). 2. In Spark, you can also limit the number of cores per task in Spark through the `spark.task.cpus` setting. You probably want to set `spark.cores.max`, and not change the `spark.executor.cores` and `spark.driver.cores`. The Spark config page explains everything in more detail here: . https://spark.apache.org/docs/latest/configuration.html. Hope it helps,. ~p.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:1069,energy efficiency,core,cores,1069,"@A-Tsai Of course you can especially with `pipe()`, which can take a script/command as input. At the least, you have the following two options to play with:. 1. If you use pipe to launch a script, then you can launch the application through `taskset` to limit the number of cores at launch-time. Here's the options for launching with an example: . _*Options to launch a program*_: `taskset [options] mask command [argument...]`. _*Example to use only 2 specific cores*_: `taskset -c 0,2 python ~/loop.py`. The `pipe(...)` command [as defined in the RDD base-class](https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.rdd.RDD) takes an external command, which in this case would be `taskset -c core-list your-program`:. ![rdd-pipe](https://user-images.githubusercontent.com/6555937/44763439-4c73f500-ab19-11e8-99d7-99adac28c913.png). 2. In Spark, you can also limit the number of cores per task in Spark through the `spark.task.cpus` setting. You probably want to set `spark.cores.max`, and not change the `spark.executor.cores` and `spark.driver.cores`. The Spark config page explains everything in more detail here: . https://spark.apache.org/docs/latest/configuration.html. Hope it helps,. ~p.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:602,integrability,api,api,602,"@A-Tsai Of course you can especially with `pipe()`, which can take a script/command as input. At the least, you have the following two options to play with:. 1. If you use pipe to launch a script, then you can launch the application through `taskset` to limit the number of cores at launch-time. Here's the options for launching with an example: . _*Options to launch a program*_: `taskset [options] mask command [argument...]`. _*Example to use only 2 specific cores*_: `taskset -c 0,2 python ~/loop.py`. The `pipe(...)` command [as defined in the RDD base-class](https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.rdd.RDD) takes an external command, which in this case would be `taskset -c core-list your-program`:. ![rdd-pipe](https://user-images.githubusercontent.com/6555937/44763439-4c73f500-ab19-11e8-99d7-99adac28c913.png). 2. In Spark, you can also limit the number of cores per task in Spark through the `spark.task.cpus` setting. You probably want to set `spark.cores.max`, and not change the `spark.executor.cores` and `spark.driver.cores`. The Spark config page explains everything in more detail here: . https://spark.apache.org/docs/latest/configuration.html. Hope it helps,. ~p.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:1179,integrability,configur,configuration,1179,"@A-Tsai Of course you can especially with `pipe()`, which can take a script/command as input. At the least, you have the following two options to play with:. 1. If you use pipe to launch a script, then you can launch the application through `taskset` to limit the number of cores at launch-time. Here's the options for launching with an example: . _*Options to launch a program*_: `taskset [options] mask command [argument...]`. _*Example to use only 2 specific cores*_: `taskset -c 0,2 python ~/loop.py`. The `pipe(...)` command [as defined in the RDD base-class](https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.rdd.RDD) takes an external command, which in this case would be `taskset -c core-list your-program`:. ![rdd-pipe](https://user-images.githubusercontent.com/6555937/44763439-4c73f500-ab19-11e8-99d7-99adac28c913.png). 2. In Spark, you can also limit the number of cores per task in Spark through the `spark.task.cpus` setting. You probably want to set `spark.cores.max`, and not change the `spark.executor.cores` and `spark.driver.cores`. The Spark config page explains everything in more detail here: . https://spark.apache.org/docs/latest/configuration.html. Hope it helps,. ~p.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:453,interoperability,specif,specific,453,"@A-Tsai Of course you can especially with `pipe()`, which can take a script/command as input. At the least, you have the following two options to play with:. 1. If you use pipe to launch a script, then you can launch the application through `taskset` to limit the number of cores at launch-time. Here's the options for launching with an example: . _*Options to launch a program*_: `taskset [options] mask command [argument...]`. _*Example to use only 2 specific cores*_: `taskset -c 0,2 python ~/loop.py`. The `pipe(...)` command [as defined in the RDD base-class](https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.rdd.RDD) takes an external command, which in this case would be `taskset -c core-list your-program`:. ![rdd-pipe](https://user-images.githubusercontent.com/6555937/44763439-4c73f500-ab19-11e8-99d7-99adac28c913.png). 2. In Spark, you can also limit the number of cores per task in Spark through the `spark.task.cpus` setting. You probably want to set `spark.cores.max`, and not change the `spark.executor.cores` and `spark.driver.cores`. The Spark config page explains everything in more detail here: . https://spark.apache.org/docs/latest/configuration.html. Hope it helps,. ~p.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:602,interoperability,api,api,602,"@A-Tsai Of course you can especially with `pipe()`, which can take a script/command as input. At the least, you have the following two options to play with:. 1. If you use pipe to launch a script, then you can launch the application through `taskset` to limit the number of cores at launch-time. Here's the options for launching with an example: . _*Options to launch a program*_: `taskset [options] mask command [argument...]`. _*Example to use only 2 specific cores*_: `taskset -c 0,2 python ~/loop.py`. The `pipe(...)` command [as defined in the RDD base-class](https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.rdd.RDD) takes an external command, which in this case would be `taskset -c core-list your-program`:. ![rdd-pipe](https://user-images.githubusercontent.com/6555937/44763439-4c73f500-ab19-11e8-99d7-99adac28c913.png). 2. In Spark, you can also limit the number of cores per task in Spark through the `spark.task.cpus` setting. You probably want to set `spark.cores.max`, and not change the `spark.executor.cores` and `spark.driver.cores`. The Spark config page explains everything in more detail here: . https://spark.apache.org/docs/latest/configuration.html. Hope it helps,. ~p.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:606,modifiability,scal,scala,606,"@A-Tsai Of course you can especially with `pipe()`, which can take a script/command as input. At the least, you have the following two options to play with:. 1. If you use pipe to launch a script, then you can launch the application through `taskset` to limit the number of cores at launch-time. Here's the options for launching with an example: . _*Options to launch a program*_: `taskset [options] mask command [argument...]`. _*Example to use only 2 specific cores*_: `taskset -c 0,2 python ~/loop.py`. The `pipe(...)` command [as defined in the RDD base-class](https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.rdd.RDD) takes an external command, which in this case would be `taskset -c core-list your-program`:. ![rdd-pipe](https://user-images.githubusercontent.com/6555937/44763439-4c73f500-ab19-11e8-99d7-99adac28c913.png). 2. In Spark, you can also limit the number of cores per task in Spark through the `spark.task.cpus` setting. You probably want to set `spark.cores.max`, and not change the `spark.executor.cores` and `spark.driver.cores`. The Spark config page explains everything in more detail here: . https://spark.apache.org/docs/latest/configuration.html. Hope it helps,. ~p.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:1179,modifiability,configur,configuration,1179,"@A-Tsai Of course you can especially with `pipe()`, which can take a script/command as input. At the least, you have the following two options to play with:. 1. If you use pipe to launch a script, then you can launch the application through `taskset` to limit the number of cores at launch-time. Here's the options for launching with an example: . _*Options to launch a program*_: `taskset [options] mask command [argument...]`. _*Example to use only 2 specific cores*_: `taskset -c 0,2 python ~/loop.py`. The `pipe(...)` command [as defined in the RDD base-class](https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.rdd.RDD) takes an external command, which in this case would be `taskset -c core-list your-program`:. ![rdd-pipe](https://user-images.githubusercontent.com/6555937/44763439-4c73f500-ab19-11e8-99d7-99adac28c913.png). 2. In Spark, you can also limit the number of cores per task in Spark through the `spark.task.cpus` setting. You probably want to set `spark.cores.max`, and not change the `spark.executor.cores` and `spark.driver.cores`. The Spark config page explains everything in more detail here: . https://spark.apache.org/docs/latest/configuration.html. Hope it helps,. ~p.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:290,performance,time,time,290,"@A-Tsai Of course you can especially with `pipe()`, which can take a script/command as input. At the least, you have the following two options to play with:. 1. If you use pipe to launch a script, then you can launch the application through `taskset` to limit the number of cores at launch-time. Here's the options for launching with an example: . _*Options to launch a program*_: `taskset [options] mask command [argument...]`. _*Example to use only 2 specific cores*_: `taskset -c 0,2 python ~/loop.py`. The `pipe(...)` command [as defined in the RDD base-class](https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.rdd.RDD) takes an external command, which in this case would be `taskset -c core-list your-program`:. ![rdd-pipe](https://user-images.githubusercontent.com/6555937/44763439-4c73f500-ab19-11e8-99d7-99adac28c913.png). 2. In Spark, you can also limit the number of cores per task in Spark through the `spark.task.cpus` setting. You probably want to set `spark.cores.max`, and not change the `spark.executor.cores` and `spark.driver.cores`. The Spark config page explains everything in more detail here: . https://spark.apache.org/docs/latest/configuration.html. Hope it helps,. ~p.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:950,performance,cpu,cpus,950,"@A-Tsai Of course you can especially with `pipe()`, which can take a script/command as input. At the least, you have the following two options to play with:. 1. If you use pipe to launch a script, then you can launch the application through `taskset` to limit the number of cores at launch-time. Here's the options for launching with an example: . _*Options to launch a program*_: `taskset [options] mask command [argument...]`. _*Example to use only 2 specific cores*_: `taskset -c 0,2 python ~/loop.py`. The `pipe(...)` command [as defined in the RDD base-class](https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.rdd.RDD) takes an external command, which in this case would be `taskset -c core-list your-program`:. ![rdd-pipe](https://user-images.githubusercontent.com/6555937/44763439-4c73f500-ab19-11e8-99d7-99adac28c913.png). 2. In Spark, you can also limit the number of cores per task in Spark through the `spark.task.cpus` setting. You probably want to set `spark.cores.max`, and not change the `spark.executor.cores` and `spark.driver.cores`. The Spark config page explains everything in more detail here: . https://spark.apache.org/docs/latest/configuration.html. Hope it helps,. ~p.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:87,safety,input,input,87,"@A-Tsai Of course you can especially with `pipe()`, which can take a script/command as input. At the least, you have the following two options to play with:. 1. If you use pipe to launch a script, then you can launch the application through `taskset` to limit the number of cores at launch-time. Here's the options for launching with an example: . _*Options to launch a program*_: `taskset [options] mask command [argument...]`. _*Example to use only 2 specific cores*_: `taskset -c 0,2 python ~/loop.py`. The `pipe(...)` command [as defined in the RDD base-class](https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.rdd.RDD) takes an external command, which in this case would be `taskset -c core-list your-program`:. ![rdd-pipe](https://user-images.githubusercontent.com/6555937/44763439-4c73f500-ab19-11e8-99d7-99adac28c913.png). 2. In Spark, you can also limit the number of cores per task in Spark through the `spark.task.cpus` setting. You probably want to set `spark.cores.max`, and not change the `spark.executor.cores` and `spark.driver.cores`. The Spark config page explains everything in more detail here: . https://spark.apache.org/docs/latest/configuration.html. Hope it helps,. ~p.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:1179,security,configur,configuration,1179,"@A-Tsai Of course you can especially with `pipe()`, which can take a script/command as input. At the least, you have the following two options to play with:. 1. If you use pipe to launch a script, then you can launch the application through `taskset` to limit the number of cores at launch-time. Here's the options for launching with an example: . _*Options to launch a program*_: `taskset [options] mask command [argument...]`. _*Example to use only 2 specific cores*_: `taskset -c 0,2 python ~/loop.py`. The `pipe(...)` command [as defined in the RDD base-class](https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.rdd.RDD) takes an external command, which in this case would be `taskset -c core-list your-program`:. ![rdd-pipe](https://user-images.githubusercontent.com/6555937/44763439-4c73f500-ab19-11e8-99d7-99adac28c913.png). 2. In Spark, you can also limit the number of cores per task in Spark through the `spark.task.cpus` setting. You probably want to set `spark.cores.max`, and not change the `spark.executor.cores` and `spark.driver.cores`. The Spark config page explains everything in more detail here: . https://spark.apache.org/docs/latest/configuration.html. Hope it helps,. ~p.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:76,usability,command,command,76,"@A-Tsai Of course you can especially with `pipe()`, which can take a script/command as input. At the least, you have the following two options to play with:. 1. If you use pipe to launch a script, then you can launch the application through `taskset` to limit the number of cores at launch-time. Here's the options for launching with an example: . _*Options to launch a program*_: `taskset [options] mask command [argument...]`. _*Example to use only 2 specific cores*_: `taskset -c 0,2 python ~/loop.py`. The `pipe(...)` command [as defined in the RDD base-class](https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.rdd.RDD) takes an external command, which in this case would be `taskset -c core-list your-program`:. ![rdd-pipe](https://user-images.githubusercontent.com/6555937/44763439-4c73f500-ab19-11e8-99d7-99adac28c913.png). 2. In Spark, you can also limit the number of cores per task in Spark through the `spark.task.cpus` setting. You probably want to set `spark.cores.max`, and not change the `spark.executor.cores` and `spark.driver.cores`. The Spark config page explains everything in more detail here: . https://spark.apache.org/docs/latest/configuration.html. Hope it helps,. ~p.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:87,usability,input,input,87,"@A-Tsai Of course you can especially with `pipe()`, which can take a script/command as input. At the least, you have the following two options to play with:. 1. If you use pipe to launch a script, then you can launch the application through `taskset` to limit the number of cores at launch-time. Here's the options for launching with an example: . _*Options to launch a program*_: `taskset [options] mask command [argument...]`. _*Example to use only 2 specific cores*_: `taskset -c 0,2 python ~/loop.py`. The `pipe(...)` command [as defined in the RDD base-class](https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.rdd.RDD) takes an external command, which in this case would be `taskset -c core-list your-program`:. ![rdd-pipe](https://user-images.githubusercontent.com/6555937/44763439-4c73f500-ab19-11e8-99d7-99adac28c913.png). 2. In Spark, you can also limit the number of cores per task in Spark through the `spark.task.cpus` setting. You probably want to set `spark.cores.max`, and not change the `spark.executor.cores` and `spark.driver.cores`. The Spark config page explains everything in more detail here: . https://spark.apache.org/docs/latest/configuration.html. Hope it helps,. ~p.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:405,usability,command,command,405,"@A-Tsai Of course you can especially with `pipe()`, which can take a script/command as input. At the least, you have the following two options to play with:. 1. If you use pipe to launch a script, then you can launch the application through `taskset` to limit the number of cores at launch-time. Here's the options for launching with an example: . _*Options to launch a program*_: `taskset [options] mask command [argument...]`. _*Example to use only 2 specific cores*_: `taskset -c 0,2 python ~/loop.py`. The `pipe(...)` command [as defined in the RDD base-class](https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.rdd.RDD) takes an external command, which in this case would be `taskset -c core-list your-program`:. ![rdd-pipe](https://user-images.githubusercontent.com/6555937/44763439-4c73f500-ab19-11e8-99d7-99adac28c913.png). 2. In Spark, you can also limit the number of cores per task in Spark through the `spark.task.cpus` setting. You probably want to set `spark.cores.max`, and not change the `spark.executor.cores` and `spark.driver.cores`. The Spark config page explains everything in more detail here: . https://spark.apache.org/docs/latest/configuration.html. Hope it helps,. ~p.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:522,usability,command,command,522,"@A-Tsai Of course you can especially with `pipe()`, which can take a script/command as input. At the least, you have the following two options to play with:. 1. If you use pipe to launch a script, then you can launch the application through `taskset` to limit the number of cores at launch-time. Here's the options for launching with an example: . _*Options to launch a program*_: `taskset [options] mask command [argument...]`. _*Example to use only 2 specific cores*_: `taskset -c 0,2 python ~/loop.py`. The `pipe(...)` command [as defined in the RDD base-class](https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.rdd.RDD) takes an external command, which in this case would be `taskset -c core-list your-program`:. ![rdd-pipe](https://user-images.githubusercontent.com/6555937/44763439-4c73f500-ab19-11e8-99d7-99adac28c913.png). 2. In Spark, you can also limit the number of cores per task in Spark through the `spark.task.cpus` setting. You probably want to set `spark.cores.max`, and not change the `spark.executor.cores` and `spark.driver.cores`. The Spark config page explains everything in more detail here: . https://spark.apache.org/docs/latest/configuration.html. Hope it helps,. ~p.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:667,usability,command,command,667,"@A-Tsai Of course you can especially with `pipe()`, which can take a script/command as input. At the least, you have the following two options to play with:. 1. If you use pipe to launch a script, then you can launch the application through `taskset` to limit the number of cores at launch-time. Here's the options for launching with an example: . _*Options to launch a program*_: `taskset [options] mask command [argument...]`. _*Example to use only 2 specific cores*_: `taskset -c 0,2 python ~/loop.py`. The `pipe(...)` command [as defined in the RDD base-class](https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.rdd.RDD) takes an external command, which in this case would be `taskset -c core-list your-program`:. ![rdd-pipe](https://user-images.githubusercontent.com/6555937/44763439-4c73f500-ab19-11e8-99d7-99adac28c913.png). 2. In Spark, you can also limit the number of cores per task in Spark through the `spark.task.cpus` setting. You probably want to set `spark.cores.max`, and not change the `spark.executor.cores` and `spark.driver.cores`. The Spark config page explains everything in more detail here: . https://spark.apache.org/docs/latest/configuration.html. Hope it helps,. ~p.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:762,usability,user,user-images,762,"@A-Tsai Of course you can especially with `pipe()`, which can take a script/command as input. At the least, you have the following two options to play with:. 1. If you use pipe to launch a script, then you can launch the application through `taskset` to limit the number of cores at launch-time. Here's the options for launching with an example: . _*Options to launch a program*_: `taskset [options] mask command [argument...]`. _*Example to use only 2 specific cores*_: `taskset -c 0,2 python ~/loop.py`. The `pipe(...)` command [as defined in the RDD base-class](https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.rdd.RDD) takes an external command, which in this case would be `taskset -c core-list your-program`:. ![rdd-pipe](https://user-images.githubusercontent.com/6555937/44763439-4c73f500-ab19-11e8-99d7-99adac28c913.png). 2. In Spark, you can also limit the number of cores per task in Spark through the `spark.task.cpus` setting. You probably want to set `spark.cores.max`, and not change the `spark.executor.cores` and `spark.driver.cores`. The Spark config page explains everything in more detail here: . https://spark.apache.org/docs/latest/configuration.html. Hope it helps,. ~p.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:1207,usability,help,helps,1207,"@A-Tsai Of course you can especially with `pipe()`, which can take a script/command as input. At the least, you have the following two options to play with:. 1. If you use pipe to launch a script, then you can launch the application through `taskset` to limit the number of cores at launch-time. Here's the options for launching with an example: . _*Options to launch a program*_: `taskset [options] mask command [argument...]`. _*Example to use only 2 specific cores*_: `taskset -c 0,2 python ~/loop.py`. The `pipe(...)` command [as defined in the RDD base-class](https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.rdd.RDD) takes an external command, which in this case would be `taskset -c core-list your-program`:. ![rdd-pipe](https://user-images.githubusercontent.com/6555937/44763439-4c73f500-ab19-11e8-99d7-99adac28c913.png). 2. In Spark, you can also limit the number of cores per task in Spark through the `spark.task.cpus` setting. You probably want to set `spark.cores.max`, and not change the `spark.executor.cores` and `spark.driver.cores`. The Spark config page explains everything in more detail here: . https://spark.apache.org/docs/latest/configuration.html. Hope it helps,. ~p.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:161,availability,cluster,cluster,161,"@pgrosu Thank you for the prompt response. Correct me if I'm wrong. . taskset need to specify the specific cpu cores the process wants to occupy. Since my Spark cluster is multi-tenant, some processes may be running in the cluster and occupy some CPU cores. In addition, the dynamic resource allocation is enabled in my Spark cluster, so I can't assume all of my tasks can be equally assigned to each computing node. If my data are stored in 200 partitions, it mean that my program will launch 200 tasks by using pipe() to call taskset. I can't make sure which partition will be assigned to which computing node. Round-Robin assignment is a way, but it's violated the policy of the resource management (like Spark standalone or YARN). For example, I have 8 computing node with 4 cores per each. My Spark process might allocate 24 cores. It might be 8 computing nodes with 3 cores per each or 6 computing nodes with 4 cores per each. Furthermore, there is no information to let me know which task is done or which cpu core is available in my Spark program. the resource allocation might be unbalance and performance might be impacted severely, especially when several iterations of task assignment. .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:223,availability,cluster,cluster,223,"@pgrosu Thank you for the prompt response. Correct me if I'm wrong. . taskset need to specify the specific cpu cores the process wants to occupy. Since my Spark cluster is multi-tenant, some processes may be running in the cluster and occupy some CPU cores. In addition, the dynamic resource allocation is enabled in my Spark cluster, so I can't assume all of my tasks can be equally assigned to each computing node. If my data are stored in 200 partitions, it mean that my program will launch 200 tasks by using pipe() to call taskset. I can't make sure which partition will be assigned to which computing node. Round-Robin assignment is a way, but it's violated the policy of the resource management (like Spark standalone or YARN). For example, I have 8 computing node with 4 cores per each. My Spark process might allocate 24 cores. It might be 8 computing nodes with 3 cores per each or 6 computing nodes with 4 cores per each. Furthermore, there is no information to let me know which task is done or which cpu core is available in my Spark program. the resource allocation might be unbalance and performance might be impacted severely, especially when several iterations of task assignment. .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:326,availability,cluster,cluster,326,"@pgrosu Thank you for the prompt response. Correct me if I'm wrong. . taskset need to specify the specific cpu cores the process wants to occupy. Since my Spark cluster is multi-tenant, some processes may be running in the cluster and occupy some CPU cores. In addition, the dynamic resource allocation is enabled in my Spark cluster, so I can't assume all of my tasks can be equally assigned to each computing node. If my data are stored in 200 partitions, it mean that my program will launch 200 tasks by using pipe() to call taskset. I can't make sure which partition will be assigned to which computing node. Round-Robin assignment is a way, but it's violated the policy of the resource management (like Spark standalone or YARN). For example, I have 8 computing node with 4 cores per each. My Spark process might allocate 24 cores. It might be 8 computing nodes with 3 cores per each or 6 computing nodes with 4 cores per each. Furthermore, there is no information to let me know which task is done or which cpu core is available in my Spark program. the resource allocation might be unbalance and performance might be impacted severely, especially when several iterations of task assignment. .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:1025,availability,avail,available,1025,"@pgrosu Thank you for the prompt response. Correct me if I'm wrong. . taskset need to specify the specific cpu cores the process wants to occupy. Since my Spark cluster is multi-tenant, some processes may be running in the cluster and occupy some CPU cores. In addition, the dynamic resource allocation is enabled in my Spark cluster, so I can't assume all of my tasks can be equally assigned to each computing node. If my data are stored in 200 partitions, it mean that my program will launch 200 tasks by using pipe() to call taskset. I can't make sure which partition will be assigned to which computing node. Round-Robin assignment is a way, but it's violated the policy of the resource management (like Spark standalone or YARN). For example, I have 8 computing node with 4 cores per each. My Spark process might allocate 24 cores. It might be 8 computing nodes with 3 cores per each or 6 computing nodes with 4 cores per each. Furthermore, there is no information to let me know which task is done or which cpu core is available in my Spark program. the resource allocation might be unbalance and performance might be impacted severely, especially when several iterations of task assignment. .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:161,deployability,cluster,cluster,161,"@pgrosu Thank you for the prompt response. Correct me if I'm wrong. . taskset need to specify the specific cpu cores the process wants to occupy. Since my Spark cluster is multi-tenant, some processes may be running in the cluster and occupy some CPU cores. In addition, the dynamic resource allocation is enabled in my Spark cluster, so I can't assume all of my tasks can be equally assigned to each computing node. If my data are stored in 200 partitions, it mean that my program will launch 200 tasks by using pipe() to call taskset. I can't make sure which partition will be assigned to which computing node. Round-Robin assignment is a way, but it's violated the policy of the resource management (like Spark standalone or YARN). For example, I have 8 computing node with 4 cores per each. My Spark process might allocate 24 cores. It might be 8 computing nodes with 3 cores per each or 6 computing nodes with 4 cores per each. Furthermore, there is no information to let me know which task is done or which cpu core is available in my Spark program. the resource allocation might be unbalance and performance might be impacted severely, especially when several iterations of task assignment. .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:223,deployability,cluster,cluster,223,"@pgrosu Thank you for the prompt response. Correct me if I'm wrong. . taskset need to specify the specific cpu cores the process wants to occupy. Since my Spark cluster is multi-tenant, some processes may be running in the cluster and occupy some CPU cores. In addition, the dynamic resource allocation is enabled in my Spark cluster, so I can't assume all of my tasks can be equally assigned to each computing node. If my data are stored in 200 partitions, it mean that my program will launch 200 tasks by using pipe() to call taskset. I can't make sure which partition will be assigned to which computing node. Round-Robin assignment is a way, but it's violated the policy of the resource management (like Spark standalone or YARN). For example, I have 8 computing node with 4 cores per each. My Spark process might allocate 24 cores. It might be 8 computing nodes with 3 cores per each or 6 computing nodes with 4 cores per each. Furthermore, there is no information to let me know which task is done or which cpu core is available in my Spark program. the resource allocation might be unbalance and performance might be impacted severely, especially when several iterations of task assignment. .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:283,deployability,resourc,resource,283,"@pgrosu Thank you for the prompt response. Correct me if I'm wrong. . taskset need to specify the specific cpu cores the process wants to occupy. Since my Spark cluster is multi-tenant, some processes may be running in the cluster and occupy some CPU cores. In addition, the dynamic resource allocation is enabled in my Spark cluster, so I can't assume all of my tasks can be equally assigned to each computing node. If my data are stored in 200 partitions, it mean that my program will launch 200 tasks by using pipe() to call taskset. I can't make sure which partition will be assigned to which computing node. Round-Robin assignment is a way, but it's violated the policy of the resource management (like Spark standalone or YARN). For example, I have 8 computing node with 4 cores per each. My Spark process might allocate 24 cores. It might be 8 computing nodes with 3 cores per each or 6 computing nodes with 4 cores per each. Furthermore, there is no information to let me know which task is done or which cpu core is available in my Spark program. the resource allocation might be unbalance and performance might be impacted severely, especially when several iterations of task assignment. .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:326,deployability,cluster,cluster,326,"@pgrosu Thank you for the prompt response. Correct me if I'm wrong. . taskset need to specify the specific cpu cores the process wants to occupy. Since my Spark cluster is multi-tenant, some processes may be running in the cluster and occupy some CPU cores. In addition, the dynamic resource allocation is enabled in my Spark cluster, so I can't assume all of my tasks can be equally assigned to each computing node. If my data are stored in 200 partitions, it mean that my program will launch 200 tasks by using pipe() to call taskset. I can't make sure which partition will be assigned to which computing node. Round-Robin assignment is a way, but it's violated the policy of the resource management (like Spark standalone or YARN). For example, I have 8 computing node with 4 cores per each. My Spark process might allocate 24 cores. It might be 8 computing nodes with 3 cores per each or 6 computing nodes with 4 cores per each. Furthermore, there is no information to let me know which task is done or which cpu core is available in my Spark program. the resource allocation might be unbalance and performance might be impacted severely, especially when several iterations of task assignment. .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:682,deployability,resourc,resource,682,"@pgrosu Thank you for the prompt response. Correct me if I'm wrong. . taskset need to specify the specific cpu cores the process wants to occupy. Since my Spark cluster is multi-tenant, some processes may be running in the cluster and occupy some CPU cores. In addition, the dynamic resource allocation is enabled in my Spark cluster, so I can't assume all of my tasks can be equally assigned to each computing node. If my data are stored in 200 partitions, it mean that my program will launch 200 tasks by using pipe() to call taskset. I can't make sure which partition will be assigned to which computing node. Round-Robin assignment is a way, but it's violated the policy of the resource management (like Spark standalone or YARN). For example, I have 8 computing node with 4 cores per each. My Spark process might allocate 24 cores. It might be 8 computing nodes with 3 cores per each or 6 computing nodes with 4 cores per each. Furthermore, there is no information to let me know which task is done or which cpu core is available in my Spark program. the resource allocation might be unbalance and performance might be impacted severely, especially when several iterations of task assignment. .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:691,deployability,manag,management,691,"@pgrosu Thank you for the prompt response. Correct me if I'm wrong. . taskset need to specify the specific cpu cores the process wants to occupy. Since my Spark cluster is multi-tenant, some processes may be running in the cluster and occupy some CPU cores. In addition, the dynamic resource allocation is enabled in my Spark cluster, so I can't assume all of my tasks can be equally assigned to each computing node. If my data are stored in 200 partitions, it mean that my program will launch 200 tasks by using pipe() to call taskset. I can't make sure which partition will be assigned to which computing node. Round-Robin assignment is a way, but it's violated the policy of the resource management (like Spark standalone or YARN). For example, I have 8 computing node with 4 cores per each. My Spark process might allocate 24 cores. It might be 8 computing nodes with 3 cores per each or 6 computing nodes with 4 cores per each. Furthermore, there is no information to let me know which task is done or which cpu core is available in my Spark program. the resource allocation might be unbalance and performance might be impacted severely, especially when several iterations of task assignment. .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:1060,deployability,resourc,resource,1060,"@pgrosu Thank you for the prompt response. Correct me if I'm wrong. . taskset need to specify the specific cpu cores the process wants to occupy. Since my Spark cluster is multi-tenant, some processes may be running in the cluster and occupy some CPU cores. In addition, the dynamic resource allocation is enabled in my Spark cluster, so I can't assume all of my tasks can be equally assigned to each computing node. If my data are stored in 200 partitions, it mean that my program will launch 200 tasks by using pipe() to call taskset. I can't make sure which partition will be assigned to which computing node. Round-Robin assignment is a way, but it's violated the policy of the resource management (like Spark standalone or YARN). For example, I have 8 computing node with 4 cores per each. My Spark process might allocate 24 cores. It might be 8 computing nodes with 3 cores per each or 6 computing nodes with 4 cores per each. Furthermore, there is no information to let me know which task is done or which cpu core is available in my Spark program. the resource allocation might be unbalance and performance might be impacted severely, especially when several iterations of task assignment. .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:107,energy efficiency,cpu,cpu,107,"@pgrosu Thank you for the prompt response. Correct me if I'm wrong. . taskset need to specify the specific cpu cores the process wants to occupy. Since my Spark cluster is multi-tenant, some processes may be running in the cluster and occupy some CPU cores. In addition, the dynamic resource allocation is enabled in my Spark cluster, so I can't assume all of my tasks can be equally assigned to each computing node. If my data are stored in 200 partitions, it mean that my program will launch 200 tasks by using pipe() to call taskset. I can't make sure which partition will be assigned to which computing node. Round-Robin assignment is a way, but it's violated the policy of the resource management (like Spark standalone or YARN). For example, I have 8 computing node with 4 cores per each. My Spark process might allocate 24 cores. It might be 8 computing nodes with 3 cores per each or 6 computing nodes with 4 cores per each. Furthermore, there is no information to let me know which task is done or which cpu core is available in my Spark program. the resource allocation might be unbalance and performance might be impacted severely, especially when several iterations of task assignment. .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:111,energy efficiency,core,cores,111,"@pgrosu Thank you for the prompt response. Correct me if I'm wrong. . taskset need to specify the specific cpu cores the process wants to occupy. Since my Spark cluster is multi-tenant, some processes may be running in the cluster and occupy some CPU cores. In addition, the dynamic resource allocation is enabled in my Spark cluster, so I can't assume all of my tasks can be equally assigned to each computing node. If my data are stored in 200 partitions, it mean that my program will launch 200 tasks by using pipe() to call taskset. I can't make sure which partition will be assigned to which computing node. Round-Robin assignment is a way, but it's violated the policy of the resource management (like Spark standalone or YARN). For example, I have 8 computing node with 4 cores per each. My Spark process might allocate 24 cores. It might be 8 computing nodes with 3 cores per each or 6 computing nodes with 4 cores per each. Furthermore, there is no information to let me know which task is done or which cpu core is available in my Spark program. the resource allocation might be unbalance and performance might be impacted severely, especially when several iterations of task assignment. .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:247,energy efficiency,CPU,CPU,247,"@pgrosu Thank you for the prompt response. Correct me if I'm wrong. . taskset need to specify the specific cpu cores the process wants to occupy. Since my Spark cluster is multi-tenant, some processes may be running in the cluster and occupy some CPU cores. In addition, the dynamic resource allocation is enabled in my Spark cluster, so I can't assume all of my tasks can be equally assigned to each computing node. If my data are stored in 200 partitions, it mean that my program will launch 200 tasks by using pipe() to call taskset. I can't make sure which partition will be assigned to which computing node. Round-Robin assignment is a way, but it's violated the policy of the resource management (like Spark standalone or YARN). For example, I have 8 computing node with 4 cores per each. My Spark process might allocate 24 cores. It might be 8 computing nodes with 3 cores per each or 6 computing nodes with 4 cores per each. Furthermore, there is no information to let me know which task is done or which cpu core is available in my Spark program. the resource allocation might be unbalance and performance might be impacted severely, especially when several iterations of task assignment. .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:251,energy efficiency,core,cores,251,"@pgrosu Thank you for the prompt response. Correct me if I'm wrong. . taskset need to specify the specific cpu cores the process wants to occupy. Since my Spark cluster is multi-tenant, some processes may be running in the cluster and occupy some CPU cores. In addition, the dynamic resource allocation is enabled in my Spark cluster, so I can't assume all of my tasks can be equally assigned to each computing node. If my data are stored in 200 partitions, it mean that my program will launch 200 tasks by using pipe() to call taskset. I can't make sure which partition will be assigned to which computing node. Round-Robin assignment is a way, but it's violated the policy of the resource management (like Spark standalone or YARN). For example, I have 8 computing node with 4 cores per each. My Spark process might allocate 24 cores. It might be 8 computing nodes with 3 cores per each or 6 computing nodes with 4 cores per each. Furthermore, there is no information to let me know which task is done or which cpu core is available in my Spark program. the resource allocation might be unbalance and performance might be impacted severely, especially when several iterations of task assignment. .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:283,energy efficiency,resourc,resource,283,"@pgrosu Thank you for the prompt response. Correct me if I'm wrong. . taskset need to specify the specific cpu cores the process wants to occupy. Since my Spark cluster is multi-tenant, some processes may be running in the cluster and occupy some CPU cores. In addition, the dynamic resource allocation is enabled in my Spark cluster, so I can't assume all of my tasks can be equally assigned to each computing node. If my data are stored in 200 partitions, it mean that my program will launch 200 tasks by using pipe() to call taskset. I can't make sure which partition will be assigned to which computing node. Round-Robin assignment is a way, but it's violated the policy of the resource management (like Spark standalone or YARN). For example, I have 8 computing node with 4 cores per each. My Spark process might allocate 24 cores. It might be 8 computing nodes with 3 cores per each or 6 computing nodes with 4 cores per each. Furthermore, there is no information to let me know which task is done or which cpu core is available in my Spark program. the resource allocation might be unbalance and performance might be impacted severely, especially when several iterations of task assignment. .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:292,energy efficiency,alloc,allocation,292,"@pgrosu Thank you for the prompt response. Correct me if I'm wrong. . taskset need to specify the specific cpu cores the process wants to occupy. Since my Spark cluster is multi-tenant, some processes may be running in the cluster and occupy some CPU cores. In addition, the dynamic resource allocation is enabled in my Spark cluster, so I can't assume all of my tasks can be equally assigned to each computing node. If my data are stored in 200 partitions, it mean that my program will launch 200 tasks by using pipe() to call taskset. I can't make sure which partition will be assigned to which computing node. Round-Robin assignment is a way, but it's violated the policy of the resource management (like Spark standalone or YARN). For example, I have 8 computing node with 4 cores per each. My Spark process might allocate 24 cores. It might be 8 computing nodes with 3 cores per each or 6 computing nodes with 4 cores per each. Furthermore, there is no information to let me know which task is done or which cpu core is available in my Spark program. the resource allocation might be unbalance and performance might be impacted severely, especially when several iterations of task assignment. .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:682,energy efficiency,resourc,resource,682,"@pgrosu Thank you for the prompt response. Correct me if I'm wrong. . taskset need to specify the specific cpu cores the process wants to occupy. Since my Spark cluster is multi-tenant, some processes may be running in the cluster and occupy some CPU cores. In addition, the dynamic resource allocation is enabled in my Spark cluster, so I can't assume all of my tasks can be equally assigned to each computing node. If my data are stored in 200 partitions, it mean that my program will launch 200 tasks by using pipe() to call taskset. I can't make sure which partition will be assigned to which computing node. Round-Robin assignment is a way, but it's violated the policy of the resource management (like Spark standalone or YARN). For example, I have 8 computing node with 4 cores per each. My Spark process might allocate 24 cores. It might be 8 computing nodes with 3 cores per each or 6 computing nodes with 4 cores per each. Furthermore, there is no information to let me know which task is done or which cpu core is available in my Spark program. the resource allocation might be unbalance and performance might be impacted severely, especially when several iterations of task assignment. .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:691,energy efficiency,manag,management,691,"@pgrosu Thank you for the prompt response. Correct me if I'm wrong. . taskset need to specify the specific cpu cores the process wants to occupy. Since my Spark cluster is multi-tenant, some processes may be running in the cluster and occupy some CPU cores. In addition, the dynamic resource allocation is enabled in my Spark cluster, so I can't assume all of my tasks can be equally assigned to each computing node. If my data are stored in 200 partitions, it mean that my program will launch 200 tasks by using pipe() to call taskset. I can't make sure which partition will be assigned to which computing node. Round-Robin assignment is a way, but it's violated the policy of the resource management (like Spark standalone or YARN). For example, I have 8 computing node with 4 cores per each. My Spark process might allocate 24 cores. It might be 8 computing nodes with 3 cores per each or 6 computing nodes with 4 cores per each. Furthermore, there is no information to let me know which task is done or which cpu core is available in my Spark program. the resource allocation might be unbalance and performance might be impacted severely, especially when several iterations of task assignment. .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:779,energy efficiency,core,cores,779,"@pgrosu Thank you for the prompt response. Correct me if I'm wrong. . taskset need to specify the specific cpu cores the process wants to occupy. Since my Spark cluster is multi-tenant, some processes may be running in the cluster and occupy some CPU cores. In addition, the dynamic resource allocation is enabled in my Spark cluster, so I can't assume all of my tasks can be equally assigned to each computing node. If my data are stored in 200 partitions, it mean that my program will launch 200 tasks by using pipe() to call taskset. I can't make sure which partition will be assigned to which computing node. Round-Robin assignment is a way, but it's violated the policy of the resource management (like Spark standalone or YARN). For example, I have 8 computing node with 4 cores per each. My Spark process might allocate 24 cores. It might be 8 computing nodes with 3 cores per each or 6 computing nodes with 4 cores per each. Furthermore, there is no information to let me know which task is done or which cpu core is available in my Spark program. the resource allocation might be unbalance and performance might be impacted severely, especially when several iterations of task assignment. .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:818,energy efficiency,alloc,allocate,818,"@pgrosu Thank you for the prompt response. Correct me if I'm wrong. . taskset need to specify the specific cpu cores the process wants to occupy. Since my Spark cluster is multi-tenant, some processes may be running in the cluster and occupy some CPU cores. In addition, the dynamic resource allocation is enabled in my Spark cluster, so I can't assume all of my tasks can be equally assigned to each computing node. If my data are stored in 200 partitions, it mean that my program will launch 200 tasks by using pipe() to call taskset. I can't make sure which partition will be assigned to which computing node. Round-Robin assignment is a way, but it's violated the policy of the resource management (like Spark standalone or YARN). For example, I have 8 computing node with 4 cores per each. My Spark process might allocate 24 cores. It might be 8 computing nodes with 3 cores per each or 6 computing nodes with 4 cores per each. Furthermore, there is no information to let me know which task is done or which cpu core is available in my Spark program. the resource allocation might be unbalance and performance might be impacted severely, especially when several iterations of task assignment. .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:830,energy efficiency,core,cores,830,"@pgrosu Thank you for the prompt response. Correct me if I'm wrong. . taskset need to specify the specific cpu cores the process wants to occupy. Since my Spark cluster is multi-tenant, some processes may be running in the cluster and occupy some CPU cores. In addition, the dynamic resource allocation is enabled in my Spark cluster, so I can't assume all of my tasks can be equally assigned to each computing node. If my data are stored in 200 partitions, it mean that my program will launch 200 tasks by using pipe() to call taskset. I can't make sure which partition will be assigned to which computing node. Round-Robin assignment is a way, but it's violated the policy of the resource management (like Spark standalone or YARN). For example, I have 8 computing node with 4 cores per each. My Spark process might allocate 24 cores. It might be 8 computing nodes with 3 cores per each or 6 computing nodes with 4 cores per each. Furthermore, there is no information to let me know which task is done or which cpu core is available in my Spark program. the resource allocation might be unbalance and performance might be impacted severely, especially when several iterations of task assignment. .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:874,energy efficiency,core,cores,874,"@pgrosu Thank you for the prompt response. Correct me if I'm wrong. . taskset need to specify the specific cpu cores the process wants to occupy. Since my Spark cluster is multi-tenant, some processes may be running in the cluster and occupy some CPU cores. In addition, the dynamic resource allocation is enabled in my Spark cluster, so I can't assume all of my tasks can be equally assigned to each computing node. If my data are stored in 200 partitions, it mean that my program will launch 200 tasks by using pipe() to call taskset. I can't make sure which partition will be assigned to which computing node. Round-Robin assignment is a way, but it's violated the policy of the resource management (like Spark standalone or YARN). For example, I have 8 computing node with 4 cores per each. My Spark process might allocate 24 cores. It might be 8 computing nodes with 3 cores per each or 6 computing nodes with 4 cores per each. Furthermore, there is no information to let me know which task is done or which cpu core is available in my Spark program. the resource allocation might be unbalance and performance might be impacted severely, especially when several iterations of task assignment. .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:917,energy efficiency,core,cores,917,"@pgrosu Thank you for the prompt response. Correct me if I'm wrong. . taskset need to specify the specific cpu cores the process wants to occupy. Since my Spark cluster is multi-tenant, some processes may be running in the cluster and occupy some CPU cores. In addition, the dynamic resource allocation is enabled in my Spark cluster, so I can't assume all of my tasks can be equally assigned to each computing node. If my data are stored in 200 partitions, it mean that my program will launch 200 tasks by using pipe() to call taskset. I can't make sure which partition will be assigned to which computing node. Round-Robin assignment is a way, but it's violated the policy of the resource management (like Spark standalone or YARN). For example, I have 8 computing node with 4 cores per each. My Spark process might allocate 24 cores. It might be 8 computing nodes with 3 cores per each or 6 computing nodes with 4 cores per each. Furthermore, there is no information to let me know which task is done or which cpu core is available in my Spark program. the resource allocation might be unbalance and performance might be impacted severely, especially when several iterations of task assignment. .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:1013,energy efficiency,cpu,cpu,1013,"@pgrosu Thank you for the prompt response. Correct me if I'm wrong. . taskset need to specify the specific cpu cores the process wants to occupy. Since my Spark cluster is multi-tenant, some processes may be running in the cluster and occupy some CPU cores. In addition, the dynamic resource allocation is enabled in my Spark cluster, so I can't assume all of my tasks can be equally assigned to each computing node. If my data are stored in 200 partitions, it mean that my program will launch 200 tasks by using pipe() to call taskset. I can't make sure which partition will be assigned to which computing node. Round-Robin assignment is a way, but it's violated the policy of the resource management (like Spark standalone or YARN). For example, I have 8 computing node with 4 cores per each. My Spark process might allocate 24 cores. It might be 8 computing nodes with 3 cores per each or 6 computing nodes with 4 cores per each. Furthermore, there is no information to let me know which task is done or which cpu core is available in my Spark program. the resource allocation might be unbalance and performance might be impacted severely, especially when several iterations of task assignment. .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:1017,energy efficiency,core,core,1017,"@pgrosu Thank you for the prompt response. Correct me if I'm wrong. . taskset need to specify the specific cpu cores the process wants to occupy. Since my Spark cluster is multi-tenant, some processes may be running in the cluster and occupy some CPU cores. In addition, the dynamic resource allocation is enabled in my Spark cluster, so I can't assume all of my tasks can be equally assigned to each computing node. If my data are stored in 200 partitions, it mean that my program will launch 200 tasks by using pipe() to call taskset. I can't make sure which partition will be assigned to which computing node. Round-Robin assignment is a way, but it's violated the policy of the resource management (like Spark standalone or YARN). For example, I have 8 computing node with 4 cores per each. My Spark process might allocate 24 cores. It might be 8 computing nodes with 3 cores per each or 6 computing nodes with 4 cores per each. Furthermore, there is no information to let me know which task is done or which cpu core is available in my Spark program. the resource allocation might be unbalance and performance might be impacted severely, especially when several iterations of task assignment. .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:1060,energy efficiency,resourc,resource,1060,"@pgrosu Thank you for the prompt response. Correct me if I'm wrong. . taskset need to specify the specific cpu cores the process wants to occupy. Since my Spark cluster is multi-tenant, some processes may be running in the cluster and occupy some CPU cores. In addition, the dynamic resource allocation is enabled in my Spark cluster, so I can't assume all of my tasks can be equally assigned to each computing node. If my data are stored in 200 partitions, it mean that my program will launch 200 tasks by using pipe() to call taskset. I can't make sure which partition will be assigned to which computing node. Round-Robin assignment is a way, but it's violated the policy of the resource management (like Spark standalone or YARN). For example, I have 8 computing node with 4 cores per each. My Spark process might allocate 24 cores. It might be 8 computing nodes with 3 cores per each or 6 computing nodes with 4 cores per each. Furthermore, there is no information to let me know which task is done or which cpu core is available in my Spark program. the resource allocation might be unbalance and performance might be impacted severely, especially when several iterations of task assignment. .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:1069,energy efficiency,alloc,allocation,1069,"@pgrosu Thank you for the prompt response. Correct me if I'm wrong. . taskset need to specify the specific cpu cores the process wants to occupy. Since my Spark cluster is multi-tenant, some processes may be running in the cluster and occupy some CPU cores. In addition, the dynamic resource allocation is enabled in my Spark cluster, so I can't assume all of my tasks can be equally assigned to each computing node. If my data are stored in 200 partitions, it mean that my program will launch 200 tasks by using pipe() to call taskset. I can't make sure which partition will be assigned to which computing node. Round-Robin assignment is a way, but it's violated the policy of the resource management (like Spark standalone or YARN). For example, I have 8 computing node with 4 cores per each. My Spark process might allocate 24 cores. It might be 8 computing nodes with 3 cores per each or 6 computing nodes with 4 cores per each. Furthermore, there is no information to let me know which task is done or which cpu core is available in my Spark program. the resource allocation might be unbalance and performance might be impacted severely, especially when several iterations of task assignment. .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:86,interoperability,specif,specify,86,"@pgrosu Thank you for the prompt response. Correct me if I'm wrong. . taskset need to specify the specific cpu cores the process wants to occupy. Since my Spark cluster is multi-tenant, some processes may be running in the cluster and occupy some CPU cores. In addition, the dynamic resource allocation is enabled in my Spark cluster, so I can't assume all of my tasks can be equally assigned to each computing node. If my data are stored in 200 partitions, it mean that my program will launch 200 tasks by using pipe() to call taskset. I can't make sure which partition will be assigned to which computing node. Round-Robin assignment is a way, but it's violated the policy of the resource management (like Spark standalone or YARN). For example, I have 8 computing node with 4 cores per each. My Spark process might allocate 24 cores. It might be 8 computing nodes with 3 cores per each or 6 computing nodes with 4 cores per each. Furthermore, there is no information to let me know which task is done or which cpu core is available in my Spark program. the resource allocation might be unbalance and performance might be impacted severely, especially when several iterations of task assignment. .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:98,interoperability,specif,specific,98,"@pgrosu Thank you for the prompt response. Correct me if I'm wrong. . taskset need to specify the specific cpu cores the process wants to occupy. Since my Spark cluster is multi-tenant, some processes may be running in the cluster and occupy some CPU cores. In addition, the dynamic resource allocation is enabled in my Spark cluster, so I can't assume all of my tasks can be equally assigned to each computing node. If my data are stored in 200 partitions, it mean that my program will launch 200 tasks by using pipe() to call taskset. I can't make sure which partition will be assigned to which computing node. Round-Robin assignment is a way, but it's violated the policy of the resource management (like Spark standalone or YARN). For example, I have 8 computing node with 4 cores per each. My Spark process might allocate 24 cores. It might be 8 computing nodes with 3 cores per each or 6 computing nodes with 4 cores per each. Furthermore, there is no information to let me know which task is done or which cpu core is available in my Spark program. the resource allocation might be unbalance and performance might be impacted severely, especially when several iterations of task assignment. .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:107,performance,cpu,cpu,107,"@pgrosu Thank you for the prompt response. Correct me if I'm wrong. . taskset need to specify the specific cpu cores the process wants to occupy. Since my Spark cluster is multi-tenant, some processes may be running in the cluster and occupy some CPU cores. In addition, the dynamic resource allocation is enabled in my Spark cluster, so I can't assume all of my tasks can be equally assigned to each computing node. If my data are stored in 200 partitions, it mean that my program will launch 200 tasks by using pipe() to call taskset. I can't make sure which partition will be assigned to which computing node. Round-Robin assignment is a way, but it's violated the policy of the resource management (like Spark standalone or YARN). For example, I have 8 computing node with 4 cores per each. My Spark process might allocate 24 cores. It might be 8 computing nodes with 3 cores per each or 6 computing nodes with 4 cores per each. Furthermore, there is no information to let me know which task is done or which cpu core is available in my Spark program. the resource allocation might be unbalance and performance might be impacted severely, especially when several iterations of task assignment. .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:247,performance,CPU,CPU,247,"@pgrosu Thank you for the prompt response. Correct me if I'm wrong. . taskset need to specify the specific cpu cores the process wants to occupy. Since my Spark cluster is multi-tenant, some processes may be running in the cluster and occupy some CPU cores. In addition, the dynamic resource allocation is enabled in my Spark cluster, so I can't assume all of my tasks can be equally assigned to each computing node. If my data are stored in 200 partitions, it mean that my program will launch 200 tasks by using pipe() to call taskset. I can't make sure which partition will be assigned to which computing node. Round-Robin assignment is a way, but it's violated the policy of the resource management (like Spark standalone or YARN). For example, I have 8 computing node with 4 cores per each. My Spark process might allocate 24 cores. It might be 8 computing nodes with 3 cores per each or 6 computing nodes with 4 cores per each. Furthermore, there is no information to let me know which task is done or which cpu core is available in my Spark program. the resource allocation might be unbalance and performance might be impacted severely, especially when several iterations of task assignment. .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:283,performance,resourc,resource,283,"@pgrosu Thank you for the prompt response. Correct me if I'm wrong. . taskset need to specify the specific cpu cores the process wants to occupy. Since my Spark cluster is multi-tenant, some processes may be running in the cluster and occupy some CPU cores. In addition, the dynamic resource allocation is enabled in my Spark cluster, so I can't assume all of my tasks can be equally assigned to each computing node. If my data are stored in 200 partitions, it mean that my program will launch 200 tasks by using pipe() to call taskset. I can't make sure which partition will be assigned to which computing node. Round-Robin assignment is a way, but it's violated the policy of the resource management (like Spark standalone or YARN). For example, I have 8 computing node with 4 cores per each. My Spark process might allocate 24 cores. It might be 8 computing nodes with 3 cores per each or 6 computing nodes with 4 cores per each. Furthermore, there is no information to let me know which task is done or which cpu core is available in my Spark program. the resource allocation might be unbalance and performance might be impacted severely, especially when several iterations of task assignment. .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:682,performance,resourc,resource,682,"@pgrosu Thank you for the prompt response. Correct me if I'm wrong. . taskset need to specify the specific cpu cores the process wants to occupy. Since my Spark cluster is multi-tenant, some processes may be running in the cluster and occupy some CPU cores. In addition, the dynamic resource allocation is enabled in my Spark cluster, so I can't assume all of my tasks can be equally assigned to each computing node. If my data are stored in 200 partitions, it mean that my program will launch 200 tasks by using pipe() to call taskset. I can't make sure which partition will be assigned to which computing node. Round-Robin assignment is a way, but it's violated the policy of the resource management (like Spark standalone or YARN). For example, I have 8 computing node with 4 cores per each. My Spark process might allocate 24 cores. It might be 8 computing nodes with 3 cores per each or 6 computing nodes with 4 cores per each. Furthermore, there is no information to let me know which task is done or which cpu core is available in my Spark program. the resource allocation might be unbalance and performance might be impacted severely, especially when several iterations of task assignment. .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:1013,performance,cpu,cpu,1013,"@pgrosu Thank you for the prompt response. Correct me if I'm wrong. . taskset need to specify the specific cpu cores the process wants to occupy. Since my Spark cluster is multi-tenant, some processes may be running in the cluster and occupy some CPU cores. In addition, the dynamic resource allocation is enabled in my Spark cluster, so I can't assume all of my tasks can be equally assigned to each computing node. If my data are stored in 200 partitions, it mean that my program will launch 200 tasks by using pipe() to call taskset. I can't make sure which partition will be assigned to which computing node. Round-Robin assignment is a way, but it's violated the policy of the resource management (like Spark standalone or YARN). For example, I have 8 computing node with 4 cores per each. My Spark process might allocate 24 cores. It might be 8 computing nodes with 3 cores per each or 6 computing nodes with 4 cores per each. Furthermore, there is no information to let me know which task is done or which cpu core is available in my Spark program. the resource allocation might be unbalance and performance might be impacted severely, especially when several iterations of task assignment. .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:1060,performance,resourc,resource,1060,"@pgrosu Thank you for the prompt response. Correct me if I'm wrong. . taskset need to specify the specific cpu cores the process wants to occupy. Since my Spark cluster is multi-tenant, some processes may be running in the cluster and occupy some CPU cores. In addition, the dynamic resource allocation is enabled in my Spark cluster, so I can't assume all of my tasks can be equally assigned to each computing node. If my data are stored in 200 partitions, it mean that my program will launch 200 tasks by using pipe() to call taskset. I can't make sure which partition will be assigned to which computing node. Round-Robin assignment is a way, but it's violated the policy of the resource management (like Spark standalone or YARN). For example, I have 8 computing node with 4 cores per each. My Spark process might allocate 24 cores. It might be 8 computing nodes with 3 cores per each or 6 computing nodes with 4 cores per each. Furthermore, there is no information to let me know which task is done or which cpu core is available in my Spark program. the resource allocation might be unbalance and performance might be impacted severely, especially when several iterations of task assignment. .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:1103,performance,perform,performance,1103,"@pgrosu Thank you for the prompt response. Correct me if I'm wrong. . taskset need to specify the specific cpu cores the process wants to occupy. Since my Spark cluster is multi-tenant, some processes may be running in the cluster and occupy some CPU cores. In addition, the dynamic resource allocation is enabled in my Spark cluster, so I can't assume all of my tasks can be equally assigned to each computing node. If my data are stored in 200 partitions, it mean that my program will launch 200 tasks by using pipe() to call taskset. I can't make sure which partition will be assigned to which computing node. Round-Robin assignment is a way, but it's violated the policy of the resource management (like Spark standalone or YARN). For example, I have 8 computing node with 4 cores per each. My Spark process might allocate 24 cores. It might be 8 computing nodes with 3 cores per each or 6 computing nodes with 4 cores per each. Furthermore, there is no information to let me know which task is done or which cpu core is available in my Spark program. the resource allocation might be unbalance and performance might be impacted severely, especially when several iterations of task assignment. .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:1025,reliability,availab,available,1025,"@pgrosu Thank you for the prompt response. Correct me if I'm wrong. . taskset need to specify the specific cpu cores the process wants to occupy. Since my Spark cluster is multi-tenant, some processes may be running in the cluster and occupy some CPU cores. In addition, the dynamic resource allocation is enabled in my Spark cluster, so I can't assume all of my tasks can be equally assigned to each computing node. If my data are stored in 200 partitions, it mean that my program will launch 200 tasks by using pipe() to call taskset. I can't make sure which partition will be assigned to which computing node. Round-Robin assignment is a way, but it's violated the policy of the resource management (like Spark standalone or YARN). For example, I have 8 computing node with 4 cores per each. My Spark process might allocate 24 cores. It might be 8 computing nodes with 3 cores per each or 6 computing nodes with 4 cores per each. Furthermore, there is no information to let me know which task is done or which cpu core is available in my Spark program. the resource allocation might be unbalance and performance might be impacted severely, especially when several iterations of task assignment. .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:283,safety,resourc,resource,283,"@pgrosu Thank you for the prompt response. Correct me if I'm wrong. . taskset need to specify the specific cpu cores the process wants to occupy. Since my Spark cluster is multi-tenant, some processes may be running in the cluster and occupy some CPU cores. In addition, the dynamic resource allocation is enabled in my Spark cluster, so I can't assume all of my tasks can be equally assigned to each computing node. If my data are stored in 200 partitions, it mean that my program will launch 200 tasks by using pipe() to call taskset. I can't make sure which partition will be assigned to which computing node. Round-Robin assignment is a way, but it's violated the policy of the resource management (like Spark standalone or YARN). For example, I have 8 computing node with 4 cores per each. My Spark process might allocate 24 cores. It might be 8 computing nodes with 3 cores per each or 6 computing nodes with 4 cores per each. Furthermore, there is no information to let me know which task is done or which cpu core is available in my Spark program. the resource allocation might be unbalance and performance might be impacted severely, especially when several iterations of task assignment. .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:682,safety,resourc,resource,682,"@pgrosu Thank you for the prompt response. Correct me if I'm wrong. . taskset need to specify the specific cpu cores the process wants to occupy. Since my Spark cluster is multi-tenant, some processes may be running in the cluster and occupy some CPU cores. In addition, the dynamic resource allocation is enabled in my Spark cluster, so I can't assume all of my tasks can be equally assigned to each computing node. If my data are stored in 200 partitions, it mean that my program will launch 200 tasks by using pipe() to call taskset. I can't make sure which partition will be assigned to which computing node. Round-Robin assignment is a way, but it's violated the policy of the resource management (like Spark standalone or YARN). For example, I have 8 computing node with 4 cores per each. My Spark process might allocate 24 cores. It might be 8 computing nodes with 3 cores per each or 6 computing nodes with 4 cores per each. Furthermore, there is no information to let me know which task is done or which cpu core is available in my Spark program. the resource allocation might be unbalance and performance might be impacted severely, especially when several iterations of task assignment. .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:691,safety,manag,management,691,"@pgrosu Thank you for the prompt response. Correct me if I'm wrong. . taskset need to specify the specific cpu cores the process wants to occupy. Since my Spark cluster is multi-tenant, some processes may be running in the cluster and occupy some CPU cores. In addition, the dynamic resource allocation is enabled in my Spark cluster, so I can't assume all of my tasks can be equally assigned to each computing node. If my data are stored in 200 partitions, it mean that my program will launch 200 tasks by using pipe() to call taskset. I can't make sure which partition will be assigned to which computing node. Round-Robin assignment is a way, but it's violated the policy of the resource management (like Spark standalone or YARN). For example, I have 8 computing node with 4 cores per each. My Spark process might allocate 24 cores. It might be 8 computing nodes with 3 cores per each or 6 computing nodes with 4 cores per each. Furthermore, there is no information to let me know which task is done or which cpu core is available in my Spark program. the resource allocation might be unbalance and performance might be impacted severely, especially when several iterations of task assignment. .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:1025,safety,avail,available,1025,"@pgrosu Thank you for the prompt response. Correct me if I'm wrong. . taskset need to specify the specific cpu cores the process wants to occupy. Since my Spark cluster is multi-tenant, some processes may be running in the cluster and occupy some CPU cores. In addition, the dynamic resource allocation is enabled in my Spark cluster, so I can't assume all of my tasks can be equally assigned to each computing node. If my data are stored in 200 partitions, it mean that my program will launch 200 tasks by using pipe() to call taskset. I can't make sure which partition will be assigned to which computing node. Round-Robin assignment is a way, but it's violated the policy of the resource management (like Spark standalone or YARN). For example, I have 8 computing node with 4 cores per each. My Spark process might allocate 24 cores. It might be 8 computing nodes with 3 cores per each or 6 computing nodes with 4 cores per each. Furthermore, there is no information to let me know which task is done or which cpu core is available in my Spark program. the resource allocation might be unbalance and performance might be impacted severely, especially when several iterations of task assignment. .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:1060,safety,resourc,resource,1060,"@pgrosu Thank you for the prompt response. Correct me if I'm wrong. . taskset need to specify the specific cpu cores the process wants to occupy. Since my Spark cluster is multi-tenant, some processes may be running in the cluster and occupy some CPU cores. In addition, the dynamic resource allocation is enabled in my Spark cluster, so I can't assume all of my tasks can be equally assigned to each computing node. If my data are stored in 200 partitions, it mean that my program will launch 200 tasks by using pipe() to call taskset. I can't make sure which partition will be assigned to which computing node. Round-Robin assignment is a way, but it's violated the policy of the resource management (like Spark standalone or YARN). For example, I have 8 computing node with 4 cores per each. My Spark process might allocate 24 cores. It might be 8 computing nodes with 3 cores per each or 6 computing nodes with 4 cores per each. Furthermore, there is no information to let me know which task is done or which cpu core is available in my Spark program. the resource allocation might be unbalance and performance might be impacted severely, especially when several iterations of task assignment. .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:178,security,tenant,tenant,178,"@pgrosu Thank you for the prompt response. Correct me if I'm wrong. . taskset need to specify the specific cpu cores the process wants to occupy. Since my Spark cluster is multi-tenant, some processes may be running in the cluster and occupy some CPU cores. In addition, the dynamic resource allocation is enabled in my Spark cluster, so I can't assume all of my tasks can be equally assigned to each computing node. If my data are stored in 200 partitions, it mean that my program will launch 200 tasks by using pipe() to call taskset. I can't make sure which partition will be assigned to which computing node. Round-Robin assignment is a way, but it's violated the policy of the resource management (like Spark standalone or YARN). For example, I have 8 computing node with 4 cores per each. My Spark process might allocate 24 cores. It might be 8 computing nodes with 3 cores per each or 6 computing nodes with 4 cores per each. Furthermore, there is no information to let me know which task is done or which cpu core is available in my Spark program. the resource allocation might be unbalance and performance might be impacted severely, especially when several iterations of task assignment. .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:668,security,polic,policy,668,"@pgrosu Thank you for the prompt response. Correct me if I'm wrong. . taskset need to specify the specific cpu cores the process wants to occupy. Since my Spark cluster is multi-tenant, some processes may be running in the cluster and occupy some CPU cores. In addition, the dynamic resource allocation is enabled in my Spark cluster, so I can't assume all of my tasks can be equally assigned to each computing node. If my data are stored in 200 partitions, it mean that my program will launch 200 tasks by using pipe() to call taskset. I can't make sure which partition will be assigned to which computing node. Round-Robin assignment is a way, but it's violated the policy of the resource management (like Spark standalone or YARN). For example, I have 8 computing node with 4 cores per each. My Spark process might allocate 24 cores. It might be 8 computing nodes with 3 cores per each or 6 computing nodes with 4 cores per each. Furthermore, there is no information to let me know which task is done or which cpu core is available in my Spark program. the resource allocation might be unbalance and performance might be impacted severely, especially when several iterations of task assignment. .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:1025,security,availab,available,1025,"@pgrosu Thank you for the prompt response. Correct me if I'm wrong. . taskset need to specify the specific cpu cores the process wants to occupy. Since my Spark cluster is multi-tenant, some processes may be running in the cluster and occupy some CPU cores. In addition, the dynamic resource allocation is enabled in my Spark cluster, so I can't assume all of my tasks can be equally assigned to each computing node. If my data are stored in 200 partitions, it mean that my program will launch 200 tasks by using pipe() to call taskset. I can't make sure which partition will be assigned to which computing node. Round-Robin assignment is a way, but it's violated the policy of the resource management (like Spark standalone or YARN). For example, I have 8 computing node with 4 cores per each. My Spark process might allocate 24 cores. It might be 8 computing nodes with 3 cores per each or 6 computing nodes with 4 cores per each. Furthermore, there is no information to let me know which task is done or which cpu core is available in my Spark program. the resource allocation might be unbalance and performance might be impacted severely, especially when several iterations of task assignment. .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:283,testability,resourc,resource,283,"@pgrosu Thank you for the prompt response. Correct me if I'm wrong. . taskset need to specify the specific cpu cores the process wants to occupy. Since my Spark cluster is multi-tenant, some processes may be running in the cluster and occupy some CPU cores. In addition, the dynamic resource allocation is enabled in my Spark cluster, so I can't assume all of my tasks can be equally assigned to each computing node. If my data are stored in 200 partitions, it mean that my program will launch 200 tasks by using pipe() to call taskset. I can't make sure which partition will be assigned to which computing node. Round-Robin assignment is a way, but it's violated the policy of the resource management (like Spark standalone or YARN). For example, I have 8 computing node with 4 cores per each. My Spark process might allocate 24 cores. It might be 8 computing nodes with 3 cores per each or 6 computing nodes with 4 cores per each. Furthermore, there is no information to let me know which task is done or which cpu core is available in my Spark program. the resource allocation might be unbalance and performance might be impacted severely, especially when several iterations of task assignment. .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:682,testability,resourc,resource,682,"@pgrosu Thank you for the prompt response. Correct me if I'm wrong. . taskset need to specify the specific cpu cores the process wants to occupy. Since my Spark cluster is multi-tenant, some processes may be running in the cluster and occupy some CPU cores. In addition, the dynamic resource allocation is enabled in my Spark cluster, so I can't assume all of my tasks can be equally assigned to each computing node. If my data are stored in 200 partitions, it mean that my program will launch 200 tasks by using pipe() to call taskset. I can't make sure which partition will be assigned to which computing node. Round-Robin assignment is a way, but it's violated the policy of the resource management (like Spark standalone or YARN). For example, I have 8 computing node with 4 cores per each. My Spark process might allocate 24 cores. It might be 8 computing nodes with 3 cores per each or 6 computing nodes with 4 cores per each. Furthermore, there is no information to let me know which task is done or which cpu core is available in my Spark program. the resource allocation might be unbalance and performance might be impacted severely, especially when several iterations of task assignment. .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:1060,testability,resourc,resource,1060,"@pgrosu Thank you for the prompt response. Correct me if I'm wrong. . taskset need to specify the specific cpu cores the process wants to occupy. Since my Spark cluster is multi-tenant, some processes may be running in the cluster and occupy some CPU cores. In addition, the dynamic resource allocation is enabled in my Spark cluster, so I can't assume all of my tasks can be equally assigned to each computing node. If my data are stored in 200 partitions, it mean that my program will launch 200 tasks by using pipe() to call taskset. I can't make sure which partition will be assigned to which computing node. Round-Robin assignment is a way, but it's violated the policy of the resource management (like Spark standalone or YARN). For example, I have 8 computing node with 4 cores per each. My Spark process might allocate 24 cores. It might be 8 computing nodes with 3 cores per each or 6 computing nodes with 4 cores per each. Furthermore, there is no information to let me know which task is done or which cpu core is available in my Spark program. the resource allocation might be unbalance and performance might be impacted severely, especially when several iterations of task assignment. .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:1103,usability,perform,performance,1103,"@pgrosu Thank you for the prompt response. Correct me if I'm wrong. . taskset need to specify the specific cpu cores the process wants to occupy. Since my Spark cluster is multi-tenant, some processes may be running in the cluster and occupy some CPU cores. In addition, the dynamic resource allocation is enabled in my Spark cluster, so I can't assume all of my tasks can be equally assigned to each computing node. If my data are stored in 200 partitions, it mean that my program will launch 200 tasks by using pipe() to call taskset. I can't make sure which partition will be assigned to which computing node. Round-Robin assignment is a way, but it's violated the policy of the resource management (like Spark standalone or YARN). For example, I have 8 computing node with 4 cores per each. My Spark process might allocate 24 cores. It might be 8 computing nodes with 3 cores per each or 6 computing nodes with 4 cores per each. Furthermore, there is no information to let me know which task is done or which cpu core is available in my Spark program. the resource allocation might be unbalance and performance might be impacted severely, especially when several iterations of task assignment. .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:666,availability,slo,slows,666,"@A-Tsai So now you're getting into determining your lineage graph of computations, which requires a lot of thought on how you set up your data and computational steps. Wide dependencies (multiple child partitions from the parent RDD) should be kept on the same node, while narrow dependencies (one child partition per parent RDD) can go over the network. Spark does hash partitioning to shuffle, and tries by the modulo of the number of partitions that it is somewhat uniformly distributed. Basically you should model your computation tree in order to best organize the data for good distribution and maximal local computation, otherwise you flood you network which slows down your completion-time. If you have 8 compute node with 4 cores each, then the node number will not change. The key to think about is the cores, but you have to determine to resource-allocate properly. The following can be helpful:. http://site.clairvoyantsoft.com/understanding-resource-allocation-configurations-spark-application/. Regarding task information, you get the duration here:. https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.scheduler.TaskInfo@finishTime:Long. You can control the policy with the application as noted here:. https://spark.apache.org/docs/latest/job-scheduling.html#scheduling-within-an-application. You can control the assignment by creating pools with a `minShare` of cpu cores guaranteed for that pool. If you have one pool, then that can control it all - especially in FIFO mode - but that would not be efficient use of a Spark cluster. Spark has many moving parts, including how you structure your data and how to chose to process it (batch vs. stream). To properly perform this you have to analyze carefully the design of your computational DAG, and how your work should be processed given the resources. To me 200 partitions does not quite feel right, but if you think that is optimal for your design that's fine. Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:672,availability,down,down,672,"@A-Tsai So now you're getting into determining your lineage graph of computations, which requires a lot of thought on how you set up your data and computational steps. Wide dependencies (multiple child partitions from the parent RDD) should be kept on the same node, while narrow dependencies (one child partition per parent RDD) can go over the network. Spark does hash partitioning to shuffle, and tries by the modulo of the number of partitions that it is somewhat uniformly distributed. Basically you should model your computation tree in order to best organize the data for good distribution and maximal local computation, otherwise you flood you network which slows down your completion-time. If you have 8 compute node with 4 cores each, then the node number will not change. The key to think about is the cores, but you have to determine to resource-allocate properly. The following can be helpful:. http://site.clairvoyantsoft.com/understanding-resource-allocation-configurations-spark-application/. Regarding task information, you get the duration here:. https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.scheduler.TaskInfo@finishTime:Long. You can control the policy with the application as noted here:. https://spark.apache.org/docs/latest/job-scheduling.html#scheduling-within-an-application. You can control the assignment by creating pools with a `minShare` of cpu cores guaranteed for that pool. If you have one pool, then that can control it all - especially in FIFO mode - but that would not be efficient use of a Spark cluster. Spark has many moving parts, including how you structure your data and how to chose to process it (batch vs. stream). To properly perform this you have to analyze carefully the design of your computational DAG, and how your work should be processed given the resources. To me 200 partitions does not quite feel right, but if you think that is optimal for your design that's fine. Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:1563,availability,cluster,cluster,1563,"@A-Tsai So now you're getting into determining your lineage graph of computations, which requires a lot of thought on how you set up your data and computational steps. Wide dependencies (multiple child partitions from the parent RDD) should be kept on the same node, while narrow dependencies (one child partition per parent RDD) can go over the network. Spark does hash partitioning to shuffle, and tries by the modulo of the number of partitions that it is somewhat uniformly distributed. Basically you should model your computation tree in order to best organize the data for good distribution and maximal local computation, otherwise you flood you network which slows down your completion-time. If you have 8 compute node with 4 cores each, then the node number will not change. The key to think about is the cores, but you have to determine to resource-allocate properly. The following can be helpful:. http://site.clairvoyantsoft.com/understanding-resource-allocation-configurations-spark-application/. Regarding task information, you get the duration here:. https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.scheduler.TaskInfo@finishTime:Long. You can control the policy with the application as noted here:. https://spark.apache.org/docs/latest/job-scheduling.html#scheduling-within-an-application. You can control the assignment by creating pools with a `minShare` of cpu cores guaranteed for that pool. If you have one pool, then that can control it all - especially in FIFO mode - but that would not be efficient use of a Spark cluster. Spark has many moving parts, including how you structure your data and how to chose to process it (batch vs. stream). To properly perform this you have to analyze carefully the design of your computational DAG, and how your work should be processed given the resources. To me 200 partitions does not quite feel right, but if you think that is optimal for your design that's fine. Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:173,deployability,depend,dependencies,173,"@A-Tsai So now you're getting into determining your lineage graph of computations, which requires a lot of thought on how you set up your data and computational steps. Wide dependencies (multiple child partitions from the parent RDD) should be kept on the same node, while narrow dependencies (one child partition per parent RDD) can go over the network. Spark does hash partitioning to shuffle, and tries by the modulo of the number of partitions that it is somewhat uniformly distributed. Basically you should model your computation tree in order to best organize the data for good distribution and maximal local computation, otherwise you flood you network which slows down your completion-time. If you have 8 compute node with 4 cores each, then the node number will not change. The key to think about is the cores, but you have to determine to resource-allocate properly. The following can be helpful:. http://site.clairvoyantsoft.com/understanding-resource-allocation-configurations-spark-application/. Regarding task information, you get the duration here:. https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.scheduler.TaskInfo@finishTime:Long. You can control the policy with the application as noted here:. https://spark.apache.org/docs/latest/job-scheduling.html#scheduling-within-an-application. You can control the assignment by creating pools with a `minShare` of cpu cores guaranteed for that pool. If you have one pool, then that can control it all - especially in FIFO mode - but that would not be efficient use of a Spark cluster. Spark has many moving parts, including how you structure your data and how to chose to process it (batch vs. stream). To properly perform this you have to analyze carefully the design of your computational DAG, and how your work should be processed given the resources. To me 200 partitions does not quite feel right, but if you think that is optimal for your design that's fine. Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:280,deployability,depend,dependencies,280,"@A-Tsai So now you're getting into determining your lineage graph of computations, which requires a lot of thought on how you set up your data and computational steps. Wide dependencies (multiple child partitions from the parent RDD) should be kept on the same node, while narrow dependencies (one child partition per parent RDD) can go over the network. Spark does hash partitioning to shuffle, and tries by the modulo of the number of partitions that it is somewhat uniformly distributed. Basically you should model your computation tree in order to best organize the data for good distribution and maximal local computation, otherwise you flood you network which slows down your completion-time. If you have 8 compute node with 4 cores each, then the node number will not change. The key to think about is the cores, but you have to determine to resource-allocate properly. The following can be helpful:. http://site.clairvoyantsoft.com/understanding-resource-allocation-configurations-spark-application/. Regarding task information, you get the duration here:. https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.scheduler.TaskInfo@finishTime:Long. You can control the policy with the application as noted here:. https://spark.apache.org/docs/latest/job-scheduling.html#scheduling-within-an-application. You can control the assignment by creating pools with a `minShare` of cpu cores guaranteed for that pool. If you have one pool, then that can control it all - especially in FIFO mode - but that would not be efficient use of a Spark cluster. Spark has many moving parts, including how you structure your data and how to chose to process it (batch vs. stream). To properly perform this you have to analyze carefully the design of your computational DAG, and how your work should be processed given the resources. To me 200 partitions does not quite feel right, but if you think that is optimal for your design that's fine. Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:413,deployability,modul,modulo,413,"@A-Tsai So now you're getting into determining your lineage graph of computations, which requires a lot of thought on how you set up your data and computational steps. Wide dependencies (multiple child partitions from the parent RDD) should be kept on the same node, while narrow dependencies (one child partition per parent RDD) can go over the network. Spark does hash partitioning to shuffle, and tries by the modulo of the number of partitions that it is somewhat uniformly distributed. Basically you should model your computation tree in order to best organize the data for good distribution and maximal local computation, otherwise you flood you network which slows down your completion-time. If you have 8 compute node with 4 cores each, then the node number will not change. The key to think about is the cores, but you have to determine to resource-allocate properly. The following can be helpful:. http://site.clairvoyantsoft.com/understanding-resource-allocation-configurations-spark-application/. Regarding task information, you get the duration here:. https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.scheduler.TaskInfo@finishTime:Long. You can control the policy with the application as noted here:. https://spark.apache.org/docs/latest/job-scheduling.html#scheduling-within-an-application. You can control the assignment by creating pools with a `minShare` of cpu cores guaranteed for that pool. If you have one pool, then that can control it all - especially in FIFO mode - but that would not be efficient use of a Spark cluster. Spark has many moving parts, including how you structure your data and how to chose to process it (batch vs. stream). To properly perform this you have to analyze carefully the design of your computational DAG, and how your work should be processed given the resources. To me 200 partitions does not quite feel right, but if you think that is optimal for your design that's fine. Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:849,deployability,resourc,resource-allocate,849,"@A-Tsai So now you're getting into determining your lineage graph of computations, which requires a lot of thought on how you set up your data and computational steps. Wide dependencies (multiple child partitions from the parent RDD) should be kept on the same node, while narrow dependencies (one child partition per parent RDD) can go over the network. Spark does hash partitioning to shuffle, and tries by the modulo of the number of partitions that it is somewhat uniformly distributed. Basically you should model your computation tree in order to best organize the data for good distribution and maximal local computation, otherwise you flood you network which slows down your completion-time. If you have 8 compute node with 4 cores each, then the node number will not change. The key to think about is the cores, but you have to determine to resource-allocate properly. The following can be helpful:. http://site.clairvoyantsoft.com/understanding-resource-allocation-configurations-spark-application/. Regarding task information, you get the duration here:. https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.scheduler.TaskInfo@finishTime:Long. You can control the policy with the application as noted here:. https://spark.apache.org/docs/latest/job-scheduling.html#scheduling-within-an-application. You can control the assignment by creating pools with a `minShare` of cpu cores guaranteed for that pool. If you have one pool, then that can control it all - especially in FIFO mode - but that would not be efficient use of a Spark cluster. Spark has many moving parts, including how you structure your data and how to chose to process it (batch vs. stream). To properly perform this you have to analyze carefully the design of your computational DAG, and how your work should be processed given the resources. To me 200 partitions does not quite feel right, but if you think that is optimal for your design that's fine. Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:954,deployability,resourc,resource-allocation-configurations-spark-application,954,"@A-Tsai So now you're getting into determining your lineage graph of computations, which requires a lot of thought on how you set up your data and computational steps. Wide dependencies (multiple child partitions from the parent RDD) should be kept on the same node, while narrow dependencies (one child partition per parent RDD) can go over the network. Spark does hash partitioning to shuffle, and tries by the modulo of the number of partitions that it is somewhat uniformly distributed. Basically you should model your computation tree in order to best organize the data for good distribution and maximal local computation, otherwise you flood you network which slows down your completion-time. If you have 8 compute node with 4 cores each, then the node number will not change. The key to think about is the cores, but you have to determine to resource-allocate properly. The following can be helpful:. http://site.clairvoyantsoft.com/understanding-resource-allocation-configurations-spark-application/. Regarding task information, you get the duration here:. https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.scheduler.TaskInfo@finishTime:Long. You can control the policy with the application as noted here:. https://spark.apache.org/docs/latest/job-scheduling.html#scheduling-within-an-application. You can control the assignment by creating pools with a `minShare` of cpu cores guaranteed for that pool. If you have one pool, then that can control it all - especially in FIFO mode - but that would not be efficient use of a Spark cluster. Spark has many moving parts, including how you structure your data and how to chose to process it (batch vs. stream). To properly perform this you have to analyze carefully the design of your computational DAG, and how your work should be processed given the resources. To me 200 partitions does not quite feel right, but if you think that is optimal for your design that's fine. Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:1102,deployability,api,api,1102,"@A-Tsai So now you're getting into determining your lineage graph of computations, which requires a lot of thought on how you set up your data and computational steps. Wide dependencies (multiple child partitions from the parent RDD) should be kept on the same node, while narrow dependencies (one child partition per parent RDD) can go over the network. Spark does hash partitioning to shuffle, and tries by the modulo of the number of partitions that it is somewhat uniformly distributed. Basically you should model your computation tree in order to best organize the data for good distribution and maximal local computation, otherwise you flood you network which slows down your completion-time. If you have 8 compute node with 4 cores each, then the node number will not change. The key to think about is the cores, but you have to determine to resource-allocate properly. The following can be helpful:. http://site.clairvoyantsoft.com/understanding-resource-allocation-configurations-spark-application/. Regarding task information, you get the duration here:. https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.scheduler.TaskInfo@finishTime:Long. You can control the policy with the application as noted here:. https://spark.apache.org/docs/latest/job-scheduling.html#scheduling-within-an-application. You can control the assignment by creating pools with a `minShare` of cpu cores guaranteed for that pool. If you have one pool, then that can control it all - especially in FIFO mode - but that would not be efficient use of a Spark cluster. Spark has many moving parts, including how you structure your data and how to chose to process it (batch vs. stream). To properly perform this you have to analyze carefully the design of your computational DAG, and how your work should be processed given the resources. To me 200 partitions does not quite feel right, but if you think that is optimal for your design that's fine. Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:1563,deployability,cluster,cluster,1563,"@A-Tsai So now you're getting into determining your lineage graph of computations, which requires a lot of thought on how you set up your data and computational steps. Wide dependencies (multiple child partitions from the parent RDD) should be kept on the same node, while narrow dependencies (one child partition per parent RDD) can go over the network. Spark does hash partitioning to shuffle, and tries by the modulo of the number of partitions that it is somewhat uniformly distributed. Basically you should model your computation tree in order to best organize the data for good distribution and maximal local computation, otherwise you flood you network which slows down your completion-time. If you have 8 compute node with 4 cores each, then the node number will not change. The key to think about is the cores, but you have to determine to resource-allocate properly. The following can be helpful:. http://site.clairvoyantsoft.com/understanding-resource-allocation-configurations-spark-application/. Regarding task information, you get the duration here:. https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.scheduler.TaskInfo@finishTime:Long. You can control the policy with the application as noted here:. https://spark.apache.org/docs/latest/job-scheduling.html#scheduling-within-an-application. You can control the assignment by creating pools with a `minShare` of cpu cores guaranteed for that pool. If you have one pool, then that can control it all - especially in FIFO mode - but that would not be efficient use of a Spark cluster. Spark has many moving parts, including how you structure your data and how to chose to process it (batch vs. stream). To properly perform this you have to analyze carefully the design of your computational DAG, and how your work should be processed given the resources. To me 200 partitions does not quite feel right, but if you think that is optimal for your design that's fine. Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:1831,deployability,resourc,resources,1831,"@A-Tsai So now you're getting into determining your lineage graph of computations, which requires a lot of thought on how you set up your data and computational steps. Wide dependencies (multiple child partitions from the parent RDD) should be kept on the same node, while narrow dependencies (one child partition per parent RDD) can go over the network. Spark does hash partitioning to shuffle, and tries by the modulo of the number of partitions that it is somewhat uniformly distributed. Basically you should model your computation tree in order to best organize the data for good distribution and maximal local computation, otherwise you flood you network which slows down your completion-time. If you have 8 compute node with 4 cores each, then the node number will not change. The key to think about is the cores, but you have to determine to resource-allocate properly. The following can be helpful:. http://site.clairvoyantsoft.com/understanding-resource-allocation-configurations-spark-application/. Regarding task information, you get the duration here:. https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.scheduler.TaskInfo@finishTime:Long. You can control the policy with the application as noted here:. https://spark.apache.org/docs/latest/job-scheduling.html#scheduling-within-an-application. You can control the assignment by creating pools with a `minShare` of cpu cores guaranteed for that pool. If you have one pool, then that can control it all - especially in FIFO mode - but that would not be efficient use of a Spark cluster. Spark has many moving parts, including how you structure your data and how to chose to process it (batch vs. stream). To properly perform this you have to analyze carefully the design of your computational DAG, and how your work should be processed given the resources. To me 200 partitions does not quite feel right, but if you think that is optimal for your design that's fine. Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:512,energy efficiency,model,model,512,"@A-Tsai So now you're getting into determining your lineage graph of computations, which requires a lot of thought on how you set up your data and computational steps. Wide dependencies (multiple child partitions from the parent RDD) should be kept on the same node, while narrow dependencies (one child partition per parent RDD) can go over the network. Spark does hash partitioning to shuffle, and tries by the modulo of the number of partitions that it is somewhat uniformly distributed. Basically you should model your computation tree in order to best organize the data for good distribution and maximal local computation, otherwise you flood you network which slows down your completion-time. If you have 8 compute node with 4 cores each, then the node number will not change. The key to think about is the cores, but you have to determine to resource-allocate properly. The following can be helpful:. http://site.clairvoyantsoft.com/understanding-resource-allocation-configurations-spark-application/. Regarding task information, you get the duration here:. https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.scheduler.TaskInfo@finishTime:Long. You can control the policy with the application as noted here:. https://spark.apache.org/docs/latest/job-scheduling.html#scheduling-within-an-application. You can control the assignment by creating pools with a `minShare` of cpu cores guaranteed for that pool. If you have one pool, then that can control it all - especially in FIFO mode - but that would not be efficient use of a Spark cluster. Spark has many moving parts, including how you structure your data and how to chose to process it (batch vs. stream). To properly perform this you have to analyze carefully the design of your computational DAG, and how your work should be processed given the resources. To me 200 partitions does not quite feel right, but if you think that is optimal for your design that's fine. Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:733,energy efficiency,core,cores,733,"@A-Tsai So now you're getting into determining your lineage graph of computations, which requires a lot of thought on how you set up your data and computational steps. Wide dependencies (multiple child partitions from the parent RDD) should be kept on the same node, while narrow dependencies (one child partition per parent RDD) can go over the network. Spark does hash partitioning to shuffle, and tries by the modulo of the number of partitions that it is somewhat uniformly distributed. Basically you should model your computation tree in order to best organize the data for good distribution and maximal local computation, otherwise you flood you network which slows down your completion-time. If you have 8 compute node with 4 cores each, then the node number will not change. The key to think about is the cores, but you have to determine to resource-allocate properly. The following can be helpful:. http://site.clairvoyantsoft.com/understanding-resource-allocation-configurations-spark-application/. Regarding task information, you get the duration here:. https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.scheduler.TaskInfo@finishTime:Long. You can control the policy with the application as noted here:. https://spark.apache.org/docs/latest/job-scheduling.html#scheduling-within-an-application. You can control the assignment by creating pools with a `minShare` of cpu cores guaranteed for that pool. If you have one pool, then that can control it all - especially in FIFO mode - but that would not be efficient use of a Spark cluster. Spark has many moving parts, including how you structure your data and how to chose to process it (batch vs. stream). To properly perform this you have to analyze carefully the design of your computational DAG, and how your work should be processed given the resources. To me 200 partitions does not quite feel right, but if you think that is optimal for your design that's fine. Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:813,energy efficiency,core,cores,813,"@A-Tsai So now you're getting into determining your lineage graph of computations, which requires a lot of thought on how you set up your data and computational steps. Wide dependencies (multiple child partitions from the parent RDD) should be kept on the same node, while narrow dependencies (one child partition per parent RDD) can go over the network. Spark does hash partitioning to shuffle, and tries by the modulo of the number of partitions that it is somewhat uniformly distributed. Basically you should model your computation tree in order to best organize the data for good distribution and maximal local computation, otherwise you flood you network which slows down your completion-time. If you have 8 compute node with 4 cores each, then the node number will not change. The key to think about is the cores, but you have to determine to resource-allocate properly. The following can be helpful:. http://site.clairvoyantsoft.com/understanding-resource-allocation-configurations-spark-application/. Regarding task information, you get the duration here:. https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.scheduler.TaskInfo@finishTime:Long. You can control the policy with the application as noted here:. https://spark.apache.org/docs/latest/job-scheduling.html#scheduling-within-an-application. You can control the assignment by creating pools with a `minShare` of cpu cores guaranteed for that pool. If you have one pool, then that can control it all - especially in FIFO mode - but that would not be efficient use of a Spark cluster. Spark has many moving parts, including how you structure your data and how to chose to process it (batch vs. stream). To properly perform this you have to analyze carefully the design of your computational DAG, and how your work should be processed given the resources. To me 200 partitions does not quite feel right, but if you think that is optimal for your design that's fine. Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:849,energy efficiency,resourc,resource-allocate,849,"@A-Tsai So now you're getting into determining your lineage graph of computations, which requires a lot of thought on how you set up your data and computational steps. Wide dependencies (multiple child partitions from the parent RDD) should be kept on the same node, while narrow dependencies (one child partition per parent RDD) can go over the network. Spark does hash partitioning to shuffle, and tries by the modulo of the number of partitions that it is somewhat uniformly distributed. Basically you should model your computation tree in order to best organize the data for good distribution and maximal local computation, otherwise you flood you network which slows down your completion-time. If you have 8 compute node with 4 cores each, then the node number will not change. The key to think about is the cores, but you have to determine to resource-allocate properly. The following can be helpful:. http://site.clairvoyantsoft.com/understanding-resource-allocation-configurations-spark-application/. Regarding task information, you get the duration here:. https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.scheduler.TaskInfo@finishTime:Long. You can control the policy with the application as noted here:. https://spark.apache.org/docs/latest/job-scheduling.html#scheduling-within-an-application. You can control the assignment by creating pools with a `minShare` of cpu cores guaranteed for that pool. If you have one pool, then that can control it all - especially in FIFO mode - but that would not be efficient use of a Spark cluster. Spark has many moving parts, including how you structure your data and how to chose to process it (batch vs. stream). To properly perform this you have to analyze carefully the design of your computational DAG, and how your work should be processed given the resources. To me 200 partitions does not quite feel right, but if you think that is optimal for your design that's fine. Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:954,energy efficiency,resourc,resource-allocation-configurations-spark-application,954,"@A-Tsai So now you're getting into determining your lineage graph of computations, which requires a lot of thought on how you set up your data and computational steps. Wide dependencies (multiple child partitions from the parent RDD) should be kept on the same node, while narrow dependencies (one child partition per parent RDD) can go over the network. Spark does hash partitioning to shuffle, and tries by the modulo of the number of partitions that it is somewhat uniformly distributed. Basically you should model your computation tree in order to best organize the data for good distribution and maximal local computation, otherwise you flood you network which slows down your completion-time. If you have 8 compute node with 4 cores each, then the node number will not change. The key to think about is the cores, but you have to determine to resource-allocate properly. The following can be helpful:. http://site.clairvoyantsoft.com/understanding-resource-allocation-configurations-spark-application/. Regarding task information, you get the duration here:. https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.scheduler.TaskInfo@finishTime:Long. You can control the policy with the application as noted here:. https://spark.apache.org/docs/latest/job-scheduling.html#scheduling-within-an-application. You can control the assignment by creating pools with a `minShare` of cpu cores guaranteed for that pool. If you have one pool, then that can control it all - especially in FIFO mode - but that would not be efficient use of a Spark cluster. Spark has many moving parts, including how you structure your data and how to chose to process it (batch vs. stream). To properly perform this you have to analyze carefully the design of your computational DAG, and how your work should be processed given the resources. To me 200 partitions does not quite feel right, but if you think that is optimal for your design that's fine. Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:1140,energy efficiency,schedul,scheduler,1140,"@A-Tsai So now you're getting into determining your lineage graph of computations, which requires a lot of thought on how you set up your data and computational steps. Wide dependencies (multiple child partitions from the parent RDD) should be kept on the same node, while narrow dependencies (one child partition per parent RDD) can go over the network. Spark does hash partitioning to shuffle, and tries by the modulo of the number of partitions that it is somewhat uniformly distributed. Basically you should model your computation tree in order to best organize the data for good distribution and maximal local computation, otherwise you flood you network which slows down your completion-time. If you have 8 compute node with 4 cores each, then the node number will not change. The key to think about is the cores, but you have to determine to resource-allocate properly. The following can be helpful:. http://site.clairvoyantsoft.com/understanding-resource-allocation-configurations-spark-application/. Regarding task information, you get the duration here:. https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.scheduler.TaskInfo@finishTime:Long. You can control the policy with the application as noted here:. https://spark.apache.org/docs/latest/job-scheduling.html#scheduling-within-an-application. You can control the assignment by creating pools with a `minShare` of cpu cores guaranteed for that pool. If you have one pool, then that can control it all - especially in FIFO mode - but that would not be efficient use of a Spark cluster. Spark has many moving parts, including how you structure your data and how to chose to process it (batch vs. stream). To properly perform this you have to analyze carefully the design of your computational DAG, and how your work should be processed given the resources. To me 200 partitions does not quite feel right, but if you think that is optimal for your design that's fine. Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:1281,energy efficiency,schedul,scheduling,1281,"@A-Tsai So now you're getting into determining your lineage graph of computations, which requires a lot of thought on how you set up your data and computational steps. Wide dependencies (multiple child partitions from the parent RDD) should be kept on the same node, while narrow dependencies (one child partition per parent RDD) can go over the network. Spark does hash partitioning to shuffle, and tries by the modulo of the number of partitions that it is somewhat uniformly distributed. Basically you should model your computation tree in order to best organize the data for good distribution and maximal local computation, otherwise you flood you network which slows down your completion-time. If you have 8 compute node with 4 cores each, then the node number will not change. The key to think about is the cores, but you have to determine to resource-allocate properly. The following can be helpful:. http://site.clairvoyantsoft.com/understanding-resource-allocation-configurations-spark-application/. Regarding task information, you get the duration here:. https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.scheduler.TaskInfo@finishTime:Long. You can control the policy with the application as noted here:. https://spark.apache.org/docs/latest/job-scheduling.html#scheduling-within-an-application. You can control the assignment by creating pools with a `minShare` of cpu cores guaranteed for that pool. If you have one pool, then that can control it all - especially in FIFO mode - but that would not be efficient use of a Spark cluster. Spark has many moving parts, including how you structure your data and how to chose to process it (batch vs. stream). To properly perform this you have to analyze carefully the design of your computational DAG, and how your work should be processed given the resources. To me 200 partitions does not quite feel right, but if you think that is optimal for your design that's fine. Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:1297,energy efficiency,schedul,scheduling-within-an-application,1297,"@A-Tsai So now you're getting into determining your lineage graph of computations, which requires a lot of thought on how you set up your data and computational steps. Wide dependencies (multiple child partitions from the parent RDD) should be kept on the same node, while narrow dependencies (one child partition per parent RDD) can go over the network. Spark does hash partitioning to shuffle, and tries by the modulo of the number of partitions that it is somewhat uniformly distributed. Basically you should model your computation tree in order to best organize the data for good distribution and maximal local computation, otherwise you flood you network which slows down your completion-time. If you have 8 compute node with 4 cores each, then the node number will not change. The key to think about is the cores, but you have to determine to resource-allocate properly. The following can be helpful:. http://site.clairvoyantsoft.com/understanding-resource-allocation-configurations-spark-application/. Regarding task information, you get the duration here:. https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.scheduler.TaskInfo@finishTime:Long. You can control the policy with the application as noted here:. https://spark.apache.org/docs/latest/job-scheduling.html#scheduling-within-an-application. You can control the assignment by creating pools with a `minShare` of cpu cores guaranteed for that pool. If you have one pool, then that can control it all - especially in FIFO mode - but that would not be efficient use of a Spark cluster. Spark has many moving parts, including how you structure your data and how to chose to process it (batch vs. stream). To properly perform this you have to analyze carefully the design of your computational DAG, and how your work should be processed given the resources. To me 200 partitions does not quite feel right, but if you think that is optimal for your design that's fine. Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:1401,energy efficiency,cpu,cpu,1401,"@A-Tsai So now you're getting into determining your lineage graph of computations, which requires a lot of thought on how you set up your data and computational steps. Wide dependencies (multiple child partitions from the parent RDD) should be kept on the same node, while narrow dependencies (one child partition per parent RDD) can go over the network. Spark does hash partitioning to shuffle, and tries by the modulo of the number of partitions that it is somewhat uniformly distributed. Basically you should model your computation tree in order to best organize the data for good distribution and maximal local computation, otherwise you flood you network which slows down your completion-time. If you have 8 compute node with 4 cores each, then the node number will not change. The key to think about is the cores, but you have to determine to resource-allocate properly. The following can be helpful:. http://site.clairvoyantsoft.com/understanding-resource-allocation-configurations-spark-application/. Regarding task information, you get the duration here:. https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.scheduler.TaskInfo@finishTime:Long. You can control the policy with the application as noted here:. https://spark.apache.org/docs/latest/job-scheduling.html#scheduling-within-an-application. You can control the assignment by creating pools with a `minShare` of cpu cores guaranteed for that pool. If you have one pool, then that can control it all - especially in FIFO mode - but that would not be efficient use of a Spark cluster. Spark has many moving parts, including how you structure your data and how to chose to process it (batch vs. stream). To properly perform this you have to analyze carefully the design of your computational DAG, and how your work should be processed given the resources. To me 200 partitions does not quite feel right, but if you think that is optimal for your design that's fine. Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:1405,energy efficiency,core,cores,1405,"@A-Tsai So now you're getting into determining your lineage graph of computations, which requires a lot of thought on how you set up your data and computational steps. Wide dependencies (multiple child partitions from the parent RDD) should be kept on the same node, while narrow dependencies (one child partition per parent RDD) can go over the network. Spark does hash partitioning to shuffle, and tries by the modulo of the number of partitions that it is somewhat uniformly distributed. Basically you should model your computation tree in order to best organize the data for good distribution and maximal local computation, otherwise you flood you network which slows down your completion-time. If you have 8 compute node with 4 cores each, then the node number will not change. The key to think about is the cores, but you have to determine to resource-allocate properly. The following can be helpful:. http://site.clairvoyantsoft.com/understanding-resource-allocation-configurations-spark-application/. Regarding task information, you get the duration here:. https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.scheduler.TaskInfo@finishTime:Long. You can control the policy with the application as noted here:. https://spark.apache.org/docs/latest/job-scheduling.html#scheduling-within-an-application. You can control the assignment by creating pools with a `minShare` of cpu cores guaranteed for that pool. If you have one pool, then that can control it all - especially in FIFO mode - but that would not be efficient use of a Spark cluster. Spark has many moving parts, including how you structure your data and how to chose to process it (batch vs. stream). To properly perform this you have to analyze carefully the design of your computational DAG, and how your work should be processed given the resources. To me 200 partitions does not quite feel right, but if you think that is optimal for your design that's fine. Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:1831,energy efficiency,resourc,resources,1831,"@A-Tsai So now you're getting into determining your lineage graph of computations, which requires a lot of thought on how you set up your data and computational steps. Wide dependencies (multiple child partitions from the parent RDD) should be kept on the same node, while narrow dependencies (one child partition per parent RDD) can go over the network. Spark does hash partitioning to shuffle, and tries by the modulo of the number of partitions that it is somewhat uniformly distributed. Basically you should model your computation tree in order to best organize the data for good distribution and maximal local computation, otherwise you flood you network which slows down your completion-time. If you have 8 compute node with 4 cores each, then the node number will not change. The key to think about is the cores, but you have to determine to resource-allocate properly. The following can be helpful:. http://site.clairvoyantsoft.com/understanding-resource-allocation-configurations-spark-application/. Regarding task information, you get the duration here:. https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.scheduler.TaskInfo@finishTime:Long. You can control the policy with the application as noted here:. https://spark.apache.org/docs/latest/job-scheduling.html#scheduling-within-an-application. You can control the assignment by creating pools with a `minShare` of cpu cores guaranteed for that pool. If you have one pool, then that can control it all - especially in FIFO mode - but that would not be efficient use of a Spark cluster. Spark has many moving parts, including how you structure your data and how to chose to process it (batch vs. stream). To properly perform this you have to analyze carefully the design of your computational DAG, and how your work should be processed given the resources. To me 200 partitions does not quite feel right, but if you think that is optimal for your design that's fine. Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:1915,energy efficiency,optim,optimal,1915,"@A-Tsai So now you're getting into determining your lineage graph of computations, which requires a lot of thought on how you set up your data and computational steps. Wide dependencies (multiple child partitions from the parent RDD) should be kept on the same node, while narrow dependencies (one child partition per parent RDD) can go over the network. Spark does hash partitioning to shuffle, and tries by the modulo of the number of partitions that it is somewhat uniformly distributed. Basically you should model your computation tree in order to best organize the data for good distribution and maximal local computation, otherwise you flood you network which slows down your completion-time. If you have 8 compute node with 4 cores each, then the node number will not change. The key to think about is the cores, but you have to determine to resource-allocate properly. The following can be helpful:. http://site.clairvoyantsoft.com/understanding-resource-allocation-configurations-spark-application/. Regarding task information, you get the duration here:. https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.scheduler.TaskInfo@finishTime:Long. You can control the policy with the application as noted here:. https://spark.apache.org/docs/latest/job-scheduling.html#scheduling-within-an-application. You can control the assignment by creating pools with a `minShare` of cpu cores guaranteed for that pool. If you have one pool, then that can control it all - especially in FIFO mode - but that would not be efficient use of a Spark cluster. Spark has many moving parts, including how you structure your data and how to chose to process it (batch vs. stream). To properly perform this you have to analyze carefully the design of your computational DAG, and how your work should be processed given the resources. To me 200 partitions does not quite feel right, but if you think that is optimal for your design that's fine. Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:173,integrability,depend,dependencies,173,"@A-Tsai So now you're getting into determining your lineage graph of computations, which requires a lot of thought on how you set up your data and computational steps. Wide dependencies (multiple child partitions from the parent RDD) should be kept on the same node, while narrow dependencies (one child partition per parent RDD) can go over the network. Spark does hash partitioning to shuffle, and tries by the modulo of the number of partitions that it is somewhat uniformly distributed. Basically you should model your computation tree in order to best organize the data for good distribution and maximal local computation, otherwise you flood you network which slows down your completion-time. If you have 8 compute node with 4 cores each, then the node number will not change. The key to think about is the cores, but you have to determine to resource-allocate properly. The following can be helpful:. http://site.clairvoyantsoft.com/understanding-resource-allocation-configurations-spark-application/. Regarding task information, you get the duration here:. https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.scheduler.TaskInfo@finishTime:Long. You can control the policy with the application as noted here:. https://spark.apache.org/docs/latest/job-scheduling.html#scheduling-within-an-application. You can control the assignment by creating pools with a `minShare` of cpu cores guaranteed for that pool. If you have one pool, then that can control it all - especially in FIFO mode - but that would not be efficient use of a Spark cluster. Spark has many moving parts, including how you structure your data and how to chose to process it (batch vs. stream). To properly perform this you have to analyze carefully the design of your computational DAG, and how your work should be processed given the resources. To me 200 partitions does not quite feel right, but if you think that is optimal for your design that's fine. Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:280,integrability,depend,dependencies,280,"@A-Tsai So now you're getting into determining your lineage graph of computations, which requires a lot of thought on how you set up your data and computational steps. Wide dependencies (multiple child partitions from the parent RDD) should be kept on the same node, while narrow dependencies (one child partition per parent RDD) can go over the network. Spark does hash partitioning to shuffle, and tries by the modulo of the number of partitions that it is somewhat uniformly distributed. Basically you should model your computation tree in order to best organize the data for good distribution and maximal local computation, otherwise you flood you network which slows down your completion-time. If you have 8 compute node with 4 cores each, then the node number will not change. The key to think about is the cores, but you have to determine to resource-allocate properly. The following can be helpful:. http://site.clairvoyantsoft.com/understanding-resource-allocation-configurations-spark-application/. Regarding task information, you get the duration here:. https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.scheduler.TaskInfo@finishTime:Long. You can control the policy with the application as noted here:. https://spark.apache.org/docs/latest/job-scheduling.html#scheduling-within-an-application. You can control the assignment by creating pools with a `minShare` of cpu cores guaranteed for that pool. If you have one pool, then that can control it all - especially in FIFO mode - but that would not be efficient use of a Spark cluster. Spark has many moving parts, including how you structure your data and how to chose to process it (batch vs. stream). To properly perform this you have to analyze carefully the design of your computational DAG, and how your work should be processed given the resources. To me 200 partitions does not quite feel right, but if you think that is optimal for your design that's fine. Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:974,integrability,configur,configurations-spark-application,974,"@A-Tsai So now you're getting into determining your lineage graph of computations, which requires a lot of thought on how you set up your data and computational steps. Wide dependencies (multiple child partitions from the parent RDD) should be kept on the same node, while narrow dependencies (one child partition per parent RDD) can go over the network. Spark does hash partitioning to shuffle, and tries by the modulo of the number of partitions that it is somewhat uniformly distributed. Basically you should model your computation tree in order to best organize the data for good distribution and maximal local computation, otherwise you flood you network which slows down your completion-time. If you have 8 compute node with 4 cores each, then the node number will not change. The key to think about is the cores, but you have to determine to resource-allocate properly. The following can be helpful:. http://site.clairvoyantsoft.com/understanding-resource-allocation-configurations-spark-application/. Regarding task information, you get the duration here:. https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.scheduler.TaskInfo@finishTime:Long. You can control the policy with the application as noted here:. https://spark.apache.org/docs/latest/job-scheduling.html#scheduling-within-an-application. You can control the assignment by creating pools with a `minShare` of cpu cores guaranteed for that pool. If you have one pool, then that can control it all - especially in FIFO mode - but that would not be efficient use of a Spark cluster. Spark has many moving parts, including how you structure your data and how to chose to process it (batch vs. stream). To properly perform this you have to analyze carefully the design of your computational DAG, and how your work should be processed given the resources. To me 200 partitions does not quite feel right, but if you think that is optimal for your design that's fine. Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:1102,integrability,api,api,1102,"@A-Tsai So now you're getting into determining your lineage graph of computations, which requires a lot of thought on how you set up your data and computational steps. Wide dependencies (multiple child partitions from the parent RDD) should be kept on the same node, while narrow dependencies (one child partition per parent RDD) can go over the network. Spark does hash partitioning to shuffle, and tries by the modulo of the number of partitions that it is somewhat uniformly distributed. Basically you should model your computation tree in order to best organize the data for good distribution and maximal local computation, otherwise you flood you network which slows down your completion-time. If you have 8 compute node with 4 cores each, then the node number will not change. The key to think about is the cores, but you have to determine to resource-allocate properly. The following can be helpful:. http://site.clairvoyantsoft.com/understanding-resource-allocation-configurations-spark-application/. Regarding task information, you get the duration here:. https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.scheduler.TaskInfo@finishTime:Long. You can control the policy with the application as noted here:. https://spark.apache.org/docs/latest/job-scheduling.html#scheduling-within-an-application. You can control the assignment by creating pools with a `minShare` of cpu cores guaranteed for that pool. If you have one pool, then that can control it all - especially in FIFO mode - but that would not be efficient use of a Spark cluster. Spark has many moving parts, including how you structure your data and how to chose to process it (batch vs. stream). To properly perform this you have to analyze carefully the design of your computational DAG, and how your work should be processed given the resources. To me 200 partitions does not quite feel right, but if you think that is optimal for your design that's fine. Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:1671,integrability,batch,batch,1671,"@A-Tsai So now you're getting into determining your lineage graph of computations, which requires a lot of thought on how you set up your data and computational steps. Wide dependencies (multiple child partitions from the parent RDD) should be kept on the same node, while narrow dependencies (one child partition per parent RDD) can go over the network. Spark does hash partitioning to shuffle, and tries by the modulo of the number of partitions that it is somewhat uniformly distributed. Basically you should model your computation tree in order to best organize the data for good distribution and maximal local computation, otherwise you flood you network which slows down your completion-time. If you have 8 compute node with 4 cores each, then the node number will not change. The key to think about is the cores, but you have to determine to resource-allocate properly. The following can be helpful:. http://site.clairvoyantsoft.com/understanding-resource-allocation-configurations-spark-application/. Regarding task information, you get the duration here:. https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.scheduler.TaskInfo@finishTime:Long. You can control the policy with the application as noted here:. https://spark.apache.org/docs/latest/job-scheduling.html#scheduling-within-an-application. You can control the assignment by creating pools with a `minShare` of cpu cores guaranteed for that pool. If you have one pool, then that can control it all - especially in FIFO mode - but that would not be efficient use of a Spark cluster. Spark has many moving parts, including how you structure your data and how to chose to process it (batch vs. stream). To properly perform this you have to analyze carefully the design of your computational DAG, and how your work should be processed given the resources. To me 200 partitions does not quite feel right, but if you think that is optimal for your design that's fine. Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:478,interoperability,distribut,distributed,478,"@A-Tsai So now you're getting into determining your lineage graph of computations, which requires a lot of thought on how you set up your data and computational steps. Wide dependencies (multiple child partitions from the parent RDD) should be kept on the same node, while narrow dependencies (one child partition per parent RDD) can go over the network. Spark does hash partitioning to shuffle, and tries by the modulo of the number of partitions that it is somewhat uniformly distributed. Basically you should model your computation tree in order to best organize the data for good distribution and maximal local computation, otherwise you flood you network which slows down your completion-time. If you have 8 compute node with 4 cores each, then the node number will not change. The key to think about is the cores, but you have to determine to resource-allocate properly. The following can be helpful:. http://site.clairvoyantsoft.com/understanding-resource-allocation-configurations-spark-application/. Regarding task information, you get the duration here:. https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.scheduler.TaskInfo@finishTime:Long. You can control the policy with the application as noted here:. https://spark.apache.org/docs/latest/job-scheduling.html#scheduling-within-an-application. You can control the assignment by creating pools with a `minShare` of cpu cores guaranteed for that pool. If you have one pool, then that can control it all - especially in FIFO mode - but that would not be efficient use of a Spark cluster. Spark has many moving parts, including how you structure your data and how to chose to process it (batch vs. stream). To properly perform this you have to analyze carefully the design of your computational DAG, and how your work should be processed given the resources. To me 200 partitions does not quite feel right, but if you think that is optimal for your design that's fine. Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:584,interoperability,distribut,distribution,584,"@A-Tsai So now you're getting into determining your lineage graph of computations, which requires a lot of thought on how you set up your data and computational steps. Wide dependencies (multiple child partitions from the parent RDD) should be kept on the same node, while narrow dependencies (one child partition per parent RDD) can go over the network. Spark does hash partitioning to shuffle, and tries by the modulo of the number of partitions that it is somewhat uniformly distributed. Basically you should model your computation tree in order to best organize the data for good distribution and maximal local computation, otherwise you flood you network which slows down your completion-time. If you have 8 compute node with 4 cores each, then the node number will not change. The key to think about is the cores, but you have to determine to resource-allocate properly. The following can be helpful:. http://site.clairvoyantsoft.com/understanding-resource-allocation-configurations-spark-application/. Regarding task information, you get the duration here:. https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.scheduler.TaskInfo@finishTime:Long. You can control the policy with the application as noted here:. https://spark.apache.org/docs/latest/job-scheduling.html#scheduling-within-an-application. You can control the assignment by creating pools with a `minShare` of cpu cores guaranteed for that pool. If you have one pool, then that can control it all - especially in FIFO mode - but that would not be efficient use of a Spark cluster. Spark has many moving parts, including how you structure your data and how to chose to process it (batch vs. stream). To properly perform this you have to analyze carefully the design of your computational DAG, and how your work should be processed given the resources. To me 200 partitions does not quite feel right, but if you think that is optimal for your design that's fine. Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:1102,interoperability,api,api,1102,"@A-Tsai So now you're getting into determining your lineage graph of computations, which requires a lot of thought on how you set up your data and computational steps. Wide dependencies (multiple child partitions from the parent RDD) should be kept on the same node, while narrow dependencies (one child partition per parent RDD) can go over the network. Spark does hash partitioning to shuffle, and tries by the modulo of the number of partitions that it is somewhat uniformly distributed. Basically you should model your computation tree in order to best organize the data for good distribution and maximal local computation, otherwise you flood you network which slows down your completion-time. If you have 8 compute node with 4 cores each, then the node number will not change. The key to think about is the cores, but you have to determine to resource-allocate properly. The following can be helpful:. http://site.clairvoyantsoft.com/understanding-resource-allocation-configurations-spark-application/. Regarding task information, you get the duration here:. https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.scheduler.TaskInfo@finishTime:Long. You can control the policy with the application as noted here:. https://spark.apache.org/docs/latest/job-scheduling.html#scheduling-within-an-application. You can control the assignment by creating pools with a `minShare` of cpu cores guaranteed for that pool. If you have one pool, then that can control it all - especially in FIFO mode - but that would not be efficient use of a Spark cluster. Spark has many moving parts, including how you structure your data and how to chose to process it (batch vs. stream). To properly perform this you have to analyze carefully the design of your computational DAG, and how your work should be processed given the resources. To me 200 partitions does not quite feel right, but if you think that is optimal for your design that's fine. Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:173,modifiability,depend,dependencies,173,"@A-Tsai So now you're getting into determining your lineage graph of computations, which requires a lot of thought on how you set up your data and computational steps. Wide dependencies (multiple child partitions from the parent RDD) should be kept on the same node, while narrow dependencies (one child partition per parent RDD) can go over the network. Spark does hash partitioning to shuffle, and tries by the modulo of the number of partitions that it is somewhat uniformly distributed. Basically you should model your computation tree in order to best organize the data for good distribution and maximal local computation, otherwise you flood you network which slows down your completion-time. If you have 8 compute node with 4 cores each, then the node number will not change. The key to think about is the cores, but you have to determine to resource-allocate properly. The following can be helpful:. http://site.clairvoyantsoft.com/understanding-resource-allocation-configurations-spark-application/. Regarding task information, you get the duration here:. https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.scheduler.TaskInfo@finishTime:Long. You can control the policy with the application as noted here:. https://spark.apache.org/docs/latest/job-scheduling.html#scheduling-within-an-application. You can control the assignment by creating pools with a `minShare` of cpu cores guaranteed for that pool. If you have one pool, then that can control it all - especially in FIFO mode - but that would not be efficient use of a Spark cluster. Spark has many moving parts, including how you structure your data and how to chose to process it (batch vs. stream). To properly perform this you have to analyze carefully the design of your computational DAG, and how your work should be processed given the resources. To me 200 partitions does not quite feel right, but if you think that is optimal for your design that's fine. Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:280,modifiability,depend,dependencies,280,"@A-Tsai So now you're getting into determining your lineage graph of computations, which requires a lot of thought on how you set up your data and computational steps. Wide dependencies (multiple child partitions from the parent RDD) should be kept on the same node, while narrow dependencies (one child partition per parent RDD) can go over the network. Spark does hash partitioning to shuffle, and tries by the modulo of the number of partitions that it is somewhat uniformly distributed. Basically you should model your computation tree in order to best organize the data for good distribution and maximal local computation, otherwise you flood you network which slows down your completion-time. If you have 8 compute node with 4 cores each, then the node number will not change. The key to think about is the cores, but you have to determine to resource-allocate properly. The following can be helpful:. http://site.clairvoyantsoft.com/understanding-resource-allocation-configurations-spark-application/. Regarding task information, you get the duration here:. https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.scheduler.TaskInfo@finishTime:Long. You can control the policy with the application as noted here:. https://spark.apache.org/docs/latest/job-scheduling.html#scheduling-within-an-application. You can control the assignment by creating pools with a `minShare` of cpu cores guaranteed for that pool. If you have one pool, then that can control it all - especially in FIFO mode - but that would not be efficient use of a Spark cluster. Spark has many moving parts, including how you structure your data and how to chose to process it (batch vs. stream). To properly perform this you have to analyze carefully the design of your computational DAG, and how your work should be processed given the resources. To me 200 partitions does not quite feel right, but if you think that is optimal for your design that's fine. Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:413,modifiability,modul,modulo,413,"@A-Tsai So now you're getting into determining your lineage graph of computations, which requires a lot of thought on how you set up your data and computational steps. Wide dependencies (multiple child partitions from the parent RDD) should be kept on the same node, while narrow dependencies (one child partition per parent RDD) can go over the network. Spark does hash partitioning to shuffle, and tries by the modulo of the number of partitions that it is somewhat uniformly distributed. Basically you should model your computation tree in order to best organize the data for good distribution and maximal local computation, otherwise you flood you network which slows down your completion-time. If you have 8 compute node with 4 cores each, then the node number will not change. The key to think about is the cores, but you have to determine to resource-allocate properly. The following can be helpful:. http://site.clairvoyantsoft.com/understanding-resource-allocation-configurations-spark-application/. Regarding task information, you get the duration here:. https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.scheduler.TaskInfo@finishTime:Long. You can control the policy with the application as noted here:. https://spark.apache.org/docs/latest/job-scheduling.html#scheduling-within-an-application. You can control the assignment by creating pools with a `minShare` of cpu cores guaranteed for that pool. If you have one pool, then that can control it all - especially in FIFO mode - but that would not be efficient use of a Spark cluster. Spark has many moving parts, including how you structure your data and how to chose to process it (batch vs. stream). To properly perform this you have to analyze carefully the design of your computational DAG, and how your work should be processed given the resources. To me 200 partitions does not quite feel right, but if you think that is optimal for your design that's fine. Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:974,modifiability,configur,configurations-spark-application,974,"@A-Tsai So now you're getting into determining your lineage graph of computations, which requires a lot of thought on how you set up your data and computational steps. Wide dependencies (multiple child partitions from the parent RDD) should be kept on the same node, while narrow dependencies (one child partition per parent RDD) can go over the network. Spark does hash partitioning to shuffle, and tries by the modulo of the number of partitions that it is somewhat uniformly distributed. Basically you should model your computation tree in order to best organize the data for good distribution and maximal local computation, otherwise you flood you network which slows down your completion-time. If you have 8 compute node with 4 cores each, then the node number will not change. The key to think about is the cores, but you have to determine to resource-allocate properly. The following can be helpful:. http://site.clairvoyantsoft.com/understanding-resource-allocation-configurations-spark-application/. Regarding task information, you get the duration here:. https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.scheduler.TaskInfo@finishTime:Long. You can control the policy with the application as noted here:. https://spark.apache.org/docs/latest/job-scheduling.html#scheduling-within-an-application. You can control the assignment by creating pools with a `minShare` of cpu cores guaranteed for that pool. If you have one pool, then that can control it all - especially in FIFO mode - but that would not be efficient use of a Spark cluster. Spark has many moving parts, including how you structure your data and how to chose to process it (batch vs. stream). To properly perform this you have to analyze carefully the design of your computational DAG, and how your work should be processed given the resources. To me 200 partitions does not quite feel right, but if you think that is optimal for your design that's fine. Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:1106,modifiability,scal,scala,1106,"@A-Tsai So now you're getting into determining your lineage graph of computations, which requires a lot of thought on how you set up your data and computational steps. Wide dependencies (multiple child partitions from the parent RDD) should be kept on the same node, while narrow dependencies (one child partition per parent RDD) can go over the network. Spark does hash partitioning to shuffle, and tries by the modulo of the number of partitions that it is somewhat uniformly distributed. Basically you should model your computation tree in order to best organize the data for good distribution and maximal local computation, otherwise you flood you network which slows down your completion-time. If you have 8 compute node with 4 cores each, then the node number will not change. The key to think about is the cores, but you have to determine to resource-allocate properly. The following can be helpful:. http://site.clairvoyantsoft.com/understanding-resource-allocation-configurations-spark-application/. Regarding task information, you get the duration here:. https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.scheduler.TaskInfo@finishTime:Long. You can control the policy with the application as noted here:. https://spark.apache.org/docs/latest/job-scheduling.html#scheduling-within-an-application. You can control the assignment by creating pools with a `minShare` of cpu cores guaranteed for that pool. If you have one pool, then that can control it all - especially in FIFO mode - but that would not be efficient use of a Spark cluster. Spark has many moving parts, including how you structure your data and how to chose to process it (batch vs. stream). To properly perform this you have to analyze carefully the design of your computational DAG, and how your work should be processed given the resources. To me 200 partitions does not quite feel right, but if you think that is optimal for your design that's fine. Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:346,performance,network,network,346,"@A-Tsai So now you're getting into determining your lineage graph of computations, which requires a lot of thought on how you set up your data and computational steps. Wide dependencies (multiple child partitions from the parent RDD) should be kept on the same node, while narrow dependencies (one child partition per parent RDD) can go over the network. Spark does hash partitioning to shuffle, and tries by the modulo of the number of partitions that it is somewhat uniformly distributed. Basically you should model your computation tree in order to best organize the data for good distribution and maximal local computation, otherwise you flood you network which slows down your completion-time. If you have 8 compute node with 4 cores each, then the node number will not change. The key to think about is the cores, but you have to determine to resource-allocate properly. The following can be helpful:. http://site.clairvoyantsoft.com/understanding-resource-allocation-configurations-spark-application/. Regarding task information, you get the duration here:. https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.scheduler.TaskInfo@finishTime:Long. You can control the policy with the application as noted here:. https://spark.apache.org/docs/latest/job-scheduling.html#scheduling-within-an-application. You can control the assignment by creating pools with a `minShare` of cpu cores guaranteed for that pool. If you have one pool, then that can control it all - especially in FIFO mode - but that would not be efficient use of a Spark cluster. Spark has many moving parts, including how you structure your data and how to chose to process it (batch vs. stream). To properly perform this you have to analyze carefully the design of your computational DAG, and how your work should be processed given the resources. To me 200 partitions does not quite feel right, but if you think that is optimal for your design that's fine. Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:652,performance,network,network,652,"@A-Tsai So now you're getting into determining your lineage graph of computations, which requires a lot of thought on how you set up your data and computational steps. Wide dependencies (multiple child partitions from the parent RDD) should be kept on the same node, while narrow dependencies (one child partition per parent RDD) can go over the network. Spark does hash partitioning to shuffle, and tries by the modulo of the number of partitions that it is somewhat uniformly distributed. Basically you should model your computation tree in order to best organize the data for good distribution and maximal local computation, otherwise you flood you network which slows down your completion-time. If you have 8 compute node with 4 cores each, then the node number will not change. The key to think about is the cores, but you have to determine to resource-allocate properly. The following can be helpful:. http://site.clairvoyantsoft.com/understanding-resource-allocation-configurations-spark-application/. Regarding task information, you get the duration here:. https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.scheduler.TaskInfo@finishTime:Long. You can control the policy with the application as noted here:. https://spark.apache.org/docs/latest/job-scheduling.html#scheduling-within-an-application. You can control the assignment by creating pools with a `minShare` of cpu cores guaranteed for that pool. If you have one pool, then that can control it all - especially in FIFO mode - but that would not be efficient use of a Spark cluster. Spark has many moving parts, including how you structure your data and how to chose to process it (batch vs. stream). To properly perform this you have to analyze carefully the design of your computational DAG, and how your work should be processed given the resources. To me 200 partitions does not quite feel right, but if you think that is optimal for your design that's fine. Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:693,performance,time,time,693,"@A-Tsai So now you're getting into determining your lineage graph of computations, which requires a lot of thought on how you set up your data and computational steps. Wide dependencies (multiple child partitions from the parent RDD) should be kept on the same node, while narrow dependencies (one child partition per parent RDD) can go over the network. Spark does hash partitioning to shuffle, and tries by the modulo of the number of partitions that it is somewhat uniformly distributed. Basically you should model your computation tree in order to best organize the data for good distribution and maximal local computation, otherwise you flood you network which slows down your completion-time. If you have 8 compute node with 4 cores each, then the node number will not change. The key to think about is the cores, but you have to determine to resource-allocate properly. The following can be helpful:. http://site.clairvoyantsoft.com/understanding-resource-allocation-configurations-spark-application/. Regarding task information, you get the duration here:. https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.scheduler.TaskInfo@finishTime:Long. You can control the policy with the application as noted here:. https://spark.apache.org/docs/latest/job-scheduling.html#scheduling-within-an-application. You can control the assignment by creating pools with a `minShare` of cpu cores guaranteed for that pool. If you have one pool, then that can control it all - especially in FIFO mode - but that would not be efficient use of a Spark cluster. Spark has many moving parts, including how you structure your data and how to chose to process it (batch vs. stream). To properly perform this you have to analyze carefully the design of your computational DAG, and how your work should be processed given the resources. To me 200 partitions does not quite feel right, but if you think that is optimal for your design that's fine. Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:849,performance,resourc,resource-allocate,849,"@A-Tsai So now you're getting into determining your lineage graph of computations, which requires a lot of thought on how you set up your data and computational steps. Wide dependencies (multiple child partitions from the parent RDD) should be kept on the same node, while narrow dependencies (one child partition per parent RDD) can go over the network. Spark does hash partitioning to shuffle, and tries by the modulo of the number of partitions that it is somewhat uniformly distributed. Basically you should model your computation tree in order to best organize the data for good distribution and maximal local computation, otherwise you flood you network which slows down your completion-time. If you have 8 compute node with 4 cores each, then the node number will not change. The key to think about is the cores, but you have to determine to resource-allocate properly. The following can be helpful:. http://site.clairvoyantsoft.com/understanding-resource-allocation-configurations-spark-application/. Regarding task information, you get the duration here:. https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.scheduler.TaskInfo@finishTime:Long. You can control the policy with the application as noted here:. https://spark.apache.org/docs/latest/job-scheduling.html#scheduling-within-an-application. You can control the assignment by creating pools with a `minShare` of cpu cores guaranteed for that pool. If you have one pool, then that can control it all - especially in FIFO mode - but that would not be efficient use of a Spark cluster. Spark has many moving parts, including how you structure your data and how to chose to process it (batch vs. stream). To properly perform this you have to analyze carefully the design of your computational DAG, and how your work should be processed given the resources. To me 200 partitions does not quite feel right, but if you think that is optimal for your design that's fine. Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:954,performance,resourc,resource-allocation-configurations-spark-application,954,"@A-Tsai So now you're getting into determining your lineage graph of computations, which requires a lot of thought on how you set up your data and computational steps. Wide dependencies (multiple child partitions from the parent RDD) should be kept on the same node, while narrow dependencies (one child partition per parent RDD) can go over the network. Spark does hash partitioning to shuffle, and tries by the modulo of the number of partitions that it is somewhat uniformly distributed. Basically you should model your computation tree in order to best organize the data for good distribution and maximal local computation, otherwise you flood you network which slows down your completion-time. If you have 8 compute node with 4 cores each, then the node number will not change. The key to think about is the cores, but you have to determine to resource-allocate properly. The following can be helpful:. http://site.clairvoyantsoft.com/understanding-resource-allocation-configurations-spark-application/. Regarding task information, you get the duration here:. https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.scheduler.TaskInfo@finishTime:Long. You can control the policy with the application as noted here:. https://spark.apache.org/docs/latest/job-scheduling.html#scheduling-within-an-application. You can control the assignment by creating pools with a `minShare` of cpu cores guaranteed for that pool. If you have one pool, then that can control it all - especially in FIFO mode - but that would not be efficient use of a Spark cluster. Spark has many moving parts, including how you structure your data and how to chose to process it (batch vs. stream). To properly perform this you have to analyze carefully the design of your computational DAG, and how your work should be processed given the resources. To me 200 partitions does not quite feel right, but if you think that is optimal for your design that's fine. Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:1140,performance,schedul,scheduler,1140,"@A-Tsai So now you're getting into determining your lineage graph of computations, which requires a lot of thought on how you set up your data and computational steps. Wide dependencies (multiple child partitions from the parent RDD) should be kept on the same node, while narrow dependencies (one child partition per parent RDD) can go over the network. Spark does hash partitioning to shuffle, and tries by the modulo of the number of partitions that it is somewhat uniformly distributed. Basically you should model your computation tree in order to best organize the data for good distribution and maximal local computation, otherwise you flood you network which slows down your completion-time. If you have 8 compute node with 4 cores each, then the node number will not change. The key to think about is the cores, but you have to determine to resource-allocate properly. The following can be helpful:. http://site.clairvoyantsoft.com/understanding-resource-allocation-configurations-spark-application/. Regarding task information, you get the duration here:. https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.scheduler.TaskInfo@finishTime:Long. You can control the policy with the application as noted here:. https://spark.apache.org/docs/latest/job-scheduling.html#scheduling-within-an-application. You can control the assignment by creating pools with a `minShare` of cpu cores guaranteed for that pool. If you have one pool, then that can control it all - especially in FIFO mode - but that would not be efficient use of a Spark cluster. Spark has many moving parts, including how you structure your data and how to chose to process it (batch vs. stream). To properly perform this you have to analyze carefully the design of your computational DAG, and how your work should be processed given the resources. To me 200 partitions does not quite feel right, but if you think that is optimal for your design that's fine. Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:1281,performance,schedul,scheduling,1281,"@A-Tsai So now you're getting into determining your lineage graph of computations, which requires a lot of thought on how you set up your data and computational steps. Wide dependencies (multiple child partitions from the parent RDD) should be kept on the same node, while narrow dependencies (one child partition per parent RDD) can go over the network. Spark does hash partitioning to shuffle, and tries by the modulo of the number of partitions that it is somewhat uniformly distributed. Basically you should model your computation tree in order to best organize the data for good distribution and maximal local computation, otherwise you flood you network which slows down your completion-time. If you have 8 compute node with 4 cores each, then the node number will not change. The key to think about is the cores, but you have to determine to resource-allocate properly. The following can be helpful:. http://site.clairvoyantsoft.com/understanding-resource-allocation-configurations-spark-application/. Regarding task information, you get the duration here:. https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.scheduler.TaskInfo@finishTime:Long. You can control the policy with the application as noted here:. https://spark.apache.org/docs/latest/job-scheduling.html#scheduling-within-an-application. You can control the assignment by creating pools with a `minShare` of cpu cores guaranteed for that pool. If you have one pool, then that can control it all - especially in FIFO mode - but that would not be efficient use of a Spark cluster. Spark has many moving parts, including how you structure your data and how to chose to process it (batch vs. stream). To properly perform this you have to analyze carefully the design of your computational DAG, and how your work should be processed given the resources. To me 200 partitions does not quite feel right, but if you think that is optimal for your design that's fine. Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:1297,performance,schedul,scheduling-within-an-application,1297,"@A-Tsai So now you're getting into determining your lineage graph of computations, which requires a lot of thought on how you set up your data and computational steps. Wide dependencies (multiple child partitions from the parent RDD) should be kept on the same node, while narrow dependencies (one child partition per parent RDD) can go over the network. Spark does hash partitioning to shuffle, and tries by the modulo of the number of partitions that it is somewhat uniformly distributed. Basically you should model your computation tree in order to best organize the data for good distribution and maximal local computation, otherwise you flood you network which slows down your completion-time. If you have 8 compute node with 4 cores each, then the node number will not change. The key to think about is the cores, but you have to determine to resource-allocate properly. The following can be helpful:. http://site.clairvoyantsoft.com/understanding-resource-allocation-configurations-spark-application/. Regarding task information, you get the duration here:. https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.scheduler.TaskInfo@finishTime:Long. You can control the policy with the application as noted here:. https://spark.apache.org/docs/latest/job-scheduling.html#scheduling-within-an-application. You can control the assignment by creating pools with a `minShare` of cpu cores guaranteed for that pool. If you have one pool, then that can control it all - especially in FIFO mode - but that would not be efficient use of a Spark cluster. Spark has many moving parts, including how you structure your data and how to chose to process it (batch vs. stream). To properly perform this you have to analyze carefully the design of your computational DAG, and how your work should be processed given the resources. To me 200 partitions does not quite feel right, but if you think that is optimal for your design that's fine. Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:1401,performance,cpu,cpu,1401,"@A-Tsai So now you're getting into determining your lineage graph of computations, which requires a lot of thought on how you set up your data and computational steps. Wide dependencies (multiple child partitions from the parent RDD) should be kept on the same node, while narrow dependencies (one child partition per parent RDD) can go over the network. Spark does hash partitioning to shuffle, and tries by the modulo of the number of partitions that it is somewhat uniformly distributed. Basically you should model your computation tree in order to best organize the data for good distribution and maximal local computation, otherwise you flood you network which slows down your completion-time. If you have 8 compute node with 4 cores each, then the node number will not change. The key to think about is the cores, but you have to determine to resource-allocate properly. The following can be helpful:. http://site.clairvoyantsoft.com/understanding-resource-allocation-configurations-spark-application/. Regarding task information, you get the duration here:. https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.scheduler.TaskInfo@finishTime:Long. You can control the policy with the application as noted here:. https://spark.apache.org/docs/latest/job-scheduling.html#scheduling-within-an-application. You can control the assignment by creating pools with a `minShare` of cpu cores guaranteed for that pool. If you have one pool, then that can control it all - especially in FIFO mode - but that would not be efficient use of a Spark cluster. Spark has many moving parts, including how you structure your data and how to chose to process it (batch vs. stream). To properly perform this you have to analyze carefully the design of your computational DAG, and how your work should be processed given the resources. To me 200 partitions does not quite feel right, but if you think that is optimal for your design that's fine. Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:1671,performance,batch,batch,1671,"@A-Tsai So now you're getting into determining your lineage graph of computations, which requires a lot of thought on how you set up your data and computational steps. Wide dependencies (multiple child partitions from the parent RDD) should be kept on the same node, while narrow dependencies (one child partition per parent RDD) can go over the network. Spark does hash partitioning to shuffle, and tries by the modulo of the number of partitions that it is somewhat uniformly distributed. Basically you should model your computation tree in order to best organize the data for good distribution and maximal local computation, otherwise you flood you network which slows down your completion-time. If you have 8 compute node with 4 cores each, then the node number will not change. The key to think about is the cores, but you have to determine to resource-allocate properly. The following can be helpful:. http://site.clairvoyantsoft.com/understanding-resource-allocation-configurations-spark-application/. Regarding task information, you get the duration here:. https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.scheduler.TaskInfo@finishTime:Long. You can control the policy with the application as noted here:. https://spark.apache.org/docs/latest/job-scheduling.html#scheduling-within-an-application. You can control the assignment by creating pools with a `minShare` of cpu cores guaranteed for that pool. If you have one pool, then that can control it all - especially in FIFO mode - but that would not be efficient use of a Spark cluster. Spark has many moving parts, including how you structure your data and how to chose to process it (batch vs. stream). To properly perform this you have to analyze carefully the design of your computational DAG, and how your work should be processed given the resources. To me 200 partitions does not quite feel right, but if you think that is optimal for your design that's fine. Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:1702,performance,perform,perform,1702,"@A-Tsai So now you're getting into determining your lineage graph of computations, which requires a lot of thought on how you set up your data and computational steps. Wide dependencies (multiple child partitions from the parent RDD) should be kept on the same node, while narrow dependencies (one child partition per parent RDD) can go over the network. Spark does hash partitioning to shuffle, and tries by the modulo of the number of partitions that it is somewhat uniformly distributed. Basically you should model your computation tree in order to best organize the data for good distribution and maximal local computation, otherwise you flood you network which slows down your completion-time. If you have 8 compute node with 4 cores each, then the node number will not change. The key to think about is the cores, but you have to determine to resource-allocate properly. The following can be helpful:. http://site.clairvoyantsoft.com/understanding-resource-allocation-configurations-spark-application/. Regarding task information, you get the duration here:. https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.scheduler.TaskInfo@finishTime:Long. You can control the policy with the application as noted here:. https://spark.apache.org/docs/latest/job-scheduling.html#scheduling-within-an-application. You can control the assignment by creating pools with a `minShare` of cpu cores guaranteed for that pool. If you have one pool, then that can control it all - especially in FIFO mode - but that would not be efficient use of a Spark cluster. Spark has many moving parts, including how you structure your data and how to chose to process it (batch vs. stream). To properly perform this you have to analyze carefully the design of your computational DAG, and how your work should be processed given the resources. To me 200 partitions does not quite feel right, but if you think that is optimal for your design that's fine. Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:1831,performance,resourc,resources,1831,"@A-Tsai So now you're getting into determining your lineage graph of computations, which requires a lot of thought on how you set up your data and computational steps. Wide dependencies (multiple child partitions from the parent RDD) should be kept on the same node, while narrow dependencies (one child partition per parent RDD) can go over the network. Spark does hash partitioning to shuffle, and tries by the modulo of the number of partitions that it is somewhat uniformly distributed. Basically you should model your computation tree in order to best organize the data for good distribution and maximal local computation, otherwise you flood you network which slows down your completion-time. If you have 8 compute node with 4 cores each, then the node number will not change. The key to think about is the cores, but you have to determine to resource-allocate properly. The following can be helpful:. http://site.clairvoyantsoft.com/understanding-resource-allocation-configurations-spark-application/. Regarding task information, you get the duration here:. https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.scheduler.TaskInfo@finishTime:Long. You can control the policy with the application as noted here:. https://spark.apache.org/docs/latest/job-scheduling.html#scheduling-within-an-application. You can control the assignment by creating pools with a `minShare` of cpu cores guaranteed for that pool. If you have one pool, then that can control it all - especially in FIFO mode - but that would not be efficient use of a Spark cluster. Spark has many moving parts, including how you structure your data and how to chose to process it (batch vs. stream). To properly perform this you have to analyze carefully the design of your computational DAG, and how your work should be processed given the resources. To me 200 partitions does not quite feel right, but if you think that is optimal for your design that's fine. Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:361,reliability,doe,does,361,"@A-Tsai So now you're getting into determining your lineage graph of computations, which requires a lot of thought on how you set up your data and computational steps. Wide dependencies (multiple child partitions from the parent RDD) should be kept on the same node, while narrow dependencies (one child partition per parent RDD) can go over the network. Spark does hash partitioning to shuffle, and tries by the modulo of the number of partitions that it is somewhat uniformly distributed. Basically you should model your computation tree in order to best organize the data for good distribution and maximal local computation, otherwise you flood you network which slows down your completion-time. If you have 8 compute node with 4 cores each, then the node number will not change. The key to think about is the cores, but you have to determine to resource-allocate properly. The following can be helpful:. http://site.clairvoyantsoft.com/understanding-resource-allocation-configurations-spark-application/. Regarding task information, you get the duration here:. https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.scheduler.TaskInfo@finishTime:Long. You can control the policy with the application as noted here:. https://spark.apache.org/docs/latest/job-scheduling.html#scheduling-within-an-application. You can control the assignment by creating pools with a `minShare` of cpu cores guaranteed for that pool. If you have one pool, then that can control it all - especially in FIFO mode - but that would not be efficient use of a Spark cluster. Spark has many moving parts, including how you structure your data and how to chose to process it (batch vs. stream). To properly perform this you have to analyze carefully the design of your computational DAG, and how your work should be processed given the resources. To me 200 partitions does not quite feel right, but if you think that is optimal for your design that's fine. Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:666,reliability,slo,slows,666,"@A-Tsai So now you're getting into determining your lineage graph of computations, which requires a lot of thought on how you set up your data and computational steps. Wide dependencies (multiple child partitions from the parent RDD) should be kept on the same node, while narrow dependencies (one child partition per parent RDD) can go over the network. Spark does hash partitioning to shuffle, and tries by the modulo of the number of partitions that it is somewhat uniformly distributed. Basically you should model your computation tree in order to best organize the data for good distribution and maximal local computation, otherwise you flood you network which slows down your completion-time. If you have 8 compute node with 4 cores each, then the node number will not change. The key to think about is the cores, but you have to determine to resource-allocate properly. The following can be helpful:. http://site.clairvoyantsoft.com/understanding-resource-allocation-configurations-spark-application/. Regarding task information, you get the duration here:. https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.scheduler.TaskInfo@finishTime:Long. You can control the policy with the application as noted here:. https://spark.apache.org/docs/latest/job-scheduling.html#scheduling-within-an-application. You can control the assignment by creating pools with a `minShare` of cpu cores guaranteed for that pool. If you have one pool, then that can control it all - especially in FIFO mode - but that would not be efficient use of a Spark cluster. Spark has many moving parts, including how you structure your data and how to chose to process it (batch vs. stream). To properly perform this you have to analyze carefully the design of your computational DAG, and how your work should be processed given the resources. To me 200 partitions does not quite feel right, but if you think that is optimal for your design that's fine. Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:1863,reliability,doe,does,1863,"@A-Tsai So now you're getting into determining your lineage graph of computations, which requires a lot of thought on how you set up your data and computational steps. Wide dependencies (multiple child partitions from the parent RDD) should be kept on the same node, while narrow dependencies (one child partition per parent RDD) can go over the network. Spark does hash partitioning to shuffle, and tries by the modulo of the number of partitions that it is somewhat uniformly distributed. Basically you should model your computation tree in order to best organize the data for good distribution and maximal local computation, otherwise you flood you network which slows down your completion-time. If you have 8 compute node with 4 cores each, then the node number will not change. The key to think about is the cores, but you have to determine to resource-allocate properly. The following can be helpful:. http://site.clairvoyantsoft.com/understanding-resource-allocation-configurations-spark-application/. Regarding task information, you get the duration here:. https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.scheduler.TaskInfo@finishTime:Long. You can control the policy with the application as noted here:. https://spark.apache.org/docs/latest/job-scheduling.html#scheduling-within-an-application. You can control the assignment by creating pools with a `minShare` of cpu cores guaranteed for that pool. If you have one pool, then that can control it all - especially in FIFO mode - but that would not be efficient use of a Spark cluster. Spark has many moving parts, including how you structure your data and how to chose to process it (batch vs. stream). To properly perform this you have to analyze carefully the design of your computational DAG, and how your work should be processed given the resources. To me 200 partitions does not quite feel right, but if you think that is optimal for your design that's fine. Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:173,safety,depend,dependencies,173,"@A-Tsai So now you're getting into determining your lineage graph of computations, which requires a lot of thought on how you set up your data and computational steps. Wide dependencies (multiple child partitions from the parent RDD) should be kept on the same node, while narrow dependencies (one child partition per parent RDD) can go over the network. Spark does hash partitioning to shuffle, and tries by the modulo of the number of partitions that it is somewhat uniformly distributed. Basically you should model your computation tree in order to best organize the data for good distribution and maximal local computation, otherwise you flood you network which slows down your completion-time. If you have 8 compute node with 4 cores each, then the node number will not change. The key to think about is the cores, but you have to determine to resource-allocate properly. The following can be helpful:. http://site.clairvoyantsoft.com/understanding-resource-allocation-configurations-spark-application/. Regarding task information, you get the duration here:. https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.scheduler.TaskInfo@finishTime:Long. You can control the policy with the application as noted here:. https://spark.apache.org/docs/latest/job-scheduling.html#scheduling-within-an-application. You can control the assignment by creating pools with a `minShare` of cpu cores guaranteed for that pool. If you have one pool, then that can control it all - especially in FIFO mode - but that would not be efficient use of a Spark cluster. Spark has many moving parts, including how you structure your data and how to chose to process it (batch vs. stream). To properly perform this you have to analyze carefully the design of your computational DAG, and how your work should be processed given the resources. To me 200 partitions does not quite feel right, but if you think that is optimal for your design that's fine. Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:280,safety,depend,dependencies,280,"@A-Tsai So now you're getting into determining your lineage graph of computations, which requires a lot of thought on how you set up your data and computational steps. Wide dependencies (multiple child partitions from the parent RDD) should be kept on the same node, while narrow dependencies (one child partition per parent RDD) can go over the network. Spark does hash partitioning to shuffle, and tries by the modulo of the number of partitions that it is somewhat uniformly distributed. Basically you should model your computation tree in order to best organize the data for good distribution and maximal local computation, otherwise you flood you network which slows down your completion-time. If you have 8 compute node with 4 cores each, then the node number will not change. The key to think about is the cores, but you have to determine to resource-allocate properly. The following can be helpful:. http://site.clairvoyantsoft.com/understanding-resource-allocation-configurations-spark-application/. Regarding task information, you get the duration here:. https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.scheduler.TaskInfo@finishTime:Long. You can control the policy with the application as noted here:. https://spark.apache.org/docs/latest/job-scheduling.html#scheduling-within-an-application. You can control the assignment by creating pools with a `minShare` of cpu cores guaranteed for that pool. If you have one pool, then that can control it all - especially in FIFO mode - but that would not be efficient use of a Spark cluster. Spark has many moving parts, including how you structure your data and how to chose to process it (batch vs. stream). To properly perform this you have to analyze carefully the design of your computational DAG, and how your work should be processed given the resources. To me 200 partitions does not quite feel right, but if you think that is optimal for your design that's fine. Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:413,safety,modul,modulo,413,"@A-Tsai So now you're getting into determining your lineage graph of computations, which requires a lot of thought on how you set up your data and computational steps. Wide dependencies (multiple child partitions from the parent RDD) should be kept on the same node, while narrow dependencies (one child partition per parent RDD) can go over the network. Spark does hash partitioning to shuffle, and tries by the modulo of the number of partitions that it is somewhat uniformly distributed. Basically you should model your computation tree in order to best organize the data for good distribution and maximal local computation, otherwise you flood you network which slows down your completion-time. If you have 8 compute node with 4 cores each, then the node number will not change. The key to think about is the cores, but you have to determine to resource-allocate properly. The following can be helpful:. http://site.clairvoyantsoft.com/understanding-resource-allocation-configurations-spark-application/. Regarding task information, you get the duration here:. https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.scheduler.TaskInfo@finishTime:Long. You can control the policy with the application as noted here:. https://spark.apache.org/docs/latest/job-scheduling.html#scheduling-within-an-application. You can control the assignment by creating pools with a `minShare` of cpu cores guaranteed for that pool. If you have one pool, then that can control it all - especially in FIFO mode - but that would not be efficient use of a Spark cluster. Spark has many moving parts, including how you structure your data and how to chose to process it (batch vs. stream). To properly perform this you have to analyze carefully the design of your computational DAG, and how your work should be processed given the resources. To me 200 partitions does not quite feel right, but if you think that is optimal for your design that's fine. Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:682,safety,compl,completion-time,682,"@A-Tsai So now you're getting into determining your lineage graph of computations, which requires a lot of thought on how you set up your data and computational steps. Wide dependencies (multiple child partitions from the parent RDD) should be kept on the same node, while narrow dependencies (one child partition per parent RDD) can go over the network. Spark does hash partitioning to shuffle, and tries by the modulo of the number of partitions that it is somewhat uniformly distributed. Basically you should model your computation tree in order to best organize the data for good distribution and maximal local computation, otherwise you flood you network which slows down your completion-time. If you have 8 compute node with 4 cores each, then the node number will not change. The key to think about is the cores, but you have to determine to resource-allocate properly. The following can be helpful:. http://site.clairvoyantsoft.com/understanding-resource-allocation-configurations-spark-application/. Regarding task information, you get the duration here:. https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.scheduler.TaskInfo@finishTime:Long. You can control the policy with the application as noted here:. https://spark.apache.org/docs/latest/job-scheduling.html#scheduling-within-an-application. You can control the assignment by creating pools with a `minShare` of cpu cores guaranteed for that pool. If you have one pool, then that can control it all - especially in FIFO mode - but that would not be efficient use of a Spark cluster. Spark has many moving parts, including how you structure your data and how to chose to process it (batch vs. stream). To properly perform this you have to analyze carefully the design of your computational DAG, and how your work should be processed given the resources. To me 200 partitions does not quite feel right, but if you think that is optimal for your design that's fine. Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:849,safety,resourc,resource-allocate,849,"@A-Tsai So now you're getting into determining your lineage graph of computations, which requires a lot of thought on how you set up your data and computational steps. Wide dependencies (multiple child partitions from the parent RDD) should be kept on the same node, while narrow dependencies (one child partition per parent RDD) can go over the network. Spark does hash partitioning to shuffle, and tries by the modulo of the number of partitions that it is somewhat uniformly distributed. Basically you should model your computation tree in order to best organize the data for good distribution and maximal local computation, otherwise you flood you network which slows down your completion-time. If you have 8 compute node with 4 cores each, then the node number will not change. The key to think about is the cores, but you have to determine to resource-allocate properly. The following can be helpful:. http://site.clairvoyantsoft.com/understanding-resource-allocation-configurations-spark-application/. Regarding task information, you get the duration here:. https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.scheduler.TaskInfo@finishTime:Long. You can control the policy with the application as noted here:. https://spark.apache.org/docs/latest/job-scheduling.html#scheduling-within-an-application. You can control the assignment by creating pools with a `minShare` of cpu cores guaranteed for that pool. If you have one pool, then that can control it all - especially in FIFO mode - but that would not be efficient use of a Spark cluster. Spark has many moving parts, including how you structure your data and how to chose to process it (batch vs. stream). To properly perform this you have to analyze carefully the design of your computational DAG, and how your work should be processed given the resources. To me 200 partitions does not quite feel right, but if you think that is optimal for your design that's fine. Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:954,safety,resourc,resource-allocation-configurations-spark-application,954,"@A-Tsai So now you're getting into determining your lineage graph of computations, which requires a lot of thought on how you set up your data and computational steps. Wide dependencies (multiple child partitions from the parent RDD) should be kept on the same node, while narrow dependencies (one child partition per parent RDD) can go over the network. Spark does hash partitioning to shuffle, and tries by the modulo of the number of partitions that it is somewhat uniformly distributed. Basically you should model your computation tree in order to best organize the data for good distribution and maximal local computation, otherwise you flood you network which slows down your completion-time. If you have 8 compute node with 4 cores each, then the node number will not change. The key to think about is the cores, but you have to determine to resource-allocate properly. The following can be helpful:. http://site.clairvoyantsoft.com/understanding-resource-allocation-configurations-spark-application/. Regarding task information, you get the duration here:. https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.scheduler.TaskInfo@finishTime:Long. You can control the policy with the application as noted here:. https://spark.apache.org/docs/latest/job-scheduling.html#scheduling-within-an-application. You can control the assignment by creating pools with a `minShare` of cpu cores guaranteed for that pool. If you have one pool, then that can control it all - especially in FIFO mode - but that would not be efficient use of a Spark cluster. Spark has many moving parts, including how you structure your data and how to chose to process it (batch vs. stream). To properly perform this you have to analyze carefully the design of your computational DAG, and how your work should be processed given the resources. To me 200 partitions does not quite feel right, but if you think that is optimal for your design that's fine. Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:1831,safety,resourc,resources,1831,"@A-Tsai So now you're getting into determining your lineage graph of computations, which requires a lot of thought on how you set up your data and computational steps. Wide dependencies (multiple child partitions from the parent RDD) should be kept on the same node, while narrow dependencies (one child partition per parent RDD) can go over the network. Spark does hash partitioning to shuffle, and tries by the modulo of the number of partitions that it is somewhat uniformly distributed. Basically you should model your computation tree in order to best organize the data for good distribution and maximal local computation, otherwise you flood you network which slows down your completion-time. If you have 8 compute node with 4 cores each, then the node number will not change. The key to think about is the cores, but you have to determine to resource-allocate properly. The following can be helpful:. http://site.clairvoyantsoft.com/understanding-resource-allocation-configurations-spark-application/. Regarding task information, you get the duration here:. https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.scheduler.TaskInfo@finishTime:Long. You can control the policy with the application as noted here:. https://spark.apache.org/docs/latest/job-scheduling.html#scheduling-within-an-application. You can control the assignment by creating pools with a `minShare` of cpu cores guaranteed for that pool. If you have one pool, then that can control it all - especially in FIFO mode - but that would not be efficient use of a Spark cluster. Spark has many moving parts, including how you structure your data and how to chose to process it (batch vs. stream). To properly perform this you have to analyze carefully the design of your computational DAG, and how your work should be processed given the resources. To me 200 partitions does not quite feel right, but if you think that is optimal for your design that's fine. Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:52,security,lineag,lineage,52,"@A-Tsai So now you're getting into determining your lineage graph of computations, which requires a lot of thought on how you set up your data and computational steps. Wide dependencies (multiple child partitions from the parent RDD) should be kept on the same node, while narrow dependencies (one child partition per parent RDD) can go over the network. Spark does hash partitioning to shuffle, and tries by the modulo of the number of partitions that it is somewhat uniformly distributed. Basically you should model your computation tree in order to best organize the data for good distribution and maximal local computation, otherwise you flood you network which slows down your completion-time. If you have 8 compute node with 4 cores each, then the node number will not change. The key to think about is the cores, but you have to determine to resource-allocate properly. The following can be helpful:. http://site.clairvoyantsoft.com/understanding-resource-allocation-configurations-spark-application/. Regarding task information, you get the duration here:. https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.scheduler.TaskInfo@finishTime:Long. You can control the policy with the application as noted here:. https://spark.apache.org/docs/latest/job-scheduling.html#scheduling-within-an-application. You can control the assignment by creating pools with a `minShare` of cpu cores guaranteed for that pool. If you have one pool, then that can control it all - especially in FIFO mode - but that would not be efficient use of a Spark cluster. Spark has many moving parts, including how you structure your data and how to chose to process it (batch vs. stream). To properly perform this you have to analyze carefully the design of your computational DAG, and how your work should be processed given the resources. To me 200 partitions does not quite feel right, but if you think that is optimal for your design that's fine. Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:346,security,network,network,346,"@A-Tsai So now you're getting into determining your lineage graph of computations, which requires a lot of thought on how you set up your data and computational steps. Wide dependencies (multiple child partitions from the parent RDD) should be kept on the same node, while narrow dependencies (one child partition per parent RDD) can go over the network. Spark does hash partitioning to shuffle, and tries by the modulo of the number of partitions that it is somewhat uniformly distributed. Basically you should model your computation tree in order to best organize the data for good distribution and maximal local computation, otherwise you flood you network which slows down your completion-time. If you have 8 compute node with 4 cores each, then the node number will not change. The key to think about is the cores, but you have to determine to resource-allocate properly. The following can be helpful:. http://site.clairvoyantsoft.com/understanding-resource-allocation-configurations-spark-application/. Regarding task information, you get the duration here:. https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.scheduler.TaskInfo@finishTime:Long. You can control the policy with the application as noted here:. https://spark.apache.org/docs/latest/job-scheduling.html#scheduling-within-an-application. You can control the assignment by creating pools with a `minShare` of cpu cores guaranteed for that pool. If you have one pool, then that can control it all - especially in FIFO mode - but that would not be efficient use of a Spark cluster. Spark has many moving parts, including how you structure your data and how to chose to process it (batch vs. stream). To properly perform this you have to analyze carefully the design of your computational DAG, and how your work should be processed given the resources. To me 200 partitions does not quite feel right, but if you think that is optimal for your design that's fine. Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:366,security,hash,hash,366,"@A-Tsai So now you're getting into determining your lineage graph of computations, which requires a lot of thought on how you set up your data and computational steps. Wide dependencies (multiple child partitions from the parent RDD) should be kept on the same node, while narrow dependencies (one child partition per parent RDD) can go over the network. Spark does hash partitioning to shuffle, and tries by the modulo of the number of partitions that it is somewhat uniformly distributed. Basically you should model your computation tree in order to best organize the data for good distribution and maximal local computation, otherwise you flood you network which slows down your completion-time. If you have 8 compute node with 4 cores each, then the node number will not change. The key to think about is the cores, but you have to determine to resource-allocate properly. The following can be helpful:. http://site.clairvoyantsoft.com/understanding-resource-allocation-configurations-spark-application/. Regarding task information, you get the duration here:. https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.scheduler.TaskInfo@finishTime:Long. You can control the policy with the application as noted here:. https://spark.apache.org/docs/latest/job-scheduling.html#scheduling-within-an-application. You can control the assignment by creating pools with a `minShare` of cpu cores guaranteed for that pool. If you have one pool, then that can control it all - especially in FIFO mode - but that would not be efficient use of a Spark cluster. Spark has many moving parts, including how you structure your data and how to chose to process it (batch vs. stream). To properly perform this you have to analyze carefully the design of your computational DAG, and how your work should be processed given the resources. To me 200 partitions does not quite feel right, but if you think that is optimal for your design that's fine. Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:512,security,model,model,512,"@A-Tsai So now you're getting into determining your lineage graph of computations, which requires a lot of thought on how you set up your data and computational steps. Wide dependencies (multiple child partitions from the parent RDD) should be kept on the same node, while narrow dependencies (one child partition per parent RDD) can go over the network. Spark does hash partitioning to shuffle, and tries by the modulo of the number of partitions that it is somewhat uniformly distributed. Basically you should model your computation tree in order to best organize the data for good distribution and maximal local computation, otherwise you flood you network which slows down your completion-time. If you have 8 compute node with 4 cores each, then the node number will not change. The key to think about is the cores, but you have to determine to resource-allocate properly. The following can be helpful:. http://site.clairvoyantsoft.com/understanding-resource-allocation-configurations-spark-application/. Regarding task information, you get the duration here:. https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.scheduler.TaskInfo@finishTime:Long. You can control the policy with the application as noted here:. https://spark.apache.org/docs/latest/job-scheduling.html#scheduling-within-an-application. You can control the assignment by creating pools with a `minShare` of cpu cores guaranteed for that pool. If you have one pool, then that can control it all - especially in FIFO mode - but that would not be efficient use of a Spark cluster. Spark has many moving parts, including how you structure your data and how to chose to process it (batch vs. stream). To properly perform this you have to analyze carefully the design of your computational DAG, and how your work should be processed given the resources. To me 200 partitions does not quite feel right, but if you think that is optimal for your design that's fine. Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:652,security,network,network,652,"@A-Tsai So now you're getting into determining your lineage graph of computations, which requires a lot of thought on how you set up your data and computational steps. Wide dependencies (multiple child partitions from the parent RDD) should be kept on the same node, while narrow dependencies (one child partition per parent RDD) can go over the network. Spark does hash partitioning to shuffle, and tries by the modulo of the number of partitions that it is somewhat uniformly distributed. Basically you should model your computation tree in order to best organize the data for good distribution and maximal local computation, otherwise you flood you network which slows down your completion-time. If you have 8 compute node with 4 cores each, then the node number will not change. The key to think about is the cores, but you have to determine to resource-allocate properly. The following can be helpful:. http://site.clairvoyantsoft.com/understanding-resource-allocation-configurations-spark-application/. Regarding task information, you get the duration here:. https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.scheduler.TaskInfo@finishTime:Long. You can control the policy with the application as noted here:. https://spark.apache.org/docs/latest/job-scheduling.html#scheduling-within-an-application. You can control the assignment by creating pools with a `minShare` of cpu cores guaranteed for that pool. If you have one pool, then that can control it all - especially in FIFO mode - but that would not be efficient use of a Spark cluster. Spark has many moving parts, including how you structure your data and how to chose to process it (batch vs. stream). To properly perform this you have to analyze carefully the design of your computational DAG, and how your work should be processed given the resources. To me 200 partitions does not quite feel right, but if you think that is optimal for your design that's fine. Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:682,security,compl,completion-time,682,"@A-Tsai So now you're getting into determining your lineage graph of computations, which requires a lot of thought on how you set up your data and computational steps. Wide dependencies (multiple child partitions from the parent RDD) should be kept on the same node, while narrow dependencies (one child partition per parent RDD) can go over the network. Spark does hash partitioning to shuffle, and tries by the modulo of the number of partitions that it is somewhat uniformly distributed. Basically you should model your computation tree in order to best organize the data for good distribution and maximal local computation, otherwise you flood you network which slows down your completion-time. If you have 8 compute node with 4 cores each, then the node number will not change. The key to think about is the cores, but you have to determine to resource-allocate properly. The following can be helpful:. http://site.clairvoyantsoft.com/understanding-resource-allocation-configurations-spark-application/. Regarding task information, you get the duration here:. https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.scheduler.TaskInfo@finishTime:Long. You can control the policy with the application as noted here:. https://spark.apache.org/docs/latest/job-scheduling.html#scheduling-within-an-application. You can control the assignment by creating pools with a `minShare` of cpu cores guaranteed for that pool. If you have one pool, then that can control it all - especially in FIFO mode - but that would not be efficient use of a Spark cluster. Spark has many moving parts, including how you structure your data and how to chose to process it (batch vs. stream). To properly perform this you have to analyze carefully the design of your computational DAG, and how your work should be processed given the resources. To me 200 partitions does not quite feel right, but if you think that is optimal for your design that's fine. Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:974,security,configur,configurations-spark-application,974,"@A-Tsai So now you're getting into determining your lineage graph of computations, which requires a lot of thought on how you set up your data and computational steps. Wide dependencies (multiple child partitions from the parent RDD) should be kept on the same node, while narrow dependencies (one child partition per parent RDD) can go over the network. Spark does hash partitioning to shuffle, and tries by the modulo of the number of partitions that it is somewhat uniformly distributed. Basically you should model your computation tree in order to best organize the data for good distribution and maximal local computation, otherwise you flood you network which slows down your completion-time. If you have 8 compute node with 4 cores each, then the node number will not change. The key to think about is the cores, but you have to determine to resource-allocate properly. The following can be helpful:. http://site.clairvoyantsoft.com/understanding-resource-allocation-configurations-spark-application/. Regarding task information, you get the duration here:. https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.scheduler.TaskInfo@finishTime:Long. You can control the policy with the application as noted here:. https://spark.apache.org/docs/latest/job-scheduling.html#scheduling-within-an-application. You can control the assignment by creating pools with a `minShare` of cpu cores guaranteed for that pool. If you have one pool, then that can control it all - especially in FIFO mode - but that would not be efficient use of a Spark cluster. Spark has many moving parts, including how you structure your data and how to chose to process it (batch vs. stream). To properly perform this you have to analyze carefully the design of your computational DAG, and how your work should be processed given the resources. To me 200 partitions does not quite feel right, but if you think that is optimal for your design that's fine. Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:1184,security,control,control,1184,"@A-Tsai So now you're getting into determining your lineage graph of computations, which requires a lot of thought on how you set up your data and computational steps. Wide dependencies (multiple child partitions from the parent RDD) should be kept on the same node, while narrow dependencies (one child partition per parent RDD) can go over the network. Spark does hash partitioning to shuffle, and tries by the modulo of the number of partitions that it is somewhat uniformly distributed. Basically you should model your computation tree in order to best organize the data for good distribution and maximal local computation, otherwise you flood you network which slows down your completion-time. If you have 8 compute node with 4 cores each, then the node number will not change. The key to think about is the cores, but you have to determine to resource-allocate properly. The following can be helpful:. http://site.clairvoyantsoft.com/understanding-resource-allocation-configurations-spark-application/. Regarding task information, you get the duration here:. https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.scheduler.TaskInfo@finishTime:Long. You can control the policy with the application as noted here:. https://spark.apache.org/docs/latest/job-scheduling.html#scheduling-within-an-application. You can control the assignment by creating pools with a `minShare` of cpu cores guaranteed for that pool. If you have one pool, then that can control it all - especially in FIFO mode - but that would not be efficient use of a Spark cluster. Spark has many moving parts, including how you structure your data and how to chose to process it (batch vs. stream). To properly perform this you have to analyze carefully the design of your computational DAG, and how your work should be processed given the resources. To me 200 partitions does not quite feel right, but if you think that is optimal for your design that's fine. Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:1196,security,polic,policy,1196,"@A-Tsai So now you're getting into determining your lineage graph of computations, which requires a lot of thought on how you set up your data and computational steps. Wide dependencies (multiple child partitions from the parent RDD) should be kept on the same node, while narrow dependencies (one child partition per parent RDD) can go over the network. Spark does hash partitioning to shuffle, and tries by the modulo of the number of partitions that it is somewhat uniformly distributed. Basically you should model your computation tree in order to best organize the data for good distribution and maximal local computation, otherwise you flood you network which slows down your completion-time. If you have 8 compute node with 4 cores each, then the node number will not change. The key to think about is the cores, but you have to determine to resource-allocate properly. The following can be helpful:. http://site.clairvoyantsoft.com/understanding-resource-allocation-configurations-spark-application/. Regarding task information, you get the duration here:. https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.scheduler.TaskInfo@finishTime:Long. You can control the policy with the application as noted here:. https://spark.apache.org/docs/latest/job-scheduling.html#scheduling-within-an-application. You can control the assignment by creating pools with a `minShare` of cpu cores guaranteed for that pool. If you have one pool, then that can control it all - especially in FIFO mode - but that would not be efficient use of a Spark cluster. Spark has many moving parts, including how you structure your data and how to chose to process it (batch vs. stream). To properly perform this you have to analyze carefully the design of your computational DAG, and how your work should be processed given the resources. To me 200 partitions does not quite feel right, but if you think that is optimal for your design that's fine. Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:1339,security,control,control,1339,"@A-Tsai So now you're getting into determining your lineage graph of computations, which requires a lot of thought on how you set up your data and computational steps. Wide dependencies (multiple child partitions from the parent RDD) should be kept on the same node, while narrow dependencies (one child partition per parent RDD) can go over the network. Spark does hash partitioning to shuffle, and tries by the modulo of the number of partitions that it is somewhat uniformly distributed. Basically you should model your computation tree in order to best organize the data for good distribution and maximal local computation, otherwise you flood you network which slows down your completion-time. If you have 8 compute node with 4 cores each, then the node number will not change. The key to think about is the cores, but you have to determine to resource-allocate properly. The following can be helpful:. http://site.clairvoyantsoft.com/understanding-resource-allocation-configurations-spark-application/. Regarding task information, you get the duration here:. https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.scheduler.TaskInfo@finishTime:Long. You can control the policy with the application as noted here:. https://spark.apache.org/docs/latest/job-scheduling.html#scheduling-within-an-application. You can control the assignment by creating pools with a `minShare` of cpu cores guaranteed for that pool. If you have one pool, then that can control it all - especially in FIFO mode - but that would not be efficient use of a Spark cluster. Spark has many moving parts, including how you structure your data and how to chose to process it (batch vs. stream). To properly perform this you have to analyze carefully the design of your computational DAG, and how your work should be processed given the resources. To me 200 partitions does not quite feel right, but if you think that is optimal for your design that's fine. Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:1473,security,control,control,1473,"@A-Tsai So now you're getting into determining your lineage graph of computations, which requires a lot of thought on how you set up your data and computational steps. Wide dependencies (multiple child partitions from the parent RDD) should be kept on the same node, while narrow dependencies (one child partition per parent RDD) can go over the network. Spark does hash partitioning to shuffle, and tries by the modulo of the number of partitions that it is somewhat uniformly distributed. Basically you should model your computation tree in order to best organize the data for good distribution and maximal local computation, otherwise you flood you network which slows down your completion-time. If you have 8 compute node with 4 cores each, then the node number will not change. The key to think about is the cores, but you have to determine to resource-allocate properly. The following can be helpful:. http://site.clairvoyantsoft.com/understanding-resource-allocation-configurations-spark-application/. Regarding task information, you get the duration here:. https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.scheduler.TaskInfo@finishTime:Long. You can control the policy with the application as noted here:. https://spark.apache.org/docs/latest/job-scheduling.html#scheduling-within-an-application. You can control the assignment by creating pools with a `minShare` of cpu cores guaranteed for that pool. If you have one pool, then that can control it all - especially in FIFO mode - but that would not be efficient use of a Spark cluster. Spark has many moving parts, including how you structure your data and how to chose to process it (batch vs. stream). To properly perform this you have to analyze carefully the design of your computational DAG, and how your work should be processed given the resources. To me 200 partitions does not quite feel right, but if you think that is optimal for your design that's fine. Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:173,testability,depend,dependencies,173,"@A-Tsai So now you're getting into determining your lineage graph of computations, which requires a lot of thought on how you set up your data and computational steps. Wide dependencies (multiple child partitions from the parent RDD) should be kept on the same node, while narrow dependencies (one child partition per parent RDD) can go over the network. Spark does hash partitioning to shuffle, and tries by the modulo of the number of partitions that it is somewhat uniformly distributed. Basically you should model your computation tree in order to best organize the data for good distribution and maximal local computation, otherwise you flood you network which slows down your completion-time. If you have 8 compute node with 4 cores each, then the node number will not change. The key to think about is the cores, but you have to determine to resource-allocate properly. The following can be helpful:. http://site.clairvoyantsoft.com/understanding-resource-allocation-configurations-spark-application/. Regarding task information, you get the duration here:. https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.scheduler.TaskInfo@finishTime:Long. You can control the policy with the application as noted here:. https://spark.apache.org/docs/latest/job-scheduling.html#scheduling-within-an-application. You can control the assignment by creating pools with a `minShare` of cpu cores guaranteed for that pool. If you have one pool, then that can control it all - especially in FIFO mode - but that would not be efficient use of a Spark cluster. Spark has many moving parts, including how you structure your data and how to chose to process it (batch vs. stream). To properly perform this you have to analyze carefully the design of your computational DAG, and how your work should be processed given the resources. To me 200 partitions does not quite feel right, but if you think that is optimal for your design that's fine. Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:280,testability,depend,dependencies,280,"@A-Tsai So now you're getting into determining your lineage graph of computations, which requires a lot of thought on how you set up your data and computational steps. Wide dependencies (multiple child partitions from the parent RDD) should be kept on the same node, while narrow dependencies (one child partition per parent RDD) can go over the network. Spark does hash partitioning to shuffle, and tries by the modulo of the number of partitions that it is somewhat uniformly distributed. Basically you should model your computation tree in order to best organize the data for good distribution and maximal local computation, otherwise you flood you network which slows down your completion-time. If you have 8 compute node with 4 cores each, then the node number will not change. The key to think about is the cores, but you have to determine to resource-allocate properly. The following can be helpful:. http://site.clairvoyantsoft.com/understanding-resource-allocation-configurations-spark-application/. Regarding task information, you get the duration here:. https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.scheduler.TaskInfo@finishTime:Long. You can control the policy with the application as noted here:. https://spark.apache.org/docs/latest/job-scheduling.html#scheduling-within-an-application. You can control the assignment by creating pools with a `minShare` of cpu cores guaranteed for that pool. If you have one pool, then that can control it all - especially in FIFO mode - but that would not be efficient use of a Spark cluster. Spark has many moving parts, including how you structure your data and how to chose to process it (batch vs. stream). To properly perform this you have to analyze carefully the design of your computational DAG, and how your work should be processed given the resources. To me 200 partitions does not quite feel right, but if you think that is optimal for your design that's fine. Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:849,testability,resourc,resource-allocate,849,"@A-Tsai So now you're getting into determining your lineage graph of computations, which requires a lot of thought on how you set up your data and computational steps. Wide dependencies (multiple child partitions from the parent RDD) should be kept on the same node, while narrow dependencies (one child partition per parent RDD) can go over the network. Spark does hash partitioning to shuffle, and tries by the modulo of the number of partitions that it is somewhat uniformly distributed. Basically you should model your computation tree in order to best organize the data for good distribution and maximal local computation, otherwise you flood you network which slows down your completion-time. If you have 8 compute node with 4 cores each, then the node number will not change. The key to think about is the cores, but you have to determine to resource-allocate properly. The following can be helpful:. http://site.clairvoyantsoft.com/understanding-resource-allocation-configurations-spark-application/. Regarding task information, you get the duration here:. https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.scheduler.TaskInfo@finishTime:Long. You can control the policy with the application as noted here:. https://spark.apache.org/docs/latest/job-scheduling.html#scheduling-within-an-application. You can control the assignment by creating pools with a `minShare` of cpu cores guaranteed for that pool. If you have one pool, then that can control it all - especially in FIFO mode - but that would not be efficient use of a Spark cluster. Spark has many moving parts, including how you structure your data and how to chose to process it (batch vs. stream). To properly perform this you have to analyze carefully the design of your computational DAG, and how your work should be processed given the resources. To me 200 partitions does not quite feel right, but if you think that is optimal for your design that's fine. Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:940,testability,understand,understanding-resource-allocation-configurations-spark-application,940,"@A-Tsai So now you're getting into determining your lineage graph of computations, which requires a lot of thought on how you set up your data and computational steps. Wide dependencies (multiple child partitions from the parent RDD) should be kept on the same node, while narrow dependencies (one child partition per parent RDD) can go over the network. Spark does hash partitioning to shuffle, and tries by the modulo of the number of partitions that it is somewhat uniformly distributed. Basically you should model your computation tree in order to best organize the data for good distribution and maximal local computation, otherwise you flood you network which slows down your completion-time. If you have 8 compute node with 4 cores each, then the node number will not change. The key to think about is the cores, but you have to determine to resource-allocate properly. The following can be helpful:. http://site.clairvoyantsoft.com/understanding-resource-allocation-configurations-spark-application/. Regarding task information, you get the duration here:. https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.scheduler.TaskInfo@finishTime:Long. You can control the policy with the application as noted here:. https://spark.apache.org/docs/latest/job-scheduling.html#scheduling-within-an-application. You can control the assignment by creating pools with a `minShare` of cpu cores guaranteed for that pool. If you have one pool, then that can control it all - especially in FIFO mode - but that would not be efficient use of a Spark cluster. Spark has many moving parts, including how you structure your data and how to chose to process it (batch vs. stream). To properly perform this you have to analyze carefully the design of your computational DAG, and how your work should be processed given the resources. To me 200 partitions does not quite feel right, but if you think that is optimal for your design that's fine. Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:1184,testability,control,control,1184,"@A-Tsai So now you're getting into determining your lineage graph of computations, which requires a lot of thought on how you set up your data and computational steps. Wide dependencies (multiple child partitions from the parent RDD) should be kept on the same node, while narrow dependencies (one child partition per parent RDD) can go over the network. Spark does hash partitioning to shuffle, and tries by the modulo of the number of partitions that it is somewhat uniformly distributed. Basically you should model your computation tree in order to best organize the data for good distribution and maximal local computation, otherwise you flood you network which slows down your completion-time. If you have 8 compute node with 4 cores each, then the node number will not change. The key to think about is the cores, but you have to determine to resource-allocate properly. The following can be helpful:. http://site.clairvoyantsoft.com/understanding-resource-allocation-configurations-spark-application/. Regarding task information, you get the duration here:. https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.scheduler.TaskInfo@finishTime:Long. You can control the policy with the application as noted here:. https://spark.apache.org/docs/latest/job-scheduling.html#scheduling-within-an-application. You can control the assignment by creating pools with a `minShare` of cpu cores guaranteed for that pool. If you have one pool, then that can control it all - especially in FIFO mode - but that would not be efficient use of a Spark cluster. Spark has many moving parts, including how you structure your data and how to chose to process it (batch vs. stream). To properly perform this you have to analyze carefully the design of your computational DAG, and how your work should be processed given the resources. To me 200 partitions does not quite feel right, but if you think that is optimal for your design that's fine. Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:1339,testability,control,control,1339,"@A-Tsai So now you're getting into determining your lineage graph of computations, which requires a lot of thought on how you set up your data and computational steps. Wide dependencies (multiple child partitions from the parent RDD) should be kept on the same node, while narrow dependencies (one child partition per parent RDD) can go over the network. Spark does hash partitioning to shuffle, and tries by the modulo of the number of partitions that it is somewhat uniformly distributed. Basically you should model your computation tree in order to best organize the data for good distribution and maximal local computation, otherwise you flood you network which slows down your completion-time. If you have 8 compute node with 4 cores each, then the node number will not change. The key to think about is the cores, but you have to determine to resource-allocate properly. The following can be helpful:. http://site.clairvoyantsoft.com/understanding-resource-allocation-configurations-spark-application/. Regarding task information, you get the duration here:. https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.scheduler.TaskInfo@finishTime:Long. You can control the policy with the application as noted here:. https://spark.apache.org/docs/latest/job-scheduling.html#scheduling-within-an-application. You can control the assignment by creating pools with a `minShare` of cpu cores guaranteed for that pool. If you have one pool, then that can control it all - especially in FIFO mode - but that would not be efficient use of a Spark cluster. Spark has many moving parts, including how you structure your data and how to chose to process it (batch vs. stream). To properly perform this you have to analyze carefully the design of your computational DAG, and how your work should be processed given the resources. To me 200 partitions does not quite feel right, but if you think that is optimal for your design that's fine. Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:1473,testability,control,control,1473,"@A-Tsai So now you're getting into determining your lineage graph of computations, which requires a lot of thought on how you set up your data and computational steps. Wide dependencies (multiple child partitions from the parent RDD) should be kept on the same node, while narrow dependencies (one child partition per parent RDD) can go over the network. Spark does hash partitioning to shuffle, and tries by the modulo of the number of partitions that it is somewhat uniformly distributed. Basically you should model your computation tree in order to best organize the data for good distribution and maximal local computation, otherwise you flood you network which slows down your completion-time. If you have 8 compute node with 4 cores each, then the node number will not change. The key to think about is the cores, but you have to determine to resource-allocate properly. The following can be helpful:. http://site.clairvoyantsoft.com/understanding-resource-allocation-configurations-spark-application/. Regarding task information, you get the duration here:. https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.scheduler.TaskInfo@finishTime:Long. You can control the policy with the application as noted here:. https://spark.apache.org/docs/latest/job-scheduling.html#scheduling-within-an-application. You can control the assignment by creating pools with a `minShare` of cpu cores guaranteed for that pool. If you have one pool, then that can control it all - especially in FIFO mode - but that would not be efficient use of a Spark cluster. Spark has many moving parts, including how you structure your data and how to chose to process it (batch vs. stream). To properly perform this you have to analyze carefully the design of your computational DAG, and how your work should be processed given the resources. To me 200 partitions does not quite feel right, but if you think that is optimal for your design that's fine. Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:1831,testability,resourc,resources,1831,"@A-Tsai So now you're getting into determining your lineage graph of computations, which requires a lot of thought on how you set up your data and computational steps. Wide dependencies (multiple child partitions from the parent RDD) should be kept on the same node, while narrow dependencies (one child partition per parent RDD) can go over the network. Spark does hash partitioning to shuffle, and tries by the modulo of the number of partitions that it is somewhat uniformly distributed. Basically you should model your computation tree in order to best organize the data for good distribution and maximal local computation, otherwise you flood you network which slows down your completion-time. If you have 8 compute node with 4 cores each, then the node number will not change. The key to think about is the cores, but you have to determine to resource-allocate properly. The following can be helpful:. http://site.clairvoyantsoft.com/understanding-resource-allocation-configurations-spark-application/. Regarding task information, you get the duration here:. https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.scheduler.TaskInfo@finishTime:Long. You can control the policy with the application as noted here:. https://spark.apache.org/docs/latest/job-scheduling.html#scheduling-within-an-application. You can control the assignment by creating pools with a `minShare` of cpu cores guaranteed for that pool. If you have one pool, then that can control it all - especially in FIFO mode - but that would not be efficient use of a Spark cluster. Spark has many moving parts, including how you structure your data and how to chose to process it (batch vs. stream). To properly perform this you have to analyze carefully the design of your computational DAG, and how your work should be processed given the resources. To me 200 partitions does not quite feel right, but if you think that is optimal for your design that's fine. Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:898,usability,help,helpful,898,"@A-Tsai So now you're getting into determining your lineage graph of computations, which requires a lot of thought on how you set up your data and computational steps. Wide dependencies (multiple child partitions from the parent RDD) should be kept on the same node, while narrow dependencies (one child partition per parent RDD) can go over the network. Spark does hash partitioning to shuffle, and tries by the modulo of the number of partitions that it is somewhat uniformly distributed. Basically you should model your computation tree in order to best organize the data for good distribution and maximal local computation, otherwise you flood you network which slows down your completion-time. If you have 8 compute node with 4 cores each, then the node number will not change. The key to think about is the cores, but you have to determine to resource-allocate properly. The following can be helpful:. http://site.clairvoyantsoft.com/understanding-resource-allocation-configurations-spark-application/. Regarding task information, you get the duration here:. https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.scheduler.TaskInfo@finishTime:Long. You can control the policy with the application as noted here:. https://spark.apache.org/docs/latest/job-scheduling.html#scheduling-within-an-application. You can control the assignment by creating pools with a `minShare` of cpu cores guaranteed for that pool. If you have one pool, then that can control it all - especially in FIFO mode - but that would not be efficient use of a Spark cluster. Spark has many moving parts, including how you structure your data and how to chose to process it (batch vs. stream). To properly perform this you have to analyze carefully the design of your computational DAG, and how your work should be processed given the resources. To me 200 partitions does not quite feel right, but if you think that is optimal for your design that's fine. Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:1538,usability,efficien,efficient,1538,"@A-Tsai So now you're getting into determining your lineage graph of computations, which requires a lot of thought on how you set up your data and computational steps. Wide dependencies (multiple child partitions from the parent RDD) should be kept on the same node, while narrow dependencies (one child partition per parent RDD) can go over the network. Spark does hash partitioning to shuffle, and tries by the modulo of the number of partitions that it is somewhat uniformly distributed. Basically you should model your computation tree in order to best organize the data for good distribution and maximal local computation, otherwise you flood you network which slows down your completion-time. If you have 8 compute node with 4 cores each, then the node number will not change. The key to think about is the cores, but you have to determine to resource-allocate properly. The following can be helpful:. http://site.clairvoyantsoft.com/understanding-resource-allocation-configurations-spark-application/. Regarding task information, you get the duration here:. https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.scheduler.TaskInfo@finishTime:Long. You can control the policy with the application as noted here:. https://spark.apache.org/docs/latest/job-scheduling.html#scheduling-within-an-application. You can control the assignment by creating pools with a `minShare` of cpu cores guaranteed for that pool. If you have one pool, then that can control it all - especially in FIFO mode - but that would not be efficient use of a Spark cluster. Spark has many moving parts, including how you structure your data and how to chose to process it (batch vs. stream). To properly perform this you have to analyze carefully the design of your computational DAG, and how your work should be processed given the resources. To me 200 partitions does not quite feel right, but if you think that is optimal for your design that's fine. Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:1702,usability,perform,perform,1702,"@A-Tsai So now you're getting into determining your lineage graph of computations, which requires a lot of thought on how you set up your data and computational steps. Wide dependencies (multiple child partitions from the parent RDD) should be kept on the same node, while narrow dependencies (one child partition per parent RDD) can go over the network. Spark does hash partitioning to shuffle, and tries by the modulo of the number of partitions that it is somewhat uniformly distributed. Basically you should model your computation tree in order to best organize the data for good distribution and maximal local computation, otherwise you flood you network which slows down your completion-time. If you have 8 compute node with 4 cores each, then the node number will not change. The key to think about is the cores, but you have to determine to resource-allocate properly. The following can be helpful:. http://site.clairvoyantsoft.com/understanding-resource-allocation-configurations-spark-application/. Regarding task information, you get the duration here:. https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.scheduler.TaskInfo@finishTime:Long. You can control the policy with the application as noted here:. https://spark.apache.org/docs/latest/job-scheduling.html#scheduling-within-an-application. You can control the assignment by creating pools with a `minShare` of cpu cores guaranteed for that pool. If you have one pool, then that can control it all - especially in FIFO mode - but that would not be efficient use of a Spark cluster. Spark has many moving parts, including how you structure your data and how to chose to process it (batch vs. stream). To properly perform this you have to analyze carefully the design of your computational DAG, and how your work should be processed given the resources. To me 200 partitions does not quite feel right, but if you think that is optimal for your design that's fine. Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:1960,usability,help,helps,1960,"@A-Tsai So now you're getting into determining your lineage graph of computations, which requires a lot of thought on how you set up your data and computational steps. Wide dependencies (multiple child partitions from the parent RDD) should be kept on the same node, while narrow dependencies (one child partition per parent RDD) can go over the network. Spark does hash partitioning to shuffle, and tries by the modulo of the number of partitions that it is somewhat uniformly distributed. Basically you should model your computation tree in order to best organize the data for good distribution and maximal local computation, otherwise you flood you network which slows down your completion-time. If you have 8 compute node with 4 cores each, then the node number will not change. The key to think about is the cores, but you have to determine to resource-allocate properly. The following can be helpful:. http://site.clairvoyantsoft.com/understanding-resource-allocation-configurations-spark-application/. Regarding task information, you get the duration here:. https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.scheduler.TaskInfo@finishTime:Long. You can control the policy with the application as noted here:. https://spark.apache.org/docs/latest/job-scheduling.html#scheduling-within-an-application. You can control the assignment by creating pools with a `minShare` of cpu cores guaranteed for that pool. If you have one pool, then that can control it all - especially in FIFO mode - but that would not be efficient use of a Spark cluster. Spark has many moving parts, including how you structure your data and how to chose to process it (batch vs. stream). To properly perform this you have to analyze carefully the design of your computational DAG, and how your work should be processed given the resources. To me 200 partitions does not quite feel right, but if you think that is optimal for your design that's fine. Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:149,availability,avail,available,149,"@pgrosu Thank you for the information. Your suggestion might be a way to port DeepVariant on Spark, but it's not fit on dynamic allocation since the available resource is dynamic changed. . I did port several popular bioinformatics tools (e.g. BWA, GATK, DELLY2, Samtools, ...) on Spark and they run well. I think the fundamental problem is that the resource configuration (intra_op_parallelism_threads=1, inter_op_parallelism_threads=1) of TensorFlow doesn't work. If there is no way to limit CPU resource on DeepVariant, should I submit this issue to TensorFlow GitHub?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:159,deployability,resourc,resource,159,"@pgrosu Thank you for the information. Your suggestion might be a way to port DeepVariant on Spark, but it's not fit on dynamic allocation since the available resource is dynamic changed. . I did port several popular bioinformatics tools (e.g. BWA, GATK, DELLY2, Samtools, ...) on Spark and they run well. I think the fundamental problem is that the resource configuration (intra_op_parallelism_threads=1, inter_op_parallelism_threads=1) of TensorFlow doesn't work. If there is no way to limit CPU resource on DeepVariant, should I submit this issue to TensorFlow GitHub?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:350,deployability,resourc,resource,350,"@pgrosu Thank you for the information. Your suggestion might be a way to port DeepVariant on Spark, but it's not fit on dynamic allocation since the available resource is dynamic changed. . I did port several popular bioinformatics tools (e.g. BWA, GATK, DELLY2, Samtools, ...) on Spark and they run well. I think the fundamental problem is that the resource configuration (intra_op_parallelism_threads=1, inter_op_parallelism_threads=1) of TensorFlow doesn't work. If there is no way to limit CPU resource on DeepVariant, should I submit this issue to TensorFlow GitHub?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:359,deployability,configurat,configuration,359,"@pgrosu Thank you for the information. Your suggestion might be a way to port DeepVariant on Spark, but it's not fit on dynamic allocation since the available resource is dynamic changed. . I did port several popular bioinformatics tools (e.g. BWA, GATK, DELLY2, Samtools, ...) on Spark and they run well. I think the fundamental problem is that the resource configuration (intra_op_parallelism_threads=1, inter_op_parallelism_threads=1) of TensorFlow doesn't work. If there is no way to limit CPU resource on DeepVariant, should I submit this issue to TensorFlow GitHub?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:498,deployability,resourc,resource,498,"@pgrosu Thank you for the information. Your suggestion might be a way to port DeepVariant on Spark, but it's not fit on dynamic allocation since the available resource is dynamic changed. . I did port several popular bioinformatics tools (e.g. BWA, GATK, DELLY2, Samtools, ...) on Spark and they run well. I think the fundamental problem is that the resource configuration (intra_op_parallelism_threads=1, inter_op_parallelism_threads=1) of TensorFlow doesn't work. If there is no way to limit CPU resource on DeepVariant, should I submit this issue to TensorFlow GitHub?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:128,energy efficiency,alloc,allocation,128,"@pgrosu Thank you for the information. Your suggestion might be a way to port DeepVariant on Spark, but it's not fit on dynamic allocation since the available resource is dynamic changed. . I did port several popular bioinformatics tools (e.g. BWA, GATK, DELLY2, Samtools, ...) on Spark and they run well. I think the fundamental problem is that the resource configuration (intra_op_parallelism_threads=1, inter_op_parallelism_threads=1) of TensorFlow doesn't work. If there is no way to limit CPU resource on DeepVariant, should I submit this issue to TensorFlow GitHub?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:159,energy efficiency,resourc,resource,159,"@pgrosu Thank you for the information. Your suggestion might be a way to port DeepVariant on Spark, but it's not fit on dynamic allocation since the available resource is dynamic changed. . I did port several popular bioinformatics tools (e.g. BWA, GATK, DELLY2, Samtools, ...) on Spark and they run well. I think the fundamental problem is that the resource configuration (intra_op_parallelism_threads=1, inter_op_parallelism_threads=1) of TensorFlow doesn't work. If there is no way to limit CPU resource on DeepVariant, should I submit this issue to TensorFlow GitHub?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:350,energy efficiency,resourc,resource,350,"@pgrosu Thank you for the information. Your suggestion might be a way to port DeepVariant on Spark, but it's not fit on dynamic allocation since the available resource is dynamic changed. . I did port several popular bioinformatics tools (e.g. BWA, GATK, DELLY2, Samtools, ...) on Spark and they run well. I think the fundamental problem is that the resource configuration (intra_op_parallelism_threads=1, inter_op_parallelism_threads=1) of TensorFlow doesn't work. If there is no way to limit CPU resource on DeepVariant, should I submit this issue to TensorFlow GitHub?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:494,energy efficiency,CPU,CPU,494,"@pgrosu Thank you for the information. Your suggestion might be a way to port DeepVariant on Spark, but it's not fit on dynamic allocation since the available resource is dynamic changed. . I did port several popular bioinformatics tools (e.g. BWA, GATK, DELLY2, Samtools, ...) on Spark and they run well. I think the fundamental problem is that the resource configuration (intra_op_parallelism_threads=1, inter_op_parallelism_threads=1) of TensorFlow doesn't work. If there is no way to limit CPU resource on DeepVariant, should I submit this issue to TensorFlow GitHub?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:498,energy efficiency,resourc,resource,498,"@pgrosu Thank you for the information. Your suggestion might be a way to port DeepVariant on Spark, but it's not fit on dynamic allocation since the available resource is dynamic changed. . I did port several popular bioinformatics tools (e.g. BWA, GATK, DELLY2, Samtools, ...) on Spark and they run well. I think the fundamental problem is that the resource configuration (intra_op_parallelism_threads=1, inter_op_parallelism_threads=1) of TensorFlow doesn't work. If there is no way to limit CPU resource on DeepVariant, should I submit this issue to TensorFlow GitHub?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:359,integrability,configur,configuration,359,"@pgrosu Thank you for the information. Your suggestion might be a way to port DeepVariant on Spark, but it's not fit on dynamic allocation since the available resource is dynamic changed. . I did port several popular bioinformatics tools (e.g. BWA, GATK, DELLY2, Samtools, ...) on Spark and they run well. I think the fundamental problem is that the resource configuration (intra_op_parallelism_threads=1, inter_op_parallelism_threads=1) of TensorFlow doesn't work. If there is no way to limit CPU resource on DeepVariant, should I submit this issue to TensorFlow GitHub?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:532,integrability,sub,submit,532,"@pgrosu Thank you for the information. Your suggestion might be a way to port DeepVariant on Spark, but it's not fit on dynamic allocation since the available resource is dynamic changed. . I did port several popular bioinformatics tools (e.g. BWA, GATK, DELLY2, Samtools, ...) on Spark and they run well. I think the fundamental problem is that the resource configuration (intra_op_parallelism_threads=1, inter_op_parallelism_threads=1) of TensorFlow doesn't work. If there is no way to limit CPU resource on DeepVariant, should I submit this issue to TensorFlow GitHub?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:359,modifiability,configur,configuration,359,"@pgrosu Thank you for the information. Your suggestion might be a way to port DeepVariant on Spark, but it's not fit on dynamic allocation since the available resource is dynamic changed. . I did port several popular bioinformatics tools (e.g. BWA, GATK, DELLY2, Samtools, ...) on Spark and they run well. I think the fundamental problem is that the resource configuration (intra_op_parallelism_threads=1, inter_op_parallelism_threads=1) of TensorFlow doesn't work. If there is no way to limit CPU resource on DeepVariant, should I submit this issue to TensorFlow GitHub?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:159,performance,resourc,resource,159,"@pgrosu Thank you for the information. Your suggestion might be a way to port DeepVariant on Spark, but it's not fit on dynamic allocation since the available resource is dynamic changed. . I did port several popular bioinformatics tools (e.g. BWA, GATK, DELLY2, Samtools, ...) on Spark and they run well. I think the fundamental problem is that the resource configuration (intra_op_parallelism_threads=1, inter_op_parallelism_threads=1) of TensorFlow doesn't work. If there is no way to limit CPU resource on DeepVariant, should I submit this issue to TensorFlow GitHub?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:350,performance,resourc,resource,350,"@pgrosu Thank you for the information. Your suggestion might be a way to port DeepVariant on Spark, but it's not fit on dynamic allocation since the available resource is dynamic changed. . I did port several popular bioinformatics tools (e.g. BWA, GATK, DELLY2, Samtools, ...) on Spark and they run well. I think the fundamental problem is that the resource configuration (intra_op_parallelism_threads=1, inter_op_parallelism_threads=1) of TensorFlow doesn't work. If there is no way to limit CPU resource on DeepVariant, should I submit this issue to TensorFlow GitHub?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:494,performance,CPU,CPU,494,"@pgrosu Thank you for the information. Your suggestion might be a way to port DeepVariant on Spark, but it's not fit on dynamic allocation since the available resource is dynamic changed. . I did port several popular bioinformatics tools (e.g. BWA, GATK, DELLY2, Samtools, ...) on Spark and they run well. I think the fundamental problem is that the resource configuration (intra_op_parallelism_threads=1, inter_op_parallelism_threads=1) of TensorFlow doesn't work. If there is no way to limit CPU resource on DeepVariant, should I submit this issue to TensorFlow GitHub?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:498,performance,resourc,resource,498,"@pgrosu Thank you for the information. Your suggestion might be a way to port DeepVariant on Spark, but it's not fit on dynamic allocation since the available resource is dynamic changed. . I did port several popular bioinformatics tools (e.g. BWA, GATK, DELLY2, Samtools, ...) on Spark and they run well. I think the fundamental problem is that the resource configuration (intra_op_parallelism_threads=1, inter_op_parallelism_threads=1) of TensorFlow doesn't work. If there is no way to limit CPU resource on DeepVariant, should I submit this issue to TensorFlow GitHub?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:149,reliability,availab,available,149,"@pgrosu Thank you for the information. Your suggestion might be a way to port DeepVariant on Spark, but it's not fit on dynamic allocation since the available resource is dynamic changed. . I did port several popular bioinformatics tools (e.g. BWA, GATK, DELLY2, Samtools, ...) on Spark and they run well. I think the fundamental problem is that the resource configuration (intra_op_parallelism_threads=1, inter_op_parallelism_threads=1) of TensorFlow doesn't work. If there is no way to limit CPU resource on DeepVariant, should I submit this issue to TensorFlow GitHub?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:452,reliability,doe,doesn,452,"@pgrosu Thank you for the information. Your suggestion might be a way to port DeepVariant on Spark, but it's not fit on dynamic allocation since the available resource is dynamic changed. . I did port several popular bioinformatics tools (e.g. BWA, GATK, DELLY2, Samtools, ...) on Spark and they run well. I think the fundamental problem is that the resource configuration (intra_op_parallelism_threads=1, inter_op_parallelism_threads=1) of TensorFlow doesn't work. If there is no way to limit CPU resource on DeepVariant, should I submit this issue to TensorFlow GitHub?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:149,safety,avail,available,149,"@pgrosu Thank you for the information. Your suggestion might be a way to port DeepVariant on Spark, but it's not fit on dynamic allocation since the available resource is dynamic changed. . I did port several popular bioinformatics tools (e.g. BWA, GATK, DELLY2, Samtools, ...) on Spark and they run well. I think the fundamental problem is that the resource configuration (intra_op_parallelism_threads=1, inter_op_parallelism_threads=1) of TensorFlow doesn't work. If there is no way to limit CPU resource on DeepVariant, should I submit this issue to TensorFlow GitHub?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:159,safety,resourc,resource,159,"@pgrosu Thank you for the information. Your suggestion might be a way to port DeepVariant on Spark, but it's not fit on dynamic allocation since the available resource is dynamic changed. . I did port several popular bioinformatics tools (e.g. BWA, GATK, DELLY2, Samtools, ...) on Spark and they run well. I think the fundamental problem is that the resource configuration (intra_op_parallelism_threads=1, inter_op_parallelism_threads=1) of TensorFlow doesn't work. If there is no way to limit CPU resource on DeepVariant, should I submit this issue to TensorFlow GitHub?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:350,safety,resourc,resource,350,"@pgrosu Thank you for the information. Your suggestion might be a way to port DeepVariant on Spark, but it's not fit on dynamic allocation since the available resource is dynamic changed. . I did port several popular bioinformatics tools (e.g. BWA, GATK, DELLY2, Samtools, ...) on Spark and they run well. I think the fundamental problem is that the resource configuration (intra_op_parallelism_threads=1, inter_op_parallelism_threads=1) of TensorFlow doesn't work. If there is no way to limit CPU resource on DeepVariant, should I submit this issue to TensorFlow GitHub?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:498,safety,resourc,resource,498,"@pgrosu Thank you for the information. Your suggestion might be a way to port DeepVariant on Spark, but it's not fit on dynamic allocation since the available resource is dynamic changed. . I did port several popular bioinformatics tools (e.g. BWA, GATK, DELLY2, Samtools, ...) on Spark and they run well. I think the fundamental problem is that the resource configuration (intra_op_parallelism_threads=1, inter_op_parallelism_threads=1) of TensorFlow doesn't work. If there is no way to limit CPU resource on DeepVariant, should I submit this issue to TensorFlow GitHub?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:149,security,availab,available,149,"@pgrosu Thank you for the information. Your suggestion might be a way to port DeepVariant on Spark, but it's not fit on dynamic allocation since the available resource is dynamic changed. . I did port several popular bioinformatics tools (e.g. BWA, GATK, DELLY2, Samtools, ...) on Spark and they run well. I think the fundamental problem is that the resource configuration (intra_op_parallelism_threads=1, inter_op_parallelism_threads=1) of TensorFlow doesn't work. If there is no way to limit CPU resource on DeepVariant, should I submit this issue to TensorFlow GitHub?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:359,security,configur,configuration,359,"@pgrosu Thank you for the information. Your suggestion might be a way to port DeepVariant on Spark, but it's not fit on dynamic allocation since the available resource is dynamic changed. . I did port several popular bioinformatics tools (e.g. BWA, GATK, DELLY2, Samtools, ...) on Spark and they run well. I think the fundamental problem is that the resource configuration (intra_op_parallelism_threads=1, inter_op_parallelism_threads=1) of TensorFlow doesn't work. If there is no way to limit CPU resource on DeepVariant, should I submit this issue to TensorFlow GitHub?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:159,testability,resourc,resource,159,"@pgrosu Thank you for the information. Your suggestion might be a way to port DeepVariant on Spark, but it's not fit on dynamic allocation since the available resource is dynamic changed. . I did port several popular bioinformatics tools (e.g. BWA, GATK, DELLY2, Samtools, ...) on Spark and they run well. I think the fundamental problem is that the resource configuration (intra_op_parallelism_threads=1, inter_op_parallelism_threads=1) of TensorFlow doesn't work. If there is no way to limit CPU resource on DeepVariant, should I submit this issue to TensorFlow GitHub?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:350,testability,resourc,resource,350,"@pgrosu Thank you for the information. Your suggestion might be a way to port DeepVariant on Spark, but it's not fit on dynamic allocation since the available resource is dynamic changed. . I did port several popular bioinformatics tools (e.g. BWA, GATK, DELLY2, Samtools, ...) on Spark and they run well. I think the fundamental problem is that the resource configuration (intra_op_parallelism_threads=1, inter_op_parallelism_threads=1) of TensorFlow doesn't work. If there is no way to limit CPU resource on DeepVariant, should I submit this issue to TensorFlow GitHub?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:498,testability,resourc,resource,498,"@pgrosu Thank you for the information. Your suggestion might be a way to port DeepVariant on Spark, but it's not fit on dynamic allocation since the available resource is dynamic changed. . I did port several popular bioinformatics tools (e.g. BWA, GATK, DELLY2, Samtools, ...) on Spark and they run well. I think the fundamental problem is that the resource configuration (intra_op_parallelism_threads=1, inter_op_parallelism_threads=1) of TensorFlow doesn't work. If there is no way to limit CPU resource on DeepVariant, should I submit this issue to TensorFlow GitHub?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:232,usability,tool,tools,232,"@pgrosu Thank you for the information. Your suggestion might be a way to port DeepVariant on Spark, but it's not fit on dynamic allocation since the available resource is dynamic changed. . I did port several popular bioinformatics tools (e.g. BWA, GATK, DELLY2, Samtools, ...) on Spark and they run well. I think the fundamental problem is that the resource configuration (intra_op_parallelism_threads=1, inter_op_parallelism_threads=1) of TensorFlow doesn't work. If there is no way to limit CPU resource on DeepVariant, should I submit this issue to TensorFlow GitHub?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:10,reliability,doe,does,10,"Hi,. This does seem like a better question for tensorflow. If tensorflow itself doesn't have the capability to do this, DeepVariant likely won't be able to do it. Let us know what you find. If there's something we can add, let me know.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:80,reliability,doe,doesn,80,"Hi,. This does seem like a better question for tensorflow. If tensorflow itself doesn't have the capability to do this, DeepVariant likely won't be able to do it. Let us know what you find. If there's something we can add, let me know.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/90:42,usability,feedback,feedback,42,@pichuan and @pgrosu : Thank you for your feedback. Will keep you posted on the issue.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/90
https://github.com/google/deepvariant/issues/91:463,deployability,scale,scale,463,"Hi,. As you can see from our training case study, for larger datasets, we shuffled it on a distributed runner (dataflow). I think Beam also supports other things like Spark, but I have not tried it myself. This shuffling code achieves two things: 1. Shuffle the examples, 2. Count the number of examples. Shuffling is important for training a model. Internally our tensorflow code does some extra shuffling in each batch, but that might not be enough on a global scale. I think a global shuffling is a better practice from a machine learning perspective. But empirically it might also be ok to not shuffle globally. The other thing that you'll need is the total number of training examples, which I think you can find in the log when you made the examples (but you'll need to sum them up across the shards). The number of examples is used in the calculation of learning rate. You can certainly try without shuffling, but it's not the best practice I'd recommend. Let me know if it works for you. If you find a good way to shuffle on Spark or other distributed system that you'd like to share, that will be great! Please let me know.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/91
https://github.com/google/deepvariant/issues/91:725,deployability,log,log,725,"Hi,. As you can see from our training case study, for larger datasets, we shuffled it on a distributed runner (dataflow). I think Beam also supports other things like Spark, but I have not tried it myself. This shuffling code achieves two things: 1. Shuffle the examples, 2. Count the number of examples. Shuffling is important for training a model. Internally our tensorflow code does some extra shuffling in each batch, but that might not be enough on a global scale. I think a global shuffling is a better practice from a machine learning perspective. But empirically it might also be ok to not shuffle globally. The other thing that you'll need is the total number of training examples, which I think you can find in the log when you made the examples (but you'll need to sum them up across the shards). The number of examples is used in the calculation of learning rate. You can certainly try without shuffling, but it's not the best practice I'd recommend. Let me know if it works for you. If you find a good way to shuffle on Spark or other distributed system that you'd like to share, that will be great! Please let me know.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/91
https://github.com/google/deepvariant/issues/91:343,energy efficiency,model,model,343,"Hi,. As you can see from our training case study, for larger datasets, we shuffled it on a distributed runner (dataflow). I think Beam also supports other things like Spark, but I have not tried it myself. This shuffling code achieves two things: 1. Shuffle the examples, 2. Count the number of examples. Shuffling is important for training a model. Internally our tensorflow code does some extra shuffling in each batch, but that might not be enough on a global scale. I think a global shuffling is a better practice from a machine learning perspective. But empirically it might also be ok to not shuffle globally. The other thing that you'll need is the total number of training examples, which I think you can find in the log when you made the examples (but you'll need to sum them up across the shards). The number of examples is used in the calculation of learning rate. You can certainly try without shuffling, but it's not the best practice I'd recommend. Let me know if it works for you. If you find a good way to shuffle on Spark or other distributed system that you'd like to share, that will be great! Please let me know.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/91
https://github.com/google/deepvariant/issues/91:463,energy efficiency,scale,scale,463,"Hi,. As you can see from our training case study, for larger datasets, we shuffled it on a distributed runner (dataflow). I think Beam also supports other things like Spark, but I have not tried it myself. This shuffling code achieves two things: 1. Shuffle the examples, 2. Count the number of examples. Shuffling is important for training a model. Internally our tensorflow code does some extra shuffling in each batch, but that might not be enough on a global scale. I think a global shuffling is a better practice from a machine learning perspective. But empirically it might also be ok to not shuffle globally. The other thing that you'll need is the total number of training examples, which I think you can find in the log when you made the examples (but you'll need to sum them up across the shards). The number of examples is used in the calculation of learning rate. You can certainly try without shuffling, but it's not the best practice I'd recommend. Let me know if it works for you. If you find a good way to shuffle on Spark or other distributed system that you'd like to share, that will be great! Please let me know.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/91
https://github.com/google/deepvariant/issues/91:415,integrability,batch,batch,415,"Hi,. As you can see from our training case study, for larger datasets, we shuffled it on a distributed runner (dataflow). I think Beam also supports other things like Spark, but I have not tried it myself. This shuffling code achieves two things: 1. Shuffle the examples, 2. Count the number of examples. Shuffling is important for training a model. Internally our tensorflow code does some extra shuffling in each batch, but that might not be enough on a global scale. I think a global shuffling is a better practice from a machine learning perspective. But empirically it might also be ok to not shuffle globally. The other thing that you'll need is the total number of training examples, which I think you can find in the log when you made the examples (but you'll need to sum them up across the shards). The number of examples is used in the calculation of learning rate. You can certainly try without shuffling, but it's not the best practice I'd recommend. Let me know if it works for you. If you find a good way to shuffle on Spark or other distributed system that you'd like to share, that will be great! Please let me know.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/91
https://github.com/google/deepvariant/issues/91:91,interoperability,distribut,distributed,91,"Hi,. As you can see from our training case study, for larger datasets, we shuffled it on a distributed runner (dataflow). I think Beam also supports other things like Spark, but I have not tried it myself. This shuffling code achieves two things: 1. Shuffle the examples, 2. Count the number of examples. Shuffling is important for training a model. Internally our tensorflow code does some extra shuffling in each batch, but that might not be enough on a global scale. I think a global shuffling is a better practice from a machine learning perspective. But empirically it might also be ok to not shuffle globally. The other thing that you'll need is the total number of training examples, which I think you can find in the log when you made the examples (but you'll need to sum them up across the shards). The number of examples is used in the calculation of learning rate. You can certainly try without shuffling, but it's not the best practice I'd recommend. Let me know if it works for you. If you find a good way to shuffle on Spark or other distributed system that you'd like to share, that will be great! Please let me know.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/91
https://github.com/google/deepvariant/issues/91:1048,interoperability,distribut,distributed,1048,"Hi,. As you can see from our training case study, for larger datasets, we shuffled it on a distributed runner (dataflow). I think Beam also supports other things like Spark, but I have not tried it myself. This shuffling code achieves two things: 1. Shuffle the examples, 2. Count the number of examples. Shuffling is important for training a model. Internally our tensorflow code does some extra shuffling in each batch, but that might not be enough on a global scale. I think a global shuffling is a better practice from a machine learning perspective. But empirically it might also be ok to not shuffle globally. The other thing that you'll need is the total number of training examples, which I think you can find in the log when you made the examples (but you'll need to sum them up across the shards). The number of examples is used in the calculation of learning rate. You can certainly try without shuffling, but it's not the best practice I'd recommend. Let me know if it works for you. If you find a good way to shuffle on Spark or other distributed system that you'd like to share, that will be great! Please let me know.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/91
https://github.com/google/deepvariant/issues/91:1086,interoperability,share,share,1086,"Hi,. As you can see from our training case study, for larger datasets, we shuffled it on a distributed runner (dataflow). I think Beam also supports other things like Spark, but I have not tried it myself. This shuffling code achieves two things: 1. Shuffle the examples, 2. Count the number of examples. Shuffling is important for training a model. Internally our tensorflow code does some extra shuffling in each batch, but that might not be enough on a global scale. I think a global shuffling is a better practice from a machine learning perspective. But empirically it might also be ok to not shuffle globally. The other thing that you'll need is the total number of training examples, which I think you can find in the log when you made the examples (but you'll need to sum them up across the shards). The number of examples is used in the calculation of learning rate. You can certainly try without shuffling, but it's not the best practice I'd recommend. Let me know if it works for you. If you find a good way to shuffle on Spark or other distributed system that you'd like to share, that will be great! Please let me know.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/91
https://github.com/google/deepvariant/issues/91:463,modifiability,scal,scale,463,"Hi,. As you can see from our training case study, for larger datasets, we shuffled it on a distributed runner (dataflow). I think Beam also supports other things like Spark, but I have not tried it myself. This shuffling code achieves two things: 1. Shuffle the examples, 2. Count the number of examples. Shuffling is important for training a model. Internally our tensorflow code does some extra shuffling in each batch, but that might not be enough on a global scale. I think a global shuffling is a better practice from a machine learning perspective. But empirically it might also be ok to not shuffle globally. The other thing that you'll need is the total number of training examples, which I think you can find in the log when you made the examples (but you'll need to sum them up across the shards). The number of examples is used in the calculation of learning rate. You can certainly try without shuffling, but it's not the best practice I'd recommend. Let me know if it works for you. If you find a good way to shuffle on Spark or other distributed system that you'd like to share, that will be great! Please let me know.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/91
https://github.com/google/deepvariant/issues/91:415,performance,batch,batch,415,"Hi,. As you can see from our training case study, for larger datasets, we shuffled it on a distributed runner (dataflow). I think Beam also supports other things like Spark, but I have not tried it myself. This shuffling code achieves two things: 1. Shuffle the examples, 2. Count the number of examples. Shuffling is important for training a model. Internally our tensorflow code does some extra shuffling in each batch, but that might not be enough on a global scale. I think a global shuffling is a better practice from a machine learning perspective. But empirically it might also be ok to not shuffle globally. The other thing that you'll need is the total number of training examples, which I think you can find in the log when you made the examples (but you'll need to sum them up across the shards). The number of examples is used in the calculation of learning rate. You can certainly try without shuffling, but it's not the best practice I'd recommend. Let me know if it works for you. If you find a good way to shuffle on Spark or other distributed system that you'd like to share, that will be great! Please let me know.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/91
https://github.com/google/deepvariant/issues/91:463,performance,scale,scale,463,"Hi,. As you can see from our training case study, for larger datasets, we shuffled it on a distributed runner (dataflow). I think Beam also supports other things like Spark, but I have not tried it myself. This shuffling code achieves two things: 1. Shuffle the examples, 2. Count the number of examples. Shuffling is important for training a model. Internally our tensorflow code does some extra shuffling in each batch, but that might not be enough on a global scale. I think a global shuffling is a better practice from a machine learning perspective. But empirically it might also be ok to not shuffle globally. The other thing that you'll need is the total number of training examples, which I think you can find in the log when you made the examples (but you'll need to sum them up across the shards). The number of examples is used in the calculation of learning rate. You can certainly try without shuffling, but it's not the best practice I'd recommend. Let me know if it works for you. If you find a good way to shuffle on Spark or other distributed system that you'd like to share, that will be great! Please let me know.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/91
https://github.com/google/deepvariant/issues/91:381,reliability,doe,does,381,"Hi,. As you can see from our training case study, for larger datasets, we shuffled it on a distributed runner (dataflow). I think Beam also supports other things like Spark, but I have not tried it myself. This shuffling code achieves two things: 1. Shuffle the examples, 2. Count the number of examples. Shuffling is important for training a model. Internally our tensorflow code does some extra shuffling in each batch, but that might not be enough on a global scale. I think a global shuffling is a better practice from a machine learning perspective. But empirically it might also be ok to not shuffle globally. The other thing that you'll need is the total number of training examples, which I think you can find in the log when you made the examples (but you'll need to sum them up across the shards). The number of examples is used in the calculation of learning rate. You can certainly try without shuffling, but it's not the best practice I'd recommend. Let me know if it works for you. If you find a good way to shuffle on Spark or other distributed system that you'd like to share, that will be great! Please let me know.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/91
https://github.com/google/deepvariant/issues/91:509,reliability,pra,practice,509,"Hi,. As you can see from our training case study, for larger datasets, we shuffled it on a distributed runner (dataflow). I think Beam also supports other things like Spark, but I have not tried it myself. This shuffling code achieves two things: 1. Shuffle the examples, 2. Count the number of examples. Shuffling is important for training a model. Internally our tensorflow code does some extra shuffling in each batch, but that might not be enough on a global scale. I think a global shuffling is a better practice from a machine learning perspective. But empirically it might also be ok to not shuffle globally. The other thing that you'll need is the total number of training examples, which I think you can find in the log when you made the examples (but you'll need to sum them up across the shards). The number of examples is used in the calculation of learning rate. You can certainly try without shuffling, but it's not the best practice I'd recommend. Let me know if it works for you. If you find a good way to shuffle on Spark or other distributed system that you'd like to share, that will be great! Please let me know.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/91
https://github.com/google/deepvariant/issues/91:939,reliability,pra,practice,939,"Hi,. As you can see from our training case study, for larger datasets, we shuffled it on a distributed runner (dataflow). I think Beam also supports other things like Spark, but I have not tried it myself. This shuffling code achieves two things: 1. Shuffle the examples, 2. Count the number of examples. Shuffling is important for training a model. Internally our tensorflow code does some extra shuffling in each batch, but that might not be enough on a global scale. I think a global shuffling is a better practice from a machine learning perspective. But empirically it might also be ok to not shuffle globally. The other thing that you'll need is the total number of training examples, which I think you can find in the log when you made the examples (but you'll need to sum them up across the shards). The number of examples is used in the calculation of learning rate. You can certainly try without shuffling, but it's not the best practice I'd recommend. Let me know if it works for you. If you find a good way to shuffle on Spark or other distributed system that you'd like to share, that will be great! Please let me know.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/91
https://github.com/google/deepvariant/issues/91:725,safety,log,log,725,"Hi,. As you can see from our training case study, for larger datasets, we shuffled it on a distributed runner (dataflow). I think Beam also supports other things like Spark, but I have not tried it myself. This shuffling code achieves two things: 1. Shuffle the examples, 2. Count the number of examples. Shuffling is important for training a model. Internally our tensorflow code does some extra shuffling in each batch, but that might not be enough on a global scale. I think a global shuffling is a better practice from a machine learning perspective. But empirically it might also be ok to not shuffle globally. The other thing that you'll need is the total number of training examples, which I think you can find in the log when you made the examples (but you'll need to sum them up across the shards). The number of examples is used in the calculation of learning rate. You can certainly try without shuffling, but it's not the best practice I'd recommend. Let me know if it works for you. If you find a good way to shuffle on Spark or other distributed system that you'd like to share, that will be great! Please let me know.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/91
https://github.com/google/deepvariant/issues/91:343,security,model,model,343,"Hi,. As you can see from our training case study, for larger datasets, we shuffled it on a distributed runner (dataflow). I think Beam also supports other things like Spark, but I have not tried it myself. This shuffling code achieves two things: 1. Shuffle the examples, 2. Count the number of examples. Shuffling is important for training a model. Internally our tensorflow code does some extra shuffling in each batch, but that might not be enough on a global scale. I think a global shuffling is a better practice from a machine learning perspective. But empirically it might also be ok to not shuffle globally. The other thing that you'll need is the total number of training examples, which I think you can find in the log when you made the examples (but you'll need to sum them up across the shards). The number of examples is used in the calculation of learning rate. You can certainly try without shuffling, but it's not the best practice I'd recommend. Let me know if it works for you. If you find a good way to shuffle on Spark or other distributed system that you'd like to share, that will be great! Please let me know.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/91
https://github.com/google/deepvariant/issues/91:725,security,log,log,725,"Hi,. As you can see from our training case study, for larger datasets, we shuffled it on a distributed runner (dataflow). I think Beam also supports other things like Spark, but I have not tried it myself. This shuffling code achieves two things: 1. Shuffle the examples, 2. Count the number of examples. Shuffling is important for training a model. Internally our tensorflow code does some extra shuffling in each batch, but that might not be enough on a global scale. I think a global shuffling is a better practice from a machine learning perspective. But empirically it might also be ok to not shuffle globally. The other thing that you'll need is the total number of training examples, which I think you can find in the log when you made the examples (but you'll need to sum them up across the shards). The number of examples is used in the calculation of learning rate. You can certainly try without shuffling, but it's not the best practice I'd recommend. Let me know if it works for you. If you find a good way to shuffle on Spark or other distributed system that you'd like to share, that will be great! Please let me know.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/91
https://github.com/google/deepvariant/issues/91:725,testability,log,log,725,"Hi,. As you can see from our training case study, for larger datasets, we shuffled it on a distributed runner (dataflow). I think Beam also supports other things like Spark, but I have not tried it myself. This shuffling code achieves two things: 1. Shuffle the examples, 2. Count the number of examples. Shuffling is important for training a model. Internally our tensorflow code does some extra shuffling in each batch, but that might not be enough on a global scale. I think a global shuffling is a better practice from a machine learning perspective. But empirically it might also be ok to not shuffle globally. The other thing that you'll need is the total number of training examples, which I think you can find in the log when you made the examples (but you'll need to sum them up across the shards). The number of examples is used in the calculation of learning rate. You can certainly try without shuffling, but it's not the best practice I'd recommend. Let me know if it works for you. If you find a good way to shuffle on Spark or other distributed system that you'd like to share, that will be great! Please let me know.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/91
https://github.com/google/deepvariant/issues/91:140,usability,support,supports,140,"Hi,. As you can see from our training case study, for larger datasets, we shuffled it on a distributed runner (dataflow). I think Beam also supports other things like Spark, but I have not tried it myself. This shuffling code achieves two things: 1. Shuffle the examples, 2. Count the number of examples. Shuffling is important for training a model. Internally our tensorflow code does some extra shuffling in each batch, but that might not be enough on a global scale. I think a global shuffling is a better practice from a machine learning perspective. But empirically it might also be ok to not shuffle globally. The other thing that you'll need is the total number of training examples, which I think you can find in the log when you made the examples (but you'll need to sum them up across the shards). The number of examples is used in the calculation of learning rate. You can certainly try without shuffling, but it's not the best practice I'd recommend. Let me know if it works for you. If you find a good way to shuffle on Spark or other distributed system that you'd like to share, that will be great! Please let me know.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/91
https://github.com/google/deepvariant/issues/91:533,usability,learn,learning,533,"Hi,. As you can see from our training case study, for larger datasets, we shuffled it on a distributed runner (dataflow). I think Beam also supports other things like Spark, but I have not tried it myself. This shuffling code achieves two things: 1. Shuffle the examples, 2. Count the number of examples. Shuffling is important for training a model. Internally our tensorflow code does some extra shuffling in each batch, but that might not be enough on a global scale. I think a global shuffling is a better practice from a machine learning perspective. But empirically it might also be ok to not shuffle globally. The other thing that you'll need is the total number of training examples, which I think you can find in the log when you made the examples (but you'll need to sum them up across the shards). The number of examples is used in the calculation of learning rate. You can certainly try without shuffling, but it's not the best practice I'd recommend. Let me know if it works for you. If you find a good way to shuffle on Spark or other distributed system that you'd like to share, that will be great! Please let me know.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/91
https://github.com/google/deepvariant/issues/91:861,usability,learn,learning,861,"Hi,. As you can see from our training case study, for larger datasets, we shuffled it on a distributed runner (dataflow). I think Beam also supports other things like Spark, but I have not tried it myself. This shuffling code achieves two things: 1. Shuffle the examples, 2. Count the number of examples. Shuffling is important for training a model. Internally our tensorflow code does some extra shuffling in each batch, but that might not be enough on a global scale. I think a global shuffling is a better practice from a machine learning perspective. But empirically it might also be ok to not shuffle globally. The other thing that you'll need is the total number of training examples, which I think you can find in the log when you made the examples (but you'll need to sum them up across the shards). The number of examples is used in the calculation of learning rate. You can certainly try without shuffling, but it's not the best practice I'd recommend. Let me know if it works for you. If you find a good way to shuffle on Spark or other distributed system that you'd like to share, that will be great! Please let me know.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/91
https://github.com/google/deepvariant/issues/91:284,energy efficiency,model,model,284,"Hi, pichuan. Thanks for your help. I just change the name of tfrecord file to shuffle the training dataset. Is it OK to use this way to shuffle the training dataset? This way is introduced from ""Improve DeepVariant for . BGISEQ germline variant calling"" file. The accuracy of trained model have raised compared with trained model without shuffling. But I'm not sure whether it is the highest accuracy performance. I don't know how to shuffle on Spark. Maybe I would try to shuffle on Spark in future.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/91
https://github.com/google/deepvariant/issues/91:324,energy efficiency,model,model,324,"Hi, pichuan. Thanks for your help. I just change the name of tfrecord file to shuffle the training dataset. Is it OK to use this way to shuffle the training dataset? This way is introduced from ""Improve DeepVariant for . BGISEQ germline variant calling"" file. The accuracy of trained model have raised compared with trained model without shuffling. But I'm not sure whether it is the highest accuracy performance. I don't know how to shuffle on Spark. Maybe I would try to shuffle on Spark in future.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/91
https://github.com/google/deepvariant/issues/91:401,performance,perform,performance,401,"Hi, pichuan. Thanks for your help. I just change the name of tfrecord file to shuffle the training dataset. Is it OK to use this way to shuffle the training dataset? This way is introduced from ""Improve DeepVariant for . BGISEQ germline variant calling"" file. The accuracy of trained model have raised compared with trained model without shuffling. But I'm not sure whether it is the highest accuracy performance. I don't know how to shuffle on Spark. Maybe I would try to shuffle on Spark in future.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/91
https://github.com/google/deepvariant/issues/91:284,security,model,model,284,"Hi, pichuan. Thanks for your help. I just change the name of tfrecord file to shuffle the training dataset. Is it OK to use this way to shuffle the training dataset? This way is introduced from ""Improve DeepVariant for . BGISEQ germline variant calling"" file. The accuracy of trained model have raised compared with trained model without shuffling. But I'm not sure whether it is the highest accuracy performance. I don't know how to shuffle on Spark. Maybe I would try to shuffle on Spark in future.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/91
https://github.com/google/deepvariant/issues/91:324,security,model,model,324,"Hi, pichuan. Thanks for your help. I just change the name of tfrecord file to shuffle the training dataset. Is it OK to use this way to shuffle the training dataset? This way is introduced from ""Improve DeepVariant for . BGISEQ germline variant calling"" file. The accuracy of trained model have raised compared with trained model without shuffling. But I'm not sure whether it is the highest accuracy performance. I don't know how to shuffle on Spark. Maybe I would try to shuffle on Spark in future.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/91
https://github.com/google/deepvariant/issues/91:29,usability,help,help,29,"Hi, pichuan. Thanks for your help. I just change the name of tfrecord file to shuffle the training dataset. Is it OK to use this way to shuffle the training dataset? This way is introduced from ""Improve DeepVariant for . BGISEQ germline variant calling"" file. The accuracy of trained model have raised compared with trained model without shuffling. But I'm not sure whether it is the highest accuracy performance. I don't know how to shuffle on Spark. Maybe I would try to shuffle on Spark in future.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/91
https://github.com/google/deepvariant/issues/91:401,usability,perform,performance,401,"Hi, pichuan. Thanks for your help. I just change the name of tfrecord file to shuffle the training dataset. Is it OK to use this way to shuffle the training dataset? This way is introduced from ""Improve DeepVariant for . BGISEQ germline variant calling"" file. The accuracy of trained model have raised compared with trained model without shuffling. But I'm not sure whether it is the highest accuracy performance. I don't know how to shuffle on Spark. Maybe I would try to shuffle on Spark in future.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/91
https://github.com/google/deepvariant/issues/91:150,availability,operat,operations,150,@ssm0808 FYI on how to shuffle on Spark: http://people.apache.org/~pwendell/spark-nightly/spark-master-docs/latest/rdd-programming-guide.html#shuffle-operations,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/91
https://github.com/google/deepvariant/issues/91:131,usability,guid,guide,131,@ssm0808 FYI on how to shuffle on Spark: http://people.apache.org/~pwendell/spark-nightly/spark-master-docs/latest/rdd-programming-guide.html#shuffle-operations,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/91
https://github.com/google/deepvariant/issues/91:263,availability,Down,Downside,263,"Just for the record, I wrote a script which shuffles the records locally using as little memory as possible: [TFrecordShuffler](https://github.com/GuillaumeHolley/TFrecordShuffler). It uses about as much RAM as the total size of the input (record) files on disk. Downside is obviously the time it takes which is much longer than with a distributed google cloud or spark system I imagine. As an example, shuffling ~30 million records totaling 125 GB of files took 46h (wall-clock and CPU) and 150 GB of RAM.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/91
https://github.com/google/deepvariant/issues/91:355,energy efficiency,cloud,cloud,355,"Just for the record, I wrote a script which shuffles the records locally using as little memory as possible: [TFrecordShuffler](https://github.com/GuillaumeHolley/TFrecordShuffler). It uses about as much RAM as the total size of the input (record) files on disk. Downside is obviously the time it takes which is much longer than with a distributed google cloud or spark system I imagine. As an example, shuffling ~30 million records totaling 125 GB of files took 46h (wall-clock and CPU) and 150 GB of RAM.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/91
https://github.com/google/deepvariant/issues/91:473,energy efficiency,clock,clock,473,"Just for the record, I wrote a script which shuffles the records locally using as little memory as possible: [TFrecordShuffler](https://github.com/GuillaumeHolley/TFrecordShuffler). It uses about as much RAM as the total size of the input (record) files on disk. Downside is obviously the time it takes which is much longer than with a distributed google cloud or spark system I imagine. As an example, shuffling ~30 million records totaling 125 GB of files took 46h (wall-clock and CPU) and 150 GB of RAM.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/91
https://github.com/google/deepvariant/issues/91:483,energy efficiency,CPU,CPU,483,"Just for the record, I wrote a script which shuffles the records locally using as little memory as possible: [TFrecordShuffler](https://github.com/GuillaumeHolley/TFrecordShuffler). It uses about as much RAM as the total size of the input (record) files on disk. Downside is obviously the time it takes which is much longer than with a distributed google cloud or spark system I imagine. As an example, shuffling ~30 million records totaling 125 GB of files took 46h (wall-clock and CPU) and 150 GB of RAM.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/91
https://github.com/google/deepvariant/issues/91:336,interoperability,distribut,distributed,336,"Just for the record, I wrote a script which shuffles the records locally using as little memory as possible: [TFrecordShuffler](https://github.com/GuillaumeHolley/TFrecordShuffler). It uses about as much RAM as the total size of the input (record) files on disk. Downside is obviously the time it takes which is much longer than with a distributed google cloud or spark system I imagine. As an example, shuffling ~30 million records totaling 125 GB of files took 46h (wall-clock and CPU) and 150 GB of RAM.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/91
https://github.com/google/deepvariant/issues/91:89,performance,memor,memory,89,"Just for the record, I wrote a script which shuffles the records locally using as little memory as possible: [TFrecordShuffler](https://github.com/GuillaumeHolley/TFrecordShuffler). It uses about as much RAM as the total size of the input (record) files on disk. Downside is obviously the time it takes which is much longer than with a distributed google cloud or spark system I imagine. As an example, shuffling ~30 million records totaling 125 GB of files took 46h (wall-clock and CPU) and 150 GB of RAM.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/91
https://github.com/google/deepvariant/issues/91:257,performance,disk,disk,257,"Just for the record, I wrote a script which shuffles the records locally using as little memory as possible: [TFrecordShuffler](https://github.com/GuillaumeHolley/TFrecordShuffler). It uses about as much RAM as the total size of the input (record) files on disk. Downside is obviously the time it takes which is much longer than with a distributed google cloud or spark system I imagine. As an example, shuffling ~30 million records totaling 125 GB of files took 46h (wall-clock and CPU) and 150 GB of RAM.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/91
https://github.com/google/deepvariant/issues/91:289,performance,time,time,289,"Just for the record, I wrote a script which shuffles the records locally using as little memory as possible: [TFrecordShuffler](https://github.com/GuillaumeHolley/TFrecordShuffler). It uses about as much RAM as the total size of the input (record) files on disk. Downside is obviously the time it takes which is much longer than with a distributed google cloud or spark system I imagine. As an example, shuffling ~30 million records totaling 125 GB of files took 46h (wall-clock and CPU) and 150 GB of RAM.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/91
https://github.com/google/deepvariant/issues/91:483,performance,CPU,CPU,483,"Just for the record, I wrote a script which shuffles the records locally using as little memory as possible: [TFrecordShuffler](https://github.com/GuillaumeHolley/TFrecordShuffler). It uses about as much RAM as the total size of the input (record) files on disk. Downside is obviously the time it takes which is much longer than with a distributed google cloud or spark system I imagine. As an example, shuffling ~30 million records totaling 125 GB of files took 46h (wall-clock and CPU) and 150 GB of RAM.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/91
https://github.com/google/deepvariant/issues/91:233,safety,input,input,233,"Just for the record, I wrote a script which shuffles the records locally using as little memory as possible: [TFrecordShuffler](https://github.com/GuillaumeHolley/TFrecordShuffler). It uses about as much RAM as the total size of the input (record) files on disk. Downside is obviously the time it takes which is much longer than with a distributed google cloud or spark system I imagine. As an example, shuffling ~30 million records totaling 125 GB of files took 46h (wall-clock and CPU) and 150 GB of RAM.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/91
https://github.com/google/deepvariant/issues/91:89,usability,memor,memory,89,"Just for the record, I wrote a script which shuffles the records locally using as little memory as possible: [TFrecordShuffler](https://github.com/GuillaumeHolley/TFrecordShuffler). It uses about as much RAM as the total size of the input (record) files on disk. Downside is obviously the time it takes which is much longer than with a distributed google cloud or spark system I imagine. As an example, shuffling ~30 million records totaling 125 GB of files took 46h (wall-clock and CPU) and 150 GB of RAM.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/91
https://github.com/google/deepvariant/issues/91:233,usability,input,input,233,"Just for the record, I wrote a script which shuffles the records locally using as little memory as possible: [TFrecordShuffler](https://github.com/GuillaumeHolley/TFrecordShuffler). It uses about as much RAM as the total size of the input (record) files on disk. Downside is obviously the time it takes which is much longer than with a distributed google cloud or spark system I imagine. As an example, shuffling ~30 million records totaling 125 GB of files took 46h (wall-clock and CPU) and 150 GB of RAM.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/91
https://github.com/google/deepvariant/issues/92:443,availability,robust,robust,443,"(1) Have you considered using docker instead of the prebuilt binaries? In this version, we updated the quick start and case studies to use docker. I personally find that much more convenient. . (2) For bazel, can you try the official instructions: https://docs.bazel.build/versions/master/install-ubuntu.html. Last time I tried our script on a Ubuntu 16 machine on GCP, it worked. But maybe I should try one not on GCP. If you find out a more robust installation for bazel, please share and I can update our instructions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/92
https://github.com/google/deepvariant/issues/92:79,deployability,version,version,79,"(1) Have you considered using docker instead of the prebuilt binaries? In this version, we updated the quick start and case studies to use docker. I personally find that much more convenient. . (2) For bazel, can you try the official instructions: https://docs.bazel.build/versions/master/install-ubuntu.html. Last time I tried our script on a Ubuntu 16 machine on GCP, it worked. But maybe I should try one not on GCP. If you find out a more robust installation for bazel, please share and I can update our instructions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/92
https://github.com/google/deepvariant/issues/92:91,deployability,updat,updated,91,"(1) Have you considered using docker instead of the prebuilt binaries? In this version, we updated the quick start and case studies to use docker. I personally find that much more convenient. . (2) For bazel, can you try the official instructions: https://docs.bazel.build/versions/master/install-ubuntu.html. Last time I tried our script on a Ubuntu 16 machine on GCP, it worked. But maybe I should try one not on GCP. If you find out a more robust installation for bazel, please share and I can update our instructions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/92
https://github.com/google/deepvariant/issues/92:267,deployability,build,build,267,"(1) Have you considered using docker instead of the prebuilt binaries? In this version, we updated the quick start and case studies to use docker. I personally find that much more convenient. . (2) For bazel, can you try the official instructions: https://docs.bazel.build/versions/master/install-ubuntu.html. Last time I tried our script on a Ubuntu 16 machine on GCP, it worked. But maybe I should try one not on GCP. If you find out a more robust installation for bazel, please share and I can update our instructions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/92
https://github.com/google/deepvariant/issues/92:273,deployability,version,versions,273,"(1) Have you considered using docker instead of the prebuilt binaries? In this version, we updated the quick start and case studies to use docker. I personally find that much more convenient. . (2) For bazel, can you try the official instructions: https://docs.bazel.build/versions/master/install-ubuntu.html. Last time I tried our script on a Ubuntu 16 machine on GCP, it worked. But maybe I should try one not on GCP. If you find out a more robust installation for bazel, please share and I can update our instructions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/92
https://github.com/google/deepvariant/issues/92:289,deployability,instal,install-ubuntu,289,"(1) Have you considered using docker instead of the prebuilt binaries? In this version, we updated the quick start and case studies to use docker. I personally find that much more convenient. . (2) For bazel, can you try the official instructions: https://docs.bazel.build/versions/master/install-ubuntu.html. Last time I tried our script on a Ubuntu 16 machine on GCP, it worked. But maybe I should try one not on GCP. If you find out a more robust installation for bazel, please share and I can update our instructions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/92
https://github.com/google/deepvariant/issues/92:450,deployability,instal,installation,450,"(1) Have you considered using docker instead of the prebuilt binaries? In this version, we updated the quick start and case studies to use docker. I personally find that much more convenient. . (2) For bazel, can you try the official instructions: https://docs.bazel.build/versions/master/install-ubuntu.html. Last time I tried our script on a Ubuntu 16 machine on GCP, it worked. But maybe I should try one not on GCP. If you find out a more robust installation for bazel, please share and I can update our instructions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/92
https://github.com/google/deepvariant/issues/92:497,deployability,updat,update,497,"(1) Have you considered using docker instead of the prebuilt binaries? In this version, we updated the quick start and case studies to use docker. I personally find that much more convenient. . (2) For bazel, can you try the official instructions: https://docs.bazel.build/versions/master/install-ubuntu.html. Last time I tried our script on a Ubuntu 16 machine on GCP, it worked. But maybe I should try one not on GCP. If you find out a more robust installation for bazel, please share and I can update our instructions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/92
https://github.com/google/deepvariant/issues/92:79,integrability,version,version,79,"(1) Have you considered using docker instead of the prebuilt binaries? In this version, we updated the quick start and case studies to use docker. I personally find that much more convenient. . (2) For bazel, can you try the official instructions: https://docs.bazel.build/versions/master/install-ubuntu.html. Last time I tried our script on a Ubuntu 16 machine on GCP, it worked. But maybe I should try one not on GCP. If you find out a more robust installation for bazel, please share and I can update our instructions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/92
https://github.com/google/deepvariant/issues/92:273,integrability,version,versions,273,"(1) Have you considered using docker instead of the prebuilt binaries? In this version, we updated the quick start and case studies to use docker. I personally find that much more convenient. . (2) For bazel, can you try the official instructions: https://docs.bazel.build/versions/master/install-ubuntu.html. Last time I tried our script on a Ubuntu 16 machine on GCP, it worked. But maybe I should try one not on GCP. If you find out a more robust installation for bazel, please share and I can update our instructions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/92
https://github.com/google/deepvariant/issues/92:481,interoperability,share,share,481,"(1) Have you considered using docker instead of the prebuilt binaries? In this version, we updated the quick start and case studies to use docker. I personally find that much more convenient. . (2) For bazel, can you try the official instructions: https://docs.bazel.build/versions/master/install-ubuntu.html. Last time I tried our script on a Ubuntu 16 machine on GCP, it worked. But maybe I should try one not on GCP. If you find out a more robust installation for bazel, please share and I can update our instructions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/92
https://github.com/google/deepvariant/issues/92:79,modifiability,version,version,79,"(1) Have you considered using docker instead of the prebuilt binaries? In this version, we updated the quick start and case studies to use docker. I personally find that much more convenient. . (2) For bazel, can you try the official instructions: https://docs.bazel.build/versions/master/install-ubuntu.html. Last time I tried our script on a Ubuntu 16 machine on GCP, it worked. But maybe I should try one not on GCP. If you find out a more robust installation for bazel, please share and I can update our instructions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/92
https://github.com/google/deepvariant/issues/92:273,modifiability,version,versions,273,"(1) Have you considered using docker instead of the prebuilt binaries? In this version, we updated the quick start and case studies to use docker. I personally find that much more convenient. . (2) For bazel, can you try the official instructions: https://docs.bazel.build/versions/master/install-ubuntu.html. Last time I tried our script on a Ubuntu 16 machine on GCP, it worked. But maybe I should try one not on GCP. If you find out a more robust installation for bazel, please share and I can update our instructions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/92
https://github.com/google/deepvariant/issues/92:315,performance,time,time,315,"(1) Have you considered using docker instead of the prebuilt binaries? In this version, we updated the quick start and case studies to use docker. I personally find that much more convenient. . (2) For bazel, can you try the official instructions: https://docs.bazel.build/versions/master/install-ubuntu.html. Last time I tried our script on a Ubuntu 16 machine on GCP, it worked. But maybe I should try one not on GCP. If you find out a more robust installation for bazel, please share and I can update our instructions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/92
https://github.com/google/deepvariant/issues/92:443,reliability,robust,robust,443,"(1) Have you considered using docker instead of the prebuilt binaries? In this version, we updated the quick start and case studies to use docker. I personally find that much more convenient. . (2) For bazel, can you try the official instructions: https://docs.bazel.build/versions/master/install-ubuntu.html. Last time I tried our script on a Ubuntu 16 machine on GCP, it worked. But maybe I should try one not on GCP. If you find out a more robust installation for bazel, please share and I can update our instructions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/92
https://github.com/google/deepvariant/issues/92:91,safety,updat,updated,91,"(1) Have you considered using docker instead of the prebuilt binaries? In this version, we updated the quick start and case studies to use docker. I personally find that much more convenient. . (2) For bazel, can you try the official instructions: https://docs.bazel.build/versions/master/install-ubuntu.html. Last time I tried our script on a Ubuntu 16 machine on GCP, it worked. But maybe I should try one not on GCP. If you find out a more robust installation for bazel, please share and I can update our instructions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/92
https://github.com/google/deepvariant/issues/92:443,safety,robust,robust,443,"(1) Have you considered using docker instead of the prebuilt binaries? In this version, we updated the quick start and case studies to use docker. I personally find that much more convenient. . (2) For bazel, can you try the official instructions: https://docs.bazel.build/versions/master/install-ubuntu.html. Last time I tried our script on a Ubuntu 16 machine on GCP, it worked. But maybe I should try one not on GCP. If you find out a more robust installation for bazel, please share and I can update our instructions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/92
https://github.com/google/deepvariant/issues/92:497,safety,updat,update,497,"(1) Have you considered using docker instead of the prebuilt binaries? In this version, we updated the quick start and case studies to use docker. I personally find that much more convenient. . (2) For bazel, can you try the official instructions: https://docs.bazel.build/versions/master/install-ubuntu.html. Last time I tried our script on a Ubuntu 16 machine on GCP, it worked. But maybe I should try one not on GCP. If you find out a more robust installation for bazel, please share and I can update our instructions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/92
https://github.com/google/deepvariant/issues/92:91,security,updat,updated,91,"(1) Have you considered using docker instead of the prebuilt binaries? In this version, we updated the quick start and case studies to use docker. I personally find that much more convenient. . (2) For bazel, can you try the official instructions: https://docs.bazel.build/versions/master/install-ubuntu.html. Last time I tried our script on a Ubuntu 16 machine on GCP, it worked. But maybe I should try one not on GCP. If you find out a more robust installation for bazel, please share and I can update our instructions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/92
https://github.com/google/deepvariant/issues/92:497,security,updat,update,497,"(1) Have you considered using docker instead of the prebuilt binaries? In this version, we updated the quick start and case studies to use docker. I personally find that much more convenient. . (2) For bazel, can you try the official instructions: https://docs.bazel.build/versions/master/install-ubuntu.html. Last time I tried our script on a Ubuntu 16 machine on GCP, it worked. But maybe I should try one not on GCP. If you find out a more robust installation for bazel, please share and I can update our instructions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/92
https://github.com/google/deepvariant/issues/92:149,usability,person,personally,149,"(1) Have you considered using docker instead of the prebuilt binaries? In this version, we updated the quick start and case studies to use docker. I personally find that much more convenient. . (2) For bazel, can you try the official instructions: https://docs.bazel.build/versions/master/install-ubuntu.html. Last time I tried our script on a Ubuntu 16 machine on GCP, it worked. But maybe I should try one not on GCP. If you find out a more robust installation for bazel, please share and I can update our instructions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/92
https://github.com/google/deepvariant/issues/93:139,deployability,updat,update,139,"Hi @ramcn,. Just go into the WORKSPACE file at the following location:. https://github.com/google/deepvariant/blob/r0.7/WORKSPACE#L87. And update your path to the full path of `opt` - (below is an example):. ```. new_local_repository(. name = ""clif"",. build_file = ""third_party/clif.BUILD"",. path = ""/home/ramcn/opt"",. ). ```. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/93
https://github.com/google/deepvariant/issues/93:283,deployability,BUILD,BUILD,283,"Hi @ramcn,. Just go into the WORKSPACE file at the following location:. https://github.com/google/deepvariant/blob/r0.7/WORKSPACE#L87. And update your path to the full path of `opt` - (below is an example):. ```. new_local_repository(. name = ""clif"",. build_file = ""third_party/clif.BUILD"",. path = ""/home/ramcn/opt"",. ). ```. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/93
https://github.com/google/deepvariant/issues/93:139,safety,updat,update,139,"Hi @ramcn,. Just go into the WORKSPACE file at the following location:. https://github.com/google/deepvariant/blob/r0.7/WORKSPACE#L87. And update your path to the full path of `opt` - (below is an example):. ```. new_local_repository(. name = ""clif"",. build_file = ""third_party/clif.BUILD"",. path = ""/home/ramcn/opt"",. ). ```. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/93
https://github.com/google/deepvariant/issues/93:139,security,updat,update,139,"Hi @ramcn,. Just go into the WORKSPACE file at the following location:. https://github.com/google/deepvariant/blob/r0.7/WORKSPACE#L87. And update your path to the full path of `opt` - (below is an example):. ```. new_local_repository(. name = ""clif"",. build_file = ""third_party/clif.BUILD"",. path = ""/home/ramcn/opt"",. ). ```. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/93
https://github.com/google/deepvariant/issues/93:18,usability,help,helped,18,"Thanks Paul. That helped! Cheers,. Ram",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/93
https://github.com/google/deepvariant/issues/93:8,usability,help,helped,8,"Glad it helped Ram :). Best,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/93
https://github.com/google/deepvariant/issues/94:19,deployability,updat,update,19,"Hi Ram,. Could you update the script on the bazel lines with `--verbose_failures`, rerun and show us the log. I'm assuming you have plenty of memory and CPU resources, which means that either you are not on Ubuntu or have an older GCC. What's your Linux distribution and GCC version? Thanks,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:105,deployability,log,log,105,"Hi Ram,. Could you update the script on the bazel lines with `--verbose_failures`, rerun and show us the log. I'm assuming you have plenty of memory and CPU resources, which means that either you are not on Ubuntu or have an older GCC. What's your Linux distribution and GCC version? Thanks,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:157,deployability,resourc,resources,157,"Hi Ram,. Could you update the script on the bazel lines with `--verbose_failures`, rerun and show us the log. I'm assuming you have plenty of memory and CPU resources, which means that either you are not on Ubuntu or have an older GCC. What's your Linux distribution and GCC version? Thanks,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:275,deployability,version,version,275,"Hi Ram,. Could you update the script on the bazel lines with `--verbose_failures`, rerun and show us the log. I'm assuming you have plenty of memory and CPU resources, which means that either you are not on Ubuntu or have an older GCC. What's your Linux distribution and GCC version? Thanks,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:153,energy efficiency,CPU,CPU,153,"Hi Ram,. Could you update the script on the bazel lines with `--verbose_failures`, rerun and show us the log. I'm assuming you have plenty of memory and CPU resources, which means that either you are not on Ubuntu or have an older GCC. What's your Linux distribution and GCC version? Thanks,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:157,energy efficiency,resourc,resources,157,"Hi Ram,. Could you update the script on the bazel lines with `--verbose_failures`, rerun and show us the log. I'm assuming you have plenty of memory and CPU resources, which means that either you are not on Ubuntu or have an older GCC. What's your Linux distribution and GCC version? Thanks,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:275,integrability,version,version,275,"Hi Ram,. Could you update the script on the bazel lines with `--verbose_failures`, rerun and show us the log. I'm assuming you have plenty of memory and CPU resources, which means that either you are not on Ubuntu or have an older GCC. What's your Linux distribution and GCC version? Thanks,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:254,interoperability,distribut,distribution,254,"Hi Ram,. Could you update the script on the bazel lines with `--verbose_failures`, rerun and show us the log. I'm assuming you have plenty of memory and CPU resources, which means that either you are not on Ubuntu or have an older GCC. What's your Linux distribution and GCC version? Thanks,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:275,modifiability,version,version,275,"Hi Ram,. Could you update the script on the bazel lines with `--verbose_failures`, rerun and show us the log. I'm assuming you have plenty of memory and CPU resources, which means that either you are not on Ubuntu or have an older GCC. What's your Linux distribution and GCC version? Thanks,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:142,performance,memor,memory,142,"Hi Ram,. Could you update the script on the bazel lines with `--verbose_failures`, rerun and show us the log. I'm assuming you have plenty of memory and CPU resources, which means that either you are not on Ubuntu or have an older GCC. What's your Linux distribution and GCC version? Thanks,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:153,performance,CPU,CPU,153,"Hi Ram,. Could you update the script on the bazel lines with `--verbose_failures`, rerun and show us the log. I'm assuming you have plenty of memory and CPU resources, which means that either you are not on Ubuntu or have an older GCC. What's your Linux distribution and GCC version? Thanks,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:157,performance,resourc,resources,157,"Hi Ram,. Could you update the script on the bazel lines with `--verbose_failures`, rerun and show us the log. I'm assuming you have plenty of memory and CPU resources, which means that either you are not on Ubuntu or have an older GCC. What's your Linux distribution and GCC version? Thanks,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:19,safety,updat,update,19,"Hi Ram,. Could you update the script on the bazel lines with `--verbose_failures`, rerun and show us the log. I'm assuming you have plenty of memory and CPU resources, which means that either you are not on Ubuntu or have an older GCC. What's your Linux distribution and GCC version? Thanks,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:105,safety,log,log,105,"Hi Ram,. Could you update the script on the bazel lines with `--verbose_failures`, rerun and show us the log. I'm assuming you have plenty of memory and CPU resources, which means that either you are not on Ubuntu or have an older GCC. What's your Linux distribution and GCC version? Thanks,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:157,safety,resourc,resources,157,"Hi Ram,. Could you update the script on the bazel lines with `--verbose_failures`, rerun and show us the log. I'm assuming you have plenty of memory and CPU resources, which means that either you are not on Ubuntu or have an older GCC. What's your Linux distribution and GCC version? Thanks,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:19,security,updat,update,19,"Hi Ram,. Could you update the script on the bazel lines with `--verbose_failures`, rerun and show us the log. I'm assuming you have plenty of memory and CPU resources, which means that either you are not on Ubuntu or have an older GCC. What's your Linux distribution and GCC version? Thanks,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:105,security,log,log,105,"Hi Ram,. Could you update the script on the bazel lines with `--verbose_failures`, rerun and show us the log. I'm assuming you have plenty of memory and CPU resources, which means that either you are not on Ubuntu or have an older GCC. What's your Linux distribution and GCC version? Thanks,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:105,testability,log,log,105,"Hi Ram,. Could you update the script on the bazel lines with `--verbose_failures`, rerun and show us the log. I'm assuming you have plenty of memory and CPU resources, which means that either you are not on Ubuntu or have an older GCC. What's your Linux distribution and GCC version? Thanks,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:157,testability,resourc,resources,157,"Hi Ram,. Could you update the script on the bazel lines with `--verbose_failures`, rerun and show us the log. I'm assuming you have plenty of memory and CPU resources, which means that either you are not on Ubuntu or have an older GCC. What's your Linux distribution and GCC version? Thanks,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:142,usability,memor,memory,142,"Hi Ram,. Could you update the script on the bazel lines with `--verbose_failures`, rerun and show us the log. I'm assuming you have plenty of memory and CPU resources, which means that either you are not on Ubuntu or have an older GCC. What's your Linux distribution and GCC version? Thanks,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:164,availability,cluster,cluster,164,". [log1.txt](https://github.com/google/deepvariant/files/2393958/log1.txt). Hi Paul,. Attached is the log with --verbose_failures. Yes I am using a node on our HPC cluster. Some more details about my environment:. 1. gcc version 4.8.5. 2. centos 7. 3. protobuf version 3.5.1 installed as module with PATH and LD_LIB_PATH set accordingly. 4. clif installed under HOME directory and WORKSPACE updated accordingly. Thank you. Ram",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:102,deployability,log,log,102,". [log1.txt](https://github.com/google/deepvariant/files/2393958/log1.txt). Hi Paul,. Attached is the log with --verbose_failures. Yes I am using a node on our HPC cluster. Some more details about my environment:. 1. gcc version 4.8.5. 2. centos 7. 3. protobuf version 3.5.1 installed as module with PATH and LD_LIB_PATH set accordingly. 4. clif installed under HOME directory and WORKSPACE updated accordingly. Thank you. Ram",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:164,deployability,cluster,cluster,164,". [log1.txt](https://github.com/google/deepvariant/files/2393958/log1.txt). Hi Paul,. Attached is the log with --verbose_failures. Yes I am using a node on our HPC cluster. Some more details about my environment:. 1. gcc version 4.8.5. 2. centos 7. 3. protobuf version 3.5.1 installed as module with PATH and LD_LIB_PATH set accordingly. 4. clif installed under HOME directory and WORKSPACE updated accordingly. Thank you. Ram",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:221,deployability,version,version,221,". [log1.txt](https://github.com/google/deepvariant/files/2393958/log1.txt). Hi Paul,. Attached is the log with --verbose_failures. Yes I am using a node on our HPC cluster. Some more details about my environment:. 1. gcc version 4.8.5. 2. centos 7. 3. protobuf version 3.5.1 installed as module with PATH and LD_LIB_PATH set accordingly. 4. clif installed under HOME directory and WORKSPACE updated accordingly. Thank you. Ram",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:261,deployability,version,version,261,". [log1.txt](https://github.com/google/deepvariant/files/2393958/log1.txt). Hi Paul,. Attached is the log with --verbose_failures. Yes I am using a node on our HPC cluster. Some more details about my environment:. 1. gcc version 4.8.5. 2. centos 7. 3. protobuf version 3.5.1 installed as module with PATH and LD_LIB_PATH set accordingly. 4. clif installed under HOME directory and WORKSPACE updated accordingly. Thank you. Ram",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:275,deployability,instal,installed,275,". [log1.txt](https://github.com/google/deepvariant/files/2393958/log1.txt). Hi Paul,. Attached is the log with --verbose_failures. Yes I am using a node on our HPC cluster. Some more details about my environment:. 1. gcc version 4.8.5. 2. centos 7. 3. protobuf version 3.5.1 installed as module with PATH and LD_LIB_PATH set accordingly. 4. clif installed under HOME directory and WORKSPACE updated accordingly. Thank you. Ram",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:288,deployability,modul,module,288,". [log1.txt](https://github.com/google/deepvariant/files/2393958/log1.txt). Hi Paul,. Attached is the log with --verbose_failures. Yes I am using a node on our HPC cluster. Some more details about my environment:. 1. gcc version 4.8.5. 2. centos 7. 3. protobuf version 3.5.1 installed as module with PATH and LD_LIB_PATH set accordingly. 4. clif installed under HOME directory and WORKSPACE updated accordingly. Thank you. Ram",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:346,deployability,instal,installed,346,". [log1.txt](https://github.com/google/deepvariant/files/2393958/log1.txt). Hi Paul,. Attached is the log with --verbose_failures. Yes I am using a node on our HPC cluster. Some more details about my environment:. 1. gcc version 4.8.5. 2. centos 7. 3. protobuf version 3.5.1 installed as module with PATH and LD_LIB_PATH set accordingly. 4. clif installed under HOME directory and WORKSPACE updated accordingly. Thank you. Ram",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:391,deployability,updat,updated,391,". [log1.txt](https://github.com/google/deepvariant/files/2393958/log1.txt). Hi Paul,. Attached is the log with --verbose_failures. Yes I am using a node on our HPC cluster. Some more details about my environment:. 1. gcc version 4.8.5. 2. centos 7. 3. protobuf version 3.5.1 installed as module with PATH and LD_LIB_PATH set accordingly. 4. clif installed under HOME directory and WORKSPACE updated accordingly. Thank you. Ram",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:221,integrability,version,version,221,". [log1.txt](https://github.com/google/deepvariant/files/2393958/log1.txt). Hi Paul,. Attached is the log with --verbose_failures. Yes I am using a node on our HPC cluster. Some more details about my environment:. 1. gcc version 4.8.5. 2. centos 7. 3. protobuf version 3.5.1 installed as module with PATH and LD_LIB_PATH set accordingly. 4. clif installed under HOME directory and WORKSPACE updated accordingly. Thank you. Ram",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:261,integrability,version,version,261,". [log1.txt](https://github.com/google/deepvariant/files/2393958/log1.txt). Hi Paul,. Attached is the log with --verbose_failures. Yes I am using a node on our HPC cluster. Some more details about my environment:. 1. gcc version 4.8.5. 2. centos 7. 3. protobuf version 3.5.1 installed as module with PATH and LD_LIB_PATH set accordingly. 4. clif installed under HOME directory and WORKSPACE updated accordingly. Thank you. Ram",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:221,modifiability,version,version,221,". [log1.txt](https://github.com/google/deepvariant/files/2393958/log1.txt). Hi Paul,. Attached is the log with --verbose_failures. Yes I am using a node on our HPC cluster. Some more details about my environment:. 1. gcc version 4.8.5. 2. centos 7. 3. protobuf version 3.5.1 installed as module with PATH and LD_LIB_PATH set accordingly. 4. clif installed under HOME directory and WORKSPACE updated accordingly. Thank you. Ram",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:261,modifiability,version,version,261,". [log1.txt](https://github.com/google/deepvariant/files/2393958/log1.txt). Hi Paul,. Attached is the log with --verbose_failures. Yes I am using a node on our HPC cluster. Some more details about my environment:. 1. gcc version 4.8.5. 2. centos 7. 3. protobuf version 3.5.1 installed as module with PATH and LD_LIB_PATH set accordingly. 4. clif installed under HOME directory and WORKSPACE updated accordingly. Thank you. Ram",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:288,modifiability,modul,module,288,". [log1.txt](https://github.com/google/deepvariant/files/2393958/log1.txt). Hi Paul,. Attached is the log with --verbose_failures. Yes I am using a node on our HPC cluster. Some more details about my environment:. 1. gcc version 4.8.5. 2. centos 7. 3. protobuf version 3.5.1 installed as module with PATH and LD_LIB_PATH set accordingly. 4. clif installed under HOME directory and WORKSPACE updated accordingly. Thank you. Ram",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:102,safety,log,log,102,". [log1.txt](https://github.com/google/deepvariant/files/2393958/log1.txt). Hi Paul,. Attached is the log with --verbose_failures. Yes I am using a node on our HPC cluster. Some more details about my environment:. 1. gcc version 4.8.5. 2. centos 7. 3. protobuf version 3.5.1 installed as module with PATH and LD_LIB_PATH set accordingly. 4. clif installed under HOME directory and WORKSPACE updated accordingly. Thank you. Ram",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:288,safety,modul,module,288,". [log1.txt](https://github.com/google/deepvariant/files/2393958/log1.txt). Hi Paul,. Attached is the log with --verbose_failures. Yes I am using a node on our HPC cluster. Some more details about my environment:. 1. gcc version 4.8.5. 2. centos 7. 3. protobuf version 3.5.1 installed as module with PATH and LD_LIB_PATH set accordingly. 4. clif installed under HOME directory and WORKSPACE updated accordingly. Thank you. Ram",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:391,safety,updat,updated,391,". [log1.txt](https://github.com/google/deepvariant/files/2393958/log1.txt). Hi Paul,. Attached is the log with --verbose_failures. Yes I am using a node on our HPC cluster. Some more details about my environment:. 1. gcc version 4.8.5. 2. centos 7. 3. protobuf version 3.5.1 installed as module with PATH and LD_LIB_PATH set accordingly. 4. clif installed under HOME directory and WORKSPACE updated accordingly. Thank you. Ram",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:102,security,log,log,102,". [log1.txt](https://github.com/google/deepvariant/files/2393958/log1.txt). Hi Paul,. Attached is the log with --verbose_failures. Yes I am using a node on our HPC cluster. Some more details about my environment:. 1. gcc version 4.8.5. 2. centos 7. 3. protobuf version 3.5.1 installed as module with PATH and LD_LIB_PATH set accordingly. 4. clif installed under HOME directory and WORKSPACE updated accordingly. Thank you. Ram",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:391,security,updat,updated,391,". [log1.txt](https://github.com/google/deepvariant/files/2393958/log1.txt). Hi Paul,. Attached is the log with --verbose_failures. Yes I am using a node on our HPC cluster. Some more details about my environment:. 1. gcc version 4.8.5. 2. centos 7. 3. protobuf version 3.5.1 installed as module with PATH and LD_LIB_PATH set accordingly. 4. clif installed under HOME directory and WORKSPACE updated accordingly. Thank you. Ram",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:102,testability,log,log,102,". [log1.txt](https://github.com/google/deepvariant/files/2393958/log1.txt). Hi Paul,. Attached is the log with --verbose_failures. Yes I am using a node on our HPC cluster. Some more details about my environment:. 1. gcc version 4.8.5. 2. centos 7. 3. protobuf version 3.5.1 installed as module with PATH and LD_LIB_PATH set accordingly. 4. clif installed under HOME directory and WORKSPACE updated accordingly. Thank you. Ram",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:529,availability,cluster,cluster,529,". Hi Ram,. I see what's happening. You have protobuf 3.5.1 in your include paths, but this is trying to compile the protobuf 3.6 version. You will notice in this line:. ```. new (initial_block_) Block(options_.initial_block_size, NULL);. ```. Which is only part of `3.6.x`:. https://github.com/protocolbuffers/protobuf/blob/3.6.x/src/google/protobuf/arena.cc#L77. Basically a bunch of conflicts between declarations and use. So to simplify things, could you remove your protobuf 3.5.1 from your paths. If you are on a university cluster, it's usually something like `module unload MODULE_NAME`. After that try rerunning it again. Thanks,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:129,deployability,version,version,129,". Hi Ram,. I see what's happening. You have protobuf 3.5.1 in your include paths, but this is trying to compile the protobuf 3.6 version. You will notice in this line:. ```. new (initial_block_) Block(options_.initial_block_size, NULL);. ```. Which is only part of `3.6.x`:. https://github.com/protocolbuffers/protobuf/blob/3.6.x/src/google/protobuf/arena.cc#L77. Basically a bunch of conflicts between declarations and use. So to simplify things, could you remove your protobuf 3.5.1 from your paths. If you are on a university cluster, it's usually something like `module unload MODULE_NAME`. After that try rerunning it again. Thanks,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:529,deployability,cluster,cluster,529,". Hi Ram,. I see what's happening. You have protobuf 3.5.1 in your include paths, but this is trying to compile the protobuf 3.6 version. You will notice in this line:. ```. new (initial_block_) Block(options_.initial_block_size, NULL);. ```. Which is only part of `3.6.x`:. https://github.com/protocolbuffers/protobuf/blob/3.6.x/src/google/protobuf/arena.cc#L77. Basically a bunch of conflicts between declarations and use. So to simplify things, could you remove your protobuf 3.5.1 from your paths. If you are on a university cluster, it's usually something like `module unload MODULE_NAME`. After that try rerunning it again. Thanks,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:567,deployability,modul,module,567,". Hi Ram,. I see what's happening. You have protobuf 3.5.1 in your include paths, but this is trying to compile the protobuf 3.6 version. You will notice in this line:. ```. new (initial_block_) Block(options_.initial_block_size, NULL);. ```. Which is only part of `3.6.x`:. https://github.com/protocolbuffers/protobuf/blob/3.6.x/src/google/protobuf/arena.cc#L77. Basically a bunch of conflicts between declarations and use. So to simplify things, could you remove your protobuf 3.5.1 from your paths. If you are on a university cluster, it's usually something like `module unload MODULE_NAME`. After that try rerunning it again. Thanks,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:574,deployability,unload,unload,574,". Hi Ram,. I see what's happening. You have protobuf 3.5.1 in your include paths, but this is trying to compile the protobuf 3.6 version. You will notice in this line:. ```. new (initial_block_) Block(options_.initial_block_size, NULL);. ```. Which is only part of `3.6.x`:. https://github.com/protocolbuffers/protobuf/blob/3.6.x/src/google/protobuf/arena.cc#L77. Basically a bunch of conflicts between declarations and use. So to simplify things, could you remove your protobuf 3.5.1 from your paths. If you are on a university cluster, it's usually something like `module unload MODULE_NAME`. After that try rerunning it again. Thanks,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:129,integrability,version,version,129,". Hi Ram,. I see what's happening. You have protobuf 3.5.1 in your include paths, but this is trying to compile the protobuf 3.6 version. You will notice in this line:. ```. new (initial_block_) Block(options_.initial_block_size, NULL);. ```. Which is only part of `3.6.x`:. https://github.com/protocolbuffers/protobuf/blob/3.6.x/src/google/protobuf/arena.cc#L77. Basically a bunch of conflicts between declarations and use. So to simplify things, could you remove your protobuf 3.5.1 from your paths. If you are on a university cluster, it's usually something like `module unload MODULE_NAME`. After that try rerunning it again. Thanks,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:294,integrability,protocol,protocolbuffers,294,". Hi Ram,. I see what's happening. You have protobuf 3.5.1 in your include paths, but this is trying to compile the protobuf 3.6 version. You will notice in this line:. ```. new (initial_block_) Block(options_.initial_block_size, NULL);. ```. Which is only part of `3.6.x`:. https://github.com/protocolbuffers/protobuf/blob/3.6.x/src/google/protobuf/arena.cc#L77. Basically a bunch of conflicts between declarations and use. So to simplify things, could you remove your protobuf 3.5.1 from your paths. If you are on a university cluster, it's usually something like `module unload MODULE_NAME`. After that try rerunning it again. Thanks,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:294,interoperability,protocol,protocolbuffers,294,". Hi Ram,. I see what's happening. You have protobuf 3.5.1 in your include paths, but this is trying to compile the protobuf 3.6 version. You will notice in this line:. ```. new (initial_block_) Block(options_.initial_block_size, NULL);. ```. Which is only part of `3.6.x`:. https://github.com/protocolbuffers/protobuf/blob/3.6.x/src/google/protobuf/arena.cc#L77. Basically a bunch of conflicts between declarations and use. So to simplify things, could you remove your protobuf 3.5.1 from your paths. If you are on a university cluster, it's usually something like `module unload MODULE_NAME`. After that try rerunning it again. Thanks,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:385,interoperability,conflict,conflicts,385,". Hi Ram,. I see what's happening. You have protobuf 3.5.1 in your include paths, but this is trying to compile the protobuf 3.6 version. You will notice in this line:. ```. new (initial_block_) Block(options_.initial_block_size, NULL);. ```. Which is only part of `3.6.x`:. https://github.com/protocolbuffers/protobuf/blob/3.6.x/src/google/protobuf/arena.cc#L77. Basically a bunch of conflicts between declarations and use. So to simplify things, could you remove your protobuf 3.5.1 from your paths. If you are on a university cluster, it's usually something like `module unload MODULE_NAME`. After that try rerunning it again. Thanks,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:129,modifiability,version,version,129,". Hi Ram,. I see what's happening. You have protobuf 3.5.1 in your include paths, but this is trying to compile the protobuf 3.6 version. You will notice in this line:. ```. new (initial_block_) Block(options_.initial_block_size, NULL);. ```. Which is only part of `3.6.x`:. https://github.com/protocolbuffers/protobuf/blob/3.6.x/src/google/protobuf/arena.cc#L77. Basically a bunch of conflicts between declarations and use. So to simplify things, could you remove your protobuf 3.5.1 from your paths. If you are on a university cluster, it's usually something like `module unload MODULE_NAME`. After that try rerunning it again. Thanks,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:567,modifiability,modul,module,567,". Hi Ram,. I see what's happening. You have protobuf 3.5.1 in your include paths, but this is trying to compile the protobuf 3.6 version. You will notice in this line:. ```. new (initial_block_) Block(options_.initial_block_size, NULL);. ```. Which is only part of `3.6.x`:. https://github.com/protocolbuffers/protobuf/blob/3.6.x/src/google/protobuf/arena.cc#L77. Basically a bunch of conflicts between declarations and use. So to simplify things, could you remove your protobuf 3.5.1 from your paths. If you are on a university cluster, it's usually something like `module unload MODULE_NAME`. After that try rerunning it again. Thanks,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:567,safety,modul,module,567,". Hi Ram,. I see what's happening. You have protobuf 3.5.1 in your include paths, but this is trying to compile the protobuf 3.6 version. You will notice in this line:. ```. new (initial_block_) Block(options_.initial_block_size, NULL);. ```. Which is only part of `3.6.x`:. https://github.com/protocolbuffers/protobuf/blob/3.6.x/src/google/protobuf/arena.cc#L77. Basically a bunch of conflicts between declarations and use. So to simplify things, could you remove your protobuf 3.5.1 from your paths. If you are on a university cluster, it's usually something like `module unload MODULE_NAME`. After that try rerunning it again. Thanks,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:431,testability,simpl,simplify,431,". Hi Ram,. I see what's happening. You have protobuf 3.5.1 in your include paths, but this is trying to compile the protobuf 3.6 version. You will notice in this line:. ```. new (initial_block_) Block(options_.initial_block_size, NULL);. ```. Which is only part of `3.6.x`:. https://github.com/protocolbuffers/protobuf/blob/3.6.x/src/google/protobuf/arena.cc#L77. Basically a bunch of conflicts between declarations and use. So to simplify things, could you remove your protobuf 3.5.1 from your paths. If you are on a university cluster, it's usually something like `module unload MODULE_NAME`. After that try rerunning it again. Thanks,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:431,usability,simpl,simplify,431,". Hi Ram,. I see what's happening. You have protobuf 3.5.1 in your include paths, but this is trying to compile the protobuf 3.6 version. You will notice in this line:. ```. new (initial_block_) Block(options_.initial_block_size, NULL);. ```. Which is only part of `3.6.x`:. https://github.com/protocolbuffers/protobuf/blob/3.6.x/src/google/protobuf/arena.cc#L77. Basically a bunch of conflicts between declarations and use. So to simplify things, could you remove your protobuf 3.5.1 from your paths. If you are on a university cluster, it's usually something like `module unload MODULE_NAME`. After that try rerunning it again. Thanks,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:167,availability,error,error,167,"Hi Paul,. I simplified my setup a bit and have removed protobuf in my PATHs. I was able to complete the build, but most of the tests seem to be failing with the below error. TypeError: __new__() got an unexpected keyword argument 'serialized_options'. Attached is the log with verbose failures. Please let me know if you have any clue. [log2.txt](https://github.com/google/deepvariant/files/2397845/log2.txt).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:285,availability,failur,failures,285,"Hi Paul,. I simplified my setup a bit and have removed protobuf in my PATHs. I was able to complete the build, but most of the tests seem to be failing with the below error. TypeError: __new__() got an unexpected keyword argument 'serialized_options'. Attached is the log with verbose failures. Please let me know if you have any clue. [log2.txt](https://github.com/google/deepvariant/files/2397845/log2.txt).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:104,deployability,build,build,104,"Hi Paul,. I simplified my setup a bit and have removed protobuf in my PATHs. I was able to complete the build, but most of the tests seem to be failing with the below error. TypeError: __new__() got an unexpected keyword argument 'serialized_options'. Attached is the log with verbose failures. Please let me know if you have any clue. [log2.txt](https://github.com/google/deepvariant/files/2397845/log2.txt).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:144,deployability,fail,failing,144,"Hi Paul,. I simplified my setup a bit and have removed protobuf in my PATHs. I was able to complete the build, but most of the tests seem to be failing with the below error. TypeError: __new__() got an unexpected keyword argument 'serialized_options'. Attached is the log with verbose failures. Please let me know if you have any clue. [log2.txt](https://github.com/google/deepvariant/files/2397845/log2.txt).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:268,deployability,log,log,268,"Hi Paul,. I simplified my setup a bit and have removed protobuf in my PATHs. I was able to complete the build, but most of the tests seem to be failing with the below error. TypeError: __new__() got an unexpected keyword argument 'serialized_options'. Attached is the log with verbose failures. Please let me know if you have any clue. [log2.txt](https://github.com/google/deepvariant/files/2397845/log2.txt).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:285,deployability,fail,failures,285,"Hi Paul,. I simplified my setup a bit and have removed protobuf in my PATHs. I was able to complete the build, but most of the tests seem to be failing with the below error. TypeError: __new__() got an unexpected keyword argument 'serialized_options'. Attached is the log with verbose failures. Please let me know if you have any clue. [log2.txt](https://github.com/google/deepvariant/files/2397845/log2.txt).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:167,performance,error,error,167,"Hi Paul,. I simplified my setup a bit and have removed protobuf in my PATHs. I was able to complete the build, but most of the tests seem to be failing with the below error. TypeError: __new__() got an unexpected keyword argument 'serialized_options'. Attached is the log with verbose failures. Please let me know if you have any clue. [log2.txt](https://github.com/google/deepvariant/files/2397845/log2.txt).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:285,performance,failur,failures,285,"Hi Paul,. I simplified my setup a bit and have removed protobuf in my PATHs. I was able to complete the build, but most of the tests seem to be failing with the below error. TypeError: __new__() got an unexpected keyword argument 'serialized_options'. Attached is the log with verbose failures. Please let me know if you have any clue. [log2.txt](https://github.com/google/deepvariant/files/2397845/log2.txt).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:144,reliability,fail,failing,144,"Hi Paul,. I simplified my setup a bit and have removed protobuf in my PATHs. I was able to complete the build, but most of the tests seem to be failing with the below error. TypeError: __new__() got an unexpected keyword argument 'serialized_options'. Attached is the log with verbose failures. Please let me know if you have any clue. [log2.txt](https://github.com/google/deepvariant/files/2397845/log2.txt).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:285,reliability,fail,failures,285,"Hi Paul,. I simplified my setup a bit and have removed protobuf in my PATHs. I was able to complete the build, but most of the tests seem to be failing with the below error. TypeError: __new__() got an unexpected keyword argument 'serialized_options'. Attached is the log with verbose failures. Please let me know if you have any clue. [log2.txt](https://github.com/google/deepvariant/files/2397845/log2.txt).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:91,safety,compl,complete,91,"Hi Paul,. I simplified my setup a bit and have removed protobuf in my PATHs. I was able to complete the build, but most of the tests seem to be failing with the below error. TypeError: __new__() got an unexpected keyword argument 'serialized_options'. Attached is the log with verbose failures. Please let me know if you have any clue. [log2.txt](https://github.com/google/deepvariant/files/2397845/log2.txt).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:127,safety,test,tests,127,"Hi Paul,. I simplified my setup a bit and have removed protobuf in my PATHs. I was able to complete the build, but most of the tests seem to be failing with the below error. TypeError: __new__() got an unexpected keyword argument 'serialized_options'. Attached is the log with verbose failures. Please let me know if you have any clue. [log2.txt](https://github.com/google/deepvariant/files/2397845/log2.txt).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:167,safety,error,error,167,"Hi Paul,. I simplified my setup a bit and have removed protobuf in my PATHs. I was able to complete the build, but most of the tests seem to be failing with the below error. TypeError: __new__() got an unexpected keyword argument 'serialized_options'. Attached is the log with verbose failures. Please let me know if you have any clue. [log2.txt](https://github.com/google/deepvariant/files/2397845/log2.txt).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:268,safety,log,log,268,"Hi Paul,. I simplified my setup a bit and have removed protobuf in my PATHs. I was able to complete the build, but most of the tests seem to be failing with the below error. TypeError: __new__() got an unexpected keyword argument 'serialized_options'. Attached is the log with verbose failures. Please let me know if you have any clue. [log2.txt](https://github.com/google/deepvariant/files/2397845/log2.txt).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:91,security,compl,complete,91,"Hi Paul,. I simplified my setup a bit and have removed protobuf in my PATHs. I was able to complete the build, but most of the tests seem to be failing with the below error. TypeError: __new__() got an unexpected keyword argument 'serialized_options'. Attached is the log with verbose failures. Please let me know if you have any clue. [log2.txt](https://github.com/google/deepvariant/files/2397845/log2.txt).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:268,security,log,log,268,"Hi Paul,. I simplified my setup a bit and have removed protobuf in my PATHs. I was able to complete the build, but most of the tests seem to be failing with the below error. TypeError: __new__() got an unexpected keyword argument 'serialized_options'. Attached is the log with verbose failures. Please let me know if you have any clue. [log2.txt](https://github.com/google/deepvariant/files/2397845/log2.txt).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:12,testability,simpl,simplified,12,"Hi Paul,. I simplified my setup a bit and have removed protobuf in my PATHs. I was able to complete the build, but most of the tests seem to be failing with the below error. TypeError: __new__() got an unexpected keyword argument 'serialized_options'. Attached is the log with verbose failures. Please let me know if you have any clue. [log2.txt](https://github.com/google/deepvariant/files/2397845/log2.txt).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:127,testability,test,tests,127,"Hi Paul,. I simplified my setup a bit and have removed protobuf in my PATHs. I was able to complete the build, but most of the tests seem to be failing with the below error. TypeError: __new__() got an unexpected keyword argument 'serialized_options'. Attached is the log with verbose failures. Please let me know if you have any clue. [log2.txt](https://github.com/google/deepvariant/files/2397845/log2.txt).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:268,testability,log,log,268,"Hi Paul,. I simplified my setup a bit and have removed protobuf in my PATHs. I was able to complete the build, but most of the tests seem to be failing with the below error. TypeError: __new__() got an unexpected keyword argument 'serialized_options'. Attached is the log with verbose failures. Please let me know if you have any clue. [log2.txt](https://github.com/google/deepvariant/files/2397845/log2.txt).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:12,usability,simpl,simplified,12,"Hi Paul,. I simplified my setup a bit and have removed protobuf in my PATHs. I was able to complete the build, but most of the tests seem to be failing with the below error. TypeError: __new__() got an unexpected keyword argument 'serialized_options'. Attached is the log with verbose failures. Please let me know if you have any clue. [log2.txt](https://github.com/google/deepvariant/files/2397845/log2.txt).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:167,usability,error,error,167,"Hi Paul,. I simplified my setup a bit and have removed protobuf in my PATHs. I was able to complete the build, but most of the tests seem to be failing with the below error. TypeError: __new__() got an unexpected keyword argument 'serialized_options'. Attached is the log with verbose failures. Please let me know if you have any clue. [log2.txt](https://github.com/google/deepvariant/files/2397845/log2.txt).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:44,availability,error,errors,44,"Hi Ram,. You really do not want to have any errors show up in any of your tests, especially when performing variant calling. It's an easily fixable issue where the Google folks would just need to update their TensorFlow Python package distributed with DeepVariant, which was probably compiled with an earlier version of protobuf, while currently the Tensorflow requires `3.6` of protobuf and the Protobuf version being compiled with DeepVariant is `3.6`. Looking at your log file, you are using the CPU version. The current version on PyPI of TensorFlow is 1.10.1, and DeepVariant uses version 1.9. Here's the process by which I went about to determine what is happening:. 1. If you download both `whl` files of Tensorflow like this:. ```. wget https://storage.googleapis.com/deepvariant/packages/tensorflow/tensorflow-1.9.0.deepvariant_gcp-cp27-none-linux_x86_64.whl. wget https://files.pythonhosted.org/packages/1a/c4/8cb95df0bf06089014259b25997c3921a87aa08e2cd981417d91ca92f7e9/tensorflow-1.10.1-cp27-cp27mu-manylinux1_x86_64.whl. ```. 2. Next rename each of the `whl` files to `zip`, and then uncompress them in separate directories. If you then look at one of the version `1.10.1` files that has the `serialized_options` such as `purelib/tensorflow/core/framework/resource_handle_pb2.py`, you will see the following difference between the versions, where the `serialized_options` keyword is present in the `1.10.1` version, but not in the `1.9.0` version:. #### _*For version 1.9*_. ```Python. DESCRIPTOR = _descriptor.FileDescriptor(. name='tensorflow/core/framework/resource_handle.proto',. package='tensorflow',. syntax='proto3',. serialized_pb=_b('\n/tensorflow/core/framework/resource_handle.proto\x12\ntensorflow\""r\n\x13ResourceHandleProto\x12\x0e\n\x06\x64\x65vice\x18\x01 \x01(\t\x12\x11\n\tcontainer\x18\x02 \x01(\t\x12\x0c\n\x04name\x18\x03 \x01(\t\x12\x11\n\thash_code\x18\x04 \x01(\x04\x12\x17\n\x0fmaybe_type_name\x18\x05 \x01(\tBn\n\x18org.tensorflow.frameworkB\x0eResourceHandleP",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:683,availability,down,download,683,"Hi Ram,. You really do not want to have any errors show up in any of your tests, especially when performing variant calling. It's an easily fixable issue where the Google folks would just need to update their TensorFlow Python package distributed with DeepVariant, which was probably compiled with an earlier version of protobuf, while currently the Tensorflow requires `3.6` of protobuf and the Protobuf version being compiled with DeepVariant is `3.6`. Looking at your log file, you are using the CPU version. The current version on PyPI of TensorFlow is 1.10.1, and DeepVariant uses version 1.9. Here's the process by which I went about to determine what is happening:. 1. If you download both `whl` files of Tensorflow like this:. ```. wget https://storage.googleapis.com/deepvariant/packages/tensorflow/tensorflow-1.9.0.deepvariant_gcp-cp27-none-linux_x86_64.whl. wget https://files.pythonhosted.org/packages/1a/c4/8cb95df0bf06089014259b25997c3921a87aa08e2cd981417d91ca92f7e9/tensorflow-1.10.1-cp27-cp27mu-manylinux1_x86_64.whl. ```. 2. Next rename each of the `whl` files to `zip`, and then uncompress them in separate directories. If you then look at one of the version `1.10.1` files that has the `serialized_options` such as `purelib/tensorflow/core/framework/resource_handle_pb2.py`, you will see the following difference between the versions, where the `serialized_options` keyword is present in the `1.10.1` version, but not in the `1.9.0` version:. #### _*For version 1.9*_. ```Python. DESCRIPTOR = _descriptor.FileDescriptor(. name='tensorflow/core/framework/resource_handle.proto',. package='tensorflow',. syntax='proto3',. serialized_pb=_b('\n/tensorflow/core/framework/resource_handle.proto\x12\ntensorflow\""r\n\x13ResourceHandleProto\x12\x0e\n\x06\x64\x65vice\x18\x01 \x01(\t\x12\x11\n\tcontainer\x18\x02 \x01(\t\x12\x0c\n\x04name\x18\x03 \x01(\t\x12\x11\n\thash_code\x18\x04 \x01(\x04\x12\x17\n\x0fmaybe_type_name\x18\x05 \x01(\tBn\n\x18org.tensorflow.frameworkB\x0eResourceHandleP",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:196,deployability,updat,update,196,"Hi Ram,. You really do not want to have any errors show up in any of your tests, especially when performing variant calling. It's an easily fixable issue where the Google folks would just need to update their TensorFlow Python package distributed with DeepVariant, which was probably compiled with an earlier version of protobuf, while currently the Tensorflow requires `3.6` of protobuf and the Protobuf version being compiled with DeepVariant is `3.6`. Looking at your log file, you are using the CPU version. The current version on PyPI of TensorFlow is 1.10.1, and DeepVariant uses version 1.9. Here's the process by which I went about to determine what is happening:. 1. If you download both `whl` files of Tensorflow like this:. ```. wget https://storage.googleapis.com/deepvariant/packages/tensorflow/tensorflow-1.9.0.deepvariant_gcp-cp27-none-linux_x86_64.whl. wget https://files.pythonhosted.org/packages/1a/c4/8cb95df0bf06089014259b25997c3921a87aa08e2cd981417d91ca92f7e9/tensorflow-1.10.1-cp27-cp27mu-manylinux1_x86_64.whl. ```. 2. Next rename each of the `whl` files to `zip`, and then uncompress them in separate directories. If you then look at one of the version `1.10.1` files that has the `serialized_options` such as `purelib/tensorflow/core/framework/resource_handle_pb2.py`, you will see the following difference between the versions, where the `serialized_options` keyword is present in the `1.10.1` version, but not in the `1.9.0` version:. #### _*For version 1.9*_. ```Python. DESCRIPTOR = _descriptor.FileDescriptor(. name='tensorflow/core/framework/resource_handle.proto',. package='tensorflow',. syntax='proto3',. serialized_pb=_b('\n/tensorflow/core/framework/resource_handle.proto\x12\ntensorflow\""r\n\x13ResourceHandleProto\x12\x0e\n\x06\x64\x65vice\x18\x01 \x01(\t\x12\x11\n\tcontainer\x18\x02 \x01(\t\x12\x0c\n\x04name\x18\x03 \x01(\t\x12\x11\n\thash_code\x18\x04 \x01(\x04\x12\x17\n\x0fmaybe_type_name\x18\x05 \x01(\tBn\n\x18org.tensorflow.frameworkB\x0eResourceHandleP",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:309,deployability,version,version,309,"Hi Ram,. You really do not want to have any errors show up in any of your tests, especially when performing variant calling. It's an easily fixable issue where the Google folks would just need to update their TensorFlow Python package distributed with DeepVariant, which was probably compiled with an earlier version of protobuf, while currently the Tensorflow requires `3.6` of protobuf and the Protobuf version being compiled with DeepVariant is `3.6`. Looking at your log file, you are using the CPU version. The current version on PyPI of TensorFlow is 1.10.1, and DeepVariant uses version 1.9. Here's the process by which I went about to determine what is happening:. 1. If you download both `whl` files of Tensorflow like this:. ```. wget https://storage.googleapis.com/deepvariant/packages/tensorflow/tensorflow-1.9.0.deepvariant_gcp-cp27-none-linux_x86_64.whl. wget https://files.pythonhosted.org/packages/1a/c4/8cb95df0bf06089014259b25997c3921a87aa08e2cd981417d91ca92f7e9/tensorflow-1.10.1-cp27-cp27mu-manylinux1_x86_64.whl. ```. 2. Next rename each of the `whl` files to `zip`, and then uncompress them in separate directories. If you then look at one of the version `1.10.1` files that has the `serialized_options` such as `purelib/tensorflow/core/framework/resource_handle_pb2.py`, you will see the following difference between the versions, where the `serialized_options` keyword is present in the `1.10.1` version, but not in the `1.9.0` version:. #### _*For version 1.9*_. ```Python. DESCRIPTOR = _descriptor.FileDescriptor(. name='tensorflow/core/framework/resource_handle.proto',. package='tensorflow',. syntax='proto3',. serialized_pb=_b('\n/tensorflow/core/framework/resource_handle.proto\x12\ntensorflow\""r\n\x13ResourceHandleProto\x12\x0e\n\x06\x64\x65vice\x18\x01 \x01(\t\x12\x11\n\tcontainer\x18\x02 \x01(\t\x12\x0c\n\x04name\x18\x03 \x01(\t\x12\x11\n\thash_code\x18\x04 \x01(\x04\x12\x17\n\x0fmaybe_type_name\x18\x05 \x01(\tBn\n\x18org.tensorflow.frameworkB\x0eResourceHandleP",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:405,deployability,version,version,405,"Hi Ram,. You really do not want to have any errors show up in any of your tests, especially when performing variant calling. It's an easily fixable issue where the Google folks would just need to update their TensorFlow Python package distributed with DeepVariant, which was probably compiled with an earlier version of protobuf, while currently the Tensorflow requires `3.6` of protobuf and the Protobuf version being compiled with DeepVariant is `3.6`. Looking at your log file, you are using the CPU version. The current version on PyPI of TensorFlow is 1.10.1, and DeepVariant uses version 1.9. Here's the process by which I went about to determine what is happening:. 1. If you download both `whl` files of Tensorflow like this:. ```. wget https://storage.googleapis.com/deepvariant/packages/tensorflow/tensorflow-1.9.0.deepvariant_gcp-cp27-none-linux_x86_64.whl. wget https://files.pythonhosted.org/packages/1a/c4/8cb95df0bf06089014259b25997c3921a87aa08e2cd981417d91ca92f7e9/tensorflow-1.10.1-cp27-cp27mu-manylinux1_x86_64.whl. ```. 2. Next rename each of the `whl` files to `zip`, and then uncompress them in separate directories. If you then look at one of the version `1.10.1` files that has the `serialized_options` such as `purelib/tensorflow/core/framework/resource_handle_pb2.py`, you will see the following difference between the versions, where the `serialized_options` keyword is present in the `1.10.1` version, but not in the `1.9.0` version:. #### _*For version 1.9*_. ```Python. DESCRIPTOR = _descriptor.FileDescriptor(. name='tensorflow/core/framework/resource_handle.proto',. package='tensorflow',. syntax='proto3',. serialized_pb=_b('\n/tensorflow/core/framework/resource_handle.proto\x12\ntensorflow\""r\n\x13ResourceHandleProto\x12\x0e\n\x06\x64\x65vice\x18\x01 \x01(\t\x12\x11\n\tcontainer\x18\x02 \x01(\t\x12\x0c\n\x04name\x18\x03 \x01(\t\x12\x11\n\thash_code\x18\x04 \x01(\x04\x12\x17\n\x0fmaybe_type_name\x18\x05 \x01(\tBn\n\x18org.tensorflow.frameworkB\x0eResourceHandleP",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:471,deployability,log,log,471,"Hi Ram,. You really do not want to have any errors show up in any of your tests, especially when performing variant calling. It's an easily fixable issue where the Google folks would just need to update their TensorFlow Python package distributed with DeepVariant, which was probably compiled with an earlier version of protobuf, while currently the Tensorflow requires `3.6` of protobuf and the Protobuf version being compiled with DeepVariant is `3.6`. Looking at your log file, you are using the CPU version. The current version on PyPI of TensorFlow is 1.10.1, and DeepVariant uses version 1.9. Here's the process by which I went about to determine what is happening:. 1. If you download both `whl` files of Tensorflow like this:. ```. wget https://storage.googleapis.com/deepvariant/packages/tensorflow/tensorflow-1.9.0.deepvariant_gcp-cp27-none-linux_x86_64.whl. wget https://files.pythonhosted.org/packages/1a/c4/8cb95df0bf06089014259b25997c3921a87aa08e2cd981417d91ca92f7e9/tensorflow-1.10.1-cp27-cp27mu-manylinux1_x86_64.whl. ```. 2. Next rename each of the `whl` files to `zip`, and then uncompress them in separate directories. If you then look at one of the version `1.10.1` files that has the `serialized_options` such as `purelib/tensorflow/core/framework/resource_handle_pb2.py`, you will see the following difference between the versions, where the `serialized_options` keyword is present in the `1.10.1` version, but not in the `1.9.0` version:. #### _*For version 1.9*_. ```Python. DESCRIPTOR = _descriptor.FileDescriptor(. name='tensorflow/core/framework/resource_handle.proto',. package='tensorflow',. syntax='proto3',. serialized_pb=_b('\n/tensorflow/core/framework/resource_handle.proto\x12\ntensorflow\""r\n\x13ResourceHandleProto\x12\x0e\n\x06\x64\x65vice\x18\x01 \x01(\t\x12\x11\n\tcontainer\x18\x02 \x01(\t\x12\x0c\n\x04name\x18\x03 \x01(\t\x12\x11\n\thash_code\x18\x04 \x01(\x04\x12\x17\n\x0fmaybe_type_name\x18\x05 \x01(\tBn\n\x18org.tensorflow.frameworkB\x0eResourceHandleP",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:503,deployability,version,version,503,"Hi Ram,. You really do not want to have any errors show up in any of your tests, especially when performing variant calling. It's an easily fixable issue where the Google folks would just need to update their TensorFlow Python package distributed with DeepVariant, which was probably compiled with an earlier version of protobuf, while currently the Tensorflow requires `3.6` of protobuf and the Protobuf version being compiled with DeepVariant is `3.6`. Looking at your log file, you are using the CPU version. The current version on PyPI of TensorFlow is 1.10.1, and DeepVariant uses version 1.9. Here's the process by which I went about to determine what is happening:. 1. If you download both `whl` files of Tensorflow like this:. ```. wget https://storage.googleapis.com/deepvariant/packages/tensorflow/tensorflow-1.9.0.deepvariant_gcp-cp27-none-linux_x86_64.whl. wget https://files.pythonhosted.org/packages/1a/c4/8cb95df0bf06089014259b25997c3921a87aa08e2cd981417d91ca92f7e9/tensorflow-1.10.1-cp27-cp27mu-manylinux1_x86_64.whl. ```. 2. Next rename each of the `whl` files to `zip`, and then uncompress them in separate directories. If you then look at one of the version `1.10.1` files that has the `serialized_options` such as `purelib/tensorflow/core/framework/resource_handle_pb2.py`, you will see the following difference between the versions, where the `serialized_options` keyword is present in the `1.10.1` version, but not in the `1.9.0` version:. #### _*For version 1.9*_. ```Python. DESCRIPTOR = _descriptor.FileDescriptor(. name='tensorflow/core/framework/resource_handle.proto',. package='tensorflow',. syntax='proto3',. serialized_pb=_b('\n/tensorflow/core/framework/resource_handle.proto\x12\ntensorflow\""r\n\x13ResourceHandleProto\x12\x0e\n\x06\x64\x65vice\x18\x01 \x01(\t\x12\x11\n\tcontainer\x18\x02 \x01(\t\x12\x0c\n\x04name\x18\x03 \x01(\t\x12\x11\n\thash_code\x18\x04 \x01(\x04\x12\x17\n\x0fmaybe_type_name\x18\x05 \x01(\tBn\n\x18org.tensorflow.frameworkB\x0eResourceHandleP",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:524,deployability,version,version,524,"Hi Ram,. You really do not want to have any errors show up in any of your tests, especially when performing variant calling. It's an easily fixable issue where the Google folks would just need to update their TensorFlow Python package distributed with DeepVariant, which was probably compiled with an earlier version of protobuf, while currently the Tensorflow requires `3.6` of protobuf and the Protobuf version being compiled with DeepVariant is `3.6`. Looking at your log file, you are using the CPU version. The current version on PyPI of TensorFlow is 1.10.1, and DeepVariant uses version 1.9. Here's the process by which I went about to determine what is happening:. 1. If you download both `whl` files of Tensorflow like this:. ```. wget https://storage.googleapis.com/deepvariant/packages/tensorflow/tensorflow-1.9.0.deepvariant_gcp-cp27-none-linux_x86_64.whl. wget https://files.pythonhosted.org/packages/1a/c4/8cb95df0bf06089014259b25997c3921a87aa08e2cd981417d91ca92f7e9/tensorflow-1.10.1-cp27-cp27mu-manylinux1_x86_64.whl. ```. 2. Next rename each of the `whl` files to `zip`, and then uncompress them in separate directories. If you then look at one of the version `1.10.1` files that has the `serialized_options` such as `purelib/tensorflow/core/framework/resource_handle_pb2.py`, you will see the following difference between the versions, where the `serialized_options` keyword is present in the `1.10.1` version, but not in the `1.9.0` version:. #### _*For version 1.9*_. ```Python. DESCRIPTOR = _descriptor.FileDescriptor(. name='tensorflow/core/framework/resource_handle.proto',. package='tensorflow',. syntax='proto3',. serialized_pb=_b('\n/tensorflow/core/framework/resource_handle.proto\x12\ntensorflow\""r\n\x13ResourceHandleProto\x12\x0e\n\x06\x64\x65vice\x18\x01 \x01(\t\x12\x11\n\tcontainer\x18\x02 \x01(\t\x12\x0c\n\x04name\x18\x03 \x01(\t\x12\x11\n\thash_code\x18\x04 \x01(\x04\x12\x17\n\x0fmaybe_type_name\x18\x05 \x01(\tBn\n\x18org.tensorflow.frameworkB\x0eResourceHandleP",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:586,deployability,version,version,586,"Hi Ram,. You really do not want to have any errors show up in any of your tests, especially when performing variant calling. It's an easily fixable issue where the Google folks would just need to update their TensorFlow Python package distributed with DeepVariant, which was probably compiled with an earlier version of protobuf, while currently the Tensorflow requires `3.6` of protobuf and the Protobuf version being compiled with DeepVariant is `3.6`. Looking at your log file, you are using the CPU version. The current version on PyPI of TensorFlow is 1.10.1, and DeepVariant uses version 1.9. Here's the process by which I went about to determine what is happening:. 1. If you download both `whl` files of Tensorflow like this:. ```. wget https://storage.googleapis.com/deepvariant/packages/tensorflow/tensorflow-1.9.0.deepvariant_gcp-cp27-none-linux_x86_64.whl. wget https://files.pythonhosted.org/packages/1a/c4/8cb95df0bf06089014259b25997c3921a87aa08e2cd981417d91ca92f7e9/tensorflow-1.10.1-cp27-cp27mu-manylinux1_x86_64.whl. ```. 2. Next rename each of the `whl` files to `zip`, and then uncompress them in separate directories. If you then look at one of the version `1.10.1` files that has the `serialized_options` such as `purelib/tensorflow/core/framework/resource_handle_pb2.py`, you will see the following difference between the versions, where the `serialized_options` keyword is present in the `1.10.1` version, but not in the `1.9.0` version:. #### _*For version 1.9*_. ```Python. DESCRIPTOR = _descriptor.FileDescriptor(. name='tensorflow/core/framework/resource_handle.proto',. package='tensorflow',. syntax='proto3',. serialized_pb=_b('\n/tensorflow/core/framework/resource_handle.proto\x12\ntensorflow\""r\n\x13ResourceHandleProto\x12\x0e\n\x06\x64\x65vice\x18\x01 \x01(\t\x12\x11\n\tcontainer\x18\x02 \x01(\t\x12\x0c\n\x04name\x18\x03 \x01(\t\x12\x11\n\thash_code\x18\x04 \x01(\x04\x12\x17\n\x0fmaybe_type_name\x18\x05 \x01(\tBn\n\x18org.tensorflow.frameworkB\x0eResourceHandleP",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:1169,deployability,version,version,1169,"lks would just need to update their TensorFlow Python package distributed with DeepVariant, which was probably compiled with an earlier version of protobuf, while currently the Tensorflow requires `3.6` of protobuf and the Protobuf version being compiled with DeepVariant is `3.6`. Looking at your log file, you are using the CPU version. The current version on PyPI of TensorFlow is 1.10.1, and DeepVariant uses version 1.9. Here's the process by which I went about to determine what is happening:. 1. If you download both `whl` files of Tensorflow like this:. ```. wget https://storage.googleapis.com/deepvariant/packages/tensorflow/tensorflow-1.9.0.deepvariant_gcp-cp27-none-linux_x86_64.whl. wget https://files.pythonhosted.org/packages/1a/c4/8cb95df0bf06089014259b25997c3921a87aa08e2cd981417d91ca92f7e9/tensorflow-1.10.1-cp27-cp27mu-manylinux1_x86_64.whl. ```. 2. Next rename each of the `whl` files to `zip`, and then uncompress them in separate directories. If you then look at one of the version `1.10.1` files that has the `serialized_options` such as `purelib/tensorflow/core/framework/resource_handle_pb2.py`, you will see the following difference between the versions, where the `serialized_options` keyword is present in the `1.10.1` version, but not in the `1.9.0` version:. #### _*For version 1.9*_. ```Python. DESCRIPTOR = _descriptor.FileDescriptor(. name='tensorflow/core/framework/resource_handle.proto',. package='tensorflow',. syntax='proto3',. serialized_pb=_b('\n/tensorflow/core/framework/resource_handle.proto\x12\ntensorflow\""r\n\x13ResourceHandleProto\x12\x0e\n\x06\x64\x65vice\x18\x01 \x01(\t\x12\x11\n\tcontainer\x18\x02 \x01(\t\x12\x0c\n\x04name\x18\x03 \x01(\t\x12\x11\n\thash_code\x18\x04 \x01(\x04\x12\x17\n\x0fmaybe_type_name\x18\x05 \x01(\tBn\n\x18org.tensorflow.frameworkB\x0eResourceHandleP\x01Z=github.com/tensorflow/tensorflow/tensorflow/go/core/framework\xf8\x01\x01\x62\x06proto3'). ). ```. #### _*For version 1.10.1*_. ```Python. DESCRIPTOR = _descriptor.Fil",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:1344,deployability,version,versions,1344,"e Tensorflow requires `3.6` of protobuf and the Protobuf version being compiled with DeepVariant is `3.6`. Looking at your log file, you are using the CPU version. The current version on PyPI of TensorFlow is 1.10.1, and DeepVariant uses version 1.9. Here's the process by which I went about to determine what is happening:. 1. If you download both `whl` files of Tensorflow like this:. ```. wget https://storage.googleapis.com/deepvariant/packages/tensorflow/tensorflow-1.9.0.deepvariant_gcp-cp27-none-linux_x86_64.whl. wget https://files.pythonhosted.org/packages/1a/c4/8cb95df0bf06089014259b25997c3921a87aa08e2cd981417d91ca92f7e9/tensorflow-1.10.1-cp27-cp27mu-manylinux1_x86_64.whl. ```. 2. Next rename each of the `whl` files to `zip`, and then uncompress them in separate directories. If you then look at one of the version `1.10.1` files that has the `serialized_options` such as `purelib/tensorflow/core/framework/resource_handle_pb2.py`, you will see the following difference between the versions, where the `serialized_options` keyword is present in the `1.10.1` version, but not in the `1.9.0` version:. #### _*For version 1.9*_. ```Python. DESCRIPTOR = _descriptor.FileDescriptor(. name='tensorflow/core/framework/resource_handle.proto',. package='tensorflow',. syntax='proto3',. serialized_pb=_b('\n/tensorflow/core/framework/resource_handle.proto\x12\ntensorflow\""r\n\x13ResourceHandleProto\x12\x0e\n\x06\x64\x65vice\x18\x01 \x01(\t\x12\x11\n\tcontainer\x18\x02 \x01(\t\x12\x0c\n\x04name\x18\x03 \x01(\t\x12\x11\n\thash_code\x18\x04 \x01(\x04\x12\x17\n\x0fmaybe_type_name\x18\x05 \x01(\tBn\n\x18org.tensorflow.frameworkB\x0eResourceHandleP\x01Z=github.com/tensorflow/tensorflow/tensorflow/go/core/framework\xf8\x01\x01\x62\x06proto3'). ). ```. #### _*For version 1.10.1*_. ```Python. DESCRIPTOR = _descriptor.FileDescriptor(. name='tensorflow/core/framework/resource_handle.proto',. package='tensorflow',. syntax='proto3',. serialized_options=_b('\n\030org.tensorflow.frameworkB\016Resou",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:1420,deployability,version,version,1420,"led with DeepVariant is `3.6`. Looking at your log file, you are using the CPU version. The current version on PyPI of TensorFlow is 1.10.1, and DeepVariant uses version 1.9. Here's the process by which I went about to determine what is happening:. 1. If you download both `whl` files of Tensorflow like this:. ```. wget https://storage.googleapis.com/deepvariant/packages/tensorflow/tensorflow-1.9.0.deepvariant_gcp-cp27-none-linux_x86_64.whl. wget https://files.pythonhosted.org/packages/1a/c4/8cb95df0bf06089014259b25997c3921a87aa08e2cd981417d91ca92f7e9/tensorflow-1.10.1-cp27-cp27mu-manylinux1_x86_64.whl. ```. 2. Next rename each of the `whl` files to `zip`, and then uncompress them in separate directories. If you then look at one of the version `1.10.1` files that has the `serialized_options` such as `purelib/tensorflow/core/framework/resource_handle_pb2.py`, you will see the following difference between the versions, where the `serialized_options` keyword is present in the `1.10.1` version, but not in the `1.9.0` version:. #### _*For version 1.9*_. ```Python. DESCRIPTOR = _descriptor.FileDescriptor(. name='tensorflow/core/framework/resource_handle.proto',. package='tensorflow',. syntax='proto3',. serialized_pb=_b('\n/tensorflow/core/framework/resource_handle.proto\x12\ntensorflow\""r\n\x13ResourceHandleProto\x12\x0e\n\x06\x64\x65vice\x18\x01 \x01(\t\x12\x11\n\tcontainer\x18\x02 \x01(\t\x12\x0c\n\x04name\x18\x03 \x01(\t\x12\x11\n\thash_code\x18\x04 \x01(\x04\x12\x17\n\x0fmaybe_type_name\x18\x05 \x01(\tBn\n\x18org.tensorflow.frameworkB\x0eResourceHandleP\x01Z=github.com/tensorflow/tensorflow/tensorflow/go/core/framework\xf8\x01\x01\x62\x06proto3'). ). ```. #### _*For version 1.10.1*_. ```Python. DESCRIPTOR = _descriptor.FileDescriptor(. name='tensorflow/core/framework/resource_handle.proto',. package='tensorflow',. syntax='proto3',. serialized_options=_b('\n\030org.tensorflow.frameworkB\016ResourceHandleP\001Z=github.com/tensorflow/tensorflow/tensorflow/go/core/framewor",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:1452,deployability,version,version,1452,"ooking at your log file, you are using the CPU version. The current version on PyPI of TensorFlow is 1.10.1, and DeepVariant uses version 1.9. Here's the process by which I went about to determine what is happening:. 1. If you download both `whl` files of Tensorflow like this:. ```. wget https://storage.googleapis.com/deepvariant/packages/tensorflow/tensorflow-1.9.0.deepvariant_gcp-cp27-none-linux_x86_64.whl. wget https://files.pythonhosted.org/packages/1a/c4/8cb95df0bf06089014259b25997c3921a87aa08e2cd981417d91ca92f7e9/tensorflow-1.10.1-cp27-cp27mu-manylinux1_x86_64.whl. ```. 2. Next rename each of the `whl` files to `zip`, and then uncompress them in separate directories. If you then look at one of the version `1.10.1` files that has the `serialized_options` such as `purelib/tensorflow/core/framework/resource_handle_pb2.py`, you will see the following difference between the versions, where the `serialized_options` keyword is present in the `1.10.1` version, but not in the `1.9.0` version:. #### _*For version 1.9*_. ```Python. DESCRIPTOR = _descriptor.FileDescriptor(. name='tensorflow/core/framework/resource_handle.proto',. package='tensorflow',. syntax='proto3',. serialized_pb=_b('\n/tensorflow/core/framework/resource_handle.proto\x12\ntensorflow\""r\n\x13ResourceHandleProto\x12\x0e\n\x06\x64\x65vice\x18\x01 \x01(\t\x12\x11\n\tcontainer\x18\x02 \x01(\t\x12\x0c\n\x04name\x18\x03 \x01(\t\x12\x11\n\thash_code\x18\x04 \x01(\x04\x12\x17\n\x0fmaybe_type_name\x18\x05 \x01(\tBn\n\x18org.tensorflow.frameworkB\x0eResourceHandleP\x01Z=github.com/tensorflow/tensorflow/tensorflow/go/core/framework\xf8\x01\x01\x62\x06proto3'). ). ```. #### _*For version 1.10.1*_. ```Python. DESCRIPTOR = _descriptor.FileDescriptor(. name='tensorflow/core/framework/resource_handle.proto',. package='tensorflow',. syntax='proto3',. serialized_options=_b('\n\030org.tensorflow.frameworkB\016ResourceHandleP\001Z=github.com/tensorflow/tensorflow/tensorflow/go/core/framework\370\001\001'),. serialized_pb=",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:1473,deployability,version,version,1473,"le, you are using the CPU version. The current version on PyPI of TensorFlow is 1.10.1, and DeepVariant uses version 1.9. Here's the process by which I went about to determine what is happening:. 1. If you download both `whl` files of Tensorflow like this:. ```. wget https://storage.googleapis.com/deepvariant/packages/tensorflow/tensorflow-1.9.0.deepvariant_gcp-cp27-none-linux_x86_64.whl. wget https://files.pythonhosted.org/packages/1a/c4/8cb95df0bf06089014259b25997c3921a87aa08e2cd981417d91ca92f7e9/tensorflow-1.10.1-cp27-cp27mu-manylinux1_x86_64.whl. ```. 2. Next rename each of the `whl` files to `zip`, and then uncompress them in separate directories. If you then look at one of the version `1.10.1` files that has the `serialized_options` such as `purelib/tensorflow/core/framework/resource_handle_pb2.py`, you will see the following difference between the versions, where the `serialized_options` keyword is present in the `1.10.1` version, but not in the `1.9.0` version:. #### _*For version 1.9*_. ```Python. DESCRIPTOR = _descriptor.FileDescriptor(. name='tensorflow/core/framework/resource_handle.proto',. package='tensorflow',. syntax='proto3',. serialized_pb=_b('\n/tensorflow/core/framework/resource_handle.proto\x12\ntensorflow\""r\n\x13ResourceHandleProto\x12\x0e\n\x06\x64\x65vice\x18\x01 \x01(\t\x12\x11\n\tcontainer\x18\x02 \x01(\t\x12\x0c\n\x04name\x18\x03 \x01(\t\x12\x11\n\thash_code\x18\x04 \x01(\x04\x12\x17\n\x0fmaybe_type_name\x18\x05 \x01(\tBn\n\x18org.tensorflow.frameworkB\x0eResourceHandleP\x01Z=github.com/tensorflow/tensorflow/tensorflow/go/core/framework\xf8\x01\x01\x62\x06proto3'). ). ```. #### _*For version 1.10.1*_. ```Python. DESCRIPTOR = _descriptor.FileDescriptor(. name='tensorflow/core/framework/resource_handle.proto',. package='tensorflow',. syntax='proto3',. serialized_options=_b('\n\030org.tensorflow.frameworkB\016ResourceHandleP\001Z=github.com/tensorflow/tensorflow/tensorflow/go/core/framework\370\001\001'),. serialized_pb=_b('\n/tensorflow/cor",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:2116,deployability,version,version,2116,"rate directories. If you then look at one of the version `1.10.1` files that has the `serialized_options` such as `purelib/tensorflow/core/framework/resource_handle_pb2.py`, you will see the following difference between the versions, where the `serialized_options` keyword is present in the `1.10.1` version, but not in the `1.9.0` version:. #### _*For version 1.9*_. ```Python. DESCRIPTOR = _descriptor.FileDescriptor(. name='tensorflow/core/framework/resource_handle.proto',. package='tensorflow',. syntax='proto3',. serialized_pb=_b('\n/tensorflow/core/framework/resource_handle.proto\x12\ntensorflow\""r\n\x13ResourceHandleProto\x12\x0e\n\x06\x64\x65vice\x18\x01 \x01(\t\x12\x11\n\tcontainer\x18\x02 \x01(\t\x12\x0c\n\x04name\x18\x03 \x01(\t\x12\x11\n\thash_code\x18\x04 \x01(\x04\x12\x17\n\x0fmaybe_type_name\x18\x05 \x01(\tBn\n\x18org.tensorflow.frameworkB\x0eResourceHandleP\x01Z=github.com/tensorflow/tensorflow/tensorflow/go/core/framework\xf8\x01\x01\x62\x06proto3'). ). ```. #### _*For version 1.10.1*_. ```Python. DESCRIPTOR = _descriptor.FileDescriptor(. name='tensorflow/core/framework/resource_handle.proto',. package='tensorflow',. syntax='proto3',. serialized_options=_b('\n\030org.tensorflow.frameworkB\016ResourceHandleP\001Z=github.com/tensorflow/tensorflow/tensorflow/go/core/framework\370\001\001'),. serialized_pb=_b('\n/tensorflow/core/framework/resource_handle.proto\x12\ntensorflow\""r\n\x13ResourceHandleProto\x12\x0e\n\x06\x64\x65vice\x18\x01 \x01(\t\x12\x11\n\tcontainer\x18\x02 \x01(\t\x12\x0c\n\x04name\x18\x03 \x01(\t\x12\x11\n\thash_code\x18\x04 \x01(\x04\x12\x17\n\x0fmaybe_type_name\x18\x05 \x01(\tBn\n\x18org.tensorflow.frameworkB\x0eResourceHandleP\x01Z=github.com/tensorflow/tensorflow/tensorflow/go/core/framework\xf8\x01\x01\x62\x06proto3'). ). ```. ProtoBuf 3.6 passes the `serialized_options` argument in the call to `__new__` as shown here:. https://github.com/protocolbuffers/protobuf/blob/3.6.x/python/google/protobuf/descriptor.py#L283. ```Python. def __ne",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:3628,deployability,version,version,3628,"\x18\x05 \x01(\tBn\n\x18org.tensorflow.frameworkB\x0eResourceHandleP\x01Z=github.com/tensorflow/tensorflow/tensorflow/go/core/framework\xf8\x01\x01\x62\x06proto3'). ). ```. #### _*For version 1.10.1*_. ```Python. DESCRIPTOR = _descriptor.FileDescriptor(. name='tensorflow/core/framework/resource_handle.proto',. package='tensorflow',. syntax='proto3',. serialized_options=_b('\n\030org.tensorflow.frameworkB\016ResourceHandleP\001Z=github.com/tensorflow/tensorflow/tensorflow/go/core/framework\370\001\001'),. serialized_pb=_b('\n/tensorflow/core/framework/resource_handle.proto\x12\ntensorflow\""r\n\x13ResourceHandleProto\x12\x0e\n\x06\x64\x65vice\x18\x01 \x01(\t\x12\x11\n\tcontainer\x18\x02 \x01(\t\x12\x0c\n\x04name\x18\x03 \x01(\t\x12\x11\n\thash_code\x18\x04 \x01(\x04\x12\x17\n\x0fmaybe_type_name\x18\x05 \x01(\tBn\n\x18org.tensorflow.frameworkB\x0eResourceHandleP\x01Z=github.com/tensorflow/tensorflow/tensorflow/go/core/framework\xf8\x01\x01\x62\x06proto3'). ). ```. ProtoBuf 3.6 passes the `serialized_options` argument in the call to `__new__` as shown here:. https://github.com/protocolbuffers/protobuf/blob/3.6.x/python/google/protobuf/descriptor.py#L283. ```Python. def __new__(cls, name, full_name, filename, containing_type, fields,. nested_types, enum_types, extensions, options=None,. serialized_options=None,. is_extendable=True, extension_ranges=None, oneofs=None,. file=None, serialized_start=None, serialized_end=None, # pylint: disable=redefined-builtin. syntax=None):. _message.Message._CheckCalledFromGeneratedFile(). return _message.default_pool.FindMessageTypeByName(full_name). ```. 3. If you look at the `METADATA` file of each TensorFlow package to see the protobuf version requirement, it will look like this:. ```. paul:~/tensorflow$ cat unzip-1.9/tensorflow-1.9.0.dist-info/METADATA | grep protobuf. Requires-Dist: protobuf (>=3.4.0). paul:~/tensorflow$ cat unzip-1.10/tensorflow-1.10.1.dist-info/METADATA | grep protobuf. Requires-Dist: protobuf (>=3.6.0). ```. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:336,energy efficiency,current,currently,336,"Hi Ram,. You really do not want to have any errors show up in any of your tests, especially when performing variant calling. It's an easily fixable issue where the Google folks would just need to update their TensorFlow Python package distributed with DeepVariant, which was probably compiled with an earlier version of protobuf, while currently the Tensorflow requires `3.6` of protobuf and the Protobuf version being compiled with DeepVariant is `3.6`. Looking at your log file, you are using the CPU version. The current version on PyPI of TensorFlow is 1.10.1, and DeepVariant uses version 1.9. Here's the process by which I went about to determine what is happening:. 1. If you download both `whl` files of Tensorflow like this:. ```. wget https://storage.googleapis.com/deepvariant/packages/tensorflow/tensorflow-1.9.0.deepvariant_gcp-cp27-none-linux_x86_64.whl. wget https://files.pythonhosted.org/packages/1a/c4/8cb95df0bf06089014259b25997c3921a87aa08e2cd981417d91ca92f7e9/tensorflow-1.10.1-cp27-cp27mu-manylinux1_x86_64.whl. ```. 2. Next rename each of the `whl` files to `zip`, and then uncompress them in separate directories. If you then look at one of the version `1.10.1` files that has the `serialized_options` such as `purelib/tensorflow/core/framework/resource_handle_pb2.py`, you will see the following difference between the versions, where the `serialized_options` keyword is present in the `1.10.1` version, but not in the `1.9.0` version:. #### _*For version 1.9*_. ```Python. DESCRIPTOR = _descriptor.FileDescriptor(. name='tensorflow/core/framework/resource_handle.proto',. package='tensorflow',. syntax='proto3',. serialized_pb=_b('\n/tensorflow/core/framework/resource_handle.proto\x12\ntensorflow\""r\n\x13ResourceHandleProto\x12\x0e\n\x06\x64\x65vice\x18\x01 \x01(\t\x12\x11\n\tcontainer\x18\x02 \x01(\t\x12\x0c\n\x04name\x18\x03 \x01(\t\x12\x11\n\thash_code\x18\x04 \x01(\x04\x12\x17\n\x0fmaybe_type_name\x18\x05 \x01(\tBn\n\x18org.tensorflow.frameworkB\x0eResourceHandleP",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:499,energy efficiency,CPU,CPU,499,"Hi Ram,. You really do not want to have any errors show up in any of your tests, especially when performing variant calling. It's an easily fixable issue where the Google folks would just need to update their TensorFlow Python package distributed with DeepVariant, which was probably compiled with an earlier version of protobuf, while currently the Tensorflow requires `3.6` of protobuf and the Protobuf version being compiled with DeepVariant is `3.6`. Looking at your log file, you are using the CPU version. The current version on PyPI of TensorFlow is 1.10.1, and DeepVariant uses version 1.9. Here's the process by which I went about to determine what is happening:. 1. If you download both `whl` files of Tensorflow like this:. ```. wget https://storage.googleapis.com/deepvariant/packages/tensorflow/tensorflow-1.9.0.deepvariant_gcp-cp27-none-linux_x86_64.whl. wget https://files.pythonhosted.org/packages/1a/c4/8cb95df0bf06089014259b25997c3921a87aa08e2cd981417d91ca92f7e9/tensorflow-1.10.1-cp27-cp27mu-manylinux1_x86_64.whl. ```. 2. Next rename each of the `whl` files to `zip`, and then uncompress them in separate directories. If you then look at one of the version `1.10.1` files that has the `serialized_options` such as `purelib/tensorflow/core/framework/resource_handle_pb2.py`, you will see the following difference between the versions, where the `serialized_options` keyword is present in the `1.10.1` version, but not in the `1.9.0` version:. #### _*For version 1.9*_. ```Python. DESCRIPTOR = _descriptor.FileDescriptor(. name='tensorflow/core/framework/resource_handle.proto',. package='tensorflow',. syntax='proto3',. serialized_pb=_b('\n/tensorflow/core/framework/resource_handle.proto\x12\ntensorflow\""r\n\x13ResourceHandleProto\x12\x0e\n\x06\x64\x65vice\x18\x01 \x01(\t\x12\x11\n\tcontainer\x18\x02 \x01(\t\x12\x0c\n\x04name\x18\x03 \x01(\t\x12\x11\n\thash_code\x18\x04 \x01(\x04\x12\x17\n\x0fmaybe_type_name\x18\x05 \x01(\tBn\n\x18org.tensorflow.frameworkB\x0eResourceHandleP",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:516,energy efficiency,current,current,516,"Hi Ram,. You really do not want to have any errors show up in any of your tests, especially when performing variant calling. It's an easily fixable issue where the Google folks would just need to update their TensorFlow Python package distributed with DeepVariant, which was probably compiled with an earlier version of protobuf, while currently the Tensorflow requires `3.6` of protobuf and the Protobuf version being compiled with DeepVariant is `3.6`. Looking at your log file, you are using the CPU version. The current version on PyPI of TensorFlow is 1.10.1, and DeepVariant uses version 1.9. Here's the process by which I went about to determine what is happening:. 1. If you download both `whl` files of Tensorflow like this:. ```. wget https://storage.googleapis.com/deepvariant/packages/tensorflow/tensorflow-1.9.0.deepvariant_gcp-cp27-none-linux_x86_64.whl. wget https://files.pythonhosted.org/packages/1a/c4/8cb95df0bf06089014259b25997c3921a87aa08e2cd981417d91ca92f7e9/tensorflow-1.10.1-cp27-cp27mu-manylinux1_x86_64.whl. ```. 2. Next rename each of the `whl` files to `zip`, and then uncompress them in separate directories. If you then look at one of the version `1.10.1` files that has the `serialized_options` such as `purelib/tensorflow/core/framework/resource_handle_pb2.py`, you will see the following difference between the versions, where the `serialized_options` keyword is present in the `1.10.1` version, but not in the `1.9.0` version:. #### _*For version 1.9*_. ```Python. DESCRIPTOR = _descriptor.FileDescriptor(. name='tensorflow/core/framework/resource_handle.proto',. package='tensorflow',. syntax='proto3',. serialized_pb=_b('\n/tensorflow/core/framework/resource_handle.proto\x12\ntensorflow\""r\n\x13ResourceHandleProto\x12\x0e\n\x06\x64\x65vice\x18\x01 \x01(\t\x12\x11\n\tcontainer\x18\x02 \x01(\t\x12\x0c\n\x04name\x18\x03 \x01(\t\x12\x11\n\thash_code\x18\x04 \x01(\x04\x12\x17\n\x0fmaybe_type_name\x18\x05 \x01(\tBn\n\x18org.tensorflow.frameworkB\x0eResourceHandleP",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:1254,energy efficiency,core,core,1254,"Variant, which was probably compiled with an earlier version of protobuf, while currently the Tensorflow requires `3.6` of protobuf and the Protobuf version being compiled with DeepVariant is `3.6`. Looking at your log file, you are using the CPU version. The current version on PyPI of TensorFlow is 1.10.1, and DeepVariant uses version 1.9. Here's the process by which I went about to determine what is happening:. 1. If you download both `whl` files of Tensorflow like this:. ```. wget https://storage.googleapis.com/deepvariant/packages/tensorflow/tensorflow-1.9.0.deepvariant_gcp-cp27-none-linux_x86_64.whl. wget https://files.pythonhosted.org/packages/1a/c4/8cb95df0bf06089014259b25997c3921a87aa08e2cd981417d91ca92f7e9/tensorflow-1.10.1-cp27-cp27mu-manylinux1_x86_64.whl. ```. 2. Next rename each of the `whl` files to `zip`, and then uncompress them in separate directories. If you then look at one of the version `1.10.1` files that has the `serialized_options` such as `purelib/tensorflow/core/framework/resource_handle_pb2.py`, you will see the following difference between the versions, where the `serialized_options` keyword is present in the `1.10.1` version, but not in the `1.9.0` version:. #### _*For version 1.9*_. ```Python. DESCRIPTOR = _descriptor.FileDescriptor(. name='tensorflow/core/framework/resource_handle.proto',. package='tensorflow',. syntax='proto3',. serialized_pb=_b('\n/tensorflow/core/framework/resource_handle.proto\x12\ntensorflow\""r\n\x13ResourceHandleProto\x12\x0e\n\x06\x64\x65vice\x18\x01 \x01(\t\x12\x11\n\tcontainer\x18\x02 \x01(\t\x12\x0c\n\x04name\x18\x03 \x01(\t\x12\x11\n\thash_code\x18\x04 \x01(\x04\x12\x17\n\x0fmaybe_type_name\x18\x05 \x01(\tBn\n\x18org.tensorflow.frameworkB\x0eResourceHandleP\x01Z=github.com/tensorflow/tensorflow/tensorflow/go/core/framework\xf8\x01\x01\x62\x06proto3'). ). ```. #### _*For version 1.10.1*_. ```Python. DESCRIPTOR = _descriptor.FileDescriptor(. name='tensorflow/core/framework/resource_handle.proto',. package='ten",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:1558,energy efficiency,core,core,1558,"0.1, and DeepVariant uses version 1.9. Here's the process by which I went about to determine what is happening:. 1. If you download both `whl` files of Tensorflow like this:. ```. wget https://storage.googleapis.com/deepvariant/packages/tensorflow/tensorflow-1.9.0.deepvariant_gcp-cp27-none-linux_x86_64.whl. wget https://files.pythonhosted.org/packages/1a/c4/8cb95df0bf06089014259b25997c3921a87aa08e2cd981417d91ca92f7e9/tensorflow-1.10.1-cp27-cp27mu-manylinux1_x86_64.whl. ```. 2. Next rename each of the `whl` files to `zip`, and then uncompress them in separate directories. If you then look at one of the version `1.10.1` files that has the `serialized_options` such as `purelib/tensorflow/core/framework/resource_handle_pb2.py`, you will see the following difference between the versions, where the `serialized_options` keyword is present in the `1.10.1` version, but not in the `1.9.0` version:. #### _*For version 1.9*_. ```Python. DESCRIPTOR = _descriptor.FileDescriptor(. name='tensorflow/core/framework/resource_handle.proto',. package='tensorflow',. syntax='proto3',. serialized_pb=_b('\n/tensorflow/core/framework/resource_handle.proto\x12\ntensorflow\""r\n\x13ResourceHandleProto\x12\x0e\n\x06\x64\x65vice\x18\x01 \x01(\t\x12\x11\n\tcontainer\x18\x02 \x01(\t\x12\x0c\n\x04name\x18\x03 \x01(\t\x12\x11\n\thash_code\x18\x04 \x01(\x04\x12\x17\n\x0fmaybe_type_name\x18\x05 \x01(\tBn\n\x18org.tensorflow.frameworkB\x0eResourceHandleP\x01Z=github.com/tensorflow/tensorflow/tensorflow/go/core/framework\xf8\x01\x01\x62\x06proto3'). ). ```. #### _*For version 1.10.1*_. ```Python. DESCRIPTOR = _descriptor.FileDescriptor(. name='tensorflow/core/framework/resource_handle.proto',. package='tensorflow',. syntax='proto3',. serialized_options=_b('\n\030org.tensorflow.frameworkB\016ResourceHandleP\001Z=github.com/tensorflow/tensorflow/tensorflow/go/core/framework\370\001\001'),. serialized_pb=_b('\n/tensorflow/core/framework/resource_handle.proto\x12\ntensorflow\""r\n\x13ResourceHandleProto\x12\x",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:1671,energy efficiency,core,core,1671,"1. If you download both `whl` files of Tensorflow like this:. ```. wget https://storage.googleapis.com/deepvariant/packages/tensorflow/tensorflow-1.9.0.deepvariant_gcp-cp27-none-linux_x86_64.whl. wget https://files.pythonhosted.org/packages/1a/c4/8cb95df0bf06089014259b25997c3921a87aa08e2cd981417d91ca92f7e9/tensorflow-1.10.1-cp27-cp27mu-manylinux1_x86_64.whl. ```. 2. Next rename each of the `whl` files to `zip`, and then uncompress them in separate directories. If you then look at one of the version `1.10.1` files that has the `serialized_options` such as `purelib/tensorflow/core/framework/resource_handle_pb2.py`, you will see the following difference between the versions, where the `serialized_options` keyword is present in the `1.10.1` version, but not in the `1.9.0` version:. #### _*For version 1.9*_. ```Python. DESCRIPTOR = _descriptor.FileDescriptor(. name='tensorflow/core/framework/resource_handle.proto',. package='tensorflow',. syntax='proto3',. serialized_pb=_b('\n/tensorflow/core/framework/resource_handle.proto\x12\ntensorflow\""r\n\x13ResourceHandleProto\x12\x0e\n\x06\x64\x65vice\x18\x01 \x01(\t\x12\x11\n\tcontainer\x18\x02 \x01(\t\x12\x0c\n\x04name\x18\x03 \x01(\t\x12\x11\n\thash_code\x18\x04 \x01(\x04\x12\x17\n\x0fmaybe_type_name\x18\x05 \x01(\tBn\n\x18org.tensorflow.frameworkB\x0eResourceHandleP\x01Z=github.com/tensorflow/tensorflow/tensorflow/go/core/framework\xf8\x01\x01\x62\x06proto3'). ). ```. #### _*For version 1.10.1*_. ```Python. DESCRIPTOR = _descriptor.FileDescriptor(. name='tensorflow/core/framework/resource_handle.proto',. package='tensorflow',. syntax='proto3',. serialized_options=_b('\n\030org.tensorflow.frameworkB\016ResourceHandleP\001Z=github.com/tensorflow/tensorflow/tensorflow/go/core/framework\370\001\001'),. serialized_pb=_b('\n/tensorflow/core/framework/resource_handle.proto\x12\ntensorflow\""r\n\x13ResourceHandleProto\x12\x0e\n\x06\x64\x65vice\x18\x01 \x01(\t\x12\x11\n\tcontainer\x18\x02 \x01(\t\x12\x0c\n\x04name\x18\x03 \x01(\t\x12\x",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:2053,energy efficiency,core,core,2053,"ach of the `whl` files to `zip`, and then uncompress them in separate directories. If you then look at one of the version `1.10.1` files that has the `serialized_options` such as `purelib/tensorflow/core/framework/resource_handle_pb2.py`, you will see the following difference between the versions, where the `serialized_options` keyword is present in the `1.10.1` version, but not in the `1.9.0` version:. #### _*For version 1.9*_. ```Python. DESCRIPTOR = _descriptor.FileDescriptor(. name='tensorflow/core/framework/resource_handle.proto',. package='tensorflow',. syntax='proto3',. serialized_pb=_b('\n/tensorflow/core/framework/resource_handle.proto\x12\ntensorflow\""r\n\x13ResourceHandleProto\x12\x0e\n\x06\x64\x65vice\x18\x01 \x01(\t\x12\x11\n\tcontainer\x18\x02 \x01(\t\x12\x0c\n\x04name\x18\x03 \x01(\t\x12\x11\n\thash_code\x18\x04 \x01(\x04\x12\x17\n\x0fmaybe_type_name\x18\x05 \x01(\tBn\n\x18org.tensorflow.frameworkB\x0eResourceHandleP\x01Z=github.com/tensorflow/tensorflow/tensorflow/go/core/framework\xf8\x01\x01\x62\x06proto3'). ). ```. #### _*For version 1.10.1*_. ```Python. DESCRIPTOR = _descriptor.FileDescriptor(. name='tensorflow/core/framework/resource_handle.proto',. package='tensorflow',. syntax='proto3',. serialized_options=_b('\n\030org.tensorflow.frameworkB\016ResourceHandleP\001Z=github.com/tensorflow/tensorflow/tensorflow/go/core/framework\370\001\001'),. serialized_pb=_b('\n/tensorflow/core/framework/resource_handle.proto\x12\ntensorflow\""r\n\x13ResourceHandleProto\x12\x0e\n\x06\x64\x65vice\x18\x01 \x01(\t\x12\x11\n\tcontainer\x18\x02 \x01(\t\x12\x0c\n\x04name\x18\x03 \x01(\t\x12\x11\n\thash_code\x18\x04 \x01(\x04\x12\x17\n\x0fmaybe_type_name\x18\x05 \x01(\tBn\n\x18org.tensorflow.frameworkB\x0eResourceHandleP\x01Z=github.com/tensorflow/tensorflow/tensorflow/go/core/framework\xf8\x01\x01\x62\x06proto3'). ). ```. ProtoBuf 3.6 passes the `serialized_options` argument in the call to `__new__` as shown here:. https://github.com/protocolbuffers/protobuf/blob/3.6",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:2204,energy efficiency,core,core,2204,"serialized_options` such as `purelib/tensorflow/core/framework/resource_handle_pb2.py`, you will see the following difference between the versions, where the `serialized_options` keyword is present in the `1.10.1` version, but not in the `1.9.0` version:. #### _*For version 1.9*_. ```Python. DESCRIPTOR = _descriptor.FileDescriptor(. name='tensorflow/core/framework/resource_handle.proto',. package='tensorflow',. syntax='proto3',. serialized_pb=_b('\n/tensorflow/core/framework/resource_handle.proto\x12\ntensorflow\""r\n\x13ResourceHandleProto\x12\x0e\n\x06\x64\x65vice\x18\x01 \x01(\t\x12\x11\n\tcontainer\x18\x02 \x01(\t\x12\x0c\n\x04name\x18\x03 \x01(\t\x12\x11\n\thash_code\x18\x04 \x01(\x04\x12\x17\n\x0fmaybe_type_name\x18\x05 \x01(\tBn\n\x18org.tensorflow.frameworkB\x0eResourceHandleP\x01Z=github.com/tensorflow/tensorflow/tensorflow/go/core/framework\xf8\x01\x01\x62\x06proto3'). ). ```. #### _*For version 1.10.1*_. ```Python. DESCRIPTOR = _descriptor.FileDescriptor(. name='tensorflow/core/framework/resource_handle.proto',. package='tensorflow',. syntax='proto3',. serialized_options=_b('\n\030org.tensorflow.frameworkB\016ResourceHandleP\001Z=github.com/tensorflow/tensorflow/tensorflow/go/core/framework\370\001\001'),. serialized_pb=_b('\n/tensorflow/core/framework/resource_handle.proto\x12\ntensorflow\""r\n\x13ResourceHandleProto\x12\x0e\n\x06\x64\x65vice\x18\x01 \x01(\t\x12\x11\n\tcontainer\x18\x02 \x01(\t\x12\x0c\n\x04name\x18\x03 \x01(\t\x12\x11\n\thash_code\x18\x04 \x01(\x04\x12\x17\n\x0fmaybe_type_name\x18\x05 \x01(\tBn\n\x18org.tensorflow.frameworkB\x0eResourceHandleP\x01Z=github.com/tensorflow/tensorflow/tensorflow/go/core/framework\xf8\x01\x01\x62\x06proto3'). ). ```. ProtoBuf 3.6 passes the `serialized_options` argument in the call to `__new__` as shown here:. https://github.com/protocolbuffers/protobuf/blob/3.6.x/python/google/protobuf/descriptor.py#L283. ```Python. def __new__(cls, name, full_name, filename, containing_type, fields,. nested_types, enum_types",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:2411,energy efficiency,core,core,2411,".10.1` version, but not in the `1.9.0` version:. #### _*For version 1.9*_. ```Python. DESCRIPTOR = _descriptor.FileDescriptor(. name='tensorflow/core/framework/resource_handle.proto',. package='tensorflow',. syntax='proto3',. serialized_pb=_b('\n/tensorflow/core/framework/resource_handle.proto\x12\ntensorflow\""r\n\x13ResourceHandleProto\x12\x0e\n\x06\x64\x65vice\x18\x01 \x01(\t\x12\x11\n\tcontainer\x18\x02 \x01(\t\x12\x0c\n\x04name\x18\x03 \x01(\t\x12\x11\n\thash_code\x18\x04 \x01(\x04\x12\x17\n\x0fmaybe_type_name\x18\x05 \x01(\tBn\n\x18org.tensorflow.frameworkB\x0eResourceHandleP\x01Z=github.com/tensorflow/tensorflow/tensorflow/go/core/framework\xf8\x01\x01\x62\x06proto3'). ). ```. #### _*For version 1.10.1*_. ```Python. DESCRIPTOR = _descriptor.FileDescriptor(. name='tensorflow/core/framework/resource_handle.proto',. package='tensorflow',. syntax='proto3',. serialized_options=_b('\n\030org.tensorflow.frameworkB\016ResourceHandleP\001Z=github.com/tensorflow/tensorflow/tensorflow/go/core/framework\370\001\001'),. serialized_pb=_b('\n/tensorflow/core/framework/resource_handle.proto\x12\ntensorflow\""r\n\x13ResourceHandleProto\x12\x0e\n\x06\x64\x65vice\x18\x01 \x01(\t\x12\x11\n\tcontainer\x18\x02 \x01(\t\x12\x0c\n\x04name\x18\x03 \x01(\t\x12\x11\n\thash_code\x18\x04 \x01(\x04\x12\x17\n\x0fmaybe_type_name\x18\x05 \x01(\tBn\n\x18org.tensorflow.frameworkB\x0eResourceHandleP\x01Z=github.com/tensorflow/tensorflow/tensorflow/go/core/framework\xf8\x01\x01\x62\x06proto3'). ). ```. ProtoBuf 3.6 passes the `serialized_options` argument in the call to `__new__` as shown here:. https://github.com/protocolbuffers/protobuf/blob/3.6.x/python/google/protobuf/descriptor.py#L283. ```Python. def __new__(cls, name, full_name, filename, containing_type, fields,. nested_types, enum_types, extensions, options=None,. serialized_options=None,. is_extendable=True, extension_ranges=None, oneofs=None,. file=None, serialized_start=None, serialized_end=None, # pylint: disable=redefined-builtin. syn",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:2474,energy efficiency,core,core,2474,"sion 1.9*_. ```Python. DESCRIPTOR = _descriptor.FileDescriptor(. name='tensorflow/core/framework/resource_handle.proto',. package='tensorflow',. syntax='proto3',. serialized_pb=_b('\n/tensorflow/core/framework/resource_handle.proto\x12\ntensorflow\""r\n\x13ResourceHandleProto\x12\x0e\n\x06\x64\x65vice\x18\x01 \x01(\t\x12\x11\n\tcontainer\x18\x02 \x01(\t\x12\x0c\n\x04name\x18\x03 \x01(\t\x12\x11\n\thash_code\x18\x04 \x01(\x04\x12\x17\n\x0fmaybe_type_name\x18\x05 \x01(\tBn\n\x18org.tensorflow.frameworkB\x0eResourceHandleP\x01Z=github.com/tensorflow/tensorflow/tensorflow/go/core/framework\xf8\x01\x01\x62\x06proto3'). ). ```. #### _*For version 1.10.1*_. ```Python. DESCRIPTOR = _descriptor.FileDescriptor(. name='tensorflow/core/framework/resource_handle.proto',. package='tensorflow',. syntax='proto3',. serialized_options=_b('\n\030org.tensorflow.frameworkB\016ResourceHandleP\001Z=github.com/tensorflow/tensorflow/tensorflow/go/core/framework\370\001\001'),. serialized_pb=_b('\n/tensorflow/core/framework/resource_handle.proto\x12\ntensorflow\""r\n\x13ResourceHandleProto\x12\x0e\n\x06\x64\x65vice\x18\x01 \x01(\t\x12\x11\n\tcontainer\x18\x02 \x01(\t\x12\x0c\n\x04name\x18\x03 \x01(\t\x12\x11\n\thash_code\x18\x04 \x01(\x04\x12\x17\n\x0fmaybe_type_name\x18\x05 \x01(\tBn\n\x18org.tensorflow.frameworkB\x0eResourceHandleP\x01Z=github.com/tensorflow/tensorflow/tensorflow/go/core/framework\xf8\x01\x01\x62\x06proto3'). ). ```. ProtoBuf 3.6 passes the `serialized_options` argument in the call to `__new__` as shown here:. https://github.com/protocolbuffers/protobuf/blob/3.6.x/python/google/protobuf/descriptor.py#L283. ```Python. def __new__(cls, name, full_name, filename, containing_type, fields,. nested_types, enum_types, extensions, options=None,. serialized_options=None,. is_extendable=True, extension_ranges=None, oneofs=None,. file=None, serialized_start=None, serialized_end=None, # pylint: disable=redefined-builtin. syntax=None):. _message.Message._CheckCalledFromGeneratedFile(). r",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:2856,energy efficiency,core,core,2856,"x01(\t\x12\x11\n\thash_code\x18\x04 \x01(\x04\x12\x17\n\x0fmaybe_type_name\x18\x05 \x01(\tBn\n\x18org.tensorflow.frameworkB\x0eResourceHandleP\x01Z=github.com/tensorflow/tensorflow/tensorflow/go/core/framework\xf8\x01\x01\x62\x06proto3'). ). ```. #### _*For version 1.10.1*_. ```Python. DESCRIPTOR = _descriptor.FileDescriptor(. name='tensorflow/core/framework/resource_handle.proto',. package='tensorflow',. syntax='proto3',. serialized_options=_b('\n\030org.tensorflow.frameworkB\016ResourceHandleP\001Z=github.com/tensorflow/tensorflow/tensorflow/go/core/framework\370\001\001'),. serialized_pb=_b('\n/tensorflow/core/framework/resource_handle.proto\x12\ntensorflow\""r\n\x13ResourceHandleProto\x12\x0e\n\x06\x64\x65vice\x18\x01 \x01(\t\x12\x11\n\tcontainer\x18\x02 \x01(\t\x12\x0c\n\x04name\x18\x03 \x01(\t\x12\x11\n\thash_code\x18\x04 \x01(\x04\x12\x17\n\x0fmaybe_type_name\x18\x05 \x01(\tBn\n\x18org.tensorflow.frameworkB\x0eResourceHandleP\x01Z=github.com/tensorflow/tensorflow/tensorflow/go/core/framework\xf8\x01\x01\x62\x06proto3'). ). ```. ProtoBuf 3.6 passes the `serialized_options` argument in the call to `__new__` as shown here:. https://github.com/protocolbuffers/protobuf/blob/3.6.x/python/google/protobuf/descriptor.py#L283. ```Python. def __new__(cls, name, full_name, filename, containing_type, fields,. nested_types, enum_types, extensions, options=None,. serialized_options=None,. is_extendable=True, extension_ranges=None, oneofs=None,. file=None, serialized_start=None, serialized_end=None, # pylint: disable=redefined-builtin. syntax=None):. _message.Message._CheckCalledFromGeneratedFile(). return _message.default_pool.FindMessageTypeByName(full_name). ```. 3. If you look at the `METADATA` file of each TensorFlow package to see the protobuf version requirement, it will look like this:. ```. paul:~/tensorflow$ cat unzip-1.9/tensorflow-1.9.0.dist-info/METADATA | grep protobuf. Requires-Dist: protobuf (>=3.4.0). paul:~/tensorflow$ cat unzip-1.10/tensorflow-1.10.1.dist-i",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:309,integrability,version,version,309,"Hi Ram,. You really do not want to have any errors show up in any of your tests, especially when performing variant calling. It's an easily fixable issue where the Google folks would just need to update their TensorFlow Python package distributed with DeepVariant, which was probably compiled with an earlier version of protobuf, while currently the Tensorflow requires `3.6` of protobuf and the Protobuf version being compiled with DeepVariant is `3.6`. Looking at your log file, you are using the CPU version. The current version on PyPI of TensorFlow is 1.10.1, and DeepVariant uses version 1.9. Here's the process by which I went about to determine what is happening:. 1. If you download both `whl` files of Tensorflow like this:. ```. wget https://storage.googleapis.com/deepvariant/packages/tensorflow/tensorflow-1.9.0.deepvariant_gcp-cp27-none-linux_x86_64.whl. wget https://files.pythonhosted.org/packages/1a/c4/8cb95df0bf06089014259b25997c3921a87aa08e2cd981417d91ca92f7e9/tensorflow-1.10.1-cp27-cp27mu-manylinux1_x86_64.whl. ```. 2. Next rename each of the `whl` files to `zip`, and then uncompress them in separate directories. If you then look at one of the version `1.10.1` files that has the `serialized_options` such as `purelib/tensorflow/core/framework/resource_handle_pb2.py`, you will see the following difference between the versions, where the `serialized_options` keyword is present in the `1.10.1` version, but not in the `1.9.0` version:. #### _*For version 1.9*_. ```Python. DESCRIPTOR = _descriptor.FileDescriptor(. name='tensorflow/core/framework/resource_handle.proto',. package='tensorflow',. syntax='proto3',. serialized_pb=_b('\n/tensorflow/core/framework/resource_handle.proto\x12\ntensorflow\""r\n\x13ResourceHandleProto\x12\x0e\n\x06\x64\x65vice\x18\x01 \x01(\t\x12\x11\n\tcontainer\x18\x02 \x01(\t\x12\x0c\n\x04name\x18\x03 \x01(\t\x12\x11\n\thash_code\x18\x04 \x01(\x04\x12\x17\n\x0fmaybe_type_name\x18\x05 \x01(\tBn\n\x18org.tensorflow.frameworkB\x0eResourceHandleP",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:405,integrability,version,version,405,"Hi Ram,. You really do not want to have any errors show up in any of your tests, especially when performing variant calling. It's an easily fixable issue where the Google folks would just need to update their TensorFlow Python package distributed with DeepVariant, which was probably compiled with an earlier version of protobuf, while currently the Tensorflow requires `3.6` of protobuf and the Protobuf version being compiled with DeepVariant is `3.6`. Looking at your log file, you are using the CPU version. The current version on PyPI of TensorFlow is 1.10.1, and DeepVariant uses version 1.9. Here's the process by which I went about to determine what is happening:. 1. If you download both `whl` files of Tensorflow like this:. ```. wget https://storage.googleapis.com/deepvariant/packages/tensorflow/tensorflow-1.9.0.deepvariant_gcp-cp27-none-linux_x86_64.whl. wget https://files.pythonhosted.org/packages/1a/c4/8cb95df0bf06089014259b25997c3921a87aa08e2cd981417d91ca92f7e9/tensorflow-1.10.1-cp27-cp27mu-manylinux1_x86_64.whl. ```. 2. Next rename each of the `whl` files to `zip`, and then uncompress them in separate directories. If you then look at one of the version `1.10.1` files that has the `serialized_options` such as `purelib/tensorflow/core/framework/resource_handle_pb2.py`, you will see the following difference between the versions, where the `serialized_options` keyword is present in the `1.10.1` version, but not in the `1.9.0` version:. #### _*For version 1.9*_. ```Python. DESCRIPTOR = _descriptor.FileDescriptor(. name='tensorflow/core/framework/resource_handle.proto',. package='tensorflow',. syntax='proto3',. serialized_pb=_b('\n/tensorflow/core/framework/resource_handle.proto\x12\ntensorflow\""r\n\x13ResourceHandleProto\x12\x0e\n\x06\x64\x65vice\x18\x01 \x01(\t\x12\x11\n\tcontainer\x18\x02 \x01(\t\x12\x0c\n\x04name\x18\x03 \x01(\t\x12\x11\n\thash_code\x18\x04 \x01(\x04\x12\x17\n\x0fmaybe_type_name\x18\x05 \x01(\tBn\n\x18org.tensorflow.frameworkB\x0eResourceHandleP",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:503,integrability,version,version,503,"Hi Ram,. You really do not want to have any errors show up in any of your tests, especially when performing variant calling. It's an easily fixable issue where the Google folks would just need to update their TensorFlow Python package distributed with DeepVariant, which was probably compiled with an earlier version of protobuf, while currently the Tensorflow requires `3.6` of protobuf and the Protobuf version being compiled with DeepVariant is `3.6`. Looking at your log file, you are using the CPU version. The current version on PyPI of TensorFlow is 1.10.1, and DeepVariant uses version 1.9. Here's the process by which I went about to determine what is happening:. 1. If you download both `whl` files of Tensorflow like this:. ```. wget https://storage.googleapis.com/deepvariant/packages/tensorflow/tensorflow-1.9.0.deepvariant_gcp-cp27-none-linux_x86_64.whl. wget https://files.pythonhosted.org/packages/1a/c4/8cb95df0bf06089014259b25997c3921a87aa08e2cd981417d91ca92f7e9/tensorflow-1.10.1-cp27-cp27mu-manylinux1_x86_64.whl. ```. 2. Next rename each of the `whl` files to `zip`, and then uncompress them in separate directories. If you then look at one of the version `1.10.1` files that has the `serialized_options` such as `purelib/tensorflow/core/framework/resource_handle_pb2.py`, you will see the following difference between the versions, where the `serialized_options` keyword is present in the `1.10.1` version, but not in the `1.9.0` version:. #### _*For version 1.9*_. ```Python. DESCRIPTOR = _descriptor.FileDescriptor(. name='tensorflow/core/framework/resource_handle.proto',. package='tensorflow',. syntax='proto3',. serialized_pb=_b('\n/tensorflow/core/framework/resource_handle.proto\x12\ntensorflow\""r\n\x13ResourceHandleProto\x12\x0e\n\x06\x64\x65vice\x18\x01 \x01(\t\x12\x11\n\tcontainer\x18\x02 \x01(\t\x12\x0c\n\x04name\x18\x03 \x01(\t\x12\x11\n\thash_code\x18\x04 \x01(\x04\x12\x17\n\x0fmaybe_type_name\x18\x05 \x01(\tBn\n\x18org.tensorflow.frameworkB\x0eResourceHandleP",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:524,integrability,version,version,524,"Hi Ram,. You really do not want to have any errors show up in any of your tests, especially when performing variant calling. It's an easily fixable issue where the Google folks would just need to update their TensorFlow Python package distributed with DeepVariant, which was probably compiled with an earlier version of protobuf, while currently the Tensorflow requires `3.6` of protobuf and the Protobuf version being compiled with DeepVariant is `3.6`. Looking at your log file, you are using the CPU version. The current version on PyPI of TensorFlow is 1.10.1, and DeepVariant uses version 1.9. Here's the process by which I went about to determine what is happening:. 1. If you download both `whl` files of Tensorflow like this:. ```. wget https://storage.googleapis.com/deepvariant/packages/tensorflow/tensorflow-1.9.0.deepvariant_gcp-cp27-none-linux_x86_64.whl. wget https://files.pythonhosted.org/packages/1a/c4/8cb95df0bf06089014259b25997c3921a87aa08e2cd981417d91ca92f7e9/tensorflow-1.10.1-cp27-cp27mu-manylinux1_x86_64.whl. ```. 2. Next rename each of the `whl` files to `zip`, and then uncompress them in separate directories. If you then look at one of the version `1.10.1` files that has the `serialized_options` such as `purelib/tensorflow/core/framework/resource_handle_pb2.py`, you will see the following difference between the versions, where the `serialized_options` keyword is present in the `1.10.1` version, but not in the `1.9.0` version:. #### _*For version 1.9*_. ```Python. DESCRIPTOR = _descriptor.FileDescriptor(. name='tensorflow/core/framework/resource_handle.proto',. package='tensorflow',. syntax='proto3',. serialized_pb=_b('\n/tensorflow/core/framework/resource_handle.proto\x12\ntensorflow\""r\n\x13ResourceHandleProto\x12\x0e\n\x06\x64\x65vice\x18\x01 \x01(\t\x12\x11\n\tcontainer\x18\x02 \x01(\t\x12\x0c\n\x04name\x18\x03 \x01(\t\x12\x11\n\thash_code\x18\x04 \x01(\x04\x12\x17\n\x0fmaybe_type_name\x18\x05 \x01(\tBn\n\x18org.tensorflow.frameworkB\x0eResourceHandleP",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:586,integrability,version,version,586,"Hi Ram,. You really do not want to have any errors show up in any of your tests, especially when performing variant calling. It's an easily fixable issue where the Google folks would just need to update their TensorFlow Python package distributed with DeepVariant, which was probably compiled with an earlier version of protobuf, while currently the Tensorflow requires `3.6` of protobuf and the Protobuf version being compiled with DeepVariant is `3.6`. Looking at your log file, you are using the CPU version. The current version on PyPI of TensorFlow is 1.10.1, and DeepVariant uses version 1.9. Here's the process by which I went about to determine what is happening:. 1. If you download both `whl` files of Tensorflow like this:. ```. wget https://storage.googleapis.com/deepvariant/packages/tensorflow/tensorflow-1.9.0.deepvariant_gcp-cp27-none-linux_x86_64.whl. wget https://files.pythonhosted.org/packages/1a/c4/8cb95df0bf06089014259b25997c3921a87aa08e2cd981417d91ca92f7e9/tensorflow-1.10.1-cp27-cp27mu-manylinux1_x86_64.whl. ```. 2. Next rename each of the `whl` files to `zip`, and then uncompress them in separate directories. If you then look at one of the version `1.10.1` files that has the `serialized_options` such as `purelib/tensorflow/core/framework/resource_handle_pb2.py`, you will see the following difference between the versions, where the `serialized_options` keyword is present in the `1.10.1` version, but not in the `1.9.0` version:. #### _*For version 1.9*_. ```Python. DESCRIPTOR = _descriptor.FileDescriptor(. name='tensorflow/core/framework/resource_handle.proto',. package='tensorflow',. syntax='proto3',. serialized_pb=_b('\n/tensorflow/core/framework/resource_handle.proto\x12\ntensorflow\""r\n\x13ResourceHandleProto\x12\x0e\n\x06\x64\x65vice\x18\x01 \x01(\t\x12\x11\n\tcontainer\x18\x02 \x01(\t\x12\x0c\n\x04name\x18\x03 \x01(\t\x12\x11\n\thash_code\x18\x04 \x01(\x04\x12\x17\n\x0fmaybe_type_name\x18\x05 \x01(\tBn\n\x18org.tensorflow.frameworkB\x0eResourceHandleP",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:1169,integrability,version,version,1169,"lks would just need to update their TensorFlow Python package distributed with DeepVariant, which was probably compiled with an earlier version of protobuf, while currently the Tensorflow requires `3.6` of protobuf and the Protobuf version being compiled with DeepVariant is `3.6`. Looking at your log file, you are using the CPU version. The current version on PyPI of TensorFlow is 1.10.1, and DeepVariant uses version 1.9. Here's the process by which I went about to determine what is happening:. 1. If you download both `whl` files of Tensorflow like this:. ```. wget https://storage.googleapis.com/deepvariant/packages/tensorflow/tensorflow-1.9.0.deepvariant_gcp-cp27-none-linux_x86_64.whl. wget https://files.pythonhosted.org/packages/1a/c4/8cb95df0bf06089014259b25997c3921a87aa08e2cd981417d91ca92f7e9/tensorflow-1.10.1-cp27-cp27mu-manylinux1_x86_64.whl. ```. 2. Next rename each of the `whl` files to `zip`, and then uncompress them in separate directories. If you then look at one of the version `1.10.1` files that has the `serialized_options` such as `purelib/tensorflow/core/framework/resource_handle_pb2.py`, you will see the following difference between the versions, where the `serialized_options` keyword is present in the `1.10.1` version, but not in the `1.9.0` version:. #### _*For version 1.9*_. ```Python. DESCRIPTOR = _descriptor.FileDescriptor(. name='tensorflow/core/framework/resource_handle.proto',. package='tensorflow',. syntax='proto3',. serialized_pb=_b('\n/tensorflow/core/framework/resource_handle.proto\x12\ntensorflow\""r\n\x13ResourceHandleProto\x12\x0e\n\x06\x64\x65vice\x18\x01 \x01(\t\x12\x11\n\tcontainer\x18\x02 \x01(\t\x12\x0c\n\x04name\x18\x03 \x01(\t\x12\x11\n\thash_code\x18\x04 \x01(\x04\x12\x17\n\x0fmaybe_type_name\x18\x05 \x01(\tBn\n\x18org.tensorflow.frameworkB\x0eResourceHandleP\x01Z=github.com/tensorflow/tensorflow/tensorflow/go/core/framework\xf8\x01\x01\x62\x06proto3'). ). ```. #### _*For version 1.10.1*_. ```Python. DESCRIPTOR = _descriptor.Fil",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:1344,integrability,version,versions,1344,"e Tensorflow requires `3.6` of protobuf and the Protobuf version being compiled with DeepVariant is `3.6`. Looking at your log file, you are using the CPU version. The current version on PyPI of TensorFlow is 1.10.1, and DeepVariant uses version 1.9. Here's the process by which I went about to determine what is happening:. 1. If you download both `whl` files of Tensorflow like this:. ```. wget https://storage.googleapis.com/deepvariant/packages/tensorflow/tensorflow-1.9.0.deepvariant_gcp-cp27-none-linux_x86_64.whl. wget https://files.pythonhosted.org/packages/1a/c4/8cb95df0bf06089014259b25997c3921a87aa08e2cd981417d91ca92f7e9/tensorflow-1.10.1-cp27-cp27mu-manylinux1_x86_64.whl. ```. 2. Next rename each of the `whl` files to `zip`, and then uncompress them in separate directories. If you then look at one of the version `1.10.1` files that has the `serialized_options` such as `purelib/tensorflow/core/framework/resource_handle_pb2.py`, you will see the following difference between the versions, where the `serialized_options` keyword is present in the `1.10.1` version, but not in the `1.9.0` version:. #### _*For version 1.9*_. ```Python. DESCRIPTOR = _descriptor.FileDescriptor(. name='tensorflow/core/framework/resource_handle.proto',. package='tensorflow',. syntax='proto3',. serialized_pb=_b('\n/tensorflow/core/framework/resource_handle.proto\x12\ntensorflow\""r\n\x13ResourceHandleProto\x12\x0e\n\x06\x64\x65vice\x18\x01 \x01(\t\x12\x11\n\tcontainer\x18\x02 \x01(\t\x12\x0c\n\x04name\x18\x03 \x01(\t\x12\x11\n\thash_code\x18\x04 \x01(\x04\x12\x17\n\x0fmaybe_type_name\x18\x05 \x01(\tBn\n\x18org.tensorflow.frameworkB\x0eResourceHandleP\x01Z=github.com/tensorflow/tensorflow/tensorflow/go/core/framework\xf8\x01\x01\x62\x06proto3'). ). ```. #### _*For version 1.10.1*_. ```Python. DESCRIPTOR = _descriptor.FileDescriptor(. name='tensorflow/core/framework/resource_handle.proto',. package='tensorflow',. syntax='proto3',. serialized_options=_b('\n\030org.tensorflow.frameworkB\016Resou",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:1420,integrability,version,version,1420,"led with DeepVariant is `3.6`. Looking at your log file, you are using the CPU version. The current version on PyPI of TensorFlow is 1.10.1, and DeepVariant uses version 1.9. Here's the process by which I went about to determine what is happening:. 1. If you download both `whl` files of Tensorflow like this:. ```. wget https://storage.googleapis.com/deepvariant/packages/tensorflow/tensorflow-1.9.0.deepvariant_gcp-cp27-none-linux_x86_64.whl. wget https://files.pythonhosted.org/packages/1a/c4/8cb95df0bf06089014259b25997c3921a87aa08e2cd981417d91ca92f7e9/tensorflow-1.10.1-cp27-cp27mu-manylinux1_x86_64.whl. ```. 2. Next rename each of the `whl` files to `zip`, and then uncompress them in separate directories. If you then look at one of the version `1.10.1` files that has the `serialized_options` such as `purelib/tensorflow/core/framework/resource_handle_pb2.py`, you will see the following difference between the versions, where the `serialized_options` keyword is present in the `1.10.1` version, but not in the `1.9.0` version:. #### _*For version 1.9*_. ```Python. DESCRIPTOR = _descriptor.FileDescriptor(. name='tensorflow/core/framework/resource_handle.proto',. package='tensorflow',. syntax='proto3',. serialized_pb=_b('\n/tensorflow/core/framework/resource_handle.proto\x12\ntensorflow\""r\n\x13ResourceHandleProto\x12\x0e\n\x06\x64\x65vice\x18\x01 \x01(\t\x12\x11\n\tcontainer\x18\x02 \x01(\t\x12\x0c\n\x04name\x18\x03 \x01(\t\x12\x11\n\thash_code\x18\x04 \x01(\x04\x12\x17\n\x0fmaybe_type_name\x18\x05 \x01(\tBn\n\x18org.tensorflow.frameworkB\x0eResourceHandleP\x01Z=github.com/tensorflow/tensorflow/tensorflow/go/core/framework\xf8\x01\x01\x62\x06proto3'). ). ```. #### _*For version 1.10.1*_. ```Python. DESCRIPTOR = _descriptor.FileDescriptor(. name='tensorflow/core/framework/resource_handle.proto',. package='tensorflow',. syntax='proto3',. serialized_options=_b('\n\030org.tensorflow.frameworkB\016ResourceHandleP\001Z=github.com/tensorflow/tensorflow/tensorflow/go/core/framewor",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:1452,integrability,version,version,1452,"ooking at your log file, you are using the CPU version. The current version on PyPI of TensorFlow is 1.10.1, and DeepVariant uses version 1.9. Here's the process by which I went about to determine what is happening:. 1. If you download both `whl` files of Tensorflow like this:. ```. wget https://storage.googleapis.com/deepvariant/packages/tensorflow/tensorflow-1.9.0.deepvariant_gcp-cp27-none-linux_x86_64.whl. wget https://files.pythonhosted.org/packages/1a/c4/8cb95df0bf06089014259b25997c3921a87aa08e2cd981417d91ca92f7e9/tensorflow-1.10.1-cp27-cp27mu-manylinux1_x86_64.whl. ```. 2. Next rename each of the `whl` files to `zip`, and then uncompress them in separate directories. If you then look at one of the version `1.10.1` files that has the `serialized_options` such as `purelib/tensorflow/core/framework/resource_handle_pb2.py`, you will see the following difference between the versions, where the `serialized_options` keyword is present in the `1.10.1` version, but not in the `1.9.0` version:. #### _*For version 1.9*_. ```Python. DESCRIPTOR = _descriptor.FileDescriptor(. name='tensorflow/core/framework/resource_handle.proto',. package='tensorflow',. syntax='proto3',. serialized_pb=_b('\n/tensorflow/core/framework/resource_handle.proto\x12\ntensorflow\""r\n\x13ResourceHandleProto\x12\x0e\n\x06\x64\x65vice\x18\x01 \x01(\t\x12\x11\n\tcontainer\x18\x02 \x01(\t\x12\x0c\n\x04name\x18\x03 \x01(\t\x12\x11\n\thash_code\x18\x04 \x01(\x04\x12\x17\n\x0fmaybe_type_name\x18\x05 \x01(\tBn\n\x18org.tensorflow.frameworkB\x0eResourceHandleP\x01Z=github.com/tensorflow/tensorflow/tensorflow/go/core/framework\xf8\x01\x01\x62\x06proto3'). ). ```. #### _*For version 1.10.1*_. ```Python. DESCRIPTOR = _descriptor.FileDescriptor(. name='tensorflow/core/framework/resource_handle.proto',. package='tensorflow',. syntax='proto3',. serialized_options=_b('\n\030org.tensorflow.frameworkB\016ResourceHandleP\001Z=github.com/tensorflow/tensorflow/tensorflow/go/core/framework\370\001\001'),. serialized_pb=",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:1473,integrability,version,version,1473,"le, you are using the CPU version. The current version on PyPI of TensorFlow is 1.10.1, and DeepVariant uses version 1.9. Here's the process by which I went about to determine what is happening:. 1. If you download both `whl` files of Tensorflow like this:. ```. wget https://storage.googleapis.com/deepvariant/packages/tensorflow/tensorflow-1.9.0.deepvariant_gcp-cp27-none-linux_x86_64.whl. wget https://files.pythonhosted.org/packages/1a/c4/8cb95df0bf06089014259b25997c3921a87aa08e2cd981417d91ca92f7e9/tensorflow-1.10.1-cp27-cp27mu-manylinux1_x86_64.whl. ```. 2. Next rename each of the `whl` files to `zip`, and then uncompress them in separate directories. If you then look at one of the version `1.10.1` files that has the `serialized_options` such as `purelib/tensorflow/core/framework/resource_handle_pb2.py`, you will see the following difference between the versions, where the `serialized_options` keyword is present in the `1.10.1` version, but not in the `1.9.0` version:. #### _*For version 1.9*_. ```Python. DESCRIPTOR = _descriptor.FileDescriptor(. name='tensorflow/core/framework/resource_handle.proto',. package='tensorflow',. syntax='proto3',. serialized_pb=_b('\n/tensorflow/core/framework/resource_handle.proto\x12\ntensorflow\""r\n\x13ResourceHandleProto\x12\x0e\n\x06\x64\x65vice\x18\x01 \x01(\t\x12\x11\n\tcontainer\x18\x02 \x01(\t\x12\x0c\n\x04name\x18\x03 \x01(\t\x12\x11\n\thash_code\x18\x04 \x01(\x04\x12\x17\n\x0fmaybe_type_name\x18\x05 \x01(\tBn\n\x18org.tensorflow.frameworkB\x0eResourceHandleP\x01Z=github.com/tensorflow/tensorflow/tensorflow/go/core/framework\xf8\x01\x01\x62\x06proto3'). ). ```. #### _*For version 1.10.1*_. ```Python. DESCRIPTOR = _descriptor.FileDescriptor(. name='tensorflow/core/framework/resource_handle.proto',. package='tensorflow',. syntax='proto3',. serialized_options=_b('\n\030org.tensorflow.frameworkB\016ResourceHandleP\001Z=github.com/tensorflow/tensorflow/tensorflow/go/core/framework\370\001\001'),. serialized_pb=_b('\n/tensorflow/cor",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:2116,integrability,version,version,2116,"rate directories. If you then look at one of the version `1.10.1` files that has the `serialized_options` such as `purelib/tensorflow/core/framework/resource_handle_pb2.py`, you will see the following difference between the versions, where the `serialized_options` keyword is present in the `1.10.1` version, but not in the `1.9.0` version:. #### _*For version 1.9*_. ```Python. DESCRIPTOR = _descriptor.FileDescriptor(. name='tensorflow/core/framework/resource_handle.proto',. package='tensorflow',. syntax='proto3',. serialized_pb=_b('\n/tensorflow/core/framework/resource_handle.proto\x12\ntensorflow\""r\n\x13ResourceHandleProto\x12\x0e\n\x06\x64\x65vice\x18\x01 \x01(\t\x12\x11\n\tcontainer\x18\x02 \x01(\t\x12\x0c\n\x04name\x18\x03 \x01(\t\x12\x11\n\thash_code\x18\x04 \x01(\x04\x12\x17\n\x0fmaybe_type_name\x18\x05 \x01(\tBn\n\x18org.tensorflow.frameworkB\x0eResourceHandleP\x01Z=github.com/tensorflow/tensorflow/tensorflow/go/core/framework\xf8\x01\x01\x62\x06proto3'). ). ```. #### _*For version 1.10.1*_. ```Python. DESCRIPTOR = _descriptor.FileDescriptor(. name='tensorflow/core/framework/resource_handle.proto',. package='tensorflow',. syntax='proto3',. serialized_options=_b('\n\030org.tensorflow.frameworkB\016ResourceHandleP\001Z=github.com/tensorflow/tensorflow/tensorflow/go/core/framework\370\001\001'),. serialized_pb=_b('\n/tensorflow/core/framework/resource_handle.proto\x12\ntensorflow\""r\n\x13ResourceHandleProto\x12\x0e\n\x06\x64\x65vice\x18\x01 \x01(\t\x12\x11\n\tcontainer\x18\x02 \x01(\t\x12\x0c\n\x04name\x18\x03 \x01(\t\x12\x11\n\thash_code\x18\x04 \x01(\x04\x12\x17\n\x0fmaybe_type_name\x18\x05 \x01(\tBn\n\x18org.tensorflow.frameworkB\x0eResourceHandleP\x01Z=github.com/tensorflow/tensorflow/tensorflow/go/core/framework\xf8\x01\x01\x62\x06proto3'). ). ```. ProtoBuf 3.6 passes the `serialized_options` argument in the call to `__new__` as shown here:. https://github.com/protocolbuffers/protobuf/blob/3.6.x/python/google/protobuf/descriptor.py#L283. ```Python. def __ne",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:3022,integrability,protocol,protocolbuffers,3022,"\x18\x05 \x01(\tBn\n\x18org.tensorflow.frameworkB\x0eResourceHandleP\x01Z=github.com/tensorflow/tensorflow/tensorflow/go/core/framework\xf8\x01\x01\x62\x06proto3'). ). ```. #### _*For version 1.10.1*_. ```Python. DESCRIPTOR = _descriptor.FileDescriptor(. name='tensorflow/core/framework/resource_handle.proto',. package='tensorflow',. syntax='proto3',. serialized_options=_b('\n\030org.tensorflow.frameworkB\016ResourceHandleP\001Z=github.com/tensorflow/tensorflow/tensorflow/go/core/framework\370\001\001'),. serialized_pb=_b('\n/tensorflow/core/framework/resource_handle.proto\x12\ntensorflow\""r\n\x13ResourceHandleProto\x12\x0e\n\x06\x64\x65vice\x18\x01 \x01(\t\x12\x11\n\tcontainer\x18\x02 \x01(\t\x12\x0c\n\x04name\x18\x03 \x01(\t\x12\x11\n\thash_code\x18\x04 \x01(\x04\x12\x17\n\x0fmaybe_type_name\x18\x05 \x01(\tBn\n\x18org.tensorflow.frameworkB\x0eResourceHandleP\x01Z=github.com/tensorflow/tensorflow/tensorflow/go/core/framework\xf8\x01\x01\x62\x06proto3'). ). ```. ProtoBuf 3.6 passes the `serialized_options` argument in the call to `__new__` as shown here:. https://github.com/protocolbuffers/protobuf/blob/3.6.x/python/google/protobuf/descriptor.py#L283. ```Python. def __new__(cls, name, full_name, filename, containing_type, fields,. nested_types, enum_types, extensions, options=None,. serialized_options=None,. is_extendable=True, extension_ranges=None, oneofs=None,. file=None, serialized_start=None, serialized_end=None, # pylint: disable=redefined-builtin. syntax=None):. _message.Message._CheckCalledFromGeneratedFile(). return _message.default_pool.FindMessageTypeByName(full_name). ```. 3. If you look at the `METADATA` file of each TensorFlow package to see the protobuf version requirement, it will look like this:. ```. paul:~/tensorflow$ cat unzip-1.9/tensorflow-1.9.0.dist-info/METADATA | grep protobuf. Requires-Dist: protobuf (>=3.4.0). paul:~/tensorflow$ cat unzip-1.10/tensorflow-1.10.1.dist-info/METADATA | grep protobuf. Requires-Dist: protobuf (>=3.6.0). ```. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:3434,integrability,Messag,Message,3434,"\x18\x05 \x01(\tBn\n\x18org.tensorflow.frameworkB\x0eResourceHandleP\x01Z=github.com/tensorflow/tensorflow/tensorflow/go/core/framework\xf8\x01\x01\x62\x06proto3'). ). ```. #### _*For version 1.10.1*_. ```Python. DESCRIPTOR = _descriptor.FileDescriptor(. name='tensorflow/core/framework/resource_handle.proto',. package='tensorflow',. syntax='proto3',. serialized_options=_b('\n\030org.tensorflow.frameworkB\016ResourceHandleP\001Z=github.com/tensorflow/tensorflow/tensorflow/go/core/framework\370\001\001'),. serialized_pb=_b('\n/tensorflow/core/framework/resource_handle.proto\x12\ntensorflow\""r\n\x13ResourceHandleProto\x12\x0e\n\x06\x64\x65vice\x18\x01 \x01(\t\x12\x11\n\tcontainer\x18\x02 \x01(\t\x12\x0c\n\x04name\x18\x03 \x01(\t\x12\x11\n\thash_code\x18\x04 \x01(\x04\x12\x17\n\x0fmaybe_type_name\x18\x05 \x01(\tBn\n\x18org.tensorflow.frameworkB\x0eResourceHandleP\x01Z=github.com/tensorflow/tensorflow/tensorflow/go/core/framework\xf8\x01\x01\x62\x06proto3'). ). ```. ProtoBuf 3.6 passes the `serialized_options` argument in the call to `__new__` as shown here:. https://github.com/protocolbuffers/protobuf/blob/3.6.x/python/google/protobuf/descriptor.py#L283. ```Python. def __new__(cls, name, full_name, filename, containing_type, fields,. nested_types, enum_types, extensions, options=None,. serialized_options=None,. is_extendable=True, extension_ranges=None, oneofs=None,. file=None, serialized_start=None, serialized_end=None, # pylint: disable=redefined-builtin. syntax=None):. _message.Message._CheckCalledFromGeneratedFile(). return _message.default_pool.FindMessageTypeByName(full_name). ```. 3. If you look at the `METADATA` file of each TensorFlow package to see the protobuf version requirement, it will look like this:. ```. paul:~/tensorflow$ cat unzip-1.9/tensorflow-1.9.0.dist-info/METADATA | grep protobuf. Requires-Dist: protobuf (>=3.4.0). paul:~/tensorflow$ cat unzip-1.10/tensorflow-1.10.1.dist-info/METADATA | grep protobuf. Requires-Dist: protobuf (>=3.6.0). ```. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:3628,integrability,version,version,3628,"\x18\x05 \x01(\tBn\n\x18org.tensorflow.frameworkB\x0eResourceHandleP\x01Z=github.com/tensorflow/tensorflow/tensorflow/go/core/framework\xf8\x01\x01\x62\x06proto3'). ). ```. #### _*For version 1.10.1*_. ```Python. DESCRIPTOR = _descriptor.FileDescriptor(. name='tensorflow/core/framework/resource_handle.proto',. package='tensorflow',. syntax='proto3',. serialized_options=_b('\n\030org.tensorflow.frameworkB\016ResourceHandleP\001Z=github.com/tensorflow/tensorflow/tensorflow/go/core/framework\370\001\001'),. serialized_pb=_b('\n/tensorflow/core/framework/resource_handle.proto\x12\ntensorflow\""r\n\x13ResourceHandleProto\x12\x0e\n\x06\x64\x65vice\x18\x01 \x01(\t\x12\x11\n\tcontainer\x18\x02 \x01(\t\x12\x0c\n\x04name\x18\x03 \x01(\t\x12\x11\n\thash_code\x18\x04 \x01(\x04\x12\x17\n\x0fmaybe_type_name\x18\x05 \x01(\tBn\n\x18org.tensorflow.frameworkB\x0eResourceHandleP\x01Z=github.com/tensorflow/tensorflow/tensorflow/go/core/framework\xf8\x01\x01\x62\x06proto3'). ). ```. ProtoBuf 3.6 passes the `serialized_options` argument in the call to `__new__` as shown here:. https://github.com/protocolbuffers/protobuf/blob/3.6.x/python/google/protobuf/descriptor.py#L283. ```Python. def __new__(cls, name, full_name, filename, containing_type, fields,. nested_types, enum_types, extensions, options=None,. serialized_options=None,. is_extendable=True, extension_ranges=None, oneofs=None,. file=None, serialized_start=None, serialized_end=None, # pylint: disable=redefined-builtin. syntax=None):. _message.Message._CheckCalledFromGeneratedFile(). return _message.default_pool.FindMessageTypeByName(full_name). ```. 3. If you look at the `METADATA` file of each TensorFlow package to see the protobuf version requirement, it will look like this:. ```. paul:~/tensorflow$ cat unzip-1.9/tensorflow-1.9.0.dist-info/METADATA | grep protobuf. Requires-Dist: protobuf (>=3.4.0). paul:~/tensorflow$ cat unzip-1.10/tensorflow-1.10.1.dist-info/METADATA | grep protobuf. Requires-Dist: protobuf (>=3.6.0). ```. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:235,interoperability,distribut,distributed,235,"Hi Ram,. You really do not want to have any errors show up in any of your tests, especially when performing variant calling. It's an easily fixable issue where the Google folks would just need to update their TensorFlow Python package distributed with DeepVariant, which was probably compiled with an earlier version of protobuf, while currently the Tensorflow requires `3.6` of protobuf and the Protobuf version being compiled with DeepVariant is `3.6`. Looking at your log file, you are using the CPU version. The current version on PyPI of TensorFlow is 1.10.1, and DeepVariant uses version 1.9. Here's the process by which I went about to determine what is happening:. 1. If you download both `whl` files of Tensorflow like this:. ```. wget https://storage.googleapis.com/deepvariant/packages/tensorflow/tensorflow-1.9.0.deepvariant_gcp-cp27-none-linux_x86_64.whl. wget https://files.pythonhosted.org/packages/1a/c4/8cb95df0bf06089014259b25997c3921a87aa08e2cd981417d91ca92f7e9/tensorflow-1.10.1-cp27-cp27mu-manylinux1_x86_64.whl. ```. 2. Next rename each of the `whl` files to `zip`, and then uncompress them in separate directories. If you then look at one of the version `1.10.1` files that has the `serialized_options` such as `purelib/tensorflow/core/framework/resource_handle_pb2.py`, you will see the following difference between the versions, where the `serialized_options` keyword is present in the `1.10.1` version, but not in the `1.9.0` version:. #### _*For version 1.9*_. ```Python. DESCRIPTOR = _descriptor.FileDescriptor(. name='tensorflow/core/framework/resource_handle.proto',. package='tensorflow',. syntax='proto3',. serialized_pb=_b('\n/tensorflow/core/framework/resource_handle.proto\x12\ntensorflow\""r\n\x13ResourceHandleProto\x12\x0e\n\x06\x64\x65vice\x18\x01 \x01(\t\x12\x11\n\tcontainer\x18\x02 \x01(\t\x12\x0c\n\x04name\x18\x03 \x01(\t\x12\x11\n\thash_code\x18\x04 \x01(\x04\x12\x17\n\x0fmaybe_type_name\x18\x05 \x01(\tBn\n\x18org.tensorflow.frameworkB\x0eResourceHandleP",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:3022,interoperability,protocol,protocolbuffers,3022,"\x18\x05 \x01(\tBn\n\x18org.tensorflow.frameworkB\x0eResourceHandleP\x01Z=github.com/tensorflow/tensorflow/tensorflow/go/core/framework\xf8\x01\x01\x62\x06proto3'). ). ```. #### _*For version 1.10.1*_. ```Python. DESCRIPTOR = _descriptor.FileDescriptor(. name='tensorflow/core/framework/resource_handle.proto',. package='tensorflow',. syntax='proto3',. serialized_options=_b('\n\030org.tensorflow.frameworkB\016ResourceHandleP\001Z=github.com/tensorflow/tensorflow/tensorflow/go/core/framework\370\001\001'),. serialized_pb=_b('\n/tensorflow/core/framework/resource_handle.proto\x12\ntensorflow\""r\n\x13ResourceHandleProto\x12\x0e\n\x06\x64\x65vice\x18\x01 \x01(\t\x12\x11\n\tcontainer\x18\x02 \x01(\t\x12\x0c\n\x04name\x18\x03 \x01(\t\x12\x11\n\thash_code\x18\x04 \x01(\x04\x12\x17\n\x0fmaybe_type_name\x18\x05 \x01(\tBn\n\x18org.tensorflow.frameworkB\x0eResourceHandleP\x01Z=github.com/tensorflow/tensorflow/tensorflow/go/core/framework\xf8\x01\x01\x62\x06proto3'). ). ```. ProtoBuf 3.6 passes the `serialized_options` argument in the call to `__new__` as shown here:. https://github.com/protocolbuffers/protobuf/blob/3.6.x/python/google/protobuf/descriptor.py#L283. ```Python. def __new__(cls, name, full_name, filename, containing_type, fields,. nested_types, enum_types, extensions, options=None,. serialized_options=None,. is_extendable=True, extension_ranges=None, oneofs=None,. file=None, serialized_start=None, serialized_end=None, # pylint: disable=redefined-builtin. syntax=None):. _message.Message._CheckCalledFromGeneratedFile(). return _message.default_pool.FindMessageTypeByName(full_name). ```. 3. If you look at the `METADATA` file of each TensorFlow package to see the protobuf version requirement, it will look like this:. ```. paul:~/tensorflow$ cat unzip-1.9/tensorflow-1.9.0.dist-info/METADATA | grep protobuf. Requires-Dist: protobuf (>=3.4.0). paul:~/tensorflow$ cat unzip-1.10/tensorflow-1.10.1.dist-info/METADATA | grep protobuf. Requires-Dist: protobuf (>=3.6.0). ```. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:3434,interoperability,Messag,Message,3434,"\x18\x05 \x01(\tBn\n\x18org.tensorflow.frameworkB\x0eResourceHandleP\x01Z=github.com/tensorflow/tensorflow/tensorflow/go/core/framework\xf8\x01\x01\x62\x06proto3'). ). ```. #### _*For version 1.10.1*_. ```Python. DESCRIPTOR = _descriptor.FileDescriptor(. name='tensorflow/core/framework/resource_handle.proto',. package='tensorflow',. syntax='proto3',. serialized_options=_b('\n\030org.tensorflow.frameworkB\016ResourceHandleP\001Z=github.com/tensorflow/tensorflow/tensorflow/go/core/framework\370\001\001'),. serialized_pb=_b('\n/tensorflow/core/framework/resource_handle.proto\x12\ntensorflow\""r\n\x13ResourceHandleProto\x12\x0e\n\x06\x64\x65vice\x18\x01 \x01(\t\x12\x11\n\tcontainer\x18\x02 \x01(\t\x12\x0c\n\x04name\x18\x03 \x01(\t\x12\x11\n\thash_code\x18\x04 \x01(\x04\x12\x17\n\x0fmaybe_type_name\x18\x05 \x01(\tBn\n\x18org.tensorflow.frameworkB\x0eResourceHandleP\x01Z=github.com/tensorflow/tensorflow/tensorflow/go/core/framework\xf8\x01\x01\x62\x06proto3'). ). ```. ProtoBuf 3.6 passes the `serialized_options` argument in the call to `__new__` as shown here:. https://github.com/protocolbuffers/protobuf/blob/3.6.x/python/google/protobuf/descriptor.py#L283. ```Python. def __new__(cls, name, full_name, filename, containing_type, fields,. nested_types, enum_types, extensions, options=None,. serialized_options=None,. is_extendable=True, extension_ranges=None, oneofs=None,. file=None, serialized_start=None, serialized_end=None, # pylint: disable=redefined-builtin. syntax=None):. _message.Message._CheckCalledFromGeneratedFile(). return _message.default_pool.FindMessageTypeByName(full_name). ```. 3. If you look at the `METADATA` file of each TensorFlow package to see the protobuf version requirement, it will look like this:. ```. paul:~/tensorflow$ cat unzip-1.9/tensorflow-1.9.0.dist-info/METADATA | grep protobuf. Requires-Dist: protobuf (>=3.4.0). paul:~/tensorflow$ cat unzip-1.10/tensorflow-1.10.1.dist-info/METADATA | grep protobuf. Requires-Dist: protobuf (>=3.6.0). ```. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:227,modifiability,pac,package,227,"Hi Ram,. You really do not want to have any errors show up in any of your tests, especially when performing variant calling. It's an easily fixable issue where the Google folks would just need to update their TensorFlow Python package distributed with DeepVariant, which was probably compiled with an earlier version of protobuf, while currently the Tensorflow requires `3.6` of protobuf and the Protobuf version being compiled with DeepVariant is `3.6`. Looking at your log file, you are using the CPU version. The current version on PyPI of TensorFlow is 1.10.1, and DeepVariant uses version 1.9. Here's the process by which I went about to determine what is happening:. 1. If you download both `whl` files of Tensorflow like this:. ```. wget https://storage.googleapis.com/deepvariant/packages/tensorflow/tensorflow-1.9.0.deepvariant_gcp-cp27-none-linux_x86_64.whl. wget https://files.pythonhosted.org/packages/1a/c4/8cb95df0bf06089014259b25997c3921a87aa08e2cd981417d91ca92f7e9/tensorflow-1.10.1-cp27-cp27mu-manylinux1_x86_64.whl. ```. 2. Next rename each of the `whl` files to `zip`, and then uncompress them in separate directories. If you then look at one of the version `1.10.1` files that has the `serialized_options` such as `purelib/tensorflow/core/framework/resource_handle_pb2.py`, you will see the following difference between the versions, where the `serialized_options` keyword is present in the `1.10.1` version, but not in the `1.9.0` version:. #### _*For version 1.9*_. ```Python. DESCRIPTOR = _descriptor.FileDescriptor(. name='tensorflow/core/framework/resource_handle.proto',. package='tensorflow',. syntax='proto3',. serialized_pb=_b('\n/tensorflow/core/framework/resource_handle.proto\x12\ntensorflow\""r\n\x13ResourceHandleProto\x12\x0e\n\x06\x64\x65vice\x18\x01 \x01(\t\x12\x11\n\tcontainer\x18\x02 \x01(\t\x12\x0c\n\x04name\x18\x03 \x01(\t\x12\x11\n\thash_code\x18\x04 \x01(\x04\x12\x17\n\x0fmaybe_type_name\x18\x05 \x01(\tBn\n\x18org.tensorflow.frameworkB\x0eResourceHandleP",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:309,modifiability,version,version,309,"Hi Ram,. You really do not want to have any errors show up in any of your tests, especially when performing variant calling. It's an easily fixable issue where the Google folks would just need to update their TensorFlow Python package distributed with DeepVariant, which was probably compiled with an earlier version of protobuf, while currently the Tensorflow requires `3.6` of protobuf and the Protobuf version being compiled with DeepVariant is `3.6`. Looking at your log file, you are using the CPU version. The current version on PyPI of TensorFlow is 1.10.1, and DeepVariant uses version 1.9. Here's the process by which I went about to determine what is happening:. 1. If you download both `whl` files of Tensorflow like this:. ```. wget https://storage.googleapis.com/deepvariant/packages/tensorflow/tensorflow-1.9.0.deepvariant_gcp-cp27-none-linux_x86_64.whl. wget https://files.pythonhosted.org/packages/1a/c4/8cb95df0bf06089014259b25997c3921a87aa08e2cd981417d91ca92f7e9/tensorflow-1.10.1-cp27-cp27mu-manylinux1_x86_64.whl. ```. 2. Next rename each of the `whl` files to `zip`, and then uncompress them in separate directories. If you then look at one of the version `1.10.1` files that has the `serialized_options` such as `purelib/tensorflow/core/framework/resource_handle_pb2.py`, you will see the following difference between the versions, where the `serialized_options` keyword is present in the `1.10.1` version, but not in the `1.9.0` version:. #### _*For version 1.9*_. ```Python. DESCRIPTOR = _descriptor.FileDescriptor(. name='tensorflow/core/framework/resource_handle.proto',. package='tensorflow',. syntax='proto3',. serialized_pb=_b('\n/tensorflow/core/framework/resource_handle.proto\x12\ntensorflow\""r\n\x13ResourceHandleProto\x12\x0e\n\x06\x64\x65vice\x18\x01 \x01(\t\x12\x11\n\tcontainer\x18\x02 \x01(\t\x12\x0c\n\x04name\x18\x03 \x01(\t\x12\x11\n\thash_code\x18\x04 \x01(\x04\x12\x17\n\x0fmaybe_type_name\x18\x05 \x01(\tBn\n\x18org.tensorflow.frameworkB\x0eResourceHandleP",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:405,modifiability,version,version,405,"Hi Ram,. You really do not want to have any errors show up in any of your tests, especially when performing variant calling. It's an easily fixable issue where the Google folks would just need to update their TensorFlow Python package distributed with DeepVariant, which was probably compiled with an earlier version of protobuf, while currently the Tensorflow requires `3.6` of protobuf and the Protobuf version being compiled with DeepVariant is `3.6`. Looking at your log file, you are using the CPU version. The current version on PyPI of TensorFlow is 1.10.1, and DeepVariant uses version 1.9. Here's the process by which I went about to determine what is happening:. 1. If you download both `whl` files of Tensorflow like this:. ```. wget https://storage.googleapis.com/deepvariant/packages/tensorflow/tensorflow-1.9.0.deepvariant_gcp-cp27-none-linux_x86_64.whl. wget https://files.pythonhosted.org/packages/1a/c4/8cb95df0bf06089014259b25997c3921a87aa08e2cd981417d91ca92f7e9/tensorflow-1.10.1-cp27-cp27mu-manylinux1_x86_64.whl. ```. 2. Next rename each of the `whl` files to `zip`, and then uncompress them in separate directories. If you then look at one of the version `1.10.1` files that has the `serialized_options` such as `purelib/tensorflow/core/framework/resource_handle_pb2.py`, you will see the following difference between the versions, where the `serialized_options` keyword is present in the `1.10.1` version, but not in the `1.9.0` version:. #### _*For version 1.9*_. ```Python. DESCRIPTOR = _descriptor.FileDescriptor(. name='tensorflow/core/framework/resource_handle.proto',. package='tensorflow',. syntax='proto3',. serialized_pb=_b('\n/tensorflow/core/framework/resource_handle.proto\x12\ntensorflow\""r\n\x13ResourceHandleProto\x12\x0e\n\x06\x64\x65vice\x18\x01 \x01(\t\x12\x11\n\tcontainer\x18\x02 \x01(\t\x12\x0c\n\x04name\x18\x03 \x01(\t\x12\x11\n\thash_code\x18\x04 \x01(\x04\x12\x17\n\x0fmaybe_type_name\x18\x05 \x01(\tBn\n\x18org.tensorflow.frameworkB\x0eResourceHandleP",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:503,modifiability,version,version,503,"Hi Ram,. You really do not want to have any errors show up in any of your tests, especially when performing variant calling. It's an easily fixable issue where the Google folks would just need to update their TensorFlow Python package distributed with DeepVariant, which was probably compiled with an earlier version of protobuf, while currently the Tensorflow requires `3.6` of protobuf and the Protobuf version being compiled with DeepVariant is `3.6`. Looking at your log file, you are using the CPU version. The current version on PyPI of TensorFlow is 1.10.1, and DeepVariant uses version 1.9. Here's the process by which I went about to determine what is happening:. 1. If you download both `whl` files of Tensorflow like this:. ```. wget https://storage.googleapis.com/deepvariant/packages/tensorflow/tensorflow-1.9.0.deepvariant_gcp-cp27-none-linux_x86_64.whl. wget https://files.pythonhosted.org/packages/1a/c4/8cb95df0bf06089014259b25997c3921a87aa08e2cd981417d91ca92f7e9/tensorflow-1.10.1-cp27-cp27mu-manylinux1_x86_64.whl. ```. 2. Next rename each of the `whl` files to `zip`, and then uncompress them in separate directories. If you then look at one of the version `1.10.1` files that has the `serialized_options` such as `purelib/tensorflow/core/framework/resource_handle_pb2.py`, you will see the following difference between the versions, where the `serialized_options` keyword is present in the `1.10.1` version, but not in the `1.9.0` version:. #### _*For version 1.9*_. ```Python. DESCRIPTOR = _descriptor.FileDescriptor(. name='tensorflow/core/framework/resource_handle.proto',. package='tensorflow',. syntax='proto3',. serialized_pb=_b('\n/tensorflow/core/framework/resource_handle.proto\x12\ntensorflow\""r\n\x13ResourceHandleProto\x12\x0e\n\x06\x64\x65vice\x18\x01 \x01(\t\x12\x11\n\tcontainer\x18\x02 \x01(\t\x12\x0c\n\x04name\x18\x03 \x01(\t\x12\x11\n\thash_code\x18\x04 \x01(\x04\x12\x17\n\x0fmaybe_type_name\x18\x05 \x01(\tBn\n\x18org.tensorflow.frameworkB\x0eResourceHandleP",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:524,modifiability,version,version,524,"Hi Ram,. You really do not want to have any errors show up in any of your tests, especially when performing variant calling. It's an easily fixable issue where the Google folks would just need to update their TensorFlow Python package distributed with DeepVariant, which was probably compiled with an earlier version of protobuf, while currently the Tensorflow requires `3.6` of protobuf and the Protobuf version being compiled with DeepVariant is `3.6`. Looking at your log file, you are using the CPU version. The current version on PyPI of TensorFlow is 1.10.1, and DeepVariant uses version 1.9. Here's the process by which I went about to determine what is happening:. 1. If you download both `whl` files of Tensorflow like this:. ```. wget https://storage.googleapis.com/deepvariant/packages/tensorflow/tensorflow-1.9.0.deepvariant_gcp-cp27-none-linux_x86_64.whl. wget https://files.pythonhosted.org/packages/1a/c4/8cb95df0bf06089014259b25997c3921a87aa08e2cd981417d91ca92f7e9/tensorflow-1.10.1-cp27-cp27mu-manylinux1_x86_64.whl. ```. 2. Next rename each of the `whl` files to `zip`, and then uncompress them in separate directories. If you then look at one of the version `1.10.1` files that has the `serialized_options` such as `purelib/tensorflow/core/framework/resource_handle_pb2.py`, you will see the following difference between the versions, where the `serialized_options` keyword is present in the `1.10.1` version, but not in the `1.9.0` version:. #### _*For version 1.9*_. ```Python. DESCRIPTOR = _descriptor.FileDescriptor(. name='tensorflow/core/framework/resource_handle.proto',. package='tensorflow',. syntax='proto3',. serialized_pb=_b('\n/tensorflow/core/framework/resource_handle.proto\x12\ntensorflow\""r\n\x13ResourceHandleProto\x12\x0e\n\x06\x64\x65vice\x18\x01 \x01(\t\x12\x11\n\tcontainer\x18\x02 \x01(\t\x12\x0c\n\x04name\x18\x03 \x01(\t\x12\x11\n\thash_code\x18\x04 \x01(\x04\x12\x17\n\x0fmaybe_type_name\x18\x05 \x01(\tBn\n\x18org.tensorflow.frameworkB\x0eResourceHandleP",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:586,modifiability,version,version,586,"Hi Ram,. You really do not want to have any errors show up in any of your tests, especially when performing variant calling. It's an easily fixable issue where the Google folks would just need to update their TensorFlow Python package distributed with DeepVariant, which was probably compiled with an earlier version of protobuf, while currently the Tensorflow requires `3.6` of protobuf and the Protobuf version being compiled with DeepVariant is `3.6`. Looking at your log file, you are using the CPU version. The current version on PyPI of TensorFlow is 1.10.1, and DeepVariant uses version 1.9. Here's the process by which I went about to determine what is happening:. 1. If you download both `whl` files of Tensorflow like this:. ```. wget https://storage.googleapis.com/deepvariant/packages/tensorflow/tensorflow-1.9.0.deepvariant_gcp-cp27-none-linux_x86_64.whl. wget https://files.pythonhosted.org/packages/1a/c4/8cb95df0bf06089014259b25997c3921a87aa08e2cd981417d91ca92f7e9/tensorflow-1.10.1-cp27-cp27mu-manylinux1_x86_64.whl. ```. 2. Next rename each of the `whl` files to `zip`, and then uncompress them in separate directories. If you then look at one of the version `1.10.1` files that has the `serialized_options` such as `purelib/tensorflow/core/framework/resource_handle_pb2.py`, you will see the following difference between the versions, where the `serialized_options` keyword is present in the `1.10.1` version, but not in the `1.9.0` version:. #### _*For version 1.9*_. ```Python. DESCRIPTOR = _descriptor.FileDescriptor(. name='tensorflow/core/framework/resource_handle.proto',. package='tensorflow',. syntax='proto3',. serialized_pb=_b('\n/tensorflow/core/framework/resource_handle.proto\x12\ntensorflow\""r\n\x13ResourceHandleProto\x12\x0e\n\x06\x64\x65vice\x18\x01 \x01(\t\x12\x11\n\tcontainer\x18\x02 \x01(\t\x12\x0c\n\x04name\x18\x03 \x01(\t\x12\x11\n\thash_code\x18\x04 \x01(\x04\x12\x17\n\x0fmaybe_type_name\x18\x05 \x01(\tBn\n\x18org.tensorflow.frameworkB\x0eResourceHandleP",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:788,modifiability,pac,packages,788,"Hi Ram,. You really do not want to have any errors show up in any of your tests, especially when performing variant calling. It's an easily fixable issue where the Google folks would just need to update their TensorFlow Python package distributed with DeepVariant, which was probably compiled with an earlier version of protobuf, while currently the Tensorflow requires `3.6` of protobuf and the Protobuf version being compiled with DeepVariant is `3.6`. Looking at your log file, you are using the CPU version. The current version on PyPI of TensorFlow is 1.10.1, and DeepVariant uses version 1.9. Here's the process by which I went about to determine what is happening:. 1. If you download both `whl` files of Tensorflow like this:. ```. wget https://storage.googleapis.com/deepvariant/packages/tensorflow/tensorflow-1.9.0.deepvariant_gcp-cp27-none-linux_x86_64.whl. wget https://files.pythonhosted.org/packages/1a/c4/8cb95df0bf06089014259b25997c3921a87aa08e2cd981417d91ca92f7e9/tensorflow-1.10.1-cp27-cp27mu-manylinux1_x86_64.whl. ```. 2. Next rename each of the `whl` files to `zip`, and then uncompress them in separate directories. If you then look at one of the version `1.10.1` files that has the `serialized_options` such as `purelib/tensorflow/core/framework/resource_handle_pb2.py`, you will see the following difference between the versions, where the `serialized_options` keyword is present in the `1.10.1` version, but not in the `1.9.0` version:. #### _*For version 1.9*_. ```Python. DESCRIPTOR = _descriptor.FileDescriptor(. name='tensorflow/core/framework/resource_handle.proto',. package='tensorflow',. syntax='proto3',. serialized_pb=_b('\n/tensorflow/core/framework/resource_handle.proto\x12\ntensorflow\""r\n\x13ResourceHandleProto\x12\x0e\n\x06\x64\x65vice\x18\x01 \x01(\t\x12\x11\n\tcontainer\x18\x02 \x01(\t\x12\x0c\n\x04name\x18\x03 \x01(\t\x12\x11\n\thash_code\x18\x04 \x01(\x04\x12\x17\n\x0fmaybe_type_name\x18\x05 \x01(\tBn\n\x18org.tensorflow.frameworkB\x0eResourceHandleP",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:905,modifiability,pac,packages,905,"Hi Ram,. You really do not want to have any errors show up in any of your tests, especially when performing variant calling. It's an easily fixable issue where the Google folks would just need to update their TensorFlow Python package distributed with DeepVariant, which was probably compiled with an earlier version of protobuf, while currently the Tensorflow requires `3.6` of protobuf and the Protobuf version being compiled with DeepVariant is `3.6`. Looking at your log file, you are using the CPU version. The current version on PyPI of TensorFlow is 1.10.1, and DeepVariant uses version 1.9. Here's the process by which I went about to determine what is happening:. 1. If you download both `whl` files of Tensorflow like this:. ```. wget https://storage.googleapis.com/deepvariant/packages/tensorflow/tensorflow-1.9.0.deepvariant_gcp-cp27-none-linux_x86_64.whl. wget https://files.pythonhosted.org/packages/1a/c4/8cb95df0bf06089014259b25997c3921a87aa08e2cd981417d91ca92f7e9/tensorflow-1.10.1-cp27-cp27mu-manylinux1_x86_64.whl. ```. 2. Next rename each of the `whl` files to `zip`, and then uncompress them in separate directories. If you then look at one of the version `1.10.1` files that has the `serialized_options` such as `purelib/tensorflow/core/framework/resource_handle_pb2.py`, you will see the following difference between the versions, where the `serialized_options` keyword is present in the `1.10.1` version, but not in the `1.9.0` version:. #### _*For version 1.9*_. ```Python. DESCRIPTOR = _descriptor.FileDescriptor(. name='tensorflow/core/framework/resource_handle.proto',. package='tensorflow',. syntax='proto3',. serialized_pb=_b('\n/tensorflow/core/framework/resource_handle.proto\x12\ntensorflow\""r\n\x13ResourceHandleProto\x12\x0e\n\x06\x64\x65vice\x18\x01 \x01(\t\x12\x11\n\tcontainer\x18\x02 \x01(\t\x12\x0c\n\x04name\x18\x03 \x01(\t\x12\x11\n\thash_code\x18\x04 \x01(\x04\x12\x17\n\x0fmaybe_type_name\x18\x05 \x01(\tBn\n\x18org.tensorflow.frameworkB\x0eResourceHandleP",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:1169,modifiability,version,version,1169,"lks would just need to update their TensorFlow Python package distributed with DeepVariant, which was probably compiled with an earlier version of protobuf, while currently the Tensorflow requires `3.6` of protobuf and the Protobuf version being compiled with DeepVariant is `3.6`. Looking at your log file, you are using the CPU version. The current version on PyPI of TensorFlow is 1.10.1, and DeepVariant uses version 1.9. Here's the process by which I went about to determine what is happening:. 1. If you download both `whl` files of Tensorflow like this:. ```. wget https://storage.googleapis.com/deepvariant/packages/tensorflow/tensorflow-1.9.0.deepvariant_gcp-cp27-none-linux_x86_64.whl. wget https://files.pythonhosted.org/packages/1a/c4/8cb95df0bf06089014259b25997c3921a87aa08e2cd981417d91ca92f7e9/tensorflow-1.10.1-cp27-cp27mu-manylinux1_x86_64.whl. ```. 2. Next rename each of the `whl` files to `zip`, and then uncompress them in separate directories. If you then look at one of the version `1.10.1` files that has the `serialized_options` such as `purelib/tensorflow/core/framework/resource_handle_pb2.py`, you will see the following difference between the versions, where the `serialized_options` keyword is present in the `1.10.1` version, but not in the `1.9.0` version:. #### _*For version 1.9*_. ```Python. DESCRIPTOR = _descriptor.FileDescriptor(. name='tensorflow/core/framework/resource_handle.proto',. package='tensorflow',. syntax='proto3',. serialized_pb=_b('\n/tensorflow/core/framework/resource_handle.proto\x12\ntensorflow\""r\n\x13ResourceHandleProto\x12\x0e\n\x06\x64\x65vice\x18\x01 \x01(\t\x12\x11\n\tcontainer\x18\x02 \x01(\t\x12\x0c\n\x04name\x18\x03 \x01(\t\x12\x11\n\thash_code\x18\x04 \x01(\x04\x12\x17\n\x0fmaybe_type_name\x18\x05 \x01(\tBn\n\x18org.tensorflow.frameworkB\x0eResourceHandleP\x01Z=github.com/tensorflow/tensorflow/tensorflow/go/core/framework\xf8\x01\x01\x62\x06proto3'). ). ```. #### _*For version 1.10.1*_. ```Python. DESCRIPTOR = _descriptor.Fil",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:1344,modifiability,version,versions,1344,"e Tensorflow requires `3.6` of protobuf and the Protobuf version being compiled with DeepVariant is `3.6`. Looking at your log file, you are using the CPU version. The current version on PyPI of TensorFlow is 1.10.1, and DeepVariant uses version 1.9. Here's the process by which I went about to determine what is happening:. 1. If you download both `whl` files of Tensorflow like this:. ```. wget https://storage.googleapis.com/deepvariant/packages/tensorflow/tensorflow-1.9.0.deepvariant_gcp-cp27-none-linux_x86_64.whl. wget https://files.pythonhosted.org/packages/1a/c4/8cb95df0bf06089014259b25997c3921a87aa08e2cd981417d91ca92f7e9/tensorflow-1.10.1-cp27-cp27mu-manylinux1_x86_64.whl. ```. 2. Next rename each of the `whl` files to `zip`, and then uncompress them in separate directories. If you then look at one of the version `1.10.1` files that has the `serialized_options` such as `purelib/tensorflow/core/framework/resource_handle_pb2.py`, you will see the following difference between the versions, where the `serialized_options` keyword is present in the `1.10.1` version, but not in the `1.9.0` version:. #### _*For version 1.9*_. ```Python. DESCRIPTOR = _descriptor.FileDescriptor(. name='tensorflow/core/framework/resource_handle.proto',. package='tensorflow',. syntax='proto3',. serialized_pb=_b('\n/tensorflow/core/framework/resource_handle.proto\x12\ntensorflow\""r\n\x13ResourceHandleProto\x12\x0e\n\x06\x64\x65vice\x18\x01 \x01(\t\x12\x11\n\tcontainer\x18\x02 \x01(\t\x12\x0c\n\x04name\x18\x03 \x01(\t\x12\x11\n\thash_code\x18\x04 \x01(\x04\x12\x17\n\x0fmaybe_type_name\x18\x05 \x01(\tBn\n\x18org.tensorflow.frameworkB\x0eResourceHandleP\x01Z=github.com/tensorflow/tensorflow/tensorflow/go/core/framework\xf8\x01\x01\x62\x06proto3'). ). ```. #### _*For version 1.10.1*_. ```Python. DESCRIPTOR = _descriptor.FileDescriptor(. name='tensorflow/core/framework/resource_handle.proto',. package='tensorflow',. syntax='proto3',. serialized_options=_b('\n\030org.tensorflow.frameworkB\016Resou",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:1420,modifiability,version,version,1420,"led with DeepVariant is `3.6`. Looking at your log file, you are using the CPU version. The current version on PyPI of TensorFlow is 1.10.1, and DeepVariant uses version 1.9. Here's the process by which I went about to determine what is happening:. 1. If you download both `whl` files of Tensorflow like this:. ```. wget https://storage.googleapis.com/deepvariant/packages/tensorflow/tensorflow-1.9.0.deepvariant_gcp-cp27-none-linux_x86_64.whl. wget https://files.pythonhosted.org/packages/1a/c4/8cb95df0bf06089014259b25997c3921a87aa08e2cd981417d91ca92f7e9/tensorflow-1.10.1-cp27-cp27mu-manylinux1_x86_64.whl. ```. 2. Next rename each of the `whl` files to `zip`, and then uncompress them in separate directories. If you then look at one of the version `1.10.1` files that has the `serialized_options` such as `purelib/tensorflow/core/framework/resource_handle_pb2.py`, you will see the following difference between the versions, where the `serialized_options` keyword is present in the `1.10.1` version, but not in the `1.9.0` version:. #### _*For version 1.9*_. ```Python. DESCRIPTOR = _descriptor.FileDescriptor(. name='tensorflow/core/framework/resource_handle.proto',. package='tensorflow',. syntax='proto3',. serialized_pb=_b('\n/tensorflow/core/framework/resource_handle.proto\x12\ntensorflow\""r\n\x13ResourceHandleProto\x12\x0e\n\x06\x64\x65vice\x18\x01 \x01(\t\x12\x11\n\tcontainer\x18\x02 \x01(\t\x12\x0c\n\x04name\x18\x03 \x01(\t\x12\x11\n\thash_code\x18\x04 \x01(\x04\x12\x17\n\x0fmaybe_type_name\x18\x05 \x01(\tBn\n\x18org.tensorflow.frameworkB\x0eResourceHandleP\x01Z=github.com/tensorflow/tensorflow/tensorflow/go/core/framework\xf8\x01\x01\x62\x06proto3'). ). ```. #### _*For version 1.10.1*_. ```Python. DESCRIPTOR = _descriptor.FileDescriptor(. name='tensorflow/core/framework/resource_handle.proto',. package='tensorflow',. syntax='proto3',. serialized_options=_b('\n\030org.tensorflow.frameworkB\016ResourceHandleP\001Z=github.com/tensorflow/tensorflow/tensorflow/go/core/framewor",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:1452,modifiability,version,version,1452,"ooking at your log file, you are using the CPU version. The current version on PyPI of TensorFlow is 1.10.1, and DeepVariant uses version 1.9. Here's the process by which I went about to determine what is happening:. 1. If you download both `whl` files of Tensorflow like this:. ```. wget https://storage.googleapis.com/deepvariant/packages/tensorflow/tensorflow-1.9.0.deepvariant_gcp-cp27-none-linux_x86_64.whl. wget https://files.pythonhosted.org/packages/1a/c4/8cb95df0bf06089014259b25997c3921a87aa08e2cd981417d91ca92f7e9/tensorflow-1.10.1-cp27-cp27mu-manylinux1_x86_64.whl. ```. 2. Next rename each of the `whl` files to `zip`, and then uncompress them in separate directories. If you then look at one of the version `1.10.1` files that has the `serialized_options` such as `purelib/tensorflow/core/framework/resource_handle_pb2.py`, you will see the following difference between the versions, where the `serialized_options` keyword is present in the `1.10.1` version, but not in the `1.9.0` version:. #### _*For version 1.9*_. ```Python. DESCRIPTOR = _descriptor.FileDescriptor(. name='tensorflow/core/framework/resource_handle.proto',. package='tensorflow',. syntax='proto3',. serialized_pb=_b('\n/tensorflow/core/framework/resource_handle.proto\x12\ntensorflow\""r\n\x13ResourceHandleProto\x12\x0e\n\x06\x64\x65vice\x18\x01 \x01(\t\x12\x11\n\tcontainer\x18\x02 \x01(\t\x12\x0c\n\x04name\x18\x03 \x01(\t\x12\x11\n\thash_code\x18\x04 \x01(\x04\x12\x17\n\x0fmaybe_type_name\x18\x05 \x01(\tBn\n\x18org.tensorflow.frameworkB\x0eResourceHandleP\x01Z=github.com/tensorflow/tensorflow/tensorflow/go/core/framework\xf8\x01\x01\x62\x06proto3'). ). ```. #### _*For version 1.10.1*_. ```Python. DESCRIPTOR = _descriptor.FileDescriptor(. name='tensorflow/core/framework/resource_handle.proto',. package='tensorflow',. syntax='proto3',. serialized_options=_b('\n\030org.tensorflow.frameworkB\016ResourceHandleP\001Z=github.com/tensorflow/tensorflow/tensorflow/go/core/framework\370\001\001'),. serialized_pb=",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:1473,modifiability,version,version,1473,"le, you are using the CPU version. The current version on PyPI of TensorFlow is 1.10.1, and DeepVariant uses version 1.9. Here's the process by which I went about to determine what is happening:. 1. If you download both `whl` files of Tensorflow like this:. ```. wget https://storage.googleapis.com/deepvariant/packages/tensorflow/tensorflow-1.9.0.deepvariant_gcp-cp27-none-linux_x86_64.whl. wget https://files.pythonhosted.org/packages/1a/c4/8cb95df0bf06089014259b25997c3921a87aa08e2cd981417d91ca92f7e9/tensorflow-1.10.1-cp27-cp27mu-manylinux1_x86_64.whl. ```. 2. Next rename each of the `whl` files to `zip`, and then uncompress them in separate directories. If you then look at one of the version `1.10.1` files that has the `serialized_options` such as `purelib/tensorflow/core/framework/resource_handle_pb2.py`, you will see the following difference between the versions, where the `serialized_options` keyword is present in the `1.10.1` version, but not in the `1.9.0` version:. #### _*For version 1.9*_. ```Python. DESCRIPTOR = _descriptor.FileDescriptor(. name='tensorflow/core/framework/resource_handle.proto',. package='tensorflow',. syntax='proto3',. serialized_pb=_b('\n/tensorflow/core/framework/resource_handle.proto\x12\ntensorflow\""r\n\x13ResourceHandleProto\x12\x0e\n\x06\x64\x65vice\x18\x01 \x01(\t\x12\x11\n\tcontainer\x18\x02 \x01(\t\x12\x0c\n\x04name\x18\x03 \x01(\t\x12\x11\n\thash_code\x18\x04 \x01(\x04\x12\x17\n\x0fmaybe_type_name\x18\x05 \x01(\tBn\n\x18org.tensorflow.frameworkB\x0eResourceHandleP\x01Z=github.com/tensorflow/tensorflow/tensorflow/go/core/framework\xf8\x01\x01\x62\x06proto3'). ). ```. #### _*For version 1.10.1*_. ```Python. DESCRIPTOR = _descriptor.FileDescriptor(. name='tensorflow/core/framework/resource_handle.proto',. package='tensorflow',. syntax='proto3',. serialized_options=_b('\n\030org.tensorflow.frameworkB\016ResourceHandleP\001Z=github.com/tensorflow/tensorflow/tensorflow/go/core/framework\370\001\001'),. serialized_pb=_b('\n/tensorflow/cor",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:1598,modifiability,pac,package,1598,"e's the process by which I went about to determine what is happening:. 1. If you download both `whl` files of Tensorflow like this:. ```. wget https://storage.googleapis.com/deepvariant/packages/tensorflow/tensorflow-1.9.0.deepvariant_gcp-cp27-none-linux_x86_64.whl. wget https://files.pythonhosted.org/packages/1a/c4/8cb95df0bf06089014259b25997c3921a87aa08e2cd981417d91ca92f7e9/tensorflow-1.10.1-cp27-cp27mu-manylinux1_x86_64.whl. ```. 2. Next rename each of the `whl` files to `zip`, and then uncompress them in separate directories. If you then look at one of the version `1.10.1` files that has the `serialized_options` such as `purelib/tensorflow/core/framework/resource_handle_pb2.py`, you will see the following difference between the versions, where the `serialized_options` keyword is present in the `1.10.1` version, but not in the `1.9.0` version:. #### _*For version 1.9*_. ```Python. DESCRIPTOR = _descriptor.FileDescriptor(. name='tensorflow/core/framework/resource_handle.proto',. package='tensorflow',. syntax='proto3',. serialized_pb=_b('\n/tensorflow/core/framework/resource_handle.proto\x12\ntensorflow\""r\n\x13ResourceHandleProto\x12\x0e\n\x06\x64\x65vice\x18\x01 \x01(\t\x12\x11\n\tcontainer\x18\x02 \x01(\t\x12\x0c\n\x04name\x18\x03 \x01(\t\x12\x11\n\thash_code\x18\x04 \x01(\x04\x12\x17\n\x0fmaybe_type_name\x18\x05 \x01(\tBn\n\x18org.tensorflow.frameworkB\x0eResourceHandleP\x01Z=github.com/tensorflow/tensorflow/tensorflow/go/core/framework\xf8\x01\x01\x62\x06proto3'). ). ```. #### _*For version 1.10.1*_. ```Python. DESCRIPTOR = _descriptor.FileDescriptor(. name='tensorflow/core/framework/resource_handle.proto',. package='tensorflow',. syntax='proto3',. serialized_options=_b('\n\030org.tensorflow.frameworkB\016ResourceHandleP\001Z=github.com/tensorflow/tensorflow/tensorflow/go/core/framework\370\001\001'),. serialized_pb=_b('\n/tensorflow/core/framework/resource_handle.proto\x12\ntensorflow\""r\n\x13ResourceHandleProto\x12\x0e\n\x06\x64\x65vice\x18\x01 \x01(\t\x12\x",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:2116,modifiability,version,version,2116,"rate directories. If you then look at one of the version `1.10.1` files that has the `serialized_options` such as `purelib/tensorflow/core/framework/resource_handle_pb2.py`, you will see the following difference between the versions, where the `serialized_options` keyword is present in the `1.10.1` version, but not in the `1.9.0` version:. #### _*For version 1.9*_. ```Python. DESCRIPTOR = _descriptor.FileDescriptor(. name='tensorflow/core/framework/resource_handle.proto',. package='tensorflow',. syntax='proto3',. serialized_pb=_b('\n/tensorflow/core/framework/resource_handle.proto\x12\ntensorflow\""r\n\x13ResourceHandleProto\x12\x0e\n\x06\x64\x65vice\x18\x01 \x01(\t\x12\x11\n\tcontainer\x18\x02 \x01(\t\x12\x0c\n\x04name\x18\x03 \x01(\t\x12\x11\n\thash_code\x18\x04 \x01(\x04\x12\x17\n\x0fmaybe_type_name\x18\x05 \x01(\tBn\n\x18org.tensorflow.frameworkB\x0eResourceHandleP\x01Z=github.com/tensorflow/tensorflow/tensorflow/go/core/framework\xf8\x01\x01\x62\x06proto3'). ). ```. #### _*For version 1.10.1*_. ```Python. DESCRIPTOR = _descriptor.FileDescriptor(. name='tensorflow/core/framework/resource_handle.proto',. package='tensorflow',. syntax='proto3',. serialized_options=_b('\n\030org.tensorflow.frameworkB\016ResourceHandleP\001Z=github.com/tensorflow/tensorflow/tensorflow/go/core/framework\370\001\001'),. serialized_pb=_b('\n/tensorflow/core/framework/resource_handle.proto\x12\ntensorflow\""r\n\x13ResourceHandleProto\x12\x0e\n\x06\x64\x65vice\x18\x01 \x01(\t\x12\x11\n\tcontainer\x18\x02 \x01(\t\x12\x0c\n\x04name\x18\x03 \x01(\t\x12\x11\n\thash_code\x18\x04 \x01(\x04\x12\x17\n\x0fmaybe_type_name\x18\x05 \x01(\tBn\n\x18org.tensorflow.frameworkB\x0eResourceHandleP\x01Z=github.com/tensorflow/tensorflow/tensorflow/go/core/framework\xf8\x01\x01\x62\x06proto3'). ). ```. ProtoBuf 3.6 passes the `serialized_options` argument in the call to `__new__` as shown here:. https://github.com/protocolbuffers/protobuf/blob/3.6.x/python/google/protobuf/descriptor.py#L283. ```Python. def __ne",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:2244,modifiability,pac,package,2244,"rflow/core/framework/resource_handle_pb2.py`, you will see the following difference between the versions, where the `serialized_options` keyword is present in the `1.10.1` version, but not in the `1.9.0` version:. #### _*For version 1.9*_. ```Python. DESCRIPTOR = _descriptor.FileDescriptor(. name='tensorflow/core/framework/resource_handle.proto',. package='tensorflow',. syntax='proto3',. serialized_pb=_b('\n/tensorflow/core/framework/resource_handle.proto\x12\ntensorflow\""r\n\x13ResourceHandleProto\x12\x0e\n\x06\x64\x65vice\x18\x01 \x01(\t\x12\x11\n\tcontainer\x18\x02 \x01(\t\x12\x0c\n\x04name\x18\x03 \x01(\t\x12\x11\n\thash_code\x18\x04 \x01(\x04\x12\x17\n\x0fmaybe_type_name\x18\x05 \x01(\tBn\n\x18org.tensorflow.frameworkB\x0eResourceHandleP\x01Z=github.com/tensorflow/tensorflow/tensorflow/go/core/framework\xf8\x01\x01\x62\x06proto3'). ). ```. #### _*For version 1.10.1*_. ```Python. DESCRIPTOR = _descriptor.FileDescriptor(. name='tensorflow/core/framework/resource_handle.proto',. package='tensorflow',. syntax='proto3',. serialized_options=_b('\n\030org.tensorflow.frameworkB\016ResourceHandleP\001Z=github.com/tensorflow/tensorflow/tensorflow/go/core/framework\370\001\001'),. serialized_pb=_b('\n/tensorflow/core/framework/resource_handle.proto\x12\ntensorflow\""r\n\x13ResourceHandleProto\x12\x0e\n\x06\x64\x65vice\x18\x01 \x01(\t\x12\x11\n\tcontainer\x18\x02 \x01(\t\x12\x0c\n\x04name\x18\x03 \x01(\t\x12\x11\n\thash_code\x18\x04 \x01(\x04\x12\x17\n\x0fmaybe_type_name\x18\x05 \x01(\tBn\n\x18org.tensorflow.frameworkB\x0eResourceHandleP\x01Z=github.com/tensorflow/tensorflow/tensorflow/go/core/framework\xf8\x01\x01\x62\x06proto3'). ). ```. ProtoBuf 3.6 passes the `serialized_options` argument in the call to `__new__` as shown here:. https://github.com/protocolbuffers/protobuf/blob/3.6.x/python/google/protobuf/descriptor.py#L283. ```Python. def __new__(cls, name, full_name, filename, containing_type, fields,. nested_types, enum_types, extensions, options=None,. serialized_op",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:3208,modifiability,extens,extensions,3208,"\x18\x05 \x01(\tBn\n\x18org.tensorflow.frameworkB\x0eResourceHandleP\x01Z=github.com/tensorflow/tensorflow/tensorflow/go/core/framework\xf8\x01\x01\x62\x06proto3'). ). ```. #### _*For version 1.10.1*_. ```Python. DESCRIPTOR = _descriptor.FileDescriptor(. name='tensorflow/core/framework/resource_handle.proto',. package='tensorflow',. syntax='proto3',. serialized_options=_b('\n\030org.tensorflow.frameworkB\016ResourceHandleP\001Z=github.com/tensorflow/tensorflow/tensorflow/go/core/framework\370\001\001'),. serialized_pb=_b('\n/tensorflow/core/framework/resource_handle.proto\x12\ntensorflow\""r\n\x13ResourceHandleProto\x12\x0e\n\x06\x64\x65vice\x18\x01 \x01(\t\x12\x11\n\tcontainer\x18\x02 \x01(\t\x12\x0c\n\x04name\x18\x03 \x01(\t\x12\x11\n\thash_code\x18\x04 \x01(\x04\x12\x17\n\x0fmaybe_type_name\x18\x05 \x01(\tBn\n\x18org.tensorflow.frameworkB\x0eResourceHandleP\x01Z=github.com/tensorflow/tensorflow/tensorflow/go/core/framework\xf8\x01\x01\x62\x06proto3'). ). ```. ProtoBuf 3.6 passes the `serialized_options` argument in the call to `__new__` as shown here:. https://github.com/protocolbuffers/protobuf/blob/3.6.x/python/google/protobuf/descriptor.py#L283. ```Python. def __new__(cls, name, full_name, filename, containing_type, fields,. nested_types, enum_types, extensions, options=None,. serialized_options=None,. is_extendable=True, extension_ranges=None, oneofs=None,. file=None, serialized_start=None, serialized_end=None, # pylint: disable=redefined-builtin. syntax=None):. _message.Message._CheckCalledFromGeneratedFile(). return _message.default_pool.FindMessageTypeByName(full_name). ```. 3. If you look at the `METADATA` file of each TensorFlow package to see the protobuf version requirement, it will look like this:. ```. paul:~/tensorflow$ cat unzip-1.9/tensorflow-1.9.0.dist-info/METADATA | grep protobuf. Requires-Dist: protobuf (>=3.4.0). paul:~/tensorflow$ cat unzip-1.10/tensorflow-1.10.1.dist-info/METADATA | grep protobuf. Requires-Dist: protobuf (>=3.6.0). ```. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:3600,modifiability,pac,package,3600,"\x18\x05 \x01(\tBn\n\x18org.tensorflow.frameworkB\x0eResourceHandleP\x01Z=github.com/tensorflow/tensorflow/tensorflow/go/core/framework\xf8\x01\x01\x62\x06proto3'). ). ```. #### _*For version 1.10.1*_. ```Python. DESCRIPTOR = _descriptor.FileDescriptor(. name='tensorflow/core/framework/resource_handle.proto',. package='tensorflow',. syntax='proto3',. serialized_options=_b('\n\030org.tensorflow.frameworkB\016ResourceHandleP\001Z=github.com/tensorflow/tensorflow/tensorflow/go/core/framework\370\001\001'),. serialized_pb=_b('\n/tensorflow/core/framework/resource_handle.proto\x12\ntensorflow\""r\n\x13ResourceHandleProto\x12\x0e\n\x06\x64\x65vice\x18\x01 \x01(\t\x12\x11\n\tcontainer\x18\x02 \x01(\t\x12\x0c\n\x04name\x18\x03 \x01(\t\x12\x11\n\thash_code\x18\x04 \x01(\x04\x12\x17\n\x0fmaybe_type_name\x18\x05 \x01(\tBn\n\x18org.tensorflow.frameworkB\x0eResourceHandleP\x01Z=github.com/tensorflow/tensorflow/tensorflow/go/core/framework\xf8\x01\x01\x62\x06proto3'). ). ```. ProtoBuf 3.6 passes the `serialized_options` argument in the call to `__new__` as shown here:. https://github.com/protocolbuffers/protobuf/blob/3.6.x/python/google/protobuf/descriptor.py#L283. ```Python. def __new__(cls, name, full_name, filename, containing_type, fields,. nested_types, enum_types, extensions, options=None,. serialized_options=None,. is_extendable=True, extension_ranges=None, oneofs=None,. file=None, serialized_start=None, serialized_end=None, # pylint: disable=redefined-builtin. syntax=None):. _message.Message._CheckCalledFromGeneratedFile(). return _message.default_pool.FindMessageTypeByName(full_name). ```. 3. If you look at the `METADATA` file of each TensorFlow package to see the protobuf version requirement, it will look like this:. ```. paul:~/tensorflow$ cat unzip-1.9/tensorflow-1.9.0.dist-info/METADATA | grep protobuf. Requires-Dist: protobuf (>=3.4.0). paul:~/tensorflow$ cat unzip-1.10/tensorflow-1.10.1.dist-info/METADATA | grep protobuf. Requires-Dist: protobuf (>=3.6.0). ```. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:3628,modifiability,version,version,3628,"\x18\x05 \x01(\tBn\n\x18org.tensorflow.frameworkB\x0eResourceHandleP\x01Z=github.com/tensorflow/tensorflow/tensorflow/go/core/framework\xf8\x01\x01\x62\x06proto3'). ). ```. #### _*For version 1.10.1*_. ```Python. DESCRIPTOR = _descriptor.FileDescriptor(. name='tensorflow/core/framework/resource_handle.proto',. package='tensorflow',. syntax='proto3',. serialized_options=_b('\n\030org.tensorflow.frameworkB\016ResourceHandleP\001Z=github.com/tensorflow/tensorflow/tensorflow/go/core/framework\370\001\001'),. serialized_pb=_b('\n/tensorflow/core/framework/resource_handle.proto\x12\ntensorflow\""r\n\x13ResourceHandleProto\x12\x0e\n\x06\x64\x65vice\x18\x01 \x01(\t\x12\x11\n\tcontainer\x18\x02 \x01(\t\x12\x0c\n\x04name\x18\x03 \x01(\t\x12\x11\n\thash_code\x18\x04 \x01(\x04\x12\x17\n\x0fmaybe_type_name\x18\x05 \x01(\tBn\n\x18org.tensorflow.frameworkB\x0eResourceHandleP\x01Z=github.com/tensorflow/tensorflow/tensorflow/go/core/framework\xf8\x01\x01\x62\x06proto3'). ). ```. ProtoBuf 3.6 passes the `serialized_options` argument in the call to `__new__` as shown here:. https://github.com/protocolbuffers/protobuf/blob/3.6.x/python/google/protobuf/descriptor.py#L283. ```Python. def __new__(cls, name, full_name, filename, containing_type, fields,. nested_types, enum_types, extensions, options=None,. serialized_options=None,. is_extendable=True, extension_ranges=None, oneofs=None,. file=None, serialized_start=None, serialized_end=None, # pylint: disable=redefined-builtin. syntax=None):. _message.Message._CheckCalledFromGeneratedFile(). return _message.default_pool.FindMessageTypeByName(full_name). ```. 3. If you look at the `METADATA` file of each TensorFlow package to see the protobuf version requirement, it will look like this:. ```. paul:~/tensorflow$ cat unzip-1.9/tensorflow-1.9.0.dist-info/METADATA | grep protobuf. Requires-Dist: protobuf (>=3.4.0). paul:~/tensorflow$ cat unzip-1.10/tensorflow-1.10.1.dist-info/METADATA | grep protobuf. Requires-Dist: protobuf (>=3.6.0). ```. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:44,performance,error,errors,44,"Hi Ram,. You really do not want to have any errors show up in any of your tests, especially when performing variant calling. It's an easily fixable issue where the Google folks would just need to update their TensorFlow Python package distributed with DeepVariant, which was probably compiled with an earlier version of protobuf, while currently the Tensorflow requires `3.6` of protobuf and the Protobuf version being compiled with DeepVariant is `3.6`. Looking at your log file, you are using the CPU version. The current version on PyPI of TensorFlow is 1.10.1, and DeepVariant uses version 1.9. Here's the process by which I went about to determine what is happening:. 1. If you download both `whl` files of Tensorflow like this:. ```. wget https://storage.googleapis.com/deepvariant/packages/tensorflow/tensorflow-1.9.0.deepvariant_gcp-cp27-none-linux_x86_64.whl. wget https://files.pythonhosted.org/packages/1a/c4/8cb95df0bf06089014259b25997c3921a87aa08e2cd981417d91ca92f7e9/tensorflow-1.10.1-cp27-cp27mu-manylinux1_x86_64.whl. ```. 2. Next rename each of the `whl` files to `zip`, and then uncompress them in separate directories. If you then look at one of the version `1.10.1` files that has the `serialized_options` such as `purelib/tensorflow/core/framework/resource_handle_pb2.py`, you will see the following difference between the versions, where the `serialized_options` keyword is present in the `1.10.1` version, but not in the `1.9.0` version:. #### _*For version 1.9*_. ```Python. DESCRIPTOR = _descriptor.FileDescriptor(. name='tensorflow/core/framework/resource_handle.proto',. package='tensorflow',. syntax='proto3',. serialized_pb=_b('\n/tensorflow/core/framework/resource_handle.proto\x12\ntensorflow\""r\n\x13ResourceHandleProto\x12\x0e\n\x06\x64\x65vice\x18\x01 \x01(\t\x12\x11\n\tcontainer\x18\x02 \x01(\t\x12\x0c\n\x04name\x18\x03 \x01(\t\x12\x11\n\thash_code\x18\x04 \x01(\x04\x12\x17\n\x0fmaybe_type_name\x18\x05 \x01(\tBn\n\x18org.tensorflow.frameworkB\x0eResourceHandleP",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:97,performance,perform,performing,97,"Hi Ram,. You really do not want to have any errors show up in any of your tests, especially when performing variant calling. It's an easily fixable issue where the Google folks would just need to update their TensorFlow Python package distributed with DeepVariant, which was probably compiled with an earlier version of protobuf, while currently the Tensorflow requires `3.6` of protobuf and the Protobuf version being compiled with DeepVariant is `3.6`. Looking at your log file, you are using the CPU version. The current version on PyPI of TensorFlow is 1.10.1, and DeepVariant uses version 1.9. Here's the process by which I went about to determine what is happening:. 1. If you download both `whl` files of Tensorflow like this:. ```. wget https://storage.googleapis.com/deepvariant/packages/tensorflow/tensorflow-1.9.0.deepvariant_gcp-cp27-none-linux_x86_64.whl. wget https://files.pythonhosted.org/packages/1a/c4/8cb95df0bf06089014259b25997c3921a87aa08e2cd981417d91ca92f7e9/tensorflow-1.10.1-cp27-cp27mu-manylinux1_x86_64.whl. ```. 2. Next rename each of the `whl` files to `zip`, and then uncompress them in separate directories. If you then look at one of the version `1.10.1` files that has the `serialized_options` such as `purelib/tensorflow/core/framework/resource_handle_pb2.py`, you will see the following difference between the versions, where the `serialized_options` keyword is present in the `1.10.1` version, but not in the `1.9.0` version:. #### _*For version 1.9*_. ```Python. DESCRIPTOR = _descriptor.FileDescriptor(. name='tensorflow/core/framework/resource_handle.proto',. package='tensorflow',. syntax='proto3',. serialized_pb=_b('\n/tensorflow/core/framework/resource_handle.proto\x12\ntensorflow\""r\n\x13ResourceHandleProto\x12\x0e\n\x06\x64\x65vice\x18\x01 \x01(\t\x12\x11\n\tcontainer\x18\x02 \x01(\t\x12\x0c\n\x04name\x18\x03 \x01(\t\x12\x11\n\thash_code\x18\x04 \x01(\x04\x12\x17\n\x0fmaybe_type_name\x18\x05 \x01(\tBn\n\x18org.tensorflow.frameworkB\x0eResourceHandleP",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:499,performance,CPU,CPU,499,"Hi Ram,. You really do not want to have any errors show up in any of your tests, especially when performing variant calling. It's an easily fixable issue where the Google folks would just need to update their TensorFlow Python package distributed with DeepVariant, which was probably compiled with an earlier version of protobuf, while currently the Tensorflow requires `3.6` of protobuf and the Protobuf version being compiled with DeepVariant is `3.6`. Looking at your log file, you are using the CPU version. The current version on PyPI of TensorFlow is 1.10.1, and DeepVariant uses version 1.9. Here's the process by which I went about to determine what is happening:. 1. If you download both `whl` files of Tensorflow like this:. ```. wget https://storage.googleapis.com/deepvariant/packages/tensorflow/tensorflow-1.9.0.deepvariant_gcp-cp27-none-linux_x86_64.whl. wget https://files.pythonhosted.org/packages/1a/c4/8cb95df0bf06089014259b25997c3921a87aa08e2cd981417d91ca92f7e9/tensorflow-1.10.1-cp27-cp27mu-manylinux1_x86_64.whl. ```. 2. Next rename each of the `whl` files to `zip`, and then uncompress them in separate directories. If you then look at one of the version `1.10.1` files that has the `serialized_options` such as `purelib/tensorflow/core/framework/resource_handle_pb2.py`, you will see the following difference between the versions, where the `serialized_options` keyword is present in the `1.10.1` version, but not in the `1.9.0` version:. #### _*For version 1.9*_. ```Python. DESCRIPTOR = _descriptor.FileDescriptor(. name='tensorflow/core/framework/resource_handle.proto',. package='tensorflow',. syntax='proto3',. serialized_pb=_b('\n/tensorflow/core/framework/resource_handle.proto\x12\ntensorflow\""r\n\x13ResourceHandleProto\x12\x0e\n\x06\x64\x65vice\x18\x01 \x01(\t\x12\x11\n\tcontainer\x18\x02 \x01(\t\x12\x0c\n\x04name\x18\x03 \x01(\t\x12\x11\n\thash_code\x18\x04 \x01(\x04\x12\x17\n\x0fmaybe_type_name\x18\x05 \x01(\tBn\n\x18org.tensorflow.frameworkB\x0eResourceHandleP",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:44,safety,error,errors,44,"Hi Ram,. You really do not want to have any errors show up in any of your tests, especially when performing variant calling. It's an easily fixable issue where the Google folks would just need to update their TensorFlow Python package distributed with DeepVariant, which was probably compiled with an earlier version of protobuf, while currently the Tensorflow requires `3.6` of protobuf and the Protobuf version being compiled with DeepVariant is `3.6`. Looking at your log file, you are using the CPU version. The current version on PyPI of TensorFlow is 1.10.1, and DeepVariant uses version 1.9. Here's the process by which I went about to determine what is happening:. 1. If you download both `whl` files of Tensorflow like this:. ```. wget https://storage.googleapis.com/deepvariant/packages/tensorflow/tensorflow-1.9.0.deepvariant_gcp-cp27-none-linux_x86_64.whl. wget https://files.pythonhosted.org/packages/1a/c4/8cb95df0bf06089014259b25997c3921a87aa08e2cd981417d91ca92f7e9/tensorflow-1.10.1-cp27-cp27mu-manylinux1_x86_64.whl. ```. 2. Next rename each of the `whl` files to `zip`, and then uncompress them in separate directories. If you then look at one of the version `1.10.1` files that has the `serialized_options` such as `purelib/tensorflow/core/framework/resource_handle_pb2.py`, you will see the following difference between the versions, where the `serialized_options` keyword is present in the `1.10.1` version, but not in the `1.9.0` version:. #### _*For version 1.9*_. ```Python. DESCRIPTOR = _descriptor.FileDescriptor(. name='tensorflow/core/framework/resource_handle.proto',. package='tensorflow',. syntax='proto3',. serialized_pb=_b('\n/tensorflow/core/framework/resource_handle.proto\x12\ntensorflow\""r\n\x13ResourceHandleProto\x12\x0e\n\x06\x64\x65vice\x18\x01 \x01(\t\x12\x11\n\tcontainer\x18\x02 \x01(\t\x12\x0c\n\x04name\x18\x03 \x01(\t\x12\x11\n\thash_code\x18\x04 \x01(\x04\x12\x17\n\x0fmaybe_type_name\x18\x05 \x01(\tBn\n\x18org.tensorflow.frameworkB\x0eResourceHandleP",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:74,safety,test,tests,74,"Hi Ram,. You really do not want to have any errors show up in any of your tests, especially when performing variant calling. It's an easily fixable issue where the Google folks would just need to update their TensorFlow Python package distributed with DeepVariant, which was probably compiled with an earlier version of protobuf, while currently the Tensorflow requires `3.6` of protobuf and the Protobuf version being compiled with DeepVariant is `3.6`. Looking at your log file, you are using the CPU version. The current version on PyPI of TensorFlow is 1.10.1, and DeepVariant uses version 1.9. Here's the process by which I went about to determine what is happening:. 1. If you download both `whl` files of Tensorflow like this:. ```. wget https://storage.googleapis.com/deepvariant/packages/tensorflow/tensorflow-1.9.0.deepvariant_gcp-cp27-none-linux_x86_64.whl. wget https://files.pythonhosted.org/packages/1a/c4/8cb95df0bf06089014259b25997c3921a87aa08e2cd981417d91ca92f7e9/tensorflow-1.10.1-cp27-cp27mu-manylinux1_x86_64.whl. ```. 2. Next rename each of the `whl` files to `zip`, and then uncompress them in separate directories. If you then look at one of the version `1.10.1` files that has the `serialized_options` such as `purelib/tensorflow/core/framework/resource_handle_pb2.py`, you will see the following difference between the versions, where the `serialized_options` keyword is present in the `1.10.1` version, but not in the `1.9.0` version:. #### _*For version 1.9*_. ```Python. DESCRIPTOR = _descriptor.FileDescriptor(. name='tensorflow/core/framework/resource_handle.proto',. package='tensorflow',. syntax='proto3',. serialized_pb=_b('\n/tensorflow/core/framework/resource_handle.proto\x12\ntensorflow\""r\n\x13ResourceHandleProto\x12\x0e\n\x06\x64\x65vice\x18\x01 \x01(\t\x12\x11\n\tcontainer\x18\x02 \x01(\t\x12\x0c\n\x04name\x18\x03 \x01(\t\x12\x11\n\thash_code\x18\x04 \x01(\x04\x12\x17\n\x0fmaybe_type_name\x18\x05 \x01(\tBn\n\x18org.tensorflow.frameworkB\x0eResourceHandleP",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:196,safety,updat,update,196,"Hi Ram,. You really do not want to have any errors show up in any of your tests, especially when performing variant calling. It's an easily fixable issue where the Google folks would just need to update their TensorFlow Python package distributed with DeepVariant, which was probably compiled with an earlier version of protobuf, while currently the Tensorflow requires `3.6` of protobuf and the Protobuf version being compiled with DeepVariant is `3.6`. Looking at your log file, you are using the CPU version. The current version on PyPI of TensorFlow is 1.10.1, and DeepVariant uses version 1.9. Here's the process by which I went about to determine what is happening:. 1. If you download both `whl` files of Tensorflow like this:. ```. wget https://storage.googleapis.com/deepvariant/packages/tensorflow/tensorflow-1.9.0.deepvariant_gcp-cp27-none-linux_x86_64.whl. wget https://files.pythonhosted.org/packages/1a/c4/8cb95df0bf06089014259b25997c3921a87aa08e2cd981417d91ca92f7e9/tensorflow-1.10.1-cp27-cp27mu-manylinux1_x86_64.whl. ```. 2. Next rename each of the `whl` files to `zip`, and then uncompress them in separate directories. If you then look at one of the version `1.10.1` files that has the `serialized_options` such as `purelib/tensorflow/core/framework/resource_handle_pb2.py`, you will see the following difference between the versions, where the `serialized_options` keyword is present in the `1.10.1` version, but not in the `1.9.0` version:. #### _*For version 1.9*_. ```Python. DESCRIPTOR = _descriptor.FileDescriptor(. name='tensorflow/core/framework/resource_handle.proto',. package='tensorflow',. syntax='proto3',. serialized_pb=_b('\n/tensorflow/core/framework/resource_handle.proto\x12\ntensorflow\""r\n\x13ResourceHandleProto\x12\x0e\n\x06\x64\x65vice\x18\x01 \x01(\t\x12\x11\n\tcontainer\x18\x02 \x01(\t\x12\x0c\n\x04name\x18\x03 \x01(\t\x12\x11\n\thash_code\x18\x04 \x01(\x04\x12\x17\n\x0fmaybe_type_name\x18\x05 \x01(\tBn\n\x18org.tensorflow.frameworkB\x0eResourceHandleP",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:471,safety,log,log,471,"Hi Ram,. You really do not want to have any errors show up in any of your tests, especially when performing variant calling. It's an easily fixable issue where the Google folks would just need to update their TensorFlow Python package distributed with DeepVariant, which was probably compiled with an earlier version of protobuf, while currently the Tensorflow requires `3.6` of protobuf and the Protobuf version being compiled with DeepVariant is `3.6`. Looking at your log file, you are using the CPU version. The current version on PyPI of TensorFlow is 1.10.1, and DeepVariant uses version 1.9. Here's the process by which I went about to determine what is happening:. 1. If you download both `whl` files of Tensorflow like this:. ```. wget https://storage.googleapis.com/deepvariant/packages/tensorflow/tensorflow-1.9.0.deepvariant_gcp-cp27-none-linux_x86_64.whl. wget https://files.pythonhosted.org/packages/1a/c4/8cb95df0bf06089014259b25997c3921a87aa08e2cd981417d91ca92f7e9/tensorflow-1.10.1-cp27-cp27mu-manylinux1_x86_64.whl. ```. 2. Next rename each of the `whl` files to `zip`, and then uncompress them in separate directories. If you then look at one of the version `1.10.1` files that has the `serialized_options` such as `purelib/tensorflow/core/framework/resource_handle_pb2.py`, you will see the following difference between the versions, where the `serialized_options` keyword is present in the `1.10.1` version, but not in the `1.9.0` version:. #### _*For version 1.9*_. ```Python. DESCRIPTOR = _descriptor.FileDescriptor(. name='tensorflow/core/framework/resource_handle.proto',. package='tensorflow',. syntax='proto3',. serialized_pb=_b('\n/tensorflow/core/framework/resource_handle.proto\x12\ntensorflow\""r\n\x13ResourceHandleProto\x12\x0e\n\x06\x64\x65vice\x18\x01 \x01(\t\x12\x11\n\tcontainer\x18\x02 \x01(\t\x12\x0c\n\x04name\x18\x03 \x01(\t\x12\x11\n\thash_code\x18\x04 \x01(\x04\x12\x17\n\x0fmaybe_type_name\x18\x05 \x01(\tBn\n\x18org.tensorflow.frameworkB\x0eResourceHandleP",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:196,security,updat,update,196,"Hi Ram,. You really do not want to have any errors show up in any of your tests, especially when performing variant calling. It's an easily fixable issue where the Google folks would just need to update their TensorFlow Python package distributed with DeepVariant, which was probably compiled with an earlier version of protobuf, while currently the Tensorflow requires `3.6` of protobuf and the Protobuf version being compiled with DeepVariant is `3.6`. Looking at your log file, you are using the CPU version. The current version on PyPI of TensorFlow is 1.10.1, and DeepVariant uses version 1.9. Here's the process by which I went about to determine what is happening:. 1. If you download both `whl` files of Tensorflow like this:. ```. wget https://storage.googleapis.com/deepvariant/packages/tensorflow/tensorflow-1.9.0.deepvariant_gcp-cp27-none-linux_x86_64.whl. wget https://files.pythonhosted.org/packages/1a/c4/8cb95df0bf06089014259b25997c3921a87aa08e2cd981417d91ca92f7e9/tensorflow-1.10.1-cp27-cp27mu-manylinux1_x86_64.whl. ```. 2. Next rename each of the `whl` files to `zip`, and then uncompress them in separate directories. If you then look at one of the version `1.10.1` files that has the `serialized_options` such as `purelib/tensorflow/core/framework/resource_handle_pb2.py`, you will see the following difference between the versions, where the `serialized_options` keyword is present in the `1.10.1` version, but not in the `1.9.0` version:. #### _*For version 1.9*_. ```Python. DESCRIPTOR = _descriptor.FileDescriptor(. name='tensorflow/core/framework/resource_handle.proto',. package='tensorflow',. syntax='proto3',. serialized_pb=_b('\n/tensorflow/core/framework/resource_handle.proto\x12\ntensorflow\""r\n\x13ResourceHandleProto\x12\x0e\n\x06\x64\x65vice\x18\x01 \x01(\t\x12\x11\n\tcontainer\x18\x02 \x01(\t\x12\x0c\n\x04name\x18\x03 \x01(\t\x12\x11\n\thash_code\x18\x04 \x01(\x04\x12\x17\n\x0fmaybe_type_name\x18\x05 \x01(\tBn\n\x18org.tensorflow.frameworkB\x0eResourceHandleP",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:471,security,log,log,471,"Hi Ram,. You really do not want to have any errors show up in any of your tests, especially when performing variant calling. It's an easily fixable issue where the Google folks would just need to update their TensorFlow Python package distributed with DeepVariant, which was probably compiled with an earlier version of protobuf, while currently the Tensorflow requires `3.6` of protobuf and the Protobuf version being compiled with DeepVariant is `3.6`. Looking at your log file, you are using the CPU version. The current version on PyPI of TensorFlow is 1.10.1, and DeepVariant uses version 1.9. Here's the process by which I went about to determine what is happening:. 1. If you download both `whl` files of Tensorflow like this:. ```. wget https://storage.googleapis.com/deepvariant/packages/tensorflow/tensorflow-1.9.0.deepvariant_gcp-cp27-none-linux_x86_64.whl. wget https://files.pythonhosted.org/packages/1a/c4/8cb95df0bf06089014259b25997c3921a87aa08e2cd981417d91ca92f7e9/tensorflow-1.10.1-cp27-cp27mu-manylinux1_x86_64.whl. ```. 2. Next rename each of the `whl` files to `zip`, and then uncompress them in separate directories. If you then look at one of the version `1.10.1` files that has the `serialized_options` such as `purelib/tensorflow/core/framework/resource_handle_pb2.py`, you will see the following difference between the versions, where the `serialized_options` keyword is present in the `1.10.1` version, but not in the `1.9.0` version:. #### _*For version 1.9*_. ```Python. DESCRIPTOR = _descriptor.FileDescriptor(. name='tensorflow/core/framework/resource_handle.proto',. package='tensorflow',. syntax='proto3',. serialized_pb=_b('\n/tensorflow/core/framework/resource_handle.proto\x12\ntensorflow\""r\n\x13ResourceHandleProto\x12\x0e\n\x06\x64\x65vice\x18\x01 \x01(\t\x12\x11\n\tcontainer\x18\x02 \x01(\t\x12\x0c\n\x04name\x18\x03 \x01(\t\x12\x11\n\thash_code\x18\x04 \x01(\x04\x12\x17\n\x0fmaybe_type_name\x18\x05 \x01(\tBn\n\x18org.tensorflow.frameworkB\x0eResourceHandleP",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:74,testability,test,tests,74,"Hi Ram,. You really do not want to have any errors show up in any of your tests, especially when performing variant calling. It's an easily fixable issue where the Google folks would just need to update their TensorFlow Python package distributed with DeepVariant, which was probably compiled with an earlier version of protobuf, while currently the Tensorflow requires `3.6` of protobuf and the Protobuf version being compiled with DeepVariant is `3.6`. Looking at your log file, you are using the CPU version. The current version on PyPI of TensorFlow is 1.10.1, and DeepVariant uses version 1.9. Here's the process by which I went about to determine what is happening:. 1. If you download both `whl` files of Tensorflow like this:. ```. wget https://storage.googleapis.com/deepvariant/packages/tensorflow/tensorflow-1.9.0.deepvariant_gcp-cp27-none-linux_x86_64.whl. wget https://files.pythonhosted.org/packages/1a/c4/8cb95df0bf06089014259b25997c3921a87aa08e2cd981417d91ca92f7e9/tensorflow-1.10.1-cp27-cp27mu-manylinux1_x86_64.whl. ```. 2. Next rename each of the `whl` files to `zip`, and then uncompress them in separate directories. If you then look at one of the version `1.10.1` files that has the `serialized_options` such as `purelib/tensorflow/core/framework/resource_handle_pb2.py`, you will see the following difference between the versions, where the `serialized_options` keyword is present in the `1.10.1` version, but not in the `1.9.0` version:. #### _*For version 1.9*_. ```Python. DESCRIPTOR = _descriptor.FileDescriptor(. name='tensorflow/core/framework/resource_handle.proto',. package='tensorflow',. syntax='proto3',. serialized_pb=_b('\n/tensorflow/core/framework/resource_handle.proto\x12\ntensorflow\""r\n\x13ResourceHandleProto\x12\x0e\n\x06\x64\x65vice\x18\x01 \x01(\t\x12\x11\n\tcontainer\x18\x02 \x01(\t\x12\x0c\n\x04name\x18\x03 \x01(\t\x12\x11\n\thash_code\x18\x04 \x01(\x04\x12\x17\n\x0fmaybe_type_name\x18\x05 \x01(\tBn\n\x18org.tensorflow.frameworkB\x0eResourceHandleP",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:471,testability,log,log,471,"Hi Ram,. You really do not want to have any errors show up in any of your tests, especially when performing variant calling. It's an easily fixable issue where the Google folks would just need to update their TensorFlow Python package distributed with DeepVariant, which was probably compiled with an earlier version of protobuf, while currently the Tensorflow requires `3.6` of protobuf and the Protobuf version being compiled with DeepVariant is `3.6`. Looking at your log file, you are using the CPU version. The current version on PyPI of TensorFlow is 1.10.1, and DeepVariant uses version 1.9. Here's the process by which I went about to determine what is happening:. 1. If you download both `whl` files of Tensorflow like this:. ```. wget https://storage.googleapis.com/deepvariant/packages/tensorflow/tensorflow-1.9.0.deepvariant_gcp-cp27-none-linux_x86_64.whl. wget https://files.pythonhosted.org/packages/1a/c4/8cb95df0bf06089014259b25997c3921a87aa08e2cd981417d91ca92f7e9/tensorflow-1.10.1-cp27-cp27mu-manylinux1_x86_64.whl. ```. 2. Next rename each of the `whl` files to `zip`, and then uncompress them in separate directories. If you then look at one of the version `1.10.1` files that has the `serialized_options` such as `purelib/tensorflow/core/framework/resource_handle_pb2.py`, you will see the following difference between the versions, where the `serialized_options` keyword is present in the `1.10.1` version, but not in the `1.9.0` version:. #### _*For version 1.9*_. ```Python. DESCRIPTOR = _descriptor.FileDescriptor(. name='tensorflow/core/framework/resource_handle.proto',. package='tensorflow',. syntax='proto3',. serialized_pb=_b('\n/tensorflow/core/framework/resource_handle.proto\x12\ntensorflow\""r\n\x13ResourceHandleProto\x12\x0e\n\x06\x64\x65vice\x18\x01 \x01(\t\x12\x11\n\tcontainer\x18\x02 \x01(\t\x12\x0c\n\x04name\x18\x03 \x01(\t\x12\x11\n\thash_code\x18\x04 \x01(\x04\x12\x17\n\x0fmaybe_type_name\x18\x05 \x01(\tBn\n\x18org.tensorflow.frameworkB\x0eResourceHandleP",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:44,usability,error,errors,44,"Hi Ram,. You really do not want to have any errors show up in any of your tests, especially when performing variant calling. It's an easily fixable issue where the Google folks would just need to update their TensorFlow Python package distributed with DeepVariant, which was probably compiled with an earlier version of protobuf, while currently the Tensorflow requires `3.6` of protobuf and the Protobuf version being compiled with DeepVariant is `3.6`. Looking at your log file, you are using the CPU version. The current version on PyPI of TensorFlow is 1.10.1, and DeepVariant uses version 1.9. Here's the process by which I went about to determine what is happening:. 1. If you download both `whl` files of Tensorflow like this:. ```. wget https://storage.googleapis.com/deepvariant/packages/tensorflow/tensorflow-1.9.0.deepvariant_gcp-cp27-none-linux_x86_64.whl. wget https://files.pythonhosted.org/packages/1a/c4/8cb95df0bf06089014259b25997c3921a87aa08e2cd981417d91ca92f7e9/tensorflow-1.10.1-cp27-cp27mu-manylinux1_x86_64.whl. ```. 2. Next rename each of the `whl` files to `zip`, and then uncompress them in separate directories. If you then look at one of the version `1.10.1` files that has the `serialized_options` such as `purelib/tensorflow/core/framework/resource_handle_pb2.py`, you will see the following difference between the versions, where the `serialized_options` keyword is present in the `1.10.1` version, but not in the `1.9.0` version:. #### _*For version 1.9*_. ```Python. DESCRIPTOR = _descriptor.FileDescriptor(. name='tensorflow/core/framework/resource_handle.proto',. package='tensorflow',. syntax='proto3',. serialized_pb=_b('\n/tensorflow/core/framework/resource_handle.proto\x12\ntensorflow\""r\n\x13ResourceHandleProto\x12\x0e\n\x06\x64\x65vice\x18\x01 \x01(\t\x12\x11\n\tcontainer\x18\x02 \x01(\t\x12\x0c\n\x04name\x18\x03 \x01(\t\x12\x11\n\thash_code\x18\x04 \x01(\x04\x12\x17\n\x0fmaybe_type_name\x18\x05 \x01(\tBn\n\x18org.tensorflow.frameworkB\x0eResourceHandleP",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:97,usability,perform,performing,97,"Hi Ram,. You really do not want to have any errors show up in any of your tests, especially when performing variant calling. It's an easily fixable issue where the Google folks would just need to update their TensorFlow Python package distributed with DeepVariant, which was probably compiled with an earlier version of protobuf, while currently the Tensorflow requires `3.6` of protobuf and the Protobuf version being compiled with DeepVariant is `3.6`. Looking at your log file, you are using the CPU version. The current version on PyPI of TensorFlow is 1.10.1, and DeepVariant uses version 1.9. Here's the process by which I went about to determine what is happening:. 1. If you download both `whl` files of Tensorflow like this:. ```. wget https://storage.googleapis.com/deepvariant/packages/tensorflow/tensorflow-1.9.0.deepvariant_gcp-cp27-none-linux_x86_64.whl. wget https://files.pythonhosted.org/packages/1a/c4/8cb95df0bf06089014259b25997c3921a87aa08e2cd981417d91ca92f7e9/tensorflow-1.10.1-cp27-cp27mu-manylinux1_x86_64.whl. ```. 2. Next rename each of the `whl` files to `zip`, and then uncompress them in separate directories. If you then look at one of the version `1.10.1` files that has the `serialized_options` such as `purelib/tensorflow/core/framework/resource_handle_pb2.py`, you will see the following difference between the versions, where the `serialized_options` keyword is present in the `1.10.1` version, but not in the `1.9.0` version:. #### _*For version 1.9*_. ```Python. DESCRIPTOR = _descriptor.FileDescriptor(. name='tensorflow/core/framework/resource_handle.proto',. package='tensorflow',. syntax='proto3',. serialized_pb=_b('\n/tensorflow/core/framework/resource_handle.proto\x12\ntensorflow\""r\n\x13ResourceHandleProto\x12\x0e\n\x06\x64\x65vice\x18\x01 \x01(\t\x12\x11\n\tcontainer\x18\x02 \x01(\t\x12\x0c\n\x04name\x18\x03 \x01(\t\x12\x11\n\thash_code\x18\x04 \x01(\x04\x12\x17\n\x0fmaybe_type_name\x18\x05 \x01(\tBn\n\x18org.tensorflow.frameworkB\x0eResourceHandleP",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:203,deployability,build,build-prereq,203,"Thanks paul for the detailed analysis and explanation of how you went about it. To confirm this analysis I tried out by changing TF_WHL_VERSION and other related symbols to 1.10.1 in settings.sh so that build-prereq.sh installs the matching tensorflow. Now, the build and test passes and I am able to run variant calling. I presume this is a good workaround to address this issue.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:219,deployability,instal,installs,219,"Thanks paul for the detailed analysis and explanation of how you went about it. To confirm this analysis I tried out by changing TF_WHL_VERSION and other related symbols to 1.10.1 in settings.sh so that build-prereq.sh installs the matching tensorflow. Now, the build and test passes and I am able to run variant calling. I presume this is a good workaround to address this issue.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:262,deployability,build,build,262,"Thanks paul for the detailed analysis and explanation of how you went about it. To confirm this analysis I tried out by changing TF_WHL_VERSION and other related symbols to 1.10.1 in settings.sh so that build-prereq.sh installs the matching tensorflow. Now, the build and test passes and I am able to run variant calling. I presume this is a good workaround to address this issue.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:272,safety,test,test,272,"Thanks paul for the detailed analysis and explanation of how you went about it. To confirm this analysis I tried out by changing TF_WHL_VERSION and other related symbols to 1.10.1 in settings.sh so that build-prereq.sh installs the matching tensorflow. Now, the build and test passes and I am able to run variant calling. I presume this is a good workaround to address this issue.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:272,testability,test,test,272,"Thanks paul for the detailed analysis and explanation of how you went about it. To confirm this analysis I tried out by changing TF_WHL_VERSION and other related symbols to 1.10.1 in settings.sh so that build-prereq.sh installs the matching tensorflow. Now, the build and test passes and I am able to run variant calling. I presume this is a good workaround to address this issue.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:83,usability,confirm,confirm,83,"Thanks paul for the detailed analysis and explanation of how you went about it. To confirm this analysis I tried out by changing TF_WHL_VERSION and other related symbols to 1.10.1 in settings.sh so that build-prereq.sh installs the matching tensorflow. Now, the build and test passes and I am able to run variant calling. I presume this is a good workaround to address this issue.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:40,deployability,build,build,40,"@ramcn I'm delighted you've gotten your build sorted out. @ramcn If you are building DeepVariant from scratch, and in particular TF's wheels directly, I'd recommend looking into the exact version of TF you want to use with DeepVariant. In particular, if you are intending to run on CPUs, we've found that the MKL extensions to TF make call_variants 3-4x faster. It may be worth building yourself an optimized TF wheel for DeepVariant to maximize performance. @pgrosu Thank you for all of your insights into these issues Paul. It is much appreciate by myself and the rest of the team here at Google",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:76,deployability,build,building,76,"@ramcn I'm delighted you've gotten your build sorted out. @ramcn If you are building DeepVariant from scratch, and in particular TF's wheels directly, I'd recommend looking into the exact version of TF you want to use with DeepVariant. In particular, if you are intending to run on CPUs, we've found that the MKL extensions to TF make call_variants 3-4x faster. It may be worth building yourself an optimized TF wheel for DeepVariant to maximize performance. @pgrosu Thank you for all of your insights into these issues Paul. It is much appreciate by myself and the rest of the team here at Google",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:188,deployability,version,version,188,"@ramcn I'm delighted you've gotten your build sorted out. @ramcn If you are building DeepVariant from scratch, and in particular TF's wheels directly, I'd recommend looking into the exact version of TF you want to use with DeepVariant. In particular, if you are intending to run on CPUs, we've found that the MKL extensions to TF make call_variants 3-4x faster. It may be worth building yourself an optimized TF wheel for DeepVariant to maximize performance. @pgrosu Thank you for all of your insights into these issues Paul. It is much appreciate by myself and the rest of the team here at Google",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:378,deployability,build,building,378,"@ramcn I'm delighted you've gotten your build sorted out. @ramcn If you are building DeepVariant from scratch, and in particular TF's wheels directly, I'd recommend looking into the exact version of TF you want to use with DeepVariant. In particular, if you are intending to run on CPUs, we've found that the MKL extensions to TF make call_variants 3-4x faster. It may be worth building yourself an optimized TF wheel for DeepVariant to maximize performance. @pgrosu Thank you for all of your insights into these issues Paul. It is much appreciate by myself and the rest of the team here at Google",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:282,energy efficiency,CPU,CPUs,282,"@ramcn I'm delighted you've gotten your build sorted out. @ramcn If you are building DeepVariant from scratch, and in particular TF's wheels directly, I'd recommend looking into the exact version of TF you want to use with DeepVariant. In particular, if you are intending to run on CPUs, we've found that the MKL extensions to TF make call_variants 3-4x faster. It may be worth building yourself an optimized TF wheel for DeepVariant to maximize performance. @pgrosu Thank you for all of your insights into these issues Paul. It is much appreciate by myself and the rest of the team here at Google",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:399,energy efficiency,optim,optimized,399,"@ramcn I'm delighted you've gotten your build sorted out. @ramcn If you are building DeepVariant from scratch, and in particular TF's wheels directly, I'd recommend looking into the exact version of TF you want to use with DeepVariant. In particular, if you are intending to run on CPUs, we've found that the MKL extensions to TF make call_variants 3-4x faster. It may be worth building yourself an optimized TF wheel for DeepVariant to maximize performance. @pgrosu Thank you for all of your insights into these issues Paul. It is much appreciate by myself and the rest of the team here at Google",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:188,integrability,version,version,188,"@ramcn I'm delighted you've gotten your build sorted out. @ramcn If you are building DeepVariant from scratch, and in particular TF's wheels directly, I'd recommend looking into the exact version of TF you want to use with DeepVariant. In particular, if you are intending to run on CPUs, we've found that the MKL extensions to TF make call_variants 3-4x faster. It may be worth building yourself an optimized TF wheel for DeepVariant to maximize performance. @pgrosu Thank you for all of your insights into these issues Paul. It is much appreciate by myself and the rest of the team here at Google",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:188,modifiability,version,version,188,"@ramcn I'm delighted you've gotten your build sorted out. @ramcn If you are building DeepVariant from scratch, and in particular TF's wheels directly, I'd recommend looking into the exact version of TF you want to use with DeepVariant. In particular, if you are intending to run on CPUs, we've found that the MKL extensions to TF make call_variants 3-4x faster. It may be worth building yourself an optimized TF wheel for DeepVariant to maximize performance. @pgrosu Thank you for all of your insights into these issues Paul. It is much appreciate by myself and the rest of the team here at Google",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:313,modifiability,extens,extensions,313,"@ramcn I'm delighted you've gotten your build sorted out. @ramcn If you are building DeepVariant from scratch, and in particular TF's wheels directly, I'd recommend looking into the exact version of TF you want to use with DeepVariant. In particular, if you are intending to run on CPUs, we've found that the MKL extensions to TF make call_variants 3-4x faster. It may be worth building yourself an optimized TF wheel for DeepVariant to maximize performance. @pgrosu Thank you for all of your insights into these issues Paul. It is much appreciate by myself and the rest of the team here at Google",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:282,performance,CPU,CPUs,282,"@ramcn I'm delighted you've gotten your build sorted out. @ramcn If you are building DeepVariant from scratch, and in particular TF's wheels directly, I'd recommend looking into the exact version of TF you want to use with DeepVariant. In particular, if you are intending to run on CPUs, we've found that the MKL extensions to TF make call_variants 3-4x faster. It may be worth building yourself an optimized TF wheel for DeepVariant to maximize performance. @pgrosu Thank you for all of your insights into these issues Paul. It is much appreciate by myself and the rest of the team here at Google",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:399,performance,optimiz,optimized,399,"@ramcn I'm delighted you've gotten your build sorted out. @ramcn If you are building DeepVariant from scratch, and in particular TF's wheels directly, I'd recommend looking into the exact version of TF you want to use with DeepVariant. In particular, if you are intending to run on CPUs, we've found that the MKL extensions to TF make call_variants 3-4x faster. It may be worth building yourself an optimized TF wheel for DeepVariant to maximize performance. @pgrosu Thank you for all of your insights into these issues Paul. It is much appreciate by myself and the rest of the team here at Google",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:446,performance,perform,performance,446,"@ramcn I'm delighted you've gotten your build sorted out. @ramcn If you are building DeepVariant from scratch, and in particular TF's wheels directly, I'd recommend looking into the exact version of TF you want to use with DeepVariant. In particular, if you are intending to run on CPUs, we've found that the MKL extensions to TF make call_variants 3-4x faster. It may be worth building yourself an optimized TF wheel for DeepVariant to maximize performance. @pgrosu Thank you for all of your insights into these issues Paul. It is much appreciate by myself and the rest of the team here at Google",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:578,security,team,team,578,"@ramcn I'm delighted you've gotten your build sorted out. @ramcn If you are building DeepVariant from scratch, and in particular TF's wheels directly, I'd recommend looking into the exact version of TF you want to use with DeepVariant. In particular, if you are intending to run on CPUs, we've found that the MKL extensions to TF make call_variants 3-4x faster. It may be worth building yourself an optimized TF wheel for DeepVariant to maximize performance. @pgrosu Thank you for all of your insights into these issues Paul. It is much appreciate by myself and the rest of the team here at Google",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:446,usability,perform,performance,446,"@ramcn I'm delighted you've gotten your build sorted out. @ramcn If you are building DeepVariant from scratch, and in particular TF's wheels directly, I'd recommend looking into the exact version of TF you want to use with DeepVariant. In particular, if you are intending to run on CPUs, we've found that the MKL extensions to TF make call_variants 3-4x faster. It may be worth building yourself an optimized TF wheel for DeepVariant to maximize performance. @pgrosu Thank you for all of your insights into these issues Paul. It is much appreciate by myself and the rest of the team here at Google",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:63,deployability,log,logs,63,"That's great news Ram, and glad to hear it all worked out. The logs were basically guiding me through rules of implication, and it looked like we were getting close. Let us know if you run into any other issues, as we would be happy to help you out. @depristo Thank you Mark for the nice compliments, that means quite a lot. I always enjoy helping out folks and the team. I find exploring complex and challenging problems interesting and fun.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:63,safety,log,logs,63,"That's great news Ram, and glad to hear it all worked out. The logs were basically guiding me through rules of implication, and it looked like we were getting close. Let us know if you run into any other issues, as we would be happy to help you out. @depristo Thank you Mark for the nice compliments, that means quite a lot. I always enjoy helping out folks and the team. I find exploring complex and challenging problems interesting and fun.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:288,safety,compl,compliments,288,"That's great news Ram, and glad to hear it all worked out. The logs were basically guiding me through rules of implication, and it looked like we were getting close. Let us know if you run into any other issues, as we would be happy to help you out. @depristo Thank you Mark for the nice compliments, that means quite a lot. I always enjoy helping out folks and the team. I find exploring complex and challenging problems interesting and fun.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:389,safety,compl,complex,389,"That's great news Ram, and glad to hear it all worked out. The logs were basically guiding me through rules of implication, and it looked like we were getting close. Let us know if you run into any other issues, as we would be happy to help you out. @depristo Thank you Mark for the nice compliments, that means quite a lot. I always enjoy helping out folks and the team. I find exploring complex and challenging problems interesting and fun.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:63,security,log,logs,63,"That's great news Ram, and glad to hear it all worked out. The logs were basically guiding me through rules of implication, and it looked like we were getting close. Let us know if you run into any other issues, as we would be happy to help you out. @depristo Thank you Mark for the nice compliments, that means quite a lot. I always enjoy helping out folks and the team. I find exploring complex and challenging problems interesting and fun.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:288,security,compl,compliments,288,"That's great news Ram, and glad to hear it all worked out. The logs were basically guiding me through rules of implication, and it looked like we were getting close. Let us know if you run into any other issues, as we would be happy to help you out. @depristo Thank you Mark for the nice compliments, that means quite a lot. I always enjoy helping out folks and the team. I find exploring complex and challenging problems interesting and fun.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:366,security,team,team,366,"That's great news Ram, and glad to hear it all worked out. The logs were basically guiding me through rules of implication, and it looked like we were getting close. Let us know if you run into any other issues, as we would be happy to help you out. @depristo Thank you Mark for the nice compliments, that means quite a lot. I always enjoy helping out folks and the team. I find exploring complex and challenging problems interesting and fun.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:389,security,compl,complex,389,"That's great news Ram, and glad to hear it all worked out. The logs were basically guiding me through rules of implication, and it looked like we were getting close. Let us know if you run into any other issues, as we would be happy to help you out. @depristo Thank you Mark for the nice compliments, that means quite a lot. I always enjoy helping out folks and the team. I find exploring complex and challenging problems interesting and fun.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:63,testability,log,logs,63,"That's great news Ram, and glad to hear it all worked out. The logs were basically guiding me through rules of implication, and it looked like we were getting close. Let us know if you run into any other issues, as we would be happy to help you out. @depristo Thank you Mark for the nice compliments, that means quite a lot. I always enjoy helping out folks and the team. I find exploring complex and challenging problems interesting and fun.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:83,usability,guid,guiding,83,"That's great news Ram, and glad to hear it all worked out. The logs were basically guiding me through rules of implication, and it looked like we were getting close. Let us know if you run into any other issues, as we would be happy to help you out. @depristo Thank you Mark for the nice compliments, that means quite a lot. I always enjoy helping out folks and the team. I find exploring complex and challenging problems interesting and fun.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:159,usability,close,close,159,"That's great news Ram, and glad to hear it all worked out. The logs were basically guiding me through rules of implication, and it looked like we were getting close. Let us know if you run into any other issues, as we would be happy to help you out. @depristo Thank you Mark for the nice compliments, that means quite a lot. I always enjoy helping out folks and the team. I find exploring complex and challenging problems interesting and fun.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:236,usability,help,help,236,"That's great news Ram, and glad to hear it all worked out. The logs were basically guiding me through rules of implication, and it looked like we were getting close. Let us know if you run into any other issues, as we would be happy to help you out. @depristo Thank you Mark for the nice compliments, that means quite a lot. I always enjoy helping out folks and the team. I find exploring complex and challenging problems interesting and fun.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:340,usability,help,helping,340,"That's great news Ram, and glad to hear it all worked out. The logs were basically guiding me through rules of implication, and it looked like we were getting close. Let us know if you run into any other issues, as we would be happy to help you out. @depristo Thank you Mark for the nice compliments, that means quite a lot. I always enjoy helping out folks and the team. I find exploring complex and challenging problems interesting and fun.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/94:5,usability,close,close,5,I'll close this issue now. Thanks Paul!,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/94
https://github.com/google/deepvariant/issues/95:36,deployability,instal,installed,36,"Hi Simon,. You'll need the bz2 libs installed. Either yum bzip2-libs and/or libbz2, as they are required. @ramcn Which do you have installed on your system? ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/95
https://github.com/google/deepvariant/issues/95:131,deployability,instal,installed,131,"Hi Simon,. You'll need the bz2 libs installed. Either yum bzip2-libs and/or libbz2, as they are required. @ramcn Which do you have installed on your system? ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/95
https://github.com/google/deepvariant/issues/95:24,deployability,build,building,24,"@ssm0808 Hi, I've tried building on CentOS a while ago, but didn't succeed. At the time I was trying to build on CentOS 6 (in this issue: https://github.com/google/deepvariant/issues/29). If you made more progress, please let us know.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/95
https://github.com/google/deepvariant/issues/95:104,deployability,build,build,104,"@ssm0808 Hi, I've tried building on CentOS a while ago, but didn't succeed. At the time I was trying to build on CentOS 6 (in this issue: https://github.com/google/deepvariant/issues/29). If you made more progress, please let us know.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/95
https://github.com/google/deepvariant/issues/95:83,performance,time,time,83,"@ssm0808 Hi, I've tried building on CentOS a while ago, but didn't succeed. At the time I was trying to build on CentOS 6 (in this issue: https://github.com/google/deepvariant/issues/29). If you made more progress, please let us know.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/95
https://github.com/google/deepvariant/issues/95:205,usability,progress,progress,205,"@ssm0808 Hi, I've tried building on CentOS a while ago, but didn't succeed. At the time I was trying to build on CentOS 6 (in this issue: https://github.com/google/deepvariant/issues/29). If you made more progress, please let us know.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/95
https://github.com/google/deepvariant/issues/95:227,deployability,instal,install,227,"Closing this issue as there has been no activity for a while. For anyone referencing this discussion, [here is a link](https://github.com/google/deepvariant/issues/137#issuecomment-452921108) to detailed instructions on how to install DeepVariant for CentOS7.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/95
https://github.com/google/deepvariant/issues/96:162,deployability,pipelin,pipeline,162,"Hi Shruti,. The issue is that computations have locality, and would prefer to stay within the same data center. In your 0.6.1 scripts you specified zones for you pipeline runs (`--zones us-west1-b`) and for your gcp_deepvariant_runner (`--zones 'us-*'`), and not a region. In your 0.7.0 script you included both a zone `--zones us-west1-*` for your gcp_deepvariant_runner, and a region in your pipelines run `--regions us-west1`. Try to stick to one or the other, where a zone is more precise and a region contains a collection of zones. For more information here a couple of useful links:. https://cloud.google.com/compute/docs/regions-zones/. https://cloud.google.com/compute/docs/regions-zones/global-regional-zonal-resources. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/96
https://github.com/google/deepvariant/issues/96:394,deployability,pipelin,pipelines,394,"Hi Shruti,. The issue is that computations have locality, and would prefer to stay within the same data center. In your 0.6.1 scripts you specified zones for you pipeline runs (`--zones us-west1-b`) and for your gcp_deepvariant_runner (`--zones 'us-*'`), and not a region. In your 0.7.0 script you included both a zone `--zones us-west1-*` for your gcp_deepvariant_runner, and a region in your pipelines run `--regions us-west1`. Try to stick to one or the other, where a zone is more precise and a region contains a collection of zones. For more information here a couple of useful links:. https://cloud.google.com/compute/docs/regions-zones/. https://cloud.google.com/compute/docs/regions-zones/global-regional-zonal-resources. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/96
https://github.com/google/deepvariant/issues/96:506,deployability,contain,contains,506,"Hi Shruti,. The issue is that computations have locality, and would prefer to stay within the same data center. In your 0.6.1 scripts you specified zones for you pipeline runs (`--zones us-west1-b`) and for your gcp_deepvariant_runner (`--zones 'us-*'`), and not a region. In your 0.7.0 script you included both a zone `--zones us-west1-*` for your gcp_deepvariant_runner, and a region in your pipelines run `--regions us-west1`. Try to stick to one or the other, where a zone is more precise and a region contains a collection of zones. For more information here a couple of useful links:. https://cloud.google.com/compute/docs/regions-zones/. https://cloud.google.com/compute/docs/regions-zones/global-regional-zonal-resources. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/96
https://github.com/google/deepvariant/issues/96:719,deployability,resourc,resources,719,"Hi Shruti,. The issue is that computations have locality, and would prefer to stay within the same data center. In your 0.6.1 scripts you specified zones for you pipeline runs (`--zones us-west1-b`) and for your gcp_deepvariant_runner (`--zones 'us-*'`), and not a region. In your 0.7.0 script you included both a zone `--zones us-west1-*` for your gcp_deepvariant_runner, and a region in your pipelines run `--regions us-west1`. Try to stick to one or the other, where a zone is more precise and a region contains a collection of zones. For more information here a couple of useful links:. https://cloud.google.com/compute/docs/regions-zones/. https://cloud.google.com/compute/docs/regions-zones/global-regional-zonal-resources. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/96
https://github.com/google/deepvariant/issues/96:599,energy efficiency,cloud,cloud,599,"Hi Shruti,. The issue is that computations have locality, and would prefer to stay within the same data center. In your 0.6.1 scripts you specified zones for you pipeline runs (`--zones us-west1-b`) and for your gcp_deepvariant_runner (`--zones 'us-*'`), and not a region. In your 0.7.0 script you included both a zone `--zones us-west1-*` for your gcp_deepvariant_runner, and a region in your pipelines run `--regions us-west1`. Try to stick to one or the other, where a zone is more precise and a region contains a collection of zones. For more information here a couple of useful links:. https://cloud.google.com/compute/docs/regions-zones/. https://cloud.google.com/compute/docs/regions-zones/global-regional-zonal-resources. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/96
https://github.com/google/deepvariant/issues/96:653,energy efficiency,cloud,cloud,653,"Hi Shruti,. The issue is that computations have locality, and would prefer to stay within the same data center. In your 0.6.1 scripts you specified zones for you pipeline runs (`--zones us-west1-b`) and for your gcp_deepvariant_runner (`--zones 'us-*'`), and not a region. In your 0.7.0 script you included both a zone `--zones us-west1-*` for your gcp_deepvariant_runner, and a region in your pipelines run `--regions us-west1`. Try to stick to one or the other, where a zone is more precise and a region contains a collection of zones. For more information here a couple of useful links:. https://cloud.google.com/compute/docs/regions-zones/. https://cloud.google.com/compute/docs/regions-zones/global-regional-zonal-resources. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/96
https://github.com/google/deepvariant/issues/96:719,energy efficiency,resourc,resources,719,"Hi Shruti,. The issue is that computations have locality, and would prefer to stay within the same data center. In your 0.6.1 scripts you specified zones for you pipeline runs (`--zones us-west1-b`) and for your gcp_deepvariant_runner (`--zones 'us-*'`), and not a region. In your 0.7.0 script you included both a zone `--zones us-west1-*` for your gcp_deepvariant_runner, and a region in your pipelines run `--regions us-west1`. Try to stick to one or the other, where a zone is more precise and a region contains a collection of zones. For more information here a couple of useful links:. https://cloud.google.com/compute/docs/regions-zones/. https://cloud.google.com/compute/docs/regions-zones/global-regional-zonal-resources. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/96
https://github.com/google/deepvariant/issues/96:162,integrability,pipelin,pipeline,162,"Hi Shruti,. The issue is that computations have locality, and would prefer to stay within the same data center. In your 0.6.1 scripts you specified zones for you pipeline runs (`--zones us-west1-b`) and for your gcp_deepvariant_runner (`--zones 'us-*'`), and not a region. In your 0.7.0 script you included both a zone `--zones us-west1-*` for your gcp_deepvariant_runner, and a region in your pipelines run `--regions us-west1`. Try to stick to one or the other, where a zone is more precise and a region contains a collection of zones. For more information here a couple of useful links:. https://cloud.google.com/compute/docs/regions-zones/. https://cloud.google.com/compute/docs/regions-zones/global-regional-zonal-resources. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/96
https://github.com/google/deepvariant/issues/96:394,integrability,pipelin,pipelines,394,"Hi Shruti,. The issue is that computations have locality, and would prefer to stay within the same data center. In your 0.6.1 scripts you specified zones for you pipeline runs (`--zones us-west1-b`) and for your gcp_deepvariant_runner (`--zones 'us-*'`), and not a region. In your 0.7.0 script you included both a zone `--zones us-west1-*` for your gcp_deepvariant_runner, and a region in your pipelines run `--regions us-west1`. Try to stick to one or the other, where a zone is more precise and a region contains a collection of zones. For more information here a couple of useful links:. https://cloud.google.com/compute/docs/regions-zones/. https://cloud.google.com/compute/docs/regions-zones/global-regional-zonal-resources. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/96
https://github.com/google/deepvariant/issues/96:566,integrability,coupl,couple,566,"Hi Shruti,. The issue is that computations have locality, and would prefer to stay within the same data center. In your 0.6.1 scripts you specified zones for you pipeline runs (`--zones us-west1-b`) and for your gcp_deepvariant_runner (`--zones 'us-*'`), and not a region. In your 0.7.0 script you included both a zone `--zones us-west1-*` for your gcp_deepvariant_runner, and a region in your pipelines run `--regions us-west1`. Try to stick to one or the other, where a zone is more precise and a region contains a collection of zones. For more information here a couple of useful links:. https://cloud.google.com/compute/docs/regions-zones/. https://cloud.google.com/compute/docs/regions-zones/global-regional-zonal-resources. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/96
https://github.com/google/deepvariant/issues/96:138,interoperability,specif,specified,138,"Hi Shruti,. The issue is that computations have locality, and would prefer to stay within the same data center. In your 0.6.1 scripts you specified zones for you pipeline runs (`--zones us-west1-b`) and for your gcp_deepvariant_runner (`--zones 'us-*'`), and not a region. In your 0.7.0 script you included both a zone `--zones us-west1-*` for your gcp_deepvariant_runner, and a region in your pipelines run `--regions us-west1`. Try to stick to one or the other, where a zone is more precise and a region contains a collection of zones. For more information here a couple of useful links:. https://cloud.google.com/compute/docs/regions-zones/. https://cloud.google.com/compute/docs/regions-zones/global-regional-zonal-resources. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/96
https://github.com/google/deepvariant/issues/96:566,modifiability,coupl,couple,566,"Hi Shruti,. The issue is that computations have locality, and would prefer to stay within the same data center. In your 0.6.1 scripts you specified zones for you pipeline runs (`--zones us-west1-b`) and for your gcp_deepvariant_runner (`--zones 'us-*'`), and not a region. In your 0.7.0 script you included both a zone `--zones us-west1-*` for your gcp_deepvariant_runner, and a region in your pipelines run `--regions us-west1`. Try to stick to one or the other, where a zone is more precise and a region contains a collection of zones. For more information here a couple of useful links:. https://cloud.google.com/compute/docs/regions-zones/. https://cloud.google.com/compute/docs/regions-zones/global-regional-zonal-resources. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/96
https://github.com/google/deepvariant/issues/96:719,performance,resourc,resources,719,"Hi Shruti,. The issue is that computations have locality, and would prefer to stay within the same data center. In your 0.6.1 scripts you specified zones for you pipeline runs (`--zones us-west1-b`) and for your gcp_deepvariant_runner (`--zones 'us-*'`), and not a region. In your 0.7.0 script you included both a zone `--zones us-west1-*` for your gcp_deepvariant_runner, and a region in your pipelines run `--regions us-west1`. Try to stick to one or the other, where a zone is more precise and a region contains a collection of zones. For more information here a couple of useful links:. https://cloud.google.com/compute/docs/regions-zones/. https://cloud.google.com/compute/docs/regions-zones/global-regional-zonal-resources. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/96
https://github.com/google/deepvariant/issues/96:719,safety,resourc,resources,719,"Hi Shruti,. The issue is that computations have locality, and would prefer to stay within the same data center. In your 0.6.1 scripts you specified zones for you pipeline runs (`--zones us-west1-b`) and for your gcp_deepvariant_runner (`--zones 'us-*'`), and not a region. In your 0.7.0 script you included both a zone `--zones us-west1-*` for your gcp_deepvariant_runner, and a region in your pipelines run `--regions us-west1`. Try to stick to one or the other, where a zone is more precise and a region contains a collection of zones. For more information here a couple of useful links:. https://cloud.google.com/compute/docs/regions-zones/. https://cloud.google.com/compute/docs/regions-zones/global-regional-zonal-resources. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/96
https://github.com/google/deepvariant/issues/96:566,testability,coupl,couple,566,"Hi Shruti,. The issue is that computations have locality, and would prefer to stay within the same data center. In your 0.6.1 scripts you specified zones for you pipeline runs (`--zones us-west1-b`) and for your gcp_deepvariant_runner (`--zones 'us-*'`), and not a region. In your 0.7.0 script you included both a zone `--zones us-west1-*` for your gcp_deepvariant_runner, and a region in your pipelines run `--regions us-west1`. Try to stick to one or the other, where a zone is more precise and a region contains a collection of zones. For more information here a couple of useful links:. https://cloud.google.com/compute/docs/regions-zones/. https://cloud.google.com/compute/docs/regions-zones/global-regional-zonal-resources. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/96
https://github.com/google/deepvariant/issues/96:719,testability,resourc,resources,719,"Hi Shruti,. The issue is that computations have locality, and would prefer to stay within the same data center. In your 0.6.1 scripts you specified zones for you pipeline runs (`--zones us-west1-b`) and for your gcp_deepvariant_runner (`--zones 'us-*'`), and not a region. In your 0.7.0 script you included both a zone `--zones us-west1-*` for your gcp_deepvariant_runner, and a region in your pipelines run `--regions us-west1`. Try to stick to one or the other, where a zone is more precise and a region contains a collection of zones. For more information here a couple of useful links:. https://cloud.google.com/compute/docs/regions-zones/. https://cloud.google.com/compute/docs/regions-zones/global-regional-zonal-resources. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/96
https://github.com/google/deepvariant/issues/96:68,usability,prefer,prefer,68,"Hi Shruti,. The issue is that computations have locality, and would prefer to stay within the same data center. In your 0.6.1 scripts you specified zones for you pipeline runs (`--zones us-west1-b`) and for your gcp_deepvariant_runner (`--zones 'us-*'`), and not a region. In your 0.7.0 script you included both a zone `--zones us-west1-*` for your gcp_deepvariant_runner, and a region in your pipelines run `--regions us-west1`. Try to stick to one or the other, where a zone is more precise and a region contains a collection of zones. For more information here a couple of useful links:. https://cloud.google.com/compute/docs/regions-zones/. https://cloud.google.com/compute/docs/regions-zones/global-regional-zonal-resources. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/96
https://github.com/google/deepvariant/issues/96:78,usability,close,close,78,"Hi @ShrutiMarwaha , hopefully the answers above addressed your question. I'll close this issue, but feel free to re-open if you still have trouble running this.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/96
https://github.com/google/deepvariant/issues/96:108,usability,help,helped,108,"Sorry @pichuan, I forgot to follow up. @nmousavi 's suggestion to unset gcloud config set compute/region """" helped.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/96
https://github.com/google/deepvariant/pull/97:34,deployability,updat,updated,34,Thanks for the pull request. I've updated the code internally and it'll go out with the next release.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/97
https://github.com/google/deepvariant/pull/97:93,deployability,releas,release,93,Thanks for the pull request. I've updated the code internally and it'll go out with the next release.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/97
https://github.com/google/deepvariant/pull/97:34,safety,updat,updated,34,Thanks for the pull request. I've updated the code internally and it'll go out with the next release.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/97
https://github.com/google/deepvariant/pull/97:34,security,updat,updated,34,Thanks for the pull request. I've updated the code internally and it'll go out with the next release.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/97
https://github.com/google/deepvariant/issues/98:16,deployability,instal,installation,16,"I wonder if the installation for bazel is different on Ubuntu 18.04. Can you try installing bazel separately, see https://docs.bazel.build/versions/master/install-ubuntu.html and see if you can install bazel?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/98
https://github.com/google/deepvariant/issues/98:81,deployability,instal,installing,81,"I wonder if the installation for bazel is different on Ubuntu 18.04. Can you try installing bazel separately, see https://docs.bazel.build/versions/master/install-ubuntu.html and see if you can install bazel?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/98
https://github.com/google/deepvariant/issues/98:133,deployability,build,build,133,"I wonder if the installation for bazel is different on Ubuntu 18.04. Can you try installing bazel separately, see https://docs.bazel.build/versions/master/install-ubuntu.html and see if you can install bazel?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/98
https://github.com/google/deepvariant/issues/98:139,deployability,version,versions,139,"I wonder if the installation for bazel is different on Ubuntu 18.04. Can you try installing bazel separately, see https://docs.bazel.build/versions/master/install-ubuntu.html and see if you can install bazel?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/98
https://github.com/google/deepvariant/issues/98:155,deployability,instal,install-ubuntu,155,"I wonder if the installation for bazel is different on Ubuntu 18.04. Can you try installing bazel separately, see https://docs.bazel.build/versions/master/install-ubuntu.html and see if you can install bazel?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/98
https://github.com/google/deepvariant/issues/98:194,deployability,instal,install,194,"I wonder if the installation for bazel is different on Ubuntu 18.04. Can you try installing bazel separately, see https://docs.bazel.build/versions/master/install-ubuntu.html and see if you can install bazel?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/98
https://github.com/google/deepvariant/issues/98:139,integrability,version,versions,139,"I wonder if the installation for bazel is different on Ubuntu 18.04. Can you try installing bazel separately, see https://docs.bazel.build/versions/master/install-ubuntu.html and see if you can install bazel?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/98
https://github.com/google/deepvariant/issues/98:139,modifiability,version,versions,139,"I wonder if the installation for bazel is different on Ubuntu 18.04. Can you try installing bazel separately, see https://docs.bazel.build/versions/master/install-ubuntu.html and see if you can install bazel?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/98
https://github.com/google/deepvariant/issues/98:126,availability,error,error,126,"Hello @pichuan , thanks for the swift reply. I installed bazel manually, the installations is working, however I get the same error from ./build-prereq.sh",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/98
https://github.com/google/deepvariant/issues/98:47,deployability,instal,installed,47,"Hello @pichuan , thanks for the swift reply. I installed bazel manually, the installations is working, however I get the same error from ./build-prereq.sh",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/98
https://github.com/google/deepvariant/issues/98:77,deployability,instal,installations,77,"Hello @pichuan , thanks for the swift reply. I installed bazel manually, the installations is working, however I get the same error from ./build-prereq.sh",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/98
https://github.com/google/deepvariant/issues/98:139,deployability,build,build-prereq,139,"Hello @pichuan , thanks for the swift reply. I installed bazel manually, the installations is working, however I get the same error from ./build-prereq.sh",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/98
https://github.com/google/deepvariant/issues/98:126,performance,error,error,126,"Hello @pichuan , thanks for the swift reply. I installed bazel manually, the installations is working, however I get the same error from ./build-prereq.sh",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/98
https://github.com/google/deepvariant/issues/98:126,safety,error,error,126,"Hello @pichuan , thanks for the swift reply. I installed bazel manually, the installations is working, however I get the same error from ./build-prereq.sh",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/98
https://github.com/google/deepvariant/issues/98:126,usability,error,error,126,"Hello @pichuan , thanks for the swift reply. I installed bazel manually, the installations is working, however I get the same error from ./build-prereq.sh",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/98
https://github.com/google/deepvariant/issues/98:56,deployability,log,log,56,"@vinisalazar Can you create a gist or attach a complete log of what you see when you run `./build-prereq.sh`? Also if you type `which bazel` what does show up? It might not be in your path. Thanks,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/98
https://github.com/google/deepvariant/issues/98:92,deployability,build,build-prereq,92,"@vinisalazar Can you create a gist or attach a complete log of what you see when you run `./build-prereq.sh`? Also if you type `which bazel` what does show up? It might not be in your path. Thanks,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/98
https://github.com/google/deepvariant/issues/98:146,reliability,doe,does,146,"@vinisalazar Can you create a gist or attach a complete log of what you see when you run `./build-prereq.sh`? Also if you type `which bazel` what does show up? It might not be in your path. Thanks,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/98
https://github.com/google/deepvariant/issues/98:47,safety,compl,complete,47,"@vinisalazar Can you create a gist or attach a complete log of what you see when you run `./build-prereq.sh`? Also if you type `which bazel` what does show up? It might not be in your path. Thanks,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/98
https://github.com/google/deepvariant/issues/98:56,safety,log,log,56,"@vinisalazar Can you create a gist or attach a complete log of what you see when you run `./build-prereq.sh`? Also if you type `which bazel` what does show up? It might not be in your path. Thanks,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/98
https://github.com/google/deepvariant/issues/98:47,security,compl,complete,47,"@vinisalazar Can you create a gist or attach a complete log of what you see when you run `./build-prereq.sh`? Also if you type `which bazel` what does show up? It might not be in your path. Thanks,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/98
https://github.com/google/deepvariant/issues/98:56,security,log,log,56,"@vinisalazar Can you create a gist or attach a complete log of what you see when you run `./build-prereq.sh`? Also if you type `which bazel` what does show up? It might not be in your path. Thanks,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/98
https://github.com/google/deepvariant/issues/98:56,testability,log,log,56,"@vinisalazar Can you create a gist or attach a complete log of what you see when you run `./build-prereq.sh`? Also if you type `which bazel` what does show up? It might not be in your path. Thanks,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/98
https://github.com/google/deepvariant/issues/98:89,deployability,instal,installed,89,"Hello, @pgrosu , thanks for the support. `which bazel` returns `/usr/local/bin/bazel` (I installed with sudo). As for the gist, [here it is.](https://gist.github.com/vinisalazar/c68d290a68f12677211c1398ba3c6dcc).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/98
https://github.com/google/deepvariant/issues/98:32,usability,support,support,32,"Hello, @pgrosu , thanks for the support. `which bazel` returns `/usr/local/bin/bazel` (I installed with sudo). As for the gist, [here it is.](https://gist.github.com/vinisalazar/c68d290a68f12677211c1398ba3c6dcc).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/98
https://github.com/google/deepvariant/issues/98:84,deployability,instal,install,84,"Hi @vinisalazar,. Out of curiosity, what happens if you type the following:. `conda install -c bioconda deepvariant`. Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/98
https://github.com/google/deepvariant/issues/98:70,deployability,build,build,70,"Hi @pgrosu ,. Thanks, that solved it. I had no idea there was a conda build for this package, otherwise it'd be the first way I'd try to install it. However, I'd recommend looking into these building problems. Thank you very much, . V",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/98
https://github.com/google/deepvariant/issues/98:137,deployability,instal,install,137,"Hi @pgrosu ,. Thanks, that solved it. I had no idea there was a conda build for this package, otherwise it'd be the first way I'd try to install it. However, I'd recommend looking into these building problems. Thank you very much, . V",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/98
https://github.com/google/deepvariant/issues/98:191,deployability,build,building,191,"Hi @pgrosu ,. Thanks, that solved it. I had no idea there was a conda build for this package, otherwise it'd be the first way I'd try to install it. However, I'd recommend looking into these building problems. Thank you very much, . V",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/98
https://github.com/google/deepvariant/issues/98:85,modifiability,pac,package,85,"Hi @pgrosu ,. Thanks, that solved it. I had no idea there was a conda build for this package, otherwise it'd be the first way I'd try to install it. However, I'd recommend looking into these building problems. Thank you very much, . V",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/98
https://github.com/google/deepvariant/issues/98:49,deployability,version,version,49,"Hi @vinisalazar , note that the current bioconda version seems to be 0.6.1. It's also not directly maintained by our team, but it's contribution from @chapmanb. I'll check with him to see if we can update it. And yes, we'll look into the building issues. Thank you for reporting the issue!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/98
https://github.com/google/deepvariant/issues/98:198,deployability,updat,update,198,"Hi @vinisalazar , note that the current bioconda version seems to be 0.6.1. It's also not directly maintained by our team, but it's contribution from @chapmanb. I'll check with him to see if we can update it. And yes, we'll look into the building issues. Thank you for reporting the issue!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/98
https://github.com/google/deepvariant/issues/98:238,deployability,build,building,238,"Hi @vinisalazar , note that the current bioconda version seems to be 0.6.1. It's also not directly maintained by our team, but it's contribution from @chapmanb. I'll check with him to see if we can update it. And yes, we'll look into the building issues. Thank you for reporting the issue!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/98
https://github.com/google/deepvariant/issues/98:32,energy efficiency,current,current,32,"Hi @vinisalazar , note that the current bioconda version seems to be 0.6.1. It's also not directly maintained by our team, but it's contribution from @chapmanb. I'll check with him to see if we can update it. And yes, we'll look into the building issues. Thank you for reporting the issue!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/98
https://github.com/google/deepvariant/issues/98:49,integrability,version,version,49,"Hi @vinisalazar , note that the current bioconda version seems to be 0.6.1. It's also not directly maintained by our team, but it's contribution from @chapmanb. I'll check with him to see if we can update it. And yes, we'll look into the building issues. Thank you for reporting the issue!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/98
https://github.com/google/deepvariant/issues/98:49,modifiability,version,version,49,"Hi @vinisalazar , note that the current bioconda version seems to be 0.6.1. It's also not directly maintained by our team, but it's contribution from @chapmanb. I'll check with him to see if we can update it. And yes, we'll look into the building issues. Thank you for reporting the issue!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/98
https://github.com/google/deepvariant/issues/98:99,modifiability,maintain,maintained,99,"Hi @vinisalazar , note that the current bioconda version seems to be 0.6.1. It's also not directly maintained by our team, but it's contribution from @chapmanb. I'll check with him to see if we can update it. And yes, we'll look into the building issues. Thank you for reporting the issue!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/98
https://github.com/google/deepvariant/issues/98:99,safety,maintain,maintained,99,"Hi @vinisalazar , note that the current bioconda version seems to be 0.6.1. It's also not directly maintained by our team, but it's contribution from @chapmanb. I'll check with him to see if we can update it. And yes, we'll look into the building issues. Thank you for reporting the issue!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/98
https://github.com/google/deepvariant/issues/98:198,safety,updat,update,198,"Hi @vinisalazar , note that the current bioconda version seems to be 0.6.1. It's also not directly maintained by our team, but it's contribution from @chapmanb. I'll check with him to see if we can update it. And yes, we'll look into the building issues. Thank you for reporting the issue!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/98
https://github.com/google/deepvariant/issues/98:117,security,team,team,117,"Hi @vinisalazar , note that the current bioconda version seems to be 0.6.1. It's also not directly maintained by our team, but it's contribution from @chapmanb. I'll check with him to see if we can update it. And yes, we'll look into the building issues. Thank you for reporting the issue!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/98
https://github.com/google/deepvariant/issues/98:198,security,updat,update,198,"Hi @vinisalazar , note that the current bioconda version seems to be 0.6.1. It's also not directly maintained by our team, but it's contribution from @chapmanb. I'll check with him to see if we can update it. And yes, we'll look into the building issues. Thank you for reporting the issue!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/98
https://github.com/google/deepvariant/issues/98:34,deployability,build,build,34,"Hi @vinisalazar , I just tried to build DeepVariant on a Ubuntu 18.04 machine. I did encounter some issue, but it didn't seem to be the same as the one you have. I suspect when you run `build-prereq.sh`, it actually failed already at this line:. ```. sudo -H apt-get -qq -y update. ```. Can you let me know if that works for you? Maybe you can run it with out the `-qq` so it will actually report why it fails. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/98
https://github.com/google/deepvariant/issues/98:186,deployability,build,build-prereq,186,"Hi @vinisalazar , I just tried to build DeepVariant on a Ubuntu 18.04 machine. I did encounter some issue, but it didn't seem to be the same as the one you have. I suspect when you run `build-prereq.sh`, it actually failed already at this line:. ```. sudo -H apt-get -qq -y update. ```. Can you let me know if that works for you? Maybe you can run it with out the `-qq` so it will actually report why it fails. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/98
https://github.com/google/deepvariant/issues/98:216,deployability,fail,failed,216,"Hi @vinisalazar , I just tried to build DeepVariant on a Ubuntu 18.04 machine. I did encounter some issue, but it didn't seem to be the same as the one you have. I suspect when you run `build-prereq.sh`, it actually failed already at this line:. ```. sudo -H apt-get -qq -y update. ```. Can you let me know if that works for you? Maybe you can run it with out the `-qq` so it will actually report why it fails. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/98
https://github.com/google/deepvariant/issues/98:274,deployability,updat,update,274,"Hi @vinisalazar , I just tried to build DeepVariant on a Ubuntu 18.04 machine. I did encounter some issue, but it didn't seem to be the same as the one you have. I suspect when you run `build-prereq.sh`, it actually failed already at this line:. ```. sudo -H apt-get -qq -y update. ```. Can you let me know if that works for you? Maybe you can run it with out the `-qq` so it will actually report why it fails. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/98
https://github.com/google/deepvariant/issues/98:404,deployability,fail,fails,404,"Hi @vinisalazar , I just tried to build DeepVariant on a Ubuntu 18.04 machine. I did encounter some issue, but it didn't seem to be the same as the one you have. I suspect when you run `build-prereq.sh`, it actually failed already at this line:. ```. sudo -H apt-get -qq -y update. ```. Can you let me know if that works for you? Maybe you can run it with out the `-qq` so it will actually report why it fails. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/98
https://github.com/google/deepvariant/issues/98:216,reliability,fail,failed,216,"Hi @vinisalazar , I just tried to build DeepVariant on a Ubuntu 18.04 machine. I did encounter some issue, but it didn't seem to be the same as the one you have. I suspect when you run `build-prereq.sh`, it actually failed already at this line:. ```. sudo -H apt-get -qq -y update. ```. Can you let me know if that works for you? Maybe you can run it with out the `-qq` so it will actually report why it fails. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/98
https://github.com/google/deepvariant/issues/98:404,reliability,fail,fails,404,"Hi @vinisalazar , I just tried to build DeepVariant on a Ubuntu 18.04 machine. I did encounter some issue, but it didn't seem to be the same as the one you have. I suspect when you run `build-prereq.sh`, it actually failed already at this line:. ```. sudo -H apt-get -qq -y update. ```. Can you let me know if that works for you? Maybe you can run it with out the `-qq` so it will actually report why it fails. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/98
https://github.com/google/deepvariant/issues/98:274,safety,updat,update,274,"Hi @vinisalazar , I just tried to build DeepVariant on a Ubuntu 18.04 machine. I did encounter some issue, but it didn't seem to be the same as the one you have. I suspect when you run `build-prereq.sh`, it actually failed already at this line:. ```. sudo -H apt-get -qq -y update. ```. Can you let me know if that works for you? Maybe you can run it with out the `-qq` so it will actually report why it fails. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/98
https://github.com/google/deepvariant/issues/98:259,security,apt,apt-get,259,"Hi @vinisalazar , I just tried to build DeepVariant on a Ubuntu 18.04 machine. I did encounter some issue, but it didn't seem to be the same as the one you have. I suspect when you run `build-prereq.sh`, it actually failed already at this line:. ```. sudo -H apt-get -qq -y update. ```. Can you let me know if that works for you? Maybe you can run it with out the `-qq` so it will actually report why it fails. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/98
https://github.com/google/deepvariant/issues/98:274,security,updat,update,274,"Hi @vinisalazar , I just tried to build DeepVariant on a Ubuntu 18.04 machine. I did encounter some issue, but it didn't seem to be the same as the one you have. I suspect when you run `build-prereq.sh`, it actually failed already at this line:. ```. sudo -H apt-get -qq -y update. ```. Can you let me know if that works for you? Maybe you can run it with out the `-qq` so it will actually report why it fails. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/98
https://github.com/google/deepvariant/issues/98:110,deployability,updat,update,110,"Hello @pichuan, thank you, I will try this on Monday when I get back to my work machine and come back with an update.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/98
https://github.com/google/deepvariant/issues/98:110,safety,updat,update,110,"Hello @pichuan, thank you, I will try this on Monday when I get back to my work machine and come back with an update.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/98
https://github.com/google/deepvariant/issues/98:110,security,updat,update,110,"Hello @pichuan, thank you, I will try this on Monday when I get back to my work machine and come back with an update.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/98
https://github.com/google/deepvariant/issues/98:46,availability,ping,ping,46,"Vini, Paul and Pi-Chuan;. Thanks much for the ping about updating the conda recipe. This is now synced to the latest release (0.7.0) so you can use that as a backup option in addition to your work on getting it built on 18.04. Please let me know if you run into any issues.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/98
https://github.com/google/deepvariant/issues/98:158,availability,backup,backup,158,"Vini, Paul and Pi-Chuan;. Thanks much for the ping about updating the conda recipe. This is now synced to the latest release (0.7.0) so you can use that as a backup option in addition to your work on getting it built on 18.04. Please let me know if you run into any issues.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/98
https://github.com/google/deepvariant/issues/98:57,deployability,updat,updating,57,"Vini, Paul and Pi-Chuan;. Thanks much for the ping about updating the conda recipe. This is now synced to the latest release (0.7.0) so you can use that as a backup option in addition to your work on getting it built on 18.04. Please let me know if you run into any issues.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/98
https://github.com/google/deepvariant/issues/98:117,deployability,releas,release,117,"Vini, Paul and Pi-Chuan;. Thanks much for the ping about updating the conda recipe. This is now synced to the latest release (0.7.0) so you can use that as a backup option in addition to your work on getting it built on 18.04. Please let me know if you run into any issues.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/98
https://github.com/google/deepvariant/issues/98:158,reliability,backup,backup,158,"Vini, Paul and Pi-Chuan;. Thanks much for the ping about updating the conda recipe. This is now synced to the latest release (0.7.0) so you can use that as a backup option in addition to your work on getting it built on 18.04. Please let me know if you run into any issues.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/98
https://github.com/google/deepvariant/issues/98:57,safety,updat,updating,57,"Vini, Paul and Pi-Chuan;. Thanks much for the ping about updating the conda recipe. This is now synced to the latest release (0.7.0) so you can use that as a backup option in addition to your work on getting it built on 18.04. Please let me know if you run into any issues.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/98
https://github.com/google/deepvariant/issues/98:158,safety,backup,backup,158,"Vini, Paul and Pi-Chuan;. Thanks much for the ping about updating the conda recipe. This is now synced to the latest release (0.7.0) so you can use that as a backup option in addition to your work on getting it built on 18.04. Please let me know if you run into any issues.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/98
https://github.com/google/deepvariant/issues/98:57,security,updat,updating,57,"Vini, Paul and Pi-Chuan;. Thanks much for the ping about updating the conda recipe. This is now synced to the latest release (0.7.0) so you can use that as a backup option in addition to your work on getting it built on 18.04. Please let me know if you run into any issues.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/98
https://github.com/google/deepvariant/issues/98:0,energy efficiency,Cool,Cool,0,Cool beans! Thanks Brad for the quick turnaround.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/98
https://github.com/google/deepvariant/issues/98:23,deployability,updat,update,23,"Hi,. I want to give an update on this - . in the next minor release of DeepVariant, we'll plan to update the building script to allow you build on Ubuntu 18.04.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/98
https://github.com/google/deepvariant/issues/98:60,deployability,releas,release,60,"Hi,. I want to give an update on this - . in the next minor release of DeepVariant, we'll plan to update the building script to allow you build on Ubuntu 18.04.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/98
https://github.com/google/deepvariant/issues/98:98,deployability,updat,update,98,"Hi,. I want to give an update on this - . in the next minor release of DeepVariant, we'll plan to update the building script to allow you build on Ubuntu 18.04.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/98
https://github.com/google/deepvariant/issues/98:109,deployability,build,building,109,"Hi,. I want to give an update on this - . in the next minor release of DeepVariant, we'll plan to update the building script to allow you build on Ubuntu 18.04.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/98
https://github.com/google/deepvariant/issues/98:138,deployability,build,build,138,"Hi,. I want to give an update on this - . in the next minor release of DeepVariant, we'll plan to update the building script to allow you build on Ubuntu 18.04.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/98
https://github.com/google/deepvariant/issues/98:23,safety,updat,update,23,"Hi,. I want to give an update on this - . in the next minor release of DeepVariant, we'll plan to update the building script to allow you build on Ubuntu 18.04.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/98
https://github.com/google/deepvariant/issues/98:98,safety,updat,update,98,"Hi,. I want to give an update on this - . in the next minor release of DeepVariant, we'll plan to update the building script to allow you build on Ubuntu 18.04.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/98
https://github.com/google/deepvariant/issues/98:23,security,updat,update,23,"Hi,. I want to give an update on this - . in the next minor release of DeepVariant, we'll plan to update the building script to allow you build on Ubuntu 18.04.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/98
https://github.com/google/deepvariant/issues/98:98,security,updat,update,98,"Hi,. I want to give an update on this - . in the next minor release of DeepVariant, we'll plan to update the building script to allow you build on Ubuntu 18.04.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/98
https://github.com/google/deepvariant/issues/98:90,testability,plan,plan,90,"Hi,. I want to give an update on this - . in the next minor release of DeepVariant, we'll plan to update the building script to allow you build on Ubuntu 18.04.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/98
https://github.com/google/deepvariant/issues/99:10,availability,error,error,10,"Hi,. this error corresponding to this line in the Nucleus codebase:. https://github.com/google/nucleus/blob/master/nucleus/io/sam_reader.cc#L409. which I think is indicating your BAM file actually isn't quite we're expecting. One qustion for you:. Is there anything after `fragment_name`? If so, it's useful to find out the read in your BAM file so we can understand it better. . samtools view YOUR_BAM | grep FRAGMENT_NAME. might give you more information about the read that our SamReader is complaining. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:10,performance,error,error,10,"Hi,. this error corresponding to this line in the Nucleus codebase:. https://github.com/google/nucleus/blob/master/nucleus/io/sam_reader.cc#L409. which I think is indicating your BAM file actually isn't quite we're expecting. One qustion for you:. Is there anything after `fragment_name`? If so, it's useful to find out the read in your BAM file so we can understand it better. . samtools view YOUR_BAM | grep FRAGMENT_NAME. might give you more information about the read that our SamReader is complaining. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:10,safety,error,error,10,"Hi,. this error corresponding to this line in the Nucleus codebase:. https://github.com/google/nucleus/blob/master/nucleus/io/sam_reader.cc#L409. which I think is indicating your BAM file actually isn't quite we're expecting. One qustion for you:. Is there anything after `fragment_name`? If so, it's useful to find out the read in your BAM file so we can understand it better. . samtools view YOUR_BAM | grep FRAGMENT_NAME. might give you more information about the read that our SamReader is complaining. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:494,safety,compl,complaining,494,"Hi,. this error corresponding to this line in the Nucleus codebase:. https://github.com/google/nucleus/blob/master/nucleus/io/sam_reader.cc#L409. which I think is indicating your BAM file actually isn't quite we're expecting. One qustion for you:. Is there anything after `fragment_name`? If so, it's useful to find out the read in your BAM file so we can understand it better. . samtools view YOUR_BAM | grep FRAGMENT_NAME. might give you more information about the read that our SamReader is complaining. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:494,security,compl,complaining,494,"Hi,. this error corresponding to this line in the Nucleus codebase:. https://github.com/google/nucleus/blob/master/nucleus/io/sam_reader.cc#L409. which I think is indicating your BAM file actually isn't quite we're expecting. One qustion for you:. Is there anything after `fragment_name`? If so, it's useful to find out the read in your BAM file so we can understand it better. . samtools view YOUR_BAM | grep FRAGMENT_NAME. might give you more information about the read that our SamReader is complaining. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:356,testability,understand,understand,356,"Hi,. this error corresponding to this line in the Nucleus codebase:. https://github.com/google/nucleus/blob/master/nucleus/io/sam_reader.cc#L409. which I think is indicating your BAM file actually isn't quite we're expecting. One qustion for you:. Is there anything after `fragment_name`? If so, it's useful to find out the read in your BAM file so we can understand it better. . samtools view YOUR_BAM | grep FRAGMENT_NAME. might give you more information about the read that our SamReader is complaining. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:10,usability,error,error,10,"Hi,. this error corresponding to this line in the Nucleus codebase:. https://github.com/google/nucleus/blob/master/nucleus/io/sam_reader.cc#L409. which I think is indicating your BAM file actually isn't quite we're expecting. One qustion for you:. Is there anything after `fragment_name`? If so, it's useful to find out the read in your BAM file so we can understand it better. . samtools view YOUR_BAM | grep FRAGMENT_NAME. might give you more information about the read that our SamReader is complaining. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:163,usability,indicat,indicating,163,"Hi,. this error corresponding to this line in the Nucleus codebase:. https://github.com/google/nucleus/blob/master/nucleus/io/sam_reader.cc#L409. which I think is indicating your BAM file actually isn't quite we're expecting. One qustion for you:. Is there anything after `fragment_name`? If so, it's useful to find out the read in your BAM file so we can understand it better. . samtools view YOUR_BAM | grep FRAGMENT_NAME. might give you more information about the read that our SamReader is complaining. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:134,modifiability,variab,variable,134,"Hi Zhuyi,. DeepVariant is complaining here because your BAM has a record that says it has a mapped mate but mtid, which is the htslib variable holding the offset into the chromosome array, isn't set so its actual mapped location isn't present. This would normally indicate that's something corrupted with your BAM. Where did you get? How was it aligned? I'd recommend running ValidateSamFile to see if it complains. It could be we've being overly strict in Nucleus for parsing our BAMs. It'd be great if you can determine if your BAM is considered valid or not, and let us know if we need to be more permissive in our parsing or if the BAM needs to be fixed up. All the best,. Mark",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:26,safety,compl,complaining,26,"Hi Zhuyi,. DeepVariant is complaining here because your BAM has a record that says it has a mapped mate but mtid, which is the htslib variable holding the offset into the chromosome array, isn't set so its actual mapped location isn't present. This would normally indicate that's something corrupted with your BAM. Where did you get? How was it aligned? I'd recommend running ValidateSamFile to see if it complains. It could be we've being overly strict in Nucleus for parsing our BAMs. It'd be great if you can determine if your BAM is considered valid or not, and let us know if we need to be more permissive in our parsing or if the BAM needs to be fixed up. All the best,. Mark",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:376,safety,Valid,ValidateSamFile,376,"Hi Zhuyi,. DeepVariant is complaining here because your BAM has a record that says it has a mapped mate but mtid, which is the htslib variable holding the offset into the chromosome array, isn't set so its actual mapped location isn't present. This would normally indicate that's something corrupted with your BAM. Where did you get? How was it aligned? I'd recommend running ValidateSamFile to see if it complains. It could be we've being overly strict in Nucleus for parsing our BAMs. It'd be great if you can determine if your BAM is considered valid or not, and let us know if we need to be more permissive in our parsing or if the BAM needs to be fixed up. All the best,. Mark",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:405,safety,compl,complains,405,"Hi Zhuyi,. DeepVariant is complaining here because your BAM has a record that says it has a mapped mate but mtid, which is the htslib variable holding the offset into the chromosome array, isn't set so its actual mapped location isn't present. This would normally indicate that's something corrupted with your BAM. Where did you get? How was it aligned? I'd recommend running ValidateSamFile to see if it complains. It could be we've being overly strict in Nucleus for parsing our BAMs. It'd be great if you can determine if your BAM is considered valid or not, and let us know if we need to be more permissive in our parsing or if the BAM needs to be fixed up. All the best,. Mark",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:548,safety,valid,valid,548,"Hi Zhuyi,. DeepVariant is complaining here because your BAM has a record that says it has a mapped mate but mtid, which is the htslib variable holding the offset into the chromosome array, isn't set so its actual mapped location isn't present. This would normally indicate that's something corrupted with your BAM. Where did you get? How was it aligned? I'd recommend running ValidateSamFile to see if it complains. It could be we've being overly strict in Nucleus for parsing our BAMs. It'd be great if you can determine if your BAM is considered valid or not, and let us know if we need to be more permissive in our parsing or if the BAM needs to be fixed up. All the best,. Mark",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:600,safety,permiss,permissive,600,"Hi Zhuyi,. DeepVariant is complaining here because your BAM has a record that says it has a mapped mate but mtid, which is the htslib variable holding the offset into the chromosome array, isn't set so its actual mapped location isn't present. This would normally indicate that's something corrupted with your BAM. Where did you get? How was it aligned? I'd recommend running ValidateSamFile to see if it complains. It could be we've being overly strict in Nucleus for parsing our BAMs. It'd be great if you can determine if your BAM is considered valid or not, and let us know if we need to be more permissive in our parsing or if the BAM needs to be fixed up. All the best,. Mark",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:26,security,compl,complaining,26,"Hi Zhuyi,. DeepVariant is complaining here because your BAM has a record that says it has a mapped mate but mtid, which is the htslib variable holding the offset into the chromosome array, isn't set so its actual mapped location isn't present. This would normally indicate that's something corrupted with your BAM. Where did you get? How was it aligned? I'd recommend running ValidateSamFile to see if it complains. It could be we've being overly strict in Nucleus for parsing our BAMs. It'd be great if you can determine if your BAM is considered valid or not, and let us know if we need to be more permissive in our parsing or if the BAM needs to be fixed up. All the best,. Mark",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:376,security,Validat,ValidateSamFile,376,"Hi Zhuyi,. DeepVariant is complaining here because your BAM has a record that says it has a mapped mate but mtid, which is the htslib variable holding the offset into the chromosome array, isn't set so its actual mapped location isn't present. This would normally indicate that's something corrupted with your BAM. Where did you get? How was it aligned? I'd recommend running ValidateSamFile to see if it complains. It could be we've being overly strict in Nucleus for parsing our BAMs. It'd be great if you can determine if your BAM is considered valid or not, and let us know if we need to be more permissive in our parsing or if the BAM needs to be fixed up. All the best,. Mark",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:405,security,compl,complains,405,"Hi Zhuyi,. DeepVariant is complaining here because your BAM has a record that says it has a mapped mate but mtid, which is the htslib variable holding the offset into the chromosome array, isn't set so its actual mapped location isn't present. This would normally indicate that's something corrupted with your BAM. Where did you get? How was it aligned? I'd recommend running ValidateSamFile to see if it complains. It could be we've being overly strict in Nucleus for parsing our BAMs. It'd be great if you can determine if your BAM is considered valid or not, and let us know if we need to be more permissive in our parsing or if the BAM needs to be fixed up. All the best,. Mark",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:264,usability,indicat,indicate,264,"Hi Zhuyi,. DeepVariant is complaining here because your BAM has a record that says it has a mapped mate but mtid, which is the htslib variable holding the offset into the chromosome array, isn't set so its actual mapped location isn't present. This would normally indicate that's something corrupted with your BAM. Where did you get? How was it aligned? I'd recommend running ValidateSamFile to see if it complains. It could be we've being overly strict in Nucleus for parsing our BAMs. It'd be great if you can determine if your BAM is considered valid or not, and let us know if we need to be more permissive in our parsing or if the BAM needs to be fixed up. All the best,. Mark",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:68,availability,down,downloaded,68,"It is the bam file of a TCGA sample. I didn't align it myself, it's downloaded directly from a TCGA host. I will check and see it's validity, thank you for the information.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:132,safety,valid,validity,132,"It is the bam file of a TCGA sample. I didn't align it myself, it's downloaded directly from a TCGA host. I will check and see it's validity, thank you for the information.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:470,availability,error,error,470,"I identified the read pairs that are causing the problem:. ```. [read_id]/2 145 chr1 10535 59 50M * 0 0 [read_seq] CC?DD@DDDDDEEEEEFFFFFFHHHHJIJJJJJIIJJGHHHHFFFFFCCC ... [read_id]/1 81 chr10 38696640 69 29M1062N21M * 0 0 [read_seq] JJJJJJJJJJJJJJJJJJJJIJIFIGIJJIJJIGHGJHHFHHFFFFFCCB ... ```. These are the primary alignments, they also has a few non-primary alignments. Hmm... the pair of reads are aligned to two chromosomes, is that why `make_examples` is raising the error? Could those reads just be ignored? I tried `make_examples` with one other bam, and see the same error. Also, wondering how `make_examples` deals with non-primary alignments?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:573,availability,error,error,573,"I identified the read pairs that are causing the problem:. ```. [read_id]/2 145 chr1 10535 59 50M * 0 0 [read_seq] CC?DD@DDDDDEEEEEFFFFFFHHHHJIJJJJJIIJJGHHHHFFFFFCCC ... [read_id]/1 81 chr10 38696640 69 29M1062N21M * 0 0 [read_seq] JJJJJJJJJJJJJJJJJJJJIJIFIGIJJIJJIGHGJHHFHHFFFFFCCB ... ```. These are the primary alignments, they also has a few non-primary alignments. Hmm... the pair of reads are aligned to two chromosomes, is that why `make_examples` is raising the error? Could those reads just be ignored? I tried `make_examples` with one other bam, and see the same error. Also, wondering how `make_examples` deals with non-primary alignments?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:470,performance,error,error,470,"I identified the read pairs that are causing the problem:. ```. [read_id]/2 145 chr1 10535 59 50M * 0 0 [read_seq] CC?DD@DDDDDEEEEEFFFFFFHHHHJIJJJJJIIJJGHHHHFFFFFCCC ... [read_id]/1 81 chr10 38696640 69 29M1062N21M * 0 0 [read_seq] JJJJJJJJJJJJJJJJJJJJIJIFIGIJJIJJIGHGJHHFHHFFFFFCCB ... ```. These are the primary alignments, they also has a few non-primary alignments. Hmm... the pair of reads are aligned to two chromosomes, is that why `make_examples` is raising the error? Could those reads just be ignored? I tried `make_examples` with one other bam, and see the same error. Also, wondering how `make_examples` deals with non-primary alignments?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:573,performance,error,error,573,"I identified the read pairs that are causing the problem:. ```. [read_id]/2 145 chr1 10535 59 50M * 0 0 [read_seq] CC?DD@DDDDDEEEEEFFFFFFHHHHJIJJJJJIIJJGHHHHFFFFFCCC ... [read_id]/1 81 chr10 38696640 69 29M1062N21M * 0 0 [read_seq] JJJJJJJJJJJJJJJJJJJJIJIFIGIJJIJJIGHGJHHFHHFFFFFCCB ... ```. These are the primary alignments, they also has a few non-primary alignments. Hmm... the pair of reads are aligned to two chromosomes, is that why `make_examples` is raising the error? Could those reads just be ignored? I tried `make_examples` with one other bam, and see the same error. Also, wondering how `make_examples` deals with non-primary alignments?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:470,safety,error,error,470,"I identified the read pairs that are causing the problem:. ```. [read_id]/2 145 chr1 10535 59 50M * 0 0 [read_seq] CC?DD@DDDDDEEEEEFFFFFFHHHHJIJJJJJIIJJGHHHHFFFFFCCC ... [read_id]/1 81 chr10 38696640 69 29M1062N21M * 0 0 [read_seq] JJJJJJJJJJJJJJJJJJJJIJIFIGIJJIJJIGHGJHHFHHFFFFFCCB ... ```. These are the primary alignments, they also has a few non-primary alignments. Hmm... the pair of reads are aligned to two chromosomes, is that why `make_examples` is raising the error? Could those reads just be ignored? I tried `make_examples` with one other bam, and see the same error. Also, wondering how `make_examples` deals with non-primary alignments?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:573,safety,error,error,573,"I identified the read pairs that are causing the problem:. ```. [read_id]/2 145 chr1 10535 59 50M * 0 0 [read_seq] CC?DD@DDDDDEEEEEFFFFFFHHHHJIJJJJJIIJJGHHHHFFFFFCCC ... [read_id]/1 81 chr10 38696640 69 29M1062N21M * 0 0 [read_seq] JJJJJJJJJJJJJJJJJJJJIJIFIGIJJIJJIGHGJHHFHHFFFFFCCB ... ```. These are the primary alignments, they also has a few non-primary alignments. Hmm... the pair of reads are aligned to two chromosomes, is that why `make_examples` is raising the error? Could those reads just be ignored? I tried `make_examples` with one other bam, and see the same error. Also, wondering how `make_examples` deals with non-primary alignments?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:2,security,ident,identified,2,"I identified the read pairs that are causing the problem:. ```. [read_id]/2 145 chr1 10535 59 50M * 0 0 [read_seq] CC?DD@DDDDDEEEEEFFFFFFHHHHJIJJJJJIIJJGHHHHFFFFFCCC ... [read_id]/1 81 chr10 38696640 69 29M1062N21M * 0 0 [read_seq] JJJJJJJJJJJJJJJJJJJJIJIFIGIJJIJJIGHGJHHFHHFFFFFCCB ... ```. These are the primary alignments, they also has a few non-primary alignments. Hmm... the pair of reads are aligned to two chromosomes, is that why `make_examples` is raising the error? Could those reads just be ignored? I tried `make_examples` with one other bam, and see the same error. Also, wondering how `make_examples` deals with non-primary alignments?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:470,usability,error,error,470,"I identified the read pairs that are causing the problem:. ```. [read_id]/2 145 chr1 10535 59 50M * 0 0 [read_seq] CC?DD@DDDDDEEEEEFFFFFFHHHHJIJJJJJIIJJGHHHHFFFFFCCC ... [read_id]/1 81 chr10 38696640 69 29M1062N21M * 0 0 [read_seq] JJJJJJJJJJJJJJJJJJJJIJIFIGIJJIJJIGHGJHHFHHFFFFFCCB ... ```. These are the primary alignments, they also has a few non-primary alignments. Hmm... the pair of reads are aligned to two chromosomes, is that why `make_examples` is raising the error? Could those reads just be ignored? I tried `make_examples` with one other bam, and see the same error. Also, wondering how `make_examples` deals with non-primary alignments?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:573,usability,error,error,573,"I identified the read pairs that are causing the problem:. ```. [read_id]/2 145 chr1 10535 59 50M * 0 0 [read_seq] CC?DD@DDDDDEEEEEFFFFFFHHHHJIJJJJJIIJJGHHHHFFFFFCCC ... [read_id]/1 81 chr10 38696640 69 29M1062N21M * 0 0 [read_seq] JJJJJJJJJJJJJJJJJJJJIJIFIGIJJIJJIGHGJHHFHHFFFFFCCB ... ```. These are the primary alignments, they also has a few non-primary alignments. Hmm... the pair of reads are aligned to two chromosomes, is that why `make_examples` is raising the error? Could those reads just be ignored? I tried `make_examples` with one other bam, and see the same error. Also, wondering how `make_examples` deals with non-primary alignments?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:25,modifiability,scenario,scenario,25,"Maybe it's the following scenario:. So the flags indicate these are paired-end reads:. ```. 81 -> (read paired [0x1 (hex) = 1 (dec)], read reverse strand [0x10 = 16], first in pair [0x40 = 64] ). 145 -> (read paired [0x1 = 1], read reverse strand [0x10 = 16], second in pair [0x80 = 128]). ```. But the mate chromosome is * instead of =, which sets the `mtid` to -1 in [sam.c at the following lines](https://github.com/samtools/htslib/blob/master/sam.c#L1278-L1287):. ```C. // mate chr. q = _read_token(p);. if (strcmp(q, ""="") == 0) {. c->mtid = c->tid;. } else if (strcmp(q, ""*"") == 0) {. c->mtid = -1;. } else {. c->mtid = bam_name2id(h, q);. _parse_warn(c->mtid < 0, ""urecognized mate reference name; treated as unmapped"");. }. ```. Notice the assignment to `-1`, which might be because these reside on different chromosomes (`chr1` and `chr10`), which can happen in cancer through translocation. Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:49,usability,indicat,indicate,49,"Maybe it's the following scenario:. So the flags indicate these are paired-end reads:. ```. 81 -> (read paired [0x1 (hex) = 1 (dec)], read reverse strand [0x10 = 16], first in pair [0x40 = 64] ). 145 -> (read paired [0x1 = 1], read reverse strand [0x10 = 16], second in pair [0x80 = 128]). ```. But the mate chromosome is * instead of =, which sets the `mtid` to -1 in [sam.c at the following lines](https://github.com/samtools/htslib/blob/master/sam.c#L1278-L1287):. ```C. // mate chr. q = _read_token(p);. if (strcmp(q, ""="") == 0) {. c->mtid = c->tid;. } else if (strcmp(q, ""*"") == 0) {. c->mtid = -1;. } else {. c->mtid = bam_name2id(h, q);. _parse_warn(c->mtid < 0, ""urecognized mate reference name; treated as unmapped"");. }. ```. Notice the assignment to `-1`, which might be because these reside on different chromosomes (`chr1` and `chr10`), which can happen in cancer through translocation. Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:908,usability,help,helps,908,"Maybe it's the following scenario:. So the flags indicate these are paired-end reads:. ```. 81 -> (read paired [0x1 (hex) = 1 (dec)], read reverse strand [0x10 = 16], first in pair [0x40 = 64] ). 145 -> (read paired [0x1 = 1], read reverse strand [0x10 = 16], second in pair [0x80 = 128]). ```. But the mate chromosome is * instead of =, which sets the `mtid` to -1 in [sam.c at the following lines](https://github.com/samtools/htslib/blob/master/sam.c#L1278-L1287):. ```C. // mate chr. q = _read_token(p);. if (strcmp(q, ""="") == 0) {. c->mtid = c->tid;. } else if (strcmp(q, ""*"") == 0) {. c->mtid = -1;. } else {. c->mtid = bam_name2id(h, q);. _parse_warn(c->mtid < 0, ""urecognized mate reference name; treated as unmapped"");. }. ```. Notice the assignment to `-1`, which might be because these reside on different chromosomes (`chr1` and `chr10`), which can happen in cancer through translocation. Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:117,availability,ping,ping,117,"Hi @zyxue , we'll look into this a bit more. Might be something we can improve on the Nucleus codebase. Feel free to ping again if we don't give another updates in a few days.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:153,deployability,updat,updates,153,"Hi @zyxue , we'll look into this a bit more. Might be something we can improve on the Nucleus codebase. Feel free to ping again if we don't give another updates in a few days.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:153,safety,updat,updates,153,"Hi @zyxue , we'll look into this a bit more. Might be something we can improve on the Nucleus codebase. Feel free to ping again if we don't give another updates in a few days.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:153,security,updat,updates,153,"Hi @zyxue , we'll look into this a bit more. Might be something we can improve on the Nucleus codebase. Feel free to ping again if we don't give another updates in a few days.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:4,deployability,updat,update,4,"Any update on this, please? Is there a quick way that I could do to work around this, maybe even temporarily? By the way, I am using the docker image of DeepVariant.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:4,safety,updat,update,4,"Any update on this, please? Is there a quick way that I could do to work around this, maybe even temporarily? By the way, I am using the docker image of DeepVariant.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:4,security,updat,update,4,"Any update on this, please? Is there a quick way that I could do to work around this, maybe even temporarily? By the way, I am using the docker image of DeepVariant.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:62,availability,avail,available,62,"@zyxue I believe a proper bugfix is going in soon and will be available when we release an updated version of 0.7. Since the ETA for that isn't *right now* you can fix this in a local build yourself by:. changing:. https://github.com/google/deepvariant/blob/3c43de4541c45673e30d14daef742fca68fdf69b/third_party/nucleus/io/sam_reader.cc#L448. so that you have:. ```. if (c->mtid < -1). return tf::errors::DataLoss(. ""Expected mtid >= 0 as mate is supposedly mapped: "",. read_message->ShortDebugString());. else if (c->mtid == -1) {. mate_position->set_reference_name(""*"");. } else {. mate_position->set_reference_name(h->target_name[c->mtid]);. }. mate_position->set_position(c->mpos);. mate_position->set_reverse_strand(bam_is_mrev(b));. ```. which I believe should get your running again. You'll need to build DV from sources though.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:396,availability,error,errors,396,"@zyxue I believe a proper bugfix is going in soon and will be available when we release an updated version of 0.7. Since the ETA for that isn't *right now* you can fix this in a local build yourself by:. changing:. https://github.com/google/deepvariant/blob/3c43de4541c45673e30d14daef742fca68fdf69b/third_party/nucleus/io/sam_reader.cc#L448. so that you have:. ```. if (c->mtid < -1). return tf::errors::DataLoss(. ""Expected mtid >= 0 as mate is supposedly mapped: "",. read_message->ShortDebugString());. else if (c->mtid == -1) {. mate_position->set_reference_name(""*"");. } else {. mate_position->set_reference_name(h->target_name[c->mtid]);. }. mate_position->set_position(c->mpos);. mate_position->set_reverse_strand(bam_is_mrev(b));. ```. which I believe should get your running again. You'll need to build DV from sources though.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:80,deployability,releas,release,80,"@zyxue I believe a proper bugfix is going in soon and will be available when we release an updated version of 0.7. Since the ETA for that isn't *right now* you can fix this in a local build yourself by:. changing:. https://github.com/google/deepvariant/blob/3c43de4541c45673e30d14daef742fca68fdf69b/third_party/nucleus/io/sam_reader.cc#L448. so that you have:. ```. if (c->mtid < -1). return tf::errors::DataLoss(. ""Expected mtid >= 0 as mate is supposedly mapped: "",. read_message->ShortDebugString());. else if (c->mtid == -1) {. mate_position->set_reference_name(""*"");. } else {. mate_position->set_reference_name(h->target_name[c->mtid]);. }. mate_position->set_position(c->mpos);. mate_position->set_reverse_strand(bam_is_mrev(b));. ```. which I believe should get your running again. You'll need to build DV from sources though.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:91,deployability,updat,updated,91,"@zyxue I believe a proper bugfix is going in soon and will be available when we release an updated version of 0.7. Since the ETA for that isn't *right now* you can fix this in a local build yourself by:. changing:. https://github.com/google/deepvariant/blob/3c43de4541c45673e30d14daef742fca68fdf69b/third_party/nucleus/io/sam_reader.cc#L448. so that you have:. ```. if (c->mtid < -1). return tf::errors::DataLoss(. ""Expected mtid >= 0 as mate is supposedly mapped: "",. read_message->ShortDebugString());. else if (c->mtid == -1) {. mate_position->set_reference_name(""*"");. } else {. mate_position->set_reference_name(h->target_name[c->mtid]);. }. mate_position->set_position(c->mpos);. mate_position->set_reverse_strand(bam_is_mrev(b));. ```. which I believe should get your running again. You'll need to build DV from sources though.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:99,deployability,version,version,99,"@zyxue I believe a proper bugfix is going in soon and will be available when we release an updated version of 0.7. Since the ETA for that isn't *right now* you can fix this in a local build yourself by:. changing:. https://github.com/google/deepvariant/blob/3c43de4541c45673e30d14daef742fca68fdf69b/third_party/nucleus/io/sam_reader.cc#L448. so that you have:. ```. if (c->mtid < -1). return tf::errors::DataLoss(. ""Expected mtid >= 0 as mate is supposedly mapped: "",. read_message->ShortDebugString());. else if (c->mtid == -1) {. mate_position->set_reference_name(""*"");. } else {. mate_position->set_reference_name(h->target_name[c->mtid]);. }. mate_position->set_position(c->mpos);. mate_position->set_reverse_strand(bam_is_mrev(b));. ```. which I believe should get your running again. You'll need to build DV from sources though.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:184,deployability,build,build,184,"@zyxue I believe a proper bugfix is going in soon and will be available when we release an updated version of 0.7. Since the ETA for that isn't *right now* you can fix this in a local build yourself by:. changing:. https://github.com/google/deepvariant/blob/3c43de4541c45673e30d14daef742fca68fdf69b/third_party/nucleus/io/sam_reader.cc#L448. so that you have:. ```. if (c->mtid < -1). return tf::errors::DataLoss(. ""Expected mtid >= 0 as mate is supposedly mapped: "",. read_message->ShortDebugString());. else if (c->mtid == -1) {. mate_position->set_reference_name(""*"");. } else {. mate_position->set_reference_name(h->target_name[c->mtid]);. }. mate_position->set_position(c->mpos);. mate_position->set_reverse_strand(bam_is_mrev(b));. ```. which I believe should get your running again. You'll need to build DV from sources though.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:805,deployability,build,build,805,"@zyxue I believe a proper bugfix is going in soon and will be available when we release an updated version of 0.7. Since the ETA for that isn't *right now* you can fix this in a local build yourself by:. changing:. https://github.com/google/deepvariant/blob/3c43de4541c45673e30d14daef742fca68fdf69b/third_party/nucleus/io/sam_reader.cc#L448. so that you have:. ```. if (c->mtid < -1). return tf::errors::DataLoss(. ""Expected mtid >= 0 as mate is supposedly mapped: "",. read_message->ShortDebugString());. else if (c->mtid == -1) {. mate_position->set_reference_name(""*"");. } else {. mate_position->set_reference_name(h->target_name[c->mtid]);. }. mate_position->set_position(c->mpos);. mate_position->set_reverse_strand(bam_is_mrev(b));. ```. which I believe should get your running again. You'll need to build DV from sources though.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:99,integrability,version,version,99,"@zyxue I believe a proper bugfix is going in soon and will be available when we release an updated version of 0.7. Since the ETA for that isn't *right now* you can fix this in a local build yourself by:. changing:. https://github.com/google/deepvariant/blob/3c43de4541c45673e30d14daef742fca68fdf69b/third_party/nucleus/io/sam_reader.cc#L448. so that you have:. ```. if (c->mtid < -1). return tf::errors::DataLoss(. ""Expected mtid >= 0 as mate is supposedly mapped: "",. read_message->ShortDebugString());. else if (c->mtid == -1) {. mate_position->set_reference_name(""*"");. } else {. mate_position->set_reference_name(h->target_name[c->mtid]);. }. mate_position->set_position(c->mpos);. mate_position->set_reverse_strand(bam_is_mrev(b));. ```. which I believe should get your running again. You'll need to build DV from sources though.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:99,modifiability,version,version,99,"@zyxue I believe a proper bugfix is going in soon and will be available when we release an updated version of 0.7. Since the ETA for that isn't *right now* you can fix this in a local build yourself by:. changing:. https://github.com/google/deepvariant/blob/3c43de4541c45673e30d14daef742fca68fdf69b/third_party/nucleus/io/sam_reader.cc#L448. so that you have:. ```. if (c->mtid < -1). return tf::errors::DataLoss(. ""Expected mtid >= 0 as mate is supposedly mapped: "",. read_message->ShortDebugString());. else if (c->mtid == -1) {. mate_position->set_reference_name(""*"");. } else {. mate_position->set_reference_name(h->target_name[c->mtid]);. }. mate_position->set_position(c->mpos);. mate_position->set_reverse_strand(bam_is_mrev(b));. ```. which I believe should get your running again. You'll need to build DV from sources though.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:396,performance,error,errors,396,"@zyxue I believe a proper bugfix is going in soon and will be available when we release an updated version of 0.7. Since the ETA for that isn't *right now* you can fix this in a local build yourself by:. changing:. https://github.com/google/deepvariant/blob/3c43de4541c45673e30d14daef742fca68fdf69b/third_party/nucleus/io/sam_reader.cc#L448. so that you have:. ```. if (c->mtid < -1). return tf::errors::DataLoss(. ""Expected mtid >= 0 as mate is supposedly mapped: "",. read_message->ShortDebugString());. else if (c->mtid == -1) {. mate_position->set_reference_name(""*"");. } else {. mate_position->set_reference_name(h->target_name[c->mtid]);. }. mate_position->set_position(c->mpos);. mate_position->set_reverse_strand(bam_is_mrev(b));. ```. which I believe should get your running again. You'll need to build DV from sources though.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:62,reliability,availab,available,62,"@zyxue I believe a proper bugfix is going in soon and will be available when we release an updated version of 0.7. Since the ETA for that isn't *right now* you can fix this in a local build yourself by:. changing:. https://github.com/google/deepvariant/blob/3c43de4541c45673e30d14daef742fca68fdf69b/third_party/nucleus/io/sam_reader.cc#L448. so that you have:. ```. if (c->mtid < -1). return tf::errors::DataLoss(. ""Expected mtid >= 0 as mate is supposedly mapped: "",. read_message->ShortDebugString());. else if (c->mtid == -1) {. mate_position->set_reference_name(""*"");. } else {. mate_position->set_reference_name(h->target_name[c->mtid]);. }. mate_position->set_position(c->mpos);. mate_position->set_reverse_strand(bam_is_mrev(b));. ```. which I believe should get your running again. You'll need to build DV from sources though.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:62,safety,avail,available,62,"@zyxue I believe a proper bugfix is going in soon and will be available when we release an updated version of 0.7. Since the ETA for that isn't *right now* you can fix this in a local build yourself by:. changing:. https://github.com/google/deepvariant/blob/3c43de4541c45673e30d14daef742fca68fdf69b/third_party/nucleus/io/sam_reader.cc#L448. so that you have:. ```. if (c->mtid < -1). return tf::errors::DataLoss(. ""Expected mtid >= 0 as mate is supposedly mapped: "",. read_message->ShortDebugString());. else if (c->mtid == -1) {. mate_position->set_reference_name(""*"");. } else {. mate_position->set_reference_name(h->target_name[c->mtid]);. }. mate_position->set_position(c->mpos);. mate_position->set_reverse_strand(bam_is_mrev(b));. ```. which I believe should get your running again. You'll need to build DV from sources though.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:91,safety,updat,updated,91,"@zyxue I believe a proper bugfix is going in soon and will be available when we release an updated version of 0.7. Since the ETA for that isn't *right now* you can fix this in a local build yourself by:. changing:. https://github.com/google/deepvariant/blob/3c43de4541c45673e30d14daef742fca68fdf69b/third_party/nucleus/io/sam_reader.cc#L448. so that you have:. ```. if (c->mtid < -1). return tf::errors::DataLoss(. ""Expected mtid >= 0 as mate is supposedly mapped: "",. read_message->ShortDebugString());. else if (c->mtid == -1) {. mate_position->set_reference_name(""*"");. } else {. mate_position->set_reference_name(h->target_name[c->mtid]);. }. mate_position->set_position(c->mpos);. mate_position->set_reverse_strand(bam_is_mrev(b));. ```. which I believe should get your running again. You'll need to build DV from sources though.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:396,safety,error,errors,396,"@zyxue I believe a proper bugfix is going in soon and will be available when we release an updated version of 0.7. Since the ETA for that isn't *right now* you can fix this in a local build yourself by:. changing:. https://github.com/google/deepvariant/blob/3c43de4541c45673e30d14daef742fca68fdf69b/third_party/nucleus/io/sam_reader.cc#L448. so that you have:. ```. if (c->mtid < -1). return tf::errors::DataLoss(. ""Expected mtid >= 0 as mate is supposedly mapped: "",. read_message->ShortDebugString());. else if (c->mtid == -1) {. mate_position->set_reference_name(""*"");. } else {. mate_position->set_reference_name(h->target_name[c->mtid]);. }. mate_position->set_position(c->mpos);. mate_position->set_reverse_strand(bam_is_mrev(b));. ```. which I believe should get your running again. You'll need to build DV from sources though.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:62,security,availab,available,62,"@zyxue I believe a proper bugfix is going in soon and will be available when we release an updated version of 0.7. Since the ETA for that isn't *right now* you can fix this in a local build yourself by:. changing:. https://github.com/google/deepvariant/blob/3c43de4541c45673e30d14daef742fca68fdf69b/third_party/nucleus/io/sam_reader.cc#L448. so that you have:. ```. if (c->mtid < -1). return tf::errors::DataLoss(. ""Expected mtid >= 0 as mate is supposedly mapped: "",. read_message->ShortDebugString());. else if (c->mtid == -1) {. mate_position->set_reference_name(""*"");. } else {. mate_position->set_reference_name(h->target_name[c->mtid]);. }. mate_position->set_position(c->mpos);. mate_position->set_reverse_strand(bam_is_mrev(b));. ```. which I believe should get your running again. You'll need to build DV from sources though.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:91,security,updat,updated,91,"@zyxue I believe a proper bugfix is going in soon and will be available when we release an updated version of 0.7. Since the ETA for that isn't *right now* you can fix this in a local build yourself by:. changing:. https://github.com/google/deepvariant/blob/3c43de4541c45673e30d14daef742fca68fdf69b/third_party/nucleus/io/sam_reader.cc#L448. so that you have:. ```. if (c->mtid < -1). return tf::errors::DataLoss(. ""Expected mtid >= 0 as mate is supposedly mapped: "",. read_message->ShortDebugString());. else if (c->mtid == -1) {. mate_position->set_reference_name(""*"");. } else {. mate_position->set_reference_name(h->target_name[c->mtid]);. }. mate_position->set_position(c->mpos);. mate_position->set_reverse_strand(bam_is_mrev(b));. ```. which I believe should get your running again. You'll need to build DV from sources though.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:396,usability,error,errors,396,"@zyxue I believe a proper bugfix is going in soon and will be available when we release an updated version of 0.7. Since the ETA for that isn't *right now* you can fix this in a local build yourself by:. changing:. https://github.com/google/deepvariant/blob/3c43de4541c45673e30d14daef742fca68fdf69b/third_party/nucleus/io/sam_reader.cc#L448. so that you have:. ```. if (c->mtid < -1). return tf::errors::DataLoss(. ""Expected mtid >= 0 as mate is supposedly mapped: "",. read_message->ShortDebugString());. else if (c->mtid == -1) {. mate_position->set_reference_name(""*"");. } else {. mate_position->set_reference_name(h->target_name[c->mtid]);. }. mate_position->set_position(c->mpos);. mate_position->set_reverse_strand(bam_is_mrev(b));. ```. which I believe should get your running again. You'll need to build DV from sources though.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:647,availability,error,errors,647,"I've made the suggested changes at https://github.com/zyxue/deepvariant/commit/cc09d6da17dcb700144cb3cd8dd2b7ece2c3ad86. ```diff. diff --git a/third_party/nucleus/io/sam_reader.cc b/third_party/nucleus/io/sam_reader.cc. index d8c7cae..1b020be 100644. --- a/third_party/nucleus/io/sam_reader.cc. +++ b/third_party/nucleus/io/sam_reader.cc. @@ -445,11 +445,15 @@ tf::Status ConvertToPb(const bam_hdr_t* h, const bam1_t* b,. // Set the mates map position if the mate is not unmapped. if (paired && !(c->flag & BAM_FMUNMAP)) {. Position* mate_position = read_message->mutable_next_mate_position();. - if (c->mtid < 0). + if (c->mtid < -1). return tf::errors::DataLoss(. ""Expected mtid >= 0 as mate is supposedly mapped: "",. read_message->ShortDebugString());. - mate_position->set_reference_name(h->target_name[c->mtid]);. + else if (c->mtid == -1) {. + mate_position->set_reference_name(""*"");. + } else {. + mate_position->set_reference_name(h->target_name[c->mtid]);. + }. mate_position->set_position(c->mpos);. mate_position->set_reverse_strand(bam_is_mrev(b));. }. ```. What command do you use to build the docker image, please?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:1097,deployability,build,build,1097,"I've made the suggested changes at https://github.com/zyxue/deepvariant/commit/cc09d6da17dcb700144cb3cd8dd2b7ece2c3ad86. ```diff. diff --git a/third_party/nucleus/io/sam_reader.cc b/third_party/nucleus/io/sam_reader.cc. index d8c7cae..1b020be 100644. --- a/third_party/nucleus/io/sam_reader.cc. +++ b/third_party/nucleus/io/sam_reader.cc. @@ -445,11 +445,15 @@ tf::Status ConvertToPb(const bam_hdr_t* h, const bam1_t* b,. // Set the mates map position if the mate is not unmapped. if (paired && !(c->flag & BAM_FMUNMAP)) {. Position* mate_position = read_message->mutable_next_mate_position();. - if (c->mtid < 0). + if (c->mtid < -1). return tf::errors::DataLoss(. ""Expected mtid >= 0 as mate is supposedly mapped: "",. read_message->ShortDebugString());. - mate_position->set_reference_name(h->target_name[c->mtid]);. + else if (c->mtid == -1) {. + mate_position->set_reference_name(""*"");. + } else {. + mate_position->set_reference_name(h->target_name[c->mtid]);. + }. mate_position->set_position(c->mpos);. mate_position->set_reverse_strand(bam_is_mrev(b));. }. ```. What command do you use to build the docker image, please?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:647,performance,error,errors,647,"I've made the suggested changes at https://github.com/zyxue/deepvariant/commit/cc09d6da17dcb700144cb3cd8dd2b7ece2c3ad86. ```diff. diff --git a/third_party/nucleus/io/sam_reader.cc b/third_party/nucleus/io/sam_reader.cc. index d8c7cae..1b020be 100644. --- a/third_party/nucleus/io/sam_reader.cc. +++ b/third_party/nucleus/io/sam_reader.cc. @@ -445,11 +445,15 @@ tf::Status ConvertToPb(const bam_hdr_t* h, const bam1_t* b,. // Set the mates map position if the mate is not unmapped. if (paired && !(c->flag & BAM_FMUNMAP)) {. Position* mate_position = read_message->mutable_next_mate_position();. - if (c->mtid < 0). + if (c->mtid < -1). return tf::errors::DataLoss(. ""Expected mtid >= 0 as mate is supposedly mapped: "",. read_message->ShortDebugString());. - mate_position->set_reference_name(h->target_name[c->mtid]);. + else if (c->mtid == -1) {. + mate_position->set_reference_name(""*"");. + } else {. + mate_position->set_reference_name(h->target_name[c->mtid]);. + }. mate_position->set_position(c->mpos);. mate_position->set_reverse_strand(bam_is_mrev(b));. }. ```. What command do you use to build the docker image, please?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:647,safety,error,errors,647,"I've made the suggested changes at https://github.com/zyxue/deepvariant/commit/cc09d6da17dcb700144cb3cd8dd2b7ece2c3ad86. ```diff. diff --git a/third_party/nucleus/io/sam_reader.cc b/third_party/nucleus/io/sam_reader.cc. index d8c7cae..1b020be 100644. --- a/third_party/nucleus/io/sam_reader.cc. +++ b/third_party/nucleus/io/sam_reader.cc. @@ -445,11 +445,15 @@ tf::Status ConvertToPb(const bam_hdr_t* h, const bam1_t* b,. // Set the mates map position if the mate is not unmapped. if (paired && !(c->flag & BAM_FMUNMAP)) {. Position* mate_position = read_message->mutable_next_mate_position();. - if (c->mtid < 0). + if (c->mtid < -1). return tf::errors::DataLoss(. ""Expected mtid >= 0 as mate is supposedly mapped: "",. read_message->ShortDebugString());. - mate_position->set_reference_name(h->target_name[c->mtid]);. + else if (c->mtid == -1) {. + mate_position->set_reference_name(""*"");. + } else {. + mate_position->set_reference_name(h->target_name[c->mtid]);. + }. mate_position->set_position(c->mpos);. mate_position->set_reverse_strand(bam_is_mrev(b));. }. ```. What command do you use to build the docker image, please?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:365,usability,Statu,Status,365,"I've made the suggested changes at https://github.com/zyxue/deepvariant/commit/cc09d6da17dcb700144cb3cd8dd2b7ece2c3ad86. ```diff. diff --git a/third_party/nucleus/io/sam_reader.cc b/third_party/nucleus/io/sam_reader.cc. index d8c7cae..1b020be 100644. --- a/third_party/nucleus/io/sam_reader.cc. +++ b/third_party/nucleus/io/sam_reader.cc. @@ -445,11 +445,15 @@ tf::Status ConvertToPb(const bam_hdr_t* h, const bam1_t* b,. // Set the mates map position if the mate is not unmapped. if (paired && !(c->flag & BAM_FMUNMAP)) {. Position* mate_position = read_message->mutable_next_mate_position();. - if (c->mtid < 0). + if (c->mtid < -1). return tf::errors::DataLoss(. ""Expected mtid >= 0 as mate is supposedly mapped: "",. read_message->ShortDebugString());. - mate_position->set_reference_name(h->target_name[c->mtid]);. + else if (c->mtid == -1) {. + mate_position->set_reference_name(""*"");. + } else {. + mate_position->set_reference_name(h->target_name[c->mtid]);. + }. mate_position->set_position(c->mpos);. mate_position->set_reverse_strand(bam_is_mrev(b));. }. ```. What command do you use to build the docker image, please?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:647,usability,error,errors,647,"I've made the suggested changes at https://github.com/zyxue/deepvariant/commit/cc09d6da17dcb700144cb3cd8dd2b7ece2c3ad86. ```diff. diff --git a/third_party/nucleus/io/sam_reader.cc b/third_party/nucleus/io/sam_reader.cc. index d8c7cae..1b020be 100644. --- a/third_party/nucleus/io/sam_reader.cc. +++ b/third_party/nucleus/io/sam_reader.cc. @@ -445,11 +445,15 @@ tf::Status ConvertToPb(const bam_hdr_t* h, const bam1_t* b,. // Set the mates map position if the mate is not unmapped. if (paired && !(c->flag & BAM_FMUNMAP)) {. Position* mate_position = read_message->mutable_next_mate_position();. - if (c->mtid < 0). + if (c->mtid < -1). return tf::errors::DataLoss(. ""Expected mtid >= 0 as mate is supposedly mapped: "",. read_message->ShortDebugString());. - mate_position->set_reference_name(h->target_name[c->mtid]);. + else if (c->mtid == -1) {. + mate_position->set_reference_name(""*"");. + } else {. + mate_position->set_reference_name(h->target_name[c->mtid]);. + }. mate_position->set_position(c->mpos);. mate_position->set_reverse_strand(bam_is_mrev(b));. }. ```. What command do you use to build the docker image, please?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:1075,usability,command,command,1075,"I've made the suggested changes at https://github.com/zyxue/deepvariant/commit/cc09d6da17dcb700144cb3cd8dd2b7ece2c3ad86. ```diff. diff --git a/third_party/nucleus/io/sam_reader.cc b/third_party/nucleus/io/sam_reader.cc. index d8c7cae..1b020be 100644. --- a/third_party/nucleus/io/sam_reader.cc. +++ b/third_party/nucleus/io/sam_reader.cc. @@ -445,11 +445,15 @@ tf::Status ConvertToPb(const bam_hdr_t* h, const bam1_t* b,. // Set the mates map position if the mate is not unmapped. if (paired && !(c->flag & BAM_FMUNMAP)) {. Position* mate_position = read_message->mutable_next_mate_position();. - if (c->mtid < 0). + if (c->mtid < -1). return tf::errors::DataLoss(. ""Expected mtid >= 0 as mate is supposedly mapped: "",. read_message->ShortDebugString());. - mate_position->set_reference_name(h->target_name[c->mtid]);. + else if (c->mtid == -1) {. + mate_position->set_reference_name(""*"");. + } else {. + mate_position->set_reference_name(h->target_name[c->mtid]);. + }. mate_position->set_position(c->mpos);. mate_position->set_reverse_strand(bam_is_mrev(b));. }. ```. What command do you use to build the docker image, please?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:10,deployability,build,build,10,"Use could build docker image with this command. It needs to be run from 'deepvariant' directory. I used arbitrary values for PROJECT_ID and VERSION_NUMBER, you may replace them. . PROJECT_ID=my-deepvariant-docker. VERSION_NUMBER=0.7.2 . gcloud builds submit --project ""${PROJECT_ID}"" --config cloudbuild.yaml --substitutions TAG_NAME=""${VERSION_NUMBER}"" --timeout 2h .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:244,deployability,build,builds,244,"Use could build docker image with this command. It needs to be run from 'deepvariant' directory. I used arbitrary values for PROJECT_ID and VERSION_NUMBER, you may replace them. . PROJECT_ID=my-deepvariant-docker. VERSION_NUMBER=0.7.2 . gcloud builds submit --project ""${PROJECT_ID}"" --config cloudbuild.yaml --substitutions TAG_NAME=""${VERSION_NUMBER}"" --timeout 2h .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:293,energy efficiency,cloud,cloudbuild,293,"Use could build docker image with this command. It needs to be run from 'deepvariant' directory. I used arbitrary values for PROJECT_ID and VERSION_NUMBER, you may replace them. . PROJECT_ID=my-deepvariant-docker. VERSION_NUMBER=0.7.2 . gcloud builds submit --project ""${PROJECT_ID}"" --config cloudbuild.yaml --substitutions TAG_NAME=""${VERSION_NUMBER}"" --timeout 2h .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:251,integrability,sub,submit,251,"Use could build docker image with this command. It needs to be run from 'deepvariant' directory. I used arbitrary values for PROJECT_ID and VERSION_NUMBER, you may replace them. . PROJECT_ID=my-deepvariant-docker. VERSION_NUMBER=0.7.2 . gcloud builds submit --project ""${PROJECT_ID}"" --config cloudbuild.yaml --substitutions TAG_NAME=""${VERSION_NUMBER}"" --timeout 2h .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:311,integrability,sub,substitutions,311,"Use could build docker image with this command. It needs to be run from 'deepvariant' directory. I used arbitrary values for PROJECT_ID and VERSION_NUMBER, you may replace them. . PROJECT_ID=my-deepvariant-docker. VERSION_NUMBER=0.7.2 . gcloud builds submit --project ""${PROJECT_ID}"" --config cloudbuild.yaml --substitutions TAG_NAME=""${VERSION_NUMBER}"" --timeout 2h .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:356,performance,time,timeout,356,"Use could build docker image with this command. It needs to be run from 'deepvariant' directory. I used arbitrary values for PROJECT_ID and VERSION_NUMBER, you may replace them. . PROJECT_ID=my-deepvariant-docker. VERSION_NUMBER=0.7.2 . gcloud builds submit --project ""${PROJECT_ID}"" --config cloudbuild.yaml --substitutions TAG_NAME=""${VERSION_NUMBER}"" --timeout 2h .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:356,safety,timeout,timeout,356,"Use could build docker image with this command. It needs to be run from 'deepvariant' directory. I used arbitrary values for PROJECT_ID and VERSION_NUMBER, you may replace them. . PROJECT_ID=my-deepvariant-docker. VERSION_NUMBER=0.7.2 . gcloud builds submit --project ""${PROJECT_ID}"" --config cloudbuild.yaml --substitutions TAG_NAME=""${VERSION_NUMBER}"" --timeout 2h .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:39,usability,command,command,39,"Use could build docker image with this command. It needs to be run from 'deepvariant' directory. I used arbitrary values for PROJECT_ID and VERSION_NUMBER, you may replace them. . PROJECT_ID=my-deepvariant-docker. VERSION_NUMBER=0.7.2 . gcloud builds submit --project ""${PROJECT_ID}"" --config cloudbuild.yaml --substitutions TAG_NAME=""${VERSION_NUMBER}"" --timeout 2h .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:82,deployability,build,build,82,"Thanks for your command @akolesnikov, I've made it running. Also, I wonder how to build it locally without GCP access, please?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:111,security,access,access,111,"Thanks for your command @akolesnikov, I've made it running. Also, I wonder how to build it locally without GCP access, please?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:16,usability,command,command,16,"Thanks for your command @akolesnikov, I've made it running. Also, I wonder how to build it locally without GCP access, please?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:18,deployability,build,build-local,18,"@zyxue Via `cloud-build-local`, below is a link to more information about it: . https://cloud.google.com/cloud-build/docs/build-debug-locally. You will need to run the following command to install it:. `gcloud components install cloud-build-local`",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:111,deployability,build,build,111,"@zyxue Via `cloud-build-local`, below is a link to more information about it: . https://cloud.google.com/cloud-build/docs/build-debug-locally. You will need to run the following command to install it:. `gcloud components install cloud-build-local`",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:122,deployability,build,build-debug-locally,122,"@zyxue Via `cloud-build-local`, below is a link to more information about it: . https://cloud.google.com/cloud-build/docs/build-debug-locally. You will need to run the following command to install it:. `gcloud components install cloud-build-local`",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:189,deployability,instal,install,189,"@zyxue Via `cloud-build-local`, below is a link to more information about it: . https://cloud.google.com/cloud-build/docs/build-debug-locally. You will need to run the following command to install it:. `gcloud components install cloud-build-local`",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:221,deployability,instal,install,221,"@zyxue Via `cloud-build-local`, below is a link to more information about it: . https://cloud.google.com/cloud-build/docs/build-debug-locally. You will need to run the following command to install it:. `gcloud components install cloud-build-local`",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:235,deployability,build,build-local,235,"@zyxue Via `cloud-build-local`, below is a link to more information about it: . https://cloud.google.com/cloud-build/docs/build-debug-locally. You will need to run the following command to install it:. `gcloud components install cloud-build-local`",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:12,energy efficiency,cloud,cloud-build-local,12,"@zyxue Via `cloud-build-local`, below is a link to more information about it: . https://cloud.google.com/cloud-build/docs/build-debug-locally. You will need to run the following command to install it:. `gcloud components install cloud-build-local`",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:88,energy efficiency,cloud,cloud,88,"@zyxue Via `cloud-build-local`, below is a link to more information about it: . https://cloud.google.com/cloud-build/docs/build-debug-locally. You will need to run the following command to install it:. `gcloud components install cloud-build-local`",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:105,energy efficiency,cloud,cloud-build,105,"@zyxue Via `cloud-build-local`, below is a link to more information about it: . https://cloud.google.com/cloud-build/docs/build-debug-locally. You will need to run the following command to install it:. `gcloud components install cloud-build-local`",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:229,energy efficiency,cloud,cloud-build-local,229,"@zyxue Via `cloud-build-local`, below is a link to more information about it: . https://cloud.google.com/cloud-build/docs/build-debug-locally. You will need to run the following command to install it:. `gcloud components install cloud-build-local`",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:210,integrability,compon,components,210,"@zyxue Via `cloud-build-local`, below is a link to more information about it: . https://cloud.google.com/cloud-build/docs/build-debug-locally. You will need to run the following command to install it:. `gcloud components install cloud-build-local`",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:210,interoperability,compon,components,210,"@zyxue Via `cloud-build-local`, below is a link to more information about it: . https://cloud.google.com/cloud-build/docs/build-debug-locally. You will need to run the following command to install it:. `gcloud components install cloud-build-local`",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:210,modifiability,compon,components,210,"@zyxue Via `cloud-build-local`, below is a link to more information about it: . https://cloud.google.com/cloud-build/docs/build-debug-locally. You will need to run the following command to install it:. `gcloud components install cloud-build-local`",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:178,usability,command,command,178,"@zyxue Via `cloud-build-local`, below is a link to more information about it: . https://cloud.google.com/cloud-build/docs/build-debug-locally. You will need to run the following command to install it:. `gcloud components install cloud-build-local`",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:32,deployability,build,build-local,32,"Thanks for the info about cloud-build-local, @pgrosu. FYI, my rebuilt image seems to be running properly now. Thank you for all your help!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:26,energy efficiency,cloud,cloud-build-local,26,"Thanks for the info about cloud-build-local, @pgrosu. FYI, my rebuilt image seems to be running properly now. Thank you for all your help!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:133,usability,help,help,133,"Thanks for the info about cloud-build-local, @pgrosu. FYI, my rebuilt image seems to be running properly now. Thank you for all your help!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:31,availability,ping,ping,31,"@zyxue Fantastic! Feel free to ping us if you run into any other issues :). Thanks,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:628,energy efficiency,current,current,628,"`make_example.py` seems to stuck after a long time of running at chr14,. ```. I1010 11:12:31.993017 140686008715008 make_examples.py:825] Found 0 candidates in chr14:106812001-106813000 [1000 bp] [0.08s elapsed]. I1010 11:12:32.117227 140686008715008 make_examples.py:825] Found 1 candidates in chr14:106813001-106814000 [1000 bp] [0.12s elapsed]. I1010 11:12:32.204456 140686008715008 make_examples.py:825] Found 0 candidates in chr14:106814001-106815000 [1000 bp] [0.09s elapsed]. I1010 11:12:32.953804 140686008715008 make_examples.py:825] Found 12 candidates in chr14:106815001-106816000 [1000 bp] [0.75s elapsed]. ```. The current timestamp is Oct 10 15:18:07 UTC 2018, so it's been over four hours, the cpu is still full, showing some computation is still going on. What could be possible reason please? BTW, is it possible to parallelize make_example? It seems to only use one cpu at a time at the moment. The command I used. ```. sudo docker run \. -v /home/${USER}:/home/${USER} \. gcr.io/${PROJECT_NAME}/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/make_examples \. --mode calling \. --ref ""${REF}"" \. --reads ""${BAM}"" \. --examples ""${OUTPUT_DIR}/examples.tfrecord.gz"". ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:709,energy efficiency,cpu,cpu,709,"`make_example.py` seems to stuck after a long time of running at chr14,. ```. I1010 11:12:31.993017 140686008715008 make_examples.py:825] Found 0 candidates in chr14:106812001-106813000 [1000 bp] [0.08s elapsed]. I1010 11:12:32.117227 140686008715008 make_examples.py:825] Found 1 candidates in chr14:106813001-106814000 [1000 bp] [0.12s elapsed]. I1010 11:12:32.204456 140686008715008 make_examples.py:825] Found 0 candidates in chr14:106814001-106815000 [1000 bp] [0.09s elapsed]. I1010 11:12:32.953804 140686008715008 make_examples.py:825] Found 12 candidates in chr14:106815001-106816000 [1000 bp] [0.75s elapsed]. ```. The current timestamp is Oct 10 15:18:07 UTC 2018, so it's been over four hours, the cpu is still full, showing some computation is still going on. What could be possible reason please? BTW, is it possible to parallelize make_example? It seems to only use one cpu at a time at the moment. The command I used. ```. sudo docker run \. -v /home/${USER}:/home/${USER} \. gcr.io/${PROJECT_NAME}/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/make_examples \. --mode calling \. --ref ""${REF}"" \. --reads ""${BAM}"" \. --examples ""${OUTPUT_DIR}/examples.tfrecord.gz"". ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:884,energy efficiency,cpu,cpu,884,"`make_example.py` seems to stuck after a long time of running at chr14,. ```. I1010 11:12:31.993017 140686008715008 make_examples.py:825] Found 0 candidates in chr14:106812001-106813000 [1000 bp] [0.08s elapsed]. I1010 11:12:32.117227 140686008715008 make_examples.py:825] Found 1 candidates in chr14:106813001-106814000 [1000 bp] [0.12s elapsed]. I1010 11:12:32.204456 140686008715008 make_examples.py:825] Found 0 candidates in chr14:106814001-106815000 [1000 bp] [0.09s elapsed]. I1010 11:12:32.953804 140686008715008 make_examples.py:825] Found 12 candidates in chr14:106815001-106816000 [1000 bp] [0.75s elapsed]. ```. The current timestamp is Oct 10 15:18:07 UTC 2018, so it's been over four hours, the cpu is still full, showing some computation is still going on. What could be possible reason please? BTW, is it possible to parallelize make_example? It seems to only use one cpu at a time at the moment. The command I used. ```. sudo docker run \. -v /home/${USER}:/home/${USER} \. gcr.io/${PROJECT_NAME}/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/make_examples \. --mode calling \. --ref ""${REF}"" \. --reads ""${BAM}"" \. --examples ""${OUTPUT_DIR}/examples.tfrecord.gz"". ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:46,performance,time,time,46,"`make_example.py` seems to stuck after a long time of running at chr14,. ```. I1010 11:12:31.993017 140686008715008 make_examples.py:825] Found 0 candidates in chr14:106812001-106813000 [1000 bp] [0.08s elapsed]. I1010 11:12:32.117227 140686008715008 make_examples.py:825] Found 1 candidates in chr14:106813001-106814000 [1000 bp] [0.12s elapsed]. I1010 11:12:32.204456 140686008715008 make_examples.py:825] Found 0 candidates in chr14:106814001-106815000 [1000 bp] [0.09s elapsed]. I1010 11:12:32.953804 140686008715008 make_examples.py:825] Found 12 candidates in chr14:106815001-106816000 [1000 bp] [0.75s elapsed]. ```. The current timestamp is Oct 10 15:18:07 UTC 2018, so it's been over four hours, the cpu is still full, showing some computation is still going on. What could be possible reason please? BTW, is it possible to parallelize make_example? It seems to only use one cpu at a time at the moment. The command I used. ```. sudo docker run \. -v /home/${USER}:/home/${USER} \. gcr.io/${PROJECT_NAME}/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/make_examples \. --mode calling \. --ref ""${REF}"" \. --reads ""${BAM}"" \. --examples ""${OUTPUT_DIR}/examples.tfrecord.gz"". ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:636,performance,time,timestamp,636,"`make_example.py` seems to stuck after a long time of running at chr14,. ```. I1010 11:12:31.993017 140686008715008 make_examples.py:825] Found 0 candidates in chr14:106812001-106813000 [1000 bp] [0.08s elapsed]. I1010 11:12:32.117227 140686008715008 make_examples.py:825] Found 1 candidates in chr14:106813001-106814000 [1000 bp] [0.12s elapsed]. I1010 11:12:32.204456 140686008715008 make_examples.py:825] Found 0 candidates in chr14:106814001-106815000 [1000 bp] [0.09s elapsed]. I1010 11:12:32.953804 140686008715008 make_examples.py:825] Found 12 candidates in chr14:106815001-106816000 [1000 bp] [0.75s elapsed]. ```. The current timestamp is Oct 10 15:18:07 UTC 2018, so it's been over four hours, the cpu is still full, showing some computation is still going on. What could be possible reason please? BTW, is it possible to parallelize make_example? It seems to only use one cpu at a time at the moment. The command I used. ```. sudo docker run \. -v /home/${USER}:/home/${USER} \. gcr.io/${PROJECT_NAME}/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/make_examples \. --mode calling \. --ref ""${REF}"" \. --reads ""${BAM}"" \. --examples ""${OUTPUT_DIR}/examples.tfrecord.gz"". ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:709,performance,cpu,cpu,709,"`make_example.py` seems to stuck after a long time of running at chr14,. ```. I1010 11:12:31.993017 140686008715008 make_examples.py:825] Found 0 candidates in chr14:106812001-106813000 [1000 bp] [0.08s elapsed]. I1010 11:12:32.117227 140686008715008 make_examples.py:825] Found 1 candidates in chr14:106813001-106814000 [1000 bp] [0.12s elapsed]. I1010 11:12:32.204456 140686008715008 make_examples.py:825] Found 0 candidates in chr14:106814001-106815000 [1000 bp] [0.09s elapsed]. I1010 11:12:32.953804 140686008715008 make_examples.py:825] Found 12 candidates in chr14:106815001-106816000 [1000 bp] [0.75s elapsed]. ```. The current timestamp is Oct 10 15:18:07 UTC 2018, so it's been over four hours, the cpu is still full, showing some computation is still going on. What could be possible reason please? BTW, is it possible to parallelize make_example? It seems to only use one cpu at a time at the moment. The command I used. ```. sudo docker run \. -v /home/${USER}:/home/${USER} \. gcr.io/${PROJECT_NAME}/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/make_examples \. --mode calling \. --ref ""${REF}"" \. --reads ""${BAM}"" \. --examples ""${OUTPUT_DIR}/examples.tfrecord.gz"". ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:833,performance,parallel,parallelize,833,"`make_example.py` seems to stuck after a long time of running at chr14,. ```. I1010 11:12:31.993017 140686008715008 make_examples.py:825] Found 0 candidates in chr14:106812001-106813000 [1000 bp] [0.08s elapsed]. I1010 11:12:32.117227 140686008715008 make_examples.py:825] Found 1 candidates in chr14:106813001-106814000 [1000 bp] [0.12s elapsed]. I1010 11:12:32.204456 140686008715008 make_examples.py:825] Found 0 candidates in chr14:106814001-106815000 [1000 bp] [0.09s elapsed]. I1010 11:12:32.953804 140686008715008 make_examples.py:825] Found 12 candidates in chr14:106815001-106816000 [1000 bp] [0.75s elapsed]. ```. The current timestamp is Oct 10 15:18:07 UTC 2018, so it's been over four hours, the cpu is still full, showing some computation is still going on. What could be possible reason please? BTW, is it possible to parallelize make_example? It seems to only use one cpu at a time at the moment. The command I used. ```. sudo docker run \. -v /home/${USER}:/home/${USER} \. gcr.io/${PROJECT_NAME}/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/make_examples \. --mode calling \. --ref ""${REF}"" \. --reads ""${BAM}"" \. --examples ""${OUTPUT_DIR}/examples.tfrecord.gz"". ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:884,performance,cpu,cpu,884,"`make_example.py` seems to stuck after a long time of running at chr14,. ```. I1010 11:12:31.993017 140686008715008 make_examples.py:825] Found 0 candidates in chr14:106812001-106813000 [1000 bp] [0.08s elapsed]. I1010 11:12:32.117227 140686008715008 make_examples.py:825] Found 1 candidates in chr14:106813001-106814000 [1000 bp] [0.12s elapsed]. I1010 11:12:32.204456 140686008715008 make_examples.py:825] Found 0 candidates in chr14:106814001-106815000 [1000 bp] [0.09s elapsed]. I1010 11:12:32.953804 140686008715008 make_examples.py:825] Found 12 candidates in chr14:106815001-106816000 [1000 bp] [0.75s elapsed]. ```. The current timestamp is Oct 10 15:18:07 UTC 2018, so it's been over four hours, the cpu is still full, showing some computation is still going on. What could be possible reason please? BTW, is it possible to parallelize make_example? It seems to only use one cpu at a time at the moment. The command I used. ```. sudo docker run \. -v /home/${USER}:/home/${USER} \. gcr.io/${PROJECT_NAME}/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/make_examples \. --mode calling \. --ref ""${REF}"" \. --reads ""${BAM}"" \. --examples ""${OUTPUT_DIR}/examples.tfrecord.gz"". ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:893,performance,time,time,893,"`make_example.py` seems to stuck after a long time of running at chr14,. ```. I1010 11:12:31.993017 140686008715008 make_examples.py:825] Found 0 candidates in chr14:106812001-106813000 [1000 bp] [0.08s elapsed]. I1010 11:12:32.117227 140686008715008 make_examples.py:825] Found 1 candidates in chr14:106813001-106814000 [1000 bp] [0.12s elapsed]. I1010 11:12:32.204456 140686008715008 make_examples.py:825] Found 0 candidates in chr14:106814001-106815000 [1000 bp] [0.09s elapsed]. I1010 11:12:32.953804 140686008715008 make_examples.py:825] Found 12 candidates in chr14:106815001-106816000 [1000 bp] [0.75s elapsed]. ```. The current timestamp is Oct 10 15:18:07 UTC 2018, so it's been over four hours, the cpu is still full, showing some computation is still going on. What could be possible reason please? BTW, is it possible to parallelize make_example? It seems to only use one cpu at a time at the moment. The command I used. ```. sudo docker run \. -v /home/${USER}:/home/${USER} \. gcr.io/${PROJECT_NAME}/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/make_examples \. --mode calling \. --ref ""${REF}"" \. --reads ""${BAM}"" \. --examples ""${OUTPUT_DIR}/examples.tfrecord.gz"". ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:917,usability,command,command,917,"`make_example.py` seems to stuck after a long time of running at chr14,. ```. I1010 11:12:31.993017 140686008715008 make_examples.py:825] Found 0 candidates in chr14:106812001-106813000 [1000 bp] [0.08s elapsed]. I1010 11:12:32.117227 140686008715008 make_examples.py:825] Found 1 candidates in chr14:106813001-106814000 [1000 bp] [0.12s elapsed]. I1010 11:12:32.204456 140686008715008 make_examples.py:825] Found 0 candidates in chr14:106814001-106815000 [1000 bp] [0.09s elapsed]. I1010 11:12:32.953804 140686008715008 make_examples.py:825] Found 12 candidates in chr14:106815001-106816000 [1000 bp] [0.75s elapsed]. ```. The current timestamp is Oct 10 15:18:07 UTC 2018, so it's been over four hours, the cpu is still full, showing some computation is still going on. What could be possible reason please? BTW, is it possible to parallelize make_example? It seems to only use one cpu at a time at the moment. The command I used. ```. sudo docker run \. -v /home/${USER}:/home/${USER} \. gcr.io/${PROJECT_NAME}/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/make_examples \. --mode calling \. --ref ""${REF}"" \. --reads ""${BAM}"" \. --examples ""${OUTPUT_DIR}/examples.tfrecord.gz"". ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:968,usability,USER,USER,968,"`make_example.py` seems to stuck after a long time of running at chr14,. ```. I1010 11:12:31.993017 140686008715008 make_examples.py:825] Found 0 candidates in chr14:106812001-106813000 [1000 bp] [0.08s elapsed]. I1010 11:12:32.117227 140686008715008 make_examples.py:825] Found 1 candidates in chr14:106813001-106814000 [1000 bp] [0.12s elapsed]. I1010 11:12:32.204456 140686008715008 make_examples.py:825] Found 0 candidates in chr14:106814001-106815000 [1000 bp] [0.09s elapsed]. I1010 11:12:32.953804 140686008715008 make_examples.py:825] Found 12 candidates in chr14:106815001-106816000 [1000 bp] [0.75s elapsed]. ```. The current timestamp is Oct 10 15:18:07 UTC 2018, so it's been over four hours, the cpu is still full, showing some computation is still going on. What could be possible reason please? BTW, is it possible to parallelize make_example? It seems to only use one cpu at a time at the moment. The command I used. ```. sudo docker run \. -v /home/${USER}:/home/${USER} \. gcr.io/${PROJECT_NAME}/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/make_examples \. --mode calling \. --ref ""${REF}"" \. --reads ""${BAM}"" \. --examples ""${OUTPUT_DIR}/examples.tfrecord.gz"". ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:982,usability,USER,USER,982,"`make_example.py` seems to stuck after a long time of running at chr14,. ```. I1010 11:12:31.993017 140686008715008 make_examples.py:825] Found 0 candidates in chr14:106812001-106813000 [1000 bp] [0.08s elapsed]. I1010 11:12:32.117227 140686008715008 make_examples.py:825] Found 1 candidates in chr14:106813001-106814000 [1000 bp] [0.12s elapsed]. I1010 11:12:32.204456 140686008715008 make_examples.py:825] Found 0 candidates in chr14:106814001-106815000 [1000 bp] [0.09s elapsed]. I1010 11:12:32.953804 140686008715008 make_examples.py:825] Found 12 candidates in chr14:106815001-106816000 [1000 bp] [0.75s elapsed]. ```. The current timestamp is Oct 10 15:18:07 UTC 2018, so it's been over four hours, the cpu is still full, showing some computation is still going on. What could be possible reason please? BTW, is it possible to parallelize make_example? It seems to only use one cpu at a time at the moment. The command I used. ```. sudo docker run \. -v /home/${USER}:/home/${USER} \. gcr.io/${PROJECT_NAME}/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/make_examples \. --mode calling \. --ref ""${REF}"" \. --reads ""${BAM}"" \. --examples ""${OUTPUT_DIR}/examples.tfrecord.gz"". ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:51,performance,parallel,parallel,51,"Hi @zyxue ,. in our case study example we used GNU parallel to run make_examples. You can see here for an example:. https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-exome-case-study.md#run-make_examples",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:150,availability,Monitor,Monitoring,150,"Thanks, @pichuan. Any suggestion about the long hangs, please? My BAM size is 8.5G. I confirm the machine has been running overnight based on the GCE Monitoring tab.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:150,deployability,Monitor,Monitoring,150,"Thanks, @pichuan. Any suggestion about the long hangs, please? My BAM size is 8.5G. I confirm the machine has been running overnight based on the GCE Monitoring tab.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:150,energy efficiency,Monitor,Monitoring,150,"Thanks, @pichuan. Any suggestion about the long hangs, please? My BAM size is 8.5G. I confirm the machine has been running overnight based on the GCE Monitoring tab.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:150,reliability,Monitor,Monitoring,150,"Thanks, @pichuan. Any suggestion about the long hangs, please? My BAM size is 8.5G. I confirm the machine has been running overnight based on the GCE Monitoring tab.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:150,safety,Monitor,Monitoring,150,"Thanks, @pichuan. Any suggestion about the long hangs, please? My BAM size is 8.5G. I confirm the machine has been running overnight based on the GCE Monitoring tab.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:150,testability,Monitor,Monitoring,150,"Thanks, @pichuan. Any suggestion about the long hangs, please? My BAM size is 8.5G. I confirm the machine has been running overnight based on the GCE Monitoring tab.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:86,usability,confirm,confirm,86,"Thanks, @pichuan. Any suggestion about the long hangs, please? My BAM size is 8.5G. I confirm the machine has been running overnight based on the GCE Monitoring tab.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:155,deployability,configurat,configuration,155,"Hi @pichuan, are you sure that doc uses GPU? >For this case study, we used a 64-core non-preemptible instance with 128GiB and no GPU. and I didn't see GPU configuration in the link to the command you posted?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:40,energy efficiency,GPU,GPU,40,"Hi @pichuan, are you sure that doc uses GPU? >For this case study, we used a 64-core non-preemptible instance with 128GiB and no GPU. and I didn't see GPU configuration in the link to the command you posted?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:80,energy efficiency,core,core,80,"Hi @pichuan, are you sure that doc uses GPU? >For this case study, we used a 64-core non-preemptible instance with 128GiB and no GPU. and I didn't see GPU configuration in the link to the command you posted?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:129,energy efficiency,GPU,GPU,129,"Hi @pichuan, are you sure that doc uses GPU? >For this case study, we used a 64-core non-preemptible instance with 128GiB and no GPU. and I didn't see GPU configuration in the link to the command you posted?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:151,energy efficiency,GPU,GPU,151,"Hi @pichuan, are you sure that doc uses GPU? >For this case study, we used a 64-core non-preemptible instance with 128GiB and no GPU. and I didn't see GPU configuration in the link to the command you posted?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:155,integrability,configur,configuration,155,"Hi @pichuan, are you sure that doc uses GPU? >For this case study, we used a 64-core non-preemptible instance with 128GiB and no GPU. and I didn't see GPU configuration in the link to the command you posted?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:155,modifiability,configur,configuration,155,"Hi @pichuan, are you sure that doc uses GPU? >For this case study, we used a 64-core non-preemptible instance with 128GiB and no GPU. and I didn't see GPU configuration in the link to the command you posted?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:40,performance,GPU,GPU,40,"Hi @pichuan, are you sure that doc uses GPU? >For this case study, we used a 64-core non-preemptible instance with 128GiB and no GPU. and I didn't see GPU configuration in the link to the command you posted?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:129,performance,GPU,GPU,129,"Hi @pichuan, are you sure that doc uses GPU? >For this case study, we used a 64-core non-preemptible instance with 128GiB and no GPU. and I didn't see GPU configuration in the link to the command you posted?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:151,performance,GPU,GPU,151,"Hi @pichuan, are you sure that doc uses GPU? >For this case study, we used a 64-core non-preemptible instance with 128GiB and no GPU. and I didn't see GPU configuration in the link to the command you posted?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:155,security,configur,configuration,155,"Hi @pichuan, are you sure that doc uses GPU? >For this case study, we used a 64-core non-preemptible instance with 128GiB and no GPU. and I didn't see GPU configuration in the link to the command you posted?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:188,usability,command,command,188,"Hi @pichuan, are you sure that doc uses GPU? >For this case study, we used a 64-core non-preemptible instance with 128GiB and no GPU. and I didn't see GPU configuration in the link to the command you posted?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:125,energy efficiency,GPU,GPU,125,"Reading https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-details.md, it doesn't seem make_examples could use GPU, does it?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:125,performance,GPU,GPU,125,"Reading https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-details.md, it doesn't seem make_examples could use GPU, does it?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:88,reliability,doe,doesn,88,"Reading https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-details.md, it doesn't seem make_examples could use GPU, does it?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:130,reliability,doe,does,130,"Reading https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-details.md, it doesn't seem make_examples could use GPU, does it?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:143,deployability,updat,updates,143,"Hi @zyxue . since your questions seem to be no longer relevant to the original question, I'll close this issue. Internally we've made the code updates to address the original issue, and will come out in a next release. It also seems like the local changes that @depristo suggested works for you now. Regarding your latest questions:. (1) There are areas in the genome that do take longer to run. This is usually areas where more reads piled up. We've made a lot of speed optimization over time, but it's still certainly true that will be regions that seem to run for much longer. (2) Case study says ""no GPU"" in the sentence you quoted. Currently the case studies (WGS and WES) were both CPU only. (3) For how to run with GPU, see this previous issue: https://github.com/google/deepvariant/issues/81",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:210,deployability,releas,release,210,"Hi @zyxue . since your questions seem to be no longer relevant to the original question, I'll close this issue. Internally we've made the code updates to address the original issue, and will come out in a next release. It also seems like the local changes that @depristo suggested works for you now. Regarding your latest questions:. (1) There are areas in the genome that do take longer to run. This is usually areas where more reads piled up. We've made a lot of speed optimization over time, but it's still certainly true that will be regions that seem to run for much longer. (2) Case study says ""no GPU"" in the sentence you quoted. Currently the case studies (WGS and WES) were both CPU only. (3) For how to run with GPU, see this previous issue: https://github.com/google/deepvariant/issues/81",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:471,energy efficiency,optim,optimization,471,"Hi @zyxue . since your questions seem to be no longer relevant to the original question, I'll close this issue. Internally we've made the code updates to address the original issue, and will come out in a next release. It also seems like the local changes that @depristo suggested works for you now. Regarding your latest questions:. (1) There are areas in the genome that do take longer to run. This is usually areas where more reads piled up. We've made a lot of speed optimization over time, but it's still certainly true that will be regions that seem to run for much longer. (2) Case study says ""no GPU"" in the sentence you quoted. Currently the case studies (WGS and WES) were both CPU only. (3) For how to run with GPU, see this previous issue: https://github.com/google/deepvariant/issues/81",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:604,energy efficiency,GPU,GPU,604,"Hi @zyxue . since your questions seem to be no longer relevant to the original question, I'll close this issue. Internally we've made the code updates to address the original issue, and will come out in a next release. It also seems like the local changes that @depristo suggested works for you now. Regarding your latest questions:. (1) There are areas in the genome that do take longer to run. This is usually areas where more reads piled up. We've made a lot of speed optimization over time, but it's still certainly true that will be regions that seem to run for much longer. (2) Case study says ""no GPU"" in the sentence you quoted. Currently the case studies (WGS and WES) were both CPU only. (3) For how to run with GPU, see this previous issue: https://github.com/google/deepvariant/issues/81",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:637,energy efficiency,Current,Currently,637,"Hi @zyxue . since your questions seem to be no longer relevant to the original question, I'll close this issue. Internally we've made the code updates to address the original issue, and will come out in a next release. It also seems like the local changes that @depristo suggested works for you now. Regarding your latest questions:. (1) There are areas in the genome that do take longer to run. This is usually areas where more reads piled up. We've made a lot of speed optimization over time, but it's still certainly true that will be regions that seem to run for much longer. (2) Case study says ""no GPU"" in the sentence you quoted. Currently the case studies (WGS and WES) were both CPU only. (3) For how to run with GPU, see this previous issue: https://github.com/google/deepvariant/issues/81",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:688,energy efficiency,CPU,CPU,688,"Hi @zyxue . since your questions seem to be no longer relevant to the original question, I'll close this issue. Internally we've made the code updates to address the original issue, and will come out in a next release. It also seems like the local changes that @depristo suggested works for you now. Regarding your latest questions:. (1) There are areas in the genome that do take longer to run. This is usually areas where more reads piled up. We've made a lot of speed optimization over time, but it's still certainly true that will be regions that seem to run for much longer. (2) Case study says ""no GPU"" in the sentence you quoted. Currently the case studies (WGS and WES) were both CPU only. (3) For how to run with GPU, see this previous issue: https://github.com/google/deepvariant/issues/81",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:722,energy efficiency,GPU,GPU,722,"Hi @zyxue . since your questions seem to be no longer relevant to the original question, I'll close this issue. Internally we've made the code updates to address the original issue, and will come out in a next release. It also seems like the local changes that @depristo suggested works for you now. Regarding your latest questions:. (1) There are areas in the genome that do take longer to run. This is usually areas where more reads piled up. We've made a lot of speed optimization over time, but it's still certainly true that will be regions that seem to run for much longer. (2) Case study says ""no GPU"" in the sentence you quoted. Currently the case studies (WGS and WES) were both CPU only. (3) For how to run with GPU, see this previous issue: https://github.com/google/deepvariant/issues/81",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:471,performance,optimiz,optimization,471,"Hi @zyxue . since your questions seem to be no longer relevant to the original question, I'll close this issue. Internally we've made the code updates to address the original issue, and will come out in a next release. It also seems like the local changes that @depristo suggested works for you now. Regarding your latest questions:. (1) There are areas in the genome that do take longer to run. This is usually areas where more reads piled up. We've made a lot of speed optimization over time, but it's still certainly true that will be regions that seem to run for much longer. (2) Case study says ""no GPU"" in the sentence you quoted. Currently the case studies (WGS and WES) were both CPU only. (3) For how to run with GPU, see this previous issue: https://github.com/google/deepvariant/issues/81",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:489,performance,time,time,489,"Hi @zyxue . since your questions seem to be no longer relevant to the original question, I'll close this issue. Internally we've made the code updates to address the original issue, and will come out in a next release. It also seems like the local changes that @depristo suggested works for you now. Regarding your latest questions:. (1) There are areas in the genome that do take longer to run. This is usually areas where more reads piled up. We've made a lot of speed optimization over time, but it's still certainly true that will be regions that seem to run for much longer. (2) Case study says ""no GPU"" in the sentence you quoted. Currently the case studies (WGS and WES) were both CPU only. (3) For how to run with GPU, see this previous issue: https://github.com/google/deepvariant/issues/81",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:604,performance,GPU,GPU,604,"Hi @zyxue . since your questions seem to be no longer relevant to the original question, I'll close this issue. Internally we've made the code updates to address the original issue, and will come out in a next release. It also seems like the local changes that @depristo suggested works for you now. Regarding your latest questions:. (1) There are areas in the genome that do take longer to run. This is usually areas where more reads piled up. We've made a lot of speed optimization over time, but it's still certainly true that will be regions that seem to run for much longer. (2) Case study says ""no GPU"" in the sentence you quoted. Currently the case studies (WGS and WES) were both CPU only. (3) For how to run with GPU, see this previous issue: https://github.com/google/deepvariant/issues/81",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:688,performance,CPU,CPU,688,"Hi @zyxue . since your questions seem to be no longer relevant to the original question, I'll close this issue. Internally we've made the code updates to address the original issue, and will come out in a next release. It also seems like the local changes that @depristo suggested works for you now. Regarding your latest questions:. (1) There are areas in the genome that do take longer to run. This is usually areas where more reads piled up. We've made a lot of speed optimization over time, but it's still certainly true that will be regions that seem to run for much longer. (2) Case study says ""no GPU"" in the sentence you quoted. Currently the case studies (WGS and WES) were both CPU only. (3) For how to run with GPU, see this previous issue: https://github.com/google/deepvariant/issues/81",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:722,performance,GPU,GPU,722,"Hi @zyxue . since your questions seem to be no longer relevant to the original question, I'll close this issue. Internally we've made the code updates to address the original issue, and will come out in a next release. It also seems like the local changes that @depristo suggested works for you now. Regarding your latest questions:. (1) There are areas in the genome that do take longer to run. This is usually areas where more reads piled up. We've made a lot of speed optimization over time, but it's still certainly true that will be regions that seem to run for much longer. (2) Case study says ""no GPU"" in the sentence you quoted. Currently the case studies (WGS and WES) were both CPU only. (3) For how to run with GPU, see this previous issue: https://github.com/google/deepvariant/issues/81",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:143,safety,updat,updates,143,"Hi @zyxue . since your questions seem to be no longer relevant to the original question, I'll close this issue. Internally we've made the code updates to address the original issue, and will come out in a next release. It also seems like the local changes that @depristo suggested works for you now. Regarding your latest questions:. (1) There are areas in the genome that do take longer to run. This is usually areas where more reads piled up. We've made a lot of speed optimization over time, but it's still certainly true that will be regions that seem to run for much longer. (2) Case study says ""no GPU"" in the sentence you quoted. Currently the case studies (WGS and WES) were both CPU only. (3) For how to run with GPU, see this previous issue: https://github.com/google/deepvariant/issues/81",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:143,security,updat,updates,143,"Hi @zyxue . since your questions seem to be no longer relevant to the original question, I'll close this issue. Internally we've made the code updates to address the original issue, and will come out in a next release. It also seems like the local changes that @depristo suggested works for you now. Regarding your latest questions:. (1) There are areas in the genome that do take longer to run. This is usually areas where more reads piled up. We've made a lot of speed optimization over time, but it's still certainly true that will be regions that seem to run for much longer. (2) Case study says ""no GPU"" in the sentence you quoted. Currently the case studies (WGS and WES) were both CPU only. (3) For how to run with GPU, see this previous issue: https://github.com/google/deepvariant/issues/81",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:94,usability,close,close,94,"Hi @zyxue . since your questions seem to be no longer relevant to the original question, I'll close this issue. Internally we've made the code updates to address the original issue, and will come out in a next release. It also seems like the local changes that @depristo suggested works for you now. Regarding your latest questions:. (1) There are areas in the genome that do take longer to run. This is usually areas where more reads piled up. We've made a lot of speed optimization over time, but it's still certainly true that will be regions that seem to run for much longer. (2) Case study says ""no GPU"" in the sentence you quoted. Currently the case studies (WGS and WES) were both CPU only. (3) For how to run with GPU, see this previous issue: https://github.com/google/deepvariant/issues/81",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:121,energy efficiency,GPU,GPU,121,"OK, thanks, you could close the ticket now. I meant to ask whether `make_examples` could be parallelized with or without GPU. Your previous link and #81 only show GPU use `call_variants`. From my understanding call_variant loads the Inception model and do NN forward computation to do prediction, so it makes sense it leverages the parallel power from GPU. But make_examples just convert BAM into images. Also, hanging for > 4hr doesn't seem to be caused only by deep pileup. I am currently rerunning make_examples, and will report in a new issue if it hangs again. .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:163,energy efficiency,GPU,GPU,163,"OK, thanks, you could close the ticket now. I meant to ask whether `make_examples` could be parallelized with or without GPU. Your previous link and #81 only show GPU use `call_variants`. From my understanding call_variant loads the Inception model and do NN forward computation to do prediction, so it makes sense it leverages the parallel power from GPU. But make_examples just convert BAM into images. Also, hanging for > 4hr doesn't seem to be caused only by deep pileup. I am currently rerunning make_examples, and will report in a new issue if it hangs again. .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:223,energy efficiency,load,loads,223,"OK, thanks, you could close the ticket now. I meant to ask whether `make_examples` could be parallelized with or without GPU. Your previous link and #81 only show GPU use `call_variants`. From my understanding call_variant loads the Inception model and do NN forward computation to do prediction, so it makes sense it leverages the parallel power from GPU. But make_examples just convert BAM into images. Also, hanging for > 4hr doesn't seem to be caused only by deep pileup. I am currently rerunning make_examples, and will report in a new issue if it hangs again. .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:243,energy efficiency,model,model,243,"OK, thanks, you could close the ticket now. I meant to ask whether `make_examples` could be parallelized with or without GPU. Your previous link and #81 only show GPU use `call_variants`. From my understanding call_variant loads the Inception model and do NN forward computation to do prediction, so it makes sense it leverages the parallel power from GPU. But make_examples just convert BAM into images. Also, hanging for > 4hr doesn't seem to be caused only by deep pileup. I am currently rerunning make_examples, and will report in a new issue if it hangs again. .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:285,energy efficiency,predict,prediction,285,"OK, thanks, you could close the ticket now. I meant to ask whether `make_examples` could be parallelized with or without GPU. Your previous link and #81 only show GPU use `call_variants`. From my understanding call_variant loads the Inception model and do NN forward computation to do prediction, so it makes sense it leverages the parallel power from GPU. But make_examples just convert BAM into images. Also, hanging for > 4hr doesn't seem to be caused only by deep pileup. I am currently rerunning make_examples, and will report in a new issue if it hangs again. .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:341,energy efficiency,power,power,341,"OK, thanks, you could close the ticket now. I meant to ask whether `make_examples` could be parallelized with or without GPU. Your previous link and #81 only show GPU use `call_variants`. From my understanding call_variant loads the Inception model and do NN forward computation to do prediction, so it makes sense it leverages the parallel power from GPU. But make_examples just convert BAM into images. Also, hanging for > 4hr doesn't seem to be caused only by deep pileup. I am currently rerunning make_examples, and will report in a new issue if it hangs again. .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:352,energy efficiency,GPU,GPU,352,"OK, thanks, you could close the ticket now. I meant to ask whether `make_examples` could be parallelized with or without GPU. Your previous link and #81 only show GPU use `call_variants`. From my understanding call_variant loads the Inception model and do NN forward computation to do prediction, so it makes sense it leverages the parallel power from GPU. But make_examples just convert BAM into images. Also, hanging for > 4hr doesn't seem to be caused only by deep pileup. I am currently rerunning make_examples, and will report in a new issue if it hangs again. .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:481,energy efficiency,current,currently,481,"OK, thanks, you could close the ticket now. I meant to ask whether `make_examples` could be parallelized with or without GPU. Your previous link and #81 only show GPU use `call_variants`. From my understanding call_variant loads the Inception model and do NN forward computation to do prediction, so it makes sense it leverages the parallel power from GPU. But make_examples just convert BAM into images. Also, hanging for > 4hr doesn't seem to be caused only by deep pileup. I am currently rerunning make_examples, and will report in a new issue if it hangs again. .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:92,performance,parallel,parallelized,92,"OK, thanks, you could close the ticket now. I meant to ask whether `make_examples` could be parallelized with or without GPU. Your previous link and #81 only show GPU use `call_variants`. From my understanding call_variant loads the Inception model and do NN forward computation to do prediction, so it makes sense it leverages the parallel power from GPU. But make_examples just convert BAM into images. Also, hanging for > 4hr doesn't seem to be caused only by deep pileup. I am currently rerunning make_examples, and will report in a new issue if it hangs again. .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:121,performance,GPU,GPU,121,"OK, thanks, you could close the ticket now. I meant to ask whether `make_examples` could be parallelized with or without GPU. Your previous link and #81 only show GPU use `call_variants`. From my understanding call_variant loads the Inception model and do NN forward computation to do prediction, so it makes sense it leverages the parallel power from GPU. But make_examples just convert BAM into images. Also, hanging for > 4hr doesn't seem to be caused only by deep pileup. I am currently rerunning make_examples, and will report in a new issue if it hangs again. .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:163,performance,GPU,GPU,163,"OK, thanks, you could close the ticket now. I meant to ask whether `make_examples` could be parallelized with or without GPU. Your previous link and #81 only show GPU use `call_variants`. From my understanding call_variant loads the Inception model and do NN forward computation to do prediction, so it makes sense it leverages the parallel power from GPU. But make_examples just convert BAM into images. Also, hanging for > 4hr doesn't seem to be caused only by deep pileup. I am currently rerunning make_examples, and will report in a new issue if it hangs again. .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:223,performance,load,loads,223,"OK, thanks, you could close the ticket now. I meant to ask whether `make_examples` could be parallelized with or without GPU. Your previous link and #81 only show GPU use `call_variants`. From my understanding call_variant loads the Inception model and do NN forward computation to do prediction, so it makes sense it leverages the parallel power from GPU. But make_examples just convert BAM into images. Also, hanging for > 4hr doesn't seem to be caused only by deep pileup. I am currently rerunning make_examples, and will report in a new issue if it hangs again. .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:332,performance,parallel,parallel,332,"OK, thanks, you could close the ticket now. I meant to ask whether `make_examples` could be parallelized with or without GPU. Your previous link and #81 only show GPU use `call_variants`. From my understanding call_variant loads the Inception model and do NN forward computation to do prediction, so it makes sense it leverages the parallel power from GPU. But make_examples just convert BAM into images. Also, hanging for > 4hr doesn't seem to be caused only by deep pileup. I am currently rerunning make_examples, and will report in a new issue if it hangs again. .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:352,performance,GPU,GPU,352,"OK, thanks, you could close the ticket now. I meant to ask whether `make_examples` could be parallelized with or without GPU. Your previous link and #81 only show GPU use `call_variants`. From my understanding call_variant loads the Inception model and do NN forward computation to do prediction, so it makes sense it leverages the parallel power from GPU. But make_examples just convert BAM into images. Also, hanging for > 4hr doesn't seem to be caused only by deep pileup. I am currently rerunning make_examples, and will report in a new issue if it hangs again. .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:429,reliability,doe,doesn,429,"OK, thanks, you could close the ticket now. I meant to ask whether `make_examples` could be parallelized with or without GPU. Your previous link and #81 only show GPU use `call_variants`. From my understanding call_variant loads the Inception model and do NN forward computation to do prediction, so it makes sense it leverages the parallel power from GPU. But make_examples just convert BAM into images. Also, hanging for > 4hr doesn't seem to be caused only by deep pileup. I am currently rerunning make_examples, and will report in a new issue if it hangs again. .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:285,safety,predict,prediction,285,"OK, thanks, you could close the ticket now. I meant to ask whether `make_examples` could be parallelized with or without GPU. Your previous link and #81 only show GPU use `call_variants`. From my understanding call_variant loads the Inception model and do NN forward computation to do prediction, so it makes sense it leverages the parallel power from GPU. But make_examples just convert BAM into images. Also, hanging for > 4hr doesn't seem to be caused only by deep pileup. I am currently rerunning make_examples, and will report in a new issue if it hangs again. .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:243,security,model,model,243,"OK, thanks, you could close the ticket now. I meant to ask whether `make_examples` could be parallelized with or without GPU. Your previous link and #81 only show GPU use `call_variants`. From my understanding call_variant loads the Inception model and do NN forward computation to do prediction, so it makes sense it leverages the parallel power from GPU. But make_examples just convert BAM into images. Also, hanging for > 4hr doesn't seem to be caused only by deep pileup. I am currently rerunning make_examples, and will report in a new issue if it hangs again. .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:196,testability,understand,understanding,196,"OK, thanks, you could close the ticket now. I meant to ask whether `make_examples` could be parallelized with or without GPU. Your previous link and #81 only show GPU use `call_variants`. From my understanding call_variant loads the Inception model and do NN forward computation to do prediction, so it makes sense it leverages the parallel power from GPU. But make_examples just convert BAM into images. Also, hanging for > 4hr doesn't seem to be caused only by deep pileup. I am currently rerunning make_examples, and will report in a new issue if it hangs again. .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:22,usability,close,close,22,"OK, thanks, you could close the ticket now. I meant to ask whether `make_examples` could be parallelized with or without GPU. Your previous link and #81 only show GPU use `call_variants`. From my understanding call_variant loads the Inception model and do NN forward computation to do prediction, so it makes sense it leverages the parallel power from GPU. But make_examples just convert BAM into images. Also, hanging for > 4hr doesn't seem to be caused only by deep pileup. I am currently rerunning make_examples, and will report in a new issue if it hangs again. .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:72,energy efficiency,GPU,GPUs,72,"Ah I see. The answer to your question: `make_examples` does not utilize GPUs. So it won't be faster if you run with GPUs. And - if you have a region that hangs for a suspiciously long time, and if it's possible to share a reproducible setting that we can try, we'll be happy to use it to improve DeepVariant. Thank you!!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:116,energy efficiency,GPU,GPUs,116,"Ah I see. The answer to your question: `make_examples` does not utilize GPUs. So it won't be faster if you run with GPUs. And - if you have a region that hangs for a suspiciously long time, and if it's possible to share a reproducible setting that we can try, we'll be happy to use it to improve DeepVariant. Thank you!!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:214,interoperability,share,share,214,"Ah I see. The answer to your question: `make_examples` does not utilize GPUs. So it won't be faster if you run with GPUs. And - if you have a region that hangs for a suspiciously long time, and if it's possible to share a reproducible setting that we can try, we'll be happy to use it to improve DeepVariant. Thank you!!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:72,performance,GPU,GPUs,72,"Ah I see. The answer to your question: `make_examples` does not utilize GPUs. So it won't be faster if you run with GPUs. And - if you have a region that hangs for a suspiciously long time, and if it's possible to share a reproducible setting that we can try, we'll be happy to use it to improve DeepVariant. Thank you!!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:116,performance,GPU,GPUs,116,"Ah I see. The answer to your question: `make_examples` does not utilize GPUs. So it won't be faster if you run with GPUs. And - if you have a region that hangs for a suspiciously long time, and if it's possible to share a reproducible setting that we can try, we'll be happy to use it to improve DeepVariant. Thank you!!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:184,performance,time,time,184,"Ah I see. The answer to your question: `make_examples` does not utilize GPUs. So it won't be faster if you run with GPUs. And - if you have a region that hangs for a suspiciously long time, and if it's possible to share a reproducible setting that we can try, we'll be happy to use it to improve DeepVariant. Thank you!!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:55,reliability,doe,does,55,"Ah I see. The answer to your question: `make_examples` does not utilize GPUs. So it won't be faster if you run with GPUs. And - if you have a region that hangs for a suspiciously long time, and if it's possible to share a reproducible setting that we can try, we'll be happy to use it to improve DeepVariant. Thank you!!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:128,availability,slo,slow,128,One possibility make_examples could take long time is if reads are too long. If your reads are greater than 250 there will be a slow down.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:133,availability,down,down,133,One possibility make_examples could take long time is if reads are too long. If your reads are greater than 250 there will be a slow down.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:46,performance,time,time,46,One possibility make_examples could take long time is if reads are too long. If your reads are greater than 250 there will be a slow down.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:128,reliability,slo,slow,128,One possibility make_examples could take long time is if reads are too long. If your reads are greater than 250 there will be a slow down.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:191,energy efficiency,GPU,GPU,191,"Hi @zyxue ,. my teammate @cmclean pointed out that I might have confused you in my earlier comment ( https://github.com/google/deepvariant/issues/99#issuecomment-428622073 ) because I typed ""GPU"" parallel instead of ""GNU"" parallel. Sorry about that. :-/ I corrected it.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:191,performance,GPU,GPU,191,"Hi @zyxue ,. my teammate @cmclean pointed out that I might have confused you in my earlier comment ( https://github.com/google/deepvariant/issues/99#issuecomment-428622073 ) because I typed ""GPU"" parallel instead of ""GNU"" parallel. Sorry about that. :-/ I corrected it.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:196,performance,parallel,parallel,196,"Hi @zyxue ,. my teammate @cmclean pointed out that I might have confused you in my earlier comment ( https://github.com/google/deepvariant/issues/99#issuecomment-428622073 ) because I typed ""GPU"" parallel instead of ""GNU"" parallel. Sorry about that. :-/ I corrected it.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:222,performance,parallel,parallel,222,"Hi @zyxue ,. my teammate @cmclean pointed out that I might have confused you in my earlier comment ( https://github.com/google/deepvariant/issues/99#issuecomment-428622073 ) because I typed ""GPU"" parallel instead of ""GNU"" parallel. Sorry about that. :-/ I corrected it.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:16,security,team,teammate,16,"Hi @zyxue ,. my teammate @cmclean pointed out that I might have confused you in my earlier comment ( https://github.com/google/deepvariant/issues/99#issuecomment-428622073 ) because I typed ""GPU"" parallel instead of ""GNU"" parallel. Sorry about that. :-/ I corrected it.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:72,energy efficiency,adapt,adapting,72,"Ahh, I see. Thank you @pichuan, now it makes total sense! I will rerun, adapting the command from https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-exome-case-study.md#run-make_examples",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:72,integrability,adapt,adapting,72,"Ahh, I see. Thank you @pichuan, now it makes total sense! I will rerun, adapting the command from https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-exome-case-study.md#run-make_examples",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:72,interoperability,adapt,adapting,72,"Ahh, I see. Thank you @pichuan, now it makes total sense! I will rerun, adapting the command from https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-exome-case-study.md#run-make_examples",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:72,modifiability,adapt,adapting,72,"Ahh, I see. Thank you @pichuan, now it makes total sense! I will rerun, adapting the command from https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-exome-case-study.md#run-make_examples",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:85,usability,command,command,85,"Ahh, I see. Thank you @pichuan, now it makes total sense! I will rerun, adapting the command from https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-exome-case-study.md#run-make_examples",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:902,availability,error,errors,902,"@zyxue I did an analysis a while ago, that posted at the following link:. [Generalized performance analysis between the versions](https://github.com/google/deepvariant/issues/50). The thing that dominated the processing at that time was the aligner, and would require more surgery to determine possibilities for optimization even though it got recently updated with the [FastPassAligner](https://github.com/google/deepvariant/blob/r0.7/deepvariant/realigner/fast_pass_aligner.cc) - which would require re-profiling. Basically a bunch of profiling tools would need to be built for you to then run, in order to determine for your scenario what the best optimization path would be. You probably noticed the following lines in [make_examples.py](https://github.com/google/deepvariant/blob/r0.7/deepvariant/make_examples.py#L1150-L1153) regarding the core restriction:. ```Python. if options.n_cores != 1:. errors.log_and_raise(. 'Currently only supports n_cores == 1 but got {}.'.format(. options.n_cores), errors.CommandLineError). ```. Though there are possibilities around that like @pichuan mentioned. ~p.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:1003,availability,error,errors,1003,"@zyxue I did an analysis a while ago, that posted at the following link:. [Generalized performance analysis between the versions](https://github.com/google/deepvariant/issues/50). The thing that dominated the processing at that time was the aligner, and would require more surgery to determine possibilities for optimization even though it got recently updated with the [FastPassAligner](https://github.com/google/deepvariant/blob/r0.7/deepvariant/realigner/fast_pass_aligner.cc) - which would require re-profiling. Basically a bunch of profiling tools would need to be built for you to then run, in order to determine for your scenario what the best optimization path would be. You probably noticed the following lines in [make_examples.py](https://github.com/google/deepvariant/blob/r0.7/deepvariant/make_examples.py#L1150-L1153) regarding the core restriction:. ```Python. if options.n_cores != 1:. errors.log_and_raise(. 'Currently only supports n_cores == 1 but got {}.'.format(. options.n_cores), errors.CommandLineError). ```. Though there are possibilities around that like @pichuan mentioned. ~p.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:120,deployability,version,versions,120,"@zyxue I did an analysis a while ago, that posted at the following link:. [Generalized performance analysis between the versions](https://github.com/google/deepvariant/issues/50). The thing that dominated the processing at that time was the aligner, and would require more surgery to determine possibilities for optimization even though it got recently updated with the [FastPassAligner](https://github.com/google/deepvariant/blob/r0.7/deepvariant/realigner/fast_pass_aligner.cc) - which would require re-profiling. Basically a bunch of profiling tools would need to be built for you to then run, in order to determine for your scenario what the best optimization path would be. You probably noticed the following lines in [make_examples.py](https://github.com/google/deepvariant/blob/r0.7/deepvariant/make_examples.py#L1150-L1153) regarding the core restriction:. ```Python. if options.n_cores != 1:. errors.log_and_raise(. 'Currently only supports n_cores == 1 but got {}.'.format(. options.n_cores), errors.CommandLineError). ```. Though there are possibilities around that like @pichuan mentioned. ~p.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:353,deployability,updat,updated,353,"@zyxue I did an analysis a while ago, that posted at the following link:. [Generalized performance analysis between the versions](https://github.com/google/deepvariant/issues/50). The thing that dominated the processing at that time was the aligner, and would require more surgery to determine possibilities for optimization even though it got recently updated with the [FastPassAligner](https://github.com/google/deepvariant/blob/r0.7/deepvariant/realigner/fast_pass_aligner.cc) - which would require re-profiling. Basically a bunch of profiling tools would need to be built for you to then run, in order to determine for your scenario what the best optimization path would be. You probably noticed the following lines in [make_examples.py](https://github.com/google/deepvariant/blob/r0.7/deepvariant/make_examples.py#L1150-L1153) regarding the core restriction:. ```Python. if options.n_cores != 1:. errors.log_and_raise(. 'Currently only supports n_cores == 1 but got {}.'.format(. options.n_cores), errors.CommandLineError). ```. Though there are possibilities around that like @pichuan mentioned. ~p.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:312,energy efficiency,optim,optimization,312,"@zyxue I did an analysis a while ago, that posted at the following link:. [Generalized performance analysis between the versions](https://github.com/google/deepvariant/issues/50). The thing that dominated the processing at that time was the aligner, and would require more surgery to determine possibilities for optimization even though it got recently updated with the [FastPassAligner](https://github.com/google/deepvariant/blob/r0.7/deepvariant/realigner/fast_pass_aligner.cc) - which would require re-profiling. Basically a bunch of profiling tools would need to be built for you to then run, in order to determine for your scenario what the best optimization path would be. You probably noticed the following lines in [make_examples.py](https://github.com/google/deepvariant/blob/r0.7/deepvariant/make_examples.py#L1150-L1153) regarding the core restriction:. ```Python. if options.n_cores != 1:. errors.log_and_raise(. 'Currently only supports n_cores == 1 but got {}.'.format(. options.n_cores), errors.CommandLineError). ```. Though there are possibilities around that like @pichuan mentioned. ~p.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:505,energy efficiency,profil,profiling,505,"@zyxue I did an analysis a while ago, that posted at the following link:. [Generalized performance analysis between the versions](https://github.com/google/deepvariant/issues/50). The thing that dominated the processing at that time was the aligner, and would require more surgery to determine possibilities for optimization even though it got recently updated with the [FastPassAligner](https://github.com/google/deepvariant/blob/r0.7/deepvariant/realigner/fast_pass_aligner.cc) - which would require re-profiling. Basically a bunch of profiling tools would need to be built for you to then run, in order to determine for your scenario what the best optimization path would be. You probably noticed the following lines in [make_examples.py](https://github.com/google/deepvariant/blob/r0.7/deepvariant/make_examples.py#L1150-L1153) regarding the core restriction:. ```Python. if options.n_cores != 1:. errors.log_and_raise(. 'Currently only supports n_cores == 1 but got {}.'.format(. options.n_cores), errors.CommandLineError). ```. Though there are possibilities around that like @pichuan mentioned. ~p.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:537,energy efficiency,profil,profiling,537,"@zyxue I did an analysis a while ago, that posted at the following link:. [Generalized performance analysis between the versions](https://github.com/google/deepvariant/issues/50). The thing that dominated the processing at that time was the aligner, and would require more surgery to determine possibilities for optimization even though it got recently updated with the [FastPassAligner](https://github.com/google/deepvariant/blob/r0.7/deepvariant/realigner/fast_pass_aligner.cc) - which would require re-profiling. Basically a bunch of profiling tools would need to be built for you to then run, in order to determine for your scenario what the best optimization path would be. You probably noticed the following lines in [make_examples.py](https://github.com/google/deepvariant/blob/r0.7/deepvariant/make_examples.py#L1150-L1153) regarding the core restriction:. ```Python. if options.n_cores != 1:. errors.log_and_raise(. 'Currently only supports n_cores == 1 but got {}.'.format(. options.n_cores), errors.CommandLineError). ```. Though there are possibilities around that like @pichuan mentioned. ~p.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:651,energy efficiency,optim,optimization,651,"@zyxue I did an analysis a while ago, that posted at the following link:. [Generalized performance analysis between the versions](https://github.com/google/deepvariant/issues/50). The thing that dominated the processing at that time was the aligner, and would require more surgery to determine possibilities for optimization even though it got recently updated with the [FastPassAligner](https://github.com/google/deepvariant/blob/r0.7/deepvariant/realigner/fast_pass_aligner.cc) - which would require re-profiling. Basically a bunch of profiling tools would need to be built for you to then run, in order to determine for your scenario what the best optimization path would be. You probably noticed the following lines in [make_examples.py](https://github.com/google/deepvariant/blob/r0.7/deepvariant/make_examples.py#L1150-L1153) regarding the core restriction:. ```Python. if options.n_cores != 1:. errors.log_and_raise(. 'Currently only supports n_cores == 1 but got {}.'.format(. options.n_cores), errors.CommandLineError). ```. Though there are possibilities around that like @pichuan mentioned. ~p.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:846,energy efficiency,core,core,846,"@zyxue I did an analysis a while ago, that posted at the following link:. [Generalized performance analysis between the versions](https://github.com/google/deepvariant/issues/50). The thing that dominated the processing at that time was the aligner, and would require more surgery to determine possibilities for optimization even though it got recently updated with the [FastPassAligner](https://github.com/google/deepvariant/blob/r0.7/deepvariant/realigner/fast_pass_aligner.cc) - which would require re-profiling. Basically a bunch of profiling tools would need to be built for you to then run, in order to determine for your scenario what the best optimization path would be. You probably noticed the following lines in [make_examples.py](https://github.com/google/deepvariant/blob/r0.7/deepvariant/make_examples.py#L1150-L1153) regarding the core restriction:. ```Python. if options.n_cores != 1:. errors.log_and_raise(. 'Currently only supports n_cores == 1 but got {}.'.format(. options.n_cores), errors.CommandLineError). ```. Though there are possibilities around that like @pichuan mentioned. ~p.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:926,energy efficiency,Current,Currently,926,"@zyxue I did an analysis a while ago, that posted at the following link:. [Generalized performance analysis between the versions](https://github.com/google/deepvariant/issues/50). The thing that dominated the processing at that time was the aligner, and would require more surgery to determine possibilities for optimization even though it got recently updated with the [FastPassAligner](https://github.com/google/deepvariant/blob/r0.7/deepvariant/realigner/fast_pass_aligner.cc) - which would require re-profiling. Basically a bunch of profiling tools would need to be built for you to then run, in order to determine for your scenario what the best optimization path would be. You probably noticed the following lines in [make_examples.py](https://github.com/google/deepvariant/blob/r0.7/deepvariant/make_examples.py#L1150-L1153) regarding the core restriction:. ```Python. if options.n_cores != 1:. errors.log_and_raise(. 'Currently only supports n_cores == 1 but got {}.'.format(. options.n_cores), errors.CommandLineError). ```. Though there are possibilities around that like @pichuan mentioned. ~p.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:120,integrability,version,versions,120,"@zyxue I did an analysis a while ago, that posted at the following link:. [Generalized performance analysis between the versions](https://github.com/google/deepvariant/issues/50). The thing that dominated the processing at that time was the aligner, and would require more surgery to determine possibilities for optimization even though it got recently updated with the [FastPassAligner](https://github.com/google/deepvariant/blob/r0.7/deepvariant/realigner/fast_pass_aligner.cc) - which would require re-profiling. Basically a bunch of profiling tools would need to be built for you to then run, in order to determine for your scenario what the best optimization path would be. You probably noticed the following lines in [make_examples.py](https://github.com/google/deepvariant/blob/r0.7/deepvariant/make_examples.py#L1150-L1153) regarding the core restriction:. ```Python. if options.n_cores != 1:. errors.log_and_raise(. 'Currently only supports n_cores == 1 but got {}.'.format(. options.n_cores), errors.CommandLineError). ```. Though there are possibilities around that like @pichuan mentioned. ~p.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:976,interoperability,format,format,976,"@zyxue I did an analysis a while ago, that posted at the following link:. [Generalized performance analysis between the versions](https://github.com/google/deepvariant/issues/50). The thing that dominated the processing at that time was the aligner, and would require more surgery to determine possibilities for optimization even though it got recently updated with the [FastPassAligner](https://github.com/google/deepvariant/blob/r0.7/deepvariant/realigner/fast_pass_aligner.cc) - which would require re-profiling. Basically a bunch of profiling tools would need to be built for you to then run, in order to determine for your scenario what the best optimization path would be. You probably noticed the following lines in [make_examples.py](https://github.com/google/deepvariant/blob/r0.7/deepvariant/make_examples.py#L1150-L1153) regarding the core restriction:. ```Python. if options.n_cores != 1:. errors.log_and_raise(. 'Currently only supports n_cores == 1 but got {}.'.format(. options.n_cores), errors.CommandLineError). ```. Though there are possibilities around that like @pichuan mentioned. ~p.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:120,modifiability,version,versions,120,"@zyxue I did an analysis a while ago, that posted at the following link:. [Generalized performance analysis between the versions](https://github.com/google/deepvariant/issues/50). The thing that dominated the processing at that time was the aligner, and would require more surgery to determine possibilities for optimization even though it got recently updated with the [FastPassAligner](https://github.com/google/deepvariant/blob/r0.7/deepvariant/realigner/fast_pass_aligner.cc) - which would require re-profiling. Basically a bunch of profiling tools would need to be built for you to then run, in order to determine for your scenario what the best optimization path would be. You probably noticed the following lines in [make_examples.py](https://github.com/google/deepvariant/blob/r0.7/deepvariant/make_examples.py#L1150-L1153) regarding the core restriction:. ```Python. if options.n_cores != 1:. errors.log_and_raise(. 'Currently only supports n_cores == 1 but got {}.'.format(. options.n_cores), errors.CommandLineError). ```. Though there are possibilities around that like @pichuan mentioned. ~p.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:628,modifiability,scenario,scenario,628,"@zyxue I did an analysis a while ago, that posted at the following link:. [Generalized performance analysis between the versions](https://github.com/google/deepvariant/issues/50). The thing that dominated the processing at that time was the aligner, and would require more surgery to determine possibilities for optimization even though it got recently updated with the [FastPassAligner](https://github.com/google/deepvariant/blob/r0.7/deepvariant/realigner/fast_pass_aligner.cc) - which would require re-profiling. Basically a bunch of profiling tools would need to be built for you to then run, in order to determine for your scenario what the best optimization path would be. You probably noticed the following lines in [make_examples.py](https://github.com/google/deepvariant/blob/r0.7/deepvariant/make_examples.py#L1150-L1153) regarding the core restriction:. ```Python. if options.n_cores != 1:. errors.log_and_raise(. 'Currently only supports n_cores == 1 but got {}.'.format(. options.n_cores), errors.CommandLineError). ```. Though there are possibilities around that like @pichuan mentioned. ~p.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:87,performance,performance analys,performance analysis,87,"@zyxue I did an analysis a while ago, that posted at the following link:. [Generalized performance analysis between the versions](https://github.com/google/deepvariant/issues/50). The thing that dominated the processing at that time was the aligner, and would require more surgery to determine possibilities for optimization even though it got recently updated with the [FastPassAligner](https://github.com/google/deepvariant/blob/r0.7/deepvariant/realigner/fast_pass_aligner.cc) - which would require re-profiling. Basically a bunch of profiling tools would need to be built for you to then run, in order to determine for your scenario what the best optimization path would be. You probably noticed the following lines in [make_examples.py](https://github.com/google/deepvariant/blob/r0.7/deepvariant/make_examples.py#L1150-L1153) regarding the core restriction:. ```Python. if options.n_cores != 1:. errors.log_and_raise(. 'Currently only supports n_cores == 1 but got {}.'.format(. options.n_cores), errors.CommandLineError). ```. Though there are possibilities around that like @pichuan mentioned. ~p.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:228,performance,time,time,228,"@zyxue I did an analysis a while ago, that posted at the following link:. [Generalized performance analysis between the versions](https://github.com/google/deepvariant/issues/50). The thing that dominated the processing at that time was the aligner, and would require more surgery to determine possibilities for optimization even though it got recently updated with the [FastPassAligner](https://github.com/google/deepvariant/blob/r0.7/deepvariant/realigner/fast_pass_aligner.cc) - which would require re-profiling. Basically a bunch of profiling tools would need to be built for you to then run, in order to determine for your scenario what the best optimization path would be. You probably noticed the following lines in [make_examples.py](https://github.com/google/deepvariant/blob/r0.7/deepvariant/make_examples.py#L1150-L1153) regarding the core restriction:. ```Python. if options.n_cores != 1:. errors.log_and_raise(. 'Currently only supports n_cores == 1 but got {}.'.format(. options.n_cores), errors.CommandLineError). ```. Though there are possibilities around that like @pichuan mentioned. ~p.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:312,performance,optimiz,optimization,312,"@zyxue I did an analysis a while ago, that posted at the following link:. [Generalized performance analysis between the versions](https://github.com/google/deepvariant/issues/50). The thing that dominated the processing at that time was the aligner, and would require more surgery to determine possibilities for optimization even though it got recently updated with the [FastPassAligner](https://github.com/google/deepvariant/blob/r0.7/deepvariant/realigner/fast_pass_aligner.cc) - which would require re-profiling. Basically a bunch of profiling tools would need to be built for you to then run, in order to determine for your scenario what the best optimization path would be. You probably noticed the following lines in [make_examples.py](https://github.com/google/deepvariant/blob/r0.7/deepvariant/make_examples.py#L1150-L1153) regarding the core restriction:. ```Python. if options.n_cores != 1:. errors.log_and_raise(. 'Currently only supports n_cores == 1 but got {}.'.format(. options.n_cores), errors.CommandLineError). ```. Though there are possibilities around that like @pichuan mentioned. ~p.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:505,performance,profil,profiling,505,"@zyxue I did an analysis a while ago, that posted at the following link:. [Generalized performance analysis between the versions](https://github.com/google/deepvariant/issues/50). The thing that dominated the processing at that time was the aligner, and would require more surgery to determine possibilities for optimization even though it got recently updated with the [FastPassAligner](https://github.com/google/deepvariant/blob/r0.7/deepvariant/realigner/fast_pass_aligner.cc) - which would require re-profiling. Basically a bunch of profiling tools would need to be built for you to then run, in order to determine for your scenario what the best optimization path would be. You probably noticed the following lines in [make_examples.py](https://github.com/google/deepvariant/blob/r0.7/deepvariant/make_examples.py#L1150-L1153) regarding the core restriction:. ```Python. if options.n_cores != 1:. errors.log_and_raise(. 'Currently only supports n_cores == 1 but got {}.'.format(. options.n_cores), errors.CommandLineError). ```. Though there are possibilities around that like @pichuan mentioned. ~p.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:537,performance,profil,profiling,537,"@zyxue I did an analysis a while ago, that posted at the following link:. [Generalized performance analysis between the versions](https://github.com/google/deepvariant/issues/50). The thing that dominated the processing at that time was the aligner, and would require more surgery to determine possibilities for optimization even though it got recently updated with the [FastPassAligner](https://github.com/google/deepvariant/blob/r0.7/deepvariant/realigner/fast_pass_aligner.cc) - which would require re-profiling. Basically a bunch of profiling tools would need to be built for you to then run, in order to determine for your scenario what the best optimization path would be. You probably noticed the following lines in [make_examples.py](https://github.com/google/deepvariant/blob/r0.7/deepvariant/make_examples.py#L1150-L1153) regarding the core restriction:. ```Python. if options.n_cores != 1:. errors.log_and_raise(. 'Currently only supports n_cores == 1 but got {}.'.format(. options.n_cores), errors.CommandLineError). ```. Though there are possibilities around that like @pichuan mentioned. ~p.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:651,performance,optimiz,optimization,651,"@zyxue I did an analysis a while ago, that posted at the following link:. [Generalized performance analysis between the versions](https://github.com/google/deepvariant/issues/50). The thing that dominated the processing at that time was the aligner, and would require more surgery to determine possibilities for optimization even though it got recently updated with the [FastPassAligner](https://github.com/google/deepvariant/blob/r0.7/deepvariant/realigner/fast_pass_aligner.cc) - which would require re-profiling. Basically a bunch of profiling tools would need to be built for you to then run, in order to determine for your scenario what the best optimization path would be. You probably noticed the following lines in [make_examples.py](https://github.com/google/deepvariant/blob/r0.7/deepvariant/make_examples.py#L1150-L1153) regarding the core restriction:. ```Python. if options.n_cores != 1:. errors.log_and_raise(. 'Currently only supports n_cores == 1 but got {}.'.format(. options.n_cores), errors.CommandLineError). ```. Though there are possibilities around that like @pichuan mentioned. ~p.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:902,performance,error,errors,902,"@zyxue I did an analysis a while ago, that posted at the following link:. [Generalized performance analysis between the versions](https://github.com/google/deepvariant/issues/50). The thing that dominated the processing at that time was the aligner, and would require more surgery to determine possibilities for optimization even though it got recently updated with the [FastPassAligner](https://github.com/google/deepvariant/blob/r0.7/deepvariant/realigner/fast_pass_aligner.cc) - which would require re-profiling. Basically a bunch of profiling tools would need to be built for you to then run, in order to determine for your scenario what the best optimization path would be. You probably noticed the following lines in [make_examples.py](https://github.com/google/deepvariant/blob/r0.7/deepvariant/make_examples.py#L1150-L1153) regarding the core restriction:. ```Python. if options.n_cores != 1:. errors.log_and_raise(. 'Currently only supports n_cores == 1 but got {}.'.format(. options.n_cores), errors.CommandLineError). ```. Though there are possibilities around that like @pichuan mentioned. ~p.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:1003,performance,error,errors,1003,"@zyxue I did an analysis a while ago, that posted at the following link:. [Generalized performance analysis between the versions](https://github.com/google/deepvariant/issues/50). The thing that dominated the processing at that time was the aligner, and would require more surgery to determine possibilities for optimization even though it got recently updated with the [FastPassAligner](https://github.com/google/deepvariant/blob/r0.7/deepvariant/realigner/fast_pass_aligner.cc) - which would require re-profiling. Basically a bunch of profiling tools would need to be built for you to then run, in order to determine for your scenario what the best optimization path would be. You probably noticed the following lines in [make_examples.py](https://github.com/google/deepvariant/blob/r0.7/deepvariant/make_examples.py#L1150-L1153) regarding the core restriction:. ```Python. if options.n_cores != 1:. errors.log_and_raise(. 'Currently only supports n_cores == 1 but got {}.'.format(. options.n_cores), errors.CommandLineError). ```. Though there are possibilities around that like @pichuan mentioned. ~p.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:353,safety,updat,updated,353,"@zyxue I did an analysis a while ago, that posted at the following link:. [Generalized performance analysis between the versions](https://github.com/google/deepvariant/issues/50). The thing that dominated the processing at that time was the aligner, and would require more surgery to determine possibilities for optimization even though it got recently updated with the [FastPassAligner](https://github.com/google/deepvariant/blob/r0.7/deepvariant/realigner/fast_pass_aligner.cc) - which would require re-profiling. Basically a bunch of profiling tools would need to be built for you to then run, in order to determine for your scenario what the best optimization path would be. You probably noticed the following lines in [make_examples.py](https://github.com/google/deepvariant/blob/r0.7/deepvariant/make_examples.py#L1150-L1153) regarding the core restriction:. ```Python. if options.n_cores != 1:. errors.log_and_raise(. 'Currently only supports n_cores == 1 but got {}.'.format(. options.n_cores), errors.CommandLineError). ```. Though there are possibilities around that like @pichuan mentioned. ~p.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:902,safety,error,errors,902,"@zyxue I did an analysis a while ago, that posted at the following link:. [Generalized performance analysis between the versions](https://github.com/google/deepvariant/issues/50). The thing that dominated the processing at that time was the aligner, and would require more surgery to determine possibilities for optimization even though it got recently updated with the [FastPassAligner](https://github.com/google/deepvariant/blob/r0.7/deepvariant/realigner/fast_pass_aligner.cc) - which would require re-profiling. Basically a bunch of profiling tools would need to be built for you to then run, in order to determine for your scenario what the best optimization path would be. You probably noticed the following lines in [make_examples.py](https://github.com/google/deepvariant/blob/r0.7/deepvariant/make_examples.py#L1150-L1153) regarding the core restriction:. ```Python. if options.n_cores != 1:. errors.log_and_raise(. 'Currently only supports n_cores == 1 but got {}.'.format(. options.n_cores), errors.CommandLineError). ```. Though there are possibilities around that like @pichuan mentioned. ~p.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:1003,safety,error,errors,1003,"@zyxue I did an analysis a while ago, that posted at the following link:. [Generalized performance analysis between the versions](https://github.com/google/deepvariant/issues/50). The thing that dominated the processing at that time was the aligner, and would require more surgery to determine possibilities for optimization even though it got recently updated with the [FastPassAligner](https://github.com/google/deepvariant/blob/r0.7/deepvariant/realigner/fast_pass_aligner.cc) - which would require re-profiling. Basically a bunch of profiling tools would need to be built for you to then run, in order to determine for your scenario what the best optimization path would be. You probably noticed the following lines in [make_examples.py](https://github.com/google/deepvariant/blob/r0.7/deepvariant/make_examples.py#L1150-L1153) regarding the core restriction:. ```Python. if options.n_cores != 1:. errors.log_and_raise(. 'Currently only supports n_cores == 1 but got {}.'.format(. options.n_cores), errors.CommandLineError). ```. Though there are possibilities around that like @pichuan mentioned. ~p.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:353,security,updat,updated,353,"@zyxue I did an analysis a while ago, that posted at the following link:. [Generalized performance analysis between the versions](https://github.com/google/deepvariant/issues/50). The thing that dominated the processing at that time was the aligner, and would require more surgery to determine possibilities for optimization even though it got recently updated with the [FastPassAligner](https://github.com/google/deepvariant/blob/r0.7/deepvariant/realigner/fast_pass_aligner.cc) - which would require re-profiling. Basically a bunch of profiling tools would need to be built for you to then run, in order to determine for your scenario what the best optimization path would be. You probably noticed the following lines in [make_examples.py](https://github.com/google/deepvariant/blob/r0.7/deepvariant/make_examples.py#L1150-L1153) regarding the core restriction:. ```Python. if options.n_cores != 1:. errors.log_and_raise(. 'Currently only supports n_cores == 1 but got {}.'.format(. options.n_cores), errors.CommandLineError). ```. Though there are possibilities around that like @pichuan mentioned. ~p.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:87,usability,perform,performance,87,"@zyxue I did an analysis a while ago, that posted at the following link:. [Generalized performance analysis between the versions](https://github.com/google/deepvariant/issues/50). The thing that dominated the processing at that time was the aligner, and would require more surgery to determine possibilities for optimization even though it got recently updated with the [FastPassAligner](https://github.com/google/deepvariant/blob/r0.7/deepvariant/realigner/fast_pass_aligner.cc) - which would require re-profiling. Basically a bunch of profiling tools would need to be built for you to then run, in order to determine for your scenario what the best optimization path would be. You probably noticed the following lines in [make_examples.py](https://github.com/google/deepvariant/blob/r0.7/deepvariant/make_examples.py#L1150-L1153) regarding the core restriction:. ```Python. if options.n_cores != 1:. errors.log_and_raise(. 'Currently only supports n_cores == 1 but got {}.'.format(. options.n_cores), errors.CommandLineError). ```. Though there are possibilities around that like @pichuan mentioned. ~p.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:547,usability,tool,tools,547,"@zyxue I did an analysis a while ago, that posted at the following link:. [Generalized performance analysis between the versions](https://github.com/google/deepvariant/issues/50). The thing that dominated the processing at that time was the aligner, and would require more surgery to determine possibilities for optimization even though it got recently updated with the [FastPassAligner](https://github.com/google/deepvariant/blob/r0.7/deepvariant/realigner/fast_pass_aligner.cc) - which would require re-profiling. Basically a bunch of profiling tools would need to be built for you to then run, in order to determine for your scenario what the best optimization path would be. You probably noticed the following lines in [make_examples.py](https://github.com/google/deepvariant/blob/r0.7/deepvariant/make_examples.py#L1150-L1153) regarding the core restriction:. ```Python. if options.n_cores != 1:. errors.log_and_raise(. 'Currently only supports n_cores == 1 but got {}.'.format(. options.n_cores), errors.CommandLineError). ```. Though there are possibilities around that like @pichuan mentioned. ~p.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:902,usability,error,errors,902,"@zyxue I did an analysis a while ago, that posted at the following link:. [Generalized performance analysis between the versions](https://github.com/google/deepvariant/issues/50). The thing that dominated the processing at that time was the aligner, and would require more surgery to determine possibilities for optimization even though it got recently updated with the [FastPassAligner](https://github.com/google/deepvariant/blob/r0.7/deepvariant/realigner/fast_pass_aligner.cc) - which would require re-profiling. Basically a bunch of profiling tools would need to be built for you to then run, in order to determine for your scenario what the best optimization path would be. You probably noticed the following lines in [make_examples.py](https://github.com/google/deepvariant/blob/r0.7/deepvariant/make_examples.py#L1150-L1153) regarding the core restriction:. ```Python. if options.n_cores != 1:. errors.log_and_raise(. 'Currently only supports n_cores == 1 but got {}.'.format(. options.n_cores), errors.CommandLineError). ```. Though there are possibilities around that like @pichuan mentioned. ~p.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:941,usability,support,supports,941,"@zyxue I did an analysis a while ago, that posted at the following link:. [Generalized performance analysis between the versions](https://github.com/google/deepvariant/issues/50). The thing that dominated the processing at that time was the aligner, and would require more surgery to determine possibilities for optimization even though it got recently updated with the [FastPassAligner](https://github.com/google/deepvariant/blob/r0.7/deepvariant/realigner/fast_pass_aligner.cc) - which would require re-profiling. Basically a bunch of profiling tools would need to be built for you to then run, in order to determine for your scenario what the best optimization path would be. You probably noticed the following lines in [make_examples.py](https://github.com/google/deepvariant/blob/r0.7/deepvariant/make_examples.py#L1150-L1153) regarding the core restriction:. ```Python. if options.n_cores != 1:. errors.log_and_raise(. 'Currently only supports n_cores == 1 but got {}.'.format(. options.n_cores), errors.CommandLineError). ```. Though there are possibilities around that like @pichuan mentioned. ~p.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:1003,usability,error,errors,1003,"@zyxue I did an analysis a while ago, that posted at the following link:. [Generalized performance analysis between the versions](https://github.com/google/deepvariant/issues/50). The thing that dominated the processing at that time was the aligner, and would require more surgery to determine possibilities for optimization even though it got recently updated with the [FastPassAligner](https://github.com/google/deepvariant/blob/r0.7/deepvariant/realigner/fast_pass_aligner.cc) - which would require re-profiling. Basically a bunch of profiling tools would need to be built for you to then run, in order to determine for your scenario what the best optimization path would be. You probably noticed the following lines in [make_examples.py](https://github.com/google/deepvariant/blob/r0.7/deepvariant/make_examples.py#L1150-L1153) regarding the core restriction:. ```Python. if options.n_cores != 1:. errors.log_and_raise(. 'Currently only supports n_cores == 1 but got {}.'.format(. options.n_cores), errors.CommandLineError). ```. Though there are possibilities around that like @pichuan mentioned. ~p.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:1010,usability,Command,CommandLineError,1010,"@zyxue I did an analysis a while ago, that posted at the following link:. [Generalized performance analysis between the versions](https://github.com/google/deepvariant/issues/50). The thing that dominated the processing at that time was the aligner, and would require more surgery to determine possibilities for optimization even though it got recently updated with the [FastPassAligner](https://github.com/google/deepvariant/blob/r0.7/deepvariant/realigner/fast_pass_aligner.cc) - which would require re-profiling. Basically a bunch of profiling tools would need to be built for you to then run, in order to determine for your scenario what the best optimization path would be. You probably noticed the following lines in [make_examples.py](https://github.com/google/deepvariant/blob/r0.7/deepvariant/make_examples.py#L1150-L1153) regarding the core restriction:. ```Python. if options.n_cores != 1:. errors.log_and_raise(. 'Currently only supports n_cores == 1 but got {}.'.format(. options.n_cores), errors.CommandLineError). ```. Though there are possibilities around that like @pichuan mentioned. ~p.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:369,deployability,contain,containers,369,"I have a couple of questions about https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-exome-case-study.md#run-make_examples,. 1. how is `examples.tfrecord@${N_SHARDS}.gz` evaluated to become `examples.tfrecord-00006-of-00008.gz`. 1. what does `--task {}` mean? Could you please explain briefly how this command parallelize the processing? N_SHARDS docker containers have been started, and it seems each 1kbp region is sent to a different processor based on log, but I don't quite get it how each container knows which 1kbp region to parse.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:471,deployability,log,log,471,"I have a couple of questions about https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-exome-case-study.md#run-make_examples,. 1. how is `examples.tfrecord@${N_SHARDS}.gz` evaluated to become `examples.tfrecord-00006-of-00008.gz`. 1. what does `--task {}` mean? Could you please explain briefly how this command parallelize the processing? N_SHARDS docker containers have been started, and it seems each 1kbp region is sent to a different processor based on log, but I don't quite get it how each container knows which 1kbp region to parse.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:510,deployability,contain,container,510,"I have a couple of questions about https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-exome-case-study.md#run-make_examples,. 1. how is `examples.tfrecord@${N_SHARDS}.gz` evaluated to become `examples.tfrecord-00006-of-00008.gz`. 1. what does `--task {}` mean? Could you please explain briefly how this command parallelize the processing? N_SHARDS docker containers have been started, and it seems each 1kbp region is sent to a different processor based on log, but I don't quite get it how each container knows which 1kbp region to parse.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:9,integrability,coupl,couple,9,"I have a couple of questions about https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-exome-case-study.md#run-make_examples,. 1. how is `examples.tfrecord@${N_SHARDS}.gz` evaluated to become `examples.tfrecord-00006-of-00008.gz`. 1. what does `--task {}` mean? Could you please explain briefly how this command parallelize the processing? N_SHARDS docker containers have been started, and it seems each 1kbp region is sent to a different processor based on log, but I don't quite get it how each container knows which 1kbp region to parse.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:9,modifiability,coupl,couple,9,"I have a couple of questions about https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-exome-case-study.md#run-make_examples,. 1. how is `examples.tfrecord@${N_SHARDS}.gz` evaluated to become `examples.tfrecord-00006-of-00008.gz`. 1. what does `--task {}` mean? Could you please explain briefly how this command parallelize the processing? N_SHARDS docker containers have been started, and it seems each 1kbp region is sent to a different processor based on log, but I don't quite get it how each container knows which 1kbp region to parse.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:325,performance,parallel,parallelize,325,"I have a couple of questions about https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-exome-case-study.md#run-make_examples,. 1. how is `examples.tfrecord@${N_SHARDS}.gz` evaluated to become `examples.tfrecord-00006-of-00008.gz`. 1. what does `--task {}` mean? Could you please explain briefly how this command parallelize the processing? N_SHARDS docker containers have been started, and it seems each 1kbp region is sent to a different processor based on log, but I don't quite get it how each container knows which 1kbp region to parse.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:252,reliability,doe,does,252,"I have a couple of questions about https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-exome-case-study.md#run-make_examples,. 1. how is `examples.tfrecord@${N_SHARDS}.gz` evaluated to become `examples.tfrecord-00006-of-00008.gz`. 1. what does `--task {}` mean? Could you please explain briefly how this command parallelize the processing? N_SHARDS docker containers have been started, and it seems each 1kbp region is sent to a different processor based on log, but I don't quite get it how each container knows which 1kbp region to parse.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:471,safety,log,log,471,"I have a couple of questions about https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-exome-case-study.md#run-make_examples,. 1. how is `examples.tfrecord@${N_SHARDS}.gz` evaluated to become `examples.tfrecord-00006-of-00008.gz`. 1. what does `--task {}` mean? Could you please explain briefly how this command parallelize the processing? N_SHARDS docker containers have been started, and it seems each 1kbp region is sent to a different processor based on log, but I don't quite get it how each container knows which 1kbp region to parse.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:471,security,log,log,471,"I have a couple of questions about https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-exome-case-study.md#run-make_examples,. 1. how is `examples.tfrecord@${N_SHARDS}.gz` evaluated to become `examples.tfrecord-00006-of-00008.gz`. 1. what does `--task {}` mean? Could you please explain briefly how this command parallelize the processing? N_SHARDS docker containers have been started, and it seems each 1kbp region is sent to a different processor based on log, but I don't quite get it how each container knows which 1kbp region to parse.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:9,testability,coupl,couple,9,"I have a couple of questions about https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-exome-case-study.md#run-make_examples,. 1. how is `examples.tfrecord@${N_SHARDS}.gz` evaluated to become `examples.tfrecord-00006-of-00008.gz`. 1. what does `--task {}` mean? Could you please explain briefly how this command parallelize the processing? N_SHARDS docker containers have been started, and it seems each 1kbp region is sent to a different processor based on log, but I don't quite get it how each container knows which 1kbp region to parse.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:471,testability,log,log,471,"I have a couple of questions about https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-exome-case-study.md#run-make_examples,. 1. how is `examples.tfrecord@${N_SHARDS}.gz` evaluated to become `examples.tfrecord-00006-of-00008.gz`. 1. what does `--task {}` mean? Could you please explain briefly how this command parallelize the processing? N_SHARDS docker containers have been started, and it seems each 1kbp region is sent to a different processor based on log, but I don't quite get it how each container knows which 1kbp region to parse.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:317,usability,command,command,317,"I have a couple of questions about https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-exome-case-study.md#run-make_examples,. 1. how is `examples.tfrecord@${N_SHARDS}.gz` evaluated to become `examples.tfrecord-00006-of-00008.gz`. 1. what does `--task {}` mean? Could you please explain briefly how this command parallelize the processing? N_SHARDS docker containers have been started, and it seems each 1kbp region is sent to a different processor based on log, but I don't quite get it how each container knows which 1kbp region to parse.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:223,interoperability,specif,specific,223,"@zyxue Regarding question 1, that is done in Nucleus in the following file (`io_utils.py`) in the `GenerateShardedFilenames()` function:. https://github.com/google/nucleus/blob/master/nucleus/util/io_utils.py#L80-L100. The specific lines are the following:. ```Python. basename, num_shards, suffix = ParseShardedFileSpec(spec). files = []. width = _ShardWidth(num_shards). format_str = '{{0}}-{{1:0{0}}}-of-{{2:0{0}}}{{3}}'.format(width). for i in range(num_shards):. files.append(format_str.format(basename, i, num_shards, suffix)). return files. ```. Basically `ParseShardedFileSpec()` function uses the `SHARD_SPEC_PATTERN` to pattern-match against the following:. ```Python. SHARD_SPEC_PATTERN = re.compile(R'((.*)\@(\d*[1-9]\d*)(?:\.(.+))?)'). ```. Notice the @ symbol in the middle :). Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:424,interoperability,format,format,424,"@zyxue Regarding question 1, that is done in Nucleus in the following file (`io_utils.py`) in the `GenerateShardedFilenames()` function:. https://github.com/google/nucleus/blob/master/nucleus/util/io_utils.py#L80-L100. The specific lines are the following:. ```Python. basename, num_shards, suffix = ParseShardedFileSpec(spec). files = []. width = _ShardWidth(num_shards). format_str = '{{0}}-{{1:0{0}}}-of-{{2:0{0}}}{{3}}'.format(width). for i in range(num_shards):. files.append(format_str.format(basename, i, num_shards, suffix)). return files. ```. Basically `ParseShardedFileSpec()` function uses the `SHARD_SPEC_PATTERN` to pattern-match against the following:. ```Python. SHARD_SPEC_PATTERN = re.compile(R'((.*)\@(\d*[1-9]\d*)(?:\.(.+))?)'). ```. Notice the @ symbol in the middle :). Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:492,interoperability,format,format,492,"@zyxue Regarding question 1, that is done in Nucleus in the following file (`io_utils.py`) in the `GenerateShardedFilenames()` function:. https://github.com/google/nucleus/blob/master/nucleus/util/io_utils.py#L80-L100. The specific lines are the following:. ```Python. basename, num_shards, suffix = ParseShardedFileSpec(spec). files = []. width = _ShardWidth(num_shards). format_str = '{{0}}-{{1:0{0}}}-of-{{2:0{0}}}{{3}}'.format(width). for i in range(num_shards):. files.append(format_str.format(basename, i, num_shards, suffix)). return files. ```. Basically `ParseShardedFileSpec()` function uses the `SHARD_SPEC_PATTERN` to pattern-match against the following:. ```Python. SHARD_SPEC_PATTERN = re.compile(R'((.*)\@(\d*[1-9]\d*)(?:\.(.+))?)'). ```. Notice the @ symbol in the middle :). Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:800,usability,help,helps,800,"@zyxue Regarding question 1, that is done in Nucleus in the following file (`io_utils.py`) in the `GenerateShardedFilenames()` function:. https://github.com/google/nucleus/blob/master/nucleus/util/io_utils.py#L80-L100. The specific lines are the following:. ```Python. basename, num_shards, suffix = ParseShardedFileSpec(spec). files = []. width = _ShardWidth(num_shards). format_str = '{{0}}-{{1:0{0}}}-of-{{2:0{0}}}{{3}}'.format(width). for i in range(num_shards):. files.append(format_str.format(basename, i, num_shards, suffix)). return files. ```. Basically `ParseShardedFileSpec()` function uses the `SHARD_SPEC_PATTERN` to pattern-match against the following:. ```Python. SHARD_SPEC_PATTERN = re.compile(R'((.*)\@(\d*[1-9]\d*)(?:\.(.+))?)'). ```. Notice the @ symbol in the middle :). Hope it helps,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:699,deployability,modul,modulo,699,"@zyxue Regarding how it knows about each region, I'm not sure how much do you want to know, since we can go into great detail here. So the big picture of the control flow of the program for `make_examples.py` is this:. ```. main() -> . make_examples_runner() -> . processing_regions_from_options() -> (build_calling_regions, regions_to_process). ```. The `build_calling_regions()` first parses out relevant regions to include/exclude by calling a set of Nucleus helper functions to generate the ranges in this file:. https://github.com/google/deepvariant/blob/r0.7/third_party/nucleus/util/ranges.py. Then `build_calling_regions()` calls `regions_to_process()` where there is a key line that does a modulo to the [number of shards with task_id](https://github.com/google/deepvariant/blob/r0.7/deepvariant/make_examples.py#L659):. ```Python. return (r for i, r in enumerate(partitioned) if i % num_shards == task_id). ```. As you know modulo allows the remainder to be bounded n-1 to the divisor, and thus the distribution of tasks is ideally uniform. Ask more questions, since now you're getting into Computer Science concepts I know I can easily lose people in the details. ~[p]",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:934,deployability,modul,modulo,934,"@zyxue Regarding how it knows about each region, I'm not sure how much do you want to know, since we can go into great detail here. So the big picture of the control flow of the program for `make_examples.py` is this:. ```. main() -> . make_examples_runner() -> . processing_regions_from_options() -> (build_calling_regions, regions_to_process). ```. The `build_calling_regions()` first parses out relevant regions to include/exclude by calling a set of Nucleus helper functions to generate the ranges in this file:. https://github.com/google/deepvariant/blob/r0.7/third_party/nucleus/util/ranges.py. Then `build_calling_regions()` calls `regions_to_process()` where there is a key line that does a modulo to the [number of shards with task_id](https://github.com/google/deepvariant/blob/r0.7/deepvariant/make_examples.py#L659):. ```Python. return (r for i, r in enumerate(partitioned) if i % num_shards == task_id). ```. As you know modulo allows the remainder to be bounded n-1 to the divisor, and thus the distribution of tasks is ideally uniform. Ask more questions, since now you're getting into Computer Science concepts I know I can easily lose people in the details. ~[p]",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:1009,interoperability,distribut,distribution,1009,"@zyxue Regarding how it knows about each region, I'm not sure how much do you want to know, since we can go into great detail here. So the big picture of the control flow of the program for `make_examples.py` is this:. ```. main() -> . make_examples_runner() -> . processing_regions_from_options() -> (build_calling_regions, regions_to_process). ```. The `build_calling_regions()` first parses out relevant regions to include/exclude by calling a set of Nucleus helper functions to generate the ranges in this file:. https://github.com/google/deepvariant/blob/r0.7/third_party/nucleus/util/ranges.py. Then `build_calling_regions()` calls `regions_to_process()` where there is a key line that does a modulo to the [number of shards with task_id](https://github.com/google/deepvariant/blob/r0.7/deepvariant/make_examples.py#L659):. ```Python. return (r for i, r in enumerate(partitioned) if i % num_shards == task_id). ```. As you know modulo allows the remainder to be bounded n-1 to the divisor, and thus the distribution of tasks is ideally uniform. Ask more questions, since now you're getting into Computer Science concepts I know I can easily lose people in the details. ~[p]",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:699,modifiability,modul,modulo,699,"@zyxue Regarding how it knows about each region, I'm not sure how much do you want to know, since we can go into great detail here. So the big picture of the control flow of the program for `make_examples.py` is this:. ```. main() -> . make_examples_runner() -> . processing_regions_from_options() -> (build_calling_regions, regions_to_process). ```. The `build_calling_regions()` first parses out relevant regions to include/exclude by calling a set of Nucleus helper functions to generate the ranges in this file:. https://github.com/google/deepvariant/blob/r0.7/third_party/nucleus/util/ranges.py. Then `build_calling_regions()` calls `regions_to_process()` where there is a key line that does a modulo to the [number of shards with task_id](https://github.com/google/deepvariant/blob/r0.7/deepvariant/make_examples.py#L659):. ```Python. return (r for i, r in enumerate(partitioned) if i % num_shards == task_id). ```. As you know modulo allows the remainder to be bounded n-1 to the divisor, and thus the distribution of tasks is ideally uniform. Ask more questions, since now you're getting into Computer Science concepts I know I can easily lose people in the details. ~[p]",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:934,modifiability,modul,modulo,934,"@zyxue Regarding how it knows about each region, I'm not sure how much do you want to know, since we can go into great detail here. So the big picture of the control flow of the program for `make_examples.py` is this:. ```. main() -> . make_examples_runner() -> . processing_regions_from_options() -> (build_calling_regions, regions_to_process). ```. The `build_calling_regions()` first parses out relevant regions to include/exclude by calling a set of Nucleus helper functions to generate the ranges in this file:. https://github.com/google/deepvariant/blob/r0.7/third_party/nucleus/util/ranges.py. Then `build_calling_regions()` calls `regions_to_process()` where there is a key line that does a modulo to the [number of shards with task_id](https://github.com/google/deepvariant/blob/r0.7/deepvariant/make_examples.py#L659):. ```Python. return (r for i, r in enumerate(partitioned) if i % num_shards == task_id). ```. As you know modulo allows the remainder to be bounded n-1 to the divisor, and thus the distribution of tasks is ideally uniform. Ask more questions, since now you're getting into Computer Science concepts I know I can easily lose people in the details. ~[p]",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:692,reliability,doe,does,692,"@zyxue Regarding how it knows about each region, I'm not sure how much do you want to know, since we can go into great detail here. So the big picture of the control flow of the program for `make_examples.py` is this:. ```. main() -> . make_examples_runner() -> . processing_regions_from_options() -> (build_calling_regions, regions_to_process). ```. The `build_calling_regions()` first parses out relevant regions to include/exclude by calling a set of Nucleus helper functions to generate the ranges in this file:. https://github.com/google/deepvariant/blob/r0.7/third_party/nucleus/util/ranges.py. Then `build_calling_regions()` calls `regions_to_process()` where there is a key line that does a modulo to the [number of shards with task_id](https://github.com/google/deepvariant/blob/r0.7/deepvariant/make_examples.py#L659):. ```Python. return (r for i, r in enumerate(partitioned) if i % num_shards == task_id). ```. As you know modulo allows the remainder to be bounded n-1 to the divisor, and thus the distribution of tasks is ideally uniform. Ask more questions, since now you're getting into Computer Science concepts I know I can easily lose people in the details. ~[p]",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:699,safety,modul,modulo,699,"@zyxue Regarding how it knows about each region, I'm not sure how much do you want to know, since we can go into great detail here. So the big picture of the control flow of the program for `make_examples.py` is this:. ```. main() -> . make_examples_runner() -> . processing_regions_from_options() -> (build_calling_regions, regions_to_process). ```. The `build_calling_regions()` first parses out relevant regions to include/exclude by calling a set of Nucleus helper functions to generate the ranges in this file:. https://github.com/google/deepvariant/blob/r0.7/third_party/nucleus/util/ranges.py. Then `build_calling_regions()` calls `regions_to_process()` where there is a key line that does a modulo to the [number of shards with task_id](https://github.com/google/deepvariant/blob/r0.7/deepvariant/make_examples.py#L659):. ```Python. return (r for i, r in enumerate(partitioned) if i % num_shards == task_id). ```. As you know modulo allows the remainder to be bounded n-1 to the divisor, and thus the distribution of tasks is ideally uniform. Ask more questions, since now you're getting into Computer Science concepts I know I can easily lose people in the details. ~[p]",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:934,safety,modul,modulo,934,"@zyxue Regarding how it knows about each region, I'm not sure how much do you want to know, since we can go into great detail here. So the big picture of the control flow of the program for `make_examples.py` is this:. ```. main() -> . make_examples_runner() -> . processing_regions_from_options() -> (build_calling_regions, regions_to_process). ```. The `build_calling_regions()` first parses out relevant regions to include/exclude by calling a set of Nucleus helper functions to generate the ranges in this file:. https://github.com/google/deepvariant/blob/r0.7/third_party/nucleus/util/ranges.py. Then `build_calling_regions()` calls `regions_to_process()` where there is a key line that does a modulo to the [number of shards with task_id](https://github.com/google/deepvariant/blob/r0.7/deepvariant/make_examples.py#L659):. ```Python. return (r for i, r in enumerate(partitioned) if i % num_shards == task_id). ```. As you know modulo allows the remainder to be bounded n-1 to the divisor, and thus the distribution of tasks is ideally uniform. Ask more questions, since now you're getting into Computer Science concepts I know I can easily lose people in the details. ~[p]",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:158,security,control,control,158,"@zyxue Regarding how it knows about each region, I'm not sure how much do you want to know, since we can go into great detail here. So the big picture of the control flow of the program for `make_examples.py` is this:. ```. main() -> . make_examples_runner() -> . processing_regions_from_options() -> (build_calling_regions, regions_to_process). ```. The `build_calling_regions()` first parses out relevant regions to include/exclude by calling a set of Nucleus helper functions to generate the ranges in this file:. https://github.com/google/deepvariant/blob/r0.7/third_party/nucleus/util/ranges.py. Then `build_calling_regions()` calls `regions_to_process()` where there is a key line that does a modulo to the [number of shards with task_id](https://github.com/google/deepvariant/blob/r0.7/deepvariant/make_examples.py#L659):. ```Python. return (r for i, r in enumerate(partitioned) if i % num_shards == task_id). ```. As you know modulo allows the remainder to be bounded n-1 to the divisor, and thus the distribution of tasks is ideally uniform. Ask more questions, since now you're getting into Computer Science concepts I know I can easily lose people in the details. ~[p]",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:158,testability,control,control,158,"@zyxue Regarding how it knows about each region, I'm not sure how much do you want to know, since we can go into great detail here. So the big picture of the control flow of the program for `make_examples.py` is this:. ```. main() -> . make_examples_runner() -> . processing_regions_from_options() -> (build_calling_regions, regions_to_process). ```. The `build_calling_regions()` first parses out relevant regions to include/exclude by calling a set of Nucleus helper functions to generate the ranges in this file:. https://github.com/google/deepvariant/blob/r0.7/third_party/nucleus/util/ranges.py. Then `build_calling_regions()` calls `regions_to_process()` where there is a key line that does a modulo to the [number of shards with task_id](https://github.com/google/deepvariant/blob/r0.7/deepvariant/make_examples.py#L659):. ```Python. return (r for i, r in enumerate(partitioned) if i % num_shards == task_id). ```. As you know modulo allows the remainder to be bounded n-1 to the divisor, and thus the distribution of tasks is ideally uniform. Ask more questions, since now you're getting into Computer Science concepts I know I can easily lose people in the details. ~[p]",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:462,usability,help,helper,462,"@zyxue Regarding how it knows about each region, I'm not sure how much do you want to know, since we can go into great detail here. So the big picture of the control flow of the program for `make_examples.py` is this:. ```. main() -> . make_examples_runner() -> . processing_regions_from_options() -> (build_calling_regions, regions_to_process). ```. The `build_calling_regions()` first parses out relevant regions to include/exclude by calling a set of Nucleus helper functions to generate the ranges in this file:. https://github.com/google/deepvariant/blob/r0.7/third_party/nucleus/util/ranges.py. Then `build_calling_regions()` calls `regions_to_process()` where there is a key line that does a modulo to the [number of shards with task_id](https://github.com/google/deepvariant/blob/r0.7/deepvariant/make_examples.py#L659):. ```Python. return (r for i, r in enumerate(partitioned) if i % num_shards == task_id). ```. As you know modulo allows the remainder to be bounded n-1 to the divisor, and thus the distribution of tasks is ideally uniform. Ask more questions, since now you're getting into Computer Science concepts I know I can easily lose people in the details. ~[p]",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:53,energy efficiency,core,core,53,"Finally, make_examples finished successfully on an 8-core machine 🎉. Thank you for all your help!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:92,usability,help,help,92,"Finally, make_examples finished successfully on an 8-core machine 🎉. Thank you for all your help!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:38,security,team,team-effort,38,Super-awesome to hear!!! It was a fun team-effort :),MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/100:46,deployability,updat,updating,46,"@junehawk Looks like the `DV_COPT_FLAGS` need updating for your environment. Assuming you got 0.7 of DeepVariant, then change the following line in [settings.sh](https://github.com/google/deepvariant/blob/r0.7/settings.sh#L112):. `export DV_COPT_FLAGS=""--copt=-march=corei7 --copt=-Wno-sign-compare --copt=-Wno-write-strings""`. to the following:. `export DV_COPT_FLAGS=""--copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3 --copt=-Wno-sign-compare --copt=-Wno-write-strings""`. Then follow the instructions at the following link to make a local Docker image using the [cloudbuild.yaml](https://github.com/google/deepvariant/blob/r0.7/cloudbuild.yaml) file, located in the root directory of DeepVariant:. https://cloud.google.com/cloud-build/docs/build-debug-locally. I think that should fix it, but let us know if you still run into any issues. Thanks,. ~p.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/100
https://github.com/google/deepvariant/issues/100:737,deployability,build,build,737,"@junehawk Looks like the `DV_COPT_FLAGS` need updating for your environment. Assuming you got 0.7 of DeepVariant, then change the following line in [settings.sh](https://github.com/google/deepvariant/blob/r0.7/settings.sh#L112):. `export DV_COPT_FLAGS=""--copt=-march=corei7 --copt=-Wno-sign-compare --copt=-Wno-write-strings""`. to the following:. `export DV_COPT_FLAGS=""--copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3 --copt=-Wno-sign-compare --copt=-Wno-write-strings""`. Then follow the instructions at the following link to make a local Docker image using the [cloudbuild.yaml](https://github.com/google/deepvariant/blob/r0.7/cloudbuild.yaml) file, located in the root directory of DeepVariant:. https://cloud.google.com/cloud-build/docs/build-debug-locally. I think that should fix it, but let us know if you still run into any issues. Thanks,. ~p.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/100
https://github.com/google/deepvariant/issues/100:748,deployability,build,build-debug-locally,748,"@junehawk Looks like the `DV_COPT_FLAGS` need updating for your environment. Assuming you got 0.7 of DeepVariant, then change the following line in [settings.sh](https://github.com/google/deepvariant/blob/r0.7/settings.sh#L112):. `export DV_COPT_FLAGS=""--copt=-march=corei7 --copt=-Wno-sign-compare --copt=-Wno-write-strings""`. to the following:. `export DV_COPT_FLAGS=""--copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3 --copt=-Wno-sign-compare --copt=-Wno-write-strings""`. Then follow the instructions at the following link to make a local Docker image using the [cloudbuild.yaml](https://github.com/google/deepvariant/blob/r0.7/cloudbuild.yaml) file, located in the root directory of DeepVariant:. https://cloud.google.com/cloud-build/docs/build-debug-locally. I think that should fix it, but let us know if you still run into any issues. Thanks,. ~p.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/100
https://github.com/google/deepvariant/issues/100:571,energy efficiency,cloud,cloudbuild,571,"@junehawk Looks like the `DV_COPT_FLAGS` need updating for your environment. Assuming you got 0.7 of DeepVariant, then change the following line in [settings.sh](https://github.com/google/deepvariant/blob/r0.7/settings.sh#L112):. `export DV_COPT_FLAGS=""--copt=-march=corei7 --copt=-Wno-sign-compare --copt=-Wno-write-strings""`. to the following:. `export DV_COPT_FLAGS=""--copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3 --copt=-Wno-sign-compare --copt=-Wno-write-strings""`. Then follow the instructions at the following link to make a local Docker image using the [cloudbuild.yaml](https://github.com/google/deepvariant/blob/r0.7/cloudbuild.yaml) file, located in the root directory of DeepVariant:. https://cloud.google.com/cloud-build/docs/build-debug-locally. I think that should fix it, but let us know if you still run into any issues. Thanks,. ~p.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/100
https://github.com/google/deepvariant/issues/100:636,energy efficiency,cloud,cloudbuild,636,"@junehawk Looks like the `DV_COPT_FLAGS` need updating for your environment. Assuming you got 0.7 of DeepVariant, then change the following line in [settings.sh](https://github.com/google/deepvariant/blob/r0.7/settings.sh#L112):. `export DV_COPT_FLAGS=""--copt=-march=corei7 --copt=-Wno-sign-compare --copt=-Wno-write-strings""`. to the following:. `export DV_COPT_FLAGS=""--copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3 --copt=-Wno-sign-compare --copt=-Wno-write-strings""`. Then follow the instructions at the following link to make a local Docker image using the [cloudbuild.yaml](https://github.com/google/deepvariant/blob/r0.7/cloudbuild.yaml) file, located in the root directory of DeepVariant:. https://cloud.google.com/cloud-build/docs/build-debug-locally. I think that should fix it, but let us know if you still run into any issues. Thanks,. ~p.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/100
https://github.com/google/deepvariant/issues/100:714,energy efficiency,cloud,cloud,714,"@junehawk Looks like the `DV_COPT_FLAGS` need updating for your environment. Assuming you got 0.7 of DeepVariant, then change the following line in [settings.sh](https://github.com/google/deepvariant/blob/r0.7/settings.sh#L112):. `export DV_COPT_FLAGS=""--copt=-march=corei7 --copt=-Wno-sign-compare --copt=-Wno-write-strings""`. to the following:. `export DV_COPT_FLAGS=""--copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3 --copt=-Wno-sign-compare --copt=-Wno-write-strings""`. Then follow the instructions at the following link to make a local Docker image using the [cloudbuild.yaml](https://github.com/google/deepvariant/blob/r0.7/cloudbuild.yaml) file, located in the root directory of DeepVariant:. https://cloud.google.com/cloud-build/docs/build-debug-locally. I think that should fix it, but let us know if you still run into any issues. Thanks,. ~p.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/100
https://github.com/google/deepvariant/issues/100:731,energy efficiency,cloud,cloud-build,731,"@junehawk Looks like the `DV_COPT_FLAGS` need updating for your environment. Assuming you got 0.7 of DeepVariant, then change the following line in [settings.sh](https://github.com/google/deepvariant/blob/r0.7/settings.sh#L112):. `export DV_COPT_FLAGS=""--copt=-march=corei7 --copt=-Wno-sign-compare --copt=-Wno-write-strings""`. to the following:. `export DV_COPT_FLAGS=""--copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3 --copt=-Wno-sign-compare --copt=-Wno-write-strings""`. Then follow the instructions at the following link to make a local Docker image using the [cloudbuild.yaml](https://github.com/google/deepvariant/blob/r0.7/cloudbuild.yaml) file, located in the root directory of DeepVariant:. https://cloud.google.com/cloud-build/docs/build-debug-locally. I think that should fix it, but let us know if you still run into any issues. Thanks,. ~p.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/100
https://github.com/google/deepvariant/issues/100:46,safety,updat,updating,46,"@junehawk Looks like the `DV_COPT_FLAGS` need updating for your environment. Assuming you got 0.7 of DeepVariant, then change the following line in [settings.sh](https://github.com/google/deepvariant/blob/r0.7/settings.sh#L112):. `export DV_COPT_FLAGS=""--copt=-march=corei7 --copt=-Wno-sign-compare --copt=-Wno-write-strings""`. to the following:. `export DV_COPT_FLAGS=""--copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3 --copt=-Wno-sign-compare --copt=-Wno-write-strings""`. Then follow the instructions at the following link to make a local Docker image using the [cloudbuild.yaml](https://github.com/google/deepvariant/blob/r0.7/cloudbuild.yaml) file, located in the root directory of DeepVariant:. https://cloud.google.com/cloud-build/docs/build-debug-locally. I think that should fix it, but let us know if you still run into any issues. Thanks,. ~p.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/100
https://github.com/google/deepvariant/issues/100:46,security,updat,updating,46,"@junehawk Looks like the `DV_COPT_FLAGS` need updating for your environment. Assuming you got 0.7 of DeepVariant, then change the following line in [settings.sh](https://github.com/google/deepvariant/blob/r0.7/settings.sh#L112):. `export DV_COPT_FLAGS=""--copt=-march=corei7 --copt=-Wno-sign-compare --copt=-Wno-write-strings""`. to the following:. `export DV_COPT_FLAGS=""--copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3 --copt=-Wno-sign-compare --copt=-Wno-write-strings""`. Then follow the instructions at the following link to make a local Docker image using the [cloudbuild.yaml](https://github.com/google/deepvariant/blob/r0.7/cloudbuild.yaml) file, located in the root directory of DeepVariant:. https://cloud.google.com/cloud-build/docs/build-debug-locally. I think that should fix it, but let us know if you still run into any issues. Thanks,. ~p.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/100
https://github.com/google/deepvariant/issues/100:286,security,sign,sign-compare,286,"@junehawk Looks like the `DV_COPT_FLAGS` need updating for your environment. Assuming you got 0.7 of DeepVariant, then change the following line in [settings.sh](https://github.com/google/deepvariant/blob/r0.7/settings.sh#L112):. `export DV_COPT_FLAGS=""--copt=-march=corei7 --copt=-Wno-sign-compare --copt=-Wno-write-strings""`. to the following:. `export DV_COPT_FLAGS=""--copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3 --copt=-Wno-sign-compare --copt=-Wno-write-strings""`. Then follow the instructions at the following link to make a local Docker image using the [cloudbuild.yaml](https://github.com/google/deepvariant/blob/r0.7/cloudbuild.yaml) file, located in the root directory of DeepVariant:. https://cloud.google.com/cloud-build/docs/build-debug-locally. I think that should fix it, but let us know if you still run into any issues. Thanks,. ~p.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/100
https://github.com/google/deepvariant/issues/100:438,security,sign,sign-compare,438,"@junehawk Looks like the `DV_COPT_FLAGS` need updating for your environment. Assuming you got 0.7 of DeepVariant, then change the following line in [settings.sh](https://github.com/google/deepvariant/blob/r0.7/settings.sh#L112):. `export DV_COPT_FLAGS=""--copt=-march=corei7 --copt=-Wno-sign-compare --copt=-Wno-write-strings""`. to the following:. `export DV_COPT_FLAGS=""--copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-O3 --copt=-Wno-sign-compare --copt=-Wno-write-strings""`. Then follow the instructions at the following link to make a local Docker image using the [cloudbuild.yaml](https://github.com/google/deepvariant/blob/r0.7/cloudbuild.yaml) file, located in the root directory of DeepVariant:. https://cloud.google.com/cloud-build/docs/build-debug-locally. I think that should fix it, but let us know if you still run into any issues. Thanks,. ~p.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/100
https://github.com/google/deepvariant/issues/101:15,deployability,instal,install,15,"Is the one you install on conda this one? https://bioconda.github.io/recipes/deepvariant/README.html. If it's that, I believe it's recently updated to 0.7. . This package actually isn't manage by the team at Google. But the owner ( @chapmanb ) has updated to the latest version (0.7). A quick search of `dv_make_examples.py` seems to be pointed to this file. https://github.com/bioconda/bioconda-recipes/blob/master/recipes/deepvariant/dv_make_examples.py. which it does call python make_examples.zip.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/101
https://github.com/google/deepvariant/issues/101:140,deployability,updat,updated,140,"Is the one you install on conda this one? https://bioconda.github.io/recipes/deepvariant/README.html. If it's that, I believe it's recently updated to 0.7. . This package actually isn't manage by the team at Google. But the owner ( @chapmanb ) has updated to the latest version (0.7). A quick search of `dv_make_examples.py` seems to be pointed to this file. https://github.com/bioconda/bioconda-recipes/blob/master/recipes/deepvariant/dv_make_examples.py. which it does call python make_examples.zip.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/101
https://github.com/google/deepvariant/issues/101:186,deployability,manag,manage,186,"Is the one you install on conda this one? https://bioconda.github.io/recipes/deepvariant/README.html. If it's that, I believe it's recently updated to 0.7. . This package actually isn't manage by the team at Google. But the owner ( @chapmanb ) has updated to the latest version (0.7). A quick search of `dv_make_examples.py` seems to be pointed to this file. https://github.com/bioconda/bioconda-recipes/blob/master/recipes/deepvariant/dv_make_examples.py. which it does call python make_examples.zip.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/101
https://github.com/google/deepvariant/issues/101:248,deployability,updat,updated,248,"Is the one you install on conda this one? https://bioconda.github.io/recipes/deepvariant/README.html. If it's that, I believe it's recently updated to 0.7. . This package actually isn't manage by the team at Google. But the owner ( @chapmanb ) has updated to the latest version (0.7). A quick search of `dv_make_examples.py` seems to be pointed to this file. https://github.com/bioconda/bioconda-recipes/blob/master/recipes/deepvariant/dv_make_examples.py. which it does call python make_examples.zip.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/101
https://github.com/google/deepvariant/issues/101:270,deployability,version,version,270,"Is the one you install on conda this one? https://bioconda.github.io/recipes/deepvariant/README.html. If it's that, I believe it's recently updated to 0.7. . This package actually isn't manage by the team at Google. But the owner ( @chapmanb ) has updated to the latest version (0.7). A quick search of `dv_make_examples.py` seems to be pointed to this file. https://github.com/bioconda/bioconda-recipes/blob/master/recipes/deepvariant/dv_make_examples.py. which it does call python make_examples.zip.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/101
https://github.com/google/deepvariant/issues/101:186,energy efficiency,manag,manage,186,"Is the one you install on conda this one? https://bioconda.github.io/recipes/deepvariant/README.html. If it's that, I believe it's recently updated to 0.7. . This package actually isn't manage by the team at Google. But the owner ( @chapmanb ) has updated to the latest version (0.7). A quick search of `dv_make_examples.py` seems to be pointed to this file. https://github.com/bioconda/bioconda-recipes/blob/master/recipes/deepvariant/dv_make_examples.py. which it does call python make_examples.zip.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/101
https://github.com/google/deepvariant/issues/101:270,integrability,version,version,270,"Is the one you install on conda this one? https://bioconda.github.io/recipes/deepvariant/README.html. If it's that, I believe it's recently updated to 0.7. . This package actually isn't manage by the team at Google. But the owner ( @chapmanb ) has updated to the latest version (0.7). A quick search of `dv_make_examples.py` seems to be pointed to this file. https://github.com/bioconda/bioconda-recipes/blob/master/recipes/deepvariant/dv_make_examples.py. which it does call python make_examples.zip.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/101
https://github.com/google/deepvariant/issues/101:163,modifiability,pac,package,163,"Is the one you install on conda this one? https://bioconda.github.io/recipes/deepvariant/README.html. If it's that, I believe it's recently updated to 0.7. . This package actually isn't manage by the team at Google. But the owner ( @chapmanb ) has updated to the latest version (0.7). A quick search of `dv_make_examples.py` seems to be pointed to this file. https://github.com/bioconda/bioconda-recipes/blob/master/recipes/deepvariant/dv_make_examples.py. which it does call python make_examples.zip.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/101
https://github.com/google/deepvariant/issues/101:270,modifiability,version,version,270,"Is the one you install on conda this one? https://bioconda.github.io/recipes/deepvariant/README.html. If it's that, I believe it's recently updated to 0.7. . This package actually isn't manage by the team at Google. But the owner ( @chapmanb ) has updated to the latest version (0.7). A quick search of `dv_make_examples.py` seems to be pointed to this file. https://github.com/bioconda/bioconda-recipes/blob/master/recipes/deepvariant/dv_make_examples.py. which it does call python make_examples.zip.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/101
https://github.com/google/deepvariant/issues/101:466,reliability,doe,does,466,"Is the one you install on conda this one? https://bioconda.github.io/recipes/deepvariant/README.html. If it's that, I believe it's recently updated to 0.7. . This package actually isn't manage by the team at Google. But the owner ( @chapmanb ) has updated to the latest version (0.7). A quick search of `dv_make_examples.py` seems to be pointed to this file. https://github.com/bioconda/bioconda-recipes/blob/master/recipes/deepvariant/dv_make_examples.py. which it does call python make_examples.zip.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/101
https://github.com/google/deepvariant/issues/101:140,safety,updat,updated,140,"Is the one you install on conda this one? https://bioconda.github.io/recipes/deepvariant/README.html. If it's that, I believe it's recently updated to 0.7. . This package actually isn't manage by the team at Google. But the owner ( @chapmanb ) has updated to the latest version (0.7). A quick search of `dv_make_examples.py` seems to be pointed to this file. https://github.com/bioconda/bioconda-recipes/blob/master/recipes/deepvariant/dv_make_examples.py. which it does call python make_examples.zip.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/101
https://github.com/google/deepvariant/issues/101:186,safety,manag,manage,186,"Is the one you install on conda this one? https://bioconda.github.io/recipes/deepvariant/README.html. If it's that, I believe it's recently updated to 0.7. . This package actually isn't manage by the team at Google. But the owner ( @chapmanb ) has updated to the latest version (0.7). A quick search of `dv_make_examples.py` seems to be pointed to this file. https://github.com/bioconda/bioconda-recipes/blob/master/recipes/deepvariant/dv_make_examples.py. which it does call python make_examples.zip.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/101
https://github.com/google/deepvariant/issues/101:248,safety,updat,updated,248,"Is the one you install on conda this one? https://bioconda.github.io/recipes/deepvariant/README.html. If it's that, I believe it's recently updated to 0.7. . This package actually isn't manage by the team at Google. But the owner ( @chapmanb ) has updated to the latest version (0.7). A quick search of `dv_make_examples.py` seems to be pointed to this file. https://github.com/bioconda/bioconda-recipes/blob/master/recipes/deepvariant/dv_make_examples.py. which it does call python make_examples.zip.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/101
https://github.com/google/deepvariant/issues/101:140,security,updat,updated,140,"Is the one you install on conda this one? https://bioconda.github.io/recipes/deepvariant/README.html. If it's that, I believe it's recently updated to 0.7. . This package actually isn't manage by the team at Google. But the owner ( @chapmanb ) has updated to the latest version (0.7). A quick search of `dv_make_examples.py` seems to be pointed to this file. https://github.com/bioconda/bioconda-recipes/blob/master/recipes/deepvariant/dv_make_examples.py. which it does call python make_examples.zip.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/101
https://github.com/google/deepvariant/issues/101:200,security,team,team,200,"Is the one you install on conda this one? https://bioconda.github.io/recipes/deepvariant/README.html. If it's that, I believe it's recently updated to 0.7. . This package actually isn't manage by the team at Google. But the owner ( @chapmanb ) has updated to the latest version (0.7). A quick search of `dv_make_examples.py` seems to be pointed to this file. https://github.com/bioconda/bioconda-recipes/blob/master/recipes/deepvariant/dv_make_examples.py. which it does call python make_examples.zip.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/101
https://github.com/google/deepvariant/issues/101:248,security,updat,updated,248,"Is the one you install on conda this one? https://bioconda.github.io/recipes/deepvariant/README.html. If it's that, I believe it's recently updated to 0.7. . This package actually isn't manage by the team at Google. But the owner ( @chapmanb ) has updated to the latest version (0.7). A quick search of `dv_make_examples.py` seems to be pointed to this file. https://github.com/bioconda/bioconda-recipes/blob/master/recipes/deepvariant/dv_make_examples.py. which it does call python make_examples.zip.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/101
https://github.com/google/deepvariant/issues/101:287,deployability,instal,installs,287,"Phil and Pi-Chuan;. That's exactly right, `dv_make_examples.py` is a simple wrapper for `make_examples.zip` to make it directly callable and is part of the conda packaging process, not a default script from the Google team. If it's not useful, feel free to call directly at the standard installs, it just tries to avoid needing to know the full install path and other details about the parallelization so the command line syntax is simplified. For your example you'd use it like:. ```. dv_make_examples.py. --ref chr20.fa.gz \. --reads test.bam \. --examples shardedExamples/examples.tfrecord@2.gz \. --regions regions.bed \. --sample test \. --logdir location/to/place/logfiles. --cores 1. ```. Hope this helps.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/101
https://github.com/google/deepvariant/issues/101:345,deployability,instal,install,345,"Phil and Pi-Chuan;. That's exactly right, `dv_make_examples.py` is a simple wrapper for `make_examples.zip` to make it directly callable and is part of the conda packaging process, not a default script from the Google team. If it's not useful, feel free to call directly at the standard installs, it just tries to avoid needing to know the full install path and other details about the parallelization so the command line syntax is simplified. For your example you'd use it like:. ```. dv_make_examples.py. --ref chr20.fa.gz \. --reads test.bam \. --examples shardedExamples/examples.tfrecord@2.gz \. --regions regions.bed \. --sample test \. --logdir location/to/place/logfiles. --cores 1. ```. Hope this helps.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/101
https://github.com/google/deepvariant/issues/101:645,deployability,log,logdir,645,"Phil and Pi-Chuan;. That's exactly right, `dv_make_examples.py` is a simple wrapper for `make_examples.zip` to make it directly callable and is part of the conda packaging process, not a default script from the Google team. If it's not useful, feel free to call directly at the standard installs, it just tries to avoid needing to know the full install path and other details about the parallelization so the command line syntax is simplified. For your example you'd use it like:. ```. dv_make_examples.py. --ref chr20.fa.gz \. --reads test.bam \. --examples shardedExamples/examples.tfrecord@2.gz \. --regions regions.bed \. --sample test \. --logdir location/to/place/logfiles. --cores 1. ```. Hope this helps.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/101
https://github.com/google/deepvariant/issues/101:670,deployability,log,logfiles,670,"Phil and Pi-Chuan;. That's exactly right, `dv_make_examples.py` is a simple wrapper for `make_examples.zip` to make it directly callable and is part of the conda packaging process, not a default script from the Google team. If it's not useful, feel free to call directly at the standard installs, it just tries to avoid needing to know the full install path and other details about the parallelization so the command line syntax is simplified. For your example you'd use it like:. ```. dv_make_examples.py. --ref chr20.fa.gz \. --reads test.bam \. --examples shardedExamples/examples.tfrecord@2.gz \. --regions regions.bed \. --sample test \. --logdir location/to/place/logfiles. --cores 1. ```. Hope this helps.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/101
https://github.com/google/deepvariant/issues/101:682,energy efficiency,core,cores,682,"Phil and Pi-Chuan;. That's exactly right, `dv_make_examples.py` is a simple wrapper for `make_examples.zip` to make it directly callable and is part of the conda packaging process, not a default script from the Google team. If it's not useful, feel free to call directly at the standard installs, it just tries to avoid needing to know the full install path and other details about the parallelization so the command line syntax is simplified. For your example you'd use it like:. ```. dv_make_examples.py. --ref chr20.fa.gz \. --reads test.bam \. --examples shardedExamples/examples.tfrecord@2.gz \. --regions regions.bed \. --sample test \. --logdir location/to/place/logfiles. --cores 1. ```. Hope this helps.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/101
https://github.com/google/deepvariant/issues/101:76,integrability,wrap,wrapper,76,"Phil and Pi-Chuan;. That's exactly right, `dv_make_examples.py` is a simple wrapper for `make_examples.zip` to make it directly callable and is part of the conda packaging process, not a default script from the Google team. If it's not useful, feel free to call directly at the standard installs, it just tries to avoid needing to know the full install path and other details about the parallelization so the command line syntax is simplified. For your example you'd use it like:. ```. dv_make_examples.py. --ref chr20.fa.gz \. --reads test.bam \. --examples shardedExamples/examples.tfrecord@2.gz \. --regions regions.bed \. --sample test \. --logdir location/to/place/logfiles. --cores 1. ```. Hope this helps.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/101
https://github.com/google/deepvariant/issues/101:76,interoperability,wrapper,wrapper,76,"Phil and Pi-Chuan;. That's exactly right, `dv_make_examples.py` is a simple wrapper for `make_examples.zip` to make it directly callable and is part of the conda packaging process, not a default script from the Google team. If it's not useful, feel free to call directly at the standard installs, it just tries to avoid needing to know the full install path and other details about the parallelization so the command line syntax is simplified. For your example you'd use it like:. ```. dv_make_examples.py. --ref chr20.fa.gz \. --reads test.bam \. --examples shardedExamples/examples.tfrecord@2.gz \. --regions regions.bed \. --sample test \. --logdir location/to/place/logfiles. --cores 1. ```. Hope this helps.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/101
https://github.com/google/deepvariant/issues/101:278,interoperability,standard,standard,278,"Phil and Pi-Chuan;. That's exactly right, `dv_make_examples.py` is a simple wrapper for `make_examples.zip` to make it directly callable and is part of the conda packaging process, not a default script from the Google team. If it's not useful, feel free to call directly at the standard installs, it just tries to avoid needing to know the full install path and other details about the parallelization so the command line syntax is simplified. For your example you'd use it like:. ```. dv_make_examples.py. --ref chr20.fa.gz \. --reads test.bam \. --examples shardedExamples/examples.tfrecord@2.gz \. --regions regions.bed \. --sample test \. --logdir location/to/place/logfiles. --cores 1. ```. Hope this helps.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/101
https://github.com/google/deepvariant/issues/101:162,modifiability,pac,packaging,162,"Phil and Pi-Chuan;. That's exactly right, `dv_make_examples.py` is a simple wrapper for `make_examples.zip` to make it directly callable and is part of the conda packaging process, not a default script from the Google team. If it's not useful, feel free to call directly at the standard installs, it just tries to avoid needing to know the full install path and other details about the parallelization so the command line syntax is simplified. For your example you'd use it like:. ```. dv_make_examples.py. --ref chr20.fa.gz \. --reads test.bam \. --examples shardedExamples/examples.tfrecord@2.gz \. --regions regions.bed \. --sample test \. --logdir location/to/place/logfiles. --cores 1. ```. Hope this helps.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/101
https://github.com/google/deepvariant/issues/101:386,performance,parallel,parallelization,386,"Phil and Pi-Chuan;. That's exactly right, `dv_make_examples.py` is a simple wrapper for `make_examples.zip` to make it directly callable and is part of the conda packaging process, not a default script from the Google team. If it's not useful, feel free to call directly at the standard installs, it just tries to avoid needing to know the full install path and other details about the parallelization so the command line syntax is simplified. For your example you'd use it like:. ```. dv_make_examples.py. --ref chr20.fa.gz \. --reads test.bam \. --examples shardedExamples/examples.tfrecord@2.gz \. --regions regions.bed \. --sample test \. --logdir location/to/place/logfiles. --cores 1. ```. Hope this helps.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/101
https://github.com/google/deepvariant/issues/101:314,safety,avoid,avoid,314,"Phil and Pi-Chuan;. That's exactly right, `dv_make_examples.py` is a simple wrapper for `make_examples.zip` to make it directly callable and is part of the conda packaging process, not a default script from the Google team. If it's not useful, feel free to call directly at the standard installs, it just tries to avoid needing to know the full install path and other details about the parallelization so the command line syntax is simplified. For your example you'd use it like:. ```. dv_make_examples.py. --ref chr20.fa.gz \. --reads test.bam \. --examples shardedExamples/examples.tfrecord@2.gz \. --regions regions.bed \. --sample test \. --logdir location/to/place/logfiles. --cores 1. ```. Hope this helps.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/101
https://github.com/google/deepvariant/issues/101:536,safety,test,test,536,"Phil and Pi-Chuan;. That's exactly right, `dv_make_examples.py` is a simple wrapper for `make_examples.zip` to make it directly callable and is part of the conda packaging process, not a default script from the Google team. If it's not useful, feel free to call directly at the standard installs, it just tries to avoid needing to know the full install path and other details about the parallelization so the command line syntax is simplified. For your example you'd use it like:. ```. dv_make_examples.py. --ref chr20.fa.gz \. --reads test.bam \. --examples shardedExamples/examples.tfrecord@2.gz \. --regions regions.bed \. --sample test \. --logdir location/to/place/logfiles. --cores 1. ```. Hope this helps.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/101
https://github.com/google/deepvariant/issues/101:635,safety,test,test,635,"Phil and Pi-Chuan;. That's exactly right, `dv_make_examples.py` is a simple wrapper for `make_examples.zip` to make it directly callable and is part of the conda packaging process, not a default script from the Google team. If it's not useful, feel free to call directly at the standard installs, it just tries to avoid needing to know the full install path and other details about the parallelization so the command line syntax is simplified. For your example you'd use it like:. ```. dv_make_examples.py. --ref chr20.fa.gz \. --reads test.bam \. --examples shardedExamples/examples.tfrecord@2.gz \. --regions regions.bed \. --sample test \. --logdir location/to/place/logfiles. --cores 1. ```. Hope this helps.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/101
https://github.com/google/deepvariant/issues/101:645,safety,log,logdir,645,"Phil and Pi-Chuan;. That's exactly right, `dv_make_examples.py` is a simple wrapper for `make_examples.zip` to make it directly callable and is part of the conda packaging process, not a default script from the Google team. If it's not useful, feel free to call directly at the standard installs, it just tries to avoid needing to know the full install path and other details about the parallelization so the command line syntax is simplified. For your example you'd use it like:. ```. dv_make_examples.py. --ref chr20.fa.gz \. --reads test.bam \. --examples shardedExamples/examples.tfrecord@2.gz \. --regions regions.bed \. --sample test \. --logdir location/to/place/logfiles. --cores 1. ```. Hope this helps.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/101
https://github.com/google/deepvariant/issues/101:670,safety,log,logfiles,670,"Phil and Pi-Chuan;. That's exactly right, `dv_make_examples.py` is a simple wrapper for `make_examples.zip` to make it directly callable and is part of the conda packaging process, not a default script from the Google team. If it's not useful, feel free to call directly at the standard installs, it just tries to avoid needing to know the full install path and other details about the parallelization so the command line syntax is simplified. For your example you'd use it like:. ```. dv_make_examples.py. --ref chr20.fa.gz \. --reads test.bam \. --examples shardedExamples/examples.tfrecord@2.gz \. --regions regions.bed \. --sample test \. --logdir location/to/place/logfiles. --cores 1. ```. Hope this helps.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/101
https://github.com/google/deepvariant/issues/101:218,security,team,team,218,"Phil and Pi-Chuan;. That's exactly right, `dv_make_examples.py` is a simple wrapper for `make_examples.zip` to make it directly callable and is part of the conda packaging process, not a default script from the Google team. If it's not useful, feel free to call directly at the standard installs, it just tries to avoid needing to know the full install path and other details about the parallelization so the command line syntax is simplified. For your example you'd use it like:. ```. dv_make_examples.py. --ref chr20.fa.gz \. --reads test.bam \. --examples shardedExamples/examples.tfrecord@2.gz \. --regions regions.bed \. --sample test \. --logdir location/to/place/logfiles. --cores 1. ```. Hope this helps.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/101
https://github.com/google/deepvariant/issues/101:645,security,log,logdir,645,"Phil and Pi-Chuan;. That's exactly right, `dv_make_examples.py` is a simple wrapper for `make_examples.zip` to make it directly callable and is part of the conda packaging process, not a default script from the Google team. If it's not useful, feel free to call directly at the standard installs, it just tries to avoid needing to know the full install path and other details about the parallelization so the command line syntax is simplified. For your example you'd use it like:. ```. dv_make_examples.py. --ref chr20.fa.gz \. --reads test.bam \. --examples shardedExamples/examples.tfrecord@2.gz \. --regions regions.bed \. --sample test \. --logdir location/to/place/logfiles. --cores 1. ```. Hope this helps.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/101
https://github.com/google/deepvariant/issues/101:670,security,log,logfiles,670,"Phil and Pi-Chuan;. That's exactly right, `dv_make_examples.py` is a simple wrapper for `make_examples.zip` to make it directly callable and is part of the conda packaging process, not a default script from the Google team. If it's not useful, feel free to call directly at the standard installs, it just tries to avoid needing to know the full install path and other details about the parallelization so the command line syntax is simplified. For your example you'd use it like:. ```. dv_make_examples.py. --ref chr20.fa.gz \. --reads test.bam \. --examples shardedExamples/examples.tfrecord@2.gz \. --regions regions.bed \. --sample test \. --logdir location/to/place/logfiles. --cores 1. ```. Hope this helps.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/101
https://github.com/google/deepvariant/issues/101:69,testability,simpl,simple,69,"Phil and Pi-Chuan;. That's exactly right, `dv_make_examples.py` is a simple wrapper for `make_examples.zip` to make it directly callable and is part of the conda packaging process, not a default script from the Google team. If it's not useful, feel free to call directly at the standard installs, it just tries to avoid needing to know the full install path and other details about the parallelization so the command line syntax is simplified. For your example you'd use it like:. ```. dv_make_examples.py. --ref chr20.fa.gz \. --reads test.bam \. --examples shardedExamples/examples.tfrecord@2.gz \. --regions regions.bed \. --sample test \. --logdir location/to/place/logfiles. --cores 1. ```. Hope this helps.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/101
https://github.com/google/deepvariant/issues/101:432,testability,simpl,simplified,432,"Phil and Pi-Chuan;. That's exactly right, `dv_make_examples.py` is a simple wrapper for `make_examples.zip` to make it directly callable and is part of the conda packaging process, not a default script from the Google team. If it's not useful, feel free to call directly at the standard installs, it just tries to avoid needing to know the full install path and other details about the parallelization so the command line syntax is simplified. For your example you'd use it like:. ```. dv_make_examples.py. --ref chr20.fa.gz \. --reads test.bam \. --examples shardedExamples/examples.tfrecord@2.gz \. --regions regions.bed \. --sample test \. --logdir location/to/place/logfiles. --cores 1. ```. Hope this helps.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/101
https://github.com/google/deepvariant/issues/101:536,testability,test,test,536,"Phil and Pi-Chuan;. That's exactly right, `dv_make_examples.py` is a simple wrapper for `make_examples.zip` to make it directly callable and is part of the conda packaging process, not a default script from the Google team. If it's not useful, feel free to call directly at the standard installs, it just tries to avoid needing to know the full install path and other details about the parallelization so the command line syntax is simplified. For your example you'd use it like:. ```. dv_make_examples.py. --ref chr20.fa.gz \. --reads test.bam \. --examples shardedExamples/examples.tfrecord@2.gz \. --regions regions.bed \. --sample test \. --logdir location/to/place/logfiles. --cores 1. ```. Hope this helps.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/101
https://github.com/google/deepvariant/issues/101:635,testability,test,test,635,"Phil and Pi-Chuan;. That's exactly right, `dv_make_examples.py` is a simple wrapper for `make_examples.zip` to make it directly callable and is part of the conda packaging process, not a default script from the Google team. If it's not useful, feel free to call directly at the standard installs, it just tries to avoid needing to know the full install path and other details about the parallelization so the command line syntax is simplified. For your example you'd use it like:. ```. dv_make_examples.py. --ref chr20.fa.gz \. --reads test.bam \. --examples shardedExamples/examples.tfrecord@2.gz \. --regions regions.bed \. --sample test \. --logdir location/to/place/logfiles. --cores 1. ```. Hope this helps.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/101
https://github.com/google/deepvariant/issues/101:645,testability,log,logdir,645,"Phil and Pi-Chuan;. That's exactly right, `dv_make_examples.py` is a simple wrapper for `make_examples.zip` to make it directly callable and is part of the conda packaging process, not a default script from the Google team. If it's not useful, feel free to call directly at the standard installs, it just tries to avoid needing to know the full install path and other details about the parallelization so the command line syntax is simplified. For your example you'd use it like:. ```. dv_make_examples.py. --ref chr20.fa.gz \. --reads test.bam \. --examples shardedExamples/examples.tfrecord@2.gz \. --regions regions.bed \. --sample test \. --logdir location/to/place/logfiles. --cores 1. ```. Hope this helps.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/101
https://github.com/google/deepvariant/issues/101:670,testability,log,logfiles,670,"Phil and Pi-Chuan;. That's exactly right, `dv_make_examples.py` is a simple wrapper for `make_examples.zip` to make it directly callable and is part of the conda packaging process, not a default script from the Google team. If it's not useful, feel free to call directly at the standard installs, it just tries to avoid needing to know the full install path and other details about the parallelization so the command line syntax is simplified. For your example you'd use it like:. ```. dv_make_examples.py. --ref chr20.fa.gz \. --reads test.bam \. --examples shardedExamples/examples.tfrecord@2.gz \. --regions regions.bed \. --sample test \. --logdir location/to/place/logfiles. --cores 1. ```. Hope this helps.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/101
https://github.com/google/deepvariant/issues/101:69,usability,simpl,simple,69,"Phil and Pi-Chuan;. That's exactly right, `dv_make_examples.py` is a simple wrapper for `make_examples.zip` to make it directly callable and is part of the conda packaging process, not a default script from the Google team. If it's not useful, feel free to call directly at the standard installs, it just tries to avoid needing to know the full install path and other details about the parallelization so the command line syntax is simplified. For your example you'd use it like:. ```. dv_make_examples.py. --ref chr20.fa.gz \. --reads test.bam \. --examples shardedExamples/examples.tfrecord@2.gz \. --regions regions.bed \. --sample test \. --logdir location/to/place/logfiles. --cores 1. ```. Hope this helps.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/101
https://github.com/google/deepvariant/issues/101:409,usability,command,command,409,"Phil and Pi-Chuan;. That's exactly right, `dv_make_examples.py` is a simple wrapper for `make_examples.zip` to make it directly callable and is part of the conda packaging process, not a default script from the Google team. If it's not useful, feel free to call directly at the standard installs, it just tries to avoid needing to know the full install path and other details about the parallelization so the command line syntax is simplified. For your example you'd use it like:. ```. dv_make_examples.py. --ref chr20.fa.gz \. --reads test.bam \. --examples shardedExamples/examples.tfrecord@2.gz \. --regions regions.bed \. --sample test \. --logdir location/to/place/logfiles. --cores 1. ```. Hope this helps.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/101
https://github.com/google/deepvariant/issues/101:432,usability,simpl,simplified,432,"Phil and Pi-Chuan;. That's exactly right, `dv_make_examples.py` is a simple wrapper for `make_examples.zip` to make it directly callable and is part of the conda packaging process, not a default script from the Google team. If it's not useful, feel free to call directly at the standard installs, it just tries to avoid needing to know the full install path and other details about the parallelization so the command line syntax is simplified. For your example you'd use it like:. ```. dv_make_examples.py. --ref chr20.fa.gz \. --reads test.bam \. --examples shardedExamples/examples.tfrecord@2.gz \. --regions regions.bed \. --sample test \. --logdir location/to/place/logfiles. --cores 1. ```. Hope this helps.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/101
https://github.com/google/deepvariant/issues/101:706,usability,help,helps,706,"Phil and Pi-Chuan;. That's exactly right, `dv_make_examples.py` is a simple wrapper for `make_examples.zip` to make it directly callable and is part of the conda packaging process, not a default script from the Google team. If it's not useful, feel free to call directly at the standard installs, it just tries to avoid needing to know the full install path and other details about the parallelization so the command line syntax is simplified. For your example you'd use it like:. ```. dv_make_examples.py. --ref chr20.fa.gz \. --reads test.bam \. --examples shardedExamples/examples.tfrecord@2.gz \. --regions regions.bed \. --sample test \. --logdir location/to/place/logfiles. --cores 1. ```. Hope this helps.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/101
https://github.com/google/deepvariant/issues/102:53,energy efficiency,GPU,GPU,53,"@zyxue Two small questions:. 1) Do you have a NVidia GPU on the machine you are running DeepVariant on? 2) If you type `find / -name ""*libcublas*"" -print 2>/dev/null` on the command prompt, do you see something similar to this:. ```. $ find / -name ""*libcublas*"" -print 2>/dev/null. /opt/apps/cuda75/sdk/7.5.18/doc/man/man7/libcublas.7. /opt/apps/cuda75/sdk/7.5.18/doc/man/man7/libcublas.so.7. /opt/apps/cuda75/sdk/7.5.18/lib64/libcublas_static.a. /opt/apps/cuda75/sdk/7.5.18/lib64/libcublas.so. /opt/apps/cuda75/sdk/7.5.18/lib64/libcublas_device.a. /opt/apps/cuda75/sdk/7.5.18/lib64/libcublas.so.7.5. /opt/apps/cuda75/sdk/7.5.18/lib64/libcublas.so.7.5.18. /opt/apps/cuda75/sdk/7.5.18/lib64/stubs/libcublas.so. $. ```. Thanks,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/102
https://github.com/google/deepvariant/issues/102:691,interoperability,stub,stubs,691,"@zyxue Two small questions:. 1) Do you have a NVidia GPU on the machine you are running DeepVariant on? 2) If you type `find / -name ""*libcublas*"" -print 2>/dev/null` on the command prompt, do you see something similar to this:. ```. $ find / -name ""*libcublas*"" -print 2>/dev/null. /opt/apps/cuda75/sdk/7.5.18/doc/man/man7/libcublas.7. /opt/apps/cuda75/sdk/7.5.18/doc/man/man7/libcublas.so.7. /opt/apps/cuda75/sdk/7.5.18/lib64/libcublas_static.a. /opt/apps/cuda75/sdk/7.5.18/lib64/libcublas.so. /opt/apps/cuda75/sdk/7.5.18/lib64/libcublas_device.a. /opt/apps/cuda75/sdk/7.5.18/lib64/libcublas.so.7.5. /opt/apps/cuda75/sdk/7.5.18/lib64/libcublas.so.7.5.18. /opt/apps/cuda75/sdk/7.5.18/lib64/stubs/libcublas.so. $. ```. Thanks,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/102
https://github.com/google/deepvariant/issues/102:53,performance,GPU,GPU,53,"@zyxue Two small questions:. 1) Do you have a NVidia GPU on the machine you are running DeepVariant on? 2) If you type `find / -name ""*libcublas*"" -print 2>/dev/null` on the command prompt, do you see something similar to this:. ```. $ find / -name ""*libcublas*"" -print 2>/dev/null. /opt/apps/cuda75/sdk/7.5.18/doc/man/man7/libcublas.7. /opt/apps/cuda75/sdk/7.5.18/doc/man/man7/libcublas.so.7. /opt/apps/cuda75/sdk/7.5.18/lib64/libcublas_static.a. /opt/apps/cuda75/sdk/7.5.18/lib64/libcublas.so. /opt/apps/cuda75/sdk/7.5.18/lib64/libcublas_device.a. /opt/apps/cuda75/sdk/7.5.18/lib64/libcublas.so.7.5. /opt/apps/cuda75/sdk/7.5.18/lib64/libcublas.so.7.5.18. /opt/apps/cuda75/sdk/7.5.18/lib64/stubs/libcublas.so. $. ```. Thanks,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/102
https://github.com/google/deepvariant/issues/102:691,testability,stub,stubs,691,"@zyxue Two small questions:. 1) Do you have a NVidia GPU on the machine you are running DeepVariant on? 2) If you type `find / -name ""*libcublas*"" -print 2>/dev/null` on the command prompt, do you see something similar to this:. ```. $ find / -name ""*libcublas*"" -print 2>/dev/null. /opt/apps/cuda75/sdk/7.5.18/doc/man/man7/libcublas.7. /opt/apps/cuda75/sdk/7.5.18/doc/man/man7/libcublas.so.7. /opt/apps/cuda75/sdk/7.5.18/lib64/libcublas_static.a. /opt/apps/cuda75/sdk/7.5.18/lib64/libcublas.so. /opt/apps/cuda75/sdk/7.5.18/lib64/libcublas_device.a. /opt/apps/cuda75/sdk/7.5.18/lib64/libcublas.so.7.5. /opt/apps/cuda75/sdk/7.5.18/lib64/libcublas.so.7.5.18. /opt/apps/cuda75/sdk/7.5.18/lib64/stubs/libcublas.so. $. ```. Thanks,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/102
https://github.com/google/deepvariant/issues/102:174,usability,command,command,174,"@zyxue Two small questions:. 1) Do you have a NVidia GPU on the machine you are running DeepVariant on? 2) If you type `find / -name ""*libcublas*"" -print 2>/dev/null` on the command prompt, do you see something similar to this:. ```. $ find / -name ""*libcublas*"" -print 2>/dev/null. /opt/apps/cuda75/sdk/7.5.18/doc/man/man7/libcublas.7. /opt/apps/cuda75/sdk/7.5.18/doc/man/man7/libcublas.so.7. /opt/apps/cuda75/sdk/7.5.18/lib64/libcublas_static.a. /opt/apps/cuda75/sdk/7.5.18/lib64/libcublas.so. /opt/apps/cuda75/sdk/7.5.18/lib64/libcublas_device.a. /opt/apps/cuda75/sdk/7.5.18/lib64/libcublas.so.7.5. /opt/apps/cuda75/sdk/7.5.18/lib64/libcublas.so.7.5.18. /opt/apps/cuda75/sdk/7.5.18/lib64/stubs/libcublas.so. $. ```. Thanks,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/102
https://github.com/google/deepvariant/issues/102:149,availability,error,error,149,"Yes, I have a GPU. I've made it work with. ```. gcr.io/deepvariant-docker/deepvariant_gpu:0.7.0. ```. But it pops out the `libcublas.so.9.0` related error with my own built (following instruction on https://github.com/google/deepvariant/issues/99#issuecomment-428366972). ```. gcr.io/my_project/deepvariant_gpu:0.7.2. ```.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/102
https://github.com/google/deepvariant/issues/102:14,energy efficiency,GPU,GPU,14,"Yes, I have a GPU. I've made it work with. ```. gcr.io/deepvariant-docker/deepvariant_gpu:0.7.0. ```. But it pops out the `libcublas.so.9.0` related error with my own built (following instruction on https://github.com/google/deepvariant/issues/99#issuecomment-428366972). ```. gcr.io/my_project/deepvariant_gpu:0.7.2. ```.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/102
https://github.com/google/deepvariant/issues/102:14,performance,GPU,GPU,14,"Yes, I have a GPU. I've made it work with. ```. gcr.io/deepvariant-docker/deepvariant_gpu:0.7.0. ```. But it pops out the `libcublas.so.9.0` related error with my own built (following instruction on https://github.com/google/deepvariant/issues/99#issuecomment-428366972). ```. gcr.io/my_project/deepvariant_gpu:0.7.2. ```.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/102
https://github.com/google/deepvariant/issues/102:149,performance,error,error,149,"Yes, I have a GPU. I've made it work with. ```. gcr.io/deepvariant-docker/deepvariant_gpu:0.7.0. ```. But it pops out the `libcublas.so.9.0` related error with my own built (following instruction on https://github.com/google/deepvariant/issues/99#issuecomment-428366972). ```. gcr.io/my_project/deepvariant_gpu:0.7.2. ```.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/102
https://github.com/google/deepvariant/issues/102:149,safety,error,error,149,"Yes, I have a GPU. I've made it work with. ```. gcr.io/deepvariant-docker/deepvariant_gpu:0.7.0. ```. But it pops out the `libcublas.so.9.0` related error with my own built (following instruction on https://github.com/google/deepvariant/issues/99#issuecomment-428366972). ```. gcr.io/my_project/deepvariant_gpu:0.7.2. ```.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/102
https://github.com/google/deepvariant/issues/102:149,usability,error,error,149,"Yes, I have a GPU. I've made it work with. ```. gcr.io/deepvariant-docker/deepvariant_gpu:0.7.0. ```. But it pops out the `libcublas.so.9.0` related error with my own built (following instruction on https://github.com/google/deepvariant/issues/99#issuecomment-428366972). ```. gcr.io/my_project/deepvariant_gpu:0.7.2. ```.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/102
https://github.com/google/deepvariant/issues/102:292,availability,down,download-archive,292,"Right, but which version of the Cuda Toolkit do you have? You can easily install the 9.0 from the link below, but I would do it as a local (non-sudo) user so you sandbox the changes to your environment in order to easily remove them later, if necessary:. https://developer.nvidia.com/cuda-90-download-archive. ~p.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/102
https://github.com/google/deepvariant/issues/102:17,deployability,version,version,17,"Right, but which version of the Cuda Toolkit do you have? You can easily install the 9.0 from the link below, but I would do it as a local (non-sudo) user so you sandbox the changes to your environment in order to easily remove them later, if necessary:. https://developer.nvidia.com/cuda-90-download-archive. ~p.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/102
https://github.com/google/deepvariant/issues/102:73,deployability,instal,install,73,"Right, but which version of the Cuda Toolkit do you have? You can easily install the 9.0 from the link below, but I would do it as a local (non-sudo) user so you sandbox the changes to your environment in order to easily remove them later, if necessary:. https://developer.nvidia.com/cuda-90-download-archive. ~p.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/102
https://github.com/google/deepvariant/issues/102:17,integrability,version,version,17,"Right, but which version of the Cuda Toolkit do you have? You can easily install the 9.0 from the link below, but I would do it as a local (non-sudo) user so you sandbox the changes to your environment in order to easily remove them later, if necessary:. https://developer.nvidia.com/cuda-90-download-archive. ~p.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/102
https://github.com/google/deepvariant/issues/102:17,modifiability,version,version,17,"Right, but which version of the Cuda Toolkit do you have? You can easily install the 9.0 from the link below, but I would do it as a local (non-sudo) user so you sandbox the changes to your environment in order to easily remove them later, if necessary:. https://developer.nvidia.com/cuda-90-download-archive. ~p.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/102
https://github.com/google/deepvariant/issues/102:162,security,sandbox,sandbox,162,"Right, but which version of the Cuda Toolkit do you have? You can easily install the 9.0 from the link below, but I would do it as a local (non-sudo) user so you sandbox the changes to your environment in order to easily remove them later, if necessary:. https://developer.nvidia.com/cuda-90-download-archive. ~p.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/102
https://github.com/google/deepvariant/issues/102:37,usability,Tool,Toolkit,37,"Right, but which version of the Cuda Toolkit do you have? You can easily install the 9.0 from the link below, but I would do it as a local (non-sudo) user so you sandbox the changes to your environment in order to easily remove them later, if necessary:. https://developer.nvidia.com/cuda-90-download-archive. ~p.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/102
https://github.com/google/deepvariant/issues/102:150,usability,user,user,150,"Right, but which version of the Cuda Toolkit do you have? You can easily install the 9.0 from the link below, but I would do it as a local (non-sudo) user so you sandbox the changes to your environment in order to easily remove them later, if necessary:. https://developer.nvidia.com/cuda-90-download-archive. ~p.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/102
https://github.com/google/deepvariant/issues/102:2,deployability,instal,installed,2,"I installed CUDA-9.0 based on instruction here, https://cloud.google.com/compute/docs/gpus/add-gpus#install-driver-script. and nvidia-docker based on instruction here, https://github.com/NVIDIA/nvidia-docker#ubuntu-140416041804-debian-jessiestretch. I am on a Ubuntu-16.04 GCE box. Sorry, there was a typo in my previous comment, corrected it.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/102
https://github.com/google/deepvariant/issues/102:100,deployability,instal,install-driver-script,100,"I installed CUDA-9.0 based on instruction here, https://cloud.google.com/compute/docs/gpus/add-gpus#install-driver-script. and nvidia-docker based on instruction here, https://github.com/NVIDIA/nvidia-docker#ubuntu-140416041804-debian-jessiestretch. I am on a Ubuntu-16.04 GCE box. Sorry, there was a typo in my previous comment, corrected it.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/102
https://github.com/google/deepvariant/issues/102:56,energy efficiency,cloud,cloud,56,"I installed CUDA-9.0 based on instruction here, https://cloud.google.com/compute/docs/gpus/add-gpus#install-driver-script. and nvidia-docker based on instruction here, https://github.com/NVIDIA/nvidia-docker#ubuntu-140416041804-debian-jessiestretch. I am on a Ubuntu-16.04 GCE box. Sorry, there was a typo in my previous comment, corrected it.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/102
https://github.com/google/deepvariant/issues/102:86,energy efficiency,gpu,gpus,86,"I installed CUDA-9.0 based on instruction here, https://cloud.google.com/compute/docs/gpus/add-gpus#install-driver-script. and nvidia-docker based on instruction here, https://github.com/NVIDIA/nvidia-docker#ubuntu-140416041804-debian-jessiestretch. I am on a Ubuntu-16.04 GCE box. Sorry, there was a typo in my previous comment, corrected it.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/102
https://github.com/google/deepvariant/issues/102:95,energy efficiency,gpu,gpus,95,"I installed CUDA-9.0 based on instruction here, https://cloud.google.com/compute/docs/gpus/add-gpus#install-driver-script. and nvidia-docker based on instruction here, https://github.com/NVIDIA/nvidia-docker#ubuntu-140416041804-debian-jessiestretch. I am on a Ubuntu-16.04 GCE box. Sorry, there was a typo in my previous comment, corrected it.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/102
https://github.com/google/deepvariant/issues/102:86,performance,gpu,gpus,86,"I installed CUDA-9.0 based on instruction here, https://cloud.google.com/compute/docs/gpus/add-gpus#install-driver-script. and nvidia-docker based on instruction here, https://github.com/NVIDIA/nvidia-docker#ubuntu-140416041804-debian-jessiestretch. I am on a Ubuntu-16.04 GCE box. Sorry, there was a typo in my previous comment, corrected it.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/102
https://github.com/google/deepvariant/issues/102:95,performance,gpu,gpus,95,"I installed CUDA-9.0 based on instruction here, https://cloud.google.com/compute/docs/gpus/add-gpus#install-driver-script. and nvidia-docker based on instruction here, https://github.com/NVIDIA/nvidia-docker#ubuntu-140416041804-debian-jessiestretch. I am on a Ubuntu-16.04 GCE box. Sorry, there was a typo in my previous comment, corrected it.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/102
https://github.com/google/deepvariant/issues/102:51,availability,echo,echo,51,"Could you please run the following commands:. ```. echo $LD_LIBRARY_PATH. echo $PATH. ```. And also paste the path of where `libcublas.so.9.0` actually resides. Then we can patch the paths appropriately. Thanks,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/102
https://github.com/google/deepvariant/issues/102:74,availability,echo,echo,74,"Could you please run the following commands:. ```. echo $LD_LIBRARY_PATH. echo $PATH. ```. And also paste the path of where `libcublas.so.9.0` actually resides. Then we can patch the paths appropriately. Thanks,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/102
https://github.com/google/deepvariant/issues/102:173,deployability,patch,patch,173,"Could you please run the following commands:. ```. echo $LD_LIBRARY_PATH. echo $PATH. ```. And also paste the path of where `libcublas.so.9.0` actually resides. Then we can patch the paths appropriately. Thanks,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/102
https://github.com/google/deepvariant/issues/102:173,safety,patch,patch,173,"Could you please run the following commands:. ```. echo $LD_LIBRARY_PATH. echo $PATH. ```. And also paste the path of where `libcublas.so.9.0` actually resides. Then we can patch the paths appropriately. Thanks,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/102
https://github.com/google/deepvariant/issues/102:173,security,patch,patch,173,"Could you please run the following commands:. ```. echo $LD_LIBRARY_PATH. echo $PATH. ```. And also paste the path of where `libcublas.so.9.0` actually resides. Then we can patch the paths appropriately. Thanks,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/102
https://github.com/google/deepvariant/issues/102:35,usability,command,commands,35,"Could you please run the following commands:. ```. echo $LD_LIBRARY_PATH. echo $PATH. ```. And also paste the path of where `libcublas.so.9.0` actually resides. Then we can patch the paths appropriately. Thanks,. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/102
https://github.com/google/deepvariant/issues/102:65,deployability,updat,updates,65,Closing because of inactivity. Feel free to open again with more updates.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/102
https://github.com/google/deepvariant/issues/102:65,safety,updat,updates,65,Closing because of inactivity. Feel free to open again with more updates.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/102
https://github.com/google/deepvariant/issues/102:65,security,updat,updates,65,Closing because of inactivity. Feel free to open again with more updates.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/102
https://github.com/google/deepvariant/issues/103:415,deployability,version,version,415,"@zyxue Before we get to parallelizable, we need to be a bit invasive to determine what's happening. A caution, this will get complex and a bit extensive, so don't get scared. 1) First start your session interactive like this - notice the `-it` option:. ` sudo docker run -it -v ${HOME}:${HOME} gcr.io/deepvariant-docker/deepvariant:0.7.0 /bin/bash`. Then go to your deepvariant directory and unzip, as the compiled version is just a call to that:. ```. paul:~$ sudo docker run -it -v ${HOME}:${HOME} gcr.io/deepvariant-docker/deepvariant:0.7.0 /bin/bash. root@c2b850869dc6:/# cd /opt/deepvariant/bin/. root@c2b850869dc6:/opt/deepvariant/bin# mkdir unzip-post. root@c2b850869dc6:/opt/deepvariant/bin# cd unzip-post/. root@c2b850869dc6:/opt/deepvariant/bin/unzip-post# unzip ../postprocess_variants.zip. Archive: ../postprocess_variants.zip. inflating: __main__.py. extracting: __init__.py. ... root@c2b850869dc6:/opt/deepvariant/bin/unzip-post#. ```. 2) Next switch to the location of the Python file and run it with a trace as follows - I removed the prompt entry and left a `#` so that you see the commands:. ```. # cd runfiles/com_google_deepvariant/deepvariant/. # python -mtrace --trackcalls postprocess_variants.py YOUR_ARGUMENTS_WITH_FULL_PATHS. ```. The `YOUR_ARGUMENTS_WITH_FULL_PATHS` is the arguments with absolute paths. Then just print out the output of the trace here, in order to see where it might be getting stuck. Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/103
https://github.com/google/deepvariant/issues/103:415,integrability,version,version,415,"@zyxue Before we get to parallelizable, we need to be a bit invasive to determine what's happening. A caution, this will get complex and a bit extensive, so don't get scared. 1) First start your session interactive like this - notice the `-it` option:. ` sudo docker run -it -v ${HOME}:${HOME} gcr.io/deepvariant-docker/deepvariant:0.7.0 /bin/bash`. Then go to your deepvariant directory and unzip, as the compiled version is just a call to that:. ```. paul:~$ sudo docker run -it -v ${HOME}:${HOME} gcr.io/deepvariant-docker/deepvariant:0.7.0 /bin/bash. root@c2b850869dc6:/# cd /opt/deepvariant/bin/. root@c2b850869dc6:/opt/deepvariant/bin# mkdir unzip-post. root@c2b850869dc6:/opt/deepvariant/bin# cd unzip-post/. root@c2b850869dc6:/opt/deepvariant/bin/unzip-post# unzip ../postprocess_variants.zip. Archive: ../postprocess_variants.zip. inflating: __main__.py. extracting: __init__.py. ... root@c2b850869dc6:/opt/deepvariant/bin/unzip-post#. ```. 2) Next switch to the location of the Python file and run it with a trace as follows - I removed the prompt entry and left a `#` so that you see the commands:. ```. # cd runfiles/com_google_deepvariant/deepvariant/. # python -mtrace --trackcalls postprocess_variants.py YOUR_ARGUMENTS_WITH_FULL_PATHS. ```. The `YOUR_ARGUMENTS_WITH_FULL_PATHS` is the arguments with absolute paths. Then just print out the output of the trace here, in order to see where it might be getting stuck. Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/103
https://github.com/google/deepvariant/issues/103:143,modifiability,extens,extensive,143,"@zyxue Before we get to parallelizable, we need to be a bit invasive to determine what's happening. A caution, this will get complex and a bit extensive, so don't get scared. 1) First start your session interactive like this - notice the `-it` option:. ` sudo docker run -it -v ${HOME}:${HOME} gcr.io/deepvariant-docker/deepvariant:0.7.0 /bin/bash`. Then go to your deepvariant directory and unzip, as the compiled version is just a call to that:. ```. paul:~$ sudo docker run -it -v ${HOME}:${HOME} gcr.io/deepvariant-docker/deepvariant:0.7.0 /bin/bash. root@c2b850869dc6:/# cd /opt/deepvariant/bin/. root@c2b850869dc6:/opt/deepvariant/bin# mkdir unzip-post. root@c2b850869dc6:/opt/deepvariant/bin# cd unzip-post/. root@c2b850869dc6:/opt/deepvariant/bin/unzip-post# unzip ../postprocess_variants.zip. Archive: ../postprocess_variants.zip. inflating: __main__.py. extracting: __init__.py. ... root@c2b850869dc6:/opt/deepvariant/bin/unzip-post#. ```. 2) Next switch to the location of the Python file and run it with a trace as follows - I removed the prompt entry and left a `#` so that you see the commands:. ```. # cd runfiles/com_google_deepvariant/deepvariant/. # python -mtrace --trackcalls postprocess_variants.py YOUR_ARGUMENTS_WITH_FULL_PATHS. ```. The `YOUR_ARGUMENTS_WITH_FULL_PATHS` is the arguments with absolute paths. Then just print out the output of the trace here, in order to see where it might be getting stuck. Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/103
https://github.com/google/deepvariant/issues/103:415,modifiability,version,version,415,"@zyxue Before we get to parallelizable, we need to be a bit invasive to determine what's happening. A caution, this will get complex and a bit extensive, so don't get scared. 1) First start your session interactive like this - notice the `-it` option:. ` sudo docker run -it -v ${HOME}:${HOME} gcr.io/deepvariant-docker/deepvariant:0.7.0 /bin/bash`. Then go to your deepvariant directory and unzip, as the compiled version is just a call to that:. ```. paul:~$ sudo docker run -it -v ${HOME}:${HOME} gcr.io/deepvariant-docker/deepvariant:0.7.0 /bin/bash. root@c2b850869dc6:/# cd /opt/deepvariant/bin/. root@c2b850869dc6:/opt/deepvariant/bin# mkdir unzip-post. root@c2b850869dc6:/opt/deepvariant/bin# cd unzip-post/. root@c2b850869dc6:/opt/deepvariant/bin/unzip-post# unzip ../postprocess_variants.zip. Archive: ../postprocess_variants.zip. inflating: __main__.py. extracting: __init__.py. ... root@c2b850869dc6:/opt/deepvariant/bin/unzip-post#. ```. 2) Next switch to the location of the Python file and run it with a trace as follows - I removed the prompt entry and left a `#` so that you see the commands:. ```. # cd runfiles/com_google_deepvariant/deepvariant/. # python -mtrace --trackcalls postprocess_variants.py YOUR_ARGUMENTS_WITH_FULL_PATHS. ```. The `YOUR_ARGUMENTS_WITH_FULL_PATHS` is the arguments with absolute paths. Then just print out the output of the trace here, in order to see where it might be getting stuck. Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/103
https://github.com/google/deepvariant/issues/103:24,performance,parallel,parallelizable,24,"@zyxue Before we get to parallelizable, we need to be a bit invasive to determine what's happening. A caution, this will get complex and a bit extensive, so don't get scared. 1) First start your session interactive like this - notice the `-it` option:. ` sudo docker run -it -v ${HOME}:${HOME} gcr.io/deepvariant-docker/deepvariant:0.7.0 /bin/bash`. Then go to your deepvariant directory and unzip, as the compiled version is just a call to that:. ```. paul:~$ sudo docker run -it -v ${HOME}:${HOME} gcr.io/deepvariant-docker/deepvariant:0.7.0 /bin/bash. root@c2b850869dc6:/# cd /opt/deepvariant/bin/. root@c2b850869dc6:/opt/deepvariant/bin# mkdir unzip-post. root@c2b850869dc6:/opt/deepvariant/bin# cd unzip-post/. root@c2b850869dc6:/opt/deepvariant/bin/unzip-post# unzip ../postprocess_variants.zip. Archive: ../postprocess_variants.zip. inflating: __main__.py. extracting: __init__.py. ... root@c2b850869dc6:/opt/deepvariant/bin/unzip-post#. ```. 2) Next switch to the location of the Python file and run it with a trace as follows - I removed the prompt entry and left a `#` so that you see the commands:. ```. # cd runfiles/com_google_deepvariant/deepvariant/. # python -mtrace --trackcalls postprocess_variants.py YOUR_ARGUMENTS_WITH_FULL_PATHS. ```. The `YOUR_ARGUMENTS_WITH_FULL_PATHS` is the arguments with absolute paths. Then just print out the output of the trace here, in order to see where it might be getting stuck. Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/103
https://github.com/google/deepvariant/issues/103:125,safety,compl,complex,125,"@zyxue Before we get to parallelizable, we need to be a bit invasive to determine what's happening. A caution, this will get complex and a bit extensive, so don't get scared. 1) First start your session interactive like this - notice the `-it` option:. ` sudo docker run -it -v ${HOME}:${HOME} gcr.io/deepvariant-docker/deepvariant:0.7.0 /bin/bash`. Then go to your deepvariant directory and unzip, as the compiled version is just a call to that:. ```. paul:~$ sudo docker run -it -v ${HOME}:${HOME} gcr.io/deepvariant-docker/deepvariant:0.7.0 /bin/bash. root@c2b850869dc6:/# cd /opt/deepvariant/bin/. root@c2b850869dc6:/opt/deepvariant/bin# mkdir unzip-post. root@c2b850869dc6:/opt/deepvariant/bin# cd unzip-post/. root@c2b850869dc6:/opt/deepvariant/bin/unzip-post# unzip ../postprocess_variants.zip. Archive: ../postprocess_variants.zip. inflating: __main__.py. extracting: __init__.py. ... root@c2b850869dc6:/opt/deepvariant/bin/unzip-post#. ```. 2) Next switch to the location of the Python file and run it with a trace as follows - I removed the prompt entry and left a `#` so that you see the commands:. ```. # cd runfiles/com_google_deepvariant/deepvariant/. # python -mtrace --trackcalls postprocess_variants.py YOUR_ARGUMENTS_WITH_FULL_PATHS. ```. The `YOUR_ARGUMENTS_WITH_FULL_PATHS` is the arguments with absolute paths. Then just print out the output of the trace here, in order to see where it might be getting stuck. Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/103
https://github.com/google/deepvariant/issues/103:125,security,compl,complex,125,"@zyxue Before we get to parallelizable, we need to be a bit invasive to determine what's happening. A caution, this will get complex and a bit extensive, so don't get scared. 1) First start your session interactive like this - notice the `-it` option:. ` sudo docker run -it -v ${HOME}:${HOME} gcr.io/deepvariant-docker/deepvariant:0.7.0 /bin/bash`. Then go to your deepvariant directory and unzip, as the compiled version is just a call to that:. ```. paul:~$ sudo docker run -it -v ${HOME}:${HOME} gcr.io/deepvariant-docker/deepvariant:0.7.0 /bin/bash. root@c2b850869dc6:/# cd /opt/deepvariant/bin/. root@c2b850869dc6:/opt/deepvariant/bin# mkdir unzip-post. root@c2b850869dc6:/opt/deepvariant/bin# cd unzip-post/. root@c2b850869dc6:/opt/deepvariant/bin/unzip-post# unzip ../postprocess_variants.zip. Archive: ../postprocess_variants.zip. inflating: __main__.py. extracting: __init__.py. ... root@c2b850869dc6:/opt/deepvariant/bin/unzip-post#. ```. 2) Next switch to the location of the Python file and run it with a trace as follows - I removed the prompt entry and left a `#` so that you see the commands:. ```. # cd runfiles/com_google_deepvariant/deepvariant/. # python -mtrace --trackcalls postprocess_variants.py YOUR_ARGUMENTS_WITH_FULL_PATHS. ```. The `YOUR_ARGUMENTS_WITH_FULL_PATHS` is the arguments with absolute paths. Then just print out the output of the trace here, in order to see where it might be getting stuck. Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/103
https://github.com/google/deepvariant/issues/103:195,security,session,session,195,"@zyxue Before we get to parallelizable, we need to be a bit invasive to determine what's happening. A caution, this will get complex and a bit extensive, so don't get scared. 1) First start your session interactive like this - notice the `-it` option:. ` sudo docker run -it -v ${HOME}:${HOME} gcr.io/deepvariant-docker/deepvariant:0.7.0 /bin/bash`. Then go to your deepvariant directory and unzip, as the compiled version is just a call to that:. ```. paul:~$ sudo docker run -it -v ${HOME}:${HOME} gcr.io/deepvariant-docker/deepvariant:0.7.0 /bin/bash. root@c2b850869dc6:/# cd /opt/deepvariant/bin/. root@c2b850869dc6:/opt/deepvariant/bin# mkdir unzip-post. root@c2b850869dc6:/opt/deepvariant/bin# cd unzip-post/. root@c2b850869dc6:/opt/deepvariant/bin/unzip-post# unzip ../postprocess_variants.zip. Archive: ../postprocess_variants.zip. inflating: __main__.py. extracting: __init__.py. ... root@c2b850869dc6:/opt/deepvariant/bin/unzip-post#. ```. 2) Next switch to the location of the Python file and run it with a trace as follows - I removed the prompt entry and left a `#` so that you see the commands:. ```. # cd runfiles/com_google_deepvariant/deepvariant/. # python -mtrace --trackcalls postprocess_variants.py YOUR_ARGUMENTS_WITH_FULL_PATHS. ```. The `YOUR_ARGUMENTS_WITH_FULL_PATHS` is the arguments with absolute paths. Then just print out the output of the trace here, in order to see where it might be getting stuck. Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/103
https://github.com/google/deepvariant/issues/103:1018,testability,trace,trace,1018,"@zyxue Before we get to parallelizable, we need to be a bit invasive to determine what's happening. A caution, this will get complex and a bit extensive, so don't get scared. 1) First start your session interactive like this - notice the `-it` option:. ` sudo docker run -it -v ${HOME}:${HOME} gcr.io/deepvariant-docker/deepvariant:0.7.0 /bin/bash`. Then go to your deepvariant directory and unzip, as the compiled version is just a call to that:. ```. paul:~$ sudo docker run -it -v ${HOME}:${HOME} gcr.io/deepvariant-docker/deepvariant:0.7.0 /bin/bash. root@c2b850869dc6:/# cd /opt/deepvariant/bin/. root@c2b850869dc6:/opt/deepvariant/bin# mkdir unzip-post. root@c2b850869dc6:/opt/deepvariant/bin# cd unzip-post/. root@c2b850869dc6:/opt/deepvariant/bin/unzip-post# unzip ../postprocess_variants.zip. Archive: ../postprocess_variants.zip. inflating: __main__.py. extracting: __init__.py. ... root@c2b850869dc6:/opt/deepvariant/bin/unzip-post#. ```. 2) Next switch to the location of the Python file and run it with a trace as follows - I removed the prompt entry and left a `#` so that you see the commands:. ```. # cd runfiles/com_google_deepvariant/deepvariant/. # python -mtrace --trackcalls postprocess_variants.py YOUR_ARGUMENTS_WITH_FULL_PATHS. ```. The `YOUR_ARGUMENTS_WITH_FULL_PATHS` is the arguments with absolute paths. Then just print out the output of the trace here, in order to see where it might be getting stuck. Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/103
https://github.com/google/deepvariant/issues/103:1370,testability,trace,trace,1370,"@zyxue Before we get to parallelizable, we need to be a bit invasive to determine what's happening. A caution, this will get complex and a bit extensive, so don't get scared. 1) First start your session interactive like this - notice the `-it` option:. ` sudo docker run -it -v ${HOME}:${HOME} gcr.io/deepvariant-docker/deepvariant:0.7.0 /bin/bash`. Then go to your deepvariant directory and unzip, as the compiled version is just a call to that:. ```. paul:~$ sudo docker run -it -v ${HOME}:${HOME} gcr.io/deepvariant-docker/deepvariant:0.7.0 /bin/bash. root@c2b850869dc6:/# cd /opt/deepvariant/bin/. root@c2b850869dc6:/opt/deepvariant/bin# mkdir unzip-post. root@c2b850869dc6:/opt/deepvariant/bin# cd unzip-post/. root@c2b850869dc6:/opt/deepvariant/bin/unzip-post# unzip ../postprocess_variants.zip. Archive: ../postprocess_variants.zip. inflating: __main__.py. extracting: __init__.py. ... root@c2b850869dc6:/opt/deepvariant/bin/unzip-post#. ```. 2) Next switch to the location of the Python file and run it with a trace as follows - I removed the prompt entry and left a `#` so that you see the commands:. ```. # cd runfiles/com_google_deepvariant/deepvariant/. # python -mtrace --trackcalls postprocess_variants.py YOUR_ARGUMENTS_WITH_FULL_PATHS. ```. The `YOUR_ARGUMENTS_WITH_FULL_PATHS` is the arguments with absolute paths. Then just print out the output of the trace here, in order to see where it might be getting stuck. Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/103
https://github.com/google/deepvariant/issues/103:203,usability,interact,interactive,203,"@zyxue Before we get to parallelizable, we need to be a bit invasive to determine what's happening. A caution, this will get complex and a bit extensive, so don't get scared. 1) First start your session interactive like this - notice the `-it` option:. ` sudo docker run -it -v ${HOME}:${HOME} gcr.io/deepvariant-docker/deepvariant:0.7.0 /bin/bash`. Then go to your deepvariant directory and unzip, as the compiled version is just a call to that:. ```. paul:~$ sudo docker run -it -v ${HOME}:${HOME} gcr.io/deepvariant-docker/deepvariant:0.7.0 /bin/bash. root@c2b850869dc6:/# cd /opt/deepvariant/bin/. root@c2b850869dc6:/opt/deepvariant/bin# mkdir unzip-post. root@c2b850869dc6:/opt/deepvariant/bin# cd unzip-post/. root@c2b850869dc6:/opt/deepvariant/bin/unzip-post# unzip ../postprocess_variants.zip. Archive: ../postprocess_variants.zip. inflating: __main__.py. extracting: __init__.py. ... root@c2b850869dc6:/opt/deepvariant/bin/unzip-post#. ```. 2) Next switch to the location of the Python file and run it with a trace as follows - I removed the prompt entry and left a `#` so that you see the commands:. ```. # cd runfiles/com_google_deepvariant/deepvariant/. # python -mtrace --trackcalls postprocess_variants.py YOUR_ARGUMENTS_WITH_FULL_PATHS. ```. The `YOUR_ARGUMENTS_WITH_FULL_PATHS` is the arguments with absolute paths. Then just print out the output of the trace here, in order to see where it might be getting stuck. Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/103
https://github.com/google/deepvariant/issues/103:1099,usability,command,commands,1099,"@zyxue Before we get to parallelizable, we need to be a bit invasive to determine what's happening. A caution, this will get complex and a bit extensive, so don't get scared. 1) First start your session interactive like this - notice the `-it` option:. ` sudo docker run -it -v ${HOME}:${HOME} gcr.io/deepvariant-docker/deepvariant:0.7.0 /bin/bash`. Then go to your deepvariant directory and unzip, as the compiled version is just a call to that:. ```. paul:~$ sudo docker run -it -v ${HOME}:${HOME} gcr.io/deepvariant-docker/deepvariant:0.7.0 /bin/bash. root@c2b850869dc6:/# cd /opt/deepvariant/bin/. root@c2b850869dc6:/opt/deepvariant/bin# mkdir unzip-post. root@c2b850869dc6:/opt/deepvariant/bin# cd unzip-post/. root@c2b850869dc6:/opt/deepvariant/bin/unzip-post# unzip ../postprocess_variants.zip. Archive: ../postprocess_variants.zip. inflating: __main__.py. extracting: __init__.py. ... root@c2b850869dc6:/opt/deepvariant/bin/unzip-post#. ```. 2) Next switch to the location of the Python file and run it with a trace as follows - I removed the prompt entry and left a `#` so that you see the commands:. ```. # cd runfiles/com_google_deepvariant/deepvariant/. # python -mtrace --trackcalls postprocess_variants.py YOUR_ARGUMENTS_WITH_FULL_PATHS. ```. The `YOUR_ARGUMENTS_WITH_FULL_PATHS` is the arguments with absolute paths. Then just print out the output of the trace here, in order to see where it might be getting stuck. Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/103
https://github.com/google/deepvariant/issues/103:28,availability,slo,slow,28,"The start seems to be quite slow, after about 27s it exits, here is the output. ```. root@52e2e7bb0093:/opt/deepvariant/bin/unzip-post/runfiles/com_google_deepvariant/deepvariant# time python -mtrace --trackcalls postprocess_variants.py --ref /home/zxue/deepvariant_exp/tcga-data/hg19.fa --infile /home/zxue/deepvariant_exp/output/cvo.tfrecord.gz . --outfile /home/zxue/deepvariant_exp/output/output.vcf.gz --nonvariant_site_tfrecord_path /home/zxue/deepvariant_exp/output/gvcf.tfrecord@8.gz . Traceback (most recent call last):. File ""/usr/lib/python2.7/runpy.py"", line 174, in _run_module_as_main. ""__main__"", fname, loader, pkg_name). File ""/usr/lib/python2.7/runpy.py"", line 72, in _run_code. exec code in run_globals. File ""/usr/lib/python2.7/trace.py"", line 819, in <module>. main(). File ""/usr/lib/python2.7/trace.py"", line 807, in main. t.runctx(code, globs, globs). File ""/usr/lib/python2.7/trace.py"", line 513, in runctx. exec cmd in globals, locals. File ""postprocess_variants.py"", line 46, in <module>. from third_party.nucleus.io import fasta. ImportError: No module named third_party.nucleus.io. real 0m27.273s. user 0m27.133s. sys 0m0.904s. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/103
https://github.com/google/deepvariant/issues/103:619,deployability,loader,loader,619,"The start seems to be quite slow, after about 27s it exits, here is the output. ```. root@52e2e7bb0093:/opt/deepvariant/bin/unzip-post/runfiles/com_google_deepvariant/deepvariant# time python -mtrace --trackcalls postprocess_variants.py --ref /home/zxue/deepvariant_exp/tcga-data/hg19.fa --infile /home/zxue/deepvariant_exp/output/cvo.tfrecord.gz . --outfile /home/zxue/deepvariant_exp/output/output.vcf.gz --nonvariant_site_tfrecord_path /home/zxue/deepvariant_exp/output/gvcf.tfrecord@8.gz . Traceback (most recent call last):. File ""/usr/lib/python2.7/runpy.py"", line 174, in _run_module_as_main. ""__main__"", fname, loader, pkg_name). File ""/usr/lib/python2.7/runpy.py"", line 72, in _run_code. exec code in run_globals. File ""/usr/lib/python2.7/trace.py"", line 819, in <module>. main(). File ""/usr/lib/python2.7/trace.py"", line 807, in main. t.runctx(code, globs, globs). File ""/usr/lib/python2.7/trace.py"", line 513, in runctx. exec cmd in globals, locals. File ""postprocess_variants.py"", line 46, in <module>. from third_party.nucleus.io import fasta. ImportError: No module named third_party.nucleus.io. real 0m27.273s. user 0m27.133s. sys 0m0.904s. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/103
https://github.com/google/deepvariant/issues/103:773,deployability,modul,module,773,"The start seems to be quite slow, after about 27s it exits, here is the output. ```. root@52e2e7bb0093:/opt/deepvariant/bin/unzip-post/runfiles/com_google_deepvariant/deepvariant# time python -mtrace --trackcalls postprocess_variants.py --ref /home/zxue/deepvariant_exp/tcga-data/hg19.fa --infile /home/zxue/deepvariant_exp/output/cvo.tfrecord.gz . --outfile /home/zxue/deepvariant_exp/output/output.vcf.gz --nonvariant_site_tfrecord_path /home/zxue/deepvariant_exp/output/gvcf.tfrecord@8.gz . Traceback (most recent call last):. File ""/usr/lib/python2.7/runpy.py"", line 174, in _run_module_as_main. ""__main__"", fname, loader, pkg_name). File ""/usr/lib/python2.7/runpy.py"", line 72, in _run_code. exec code in run_globals. File ""/usr/lib/python2.7/trace.py"", line 819, in <module>. main(). File ""/usr/lib/python2.7/trace.py"", line 807, in main. t.runctx(code, globs, globs). File ""/usr/lib/python2.7/trace.py"", line 513, in runctx. exec cmd in globals, locals. File ""postprocess_variants.py"", line 46, in <module>. from third_party.nucleus.io import fasta. ImportError: No module named third_party.nucleus.io. real 0m27.273s. user 0m27.133s. sys 0m0.904s. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/103
https://github.com/google/deepvariant/issues/103:1006,deployability,modul,module,1006,"The start seems to be quite slow, after about 27s it exits, here is the output. ```. root@52e2e7bb0093:/opt/deepvariant/bin/unzip-post/runfiles/com_google_deepvariant/deepvariant# time python -mtrace --trackcalls postprocess_variants.py --ref /home/zxue/deepvariant_exp/tcga-data/hg19.fa --infile /home/zxue/deepvariant_exp/output/cvo.tfrecord.gz . --outfile /home/zxue/deepvariant_exp/output/output.vcf.gz --nonvariant_site_tfrecord_path /home/zxue/deepvariant_exp/output/gvcf.tfrecord@8.gz . Traceback (most recent call last):. File ""/usr/lib/python2.7/runpy.py"", line 174, in _run_module_as_main. ""__main__"", fname, loader, pkg_name). File ""/usr/lib/python2.7/runpy.py"", line 72, in _run_code. exec code in run_globals. File ""/usr/lib/python2.7/trace.py"", line 819, in <module>. main(). File ""/usr/lib/python2.7/trace.py"", line 807, in main. t.runctx(code, globs, globs). File ""/usr/lib/python2.7/trace.py"", line 513, in runctx. exec cmd in globals, locals. File ""postprocess_variants.py"", line 46, in <module>. from third_party.nucleus.io import fasta. ImportError: No module named third_party.nucleus.io. real 0m27.273s. user 0m27.133s. sys 0m0.904s. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/103
https://github.com/google/deepvariant/issues/103:1073,deployability,modul,module,1073,"The start seems to be quite slow, after about 27s it exits, here is the output. ```. root@52e2e7bb0093:/opt/deepvariant/bin/unzip-post/runfiles/com_google_deepvariant/deepvariant# time python -mtrace --trackcalls postprocess_variants.py --ref /home/zxue/deepvariant_exp/tcga-data/hg19.fa --infile /home/zxue/deepvariant_exp/output/cvo.tfrecord.gz . --outfile /home/zxue/deepvariant_exp/output/output.vcf.gz --nonvariant_site_tfrecord_path /home/zxue/deepvariant_exp/output/gvcf.tfrecord@8.gz . Traceback (most recent call last):. File ""/usr/lib/python2.7/runpy.py"", line 174, in _run_module_as_main. ""__main__"", fname, loader, pkg_name). File ""/usr/lib/python2.7/runpy.py"", line 72, in _run_code. exec code in run_globals. File ""/usr/lib/python2.7/trace.py"", line 819, in <module>. main(). File ""/usr/lib/python2.7/trace.py"", line 807, in main. t.runctx(code, globs, globs). File ""/usr/lib/python2.7/trace.py"", line 513, in runctx. exec cmd in globals, locals. File ""postprocess_variants.py"", line 46, in <module>. from third_party.nucleus.io import fasta. ImportError: No module named third_party.nucleus.io. real 0m27.273s. user 0m27.133s. sys 0m0.904s. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/103
https://github.com/google/deepvariant/issues/103:619,energy efficiency,load,loader,619,"The start seems to be quite slow, after about 27s it exits, here is the output. ```. root@52e2e7bb0093:/opt/deepvariant/bin/unzip-post/runfiles/com_google_deepvariant/deepvariant# time python -mtrace --trackcalls postprocess_variants.py --ref /home/zxue/deepvariant_exp/tcga-data/hg19.fa --infile /home/zxue/deepvariant_exp/output/cvo.tfrecord.gz . --outfile /home/zxue/deepvariant_exp/output/output.vcf.gz --nonvariant_site_tfrecord_path /home/zxue/deepvariant_exp/output/gvcf.tfrecord@8.gz . Traceback (most recent call last):. File ""/usr/lib/python2.7/runpy.py"", line 174, in _run_module_as_main. ""__main__"", fname, loader, pkg_name). File ""/usr/lib/python2.7/runpy.py"", line 72, in _run_code. exec code in run_globals. File ""/usr/lib/python2.7/trace.py"", line 819, in <module>. main(). File ""/usr/lib/python2.7/trace.py"", line 807, in main. t.runctx(code, globs, globs). File ""/usr/lib/python2.7/trace.py"", line 513, in runctx. exec cmd in globals, locals. File ""postprocess_variants.py"", line 46, in <module>. from third_party.nucleus.io import fasta. ImportError: No module named third_party.nucleus.io. real 0m27.273s. user 0m27.133s. sys 0m0.904s. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/103
https://github.com/google/deepvariant/issues/103:773,modifiability,modul,module,773,"The start seems to be quite slow, after about 27s it exits, here is the output. ```. root@52e2e7bb0093:/opt/deepvariant/bin/unzip-post/runfiles/com_google_deepvariant/deepvariant# time python -mtrace --trackcalls postprocess_variants.py --ref /home/zxue/deepvariant_exp/tcga-data/hg19.fa --infile /home/zxue/deepvariant_exp/output/cvo.tfrecord.gz . --outfile /home/zxue/deepvariant_exp/output/output.vcf.gz --nonvariant_site_tfrecord_path /home/zxue/deepvariant_exp/output/gvcf.tfrecord@8.gz . Traceback (most recent call last):. File ""/usr/lib/python2.7/runpy.py"", line 174, in _run_module_as_main. ""__main__"", fname, loader, pkg_name). File ""/usr/lib/python2.7/runpy.py"", line 72, in _run_code. exec code in run_globals. File ""/usr/lib/python2.7/trace.py"", line 819, in <module>. main(). File ""/usr/lib/python2.7/trace.py"", line 807, in main. t.runctx(code, globs, globs). File ""/usr/lib/python2.7/trace.py"", line 513, in runctx. exec cmd in globals, locals. File ""postprocess_variants.py"", line 46, in <module>. from third_party.nucleus.io import fasta. ImportError: No module named third_party.nucleus.io. real 0m27.273s. user 0m27.133s. sys 0m0.904s. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/103
https://github.com/google/deepvariant/issues/103:1006,modifiability,modul,module,1006,"The start seems to be quite slow, after about 27s it exits, here is the output. ```. root@52e2e7bb0093:/opt/deepvariant/bin/unzip-post/runfiles/com_google_deepvariant/deepvariant# time python -mtrace --trackcalls postprocess_variants.py --ref /home/zxue/deepvariant_exp/tcga-data/hg19.fa --infile /home/zxue/deepvariant_exp/output/cvo.tfrecord.gz . --outfile /home/zxue/deepvariant_exp/output/output.vcf.gz --nonvariant_site_tfrecord_path /home/zxue/deepvariant_exp/output/gvcf.tfrecord@8.gz . Traceback (most recent call last):. File ""/usr/lib/python2.7/runpy.py"", line 174, in _run_module_as_main. ""__main__"", fname, loader, pkg_name). File ""/usr/lib/python2.7/runpy.py"", line 72, in _run_code. exec code in run_globals. File ""/usr/lib/python2.7/trace.py"", line 819, in <module>. main(). File ""/usr/lib/python2.7/trace.py"", line 807, in main. t.runctx(code, globs, globs). File ""/usr/lib/python2.7/trace.py"", line 513, in runctx. exec cmd in globals, locals. File ""postprocess_variants.py"", line 46, in <module>. from third_party.nucleus.io import fasta. ImportError: No module named third_party.nucleus.io. real 0m27.273s. user 0m27.133s. sys 0m0.904s. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/103
https://github.com/google/deepvariant/issues/103:1073,modifiability,modul,module,1073,"The start seems to be quite slow, after about 27s it exits, here is the output. ```. root@52e2e7bb0093:/opt/deepvariant/bin/unzip-post/runfiles/com_google_deepvariant/deepvariant# time python -mtrace --trackcalls postprocess_variants.py --ref /home/zxue/deepvariant_exp/tcga-data/hg19.fa --infile /home/zxue/deepvariant_exp/output/cvo.tfrecord.gz . --outfile /home/zxue/deepvariant_exp/output/output.vcf.gz --nonvariant_site_tfrecord_path /home/zxue/deepvariant_exp/output/gvcf.tfrecord@8.gz . Traceback (most recent call last):. File ""/usr/lib/python2.7/runpy.py"", line 174, in _run_module_as_main. ""__main__"", fname, loader, pkg_name). File ""/usr/lib/python2.7/runpy.py"", line 72, in _run_code. exec code in run_globals. File ""/usr/lib/python2.7/trace.py"", line 819, in <module>. main(). File ""/usr/lib/python2.7/trace.py"", line 807, in main. t.runctx(code, globs, globs). File ""/usr/lib/python2.7/trace.py"", line 513, in runctx. exec cmd in globals, locals. File ""postprocess_variants.py"", line 46, in <module>. from third_party.nucleus.io import fasta. ImportError: No module named third_party.nucleus.io. real 0m27.273s. user 0m27.133s. sys 0m0.904s. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/103
https://github.com/google/deepvariant/issues/103:180,performance,time,time,180,"The start seems to be quite slow, after about 27s it exits, here is the output. ```. root@52e2e7bb0093:/opt/deepvariant/bin/unzip-post/runfiles/com_google_deepvariant/deepvariant# time python -mtrace --trackcalls postprocess_variants.py --ref /home/zxue/deepvariant_exp/tcga-data/hg19.fa --infile /home/zxue/deepvariant_exp/output/cvo.tfrecord.gz . --outfile /home/zxue/deepvariant_exp/output/output.vcf.gz --nonvariant_site_tfrecord_path /home/zxue/deepvariant_exp/output/gvcf.tfrecord@8.gz . Traceback (most recent call last):. File ""/usr/lib/python2.7/runpy.py"", line 174, in _run_module_as_main. ""__main__"", fname, loader, pkg_name). File ""/usr/lib/python2.7/runpy.py"", line 72, in _run_code. exec code in run_globals. File ""/usr/lib/python2.7/trace.py"", line 819, in <module>. main(). File ""/usr/lib/python2.7/trace.py"", line 807, in main. t.runctx(code, globs, globs). File ""/usr/lib/python2.7/trace.py"", line 513, in runctx. exec cmd in globals, locals. File ""postprocess_variants.py"", line 46, in <module>. from third_party.nucleus.io import fasta. ImportError: No module named third_party.nucleus.io. real 0m27.273s. user 0m27.133s. sys 0m0.904s. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/103
https://github.com/google/deepvariant/issues/103:619,performance,load,loader,619,"The start seems to be quite slow, after about 27s it exits, here is the output. ```. root@52e2e7bb0093:/opt/deepvariant/bin/unzip-post/runfiles/com_google_deepvariant/deepvariant# time python -mtrace --trackcalls postprocess_variants.py --ref /home/zxue/deepvariant_exp/tcga-data/hg19.fa --infile /home/zxue/deepvariant_exp/output/cvo.tfrecord.gz . --outfile /home/zxue/deepvariant_exp/output/output.vcf.gz --nonvariant_site_tfrecord_path /home/zxue/deepvariant_exp/output/gvcf.tfrecord@8.gz . Traceback (most recent call last):. File ""/usr/lib/python2.7/runpy.py"", line 174, in _run_module_as_main. ""__main__"", fname, loader, pkg_name). File ""/usr/lib/python2.7/runpy.py"", line 72, in _run_code. exec code in run_globals. File ""/usr/lib/python2.7/trace.py"", line 819, in <module>. main(). File ""/usr/lib/python2.7/trace.py"", line 807, in main. t.runctx(code, globs, globs). File ""/usr/lib/python2.7/trace.py"", line 513, in runctx. exec cmd in globals, locals. File ""postprocess_variants.py"", line 46, in <module>. from third_party.nucleus.io import fasta. ImportError: No module named third_party.nucleus.io. real 0m27.273s. user 0m27.133s. sys 0m0.904s. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/103
https://github.com/google/deepvariant/issues/103:28,reliability,slo,slow,28,"The start seems to be quite slow, after about 27s it exits, here is the output. ```. root@52e2e7bb0093:/opt/deepvariant/bin/unzip-post/runfiles/com_google_deepvariant/deepvariant# time python -mtrace --trackcalls postprocess_variants.py --ref /home/zxue/deepvariant_exp/tcga-data/hg19.fa --infile /home/zxue/deepvariant_exp/output/cvo.tfrecord.gz . --outfile /home/zxue/deepvariant_exp/output/output.vcf.gz --nonvariant_site_tfrecord_path /home/zxue/deepvariant_exp/output/gvcf.tfrecord@8.gz . Traceback (most recent call last):. File ""/usr/lib/python2.7/runpy.py"", line 174, in _run_module_as_main. ""__main__"", fname, loader, pkg_name). File ""/usr/lib/python2.7/runpy.py"", line 72, in _run_code. exec code in run_globals. File ""/usr/lib/python2.7/trace.py"", line 819, in <module>. main(). File ""/usr/lib/python2.7/trace.py"", line 807, in main. t.runctx(code, globs, globs). File ""/usr/lib/python2.7/trace.py"", line 513, in runctx. exec cmd in globals, locals. File ""postprocess_variants.py"", line 46, in <module>. from third_party.nucleus.io import fasta. ImportError: No module named third_party.nucleus.io. real 0m27.273s. user 0m27.133s. sys 0m0.904s. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/103
https://github.com/google/deepvariant/issues/103:773,safety,modul,module,773,"The start seems to be quite slow, after about 27s it exits, here is the output. ```. root@52e2e7bb0093:/opt/deepvariant/bin/unzip-post/runfiles/com_google_deepvariant/deepvariant# time python -mtrace --trackcalls postprocess_variants.py --ref /home/zxue/deepvariant_exp/tcga-data/hg19.fa --infile /home/zxue/deepvariant_exp/output/cvo.tfrecord.gz . --outfile /home/zxue/deepvariant_exp/output/output.vcf.gz --nonvariant_site_tfrecord_path /home/zxue/deepvariant_exp/output/gvcf.tfrecord@8.gz . Traceback (most recent call last):. File ""/usr/lib/python2.7/runpy.py"", line 174, in _run_module_as_main. ""__main__"", fname, loader, pkg_name). File ""/usr/lib/python2.7/runpy.py"", line 72, in _run_code. exec code in run_globals. File ""/usr/lib/python2.7/trace.py"", line 819, in <module>. main(). File ""/usr/lib/python2.7/trace.py"", line 807, in main. t.runctx(code, globs, globs). File ""/usr/lib/python2.7/trace.py"", line 513, in runctx. exec cmd in globals, locals. File ""postprocess_variants.py"", line 46, in <module>. from third_party.nucleus.io import fasta. ImportError: No module named third_party.nucleus.io. real 0m27.273s. user 0m27.133s. sys 0m0.904s. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/103
https://github.com/google/deepvariant/issues/103:1006,safety,modul,module,1006,"The start seems to be quite slow, after about 27s it exits, here is the output. ```. root@52e2e7bb0093:/opt/deepvariant/bin/unzip-post/runfiles/com_google_deepvariant/deepvariant# time python -mtrace --trackcalls postprocess_variants.py --ref /home/zxue/deepvariant_exp/tcga-data/hg19.fa --infile /home/zxue/deepvariant_exp/output/cvo.tfrecord.gz . --outfile /home/zxue/deepvariant_exp/output/output.vcf.gz --nonvariant_site_tfrecord_path /home/zxue/deepvariant_exp/output/gvcf.tfrecord@8.gz . Traceback (most recent call last):. File ""/usr/lib/python2.7/runpy.py"", line 174, in _run_module_as_main. ""__main__"", fname, loader, pkg_name). File ""/usr/lib/python2.7/runpy.py"", line 72, in _run_code. exec code in run_globals. File ""/usr/lib/python2.7/trace.py"", line 819, in <module>. main(). File ""/usr/lib/python2.7/trace.py"", line 807, in main. t.runctx(code, globs, globs). File ""/usr/lib/python2.7/trace.py"", line 513, in runctx. exec cmd in globals, locals. File ""postprocess_variants.py"", line 46, in <module>. from third_party.nucleus.io import fasta. ImportError: No module named third_party.nucleus.io. real 0m27.273s. user 0m27.133s. sys 0m0.904s. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/103
https://github.com/google/deepvariant/issues/103:1073,safety,modul,module,1073,"The start seems to be quite slow, after about 27s it exits, here is the output. ```. root@52e2e7bb0093:/opt/deepvariant/bin/unzip-post/runfiles/com_google_deepvariant/deepvariant# time python -mtrace --trackcalls postprocess_variants.py --ref /home/zxue/deepvariant_exp/tcga-data/hg19.fa --infile /home/zxue/deepvariant_exp/output/cvo.tfrecord.gz . --outfile /home/zxue/deepvariant_exp/output/output.vcf.gz --nonvariant_site_tfrecord_path /home/zxue/deepvariant_exp/output/gvcf.tfrecord@8.gz . Traceback (most recent call last):. File ""/usr/lib/python2.7/runpy.py"", line 174, in _run_module_as_main. ""__main__"", fname, loader, pkg_name). File ""/usr/lib/python2.7/runpy.py"", line 72, in _run_code. exec code in run_globals. File ""/usr/lib/python2.7/trace.py"", line 819, in <module>. main(). File ""/usr/lib/python2.7/trace.py"", line 807, in main. t.runctx(code, globs, globs). File ""/usr/lib/python2.7/trace.py"", line 513, in runctx. exec cmd in globals, locals. File ""postprocess_variants.py"", line 46, in <module>. from third_party.nucleus.io import fasta. ImportError: No module named third_party.nucleus.io. real 0m27.273s. user 0m27.133s. sys 0m0.904s. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/103
https://github.com/google/deepvariant/issues/103:494,testability,Trace,Traceback,494,"The start seems to be quite slow, after about 27s it exits, here is the output. ```. root@52e2e7bb0093:/opt/deepvariant/bin/unzip-post/runfiles/com_google_deepvariant/deepvariant# time python -mtrace --trackcalls postprocess_variants.py --ref /home/zxue/deepvariant_exp/tcga-data/hg19.fa --infile /home/zxue/deepvariant_exp/output/cvo.tfrecord.gz . --outfile /home/zxue/deepvariant_exp/output/output.vcf.gz --nonvariant_site_tfrecord_path /home/zxue/deepvariant_exp/output/gvcf.tfrecord@8.gz . Traceback (most recent call last):. File ""/usr/lib/python2.7/runpy.py"", line 174, in _run_module_as_main. ""__main__"", fname, loader, pkg_name). File ""/usr/lib/python2.7/runpy.py"", line 72, in _run_code. exec code in run_globals. File ""/usr/lib/python2.7/trace.py"", line 819, in <module>. main(). File ""/usr/lib/python2.7/trace.py"", line 807, in main. t.runctx(code, globs, globs). File ""/usr/lib/python2.7/trace.py"", line 513, in runctx. exec cmd in globals, locals. File ""postprocess_variants.py"", line 46, in <module>. from third_party.nucleus.io import fasta. ImportError: No module named third_party.nucleus.io. real 0m27.273s. user 0m27.133s. sys 0m0.904s. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/103
https://github.com/google/deepvariant/issues/103:748,testability,trace,trace,748,"The start seems to be quite slow, after about 27s it exits, here is the output. ```. root@52e2e7bb0093:/opt/deepvariant/bin/unzip-post/runfiles/com_google_deepvariant/deepvariant# time python -mtrace --trackcalls postprocess_variants.py --ref /home/zxue/deepvariant_exp/tcga-data/hg19.fa --infile /home/zxue/deepvariant_exp/output/cvo.tfrecord.gz . --outfile /home/zxue/deepvariant_exp/output/output.vcf.gz --nonvariant_site_tfrecord_path /home/zxue/deepvariant_exp/output/gvcf.tfrecord@8.gz . Traceback (most recent call last):. File ""/usr/lib/python2.7/runpy.py"", line 174, in _run_module_as_main. ""__main__"", fname, loader, pkg_name). File ""/usr/lib/python2.7/runpy.py"", line 72, in _run_code. exec code in run_globals. File ""/usr/lib/python2.7/trace.py"", line 819, in <module>. main(). File ""/usr/lib/python2.7/trace.py"", line 807, in main. t.runctx(code, globs, globs). File ""/usr/lib/python2.7/trace.py"", line 513, in runctx. exec cmd in globals, locals. File ""postprocess_variants.py"", line 46, in <module>. from third_party.nucleus.io import fasta. ImportError: No module named third_party.nucleus.io. real 0m27.273s. user 0m27.133s. sys 0m0.904s. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/103
https://github.com/google/deepvariant/issues/103:815,testability,trace,trace,815,"The start seems to be quite slow, after about 27s it exits, here is the output. ```. root@52e2e7bb0093:/opt/deepvariant/bin/unzip-post/runfiles/com_google_deepvariant/deepvariant# time python -mtrace --trackcalls postprocess_variants.py --ref /home/zxue/deepvariant_exp/tcga-data/hg19.fa --infile /home/zxue/deepvariant_exp/output/cvo.tfrecord.gz . --outfile /home/zxue/deepvariant_exp/output/output.vcf.gz --nonvariant_site_tfrecord_path /home/zxue/deepvariant_exp/output/gvcf.tfrecord@8.gz . Traceback (most recent call last):. File ""/usr/lib/python2.7/runpy.py"", line 174, in _run_module_as_main. ""__main__"", fname, loader, pkg_name). File ""/usr/lib/python2.7/runpy.py"", line 72, in _run_code. exec code in run_globals. File ""/usr/lib/python2.7/trace.py"", line 819, in <module>. main(). File ""/usr/lib/python2.7/trace.py"", line 807, in main. t.runctx(code, globs, globs). File ""/usr/lib/python2.7/trace.py"", line 513, in runctx. exec cmd in globals, locals. File ""postprocess_variants.py"", line 46, in <module>. from third_party.nucleus.io import fasta. ImportError: No module named third_party.nucleus.io. real 0m27.273s. user 0m27.133s. sys 0m0.904s. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/103
https://github.com/google/deepvariant/issues/103:900,testability,trace,trace,900,"The start seems to be quite slow, after about 27s it exits, here is the output. ```. root@52e2e7bb0093:/opt/deepvariant/bin/unzip-post/runfiles/com_google_deepvariant/deepvariant# time python -mtrace --trackcalls postprocess_variants.py --ref /home/zxue/deepvariant_exp/tcga-data/hg19.fa --infile /home/zxue/deepvariant_exp/output/cvo.tfrecord.gz . --outfile /home/zxue/deepvariant_exp/output/output.vcf.gz --nonvariant_site_tfrecord_path /home/zxue/deepvariant_exp/output/gvcf.tfrecord@8.gz . Traceback (most recent call last):. File ""/usr/lib/python2.7/runpy.py"", line 174, in _run_module_as_main. ""__main__"", fname, loader, pkg_name). File ""/usr/lib/python2.7/runpy.py"", line 72, in _run_code. exec code in run_globals. File ""/usr/lib/python2.7/trace.py"", line 819, in <module>. main(). File ""/usr/lib/python2.7/trace.py"", line 807, in main. t.runctx(code, globs, globs). File ""/usr/lib/python2.7/trace.py"", line 513, in runctx. exec cmd in globals, locals. File ""postprocess_variants.py"", line 46, in <module>. from third_party.nucleus.io import fasta. ImportError: No module named third_party.nucleus.io. real 0m27.273s. user 0m27.133s. sys 0m0.904s. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/103
https://github.com/google/deepvariant/issues/103:1126,usability,user,user,1126,"The start seems to be quite slow, after about 27s it exits, here is the output. ```. root@52e2e7bb0093:/opt/deepvariant/bin/unzip-post/runfiles/com_google_deepvariant/deepvariant# time python -mtrace --trackcalls postprocess_variants.py --ref /home/zxue/deepvariant_exp/tcga-data/hg19.fa --infile /home/zxue/deepvariant_exp/output/cvo.tfrecord.gz . --outfile /home/zxue/deepvariant_exp/output/output.vcf.gz --nonvariant_site_tfrecord_path /home/zxue/deepvariant_exp/output/gvcf.tfrecord@8.gz . Traceback (most recent call last):. File ""/usr/lib/python2.7/runpy.py"", line 174, in _run_module_as_main. ""__main__"", fname, loader, pkg_name). File ""/usr/lib/python2.7/runpy.py"", line 72, in _run_code. exec code in run_globals. File ""/usr/lib/python2.7/trace.py"", line 819, in <module>. main(). File ""/usr/lib/python2.7/trace.py"", line 807, in main. t.runctx(code, globs, globs). File ""/usr/lib/python2.7/trace.py"", line 513, in runctx. exec cmd in globals, locals. File ""postprocess_variants.py"", line 46, in <module>. from third_party.nucleus.io import fasta. ImportError: No module named third_party.nucleus.io. real 0m27.273s. user 0m27.133s. sys 0m0.904s. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/103
https://github.com/google/deepvariant/issues/103:41,availability,slo,slower,41,"Yes unfortunately it will be temporarily slower since we're in interactive mode, which we want in order to control our debug session to discover what is happening in your session. Once we identify the root cause, then we will have a path to some solution that our empirical approach will uncover. So what you are seeing is that it needs a module, for which we need to go and launch from the parent directory (`runfiles/com_google_deepvariant`) and specify the `PYTHONPATH` as follows - notice the second `ls` command below shows the presence of `fasta.py` in `third_party/nucleus/io`:. ```Bash. root@d80a33474273:/opt/deepvariant/bin/unzip-post/# cd runfiles/com_google_deepvariant/. root@d80a33474273:/opt/deepvariant/bin/unzip-post/runfiles/com_google_deepvariant#. root@d80a33474273:/opt/deepvariant/bin/unzip-post/runfiles/com_google_deepvariant# ls. __init__.py _solib_k8 deepvariant third_party. root@d80a33474273:/opt/deepvariant/bin/unzip-post/runfiles/com_google_deepvariant#. root@d80a33474273:/opt/deepvariant/bin/unzip-post/runfiles/com_google_deepvariant# ls third_party/nucleus/io. __init__.py bed.py clif_postproc.py fasta.py genomics_reader.py genomics_writer.py python vcf.py. #. # pwd. /opt/deepvariant/bin/unzip-post/runfiles/com_google_deepvariant. #. # PYTHONPATH=. /usr/bin/python -mtrace --trackcalls deepvariant/postprocess_variants.py --ref /home/zxue/deepvariant_exp/tcga-data/hg19.fa --infile /home/zxue/deepvariant_exp/output/cvo.tfrecord.gz --outfile /home/zxue/deepvariant_exp/output/output.vcf.gz --nonvariant_site_tfrecord_path /home/zxue/deepvariant_exp/output/gvcf.tfrecord@8.gz. ```. For clarity, I left the prompt out on the last line that you would launch from the `runfiles/com_google_deepvariant` directory. You would need to launch it as is written starting with `PYTHONPATH` in order to set the search-order of modules. Let's see what this uncovers. Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/103
https://github.com/google/deepvariant/issues/103:339,deployability,modul,module,339,"Yes unfortunately it will be temporarily slower since we're in interactive mode, which we want in order to control our debug session to discover what is happening in your session. Once we identify the root cause, then we will have a path to some solution that our empirical approach will uncover. So what you are seeing is that it needs a module, for which we need to go and launch from the parent directory (`runfiles/com_google_deepvariant`) and specify the `PYTHONPATH` as follows - notice the second `ls` command below shows the presence of `fasta.py` in `third_party/nucleus/io`:. ```Bash. root@d80a33474273:/opt/deepvariant/bin/unzip-post/# cd runfiles/com_google_deepvariant/. root@d80a33474273:/opt/deepvariant/bin/unzip-post/runfiles/com_google_deepvariant#. root@d80a33474273:/opt/deepvariant/bin/unzip-post/runfiles/com_google_deepvariant# ls. __init__.py _solib_k8 deepvariant third_party. root@d80a33474273:/opt/deepvariant/bin/unzip-post/runfiles/com_google_deepvariant#. root@d80a33474273:/opt/deepvariant/bin/unzip-post/runfiles/com_google_deepvariant# ls third_party/nucleus/io. __init__.py bed.py clif_postproc.py fasta.py genomics_reader.py genomics_writer.py python vcf.py. #. # pwd. /opt/deepvariant/bin/unzip-post/runfiles/com_google_deepvariant. #. # PYTHONPATH=. /usr/bin/python -mtrace --trackcalls deepvariant/postprocess_variants.py --ref /home/zxue/deepvariant_exp/tcga-data/hg19.fa --infile /home/zxue/deepvariant_exp/output/cvo.tfrecord.gz --outfile /home/zxue/deepvariant_exp/output/output.vcf.gz --nonvariant_site_tfrecord_path /home/zxue/deepvariant_exp/output/gvcf.tfrecord@8.gz. ```. For clarity, I left the prompt out on the last line that you would launch from the `runfiles/com_google_deepvariant` directory. You would need to launch it as is written starting with `PYTHONPATH` in order to set the search-order of modules. Let's see what this uncovers. Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/103
https://github.com/google/deepvariant/issues/103:1852,deployability,modul,modules,1852,"Yes unfortunately it will be temporarily slower since we're in interactive mode, which we want in order to control our debug session to discover what is happening in your session. Once we identify the root cause, then we will have a path to some solution that our empirical approach will uncover. So what you are seeing is that it needs a module, for which we need to go and launch from the parent directory (`runfiles/com_google_deepvariant`) and specify the `PYTHONPATH` as follows - notice the second `ls` command below shows the presence of `fasta.py` in `third_party/nucleus/io`:. ```Bash. root@d80a33474273:/opt/deepvariant/bin/unzip-post/# cd runfiles/com_google_deepvariant/. root@d80a33474273:/opt/deepvariant/bin/unzip-post/runfiles/com_google_deepvariant#. root@d80a33474273:/opt/deepvariant/bin/unzip-post/runfiles/com_google_deepvariant# ls. __init__.py _solib_k8 deepvariant third_party. root@d80a33474273:/opt/deepvariant/bin/unzip-post/runfiles/com_google_deepvariant#. root@d80a33474273:/opt/deepvariant/bin/unzip-post/runfiles/com_google_deepvariant# ls third_party/nucleus/io. __init__.py bed.py clif_postproc.py fasta.py genomics_reader.py genomics_writer.py python vcf.py. #. # pwd. /opt/deepvariant/bin/unzip-post/runfiles/com_google_deepvariant. #. # PYTHONPATH=. /usr/bin/python -mtrace --trackcalls deepvariant/postprocess_variants.py --ref /home/zxue/deepvariant_exp/tcga-data/hg19.fa --infile /home/zxue/deepvariant_exp/output/cvo.tfrecord.gz --outfile /home/zxue/deepvariant_exp/output/output.vcf.gz --nonvariant_site_tfrecord_path /home/zxue/deepvariant_exp/output/gvcf.tfrecord@8.gz. ```. For clarity, I left the prompt out on the last line that you would launch from the `runfiles/com_google_deepvariant` directory. You would need to launch it as is written starting with `PYTHONPATH` in order to set the search-order of modules. Let's see what this uncovers. Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/103
https://github.com/google/deepvariant/issues/103:136,integrability,discover,discover,136,"Yes unfortunately it will be temporarily slower since we're in interactive mode, which we want in order to control our debug session to discover what is happening in your session. Once we identify the root cause, then we will have a path to some solution that our empirical approach will uncover. So what you are seeing is that it needs a module, for which we need to go and launch from the parent directory (`runfiles/com_google_deepvariant`) and specify the `PYTHONPATH` as follows - notice the second `ls` command below shows the presence of `fasta.py` in `third_party/nucleus/io`:. ```Bash. root@d80a33474273:/opt/deepvariant/bin/unzip-post/# cd runfiles/com_google_deepvariant/. root@d80a33474273:/opt/deepvariant/bin/unzip-post/runfiles/com_google_deepvariant#. root@d80a33474273:/opt/deepvariant/bin/unzip-post/runfiles/com_google_deepvariant# ls. __init__.py _solib_k8 deepvariant third_party. root@d80a33474273:/opt/deepvariant/bin/unzip-post/runfiles/com_google_deepvariant#. root@d80a33474273:/opt/deepvariant/bin/unzip-post/runfiles/com_google_deepvariant# ls third_party/nucleus/io. __init__.py bed.py clif_postproc.py fasta.py genomics_reader.py genomics_writer.py python vcf.py. #. # pwd. /opt/deepvariant/bin/unzip-post/runfiles/com_google_deepvariant. #. # PYTHONPATH=. /usr/bin/python -mtrace --trackcalls deepvariant/postprocess_variants.py --ref /home/zxue/deepvariant_exp/tcga-data/hg19.fa --infile /home/zxue/deepvariant_exp/output/cvo.tfrecord.gz --outfile /home/zxue/deepvariant_exp/output/output.vcf.gz --nonvariant_site_tfrecord_path /home/zxue/deepvariant_exp/output/gvcf.tfrecord@8.gz. ```. For clarity, I left the prompt out on the last line that you would launch from the `runfiles/com_google_deepvariant` directory. You would need to launch it as is written starting with `PYTHONPATH` in order to set the search-order of modules. Let's see what this uncovers. Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/103
https://github.com/google/deepvariant/issues/103:136,interoperability,discover,discover,136,"Yes unfortunately it will be temporarily slower since we're in interactive mode, which we want in order to control our debug session to discover what is happening in your session. Once we identify the root cause, then we will have a path to some solution that our empirical approach will uncover. So what you are seeing is that it needs a module, for which we need to go and launch from the parent directory (`runfiles/com_google_deepvariant`) and specify the `PYTHONPATH` as follows - notice the second `ls` command below shows the presence of `fasta.py` in `third_party/nucleus/io`:. ```Bash. root@d80a33474273:/opt/deepvariant/bin/unzip-post/# cd runfiles/com_google_deepvariant/. root@d80a33474273:/opt/deepvariant/bin/unzip-post/runfiles/com_google_deepvariant#. root@d80a33474273:/opt/deepvariant/bin/unzip-post/runfiles/com_google_deepvariant# ls. __init__.py _solib_k8 deepvariant third_party. root@d80a33474273:/opt/deepvariant/bin/unzip-post/runfiles/com_google_deepvariant#. root@d80a33474273:/opt/deepvariant/bin/unzip-post/runfiles/com_google_deepvariant# ls third_party/nucleus/io. __init__.py bed.py clif_postproc.py fasta.py genomics_reader.py genomics_writer.py python vcf.py. #. # pwd. /opt/deepvariant/bin/unzip-post/runfiles/com_google_deepvariant. #. # PYTHONPATH=. /usr/bin/python -mtrace --trackcalls deepvariant/postprocess_variants.py --ref /home/zxue/deepvariant_exp/tcga-data/hg19.fa --infile /home/zxue/deepvariant_exp/output/cvo.tfrecord.gz --outfile /home/zxue/deepvariant_exp/output/output.vcf.gz --nonvariant_site_tfrecord_path /home/zxue/deepvariant_exp/output/gvcf.tfrecord@8.gz. ```. For clarity, I left the prompt out on the last line that you would launch from the `runfiles/com_google_deepvariant` directory. You would need to launch it as is written starting with `PYTHONPATH` in order to set the search-order of modules. Let's see what this uncovers. Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/103
https://github.com/google/deepvariant/issues/103:448,interoperability,specif,specify,448,"Yes unfortunately it will be temporarily slower since we're in interactive mode, which we want in order to control our debug session to discover what is happening in your session. Once we identify the root cause, then we will have a path to some solution that our empirical approach will uncover. So what you are seeing is that it needs a module, for which we need to go and launch from the parent directory (`runfiles/com_google_deepvariant`) and specify the `PYTHONPATH` as follows - notice the second `ls` command below shows the presence of `fasta.py` in `third_party/nucleus/io`:. ```Bash. root@d80a33474273:/opt/deepvariant/bin/unzip-post/# cd runfiles/com_google_deepvariant/. root@d80a33474273:/opt/deepvariant/bin/unzip-post/runfiles/com_google_deepvariant#. root@d80a33474273:/opt/deepvariant/bin/unzip-post/runfiles/com_google_deepvariant# ls. __init__.py _solib_k8 deepvariant third_party. root@d80a33474273:/opt/deepvariant/bin/unzip-post/runfiles/com_google_deepvariant#. root@d80a33474273:/opt/deepvariant/bin/unzip-post/runfiles/com_google_deepvariant# ls third_party/nucleus/io. __init__.py bed.py clif_postproc.py fasta.py genomics_reader.py genomics_writer.py python vcf.py. #. # pwd. /opt/deepvariant/bin/unzip-post/runfiles/com_google_deepvariant. #. # PYTHONPATH=. /usr/bin/python -mtrace --trackcalls deepvariant/postprocess_variants.py --ref /home/zxue/deepvariant_exp/tcga-data/hg19.fa --infile /home/zxue/deepvariant_exp/output/cvo.tfrecord.gz --outfile /home/zxue/deepvariant_exp/output/output.vcf.gz --nonvariant_site_tfrecord_path /home/zxue/deepvariant_exp/output/gvcf.tfrecord@8.gz. ```. For clarity, I left the prompt out on the last line that you would launch from the `runfiles/com_google_deepvariant` directory. You would need to launch it as is written starting with `PYTHONPATH` in order to set the search-order of modules. Let's see what this uncovers. Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/103
https://github.com/google/deepvariant/issues/103:339,modifiability,modul,module,339,"Yes unfortunately it will be temporarily slower since we're in interactive mode, which we want in order to control our debug session to discover what is happening in your session. Once we identify the root cause, then we will have a path to some solution that our empirical approach will uncover. So what you are seeing is that it needs a module, for which we need to go and launch from the parent directory (`runfiles/com_google_deepvariant`) and specify the `PYTHONPATH` as follows - notice the second `ls` command below shows the presence of `fasta.py` in `third_party/nucleus/io`:. ```Bash. root@d80a33474273:/opt/deepvariant/bin/unzip-post/# cd runfiles/com_google_deepvariant/. root@d80a33474273:/opt/deepvariant/bin/unzip-post/runfiles/com_google_deepvariant#. root@d80a33474273:/opt/deepvariant/bin/unzip-post/runfiles/com_google_deepvariant# ls. __init__.py _solib_k8 deepvariant third_party. root@d80a33474273:/opt/deepvariant/bin/unzip-post/runfiles/com_google_deepvariant#. root@d80a33474273:/opt/deepvariant/bin/unzip-post/runfiles/com_google_deepvariant# ls third_party/nucleus/io. __init__.py bed.py clif_postproc.py fasta.py genomics_reader.py genomics_writer.py python vcf.py. #. # pwd. /opt/deepvariant/bin/unzip-post/runfiles/com_google_deepvariant. #. # PYTHONPATH=. /usr/bin/python -mtrace --trackcalls deepvariant/postprocess_variants.py --ref /home/zxue/deepvariant_exp/tcga-data/hg19.fa --infile /home/zxue/deepvariant_exp/output/cvo.tfrecord.gz --outfile /home/zxue/deepvariant_exp/output/output.vcf.gz --nonvariant_site_tfrecord_path /home/zxue/deepvariant_exp/output/gvcf.tfrecord@8.gz. ```. For clarity, I left the prompt out on the last line that you would launch from the `runfiles/com_google_deepvariant` directory. You would need to launch it as is written starting with `PYTHONPATH` in order to set the search-order of modules. Let's see what this uncovers. Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/103
https://github.com/google/deepvariant/issues/103:1852,modifiability,modul,modules,1852,"Yes unfortunately it will be temporarily slower since we're in interactive mode, which we want in order to control our debug session to discover what is happening in your session. Once we identify the root cause, then we will have a path to some solution that our empirical approach will uncover. So what you are seeing is that it needs a module, for which we need to go and launch from the parent directory (`runfiles/com_google_deepvariant`) and specify the `PYTHONPATH` as follows - notice the second `ls` command below shows the presence of `fasta.py` in `third_party/nucleus/io`:. ```Bash. root@d80a33474273:/opt/deepvariant/bin/unzip-post/# cd runfiles/com_google_deepvariant/. root@d80a33474273:/opt/deepvariant/bin/unzip-post/runfiles/com_google_deepvariant#. root@d80a33474273:/opt/deepvariant/bin/unzip-post/runfiles/com_google_deepvariant# ls. __init__.py _solib_k8 deepvariant third_party. root@d80a33474273:/opt/deepvariant/bin/unzip-post/runfiles/com_google_deepvariant#. root@d80a33474273:/opt/deepvariant/bin/unzip-post/runfiles/com_google_deepvariant# ls third_party/nucleus/io. __init__.py bed.py clif_postproc.py fasta.py genomics_reader.py genomics_writer.py python vcf.py. #. # pwd. /opt/deepvariant/bin/unzip-post/runfiles/com_google_deepvariant. #. # PYTHONPATH=. /usr/bin/python -mtrace --trackcalls deepvariant/postprocess_variants.py --ref /home/zxue/deepvariant_exp/tcga-data/hg19.fa --infile /home/zxue/deepvariant_exp/output/cvo.tfrecord.gz --outfile /home/zxue/deepvariant_exp/output/output.vcf.gz --nonvariant_site_tfrecord_path /home/zxue/deepvariant_exp/output/gvcf.tfrecord@8.gz. ```. For clarity, I left the prompt out on the last line that you would launch from the `runfiles/com_google_deepvariant` directory. You would need to launch it as is written starting with `PYTHONPATH` in order to set the search-order of modules. Let's see what this uncovers. Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/103
https://github.com/google/deepvariant/issues/103:41,reliability,slo,slower,41,"Yes unfortunately it will be temporarily slower since we're in interactive mode, which we want in order to control our debug session to discover what is happening in your session. Once we identify the root cause, then we will have a path to some solution that our empirical approach will uncover. So what you are seeing is that it needs a module, for which we need to go and launch from the parent directory (`runfiles/com_google_deepvariant`) and specify the `PYTHONPATH` as follows - notice the second `ls` command below shows the presence of `fasta.py` in `third_party/nucleus/io`:. ```Bash. root@d80a33474273:/opt/deepvariant/bin/unzip-post/# cd runfiles/com_google_deepvariant/. root@d80a33474273:/opt/deepvariant/bin/unzip-post/runfiles/com_google_deepvariant#. root@d80a33474273:/opt/deepvariant/bin/unzip-post/runfiles/com_google_deepvariant# ls. __init__.py _solib_k8 deepvariant third_party. root@d80a33474273:/opt/deepvariant/bin/unzip-post/runfiles/com_google_deepvariant#. root@d80a33474273:/opt/deepvariant/bin/unzip-post/runfiles/com_google_deepvariant# ls third_party/nucleus/io. __init__.py bed.py clif_postproc.py fasta.py genomics_reader.py genomics_writer.py python vcf.py. #. # pwd. /opt/deepvariant/bin/unzip-post/runfiles/com_google_deepvariant. #. # PYTHONPATH=. /usr/bin/python -mtrace --trackcalls deepvariant/postprocess_variants.py --ref /home/zxue/deepvariant_exp/tcga-data/hg19.fa --infile /home/zxue/deepvariant_exp/output/cvo.tfrecord.gz --outfile /home/zxue/deepvariant_exp/output/output.vcf.gz --nonvariant_site_tfrecord_path /home/zxue/deepvariant_exp/output/gvcf.tfrecord@8.gz. ```. For clarity, I left the prompt out on the last line that you would launch from the `runfiles/com_google_deepvariant` directory. You would need to launch it as is written starting with `PYTHONPATH` in order to set the search-order of modules. Let's see what this uncovers. Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/103
https://github.com/google/deepvariant/issues/103:339,safety,modul,module,339,"Yes unfortunately it will be temporarily slower since we're in interactive mode, which we want in order to control our debug session to discover what is happening in your session. Once we identify the root cause, then we will have a path to some solution that our empirical approach will uncover. So what you are seeing is that it needs a module, for which we need to go and launch from the parent directory (`runfiles/com_google_deepvariant`) and specify the `PYTHONPATH` as follows - notice the second `ls` command below shows the presence of `fasta.py` in `third_party/nucleus/io`:. ```Bash. root@d80a33474273:/opt/deepvariant/bin/unzip-post/# cd runfiles/com_google_deepvariant/. root@d80a33474273:/opt/deepvariant/bin/unzip-post/runfiles/com_google_deepvariant#. root@d80a33474273:/opt/deepvariant/bin/unzip-post/runfiles/com_google_deepvariant# ls. __init__.py _solib_k8 deepvariant third_party. root@d80a33474273:/opt/deepvariant/bin/unzip-post/runfiles/com_google_deepvariant#. root@d80a33474273:/opt/deepvariant/bin/unzip-post/runfiles/com_google_deepvariant# ls third_party/nucleus/io. __init__.py bed.py clif_postproc.py fasta.py genomics_reader.py genomics_writer.py python vcf.py. #. # pwd. /opt/deepvariant/bin/unzip-post/runfiles/com_google_deepvariant. #. # PYTHONPATH=. /usr/bin/python -mtrace --trackcalls deepvariant/postprocess_variants.py --ref /home/zxue/deepvariant_exp/tcga-data/hg19.fa --infile /home/zxue/deepvariant_exp/output/cvo.tfrecord.gz --outfile /home/zxue/deepvariant_exp/output/output.vcf.gz --nonvariant_site_tfrecord_path /home/zxue/deepvariant_exp/output/gvcf.tfrecord@8.gz. ```. For clarity, I left the prompt out on the last line that you would launch from the `runfiles/com_google_deepvariant` directory. You would need to launch it as is written starting with `PYTHONPATH` in order to set the search-order of modules. Let's see what this uncovers. Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/103
https://github.com/google/deepvariant/issues/103:1852,safety,modul,modules,1852,"Yes unfortunately it will be temporarily slower since we're in interactive mode, which we want in order to control our debug session to discover what is happening in your session. Once we identify the root cause, then we will have a path to some solution that our empirical approach will uncover. So what you are seeing is that it needs a module, for which we need to go and launch from the parent directory (`runfiles/com_google_deepvariant`) and specify the `PYTHONPATH` as follows - notice the second `ls` command below shows the presence of `fasta.py` in `third_party/nucleus/io`:. ```Bash. root@d80a33474273:/opt/deepvariant/bin/unzip-post/# cd runfiles/com_google_deepvariant/. root@d80a33474273:/opt/deepvariant/bin/unzip-post/runfiles/com_google_deepvariant#. root@d80a33474273:/opt/deepvariant/bin/unzip-post/runfiles/com_google_deepvariant# ls. __init__.py _solib_k8 deepvariant third_party. root@d80a33474273:/opt/deepvariant/bin/unzip-post/runfiles/com_google_deepvariant#. root@d80a33474273:/opt/deepvariant/bin/unzip-post/runfiles/com_google_deepvariant# ls third_party/nucleus/io. __init__.py bed.py clif_postproc.py fasta.py genomics_reader.py genomics_writer.py python vcf.py. #. # pwd. /opt/deepvariant/bin/unzip-post/runfiles/com_google_deepvariant. #. # PYTHONPATH=. /usr/bin/python -mtrace --trackcalls deepvariant/postprocess_variants.py --ref /home/zxue/deepvariant_exp/tcga-data/hg19.fa --infile /home/zxue/deepvariant_exp/output/cvo.tfrecord.gz --outfile /home/zxue/deepvariant_exp/output/output.vcf.gz --nonvariant_site_tfrecord_path /home/zxue/deepvariant_exp/output/gvcf.tfrecord@8.gz. ```. For clarity, I left the prompt out on the last line that you would launch from the `runfiles/com_google_deepvariant` directory. You would need to launch it as is written starting with `PYTHONPATH` in order to set the search-order of modules. Let's see what this uncovers. Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/103
https://github.com/google/deepvariant/issues/103:107,security,control,control,107,"Yes unfortunately it will be temporarily slower since we're in interactive mode, which we want in order to control our debug session to discover what is happening in your session. Once we identify the root cause, then we will have a path to some solution that our empirical approach will uncover. So what you are seeing is that it needs a module, for which we need to go and launch from the parent directory (`runfiles/com_google_deepvariant`) and specify the `PYTHONPATH` as follows - notice the second `ls` command below shows the presence of `fasta.py` in `third_party/nucleus/io`:. ```Bash. root@d80a33474273:/opt/deepvariant/bin/unzip-post/# cd runfiles/com_google_deepvariant/. root@d80a33474273:/opt/deepvariant/bin/unzip-post/runfiles/com_google_deepvariant#. root@d80a33474273:/opt/deepvariant/bin/unzip-post/runfiles/com_google_deepvariant# ls. __init__.py _solib_k8 deepvariant third_party. root@d80a33474273:/opt/deepvariant/bin/unzip-post/runfiles/com_google_deepvariant#. root@d80a33474273:/opt/deepvariant/bin/unzip-post/runfiles/com_google_deepvariant# ls third_party/nucleus/io. __init__.py bed.py clif_postproc.py fasta.py genomics_reader.py genomics_writer.py python vcf.py. #. # pwd. /opt/deepvariant/bin/unzip-post/runfiles/com_google_deepvariant. #. # PYTHONPATH=. /usr/bin/python -mtrace --trackcalls deepvariant/postprocess_variants.py --ref /home/zxue/deepvariant_exp/tcga-data/hg19.fa --infile /home/zxue/deepvariant_exp/output/cvo.tfrecord.gz --outfile /home/zxue/deepvariant_exp/output/output.vcf.gz --nonvariant_site_tfrecord_path /home/zxue/deepvariant_exp/output/gvcf.tfrecord@8.gz. ```. For clarity, I left the prompt out on the last line that you would launch from the `runfiles/com_google_deepvariant` directory. You would need to launch it as is written starting with `PYTHONPATH` in order to set the search-order of modules. Let's see what this uncovers. Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/103
https://github.com/google/deepvariant/issues/103:125,security,session,session,125,"Yes unfortunately it will be temporarily slower since we're in interactive mode, which we want in order to control our debug session to discover what is happening in your session. Once we identify the root cause, then we will have a path to some solution that our empirical approach will uncover. So what you are seeing is that it needs a module, for which we need to go and launch from the parent directory (`runfiles/com_google_deepvariant`) and specify the `PYTHONPATH` as follows - notice the second `ls` command below shows the presence of `fasta.py` in `third_party/nucleus/io`:. ```Bash. root@d80a33474273:/opt/deepvariant/bin/unzip-post/# cd runfiles/com_google_deepvariant/. root@d80a33474273:/opt/deepvariant/bin/unzip-post/runfiles/com_google_deepvariant#. root@d80a33474273:/opt/deepvariant/bin/unzip-post/runfiles/com_google_deepvariant# ls. __init__.py _solib_k8 deepvariant third_party. root@d80a33474273:/opt/deepvariant/bin/unzip-post/runfiles/com_google_deepvariant#. root@d80a33474273:/opt/deepvariant/bin/unzip-post/runfiles/com_google_deepvariant# ls third_party/nucleus/io. __init__.py bed.py clif_postproc.py fasta.py genomics_reader.py genomics_writer.py python vcf.py. #. # pwd. /opt/deepvariant/bin/unzip-post/runfiles/com_google_deepvariant. #. # PYTHONPATH=. /usr/bin/python -mtrace --trackcalls deepvariant/postprocess_variants.py --ref /home/zxue/deepvariant_exp/tcga-data/hg19.fa --infile /home/zxue/deepvariant_exp/output/cvo.tfrecord.gz --outfile /home/zxue/deepvariant_exp/output/output.vcf.gz --nonvariant_site_tfrecord_path /home/zxue/deepvariant_exp/output/gvcf.tfrecord@8.gz. ```. For clarity, I left the prompt out on the last line that you would launch from the `runfiles/com_google_deepvariant` directory. You would need to launch it as is written starting with `PYTHONPATH` in order to set the search-order of modules. Let's see what this uncovers. Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/103
https://github.com/google/deepvariant/issues/103:171,security,session,session,171,"Yes unfortunately it will be temporarily slower since we're in interactive mode, which we want in order to control our debug session to discover what is happening in your session. Once we identify the root cause, then we will have a path to some solution that our empirical approach will uncover. So what you are seeing is that it needs a module, for which we need to go and launch from the parent directory (`runfiles/com_google_deepvariant`) and specify the `PYTHONPATH` as follows - notice the second `ls` command below shows the presence of `fasta.py` in `third_party/nucleus/io`:. ```Bash. root@d80a33474273:/opt/deepvariant/bin/unzip-post/# cd runfiles/com_google_deepvariant/. root@d80a33474273:/opt/deepvariant/bin/unzip-post/runfiles/com_google_deepvariant#. root@d80a33474273:/opt/deepvariant/bin/unzip-post/runfiles/com_google_deepvariant# ls. __init__.py _solib_k8 deepvariant third_party. root@d80a33474273:/opt/deepvariant/bin/unzip-post/runfiles/com_google_deepvariant#. root@d80a33474273:/opt/deepvariant/bin/unzip-post/runfiles/com_google_deepvariant# ls third_party/nucleus/io. __init__.py bed.py clif_postproc.py fasta.py genomics_reader.py genomics_writer.py python vcf.py. #. # pwd. /opt/deepvariant/bin/unzip-post/runfiles/com_google_deepvariant. #. # PYTHONPATH=. /usr/bin/python -mtrace --trackcalls deepvariant/postprocess_variants.py --ref /home/zxue/deepvariant_exp/tcga-data/hg19.fa --infile /home/zxue/deepvariant_exp/output/cvo.tfrecord.gz --outfile /home/zxue/deepvariant_exp/output/output.vcf.gz --nonvariant_site_tfrecord_path /home/zxue/deepvariant_exp/output/gvcf.tfrecord@8.gz. ```. For clarity, I left the prompt out on the last line that you would launch from the `runfiles/com_google_deepvariant` directory. You would need to launch it as is written starting with `PYTHONPATH` in order to set the search-order of modules. Let's see what this uncovers. Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/103
https://github.com/google/deepvariant/issues/103:188,security,ident,identify,188,"Yes unfortunately it will be temporarily slower since we're in interactive mode, which we want in order to control our debug session to discover what is happening in your session. Once we identify the root cause, then we will have a path to some solution that our empirical approach will uncover. So what you are seeing is that it needs a module, for which we need to go and launch from the parent directory (`runfiles/com_google_deepvariant`) and specify the `PYTHONPATH` as follows - notice the second `ls` command below shows the presence of `fasta.py` in `third_party/nucleus/io`:. ```Bash. root@d80a33474273:/opt/deepvariant/bin/unzip-post/# cd runfiles/com_google_deepvariant/. root@d80a33474273:/opt/deepvariant/bin/unzip-post/runfiles/com_google_deepvariant#. root@d80a33474273:/opt/deepvariant/bin/unzip-post/runfiles/com_google_deepvariant# ls. __init__.py _solib_k8 deepvariant third_party. root@d80a33474273:/opt/deepvariant/bin/unzip-post/runfiles/com_google_deepvariant#. root@d80a33474273:/opt/deepvariant/bin/unzip-post/runfiles/com_google_deepvariant# ls third_party/nucleus/io. __init__.py bed.py clif_postproc.py fasta.py genomics_reader.py genomics_writer.py python vcf.py. #. # pwd. /opt/deepvariant/bin/unzip-post/runfiles/com_google_deepvariant. #. # PYTHONPATH=. /usr/bin/python -mtrace --trackcalls deepvariant/postprocess_variants.py --ref /home/zxue/deepvariant_exp/tcga-data/hg19.fa --infile /home/zxue/deepvariant_exp/output/cvo.tfrecord.gz --outfile /home/zxue/deepvariant_exp/output/output.vcf.gz --nonvariant_site_tfrecord_path /home/zxue/deepvariant_exp/output/gvcf.tfrecord@8.gz. ```. For clarity, I left the prompt out on the last line that you would launch from the `runfiles/com_google_deepvariant` directory. You would need to launch it as is written starting with `PYTHONPATH` in order to set the search-order of modules. Let's see what this uncovers. Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/103
https://github.com/google/deepvariant/issues/103:107,testability,control,control,107,"Yes unfortunately it will be temporarily slower since we're in interactive mode, which we want in order to control our debug session to discover what is happening in your session. Once we identify the root cause, then we will have a path to some solution that our empirical approach will uncover. So what you are seeing is that it needs a module, for which we need to go and launch from the parent directory (`runfiles/com_google_deepvariant`) and specify the `PYTHONPATH` as follows - notice the second `ls` command below shows the presence of `fasta.py` in `third_party/nucleus/io`:. ```Bash. root@d80a33474273:/opt/deepvariant/bin/unzip-post/# cd runfiles/com_google_deepvariant/. root@d80a33474273:/opt/deepvariant/bin/unzip-post/runfiles/com_google_deepvariant#. root@d80a33474273:/opt/deepvariant/bin/unzip-post/runfiles/com_google_deepvariant# ls. __init__.py _solib_k8 deepvariant third_party. root@d80a33474273:/opt/deepvariant/bin/unzip-post/runfiles/com_google_deepvariant#. root@d80a33474273:/opt/deepvariant/bin/unzip-post/runfiles/com_google_deepvariant# ls third_party/nucleus/io. __init__.py bed.py clif_postproc.py fasta.py genomics_reader.py genomics_writer.py python vcf.py. #. # pwd. /opt/deepvariant/bin/unzip-post/runfiles/com_google_deepvariant. #. # PYTHONPATH=. /usr/bin/python -mtrace --trackcalls deepvariant/postprocess_variants.py --ref /home/zxue/deepvariant_exp/tcga-data/hg19.fa --infile /home/zxue/deepvariant_exp/output/cvo.tfrecord.gz --outfile /home/zxue/deepvariant_exp/output/output.vcf.gz --nonvariant_site_tfrecord_path /home/zxue/deepvariant_exp/output/gvcf.tfrecord@8.gz. ```. For clarity, I left the prompt out on the last line that you would launch from the `runfiles/com_google_deepvariant` directory. You would need to launch it as is written starting with `PYTHONPATH` in order to set the search-order of modules. Let's see what this uncovers. Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/103
https://github.com/google/deepvariant/issues/103:63,usability,interact,interactive,63,"Yes unfortunately it will be temporarily slower since we're in interactive mode, which we want in order to control our debug session to discover what is happening in your session. Once we identify the root cause, then we will have a path to some solution that our empirical approach will uncover. So what you are seeing is that it needs a module, for which we need to go and launch from the parent directory (`runfiles/com_google_deepvariant`) and specify the `PYTHONPATH` as follows - notice the second `ls` command below shows the presence of `fasta.py` in `third_party/nucleus/io`:. ```Bash. root@d80a33474273:/opt/deepvariant/bin/unzip-post/# cd runfiles/com_google_deepvariant/. root@d80a33474273:/opt/deepvariant/bin/unzip-post/runfiles/com_google_deepvariant#. root@d80a33474273:/opt/deepvariant/bin/unzip-post/runfiles/com_google_deepvariant# ls. __init__.py _solib_k8 deepvariant third_party. root@d80a33474273:/opt/deepvariant/bin/unzip-post/runfiles/com_google_deepvariant#. root@d80a33474273:/opt/deepvariant/bin/unzip-post/runfiles/com_google_deepvariant# ls third_party/nucleus/io. __init__.py bed.py clif_postproc.py fasta.py genomics_reader.py genomics_writer.py python vcf.py. #. # pwd. /opt/deepvariant/bin/unzip-post/runfiles/com_google_deepvariant. #. # PYTHONPATH=. /usr/bin/python -mtrace --trackcalls deepvariant/postprocess_variants.py --ref /home/zxue/deepvariant_exp/tcga-data/hg19.fa --infile /home/zxue/deepvariant_exp/output/cvo.tfrecord.gz --outfile /home/zxue/deepvariant_exp/output/output.vcf.gz --nonvariant_site_tfrecord_path /home/zxue/deepvariant_exp/output/gvcf.tfrecord@8.gz. ```. For clarity, I left the prompt out on the last line that you would launch from the `runfiles/com_google_deepvariant` directory. You would need to launch it as is written starting with `PYTHONPATH` in order to set the search-order of modules. Let's see what this uncovers. Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/103
https://github.com/google/deepvariant/issues/103:136,usability,discov,discover,136,"Yes unfortunately it will be temporarily slower since we're in interactive mode, which we want in order to control our debug session to discover what is happening in your session. Once we identify the root cause, then we will have a path to some solution that our empirical approach will uncover. So what you are seeing is that it needs a module, for which we need to go and launch from the parent directory (`runfiles/com_google_deepvariant`) and specify the `PYTHONPATH` as follows - notice the second `ls` command below shows the presence of `fasta.py` in `third_party/nucleus/io`:. ```Bash. root@d80a33474273:/opt/deepvariant/bin/unzip-post/# cd runfiles/com_google_deepvariant/. root@d80a33474273:/opt/deepvariant/bin/unzip-post/runfiles/com_google_deepvariant#. root@d80a33474273:/opt/deepvariant/bin/unzip-post/runfiles/com_google_deepvariant# ls. __init__.py _solib_k8 deepvariant third_party. root@d80a33474273:/opt/deepvariant/bin/unzip-post/runfiles/com_google_deepvariant#. root@d80a33474273:/opt/deepvariant/bin/unzip-post/runfiles/com_google_deepvariant# ls third_party/nucleus/io. __init__.py bed.py clif_postproc.py fasta.py genomics_reader.py genomics_writer.py python vcf.py. #. # pwd. /opt/deepvariant/bin/unzip-post/runfiles/com_google_deepvariant. #. # PYTHONPATH=. /usr/bin/python -mtrace --trackcalls deepvariant/postprocess_variants.py --ref /home/zxue/deepvariant_exp/tcga-data/hg19.fa --infile /home/zxue/deepvariant_exp/output/cvo.tfrecord.gz --outfile /home/zxue/deepvariant_exp/output/output.vcf.gz --nonvariant_site_tfrecord_path /home/zxue/deepvariant_exp/output/gvcf.tfrecord@8.gz. ```. For clarity, I left the prompt out on the last line that you would launch from the `runfiles/com_google_deepvariant` directory. You would need to launch it as is written starting with `PYTHONPATH` in order to set the search-order of modules. Let's see what this uncovers. Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/103
https://github.com/google/deepvariant/issues/103:509,usability,command,command,509,"Yes unfortunately it will be temporarily slower since we're in interactive mode, which we want in order to control our debug session to discover what is happening in your session. Once we identify the root cause, then we will have a path to some solution that our empirical approach will uncover. So what you are seeing is that it needs a module, for which we need to go and launch from the parent directory (`runfiles/com_google_deepvariant`) and specify the `PYTHONPATH` as follows - notice the second `ls` command below shows the presence of `fasta.py` in `third_party/nucleus/io`:. ```Bash. root@d80a33474273:/opt/deepvariant/bin/unzip-post/# cd runfiles/com_google_deepvariant/. root@d80a33474273:/opt/deepvariant/bin/unzip-post/runfiles/com_google_deepvariant#. root@d80a33474273:/opt/deepvariant/bin/unzip-post/runfiles/com_google_deepvariant# ls. __init__.py _solib_k8 deepvariant third_party. root@d80a33474273:/opt/deepvariant/bin/unzip-post/runfiles/com_google_deepvariant#. root@d80a33474273:/opt/deepvariant/bin/unzip-post/runfiles/com_google_deepvariant# ls third_party/nucleus/io. __init__.py bed.py clif_postproc.py fasta.py genomics_reader.py genomics_writer.py python vcf.py. #. # pwd. /opt/deepvariant/bin/unzip-post/runfiles/com_google_deepvariant. #. # PYTHONPATH=. /usr/bin/python -mtrace --trackcalls deepvariant/postprocess_variants.py --ref /home/zxue/deepvariant_exp/tcga-data/hg19.fa --infile /home/zxue/deepvariant_exp/output/cvo.tfrecord.gz --outfile /home/zxue/deepvariant_exp/output/output.vcf.gz --nonvariant_site_tfrecord_path /home/zxue/deepvariant_exp/output/gvcf.tfrecord@8.gz. ```. For clarity, I left the prompt out on the last line that you would launch from the `runfiles/com_google_deepvariant` directory. You would need to launch it as is written starting with `PYTHONPATH` in order to set the search-order of modules. Let's see what this uncovers. Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/103
https://github.com/google/deepvariant/issues/103:1623,usability,clarit,clarity,1623,"Yes unfortunately it will be temporarily slower since we're in interactive mode, which we want in order to control our debug session to discover what is happening in your session. Once we identify the root cause, then we will have a path to some solution that our empirical approach will uncover. So what you are seeing is that it needs a module, for which we need to go and launch from the parent directory (`runfiles/com_google_deepvariant`) and specify the `PYTHONPATH` as follows - notice the second `ls` command below shows the presence of `fasta.py` in `third_party/nucleus/io`:. ```Bash. root@d80a33474273:/opt/deepvariant/bin/unzip-post/# cd runfiles/com_google_deepvariant/. root@d80a33474273:/opt/deepvariant/bin/unzip-post/runfiles/com_google_deepvariant#. root@d80a33474273:/opt/deepvariant/bin/unzip-post/runfiles/com_google_deepvariant# ls. __init__.py _solib_k8 deepvariant third_party. root@d80a33474273:/opt/deepvariant/bin/unzip-post/runfiles/com_google_deepvariant#. root@d80a33474273:/opt/deepvariant/bin/unzip-post/runfiles/com_google_deepvariant# ls third_party/nucleus/io. __init__.py bed.py clif_postproc.py fasta.py genomics_reader.py genomics_writer.py python vcf.py. #. # pwd. /opt/deepvariant/bin/unzip-post/runfiles/com_google_deepvariant. #. # PYTHONPATH=. /usr/bin/python -mtrace --trackcalls deepvariant/postprocess_variants.py --ref /home/zxue/deepvariant_exp/tcga-data/hg19.fa --infile /home/zxue/deepvariant_exp/output/cvo.tfrecord.gz --outfile /home/zxue/deepvariant_exp/output/output.vcf.gz --nonvariant_site_tfrecord_path /home/zxue/deepvariant_exp/output/gvcf.tfrecord@8.gz. ```. For clarity, I left the prompt out on the last line that you would launch from the `runfiles/com_google_deepvariant` directory. You would need to launch it as is written starting with `PYTHONPATH` in order to set the search-order of modules. Let's see what this uncovers. Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/103
https://github.com/google/deepvariant/issues/103:91,deployability,updat,update,91,"@zyxue curious whether you're able to resolve this? I'm going to close this since the last update was a while ago. If you have more information, feel free to update and re-open.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/103
https://github.com/google/deepvariant/issues/103:158,deployability,updat,update,158,"@zyxue curious whether you're able to resolve this? I'm going to close this since the last update was a while ago. If you have more information, feel free to update and re-open.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/103
https://github.com/google/deepvariant/issues/103:91,safety,updat,update,91,"@zyxue curious whether you're able to resolve this? I'm going to close this since the last update was a while ago. If you have more information, feel free to update and re-open.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/103
https://github.com/google/deepvariant/issues/103:158,safety,updat,update,158,"@zyxue curious whether you're able to resolve this? I'm going to close this since the last update was a while ago. If you have more information, feel free to update and re-open.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/103
https://github.com/google/deepvariant/issues/103:91,security,updat,update,91,"@zyxue curious whether you're able to resolve this? I'm going to close this since the last update was a while ago. If you have more information, feel free to update and re-open.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/103
https://github.com/google/deepvariant/issues/103:158,security,updat,update,158,"@zyxue curious whether you're able to resolve this? I'm going to close this since the last update was a while ago. If you have more information, feel free to update and re-open.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/103
https://github.com/google/deepvariant/issues/103:65,usability,close,close,65,"@zyxue curious whether you're able to resolve this? I'm going to close this since the last update was a while ago. If you have more information, feel free to update and re-open.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/103
https://github.com/google/deepvariant/issues/104:349,availability,error,error,349,"@AlfWa Have you tried it without running it being in interactive mode, basically without the `-it` flag? In interactive mode you usually need to do more work to get it to work. Try it first without that flag, but just curious why are you working with it in interactive mode as it should work outside of that mode? Are you getting the same attribute error that way too? . Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:349,performance,error,error,349,"@AlfWa Have you tried it without running it being in interactive mode, basically without the `-it` flag? In interactive mode you usually need to do more work to get it to work. Try it first without that flag, but just curious why are you working with it in interactive mode as it should work outside of that mode? Are you getting the same attribute error that way too? . Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:349,safety,error,error,349,"@AlfWa Have you tried it without running it being in interactive mode, basically without the `-it` flag? In interactive mode you usually need to do more work to get it to work. Try it first without that flag, but just curious why are you working with it in interactive mode as it should work outside of that mode? Are you getting the same attribute error that way too? . Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:53,usability,interact,interactive,53,"@AlfWa Have you tried it without running it being in interactive mode, basically without the `-it` flag? In interactive mode you usually need to do more work to get it to work. Try it first without that flag, but just curious why are you working with it in interactive mode as it should work outside of that mode? Are you getting the same attribute error that way too? . Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:108,usability,interact,interactive,108,"@AlfWa Have you tried it without running it being in interactive mode, basically without the `-it` flag? In interactive mode you usually need to do more work to get it to work. Try it first without that flag, but just curious why are you working with it in interactive mode as it should work outside of that mode? Are you getting the same attribute error that way too? . Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:257,usability,interact,interactive,257,"@AlfWa Have you tried it without running it being in interactive mode, basically without the `-it` flag? In interactive mode you usually need to do more work to get it to work. Try it first without that flag, but just curious why are you working with it in interactive mode as it should work outside of that mode? Are you getting the same attribute error that way too? . Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:349,usability,error,error,349,"@AlfWa Have you tried it without running it being in interactive mode, basically without the `-it` flag? In interactive mode you usually need to do more work to get it to work. Try it first without that flag, but just curious why are you working with it in interactive mode as it should work outside of that mode? Are you getting the same attribute error that way too? . Thanks,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:74,availability,Error,Error,74,"met same issue when we were trying to run deep variant on GCP Centos7 vm. Error was raised by the function call of psutil.cpu_freq(). https://github.com/google/deepvariant/blob/r0.7/deepvariant/resources.py#L158 . psutil.cpu_freq function is only defined under the condition . os.path.exists(""/sys/devices/system/cpu/cpufreq"") or os.path.exists(""/sys/devices/system/cpu/cpu0/cpufreq""). https://github.com/giampaolo/psutil/blob/release-5.4.2/psutil/_pslinux.py#L656-L657. So the issue is that the required paths do not exist in the CentOS 7 release. existence check of the paths before calling psutil.cpu_freq() should solve the issue.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:194,deployability,resourc,resources,194,"met same issue when we were trying to run deep variant on GCP Centos7 vm. Error was raised by the function call of psutil.cpu_freq(). https://github.com/google/deepvariant/blob/r0.7/deepvariant/resources.py#L158 . psutil.cpu_freq function is only defined under the condition . os.path.exists(""/sys/devices/system/cpu/cpufreq"") or os.path.exists(""/sys/devices/system/cpu/cpu0/cpufreq""). https://github.com/giampaolo/psutil/blob/release-5.4.2/psutil/_pslinux.py#L656-L657. So the issue is that the required paths do not exist in the CentOS 7 release. existence check of the paths before calling psutil.cpu_freq() should solve the issue.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:427,deployability,releas,release-,427,"met same issue when we were trying to run deep variant on GCP Centos7 vm. Error was raised by the function call of psutil.cpu_freq(). https://github.com/google/deepvariant/blob/r0.7/deepvariant/resources.py#L158 . psutil.cpu_freq function is only defined under the condition . os.path.exists(""/sys/devices/system/cpu/cpufreq"") or os.path.exists(""/sys/devices/system/cpu/cpu0/cpufreq""). https://github.com/giampaolo/psutil/blob/release-5.4.2/psutil/_pslinux.py#L656-L657. So the issue is that the required paths do not exist in the CentOS 7 release. existence check of the paths before calling psutil.cpu_freq() should solve the issue.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:540,deployability,releas,release,540,"met same issue when we were trying to run deep variant on GCP Centos7 vm. Error was raised by the function call of psutil.cpu_freq(). https://github.com/google/deepvariant/blob/r0.7/deepvariant/resources.py#L158 . psutil.cpu_freq function is only defined under the condition . os.path.exists(""/sys/devices/system/cpu/cpufreq"") or os.path.exists(""/sys/devices/system/cpu/cpu0/cpufreq""). https://github.com/giampaolo/psutil/blob/release-5.4.2/psutil/_pslinux.py#L656-L657. So the issue is that the required paths do not exist in the CentOS 7 release. existence check of the paths before calling psutil.cpu_freq() should solve the issue.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:194,energy efficiency,resourc,resources,194,"met same issue when we were trying to run deep variant on GCP Centos7 vm. Error was raised by the function call of psutil.cpu_freq(). https://github.com/google/deepvariant/blob/r0.7/deepvariant/resources.py#L158 . psutil.cpu_freq function is only defined under the condition . os.path.exists(""/sys/devices/system/cpu/cpufreq"") or os.path.exists(""/sys/devices/system/cpu/cpu0/cpufreq""). https://github.com/giampaolo/psutil/blob/release-5.4.2/psutil/_pslinux.py#L656-L657. So the issue is that the required paths do not exist in the CentOS 7 release. existence check of the paths before calling psutil.cpu_freq() should solve the issue.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:313,energy efficiency,cpu,cpu,313,"met same issue when we were trying to run deep variant on GCP Centos7 vm. Error was raised by the function call of psutil.cpu_freq(). https://github.com/google/deepvariant/blob/r0.7/deepvariant/resources.py#L158 . psutil.cpu_freq function is only defined under the condition . os.path.exists(""/sys/devices/system/cpu/cpufreq"") or os.path.exists(""/sys/devices/system/cpu/cpu0/cpufreq""). https://github.com/giampaolo/psutil/blob/release-5.4.2/psutil/_pslinux.py#L656-L657. So the issue is that the required paths do not exist in the CentOS 7 release. existence check of the paths before calling psutil.cpu_freq() should solve the issue.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:317,energy efficiency,cpu,cpufreq,317,"met same issue when we were trying to run deep variant on GCP Centos7 vm. Error was raised by the function call of psutil.cpu_freq(). https://github.com/google/deepvariant/blob/r0.7/deepvariant/resources.py#L158 . psutil.cpu_freq function is only defined under the condition . os.path.exists(""/sys/devices/system/cpu/cpufreq"") or os.path.exists(""/sys/devices/system/cpu/cpu0/cpufreq""). https://github.com/giampaolo/psutil/blob/release-5.4.2/psutil/_pslinux.py#L656-L657. So the issue is that the required paths do not exist in the CentOS 7 release. existence check of the paths before calling psutil.cpu_freq() should solve the issue.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:366,energy efficiency,cpu,cpu,366,"met same issue when we were trying to run deep variant on GCP Centos7 vm. Error was raised by the function call of psutil.cpu_freq(). https://github.com/google/deepvariant/blob/r0.7/deepvariant/resources.py#L158 . psutil.cpu_freq function is only defined under the condition . os.path.exists(""/sys/devices/system/cpu/cpufreq"") or os.path.exists(""/sys/devices/system/cpu/cpu0/cpufreq""). https://github.com/giampaolo/psutil/blob/release-5.4.2/psutil/_pslinux.py#L656-L657. So the issue is that the required paths do not exist in the CentOS 7 release. existence check of the paths before calling psutil.cpu_freq() should solve the issue.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:375,energy efficiency,cpu,cpufreq,375,"met same issue when we were trying to run deep variant on GCP Centos7 vm. Error was raised by the function call of psutil.cpu_freq(). https://github.com/google/deepvariant/blob/r0.7/deepvariant/resources.py#L158 . psutil.cpu_freq function is only defined under the condition . os.path.exists(""/sys/devices/system/cpu/cpufreq"") or os.path.exists(""/sys/devices/system/cpu/cpu0/cpufreq""). https://github.com/giampaolo/psutil/blob/release-5.4.2/psutil/_pslinux.py#L656-L657. So the issue is that the required paths do not exist in the CentOS 7 release. existence check of the paths before calling psutil.cpu_freq() should solve the issue.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:74,performance,Error,Error,74,"met same issue when we were trying to run deep variant on GCP Centos7 vm. Error was raised by the function call of psutil.cpu_freq(). https://github.com/google/deepvariant/blob/r0.7/deepvariant/resources.py#L158 . psutil.cpu_freq function is only defined under the condition . os.path.exists(""/sys/devices/system/cpu/cpufreq"") or os.path.exists(""/sys/devices/system/cpu/cpu0/cpufreq""). https://github.com/giampaolo/psutil/blob/release-5.4.2/psutil/_pslinux.py#L656-L657. So the issue is that the required paths do not exist in the CentOS 7 release. existence check of the paths before calling psutil.cpu_freq() should solve the issue.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:194,performance,resourc,resources,194,"met same issue when we were trying to run deep variant on GCP Centos7 vm. Error was raised by the function call of psutil.cpu_freq(). https://github.com/google/deepvariant/blob/r0.7/deepvariant/resources.py#L158 . psutil.cpu_freq function is only defined under the condition . os.path.exists(""/sys/devices/system/cpu/cpufreq"") or os.path.exists(""/sys/devices/system/cpu/cpu0/cpufreq""). https://github.com/giampaolo/psutil/blob/release-5.4.2/psutil/_pslinux.py#L656-L657. So the issue is that the required paths do not exist in the CentOS 7 release. existence check of the paths before calling psutil.cpu_freq() should solve the issue.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:313,performance,cpu,cpu,313,"met same issue when we were trying to run deep variant on GCP Centos7 vm. Error was raised by the function call of psutil.cpu_freq(). https://github.com/google/deepvariant/blob/r0.7/deepvariant/resources.py#L158 . psutil.cpu_freq function is only defined under the condition . os.path.exists(""/sys/devices/system/cpu/cpufreq"") or os.path.exists(""/sys/devices/system/cpu/cpu0/cpufreq""). https://github.com/giampaolo/psutil/blob/release-5.4.2/psutil/_pslinux.py#L656-L657. So the issue is that the required paths do not exist in the CentOS 7 release. existence check of the paths before calling psutil.cpu_freq() should solve the issue.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:317,performance,cpu,cpufreq,317,"met same issue when we were trying to run deep variant on GCP Centos7 vm. Error was raised by the function call of psutil.cpu_freq(). https://github.com/google/deepvariant/blob/r0.7/deepvariant/resources.py#L158 . psutil.cpu_freq function is only defined under the condition . os.path.exists(""/sys/devices/system/cpu/cpufreq"") or os.path.exists(""/sys/devices/system/cpu/cpu0/cpufreq""). https://github.com/giampaolo/psutil/blob/release-5.4.2/psutil/_pslinux.py#L656-L657. So the issue is that the required paths do not exist in the CentOS 7 release. existence check of the paths before calling psutil.cpu_freq() should solve the issue.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:366,performance,cpu,cpu,366,"met same issue when we were trying to run deep variant on GCP Centos7 vm. Error was raised by the function call of psutil.cpu_freq(). https://github.com/google/deepvariant/blob/r0.7/deepvariant/resources.py#L158 . psutil.cpu_freq function is only defined under the condition . os.path.exists(""/sys/devices/system/cpu/cpufreq"") or os.path.exists(""/sys/devices/system/cpu/cpu0/cpufreq""). https://github.com/giampaolo/psutil/blob/release-5.4.2/psutil/_pslinux.py#L656-L657. So the issue is that the required paths do not exist in the CentOS 7 release. existence check of the paths before calling psutil.cpu_freq() should solve the issue.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:375,performance,cpu,cpufreq,375,"met same issue when we were trying to run deep variant on GCP Centos7 vm. Error was raised by the function call of psutil.cpu_freq(). https://github.com/google/deepvariant/blob/r0.7/deepvariant/resources.py#L158 . psutil.cpu_freq function is only defined under the condition . os.path.exists(""/sys/devices/system/cpu/cpufreq"") or os.path.exists(""/sys/devices/system/cpu/cpu0/cpufreq""). https://github.com/giampaolo/psutil/blob/release-5.4.2/psutil/_pslinux.py#L656-L657. So the issue is that the required paths do not exist in the CentOS 7 release. existence check of the paths before calling psutil.cpu_freq() should solve the issue.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:74,safety,Error,Error,74,"met same issue when we were trying to run deep variant on GCP Centos7 vm. Error was raised by the function call of psutil.cpu_freq(). https://github.com/google/deepvariant/blob/r0.7/deepvariant/resources.py#L158 . psutil.cpu_freq function is only defined under the condition . os.path.exists(""/sys/devices/system/cpu/cpufreq"") or os.path.exists(""/sys/devices/system/cpu/cpu0/cpufreq""). https://github.com/giampaolo/psutil/blob/release-5.4.2/psutil/_pslinux.py#L656-L657. So the issue is that the required paths do not exist in the CentOS 7 release. existence check of the paths before calling psutil.cpu_freq() should solve the issue.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:194,safety,resourc,resources,194,"met same issue when we were trying to run deep variant on GCP Centos7 vm. Error was raised by the function call of psutil.cpu_freq(). https://github.com/google/deepvariant/blob/r0.7/deepvariant/resources.py#L158 . psutil.cpu_freq function is only defined under the condition . os.path.exists(""/sys/devices/system/cpu/cpufreq"") or os.path.exists(""/sys/devices/system/cpu/cpu0/cpufreq""). https://github.com/giampaolo/psutil/blob/release-5.4.2/psutil/_pslinux.py#L656-L657. So the issue is that the required paths do not exist in the CentOS 7 release. existence check of the paths before calling psutil.cpu_freq() should solve the issue.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:194,testability,resourc,resources,194,"met same issue when we were trying to run deep variant on GCP Centos7 vm. Error was raised by the function call of psutil.cpu_freq(). https://github.com/google/deepvariant/blob/r0.7/deepvariant/resources.py#L158 . psutil.cpu_freq function is only defined under the condition . os.path.exists(""/sys/devices/system/cpu/cpufreq"") or os.path.exists(""/sys/devices/system/cpu/cpu0/cpufreq""). https://github.com/giampaolo/psutil/blob/release-5.4.2/psutil/_pslinux.py#L656-L657. So the issue is that the required paths do not exist in the CentOS 7 release. existence check of the paths before calling psutil.cpu_freq() should solve the issue.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:74,usability,Error,Error,74,"met same issue when we were trying to run deep variant on GCP Centos7 vm. Error was raised by the function call of psutil.cpu_freq(). https://github.com/google/deepvariant/blob/r0.7/deepvariant/resources.py#L158 . psutil.cpu_freq function is only defined under the condition . os.path.exists(""/sys/devices/system/cpu/cpufreq"") or os.path.exists(""/sys/devices/system/cpu/cpu0/cpufreq""). https://github.com/giampaolo/psutil/blob/release-5.4.2/psutil/_pslinux.py#L656-L657. So the issue is that the required paths do not exist in the CentOS 7 release. existence check of the paths before calling psutil.cpu_freq() should solve the issue.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:294,deployability,modul,modules,294,"Unbelievable! Thanks for the pointing this out @obigbando! . @AlfWa you probably would need to set `intel_pstate=disable` at boot time as a kernel argument, and then `cpupower` - or if really necessary `modprobe` - according to what is listed in the directory using this command:. ```. ls /lib/modules/`uname -r`/kernel/drivers/cpufreq/. ```. You'll probably see something like the following, or close to it which might include `acpi-cpufreq`:. ```. $ ls /lib/modules/`uname -r`/kernel/drivers/cpufreq/. cpufreq_conservative.ko cpufreq_powersave.ko freq_table.ko. cpufreq_ondemand.ko cpufreq_stats.ko. $. ```. Try reading the following version 7 documentation carefully:. https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/7/html/power_management_guide/cpufreq_governors. I included also the version 6 with `modprobe` just in case:. https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/6/html/power_management_guide/cpufreq_setup. Let us know if you run into any issues. ~p.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:460,deployability,modul,modules,460,"Unbelievable! Thanks for the pointing this out @obigbando! . @AlfWa you probably would need to set `intel_pstate=disable` at boot time as a kernel argument, and then `cpupower` - or if really necessary `modprobe` - according to what is listed in the directory using this command:. ```. ls /lib/modules/`uname -r`/kernel/drivers/cpufreq/. ```. You'll probably see something like the following, or close to it which might include `acpi-cpufreq`:. ```. $ ls /lib/modules/`uname -r`/kernel/drivers/cpufreq/. cpufreq_conservative.ko cpufreq_powersave.ko freq_table.ko. cpufreq_ondemand.ko cpufreq_stats.ko. $. ```. Try reading the following version 7 documentation carefully:. https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/7/html/power_management_guide/cpufreq_governors. I included also the version 6 with `modprobe` just in case:. https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/6/html/power_management_guide/cpufreq_setup. Let us know if you run into any issues. ~p.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:636,deployability,version,version,636,"Unbelievable! Thanks for the pointing this out @obigbando! . @AlfWa you probably would need to set `intel_pstate=disable` at boot time as a kernel argument, and then `cpupower` - or if really necessary `modprobe` - according to what is listed in the directory using this command:. ```. ls /lib/modules/`uname -r`/kernel/drivers/cpufreq/. ```. You'll probably see something like the following, or close to it which might include `acpi-cpufreq`:. ```. $ ls /lib/modules/`uname -r`/kernel/drivers/cpufreq/. cpufreq_conservative.ko cpufreq_powersave.ko freq_table.ko. cpufreq_ondemand.ko cpufreq_stats.ko. $. ```. Try reading the following version 7 documentation carefully:. https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/7/html/power_management_guide/cpufreq_governors. I included also the version 6 with `modprobe` just in case:. https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/6/html/power_management_guide/cpufreq_setup. Let us know if you run into any issues. ~p.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:812,deployability,version,version,812,"Unbelievable! Thanks for the pointing this out @obigbando! . @AlfWa you probably would need to set `intel_pstate=disable` at boot time as a kernel argument, and then `cpupower` - or if really necessary `modprobe` - according to what is listed in the directory using this command:. ```. ls /lib/modules/`uname -r`/kernel/drivers/cpufreq/. ```. You'll probably see something like the following, or close to it which might include `acpi-cpufreq`:. ```. $ ls /lib/modules/`uname -r`/kernel/drivers/cpufreq/. cpufreq_conservative.ko cpufreq_powersave.ko freq_table.ko. cpufreq_ondemand.ko cpufreq_stats.ko. $. ```. Try reading the following version 7 documentation carefully:. https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/7/html/power_management_guide/cpufreq_governors. I included also the version 6 with `modprobe` just in case:. https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/6/html/power_management_guide/cpufreq_setup. Let us know if you run into any issues. ~p.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:167,energy efficiency,cpu,cpupower,167,"Unbelievable! Thanks for the pointing this out @obigbando! . @AlfWa you probably would need to set `intel_pstate=disable` at boot time as a kernel argument, and then `cpupower` - or if really necessary `modprobe` - according to what is listed in the directory using this command:. ```. ls /lib/modules/`uname -r`/kernel/drivers/cpufreq/. ```. You'll probably see something like the following, or close to it which might include `acpi-cpufreq`:. ```. $ ls /lib/modules/`uname -r`/kernel/drivers/cpufreq/. cpufreq_conservative.ko cpufreq_powersave.ko freq_table.ko. cpufreq_ondemand.ko cpufreq_stats.ko. $. ```. Try reading the following version 7 documentation carefully:. https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/7/html/power_management_guide/cpufreq_governors. I included also the version 6 with `modprobe` just in case:. https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/6/html/power_management_guide/cpufreq_setup. Let us know if you run into any issues. ~p.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:328,energy efficiency,cpu,cpufreq,328,"Unbelievable! Thanks for the pointing this out @obigbando! . @AlfWa you probably would need to set `intel_pstate=disable` at boot time as a kernel argument, and then `cpupower` - or if really necessary `modprobe` - according to what is listed in the directory using this command:. ```. ls /lib/modules/`uname -r`/kernel/drivers/cpufreq/. ```. You'll probably see something like the following, or close to it which might include `acpi-cpufreq`:. ```. $ ls /lib/modules/`uname -r`/kernel/drivers/cpufreq/. cpufreq_conservative.ko cpufreq_powersave.ko freq_table.ko. cpufreq_ondemand.ko cpufreq_stats.ko. $. ```. Try reading the following version 7 documentation carefully:. https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/7/html/power_management_guide/cpufreq_governors. I included also the version 6 with `modprobe` just in case:. https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/6/html/power_management_guide/cpufreq_setup. Let us know if you run into any issues. ~p.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:434,energy efficiency,cpu,cpufreq,434,"Unbelievable! Thanks for the pointing this out @obigbando! . @AlfWa you probably would need to set `intel_pstate=disable` at boot time as a kernel argument, and then `cpupower` - or if really necessary `modprobe` - according to what is listed in the directory using this command:. ```. ls /lib/modules/`uname -r`/kernel/drivers/cpufreq/. ```. You'll probably see something like the following, or close to it which might include `acpi-cpufreq`:. ```. $ ls /lib/modules/`uname -r`/kernel/drivers/cpufreq/. cpufreq_conservative.ko cpufreq_powersave.ko freq_table.ko. cpufreq_ondemand.ko cpufreq_stats.ko. $. ```. Try reading the following version 7 documentation carefully:. https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/7/html/power_management_guide/cpufreq_governors. I included also the version 6 with `modprobe` just in case:. https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/6/html/power_management_guide/cpufreq_setup. Let us know if you run into any issues. ~p.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:494,energy efficiency,cpu,cpufreq,494,"Unbelievable! Thanks for the pointing this out @obigbando! . @AlfWa you probably would need to set `intel_pstate=disable` at boot time as a kernel argument, and then `cpupower` - or if really necessary `modprobe` - according to what is listed in the directory using this command:. ```. ls /lib/modules/`uname -r`/kernel/drivers/cpufreq/. ```. You'll probably see something like the following, or close to it which might include `acpi-cpufreq`:. ```. $ ls /lib/modules/`uname -r`/kernel/drivers/cpufreq/. cpufreq_conservative.ko cpufreq_powersave.ko freq_table.ko. cpufreq_ondemand.ko cpufreq_stats.ko. $. ```. Try reading the following version 7 documentation carefully:. https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/7/html/power_management_guide/cpufreq_governors. I included also the version 6 with `modprobe` just in case:. https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/6/html/power_management_guide/cpufreq_setup. Let us know if you run into any issues. ~p.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:636,integrability,version,version,636,"Unbelievable! Thanks for the pointing this out @obigbando! . @AlfWa you probably would need to set `intel_pstate=disable` at boot time as a kernel argument, and then `cpupower` - or if really necessary `modprobe` - according to what is listed in the directory using this command:. ```. ls /lib/modules/`uname -r`/kernel/drivers/cpufreq/. ```. You'll probably see something like the following, or close to it which might include `acpi-cpufreq`:. ```. $ ls /lib/modules/`uname -r`/kernel/drivers/cpufreq/. cpufreq_conservative.ko cpufreq_powersave.ko freq_table.ko. cpufreq_ondemand.ko cpufreq_stats.ko. $. ```. Try reading the following version 7 documentation carefully:. https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/7/html/power_management_guide/cpufreq_governors. I included also the version 6 with `modprobe` just in case:. https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/6/html/power_management_guide/cpufreq_setup. Let us know if you run into any issues. ~p.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:812,integrability,version,version,812,"Unbelievable! Thanks for the pointing this out @obigbando! . @AlfWa you probably would need to set `intel_pstate=disable` at boot time as a kernel argument, and then `cpupower` - or if really necessary `modprobe` - according to what is listed in the directory using this command:. ```. ls /lib/modules/`uname -r`/kernel/drivers/cpufreq/. ```. You'll probably see something like the following, or close to it which might include `acpi-cpufreq`:. ```. $ ls /lib/modules/`uname -r`/kernel/drivers/cpufreq/. cpufreq_conservative.ko cpufreq_powersave.ko freq_table.ko. cpufreq_ondemand.ko cpufreq_stats.ko. $. ```. Try reading the following version 7 documentation carefully:. https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/7/html/power_management_guide/cpufreq_governors. I included also the version 6 with `modprobe` just in case:. https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/6/html/power_management_guide/cpufreq_setup. Let us know if you run into any issues. ~p.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:294,modifiability,modul,modules,294,"Unbelievable! Thanks for the pointing this out @obigbando! . @AlfWa you probably would need to set `intel_pstate=disable` at boot time as a kernel argument, and then `cpupower` - or if really necessary `modprobe` - according to what is listed in the directory using this command:. ```. ls /lib/modules/`uname -r`/kernel/drivers/cpufreq/. ```. You'll probably see something like the following, or close to it which might include `acpi-cpufreq`:. ```. $ ls /lib/modules/`uname -r`/kernel/drivers/cpufreq/. cpufreq_conservative.ko cpufreq_powersave.ko freq_table.ko. cpufreq_ondemand.ko cpufreq_stats.ko. $. ```. Try reading the following version 7 documentation carefully:. https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/7/html/power_management_guide/cpufreq_governors. I included also the version 6 with `modprobe` just in case:. https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/6/html/power_management_guide/cpufreq_setup. Let us know if you run into any issues. ~p.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:460,modifiability,modul,modules,460,"Unbelievable! Thanks for the pointing this out @obigbando! . @AlfWa you probably would need to set `intel_pstate=disable` at boot time as a kernel argument, and then `cpupower` - or if really necessary `modprobe` - according to what is listed in the directory using this command:. ```. ls /lib/modules/`uname -r`/kernel/drivers/cpufreq/. ```. You'll probably see something like the following, or close to it which might include `acpi-cpufreq`:. ```. $ ls /lib/modules/`uname -r`/kernel/drivers/cpufreq/. cpufreq_conservative.ko cpufreq_powersave.ko freq_table.ko. cpufreq_ondemand.ko cpufreq_stats.ko. $. ```. Try reading the following version 7 documentation carefully:. https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/7/html/power_management_guide/cpufreq_governors. I included also the version 6 with `modprobe` just in case:. https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/6/html/power_management_guide/cpufreq_setup. Let us know if you run into any issues. ~p.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:636,modifiability,version,version,636,"Unbelievable! Thanks for the pointing this out @obigbando! . @AlfWa you probably would need to set `intel_pstate=disable` at boot time as a kernel argument, and then `cpupower` - or if really necessary `modprobe` - according to what is listed in the directory using this command:. ```. ls /lib/modules/`uname -r`/kernel/drivers/cpufreq/. ```. You'll probably see something like the following, or close to it which might include `acpi-cpufreq`:. ```. $ ls /lib/modules/`uname -r`/kernel/drivers/cpufreq/. cpufreq_conservative.ko cpufreq_powersave.ko freq_table.ko. cpufreq_ondemand.ko cpufreq_stats.ko. $. ```. Try reading the following version 7 documentation carefully:. https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/7/html/power_management_guide/cpufreq_governors. I included also the version 6 with `modprobe` just in case:. https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/6/html/power_management_guide/cpufreq_setup. Let us know if you run into any issues. ~p.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:812,modifiability,version,version,812,"Unbelievable! Thanks for the pointing this out @obigbando! . @AlfWa you probably would need to set `intel_pstate=disable` at boot time as a kernel argument, and then `cpupower` - or if really necessary `modprobe` - according to what is listed in the directory using this command:. ```. ls /lib/modules/`uname -r`/kernel/drivers/cpufreq/. ```. You'll probably see something like the following, or close to it which might include `acpi-cpufreq`:. ```. $ ls /lib/modules/`uname -r`/kernel/drivers/cpufreq/. cpufreq_conservative.ko cpufreq_powersave.ko freq_table.ko. cpufreq_ondemand.ko cpufreq_stats.ko. $. ```. Try reading the following version 7 documentation carefully:. https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/7/html/power_management_guide/cpufreq_governors. I included also the version 6 with `modprobe` just in case:. https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/6/html/power_management_guide/cpufreq_setup. Let us know if you run into any issues. ~p.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:130,performance,time,time,130,"Unbelievable! Thanks for the pointing this out @obigbando! . @AlfWa you probably would need to set `intel_pstate=disable` at boot time as a kernel argument, and then `cpupower` - or if really necessary `modprobe` - according to what is listed in the directory using this command:. ```. ls /lib/modules/`uname -r`/kernel/drivers/cpufreq/. ```. You'll probably see something like the following, or close to it which might include `acpi-cpufreq`:. ```. $ ls /lib/modules/`uname -r`/kernel/drivers/cpufreq/. cpufreq_conservative.ko cpufreq_powersave.ko freq_table.ko. cpufreq_ondemand.ko cpufreq_stats.ko. $. ```. Try reading the following version 7 documentation carefully:. https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/7/html/power_management_guide/cpufreq_governors. I included also the version 6 with `modprobe` just in case:. https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/6/html/power_management_guide/cpufreq_setup. Let us know if you run into any issues. ~p.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:167,performance,cpu,cpupower,167,"Unbelievable! Thanks for the pointing this out @obigbando! . @AlfWa you probably would need to set `intel_pstate=disable` at boot time as a kernel argument, and then `cpupower` - or if really necessary `modprobe` - according to what is listed in the directory using this command:. ```. ls /lib/modules/`uname -r`/kernel/drivers/cpufreq/. ```. You'll probably see something like the following, or close to it which might include `acpi-cpufreq`:. ```. $ ls /lib/modules/`uname -r`/kernel/drivers/cpufreq/. cpufreq_conservative.ko cpufreq_powersave.ko freq_table.ko. cpufreq_ondemand.ko cpufreq_stats.ko. $. ```. Try reading the following version 7 documentation carefully:. https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/7/html/power_management_guide/cpufreq_governors. I included also the version 6 with `modprobe` just in case:. https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/6/html/power_management_guide/cpufreq_setup. Let us know if you run into any issues. ~p.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:328,performance,cpu,cpufreq,328,"Unbelievable! Thanks for the pointing this out @obigbando! . @AlfWa you probably would need to set `intel_pstate=disable` at boot time as a kernel argument, and then `cpupower` - or if really necessary `modprobe` - according to what is listed in the directory using this command:. ```. ls /lib/modules/`uname -r`/kernel/drivers/cpufreq/. ```. You'll probably see something like the following, or close to it which might include `acpi-cpufreq`:. ```. $ ls /lib/modules/`uname -r`/kernel/drivers/cpufreq/. cpufreq_conservative.ko cpufreq_powersave.ko freq_table.ko. cpufreq_ondemand.ko cpufreq_stats.ko. $. ```. Try reading the following version 7 documentation carefully:. https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/7/html/power_management_guide/cpufreq_governors. I included also the version 6 with `modprobe` just in case:. https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/6/html/power_management_guide/cpufreq_setup. Let us know if you run into any issues. ~p.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:434,performance,cpu,cpufreq,434,"Unbelievable! Thanks for the pointing this out @obigbando! . @AlfWa you probably would need to set `intel_pstate=disable` at boot time as a kernel argument, and then `cpupower` - or if really necessary `modprobe` - according to what is listed in the directory using this command:. ```. ls /lib/modules/`uname -r`/kernel/drivers/cpufreq/. ```. You'll probably see something like the following, or close to it which might include `acpi-cpufreq`:. ```. $ ls /lib/modules/`uname -r`/kernel/drivers/cpufreq/. cpufreq_conservative.ko cpufreq_powersave.ko freq_table.ko. cpufreq_ondemand.ko cpufreq_stats.ko. $. ```. Try reading the following version 7 documentation carefully:. https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/7/html/power_management_guide/cpufreq_governors. I included also the version 6 with `modprobe` just in case:. https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/6/html/power_management_guide/cpufreq_setup. Let us know if you run into any issues. ~p.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:494,performance,cpu,cpufreq,494,"Unbelievable! Thanks for the pointing this out @obigbando! . @AlfWa you probably would need to set `intel_pstate=disable` at boot time as a kernel argument, and then `cpupower` - or if really necessary `modprobe` - according to what is listed in the directory using this command:. ```. ls /lib/modules/`uname -r`/kernel/drivers/cpufreq/. ```. You'll probably see something like the following, or close to it which might include `acpi-cpufreq`:. ```. $ ls /lib/modules/`uname -r`/kernel/drivers/cpufreq/. cpufreq_conservative.ko cpufreq_powersave.ko freq_table.ko. cpufreq_ondemand.ko cpufreq_stats.ko. $. ```. Try reading the following version 7 documentation carefully:. https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/7/html/power_management_guide/cpufreq_governors. I included also the version 6 with `modprobe` just in case:. https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/6/html/power_management_guide/cpufreq_setup. Let us know if you run into any issues. ~p.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:294,safety,modul,modules,294,"Unbelievable! Thanks for the pointing this out @obigbando! . @AlfWa you probably would need to set `intel_pstate=disable` at boot time as a kernel argument, and then `cpupower` - or if really necessary `modprobe` - according to what is listed in the directory using this command:. ```. ls /lib/modules/`uname -r`/kernel/drivers/cpufreq/. ```. You'll probably see something like the following, or close to it which might include `acpi-cpufreq`:. ```. $ ls /lib/modules/`uname -r`/kernel/drivers/cpufreq/. cpufreq_conservative.ko cpufreq_powersave.ko freq_table.ko. cpufreq_ondemand.ko cpufreq_stats.ko. $. ```. Try reading the following version 7 documentation carefully:. https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/7/html/power_management_guide/cpufreq_governors. I included also the version 6 with `modprobe` just in case:. https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/6/html/power_management_guide/cpufreq_setup. Let us know if you run into any issues. ~p.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:460,safety,modul,modules,460,"Unbelievable! Thanks for the pointing this out @obigbando! . @AlfWa you probably would need to set `intel_pstate=disable` at boot time as a kernel argument, and then `cpupower` - or if really necessary `modprobe` - according to what is listed in the directory using this command:. ```. ls /lib/modules/`uname -r`/kernel/drivers/cpufreq/. ```. You'll probably see something like the following, or close to it which might include `acpi-cpufreq`:. ```. $ ls /lib/modules/`uname -r`/kernel/drivers/cpufreq/. cpufreq_conservative.ko cpufreq_powersave.ko freq_table.ko. cpufreq_ondemand.ko cpufreq_stats.ko. $. ```. Try reading the following version 7 documentation carefully:. https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/7/html/power_management_guide/cpufreq_governors. I included also the version 6 with `modprobe` just in case:. https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/6/html/power_management_guide/cpufreq_setup. Let us know if you run into any issues. ~p.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:680,security,access,access,680,"Unbelievable! Thanks for the pointing this out @obigbando! . @AlfWa you probably would need to set `intel_pstate=disable` at boot time as a kernel argument, and then `cpupower` - or if really necessary `modprobe` - according to what is listed in the directory using this command:. ```. ls /lib/modules/`uname -r`/kernel/drivers/cpufreq/. ```. You'll probably see something like the following, or close to it which might include `acpi-cpufreq`:. ```. $ ls /lib/modules/`uname -r`/kernel/drivers/cpufreq/. cpufreq_conservative.ko cpufreq_powersave.ko freq_table.ko. cpufreq_ondemand.ko cpufreq_stats.ko. $. ```. Try reading the following version 7 documentation carefully:. https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/7/html/power_management_guide/cpufreq_governors. I included also the version 6 with `modprobe` just in case:. https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/6/html/power_management_guide/cpufreq_setup. Let us know if you run into any issues. ~p.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:861,security,access,access,861,"Unbelievable! Thanks for the pointing this out @obigbando! . @AlfWa you probably would need to set `intel_pstate=disable` at boot time as a kernel argument, and then `cpupower` - or if really necessary `modprobe` - according to what is listed in the directory using this command:. ```. ls /lib/modules/`uname -r`/kernel/drivers/cpufreq/. ```. You'll probably see something like the following, or close to it which might include `acpi-cpufreq`:. ```. $ ls /lib/modules/`uname -r`/kernel/drivers/cpufreq/. cpufreq_conservative.ko cpufreq_powersave.ko freq_table.ko. cpufreq_ondemand.ko cpufreq_stats.ko. $. ```. Try reading the following version 7 documentation carefully:. https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/7/html/power_management_guide/cpufreq_governors. I included also the version 6 with `modprobe` just in case:. https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/6/html/power_management_guide/cpufreq_setup. Let us know if you run into any issues. ~p.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:271,usability,command,command,271,"Unbelievable! Thanks for the pointing this out @obigbando! . @AlfWa you probably would need to set `intel_pstate=disable` at boot time as a kernel argument, and then `cpupower` - or if really necessary `modprobe` - according to what is listed in the directory using this command:. ```. ls /lib/modules/`uname -r`/kernel/drivers/cpufreq/. ```. You'll probably see something like the following, or close to it which might include `acpi-cpufreq`:. ```. $ ls /lib/modules/`uname -r`/kernel/drivers/cpufreq/. cpufreq_conservative.ko cpufreq_powersave.ko freq_table.ko. cpufreq_ondemand.ko cpufreq_stats.ko. $. ```. Try reading the following version 7 documentation carefully:. https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/7/html/power_management_guide/cpufreq_governors. I included also the version 6 with `modprobe` just in case:. https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/6/html/power_management_guide/cpufreq_setup. Let us know if you run into any issues. ~p.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:396,usability,close,close,396,"Unbelievable! Thanks for the pointing this out @obigbando! . @AlfWa you probably would need to set `intel_pstate=disable` at boot time as a kernel argument, and then `cpupower` - or if really necessary `modprobe` - according to what is listed in the directory using this command:. ```. ls /lib/modules/`uname -r`/kernel/drivers/cpufreq/. ```. You'll probably see something like the following, or close to it which might include `acpi-cpufreq`:. ```. $ ls /lib/modules/`uname -r`/kernel/drivers/cpufreq/. cpufreq_conservative.ko cpufreq_powersave.ko freq_table.ko. cpufreq_ondemand.ko cpufreq_stats.ko. $. ```. Try reading the following version 7 documentation carefully:. https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/7/html/power_management_guide/cpufreq_governors. I included also the version 6 with `modprobe` just in case:. https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/6/html/power_management_guide/cpufreq_setup. Let us know if you run into any issues. ~p.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:646,usability,document,documentation,646,"Unbelievable! Thanks for the pointing this out @obigbando! . @AlfWa you probably would need to set `intel_pstate=disable` at boot time as a kernel argument, and then `cpupower` - or if really necessary `modprobe` - according to what is listed in the directory using this command:. ```. ls /lib/modules/`uname -r`/kernel/drivers/cpufreq/. ```. You'll probably see something like the following, or close to it which might include `acpi-cpufreq`:. ```. $ ls /lib/modules/`uname -r`/kernel/drivers/cpufreq/. cpufreq_conservative.ko cpufreq_powersave.ko freq_table.ko. cpufreq_ondemand.ko cpufreq_stats.ko. $. ```. Try reading the following version 7 documentation carefully:. https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/7/html/power_management_guide/cpufreq_governors. I included also the version 6 with `modprobe` just in case:. https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/6/html/power_management_guide/cpufreq_setup. Let us know if you run into any issues. ~p.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:698,usability,document,documentation,698,"Unbelievable! Thanks for the pointing this out @obigbando! . @AlfWa you probably would need to set `intel_pstate=disable` at boot time as a kernel argument, and then `cpupower` - or if really necessary `modprobe` - according to what is listed in the directory using this command:. ```. ls /lib/modules/`uname -r`/kernel/drivers/cpufreq/. ```. You'll probably see something like the following, or close to it which might include `acpi-cpufreq`:. ```. $ ls /lib/modules/`uname -r`/kernel/drivers/cpufreq/. cpufreq_conservative.ko cpufreq_powersave.ko freq_table.ko. cpufreq_ondemand.ko cpufreq_stats.ko. $. ```. Try reading the following version 7 documentation carefully:. https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/7/html/power_management_guide/cpufreq_governors. I included also the version 6 with `modprobe` just in case:. https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/6/html/power_management_guide/cpufreq_setup. Let us know if you run into any issues. ~p.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:879,usability,document,documentation,879,"Unbelievable! Thanks for the pointing this out @obigbando! . @AlfWa you probably would need to set `intel_pstate=disable` at boot time as a kernel argument, and then `cpupower` - or if really necessary `modprobe` - according to what is listed in the directory using this command:. ```. ls /lib/modules/`uname -r`/kernel/drivers/cpufreq/. ```. You'll probably see something like the following, or close to it which might include `acpi-cpufreq`:. ```. $ ls /lib/modules/`uname -r`/kernel/drivers/cpufreq/. cpufreq_conservative.ko cpufreq_powersave.ko freq_table.ko. cpufreq_ondemand.ko cpufreq_stats.ko. $. ```. Try reading the following version 7 documentation carefully:. https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/7/html/power_management_guide/cpufreq_governors. I included also the version 6 with `modprobe` just in case:. https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/6/html/power_management_guide/cpufreq_setup. Let us know if you run into any issues. ~p.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:90,energy efficiency,cpu,cpufreq,90,We're seeing this same problem on centos7 on new processors for which there is no working cpufreq support. Why not just wrap the call to `psutil.cpu_freq` in a `try`? I'm happy to provide a PR for that. (cc: @njcarriero @chris-sf),MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:120,integrability,wrap,wrap,120,We're seeing this same problem on centos7 on new processors for which there is no working cpufreq support. Why not just wrap the call to `psutil.cpu_freq` in a `try`? I'm happy to provide a PR for that. (cc: @njcarriero @chris-sf),MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:90,performance,cpu,cpufreq,90,We're seeing this same problem on centos7 on new processors for which there is no working cpufreq support. Why not just wrap the call to `psutil.cpu_freq` in a `try`? I'm happy to provide a PR for that. (cc: @njcarriero @chris-sf),MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:98,usability,support,support,98,We're seeing this same problem on centos7 on new processors for which there is no working cpufreq support. Why not just wrap the call to `psutil.cpu_freq` in a `try`? I'm happy to provide a PR for that. (cc: @njcarriero @chris-sf),MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:95,deployability,build,building,95,All it seems to be doing is be fed to `cpu_frequency_mhz` in `_initial_metrics_protobuf()` for building the `resource_metrics` in `make_examples` via a `ResourceMonitor` class instantiation. It does not seem to be used in any calculations other than keeping track of that. I guess `freq` could even be set to 0.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:153,deployability,Resourc,ResourceMonitor,153,All it seems to be doing is be fed to `cpu_frequency_mhz` in `_initial_metrics_protobuf()` for building the `resource_metrics` in `make_examples` via a `ResourceMonitor` class instantiation. It does not seem to be used in any calculations other than keeping track of that. I guess `freq` could even be set to 0.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:153,energy efficiency,Resourc,ResourceMonitor,153,All it seems to be doing is be fed to `cpu_frequency_mhz` in `_initial_metrics_protobuf()` for building the `resource_metrics` in `make_examples` via a `ResourceMonitor` class instantiation. It does not seem to be used in any calculations other than keeping track of that. I guess `freq` could even be set to 0.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:153,performance,Resourc,ResourceMonitor,153,All it seems to be doing is be fed to `cpu_frequency_mhz` in `_initial_metrics_protobuf()` for building the `resource_metrics` in `make_examples` via a `ResourceMonitor` class instantiation. It does not seem to be used in any calculations other than keeping track of that. I guess `freq` could even be set to 0.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:194,reliability,doe,does,194,All it seems to be doing is be fed to `cpu_frequency_mhz` in `_initial_metrics_protobuf()` for building the `resource_metrics` in `make_examples` via a `ResourceMonitor` class instantiation. It does not seem to be used in any calculations other than keeping track of that. I guess `freq` could even be set to 0.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:153,safety,Resourc,ResourceMonitor,153,All it seems to be doing is be fed to `cpu_frequency_mhz` in `_initial_metrics_protobuf()` for building the `resource_metrics` in `make_examples` via a `ResourceMonitor` class instantiation. It does not seem to be used in any calculations other than keeping track of that. I guess `freq` could even be set to 0.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:153,testability,Resourc,ResourceMonitor,153,All it seems to be doing is be fed to `cpu_frequency_mhz` in `_initial_metrics_protobuf()` for building the `resource_metrics` in `make_examples` via a `ResourceMonitor` class instantiation. It does not seem to be used in any calculations other than keeping track of that. I guess `freq` could even be set to 0.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:52,availability,error,error,52,"Hi,. Is there a fix for this? I am getting the same error: AttributeError: 'module' object has no attribute 'cpu_freq'. This error persists even when I include intel_pstate=disable . Thank you!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:125,availability,error,error,125,"Hi,. Is there a fix for this? I am getting the same error: AttributeError: 'module' object has no attribute 'cpu_freq'. This error persists even when I include intel_pstate=disable . Thank you!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:76,deployability,modul,module,76,"Hi,. Is there a fix for this? I am getting the same error: AttributeError: 'module' object has no attribute 'cpu_freq'. This error persists even when I include intel_pstate=disable . Thank you!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:76,modifiability,modul,module,76,"Hi,. Is there a fix for this? I am getting the same error: AttributeError: 'module' object has no attribute 'cpu_freq'. This error persists even when I include intel_pstate=disable . Thank you!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:52,performance,error,error,52,"Hi,. Is there a fix for this? I am getting the same error: AttributeError: 'module' object has no attribute 'cpu_freq'. This error persists even when I include intel_pstate=disable . Thank you!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:125,performance,error,error,125,"Hi,. Is there a fix for this? I am getting the same error: AttributeError: 'module' object has no attribute 'cpu_freq'. This error persists even when I include intel_pstate=disable . Thank you!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:52,safety,error,error,52,"Hi,. Is there a fix for this? I am getting the same error: AttributeError: 'module' object has no attribute 'cpu_freq'. This error persists even when I include intel_pstate=disable . Thank you!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:76,safety,modul,module,76,"Hi,. Is there a fix for this? I am getting the same error: AttributeError: 'module' object has no attribute 'cpu_freq'. This error persists even when I include intel_pstate=disable . Thank you!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:125,safety,error,error,125,"Hi,. Is there a fix for this? I am getting the same error: AttributeError: 'module' object has no attribute 'cpu_freq'. This error persists even when I include intel_pstate=disable . Thank you!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:52,usability,error,error,52,"Hi,. Is there a fix for this? I am getting the same error: AttributeError: 'module' object has no attribute 'cpu_freq'. This error persists even when I include intel_pstate=disable . Thank you!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:125,usability,error,error,125,"Hi,. Is there a fix for this? I am getting the same error: AttributeError: 'module' object has no attribute 'cpu_freq'. This error persists even when I include intel_pstate=disable . Thank you!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:751,availability,servic,service,751,"Hi,. can you try the 0.7.1 image? It seems to work for me on CentOS7 now. I was able to run the Exome case study with the following steps:. I used a GCE instance for testing:. ```. gcloud beta compute instances create ""${USER}-centos-test"" \. --scopes ""compute-rw,storage-full,cloud-platform"" \. --image ""centos-7-v20181011"" \. --image-project centos-cloud \. --machine-type ""custom-64-131072"" \. --boot-disk-size ""300"" \. --boot-disk-type ""pd-ssd"" \. --zone ""us-west1-b"". ```. I sshed into the machine, and checked the OS version:. ```. [pichuan@pichuan-centos-test ~]$ cat /etc/redhat-release. CentOS Linux release 7.5.1804 (Core) . ```. Then:. ```. [pichuan@pichuan-centos-test ~]$ sudo yum install -y docker. [pichuan@pichuan-centos-test ~]$ sudo service docker start. Redirecting to /bin/systemctl start docker.service. [pichuan@pichuan-centos-test ~]$ sudo docker run -it gcr.io/deepvariant-docker/deepvariant:0.7.1. ```. Then, I use a modified script to run WES case study:. ```. root@5189b7fba95b:/# curl https://gist.githubusercontent.com/pichuan/7916a5574c47fd7a2422bad4e5f73860/raw/44fb4377c9ad8b54e195fdb31489d8e9fbc459e2/inside_docker.sh | bash. ```. You can see:. https://gist.githubusercontent.com/pichuan/7916a5574c47fd7a2422bad4e5f73860/raw/44fb4377c9ad8b54e195fdb31489d8e9fbc459e2/inside_docker.sh. for the script that I ran inside the docker. If the 0.7.1 version still doesn't work, feel free to reopen. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:816,availability,servic,service,816,"Hi,. can you try the 0.7.1 image? It seems to work for me on CentOS7 now. I was able to run the Exome case study with the following steps:. I used a GCE instance for testing:. ```. gcloud beta compute instances create ""${USER}-centos-test"" \. --scopes ""compute-rw,storage-full,cloud-platform"" \. --image ""centos-7-v20181011"" \. --image-project centos-cloud \. --machine-type ""custom-64-131072"" \. --boot-disk-size ""300"" \. --boot-disk-type ""pd-ssd"" \. --zone ""us-west1-b"". ```. I sshed into the machine, and checked the OS version:. ```. [pichuan@pichuan-centos-test ~]$ cat /etc/redhat-release. CentOS Linux release 7.5.1804 (Core) . ```. Then:. ```. [pichuan@pichuan-centos-test ~]$ sudo yum install -y docker. [pichuan@pichuan-centos-test ~]$ sudo service docker start. Redirecting to /bin/systemctl start docker.service. [pichuan@pichuan-centos-test ~]$ sudo docker run -it gcr.io/deepvariant-docker/deepvariant:0.7.1. ```. Then, I use a modified script to run WES case study:. ```. root@5189b7fba95b:/# curl https://gist.githubusercontent.com/pichuan/7916a5574c47fd7a2422bad4e5f73860/raw/44fb4377c9ad8b54e195fdb31489d8e9fbc459e2/inside_docker.sh | bash. ```. You can see:. https://gist.githubusercontent.com/pichuan/7916a5574c47fd7a2422bad4e5f73860/raw/44fb4377c9ad8b54e195fdb31489d8e9fbc459e2/inside_docker.sh. for the script that I ran inside the docker. If the 0.7.1 version still doesn't work, feel free to reopen. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:523,deployability,version,version,523,"Hi,. can you try the 0.7.1 image? It seems to work for me on CentOS7 now. I was able to run the Exome case study with the following steps:. I used a GCE instance for testing:. ```. gcloud beta compute instances create ""${USER}-centos-test"" \. --scopes ""compute-rw,storage-full,cloud-platform"" \. --image ""centos-7-v20181011"" \. --image-project centos-cloud \. --machine-type ""custom-64-131072"" \. --boot-disk-size ""300"" \. --boot-disk-type ""pd-ssd"" \. --zone ""us-west1-b"". ```. I sshed into the machine, and checked the OS version:. ```. [pichuan@pichuan-centos-test ~]$ cat /etc/redhat-release. CentOS Linux release 7.5.1804 (Core) . ```. Then:. ```. [pichuan@pichuan-centos-test ~]$ sudo yum install -y docker. [pichuan@pichuan-centos-test ~]$ sudo service docker start. Redirecting to /bin/systemctl start docker.service. [pichuan@pichuan-centos-test ~]$ sudo docker run -it gcr.io/deepvariant-docker/deepvariant:0.7.1. ```. Then, I use a modified script to run WES case study:. ```. root@5189b7fba95b:/# curl https://gist.githubusercontent.com/pichuan/7916a5574c47fd7a2422bad4e5f73860/raw/44fb4377c9ad8b54e195fdb31489d8e9fbc459e2/inside_docker.sh | bash. ```. You can see:. https://gist.githubusercontent.com/pichuan/7916a5574c47fd7a2422bad4e5f73860/raw/44fb4377c9ad8b54e195fdb31489d8e9fbc459e2/inside_docker.sh. for the script that I ran inside the docker. If the 0.7.1 version still doesn't work, feel free to reopen. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:587,deployability,releas,release,587,"Hi,. can you try the 0.7.1 image? It seems to work for me on CentOS7 now. I was able to run the Exome case study with the following steps:. I used a GCE instance for testing:. ```. gcloud beta compute instances create ""${USER}-centos-test"" \. --scopes ""compute-rw,storage-full,cloud-platform"" \. --image ""centos-7-v20181011"" \. --image-project centos-cloud \. --machine-type ""custom-64-131072"" \. --boot-disk-size ""300"" \. --boot-disk-type ""pd-ssd"" \. --zone ""us-west1-b"". ```. I sshed into the machine, and checked the OS version:. ```. [pichuan@pichuan-centos-test ~]$ cat /etc/redhat-release. CentOS Linux release 7.5.1804 (Core) . ```. Then:. ```. [pichuan@pichuan-centos-test ~]$ sudo yum install -y docker. [pichuan@pichuan-centos-test ~]$ sudo service docker start. Redirecting to /bin/systemctl start docker.service. [pichuan@pichuan-centos-test ~]$ sudo docker run -it gcr.io/deepvariant-docker/deepvariant:0.7.1. ```. Then, I use a modified script to run WES case study:. ```. root@5189b7fba95b:/# curl https://gist.githubusercontent.com/pichuan/7916a5574c47fd7a2422bad4e5f73860/raw/44fb4377c9ad8b54e195fdb31489d8e9fbc459e2/inside_docker.sh | bash. ```. You can see:. https://gist.githubusercontent.com/pichuan/7916a5574c47fd7a2422bad4e5f73860/raw/44fb4377c9ad8b54e195fdb31489d8e9fbc459e2/inside_docker.sh. for the script that I ran inside the docker. If the 0.7.1 version still doesn't work, feel free to reopen. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:609,deployability,releas,release,609,"Hi,. can you try the 0.7.1 image? It seems to work for me on CentOS7 now. I was able to run the Exome case study with the following steps:. I used a GCE instance for testing:. ```. gcloud beta compute instances create ""${USER}-centos-test"" \. --scopes ""compute-rw,storage-full,cloud-platform"" \. --image ""centos-7-v20181011"" \. --image-project centos-cloud \. --machine-type ""custom-64-131072"" \. --boot-disk-size ""300"" \. --boot-disk-type ""pd-ssd"" \. --zone ""us-west1-b"". ```. I sshed into the machine, and checked the OS version:. ```. [pichuan@pichuan-centos-test ~]$ cat /etc/redhat-release. CentOS Linux release 7.5.1804 (Core) . ```. Then:. ```. [pichuan@pichuan-centos-test ~]$ sudo yum install -y docker. [pichuan@pichuan-centos-test ~]$ sudo service docker start. Redirecting to /bin/systemctl start docker.service. [pichuan@pichuan-centos-test ~]$ sudo docker run -it gcr.io/deepvariant-docker/deepvariant:0.7.1. ```. Then, I use a modified script to run WES case study:. ```. root@5189b7fba95b:/# curl https://gist.githubusercontent.com/pichuan/7916a5574c47fd7a2422bad4e5f73860/raw/44fb4377c9ad8b54e195fdb31489d8e9fbc459e2/inside_docker.sh | bash. ```. You can see:. https://gist.githubusercontent.com/pichuan/7916a5574c47fd7a2422bad4e5f73860/raw/44fb4377c9ad8b54e195fdb31489d8e9fbc459e2/inside_docker.sh. for the script that I ran inside the docker. If the 0.7.1 version still doesn't work, feel free to reopen. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:694,deployability,instal,install,694,"Hi,. can you try the 0.7.1 image? It seems to work for me on CentOS7 now. I was able to run the Exome case study with the following steps:. I used a GCE instance for testing:. ```. gcloud beta compute instances create ""${USER}-centos-test"" \. --scopes ""compute-rw,storage-full,cloud-platform"" \. --image ""centos-7-v20181011"" \. --image-project centos-cloud \. --machine-type ""custom-64-131072"" \. --boot-disk-size ""300"" \. --boot-disk-type ""pd-ssd"" \. --zone ""us-west1-b"". ```. I sshed into the machine, and checked the OS version:. ```. [pichuan@pichuan-centos-test ~]$ cat /etc/redhat-release. CentOS Linux release 7.5.1804 (Core) . ```. Then:. ```. [pichuan@pichuan-centos-test ~]$ sudo yum install -y docker. [pichuan@pichuan-centos-test ~]$ sudo service docker start. Redirecting to /bin/systemctl start docker.service. [pichuan@pichuan-centos-test ~]$ sudo docker run -it gcr.io/deepvariant-docker/deepvariant:0.7.1. ```. Then, I use a modified script to run WES case study:. ```. root@5189b7fba95b:/# curl https://gist.githubusercontent.com/pichuan/7916a5574c47fd7a2422bad4e5f73860/raw/44fb4377c9ad8b54e195fdb31489d8e9fbc459e2/inside_docker.sh | bash. ```. You can see:. https://gist.githubusercontent.com/pichuan/7916a5574c47fd7a2422bad4e5f73860/raw/44fb4377c9ad8b54e195fdb31489d8e9fbc459e2/inside_docker.sh. for the script that I ran inside the docker. If the 0.7.1 version still doesn't work, feel free to reopen. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:751,deployability,servic,service,751,"Hi,. can you try the 0.7.1 image? It seems to work for me on CentOS7 now. I was able to run the Exome case study with the following steps:. I used a GCE instance for testing:. ```. gcloud beta compute instances create ""${USER}-centos-test"" \. --scopes ""compute-rw,storage-full,cloud-platform"" \. --image ""centos-7-v20181011"" \. --image-project centos-cloud \. --machine-type ""custom-64-131072"" \. --boot-disk-size ""300"" \. --boot-disk-type ""pd-ssd"" \. --zone ""us-west1-b"". ```. I sshed into the machine, and checked the OS version:. ```. [pichuan@pichuan-centos-test ~]$ cat /etc/redhat-release. CentOS Linux release 7.5.1804 (Core) . ```. Then:. ```. [pichuan@pichuan-centos-test ~]$ sudo yum install -y docker. [pichuan@pichuan-centos-test ~]$ sudo service docker start. Redirecting to /bin/systemctl start docker.service. [pichuan@pichuan-centos-test ~]$ sudo docker run -it gcr.io/deepvariant-docker/deepvariant:0.7.1. ```. Then, I use a modified script to run WES case study:. ```. root@5189b7fba95b:/# curl https://gist.githubusercontent.com/pichuan/7916a5574c47fd7a2422bad4e5f73860/raw/44fb4377c9ad8b54e195fdb31489d8e9fbc459e2/inside_docker.sh | bash. ```. You can see:. https://gist.githubusercontent.com/pichuan/7916a5574c47fd7a2422bad4e5f73860/raw/44fb4377c9ad8b54e195fdb31489d8e9fbc459e2/inside_docker.sh. for the script that I ran inside the docker. If the 0.7.1 version still doesn't work, feel free to reopen. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:816,deployability,servic,service,816,"Hi,. can you try the 0.7.1 image? It seems to work for me on CentOS7 now. I was able to run the Exome case study with the following steps:. I used a GCE instance for testing:. ```. gcloud beta compute instances create ""${USER}-centos-test"" \. --scopes ""compute-rw,storage-full,cloud-platform"" \. --image ""centos-7-v20181011"" \. --image-project centos-cloud \. --machine-type ""custom-64-131072"" \. --boot-disk-size ""300"" \. --boot-disk-type ""pd-ssd"" \. --zone ""us-west1-b"". ```. I sshed into the machine, and checked the OS version:. ```. [pichuan@pichuan-centos-test ~]$ cat /etc/redhat-release. CentOS Linux release 7.5.1804 (Core) . ```. Then:. ```. [pichuan@pichuan-centos-test ~]$ sudo yum install -y docker. [pichuan@pichuan-centos-test ~]$ sudo service docker start. Redirecting to /bin/systemctl start docker.service. [pichuan@pichuan-centos-test ~]$ sudo docker run -it gcr.io/deepvariant-docker/deepvariant:0.7.1. ```. Then, I use a modified script to run WES case study:. ```. root@5189b7fba95b:/# curl https://gist.githubusercontent.com/pichuan/7916a5574c47fd7a2422bad4e5f73860/raw/44fb4377c9ad8b54e195fdb31489d8e9fbc459e2/inside_docker.sh | bash. ```. You can see:. https://gist.githubusercontent.com/pichuan/7916a5574c47fd7a2422bad4e5f73860/raw/44fb4377c9ad8b54e195fdb31489d8e9fbc459e2/inside_docker.sh. for the script that I ran inside the docker. If the 0.7.1 version still doesn't work, feel free to reopen. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:1375,deployability,version,version,1375,"Hi,. can you try the 0.7.1 image? It seems to work for me on CentOS7 now. I was able to run the Exome case study with the following steps:. I used a GCE instance for testing:. ```. gcloud beta compute instances create ""${USER}-centos-test"" \. --scopes ""compute-rw,storage-full,cloud-platform"" \. --image ""centos-7-v20181011"" \. --image-project centos-cloud \. --machine-type ""custom-64-131072"" \. --boot-disk-size ""300"" \. --boot-disk-type ""pd-ssd"" \. --zone ""us-west1-b"". ```. I sshed into the machine, and checked the OS version:. ```. [pichuan@pichuan-centos-test ~]$ cat /etc/redhat-release. CentOS Linux release 7.5.1804 (Core) . ```. Then:. ```. [pichuan@pichuan-centos-test ~]$ sudo yum install -y docker. [pichuan@pichuan-centos-test ~]$ sudo service docker start. Redirecting to /bin/systemctl start docker.service. [pichuan@pichuan-centos-test ~]$ sudo docker run -it gcr.io/deepvariant-docker/deepvariant:0.7.1. ```. Then, I use a modified script to run WES case study:. ```. root@5189b7fba95b:/# curl https://gist.githubusercontent.com/pichuan/7916a5574c47fd7a2422bad4e5f73860/raw/44fb4377c9ad8b54e195fdb31489d8e9fbc459e2/inside_docker.sh | bash. ```. You can see:. https://gist.githubusercontent.com/pichuan/7916a5574c47fd7a2422bad4e5f73860/raw/44fb4377c9ad8b54e195fdb31489d8e9fbc459e2/inside_docker.sh. for the script that I ran inside the docker. If the 0.7.1 version still doesn't work, feel free to reopen. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:277,energy efficiency,cloud,cloud-platform,277,"Hi,. can you try the 0.7.1 image? It seems to work for me on CentOS7 now. I was able to run the Exome case study with the following steps:. I used a GCE instance for testing:. ```. gcloud beta compute instances create ""${USER}-centos-test"" \. --scopes ""compute-rw,storage-full,cloud-platform"" \. --image ""centos-7-v20181011"" \. --image-project centos-cloud \. --machine-type ""custom-64-131072"" \. --boot-disk-size ""300"" \. --boot-disk-type ""pd-ssd"" \. --zone ""us-west1-b"". ```. I sshed into the machine, and checked the OS version:. ```. [pichuan@pichuan-centos-test ~]$ cat /etc/redhat-release. CentOS Linux release 7.5.1804 (Core) . ```. Then:. ```. [pichuan@pichuan-centos-test ~]$ sudo yum install -y docker. [pichuan@pichuan-centos-test ~]$ sudo service docker start. Redirecting to /bin/systemctl start docker.service. [pichuan@pichuan-centos-test ~]$ sudo docker run -it gcr.io/deepvariant-docker/deepvariant:0.7.1. ```. Then, I use a modified script to run WES case study:. ```. root@5189b7fba95b:/# curl https://gist.githubusercontent.com/pichuan/7916a5574c47fd7a2422bad4e5f73860/raw/44fb4377c9ad8b54e195fdb31489d8e9fbc459e2/inside_docker.sh | bash. ```. You can see:. https://gist.githubusercontent.com/pichuan/7916a5574c47fd7a2422bad4e5f73860/raw/44fb4377c9ad8b54e195fdb31489d8e9fbc459e2/inside_docker.sh. for the script that I ran inside the docker. If the 0.7.1 version still doesn't work, feel free to reopen. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:351,energy efficiency,cloud,cloud,351,"Hi,. can you try the 0.7.1 image? It seems to work for me on CentOS7 now. I was able to run the Exome case study with the following steps:. I used a GCE instance for testing:. ```. gcloud beta compute instances create ""${USER}-centos-test"" \. --scopes ""compute-rw,storage-full,cloud-platform"" \. --image ""centos-7-v20181011"" \. --image-project centos-cloud \. --machine-type ""custom-64-131072"" \. --boot-disk-size ""300"" \. --boot-disk-type ""pd-ssd"" \. --zone ""us-west1-b"". ```. I sshed into the machine, and checked the OS version:. ```. [pichuan@pichuan-centos-test ~]$ cat /etc/redhat-release. CentOS Linux release 7.5.1804 (Core) . ```. Then:. ```. [pichuan@pichuan-centos-test ~]$ sudo yum install -y docker. [pichuan@pichuan-centos-test ~]$ sudo service docker start. Redirecting to /bin/systemctl start docker.service. [pichuan@pichuan-centos-test ~]$ sudo docker run -it gcr.io/deepvariant-docker/deepvariant:0.7.1. ```. Then, I use a modified script to run WES case study:. ```. root@5189b7fba95b:/# curl https://gist.githubusercontent.com/pichuan/7916a5574c47fd7a2422bad4e5f73860/raw/44fb4377c9ad8b54e195fdb31489d8e9fbc459e2/inside_docker.sh | bash. ```. You can see:. https://gist.githubusercontent.com/pichuan/7916a5574c47fd7a2422bad4e5f73860/raw/44fb4377c9ad8b54e195fdb31489d8e9fbc459e2/inside_docker.sh. for the script that I ran inside the docker. If the 0.7.1 version still doesn't work, feel free to reopen. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:627,energy efficiency,Core,Core,627,"Hi,. can you try the 0.7.1 image? It seems to work for me on CentOS7 now. I was able to run the Exome case study with the following steps:. I used a GCE instance for testing:. ```. gcloud beta compute instances create ""${USER}-centos-test"" \. --scopes ""compute-rw,storage-full,cloud-platform"" \. --image ""centos-7-v20181011"" \. --image-project centos-cloud \. --machine-type ""custom-64-131072"" \. --boot-disk-size ""300"" \. --boot-disk-type ""pd-ssd"" \. --zone ""us-west1-b"". ```. I sshed into the machine, and checked the OS version:. ```. [pichuan@pichuan-centos-test ~]$ cat /etc/redhat-release. CentOS Linux release 7.5.1804 (Core) . ```. Then:. ```. [pichuan@pichuan-centos-test ~]$ sudo yum install -y docker. [pichuan@pichuan-centos-test ~]$ sudo service docker start. Redirecting to /bin/systemctl start docker.service. [pichuan@pichuan-centos-test ~]$ sudo docker run -it gcr.io/deepvariant-docker/deepvariant:0.7.1. ```. Then, I use a modified script to run WES case study:. ```. root@5189b7fba95b:/# curl https://gist.githubusercontent.com/pichuan/7916a5574c47fd7a2422bad4e5f73860/raw/44fb4377c9ad8b54e195fdb31489d8e9fbc459e2/inside_docker.sh | bash. ```. You can see:. https://gist.githubusercontent.com/pichuan/7916a5574c47fd7a2422bad4e5f73860/raw/44fb4377c9ad8b54e195fdb31489d8e9fbc459e2/inside_docker.sh. for the script that I ran inside the docker. If the 0.7.1 version still doesn't work, feel free to reopen. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:523,integrability,version,version,523,"Hi,. can you try the 0.7.1 image? It seems to work for me on CentOS7 now. I was able to run the Exome case study with the following steps:. I used a GCE instance for testing:. ```. gcloud beta compute instances create ""${USER}-centos-test"" \. --scopes ""compute-rw,storage-full,cloud-platform"" \. --image ""centos-7-v20181011"" \. --image-project centos-cloud \. --machine-type ""custom-64-131072"" \. --boot-disk-size ""300"" \. --boot-disk-type ""pd-ssd"" \. --zone ""us-west1-b"". ```. I sshed into the machine, and checked the OS version:. ```. [pichuan@pichuan-centos-test ~]$ cat /etc/redhat-release. CentOS Linux release 7.5.1804 (Core) . ```. Then:. ```. [pichuan@pichuan-centos-test ~]$ sudo yum install -y docker. [pichuan@pichuan-centos-test ~]$ sudo service docker start. Redirecting to /bin/systemctl start docker.service. [pichuan@pichuan-centos-test ~]$ sudo docker run -it gcr.io/deepvariant-docker/deepvariant:0.7.1. ```. Then, I use a modified script to run WES case study:. ```. root@5189b7fba95b:/# curl https://gist.githubusercontent.com/pichuan/7916a5574c47fd7a2422bad4e5f73860/raw/44fb4377c9ad8b54e195fdb31489d8e9fbc459e2/inside_docker.sh | bash. ```. You can see:. https://gist.githubusercontent.com/pichuan/7916a5574c47fd7a2422bad4e5f73860/raw/44fb4377c9ad8b54e195fdb31489d8e9fbc459e2/inside_docker.sh. for the script that I ran inside the docker. If the 0.7.1 version still doesn't work, feel free to reopen. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:751,integrability,servic,service,751,"Hi,. can you try the 0.7.1 image? It seems to work for me on CentOS7 now. I was able to run the Exome case study with the following steps:. I used a GCE instance for testing:. ```. gcloud beta compute instances create ""${USER}-centos-test"" \. --scopes ""compute-rw,storage-full,cloud-platform"" \. --image ""centos-7-v20181011"" \. --image-project centos-cloud \. --machine-type ""custom-64-131072"" \. --boot-disk-size ""300"" \. --boot-disk-type ""pd-ssd"" \. --zone ""us-west1-b"". ```. I sshed into the machine, and checked the OS version:. ```. [pichuan@pichuan-centos-test ~]$ cat /etc/redhat-release. CentOS Linux release 7.5.1804 (Core) . ```. Then:. ```. [pichuan@pichuan-centos-test ~]$ sudo yum install -y docker. [pichuan@pichuan-centos-test ~]$ sudo service docker start. Redirecting to /bin/systemctl start docker.service. [pichuan@pichuan-centos-test ~]$ sudo docker run -it gcr.io/deepvariant-docker/deepvariant:0.7.1. ```. Then, I use a modified script to run WES case study:. ```. root@5189b7fba95b:/# curl https://gist.githubusercontent.com/pichuan/7916a5574c47fd7a2422bad4e5f73860/raw/44fb4377c9ad8b54e195fdb31489d8e9fbc459e2/inside_docker.sh | bash. ```. You can see:. https://gist.githubusercontent.com/pichuan/7916a5574c47fd7a2422bad4e5f73860/raw/44fb4377c9ad8b54e195fdb31489d8e9fbc459e2/inside_docker.sh. for the script that I ran inside the docker. If the 0.7.1 version still doesn't work, feel free to reopen. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:816,integrability,servic,service,816,"Hi,. can you try the 0.7.1 image? It seems to work for me on CentOS7 now. I was able to run the Exome case study with the following steps:. I used a GCE instance for testing:. ```. gcloud beta compute instances create ""${USER}-centos-test"" \. --scopes ""compute-rw,storage-full,cloud-platform"" \. --image ""centos-7-v20181011"" \. --image-project centos-cloud \. --machine-type ""custom-64-131072"" \. --boot-disk-size ""300"" \. --boot-disk-type ""pd-ssd"" \. --zone ""us-west1-b"". ```. I sshed into the machine, and checked the OS version:. ```. [pichuan@pichuan-centos-test ~]$ cat /etc/redhat-release. CentOS Linux release 7.5.1804 (Core) . ```. Then:. ```. [pichuan@pichuan-centos-test ~]$ sudo yum install -y docker. [pichuan@pichuan-centos-test ~]$ sudo service docker start. Redirecting to /bin/systemctl start docker.service. [pichuan@pichuan-centos-test ~]$ sudo docker run -it gcr.io/deepvariant-docker/deepvariant:0.7.1. ```. Then, I use a modified script to run WES case study:. ```. root@5189b7fba95b:/# curl https://gist.githubusercontent.com/pichuan/7916a5574c47fd7a2422bad4e5f73860/raw/44fb4377c9ad8b54e195fdb31489d8e9fbc459e2/inside_docker.sh | bash. ```. You can see:. https://gist.githubusercontent.com/pichuan/7916a5574c47fd7a2422bad4e5f73860/raw/44fb4377c9ad8b54e195fdb31489d8e9fbc459e2/inside_docker.sh. for the script that I ran inside the docker. If the 0.7.1 version still doesn't work, feel free to reopen. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:1375,integrability,version,version,1375,"Hi,. can you try the 0.7.1 image? It seems to work for me on CentOS7 now. I was able to run the Exome case study with the following steps:. I used a GCE instance for testing:. ```. gcloud beta compute instances create ""${USER}-centos-test"" \. --scopes ""compute-rw,storage-full,cloud-platform"" \. --image ""centos-7-v20181011"" \. --image-project centos-cloud \. --machine-type ""custom-64-131072"" \. --boot-disk-size ""300"" \. --boot-disk-type ""pd-ssd"" \. --zone ""us-west1-b"". ```. I sshed into the machine, and checked the OS version:. ```. [pichuan@pichuan-centos-test ~]$ cat /etc/redhat-release. CentOS Linux release 7.5.1804 (Core) . ```. Then:. ```. [pichuan@pichuan-centos-test ~]$ sudo yum install -y docker. [pichuan@pichuan-centos-test ~]$ sudo service docker start. Redirecting to /bin/systemctl start docker.service. [pichuan@pichuan-centos-test ~]$ sudo docker run -it gcr.io/deepvariant-docker/deepvariant:0.7.1. ```. Then, I use a modified script to run WES case study:. ```. root@5189b7fba95b:/# curl https://gist.githubusercontent.com/pichuan/7916a5574c47fd7a2422bad4e5f73860/raw/44fb4377c9ad8b54e195fdb31489d8e9fbc459e2/inside_docker.sh | bash. ```. You can see:. https://gist.githubusercontent.com/pichuan/7916a5574c47fd7a2422bad4e5f73860/raw/44fb4377c9ad8b54e195fdb31489d8e9fbc459e2/inside_docker.sh. for the script that I ran inside the docker. If the 0.7.1 version still doesn't work, feel free to reopen. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:283,interoperability,platform,platform,283,"Hi,. can you try the 0.7.1 image? It seems to work for me on CentOS7 now. I was able to run the Exome case study with the following steps:. I used a GCE instance for testing:. ```. gcloud beta compute instances create ""${USER}-centos-test"" \. --scopes ""compute-rw,storage-full,cloud-platform"" \. --image ""centos-7-v20181011"" \. --image-project centos-cloud \. --machine-type ""custom-64-131072"" \. --boot-disk-size ""300"" \. --boot-disk-type ""pd-ssd"" \. --zone ""us-west1-b"". ```. I sshed into the machine, and checked the OS version:. ```. [pichuan@pichuan-centos-test ~]$ cat /etc/redhat-release. CentOS Linux release 7.5.1804 (Core) . ```. Then:. ```. [pichuan@pichuan-centos-test ~]$ sudo yum install -y docker. [pichuan@pichuan-centos-test ~]$ sudo service docker start. Redirecting to /bin/systemctl start docker.service. [pichuan@pichuan-centos-test ~]$ sudo docker run -it gcr.io/deepvariant-docker/deepvariant:0.7.1. ```. Then, I use a modified script to run WES case study:. ```. root@5189b7fba95b:/# curl https://gist.githubusercontent.com/pichuan/7916a5574c47fd7a2422bad4e5f73860/raw/44fb4377c9ad8b54e195fdb31489d8e9fbc459e2/inside_docker.sh | bash. ```. You can see:. https://gist.githubusercontent.com/pichuan/7916a5574c47fd7a2422bad4e5f73860/raw/44fb4377c9ad8b54e195fdb31489d8e9fbc459e2/inside_docker.sh. for the script that I ran inside the docker. If the 0.7.1 version still doesn't work, feel free to reopen. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:523,modifiability,version,version,523,"Hi,. can you try the 0.7.1 image? It seems to work for me on CentOS7 now. I was able to run the Exome case study with the following steps:. I used a GCE instance for testing:. ```. gcloud beta compute instances create ""${USER}-centos-test"" \. --scopes ""compute-rw,storage-full,cloud-platform"" \. --image ""centos-7-v20181011"" \. --image-project centos-cloud \. --machine-type ""custom-64-131072"" \. --boot-disk-size ""300"" \. --boot-disk-type ""pd-ssd"" \. --zone ""us-west1-b"". ```. I sshed into the machine, and checked the OS version:. ```. [pichuan@pichuan-centos-test ~]$ cat /etc/redhat-release. CentOS Linux release 7.5.1804 (Core) . ```. Then:. ```. [pichuan@pichuan-centos-test ~]$ sudo yum install -y docker. [pichuan@pichuan-centos-test ~]$ sudo service docker start. Redirecting to /bin/systemctl start docker.service. [pichuan@pichuan-centos-test ~]$ sudo docker run -it gcr.io/deepvariant-docker/deepvariant:0.7.1. ```. Then, I use a modified script to run WES case study:. ```. root@5189b7fba95b:/# curl https://gist.githubusercontent.com/pichuan/7916a5574c47fd7a2422bad4e5f73860/raw/44fb4377c9ad8b54e195fdb31489d8e9fbc459e2/inside_docker.sh | bash. ```. You can see:. https://gist.githubusercontent.com/pichuan/7916a5574c47fd7a2422bad4e5f73860/raw/44fb4377c9ad8b54e195fdb31489d8e9fbc459e2/inside_docker.sh. for the script that I ran inside the docker. If the 0.7.1 version still doesn't work, feel free to reopen. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:751,modifiability,servic,service,751,"Hi,. can you try the 0.7.1 image? It seems to work for me on CentOS7 now. I was able to run the Exome case study with the following steps:. I used a GCE instance for testing:. ```. gcloud beta compute instances create ""${USER}-centos-test"" \. --scopes ""compute-rw,storage-full,cloud-platform"" \. --image ""centos-7-v20181011"" \. --image-project centos-cloud \. --machine-type ""custom-64-131072"" \. --boot-disk-size ""300"" \. --boot-disk-type ""pd-ssd"" \. --zone ""us-west1-b"". ```. I sshed into the machine, and checked the OS version:. ```. [pichuan@pichuan-centos-test ~]$ cat /etc/redhat-release. CentOS Linux release 7.5.1804 (Core) . ```. Then:. ```. [pichuan@pichuan-centos-test ~]$ sudo yum install -y docker. [pichuan@pichuan-centos-test ~]$ sudo service docker start. Redirecting to /bin/systemctl start docker.service. [pichuan@pichuan-centos-test ~]$ sudo docker run -it gcr.io/deepvariant-docker/deepvariant:0.7.1. ```. Then, I use a modified script to run WES case study:. ```. root@5189b7fba95b:/# curl https://gist.githubusercontent.com/pichuan/7916a5574c47fd7a2422bad4e5f73860/raw/44fb4377c9ad8b54e195fdb31489d8e9fbc459e2/inside_docker.sh | bash. ```. You can see:. https://gist.githubusercontent.com/pichuan/7916a5574c47fd7a2422bad4e5f73860/raw/44fb4377c9ad8b54e195fdb31489d8e9fbc459e2/inside_docker.sh. for the script that I ran inside the docker. If the 0.7.1 version still doesn't work, feel free to reopen. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:816,modifiability,servic,service,816,"Hi,. can you try the 0.7.1 image? It seems to work for me on CentOS7 now. I was able to run the Exome case study with the following steps:. I used a GCE instance for testing:. ```. gcloud beta compute instances create ""${USER}-centos-test"" \. --scopes ""compute-rw,storage-full,cloud-platform"" \. --image ""centos-7-v20181011"" \. --image-project centos-cloud \. --machine-type ""custom-64-131072"" \. --boot-disk-size ""300"" \. --boot-disk-type ""pd-ssd"" \. --zone ""us-west1-b"". ```. I sshed into the machine, and checked the OS version:. ```. [pichuan@pichuan-centos-test ~]$ cat /etc/redhat-release. CentOS Linux release 7.5.1804 (Core) . ```. Then:. ```. [pichuan@pichuan-centos-test ~]$ sudo yum install -y docker. [pichuan@pichuan-centos-test ~]$ sudo service docker start. Redirecting to /bin/systemctl start docker.service. [pichuan@pichuan-centos-test ~]$ sudo docker run -it gcr.io/deepvariant-docker/deepvariant:0.7.1. ```. Then, I use a modified script to run WES case study:. ```. root@5189b7fba95b:/# curl https://gist.githubusercontent.com/pichuan/7916a5574c47fd7a2422bad4e5f73860/raw/44fb4377c9ad8b54e195fdb31489d8e9fbc459e2/inside_docker.sh | bash. ```. You can see:. https://gist.githubusercontent.com/pichuan/7916a5574c47fd7a2422bad4e5f73860/raw/44fb4377c9ad8b54e195fdb31489d8e9fbc459e2/inside_docker.sh. for the script that I ran inside the docker. If the 0.7.1 version still doesn't work, feel free to reopen. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:1375,modifiability,version,version,1375,"Hi,. can you try the 0.7.1 image? It seems to work for me on CentOS7 now. I was able to run the Exome case study with the following steps:. I used a GCE instance for testing:. ```. gcloud beta compute instances create ""${USER}-centos-test"" \. --scopes ""compute-rw,storage-full,cloud-platform"" \. --image ""centos-7-v20181011"" \. --image-project centos-cloud \. --machine-type ""custom-64-131072"" \. --boot-disk-size ""300"" \. --boot-disk-type ""pd-ssd"" \. --zone ""us-west1-b"". ```. I sshed into the machine, and checked the OS version:. ```. [pichuan@pichuan-centos-test ~]$ cat /etc/redhat-release. CentOS Linux release 7.5.1804 (Core) . ```. Then:. ```. [pichuan@pichuan-centos-test ~]$ sudo yum install -y docker. [pichuan@pichuan-centos-test ~]$ sudo service docker start. Redirecting to /bin/systemctl start docker.service. [pichuan@pichuan-centos-test ~]$ sudo docker run -it gcr.io/deepvariant-docker/deepvariant:0.7.1. ```. Then, I use a modified script to run WES case study:. ```. root@5189b7fba95b:/# curl https://gist.githubusercontent.com/pichuan/7916a5574c47fd7a2422bad4e5f73860/raw/44fb4377c9ad8b54e195fdb31489d8e9fbc459e2/inside_docker.sh | bash. ```. You can see:. https://gist.githubusercontent.com/pichuan/7916a5574c47fd7a2422bad4e5f73860/raw/44fb4377c9ad8b54e195fdb31489d8e9fbc459e2/inside_docker.sh. for the script that I ran inside the docker. If the 0.7.1 version still doesn't work, feel free to reopen. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:404,performance,disk,disk-size,404,"Hi,. can you try the 0.7.1 image? It seems to work for me on CentOS7 now. I was able to run the Exome case study with the following steps:. I used a GCE instance for testing:. ```. gcloud beta compute instances create ""${USER}-centos-test"" \. --scopes ""compute-rw,storage-full,cloud-platform"" \. --image ""centos-7-v20181011"" \. --image-project centos-cloud \. --machine-type ""custom-64-131072"" \. --boot-disk-size ""300"" \. --boot-disk-type ""pd-ssd"" \. --zone ""us-west1-b"". ```. I sshed into the machine, and checked the OS version:. ```. [pichuan@pichuan-centos-test ~]$ cat /etc/redhat-release. CentOS Linux release 7.5.1804 (Core) . ```. Then:. ```. [pichuan@pichuan-centos-test ~]$ sudo yum install -y docker. [pichuan@pichuan-centos-test ~]$ sudo service docker start. Redirecting to /bin/systemctl start docker.service. [pichuan@pichuan-centos-test ~]$ sudo docker run -it gcr.io/deepvariant-docker/deepvariant:0.7.1. ```. Then, I use a modified script to run WES case study:. ```. root@5189b7fba95b:/# curl https://gist.githubusercontent.com/pichuan/7916a5574c47fd7a2422bad4e5f73860/raw/44fb4377c9ad8b54e195fdb31489d8e9fbc459e2/inside_docker.sh | bash. ```. You can see:. https://gist.githubusercontent.com/pichuan/7916a5574c47fd7a2422bad4e5f73860/raw/44fb4377c9ad8b54e195fdb31489d8e9fbc459e2/inside_docker.sh. for the script that I ran inside the docker. If the 0.7.1 version still doesn't work, feel free to reopen. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:430,performance,disk,disk-type,430,"Hi,. can you try the 0.7.1 image? It seems to work for me on CentOS7 now. I was able to run the Exome case study with the following steps:. I used a GCE instance for testing:. ```. gcloud beta compute instances create ""${USER}-centos-test"" \. --scopes ""compute-rw,storage-full,cloud-platform"" \. --image ""centos-7-v20181011"" \. --image-project centos-cloud \. --machine-type ""custom-64-131072"" \. --boot-disk-size ""300"" \. --boot-disk-type ""pd-ssd"" \. --zone ""us-west1-b"". ```. I sshed into the machine, and checked the OS version:. ```. [pichuan@pichuan-centos-test ~]$ cat /etc/redhat-release. CentOS Linux release 7.5.1804 (Core) . ```. Then:. ```. [pichuan@pichuan-centos-test ~]$ sudo yum install -y docker. [pichuan@pichuan-centos-test ~]$ sudo service docker start. Redirecting to /bin/systemctl start docker.service. [pichuan@pichuan-centos-test ~]$ sudo docker run -it gcr.io/deepvariant-docker/deepvariant:0.7.1. ```. Then, I use a modified script to run WES case study:. ```. root@5189b7fba95b:/# curl https://gist.githubusercontent.com/pichuan/7916a5574c47fd7a2422bad4e5f73860/raw/44fb4377c9ad8b54e195fdb31489d8e9fbc459e2/inside_docker.sh | bash. ```. You can see:. https://gist.githubusercontent.com/pichuan/7916a5574c47fd7a2422bad4e5f73860/raw/44fb4377c9ad8b54e195fdb31489d8e9fbc459e2/inside_docker.sh. for the script that I ran inside the docker. If the 0.7.1 version still doesn't work, feel free to reopen. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:1389,reliability,doe,doesn,1389,"Hi,. can you try the 0.7.1 image? It seems to work for me on CentOS7 now. I was able to run the Exome case study with the following steps:. I used a GCE instance for testing:. ```. gcloud beta compute instances create ""${USER}-centos-test"" \. --scopes ""compute-rw,storage-full,cloud-platform"" \. --image ""centos-7-v20181011"" \. --image-project centos-cloud \. --machine-type ""custom-64-131072"" \. --boot-disk-size ""300"" \. --boot-disk-type ""pd-ssd"" \. --zone ""us-west1-b"". ```. I sshed into the machine, and checked the OS version:. ```. [pichuan@pichuan-centos-test ~]$ cat /etc/redhat-release. CentOS Linux release 7.5.1804 (Core) . ```. Then:. ```. [pichuan@pichuan-centos-test ~]$ sudo yum install -y docker. [pichuan@pichuan-centos-test ~]$ sudo service docker start. Redirecting to /bin/systemctl start docker.service. [pichuan@pichuan-centos-test ~]$ sudo docker run -it gcr.io/deepvariant-docker/deepvariant:0.7.1. ```. Then, I use a modified script to run WES case study:. ```. root@5189b7fba95b:/# curl https://gist.githubusercontent.com/pichuan/7916a5574c47fd7a2422bad4e5f73860/raw/44fb4377c9ad8b54e195fdb31489d8e9fbc459e2/inside_docker.sh | bash. ```. You can see:. https://gist.githubusercontent.com/pichuan/7916a5574c47fd7a2422bad4e5f73860/raw/44fb4377c9ad8b54e195fdb31489d8e9fbc459e2/inside_docker.sh. for the script that I ran inside the docker. If the 0.7.1 version still doesn't work, feel free to reopen. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:166,safety,test,testing,166,"Hi,. can you try the 0.7.1 image? It seems to work for me on CentOS7 now. I was able to run the Exome case study with the following steps:. I used a GCE instance for testing:. ```. gcloud beta compute instances create ""${USER}-centos-test"" \. --scopes ""compute-rw,storage-full,cloud-platform"" \. --image ""centos-7-v20181011"" \. --image-project centos-cloud \. --machine-type ""custom-64-131072"" \. --boot-disk-size ""300"" \. --boot-disk-type ""pd-ssd"" \. --zone ""us-west1-b"". ```. I sshed into the machine, and checked the OS version:. ```. [pichuan@pichuan-centos-test ~]$ cat /etc/redhat-release. CentOS Linux release 7.5.1804 (Core) . ```. Then:. ```. [pichuan@pichuan-centos-test ~]$ sudo yum install -y docker. [pichuan@pichuan-centos-test ~]$ sudo service docker start. Redirecting to /bin/systemctl start docker.service. [pichuan@pichuan-centos-test ~]$ sudo docker run -it gcr.io/deepvariant-docker/deepvariant:0.7.1. ```. Then, I use a modified script to run WES case study:. ```. root@5189b7fba95b:/# curl https://gist.githubusercontent.com/pichuan/7916a5574c47fd7a2422bad4e5f73860/raw/44fb4377c9ad8b54e195fdb31489d8e9fbc459e2/inside_docker.sh | bash. ```. You can see:. https://gist.githubusercontent.com/pichuan/7916a5574c47fd7a2422bad4e5f73860/raw/44fb4377c9ad8b54e195fdb31489d8e9fbc459e2/inside_docker.sh. for the script that I ran inside the docker. If the 0.7.1 version still doesn't work, feel free to reopen. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:234,safety,test,test,234,"Hi,. can you try the 0.7.1 image? It seems to work for me on CentOS7 now. I was able to run the Exome case study with the following steps:. I used a GCE instance for testing:. ```. gcloud beta compute instances create ""${USER}-centos-test"" \. --scopes ""compute-rw,storage-full,cloud-platform"" \. --image ""centos-7-v20181011"" \. --image-project centos-cloud \. --machine-type ""custom-64-131072"" \. --boot-disk-size ""300"" \. --boot-disk-type ""pd-ssd"" \. --zone ""us-west1-b"". ```. I sshed into the machine, and checked the OS version:. ```. [pichuan@pichuan-centos-test ~]$ cat /etc/redhat-release. CentOS Linux release 7.5.1804 (Core) . ```. Then:. ```. [pichuan@pichuan-centos-test ~]$ sudo yum install -y docker. [pichuan@pichuan-centos-test ~]$ sudo service docker start. Redirecting to /bin/systemctl start docker.service. [pichuan@pichuan-centos-test ~]$ sudo docker run -it gcr.io/deepvariant-docker/deepvariant:0.7.1. ```. Then, I use a modified script to run WES case study:. ```. root@5189b7fba95b:/# curl https://gist.githubusercontent.com/pichuan/7916a5574c47fd7a2422bad4e5f73860/raw/44fb4377c9ad8b54e195fdb31489d8e9fbc459e2/inside_docker.sh | bash. ```. You can see:. https://gist.githubusercontent.com/pichuan/7916a5574c47fd7a2422bad4e5f73860/raw/44fb4377c9ad8b54e195fdb31489d8e9fbc459e2/inside_docker.sh. for the script that I ran inside the docker. If the 0.7.1 version still doesn't work, feel free to reopen. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:562,safety,test,test,562,"Hi,. can you try the 0.7.1 image? It seems to work for me on CentOS7 now. I was able to run the Exome case study with the following steps:. I used a GCE instance for testing:. ```. gcloud beta compute instances create ""${USER}-centos-test"" \. --scopes ""compute-rw,storage-full,cloud-platform"" \. --image ""centos-7-v20181011"" \. --image-project centos-cloud \. --machine-type ""custom-64-131072"" \. --boot-disk-size ""300"" \. --boot-disk-type ""pd-ssd"" \. --zone ""us-west1-b"". ```. I sshed into the machine, and checked the OS version:. ```. [pichuan@pichuan-centos-test ~]$ cat /etc/redhat-release. CentOS Linux release 7.5.1804 (Core) . ```. Then:. ```. [pichuan@pichuan-centos-test ~]$ sudo yum install -y docker. [pichuan@pichuan-centos-test ~]$ sudo service docker start. Redirecting to /bin/systemctl start docker.service. [pichuan@pichuan-centos-test ~]$ sudo docker run -it gcr.io/deepvariant-docker/deepvariant:0.7.1. ```. Then, I use a modified script to run WES case study:. ```. root@5189b7fba95b:/# curl https://gist.githubusercontent.com/pichuan/7916a5574c47fd7a2422bad4e5f73860/raw/44fb4377c9ad8b54e195fdb31489d8e9fbc459e2/inside_docker.sh | bash. ```. You can see:. https://gist.githubusercontent.com/pichuan/7916a5574c47fd7a2422bad4e5f73860/raw/44fb4377c9ad8b54e195fdb31489d8e9fbc459e2/inside_docker.sh. for the script that I ran inside the docker. If the 0.7.1 version still doesn't work, feel free to reopen. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:676,safety,test,test,676,"Hi,. can you try the 0.7.1 image? It seems to work for me on CentOS7 now. I was able to run the Exome case study with the following steps:. I used a GCE instance for testing:. ```. gcloud beta compute instances create ""${USER}-centos-test"" \. --scopes ""compute-rw,storage-full,cloud-platform"" \. --image ""centos-7-v20181011"" \. --image-project centos-cloud \. --machine-type ""custom-64-131072"" \. --boot-disk-size ""300"" \. --boot-disk-type ""pd-ssd"" \. --zone ""us-west1-b"". ```. I sshed into the machine, and checked the OS version:. ```. [pichuan@pichuan-centos-test ~]$ cat /etc/redhat-release. CentOS Linux release 7.5.1804 (Core) . ```. Then:. ```. [pichuan@pichuan-centos-test ~]$ sudo yum install -y docker. [pichuan@pichuan-centos-test ~]$ sudo service docker start. Redirecting to /bin/systemctl start docker.service. [pichuan@pichuan-centos-test ~]$ sudo docker run -it gcr.io/deepvariant-docker/deepvariant:0.7.1. ```. Then, I use a modified script to run WES case study:. ```. root@5189b7fba95b:/# curl https://gist.githubusercontent.com/pichuan/7916a5574c47fd7a2422bad4e5f73860/raw/44fb4377c9ad8b54e195fdb31489d8e9fbc459e2/inside_docker.sh | bash. ```. You can see:. https://gist.githubusercontent.com/pichuan/7916a5574c47fd7a2422bad4e5f73860/raw/44fb4377c9ad8b54e195fdb31489d8e9fbc459e2/inside_docker.sh. for the script that I ran inside the docker. If the 0.7.1 version still doesn't work, feel free to reopen. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:737,safety,test,test,737,"Hi,. can you try the 0.7.1 image? It seems to work for me on CentOS7 now. I was able to run the Exome case study with the following steps:. I used a GCE instance for testing:. ```. gcloud beta compute instances create ""${USER}-centos-test"" \. --scopes ""compute-rw,storage-full,cloud-platform"" \. --image ""centos-7-v20181011"" \. --image-project centos-cloud \. --machine-type ""custom-64-131072"" \. --boot-disk-size ""300"" \. --boot-disk-type ""pd-ssd"" \. --zone ""us-west1-b"". ```. I sshed into the machine, and checked the OS version:. ```. [pichuan@pichuan-centos-test ~]$ cat /etc/redhat-release. CentOS Linux release 7.5.1804 (Core) . ```. Then:. ```. [pichuan@pichuan-centos-test ~]$ sudo yum install -y docker. [pichuan@pichuan-centos-test ~]$ sudo service docker start. Redirecting to /bin/systemctl start docker.service. [pichuan@pichuan-centos-test ~]$ sudo docker run -it gcr.io/deepvariant-docker/deepvariant:0.7.1. ```. Then, I use a modified script to run WES case study:. ```. root@5189b7fba95b:/# curl https://gist.githubusercontent.com/pichuan/7916a5574c47fd7a2422bad4e5f73860/raw/44fb4377c9ad8b54e195fdb31489d8e9fbc459e2/inside_docker.sh | bash. ```. You can see:. https://gist.githubusercontent.com/pichuan/7916a5574c47fd7a2422bad4e5f73860/raw/44fb4377c9ad8b54e195fdb31489d8e9fbc459e2/inside_docker.sh. for the script that I ran inside the docker. If the 0.7.1 version still doesn't work, feel free to reopen. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:849,safety,test,test,849,"Hi,. can you try the 0.7.1 image? It seems to work for me on CentOS7 now. I was able to run the Exome case study with the following steps:. I used a GCE instance for testing:. ```. gcloud beta compute instances create ""${USER}-centos-test"" \. --scopes ""compute-rw,storage-full,cloud-platform"" \. --image ""centos-7-v20181011"" \. --image-project centos-cloud \. --machine-type ""custom-64-131072"" \. --boot-disk-size ""300"" \. --boot-disk-type ""pd-ssd"" \. --zone ""us-west1-b"". ```. I sshed into the machine, and checked the OS version:. ```. [pichuan@pichuan-centos-test ~]$ cat /etc/redhat-release. CentOS Linux release 7.5.1804 (Core) . ```. Then:. ```. [pichuan@pichuan-centos-test ~]$ sudo yum install -y docker. [pichuan@pichuan-centos-test ~]$ sudo service docker start. Redirecting to /bin/systemctl start docker.service. [pichuan@pichuan-centos-test ~]$ sudo docker run -it gcr.io/deepvariant-docker/deepvariant:0.7.1. ```. Then, I use a modified script to run WES case study:. ```. root@5189b7fba95b:/# curl https://gist.githubusercontent.com/pichuan/7916a5574c47fd7a2422bad4e5f73860/raw/44fb4377c9ad8b54e195fdb31489d8e9fbc459e2/inside_docker.sh | bash. ```. You can see:. https://gist.githubusercontent.com/pichuan/7916a5574c47fd7a2422bad4e5f73860/raw/44fb4377c9ad8b54e195fdb31489d8e9fbc459e2/inside_docker.sh. for the script that I ran inside the docker. If the 0.7.1 version still doesn't work, feel free to reopen. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:480,security,ssh,sshed,480,"Hi,. can you try the 0.7.1 image? It seems to work for me on CentOS7 now. I was able to run the Exome case study with the following steps:. I used a GCE instance for testing:. ```. gcloud beta compute instances create ""${USER}-centos-test"" \. --scopes ""compute-rw,storage-full,cloud-platform"" \. --image ""centos-7-v20181011"" \. --image-project centos-cloud \. --machine-type ""custom-64-131072"" \. --boot-disk-size ""300"" \. --boot-disk-type ""pd-ssd"" \. --zone ""us-west1-b"". ```. I sshed into the machine, and checked the OS version:. ```. [pichuan@pichuan-centos-test ~]$ cat /etc/redhat-release. CentOS Linux release 7.5.1804 (Core) . ```. Then:. ```. [pichuan@pichuan-centos-test ~]$ sudo yum install -y docker. [pichuan@pichuan-centos-test ~]$ sudo service docker start. Redirecting to /bin/systemctl start docker.service. [pichuan@pichuan-centos-test ~]$ sudo docker run -it gcr.io/deepvariant-docker/deepvariant:0.7.1. ```. Then, I use a modified script to run WES case study:. ```. root@5189b7fba95b:/# curl https://gist.githubusercontent.com/pichuan/7916a5574c47fd7a2422bad4e5f73860/raw/44fb4377c9ad8b54e195fdb31489d8e9fbc459e2/inside_docker.sh | bash. ```. You can see:. https://gist.githubusercontent.com/pichuan/7916a5574c47fd7a2422bad4e5f73860/raw/44fb4377c9ad8b54e195fdb31489d8e9fbc459e2/inside_docker.sh. for the script that I ran inside the docker. If the 0.7.1 version still doesn't work, feel free to reopen. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:942,security,modif,modified,942,"Hi,. can you try the 0.7.1 image? It seems to work for me on CentOS7 now. I was able to run the Exome case study with the following steps:. I used a GCE instance for testing:. ```. gcloud beta compute instances create ""${USER}-centos-test"" \. --scopes ""compute-rw,storage-full,cloud-platform"" \. --image ""centos-7-v20181011"" \. --image-project centos-cloud \. --machine-type ""custom-64-131072"" \. --boot-disk-size ""300"" \. --boot-disk-type ""pd-ssd"" \. --zone ""us-west1-b"". ```. I sshed into the machine, and checked the OS version:. ```. [pichuan@pichuan-centos-test ~]$ cat /etc/redhat-release. CentOS Linux release 7.5.1804 (Core) . ```. Then:. ```. [pichuan@pichuan-centos-test ~]$ sudo yum install -y docker. [pichuan@pichuan-centos-test ~]$ sudo service docker start. Redirecting to /bin/systemctl start docker.service. [pichuan@pichuan-centos-test ~]$ sudo docker run -it gcr.io/deepvariant-docker/deepvariant:0.7.1. ```. Then, I use a modified script to run WES case study:. ```. root@5189b7fba95b:/# curl https://gist.githubusercontent.com/pichuan/7916a5574c47fd7a2422bad4e5f73860/raw/44fb4377c9ad8b54e195fdb31489d8e9fbc459e2/inside_docker.sh | bash. ```. You can see:. https://gist.githubusercontent.com/pichuan/7916a5574c47fd7a2422bad4e5f73860/raw/44fb4377c9ad8b54e195fdb31489d8e9fbc459e2/inside_docker.sh. for the script that I ran inside the docker. If the 0.7.1 version still doesn't work, feel free to reopen. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:166,testability,test,testing,166,"Hi,. can you try the 0.7.1 image? It seems to work for me on CentOS7 now. I was able to run the Exome case study with the following steps:. I used a GCE instance for testing:. ```. gcloud beta compute instances create ""${USER}-centos-test"" \. --scopes ""compute-rw,storage-full,cloud-platform"" \. --image ""centos-7-v20181011"" \. --image-project centos-cloud \. --machine-type ""custom-64-131072"" \. --boot-disk-size ""300"" \. --boot-disk-type ""pd-ssd"" \. --zone ""us-west1-b"". ```. I sshed into the machine, and checked the OS version:. ```. [pichuan@pichuan-centos-test ~]$ cat /etc/redhat-release. CentOS Linux release 7.5.1804 (Core) . ```. Then:. ```. [pichuan@pichuan-centos-test ~]$ sudo yum install -y docker. [pichuan@pichuan-centos-test ~]$ sudo service docker start. Redirecting to /bin/systemctl start docker.service. [pichuan@pichuan-centos-test ~]$ sudo docker run -it gcr.io/deepvariant-docker/deepvariant:0.7.1. ```. Then, I use a modified script to run WES case study:. ```. root@5189b7fba95b:/# curl https://gist.githubusercontent.com/pichuan/7916a5574c47fd7a2422bad4e5f73860/raw/44fb4377c9ad8b54e195fdb31489d8e9fbc459e2/inside_docker.sh | bash. ```. You can see:. https://gist.githubusercontent.com/pichuan/7916a5574c47fd7a2422bad4e5f73860/raw/44fb4377c9ad8b54e195fdb31489d8e9fbc459e2/inside_docker.sh. for the script that I ran inside the docker. If the 0.7.1 version still doesn't work, feel free to reopen. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:234,testability,test,test,234,"Hi,. can you try the 0.7.1 image? It seems to work for me on CentOS7 now. I was able to run the Exome case study with the following steps:. I used a GCE instance for testing:. ```. gcloud beta compute instances create ""${USER}-centos-test"" \. --scopes ""compute-rw,storage-full,cloud-platform"" \. --image ""centos-7-v20181011"" \. --image-project centos-cloud \. --machine-type ""custom-64-131072"" \. --boot-disk-size ""300"" \. --boot-disk-type ""pd-ssd"" \. --zone ""us-west1-b"". ```. I sshed into the machine, and checked the OS version:. ```. [pichuan@pichuan-centos-test ~]$ cat /etc/redhat-release. CentOS Linux release 7.5.1804 (Core) . ```. Then:. ```. [pichuan@pichuan-centos-test ~]$ sudo yum install -y docker. [pichuan@pichuan-centos-test ~]$ sudo service docker start. Redirecting to /bin/systemctl start docker.service. [pichuan@pichuan-centos-test ~]$ sudo docker run -it gcr.io/deepvariant-docker/deepvariant:0.7.1. ```. Then, I use a modified script to run WES case study:. ```. root@5189b7fba95b:/# curl https://gist.githubusercontent.com/pichuan/7916a5574c47fd7a2422bad4e5f73860/raw/44fb4377c9ad8b54e195fdb31489d8e9fbc459e2/inside_docker.sh | bash. ```. You can see:. https://gist.githubusercontent.com/pichuan/7916a5574c47fd7a2422bad4e5f73860/raw/44fb4377c9ad8b54e195fdb31489d8e9fbc459e2/inside_docker.sh. for the script that I ran inside the docker. If the 0.7.1 version still doesn't work, feel free to reopen. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:562,testability,test,test,562,"Hi,. can you try the 0.7.1 image? It seems to work for me on CentOS7 now. I was able to run the Exome case study with the following steps:. I used a GCE instance for testing:. ```. gcloud beta compute instances create ""${USER}-centos-test"" \. --scopes ""compute-rw,storage-full,cloud-platform"" \. --image ""centos-7-v20181011"" \. --image-project centos-cloud \. --machine-type ""custom-64-131072"" \. --boot-disk-size ""300"" \. --boot-disk-type ""pd-ssd"" \. --zone ""us-west1-b"". ```. I sshed into the machine, and checked the OS version:. ```. [pichuan@pichuan-centos-test ~]$ cat /etc/redhat-release. CentOS Linux release 7.5.1804 (Core) . ```. Then:. ```. [pichuan@pichuan-centos-test ~]$ sudo yum install -y docker. [pichuan@pichuan-centos-test ~]$ sudo service docker start. Redirecting to /bin/systemctl start docker.service. [pichuan@pichuan-centos-test ~]$ sudo docker run -it gcr.io/deepvariant-docker/deepvariant:0.7.1. ```. Then, I use a modified script to run WES case study:. ```. root@5189b7fba95b:/# curl https://gist.githubusercontent.com/pichuan/7916a5574c47fd7a2422bad4e5f73860/raw/44fb4377c9ad8b54e195fdb31489d8e9fbc459e2/inside_docker.sh | bash. ```. You can see:. https://gist.githubusercontent.com/pichuan/7916a5574c47fd7a2422bad4e5f73860/raw/44fb4377c9ad8b54e195fdb31489d8e9fbc459e2/inside_docker.sh. for the script that I ran inside the docker. If the 0.7.1 version still doesn't work, feel free to reopen. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:676,testability,test,test,676,"Hi,. can you try the 0.7.1 image? It seems to work for me on CentOS7 now. I was able to run the Exome case study with the following steps:. I used a GCE instance for testing:. ```. gcloud beta compute instances create ""${USER}-centos-test"" \. --scopes ""compute-rw,storage-full,cloud-platform"" \. --image ""centos-7-v20181011"" \. --image-project centos-cloud \. --machine-type ""custom-64-131072"" \. --boot-disk-size ""300"" \. --boot-disk-type ""pd-ssd"" \. --zone ""us-west1-b"". ```. I sshed into the machine, and checked the OS version:. ```. [pichuan@pichuan-centos-test ~]$ cat /etc/redhat-release. CentOS Linux release 7.5.1804 (Core) . ```. Then:. ```. [pichuan@pichuan-centos-test ~]$ sudo yum install -y docker. [pichuan@pichuan-centos-test ~]$ sudo service docker start. Redirecting to /bin/systemctl start docker.service. [pichuan@pichuan-centos-test ~]$ sudo docker run -it gcr.io/deepvariant-docker/deepvariant:0.7.1. ```. Then, I use a modified script to run WES case study:. ```. root@5189b7fba95b:/# curl https://gist.githubusercontent.com/pichuan/7916a5574c47fd7a2422bad4e5f73860/raw/44fb4377c9ad8b54e195fdb31489d8e9fbc459e2/inside_docker.sh | bash. ```. You can see:. https://gist.githubusercontent.com/pichuan/7916a5574c47fd7a2422bad4e5f73860/raw/44fb4377c9ad8b54e195fdb31489d8e9fbc459e2/inside_docker.sh. for the script that I ran inside the docker. If the 0.7.1 version still doesn't work, feel free to reopen. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:737,testability,test,test,737,"Hi,. can you try the 0.7.1 image? It seems to work for me on CentOS7 now. I was able to run the Exome case study with the following steps:. I used a GCE instance for testing:. ```. gcloud beta compute instances create ""${USER}-centos-test"" \. --scopes ""compute-rw,storage-full,cloud-platform"" \. --image ""centos-7-v20181011"" \. --image-project centos-cloud \. --machine-type ""custom-64-131072"" \. --boot-disk-size ""300"" \. --boot-disk-type ""pd-ssd"" \. --zone ""us-west1-b"". ```. I sshed into the machine, and checked the OS version:. ```. [pichuan@pichuan-centos-test ~]$ cat /etc/redhat-release. CentOS Linux release 7.5.1804 (Core) . ```. Then:. ```. [pichuan@pichuan-centos-test ~]$ sudo yum install -y docker. [pichuan@pichuan-centos-test ~]$ sudo service docker start. Redirecting to /bin/systemctl start docker.service. [pichuan@pichuan-centos-test ~]$ sudo docker run -it gcr.io/deepvariant-docker/deepvariant:0.7.1. ```. Then, I use a modified script to run WES case study:. ```. root@5189b7fba95b:/# curl https://gist.githubusercontent.com/pichuan/7916a5574c47fd7a2422bad4e5f73860/raw/44fb4377c9ad8b54e195fdb31489d8e9fbc459e2/inside_docker.sh | bash. ```. You can see:. https://gist.githubusercontent.com/pichuan/7916a5574c47fd7a2422bad4e5f73860/raw/44fb4377c9ad8b54e195fdb31489d8e9fbc459e2/inside_docker.sh. for the script that I ran inside the docker. If the 0.7.1 version still doesn't work, feel free to reopen. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:849,testability,test,test,849,"Hi,. can you try the 0.7.1 image? It seems to work for me on CentOS7 now. I was able to run the Exome case study with the following steps:. I used a GCE instance for testing:. ```. gcloud beta compute instances create ""${USER}-centos-test"" \. --scopes ""compute-rw,storage-full,cloud-platform"" \. --image ""centos-7-v20181011"" \. --image-project centos-cloud \. --machine-type ""custom-64-131072"" \. --boot-disk-size ""300"" \. --boot-disk-type ""pd-ssd"" \. --zone ""us-west1-b"". ```. I sshed into the machine, and checked the OS version:. ```. [pichuan@pichuan-centos-test ~]$ cat /etc/redhat-release. CentOS Linux release 7.5.1804 (Core) . ```. Then:. ```. [pichuan@pichuan-centos-test ~]$ sudo yum install -y docker. [pichuan@pichuan-centos-test ~]$ sudo service docker start. Redirecting to /bin/systemctl start docker.service. [pichuan@pichuan-centos-test ~]$ sudo docker run -it gcr.io/deepvariant-docker/deepvariant:0.7.1. ```. Then, I use a modified script to run WES case study:. ```. root@5189b7fba95b:/# curl https://gist.githubusercontent.com/pichuan/7916a5574c47fd7a2422bad4e5f73860/raw/44fb4377c9ad8b54e195fdb31489d8e9fbc459e2/inside_docker.sh | bash. ```. You can see:. https://gist.githubusercontent.com/pichuan/7916a5574c47fd7a2422bad4e5f73860/raw/44fb4377c9ad8b54e195fdb31489d8e9fbc459e2/inside_docker.sh. for the script that I ran inside the docker. If the 0.7.1 version still doesn't work, feel free to reopen. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:221,usability,USER,USER,221,"Hi,. can you try the 0.7.1 image? It seems to work for me on CentOS7 now. I was able to run the Exome case study with the following steps:. I used a GCE instance for testing:. ```. gcloud beta compute instances create ""${USER}-centos-test"" \. --scopes ""compute-rw,storage-full,cloud-platform"" \. --image ""centos-7-v20181011"" \. --image-project centos-cloud \. --machine-type ""custom-64-131072"" \. --boot-disk-size ""300"" \. --boot-disk-type ""pd-ssd"" \. --zone ""us-west1-b"". ```. I sshed into the machine, and checked the OS version:. ```. [pichuan@pichuan-centos-test ~]$ cat /etc/redhat-release. CentOS Linux release 7.5.1804 (Core) . ```. Then:. ```. [pichuan@pichuan-centos-test ~]$ sudo yum install -y docker. [pichuan@pichuan-centos-test ~]$ sudo service docker start. Redirecting to /bin/systemctl start docker.service. [pichuan@pichuan-centos-test ~]$ sudo docker run -it gcr.io/deepvariant-docker/deepvariant:0.7.1. ```. Then, I use a modified script to run WES case study:. ```. root@5189b7fba95b:/# curl https://gist.githubusercontent.com/pichuan/7916a5574c47fd7a2422bad4e5f73860/raw/44fb4377c9ad8b54e195fdb31489d8e9fbc459e2/inside_docker.sh | bash. ```. You can see:. https://gist.githubusercontent.com/pichuan/7916a5574c47fd7a2422bad4e5f73860/raw/44fb4377c9ad8b54e195fdb31489d8e9fbc459e2/inside_docker.sh. for the script that I ran inside the docker. If the 0.7.1 version still doesn't work, feel free to reopen. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:376,usability,custom,custom-,376,"Hi,. can you try the 0.7.1 image? It seems to work for me on CentOS7 now. I was able to run the Exome case study with the following steps:. I used a GCE instance for testing:. ```. gcloud beta compute instances create ""${USER}-centos-test"" \. --scopes ""compute-rw,storage-full,cloud-platform"" \. --image ""centos-7-v20181011"" \. --image-project centos-cloud \. --machine-type ""custom-64-131072"" \. --boot-disk-size ""300"" \. --boot-disk-type ""pd-ssd"" \. --zone ""us-west1-b"". ```. I sshed into the machine, and checked the OS version:. ```. [pichuan@pichuan-centos-test ~]$ cat /etc/redhat-release. CentOS Linux release 7.5.1804 (Core) . ```. Then:. ```. [pichuan@pichuan-centos-test ~]$ sudo yum install -y docker. [pichuan@pichuan-centos-test ~]$ sudo service docker start. Redirecting to /bin/systemctl start docker.service. [pichuan@pichuan-centos-test ~]$ sudo docker run -it gcr.io/deepvariant-docker/deepvariant:0.7.1. ```. Then, I use a modified script to run WES case study:. ```. root@5189b7fba95b:/# curl https://gist.githubusercontent.com/pichuan/7916a5574c47fd7a2422bad4e5f73860/raw/44fb4377c9ad8b54e195fdb31489d8e9fbc459e2/inside_docker.sh | bash. ```. You can see:. https://gist.githubusercontent.com/pichuan/7916a5574c47fd7a2422bad4e5f73860/raw/44fb4377c9ad8b54e195fdb31489d8e9fbc459e2/inside_docker.sh. for the script that I ran inside the docker. If the 0.7.1 version still doesn't work, feel free to reopen. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:69,availability,error,error,69,"Thank you - yes, I just tried in 0.7.1 and now am running into a new error. I have python and numpy installed and I am wondering how to make this accessible or if this is a Docker issue? Thank you in advance,. Best,. ```. File ""/tmp/Bazel.runfiles_uDUZWS/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 37, in <module>. import numpy as np. ImportError: No module named numpy. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:100,deployability,instal,installed,100,"Thank you - yes, I just tried in 0.7.1 and now am running into a new error. I have python and numpy installed and I am wondering how to make this accessible or if this is a Docker issue? Thank you in advance,. Best,. ```. File ""/tmp/Bazel.runfiles_uDUZWS/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 37, in <module>. import numpy as np. ImportError: No module named numpy. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:331,deployability,modul,module,331,"Thank you - yes, I just tried in 0.7.1 and now am running into a new error. I have python and numpy installed and I am wondering how to make this accessible or if this is a Docker issue? Thank you in advance,. Best,. ```. File ""/tmp/Bazel.runfiles_uDUZWS/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 37, in <module>. import numpy as np. ImportError: No module named numpy. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:376,deployability,modul,module,376,"Thank you - yes, I just tried in 0.7.1 and now am running into a new error. I have python and numpy installed and I am wondering how to make this accessible or if this is a Docker issue? Thank you in advance,. Best,. ```. File ""/tmp/Bazel.runfiles_uDUZWS/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 37, in <module>. import numpy as np. ImportError: No module named numpy. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:331,modifiability,modul,module,331,"Thank you - yes, I just tried in 0.7.1 and now am running into a new error. I have python and numpy installed and I am wondering how to make this accessible or if this is a Docker issue? Thank you in advance,. Best,. ```. File ""/tmp/Bazel.runfiles_uDUZWS/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 37, in <module>. import numpy as np. ImportError: No module named numpy. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:376,modifiability,modul,module,376,"Thank you - yes, I just tried in 0.7.1 and now am running into a new error. I have python and numpy installed and I am wondering how to make this accessible or if this is a Docker issue? Thank you in advance,. Best,. ```. File ""/tmp/Bazel.runfiles_uDUZWS/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 37, in <module>. import numpy as np. ImportError: No module named numpy. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:69,performance,error,error,69,"Thank you - yes, I just tried in 0.7.1 and now am running into a new error. I have python and numpy installed and I am wondering how to make this accessible or if this is a Docker issue? Thank you in advance,. Best,. ```. File ""/tmp/Bazel.runfiles_uDUZWS/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 37, in <module>. import numpy as np. ImportError: No module named numpy. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:69,safety,error,error,69,"Thank you - yes, I just tried in 0.7.1 and now am running into a new error. I have python and numpy installed and I am wondering how to make this accessible or if this is a Docker issue? Thank you in advance,. Best,. ```. File ""/tmp/Bazel.runfiles_uDUZWS/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 37, in <module>. import numpy as np. ImportError: No module named numpy. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:331,safety,modul,module,331,"Thank you - yes, I just tried in 0.7.1 and now am running into a new error. I have python and numpy installed and I am wondering how to make this accessible or if this is a Docker issue? Thank you in advance,. Best,. ```. File ""/tmp/Bazel.runfiles_uDUZWS/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 37, in <module>. import numpy as np. ImportError: No module named numpy. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:376,safety,modul,module,376,"Thank you - yes, I just tried in 0.7.1 and now am running into a new error. I have python and numpy installed and I am wondering how to make this accessible or if this is a Docker issue? Thank you in advance,. Best,. ```. File ""/tmp/Bazel.runfiles_uDUZWS/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 37, in <module>. import numpy as np. ImportError: No module named numpy. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:146,security,access,accessible,146,"Thank you - yes, I just tried in 0.7.1 and now am running into a new error. I have python and numpy installed and I am wondering how to make this accessible or if this is a Docker issue? Thank you in advance,. Best,. ```. File ""/tmp/Bazel.runfiles_uDUZWS/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 37, in <module>. import numpy as np. ImportError: No module named numpy. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:69,usability,error,error,69,"Thank you - yes, I just tried in 0.7.1 and now am running into a new error. I have python and numpy installed and I am wondering how to make this accessible or if this is a Docker issue? Thank you in advance,. Best,. ```. File ""/tmp/Bazel.runfiles_uDUZWS/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 37, in <module>. import numpy as np. ImportError: No module named numpy. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:860,availability,Down,Downloaded,860,"@ksw9 can you post the full sequence of commands? I tried inside the docker, and it seems to be fine:. ```. [pichuan@pichuan-centos-test ~]$ sudo docker run -it gcr.io/deepvariant-docker/deepvariant:0.7.1. Unable to find image 'gcr.io/deepvariant-docker/deepvariant:0.7.1' locally. Trying to pull repository gcr.io/deepvariant-docker/deepvariant ... . 0.7.1: Pulling from gcr.io/deepvariant-docker/deepvariant. 18d680d61657: Pull complete . 0addb6fece63: Pull complete . 78e58219b215: Pull complete . eb6959a66df2: Pull complete . 54de1d38bbd7: Pull complete . d17c3563217d: Pull complete . ba1bdbdefce9: Pull complete . 94eba53c4ad9: Pull complete . 413f494b0501: Pull complete . 4d89363e7fb4: Pull complete . e9213d1ccf36: Pull complete . fb6121657d6b: Pull complete . Digest: sha256:705523e7bc241e0d3e1e57d4d338c83e289d51a8231c09b0d2dee03c015cee0f. Status: Downloaded newer image for gcr.io/deepvariant-docker/deepvariant:0.7.1. root@e2fb03e85f9e:/# python -c ""import numpy"". root@e2fb03e85f9e:/# python -c ""import numpy as np"". root@e2fb03e85f9e:/# . ```.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:297,integrability,repositor,repository,297,"@ksw9 can you post the full sequence of commands? I tried inside the docker, and it seems to be fine:. ```. [pichuan@pichuan-centos-test ~]$ sudo docker run -it gcr.io/deepvariant-docker/deepvariant:0.7.1. Unable to find image 'gcr.io/deepvariant-docker/deepvariant:0.7.1' locally. Trying to pull repository gcr.io/deepvariant-docker/deepvariant ... . 0.7.1: Pulling from gcr.io/deepvariant-docker/deepvariant. 18d680d61657: Pull complete . 0addb6fece63: Pull complete . 78e58219b215: Pull complete . eb6959a66df2: Pull complete . 54de1d38bbd7: Pull complete . d17c3563217d: Pull complete . ba1bdbdefce9: Pull complete . 94eba53c4ad9: Pull complete . 413f494b0501: Pull complete . 4d89363e7fb4: Pull complete . e9213d1ccf36: Pull complete . fb6121657d6b: Pull complete . Digest: sha256:705523e7bc241e0d3e1e57d4d338c83e289d51a8231c09b0d2dee03c015cee0f. Status: Downloaded newer image for gcr.io/deepvariant-docker/deepvariant:0.7.1. root@e2fb03e85f9e:/# python -c ""import numpy"". root@e2fb03e85f9e:/# python -c ""import numpy as np"". root@e2fb03e85f9e:/# . ```.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:297,interoperability,repositor,repository,297,"@ksw9 can you post the full sequence of commands? I tried inside the docker, and it seems to be fine:. ```. [pichuan@pichuan-centos-test ~]$ sudo docker run -it gcr.io/deepvariant-docker/deepvariant:0.7.1. Unable to find image 'gcr.io/deepvariant-docker/deepvariant:0.7.1' locally. Trying to pull repository gcr.io/deepvariant-docker/deepvariant ... . 0.7.1: Pulling from gcr.io/deepvariant-docker/deepvariant. 18d680d61657: Pull complete . 0addb6fece63: Pull complete . 78e58219b215: Pull complete . eb6959a66df2: Pull complete . 54de1d38bbd7: Pull complete . d17c3563217d: Pull complete . ba1bdbdefce9: Pull complete . 94eba53c4ad9: Pull complete . 413f494b0501: Pull complete . 4d89363e7fb4: Pull complete . e9213d1ccf36: Pull complete . fb6121657d6b: Pull complete . Digest: sha256:705523e7bc241e0d3e1e57d4d338c83e289d51a8231c09b0d2dee03c015cee0f. Status: Downloaded newer image for gcr.io/deepvariant-docker/deepvariant:0.7.1. root@e2fb03e85f9e:/# python -c ""import numpy"". root@e2fb03e85f9e:/# python -c ""import numpy as np"". root@e2fb03e85f9e:/# . ```.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:132,safety,test,test,132,"@ksw9 can you post the full sequence of commands? I tried inside the docker, and it seems to be fine:. ```. [pichuan@pichuan-centos-test ~]$ sudo docker run -it gcr.io/deepvariant-docker/deepvariant:0.7.1. Unable to find image 'gcr.io/deepvariant-docker/deepvariant:0.7.1' locally. Trying to pull repository gcr.io/deepvariant-docker/deepvariant ... . 0.7.1: Pulling from gcr.io/deepvariant-docker/deepvariant. 18d680d61657: Pull complete . 0addb6fece63: Pull complete . 78e58219b215: Pull complete . eb6959a66df2: Pull complete . 54de1d38bbd7: Pull complete . d17c3563217d: Pull complete . ba1bdbdefce9: Pull complete . 94eba53c4ad9: Pull complete . 413f494b0501: Pull complete . 4d89363e7fb4: Pull complete . e9213d1ccf36: Pull complete . fb6121657d6b: Pull complete . Digest: sha256:705523e7bc241e0d3e1e57d4d338c83e289d51a8231c09b0d2dee03c015cee0f. Status: Downloaded newer image for gcr.io/deepvariant-docker/deepvariant:0.7.1. root@e2fb03e85f9e:/# python -c ""import numpy"". root@e2fb03e85f9e:/# python -c ""import numpy as np"". root@e2fb03e85f9e:/# . ```.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:430,safety,compl,complete,430,"@ksw9 can you post the full sequence of commands? I tried inside the docker, and it seems to be fine:. ```. [pichuan@pichuan-centos-test ~]$ sudo docker run -it gcr.io/deepvariant-docker/deepvariant:0.7.1. Unable to find image 'gcr.io/deepvariant-docker/deepvariant:0.7.1' locally. Trying to pull repository gcr.io/deepvariant-docker/deepvariant ... . 0.7.1: Pulling from gcr.io/deepvariant-docker/deepvariant. 18d680d61657: Pull complete . 0addb6fece63: Pull complete . 78e58219b215: Pull complete . eb6959a66df2: Pull complete . 54de1d38bbd7: Pull complete . d17c3563217d: Pull complete . ba1bdbdefce9: Pull complete . 94eba53c4ad9: Pull complete . 413f494b0501: Pull complete . 4d89363e7fb4: Pull complete . e9213d1ccf36: Pull complete . fb6121657d6b: Pull complete . Digest: sha256:705523e7bc241e0d3e1e57d4d338c83e289d51a8231c09b0d2dee03c015cee0f. Status: Downloaded newer image for gcr.io/deepvariant-docker/deepvariant:0.7.1. root@e2fb03e85f9e:/# python -c ""import numpy"". root@e2fb03e85f9e:/# python -c ""import numpy as np"". root@e2fb03e85f9e:/# . ```.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:460,safety,compl,complete,460,"@ksw9 can you post the full sequence of commands? I tried inside the docker, and it seems to be fine:. ```. [pichuan@pichuan-centos-test ~]$ sudo docker run -it gcr.io/deepvariant-docker/deepvariant:0.7.1. Unable to find image 'gcr.io/deepvariant-docker/deepvariant:0.7.1' locally. Trying to pull repository gcr.io/deepvariant-docker/deepvariant ... . 0.7.1: Pulling from gcr.io/deepvariant-docker/deepvariant. 18d680d61657: Pull complete . 0addb6fece63: Pull complete . 78e58219b215: Pull complete . eb6959a66df2: Pull complete . 54de1d38bbd7: Pull complete . d17c3563217d: Pull complete . ba1bdbdefce9: Pull complete . 94eba53c4ad9: Pull complete . 413f494b0501: Pull complete . 4d89363e7fb4: Pull complete . e9213d1ccf36: Pull complete . fb6121657d6b: Pull complete . Digest: sha256:705523e7bc241e0d3e1e57d4d338c83e289d51a8231c09b0d2dee03c015cee0f. Status: Downloaded newer image for gcr.io/deepvariant-docker/deepvariant:0.7.1. root@e2fb03e85f9e:/# python -c ""import numpy"". root@e2fb03e85f9e:/# python -c ""import numpy as np"". root@e2fb03e85f9e:/# . ```.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:490,safety,compl,complete,490,"@ksw9 can you post the full sequence of commands? I tried inside the docker, and it seems to be fine:. ```. [pichuan@pichuan-centos-test ~]$ sudo docker run -it gcr.io/deepvariant-docker/deepvariant:0.7.1. Unable to find image 'gcr.io/deepvariant-docker/deepvariant:0.7.1' locally. Trying to pull repository gcr.io/deepvariant-docker/deepvariant ... . 0.7.1: Pulling from gcr.io/deepvariant-docker/deepvariant. 18d680d61657: Pull complete . 0addb6fece63: Pull complete . 78e58219b215: Pull complete . eb6959a66df2: Pull complete . 54de1d38bbd7: Pull complete . d17c3563217d: Pull complete . ba1bdbdefce9: Pull complete . 94eba53c4ad9: Pull complete . 413f494b0501: Pull complete . 4d89363e7fb4: Pull complete . e9213d1ccf36: Pull complete . fb6121657d6b: Pull complete . Digest: sha256:705523e7bc241e0d3e1e57d4d338c83e289d51a8231c09b0d2dee03c015cee0f. Status: Downloaded newer image for gcr.io/deepvariant-docker/deepvariant:0.7.1. root@e2fb03e85f9e:/# python -c ""import numpy"". root@e2fb03e85f9e:/# python -c ""import numpy as np"". root@e2fb03e85f9e:/# . ```.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:520,safety,compl,complete,520,"@ksw9 can you post the full sequence of commands? I tried inside the docker, and it seems to be fine:. ```. [pichuan@pichuan-centos-test ~]$ sudo docker run -it gcr.io/deepvariant-docker/deepvariant:0.7.1. Unable to find image 'gcr.io/deepvariant-docker/deepvariant:0.7.1' locally. Trying to pull repository gcr.io/deepvariant-docker/deepvariant ... . 0.7.1: Pulling from gcr.io/deepvariant-docker/deepvariant. 18d680d61657: Pull complete . 0addb6fece63: Pull complete . 78e58219b215: Pull complete . eb6959a66df2: Pull complete . 54de1d38bbd7: Pull complete . d17c3563217d: Pull complete . ba1bdbdefce9: Pull complete . 94eba53c4ad9: Pull complete . 413f494b0501: Pull complete . 4d89363e7fb4: Pull complete . e9213d1ccf36: Pull complete . fb6121657d6b: Pull complete . Digest: sha256:705523e7bc241e0d3e1e57d4d338c83e289d51a8231c09b0d2dee03c015cee0f. Status: Downloaded newer image for gcr.io/deepvariant-docker/deepvariant:0.7.1. root@e2fb03e85f9e:/# python -c ""import numpy"". root@e2fb03e85f9e:/# python -c ""import numpy as np"". root@e2fb03e85f9e:/# . ```.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:550,safety,compl,complete,550,"@ksw9 can you post the full sequence of commands? I tried inside the docker, and it seems to be fine:. ```. [pichuan@pichuan-centos-test ~]$ sudo docker run -it gcr.io/deepvariant-docker/deepvariant:0.7.1. Unable to find image 'gcr.io/deepvariant-docker/deepvariant:0.7.1' locally. Trying to pull repository gcr.io/deepvariant-docker/deepvariant ... . 0.7.1: Pulling from gcr.io/deepvariant-docker/deepvariant. 18d680d61657: Pull complete . 0addb6fece63: Pull complete . 78e58219b215: Pull complete . eb6959a66df2: Pull complete . 54de1d38bbd7: Pull complete . d17c3563217d: Pull complete . ba1bdbdefce9: Pull complete . 94eba53c4ad9: Pull complete . 413f494b0501: Pull complete . 4d89363e7fb4: Pull complete . e9213d1ccf36: Pull complete . fb6121657d6b: Pull complete . Digest: sha256:705523e7bc241e0d3e1e57d4d338c83e289d51a8231c09b0d2dee03c015cee0f. Status: Downloaded newer image for gcr.io/deepvariant-docker/deepvariant:0.7.1. root@e2fb03e85f9e:/# python -c ""import numpy"". root@e2fb03e85f9e:/# python -c ""import numpy as np"". root@e2fb03e85f9e:/# . ```.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:580,safety,compl,complete,580,"@ksw9 can you post the full sequence of commands? I tried inside the docker, and it seems to be fine:. ```. [pichuan@pichuan-centos-test ~]$ sudo docker run -it gcr.io/deepvariant-docker/deepvariant:0.7.1. Unable to find image 'gcr.io/deepvariant-docker/deepvariant:0.7.1' locally. Trying to pull repository gcr.io/deepvariant-docker/deepvariant ... . 0.7.1: Pulling from gcr.io/deepvariant-docker/deepvariant. 18d680d61657: Pull complete . 0addb6fece63: Pull complete . 78e58219b215: Pull complete . eb6959a66df2: Pull complete . 54de1d38bbd7: Pull complete . d17c3563217d: Pull complete . ba1bdbdefce9: Pull complete . 94eba53c4ad9: Pull complete . 413f494b0501: Pull complete . 4d89363e7fb4: Pull complete . e9213d1ccf36: Pull complete . fb6121657d6b: Pull complete . Digest: sha256:705523e7bc241e0d3e1e57d4d338c83e289d51a8231c09b0d2dee03c015cee0f. Status: Downloaded newer image for gcr.io/deepvariant-docker/deepvariant:0.7.1. root@e2fb03e85f9e:/# python -c ""import numpy"". root@e2fb03e85f9e:/# python -c ""import numpy as np"". root@e2fb03e85f9e:/# . ```.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:610,safety,compl,complete,610,"@ksw9 can you post the full sequence of commands? I tried inside the docker, and it seems to be fine:. ```. [pichuan@pichuan-centos-test ~]$ sudo docker run -it gcr.io/deepvariant-docker/deepvariant:0.7.1. Unable to find image 'gcr.io/deepvariant-docker/deepvariant:0.7.1' locally. Trying to pull repository gcr.io/deepvariant-docker/deepvariant ... . 0.7.1: Pulling from gcr.io/deepvariant-docker/deepvariant. 18d680d61657: Pull complete . 0addb6fece63: Pull complete . 78e58219b215: Pull complete . eb6959a66df2: Pull complete . 54de1d38bbd7: Pull complete . d17c3563217d: Pull complete . ba1bdbdefce9: Pull complete . 94eba53c4ad9: Pull complete . 413f494b0501: Pull complete . 4d89363e7fb4: Pull complete . e9213d1ccf36: Pull complete . fb6121657d6b: Pull complete . Digest: sha256:705523e7bc241e0d3e1e57d4d338c83e289d51a8231c09b0d2dee03c015cee0f. Status: Downloaded newer image for gcr.io/deepvariant-docker/deepvariant:0.7.1. root@e2fb03e85f9e:/# python -c ""import numpy"". root@e2fb03e85f9e:/# python -c ""import numpy as np"". root@e2fb03e85f9e:/# . ```.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:640,safety,compl,complete,640,"@ksw9 can you post the full sequence of commands? I tried inside the docker, and it seems to be fine:. ```. [pichuan@pichuan-centos-test ~]$ sudo docker run -it gcr.io/deepvariant-docker/deepvariant:0.7.1. Unable to find image 'gcr.io/deepvariant-docker/deepvariant:0.7.1' locally. Trying to pull repository gcr.io/deepvariant-docker/deepvariant ... . 0.7.1: Pulling from gcr.io/deepvariant-docker/deepvariant. 18d680d61657: Pull complete . 0addb6fece63: Pull complete . 78e58219b215: Pull complete . eb6959a66df2: Pull complete . 54de1d38bbd7: Pull complete . d17c3563217d: Pull complete . ba1bdbdefce9: Pull complete . 94eba53c4ad9: Pull complete . 413f494b0501: Pull complete . 4d89363e7fb4: Pull complete . e9213d1ccf36: Pull complete . fb6121657d6b: Pull complete . Digest: sha256:705523e7bc241e0d3e1e57d4d338c83e289d51a8231c09b0d2dee03c015cee0f. Status: Downloaded newer image for gcr.io/deepvariant-docker/deepvariant:0.7.1. root@e2fb03e85f9e:/# python -c ""import numpy"". root@e2fb03e85f9e:/# python -c ""import numpy as np"". root@e2fb03e85f9e:/# . ```.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:670,safety,compl,complete,670,"@ksw9 can you post the full sequence of commands? I tried inside the docker, and it seems to be fine:. ```. [pichuan@pichuan-centos-test ~]$ sudo docker run -it gcr.io/deepvariant-docker/deepvariant:0.7.1. Unable to find image 'gcr.io/deepvariant-docker/deepvariant:0.7.1' locally. Trying to pull repository gcr.io/deepvariant-docker/deepvariant ... . 0.7.1: Pulling from gcr.io/deepvariant-docker/deepvariant. 18d680d61657: Pull complete . 0addb6fece63: Pull complete . 78e58219b215: Pull complete . eb6959a66df2: Pull complete . 54de1d38bbd7: Pull complete . d17c3563217d: Pull complete . ba1bdbdefce9: Pull complete . 94eba53c4ad9: Pull complete . 413f494b0501: Pull complete . 4d89363e7fb4: Pull complete . e9213d1ccf36: Pull complete . fb6121657d6b: Pull complete . Digest: sha256:705523e7bc241e0d3e1e57d4d338c83e289d51a8231c09b0d2dee03c015cee0f. Status: Downloaded newer image for gcr.io/deepvariant-docker/deepvariant:0.7.1. root@e2fb03e85f9e:/# python -c ""import numpy"". root@e2fb03e85f9e:/# python -c ""import numpy as np"". root@e2fb03e85f9e:/# . ```.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:700,safety,compl,complete,700,"@ksw9 can you post the full sequence of commands? I tried inside the docker, and it seems to be fine:. ```. [pichuan@pichuan-centos-test ~]$ sudo docker run -it gcr.io/deepvariant-docker/deepvariant:0.7.1. Unable to find image 'gcr.io/deepvariant-docker/deepvariant:0.7.1' locally. Trying to pull repository gcr.io/deepvariant-docker/deepvariant ... . 0.7.1: Pulling from gcr.io/deepvariant-docker/deepvariant. 18d680d61657: Pull complete . 0addb6fece63: Pull complete . 78e58219b215: Pull complete . eb6959a66df2: Pull complete . 54de1d38bbd7: Pull complete . d17c3563217d: Pull complete . ba1bdbdefce9: Pull complete . 94eba53c4ad9: Pull complete . 413f494b0501: Pull complete . 4d89363e7fb4: Pull complete . e9213d1ccf36: Pull complete . fb6121657d6b: Pull complete . Digest: sha256:705523e7bc241e0d3e1e57d4d338c83e289d51a8231c09b0d2dee03c015cee0f. Status: Downloaded newer image for gcr.io/deepvariant-docker/deepvariant:0.7.1. root@e2fb03e85f9e:/# python -c ""import numpy"". root@e2fb03e85f9e:/# python -c ""import numpy as np"". root@e2fb03e85f9e:/# . ```.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:730,safety,compl,complete,730,"@ksw9 can you post the full sequence of commands? I tried inside the docker, and it seems to be fine:. ```. [pichuan@pichuan-centos-test ~]$ sudo docker run -it gcr.io/deepvariant-docker/deepvariant:0.7.1. Unable to find image 'gcr.io/deepvariant-docker/deepvariant:0.7.1' locally. Trying to pull repository gcr.io/deepvariant-docker/deepvariant ... . 0.7.1: Pulling from gcr.io/deepvariant-docker/deepvariant. 18d680d61657: Pull complete . 0addb6fece63: Pull complete . 78e58219b215: Pull complete . eb6959a66df2: Pull complete . 54de1d38bbd7: Pull complete . d17c3563217d: Pull complete . ba1bdbdefce9: Pull complete . 94eba53c4ad9: Pull complete . 413f494b0501: Pull complete . 4d89363e7fb4: Pull complete . e9213d1ccf36: Pull complete . fb6121657d6b: Pull complete . Digest: sha256:705523e7bc241e0d3e1e57d4d338c83e289d51a8231c09b0d2dee03c015cee0f. Status: Downloaded newer image for gcr.io/deepvariant-docker/deepvariant:0.7.1. root@e2fb03e85f9e:/# python -c ""import numpy"". root@e2fb03e85f9e:/# python -c ""import numpy as np"". root@e2fb03e85f9e:/# . ```.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:760,safety,compl,complete,760,"@ksw9 can you post the full sequence of commands? I tried inside the docker, and it seems to be fine:. ```. [pichuan@pichuan-centos-test ~]$ sudo docker run -it gcr.io/deepvariant-docker/deepvariant:0.7.1. Unable to find image 'gcr.io/deepvariant-docker/deepvariant:0.7.1' locally. Trying to pull repository gcr.io/deepvariant-docker/deepvariant ... . 0.7.1: Pulling from gcr.io/deepvariant-docker/deepvariant. 18d680d61657: Pull complete . 0addb6fece63: Pull complete . 78e58219b215: Pull complete . eb6959a66df2: Pull complete . 54de1d38bbd7: Pull complete . d17c3563217d: Pull complete . ba1bdbdefce9: Pull complete . 94eba53c4ad9: Pull complete . 413f494b0501: Pull complete . 4d89363e7fb4: Pull complete . e9213d1ccf36: Pull complete . fb6121657d6b: Pull complete . Digest: sha256:705523e7bc241e0d3e1e57d4d338c83e289d51a8231c09b0d2dee03c015cee0f. Status: Downloaded newer image for gcr.io/deepvariant-docker/deepvariant:0.7.1. root@e2fb03e85f9e:/# python -c ""import numpy"". root@e2fb03e85f9e:/# python -c ""import numpy as np"". root@e2fb03e85f9e:/# . ```.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:430,security,compl,complete,430,"@ksw9 can you post the full sequence of commands? I tried inside the docker, and it seems to be fine:. ```. [pichuan@pichuan-centos-test ~]$ sudo docker run -it gcr.io/deepvariant-docker/deepvariant:0.7.1. Unable to find image 'gcr.io/deepvariant-docker/deepvariant:0.7.1' locally. Trying to pull repository gcr.io/deepvariant-docker/deepvariant ... . 0.7.1: Pulling from gcr.io/deepvariant-docker/deepvariant. 18d680d61657: Pull complete . 0addb6fece63: Pull complete . 78e58219b215: Pull complete . eb6959a66df2: Pull complete . 54de1d38bbd7: Pull complete . d17c3563217d: Pull complete . ba1bdbdefce9: Pull complete . 94eba53c4ad9: Pull complete . 413f494b0501: Pull complete . 4d89363e7fb4: Pull complete . e9213d1ccf36: Pull complete . fb6121657d6b: Pull complete . Digest: sha256:705523e7bc241e0d3e1e57d4d338c83e289d51a8231c09b0d2dee03c015cee0f. Status: Downloaded newer image for gcr.io/deepvariant-docker/deepvariant:0.7.1. root@e2fb03e85f9e:/# python -c ""import numpy"". root@e2fb03e85f9e:/# python -c ""import numpy as np"". root@e2fb03e85f9e:/# . ```.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:460,security,compl,complete,460,"@ksw9 can you post the full sequence of commands? I tried inside the docker, and it seems to be fine:. ```. [pichuan@pichuan-centos-test ~]$ sudo docker run -it gcr.io/deepvariant-docker/deepvariant:0.7.1. Unable to find image 'gcr.io/deepvariant-docker/deepvariant:0.7.1' locally. Trying to pull repository gcr.io/deepvariant-docker/deepvariant ... . 0.7.1: Pulling from gcr.io/deepvariant-docker/deepvariant. 18d680d61657: Pull complete . 0addb6fece63: Pull complete . 78e58219b215: Pull complete . eb6959a66df2: Pull complete . 54de1d38bbd7: Pull complete . d17c3563217d: Pull complete . ba1bdbdefce9: Pull complete . 94eba53c4ad9: Pull complete . 413f494b0501: Pull complete . 4d89363e7fb4: Pull complete . e9213d1ccf36: Pull complete . fb6121657d6b: Pull complete . Digest: sha256:705523e7bc241e0d3e1e57d4d338c83e289d51a8231c09b0d2dee03c015cee0f. Status: Downloaded newer image for gcr.io/deepvariant-docker/deepvariant:0.7.1. root@e2fb03e85f9e:/# python -c ""import numpy"". root@e2fb03e85f9e:/# python -c ""import numpy as np"". root@e2fb03e85f9e:/# . ```.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:490,security,compl,complete,490,"@ksw9 can you post the full sequence of commands? I tried inside the docker, and it seems to be fine:. ```. [pichuan@pichuan-centos-test ~]$ sudo docker run -it gcr.io/deepvariant-docker/deepvariant:0.7.1. Unable to find image 'gcr.io/deepvariant-docker/deepvariant:0.7.1' locally. Trying to pull repository gcr.io/deepvariant-docker/deepvariant ... . 0.7.1: Pulling from gcr.io/deepvariant-docker/deepvariant. 18d680d61657: Pull complete . 0addb6fece63: Pull complete . 78e58219b215: Pull complete . eb6959a66df2: Pull complete . 54de1d38bbd7: Pull complete . d17c3563217d: Pull complete . ba1bdbdefce9: Pull complete . 94eba53c4ad9: Pull complete . 413f494b0501: Pull complete . 4d89363e7fb4: Pull complete . e9213d1ccf36: Pull complete . fb6121657d6b: Pull complete . Digest: sha256:705523e7bc241e0d3e1e57d4d338c83e289d51a8231c09b0d2dee03c015cee0f. Status: Downloaded newer image for gcr.io/deepvariant-docker/deepvariant:0.7.1. root@e2fb03e85f9e:/# python -c ""import numpy"". root@e2fb03e85f9e:/# python -c ""import numpy as np"". root@e2fb03e85f9e:/# . ```.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:520,security,compl,complete,520,"@ksw9 can you post the full sequence of commands? I tried inside the docker, and it seems to be fine:. ```. [pichuan@pichuan-centos-test ~]$ sudo docker run -it gcr.io/deepvariant-docker/deepvariant:0.7.1. Unable to find image 'gcr.io/deepvariant-docker/deepvariant:0.7.1' locally. Trying to pull repository gcr.io/deepvariant-docker/deepvariant ... . 0.7.1: Pulling from gcr.io/deepvariant-docker/deepvariant. 18d680d61657: Pull complete . 0addb6fece63: Pull complete . 78e58219b215: Pull complete . eb6959a66df2: Pull complete . 54de1d38bbd7: Pull complete . d17c3563217d: Pull complete . ba1bdbdefce9: Pull complete . 94eba53c4ad9: Pull complete . 413f494b0501: Pull complete . 4d89363e7fb4: Pull complete . e9213d1ccf36: Pull complete . fb6121657d6b: Pull complete . Digest: sha256:705523e7bc241e0d3e1e57d4d338c83e289d51a8231c09b0d2dee03c015cee0f. Status: Downloaded newer image for gcr.io/deepvariant-docker/deepvariant:0.7.1. root@e2fb03e85f9e:/# python -c ""import numpy"". root@e2fb03e85f9e:/# python -c ""import numpy as np"". root@e2fb03e85f9e:/# . ```.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:550,security,compl,complete,550,"@ksw9 can you post the full sequence of commands? I tried inside the docker, and it seems to be fine:. ```. [pichuan@pichuan-centos-test ~]$ sudo docker run -it gcr.io/deepvariant-docker/deepvariant:0.7.1. Unable to find image 'gcr.io/deepvariant-docker/deepvariant:0.7.1' locally. Trying to pull repository gcr.io/deepvariant-docker/deepvariant ... . 0.7.1: Pulling from gcr.io/deepvariant-docker/deepvariant. 18d680d61657: Pull complete . 0addb6fece63: Pull complete . 78e58219b215: Pull complete . eb6959a66df2: Pull complete . 54de1d38bbd7: Pull complete . d17c3563217d: Pull complete . ba1bdbdefce9: Pull complete . 94eba53c4ad9: Pull complete . 413f494b0501: Pull complete . 4d89363e7fb4: Pull complete . e9213d1ccf36: Pull complete . fb6121657d6b: Pull complete . Digest: sha256:705523e7bc241e0d3e1e57d4d338c83e289d51a8231c09b0d2dee03c015cee0f. Status: Downloaded newer image for gcr.io/deepvariant-docker/deepvariant:0.7.1. root@e2fb03e85f9e:/# python -c ""import numpy"". root@e2fb03e85f9e:/# python -c ""import numpy as np"". root@e2fb03e85f9e:/# . ```.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
