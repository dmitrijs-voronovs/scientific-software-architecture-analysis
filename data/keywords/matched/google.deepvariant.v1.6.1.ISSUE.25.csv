id,quality_attribute,keyword,matched_word,match_idx,sentence,source,author,repo,version,wiki,url
https://github.com/google/deepvariant/issues/869:5729,energy efficiency,model,model,5729,"t-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: . TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). . For more information see: https://github.com/tensorflow/addons/issues/2807 . warnings.warn(. I0822 07:52:10.812179 127086447671104 call_variants.py:563] Total 1 writing processes started. I0822 07:52:10.813103 127086447671104 dv_utils.py:370] From /output/intermediate_results_dir/make_examples.tfrecord-00000-of-00020.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0822 07:52:10.813141 127086447671104 call_variants.py:588] Shape of input examples: [100, 221, 7]. I0822 07:52:10.813338 127086447671104 call_variants.py:592] Use saved model: True. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 789, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 768, in main. call_variants(. File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 598, in call_variants. model_example_shape = dv_utils.get_shape_and_channels_from_json(. File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvariant/deepvariant/dv_utils.py"", line 367, in get_shape_and_channels_from_json. example_info = json.load(f). File ""/usr/lib/python3.8/json/__init__.py"", line 293, in load. return loads(fp.read(),. File ""/usr/lib/py",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:6618,energy efficiency,load,load,6618,"hape of input examples: [100, 221, 7]. I0822 07:52:10.813338 127086447671104 call_variants.py:592] Use saved model: True. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 789, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 768, in main. call_variants(. File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 598, in call_variants. model_example_shape = dv_utils.get_shape_and_channels_from_json(. File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvariant/deepvariant/dv_utils.py"", line 367, in get_shape_and_channels_from_json. example_info = json.load(f). File ""/usr/lib/python3.8/json/__init__.py"", line 293, in load. return loads(fp.read(),. File ""/usr/lib/python3.8/json/__init__.py"", line 357, in loads. return _default_decoder.decode(s). File ""/usr/lib/python3.8/json/decoder.py"", line 337, in decode. obj, end = self.raw_decode(s, idx=_w(s, 0).end()). File ""/usr/lib/python3.8/json/decoder.py"", line 355, in raw_decode. raise JSONDecodeError(""Expecting value"", s, err.value) from None. json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0). Process ForkProcess-1:. Traceback (most recent call last):. File ""/usr/lib/python3.8/multiprocessing/process.py"", line 315, in _bootstrap. self.run(). File ""/usr/lib/python3.8/multiprocessing/process.py"", line 108, in run. self._target(*self._args, **self._kwargs). File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 454, in post_processing. item = output_queue.get(timeout=180). File ""/usr/lib/python3.8/multiprocessing/queues.py"",",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:6684,energy efficiency,load,load,6684,"6447671104 call_variants.py:592] Use saved model: True. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 789, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 768, in main. call_variants(. File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 598, in call_variants. model_example_shape = dv_utils.get_shape_and_channels_from_json(. File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvariant/deepvariant/dv_utils.py"", line 367, in get_shape_and_channels_from_json. example_info = json.load(f). File ""/usr/lib/python3.8/json/__init__.py"", line 293, in load. return loads(fp.read(),. File ""/usr/lib/python3.8/json/__init__.py"", line 357, in loads. return _default_decoder.decode(s). File ""/usr/lib/python3.8/json/decoder.py"", line 337, in decode. obj, end = self.raw_decode(s, idx=_w(s, 0).end()). File ""/usr/lib/python3.8/json/decoder.py"", line 355, in raw_decode. raise JSONDecodeError(""Expecting value"", s, err.value) from None. json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0). Process ForkProcess-1:. Traceback (most recent call last):. File ""/usr/lib/python3.8/multiprocessing/process.py"", line 315, in _bootstrap. self.run(). File ""/usr/lib/python3.8/multiprocessing/process.py"", line 108, in run. self._target(*self._args, **self._kwargs). File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 454, in post_processing. item = output_queue.get(timeout=180). File ""/usr/lib/python3.8/multiprocessing/queues.py"", line 108, in get. raise Empty. _queue.Empty. real 3m2.335s. user ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:6697,energy efficiency,load,loads,6697,"l_variants.py:592] Use saved model: True. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 789, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 768, in main. call_variants(. File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 598, in call_variants. model_example_shape = dv_utils.get_shape_and_channels_from_json(. File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvariant/deepvariant/dv_utils.py"", line 367, in get_shape_and_channels_from_json. example_info = json.load(f). File ""/usr/lib/python3.8/json/__init__.py"", line 293, in load. return loads(fp.read(),. File ""/usr/lib/python3.8/json/__init__.py"", line 357, in loads. return _default_decoder.decode(s). File ""/usr/lib/python3.8/json/decoder.py"", line 337, in decode. obj, end = self.raw_decode(s, idx=_w(s, 0).end()). File ""/usr/lib/python3.8/json/decoder.py"", line 355, in raw_decode. raise JSONDecodeError(""Expecting value"", s, err.value) from None. json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0). Process ForkProcess-1:. Traceback (most recent call last):. File ""/usr/lib/python3.8/multiprocessing/process.py"", line 315, in _bootstrap. self.run(). File ""/usr/lib/python3.8/multiprocessing/process.py"", line 108, in run. self._target(*self._args, **self._kwargs). File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 454, in post_processing. item = output_queue.get(timeout=180). File ""/usr/lib/python3.8/multiprocessing/queues.py"", line 108, in get. raise Empty. _queue.Empty. real 3m2.335s. user 0m7.450s. sys ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:6772,energy efficiency,load,loads,6772,"ll last):. File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 789, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 768, in main. call_variants(. File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 598, in call_variants. model_example_shape = dv_utils.get_shape_and_channels_from_json(. File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvariant/deepvariant/dv_utils.py"", line 367, in get_shape_and_channels_from_json. example_info = json.load(f). File ""/usr/lib/python3.8/json/__init__.py"", line 293, in load. return loads(fp.read(),. File ""/usr/lib/python3.8/json/__init__.py"", line 357, in loads. return _default_decoder.decode(s). File ""/usr/lib/python3.8/json/decoder.py"", line 337, in decode. obj, end = self.raw_decode(s, idx=_w(s, 0).end()). File ""/usr/lib/python3.8/json/decoder.py"", line 355, in raw_decode. raise JSONDecodeError(""Expecting value"", s, err.value) from None. json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0). Process ForkProcess-1:. Traceback (most recent call last):. File ""/usr/lib/python3.8/multiprocessing/process.py"", line 315, in _bootstrap. self.run(). File ""/usr/lib/python3.8/multiprocessing/process.py"", line 108, in run. self._target(*self._args, **self._kwargs). File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 454, in post_processing. item = output_queue.get(timeout=180). File ""/usr/lib/python3.8/multiprocessing/queues.py"", line 108, in get. raise Empty. _queue.Empty. real 3m2.335s. user 0m7.450s. sys 0m4.274s`. **Does the quick start test work on your system?**. Yes.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:176,integrability,pipelin,pipeline,176,"No output vcf obtained from custom model; **ISSUE**. First of all, I found DeepVariant to be a very good and innovative tool. I'm considering including it in my exome analysis pipeline. I followed the tutorial (DeepVariant worked correctly with the Complete Genomics model), and I created my own model using Genome in a Bottle samples. To do this, I sequenced the same reference sample three times to use each BAM file for training, validation, and testing. I didn't encounter any errors during the model creation process, but when I tried to test it, the process got stuck at the call_variants step. **Setup**. - Operating system: Ubuntu 22.04.4 LTS. - DeepVariant version:1.6.1. - Installation method:docker. - Type of data: MGI DNBSEQ 400, exome sequencing. **Steps to reproduce:**. - Command:. _Create examples for trainning set_. `sudo docker run -v ""${PWD}/input"":""/input"" -v ""${PWD}/REF"":""/ref"" -v ""${PWD}""/output:""/output"" google/deepvariant:""1.6.1"" make_examples --mode training --ref ""/ref/GRCh38.p14.genome.fa"" --reads ""/input/26_r_groups.bam"" --examples ""/output/training_set.gz"" --truth_variants ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.vcf.gz"" --confident_regions ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.bed""`. _Create examples for validation set_. `sudo docker run -v ""${PWD}/input"":""/input"" -v ""${PWD}/REF"":""/ref"" -v ""${PWD}""/output:""/output"" google/deepvariant:""1.6.1"" make_examples --mode training --ref ""/ref/GRCh38.p14.genome.fa"" --reads ""/input/27_r_groups.bam"" --examples ""/output/validation_set.gz"" --truth_variants ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.vcf.gz"" --confident_regions ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.bed"" `. _Trainning Shuffling_. `python3 scripts/shuffle_tfrecords_beam.py --input_pattern_list=output/training_set.gz --output_pattern_prefix=""output/training_shuffled"" --output_dataset_name=""26"" --output_dataset_config_pbtxt=""output/training.pbtxt"" --job_name=shuffle-tfrecords`. _Validation Shuffling_. `python3 scripts/shuf",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:666,integrability,version,version,666,"No output vcf obtained from custom model; **ISSUE**. First of all, I found DeepVariant to be a very good and innovative tool. I'm considering including it in my exome analysis pipeline. I followed the tutorial (DeepVariant worked correctly with the Complete Genomics model), and I created my own model using Genome in a Bottle samples. To do this, I sequenced the same reference sample three times to use each BAM file for training, validation, and testing. I didn't encounter any errors during the model creation process, but when I tried to test it, the process got stuck at the call_variants step. **Setup**. - Operating system: Ubuntu 22.04.4 LTS. - DeepVariant version:1.6.1. - Installation method:docker. - Type of data: MGI DNBSEQ 400, exome sequencing. **Steps to reproduce:**. - Command:. _Create examples for trainning set_. `sudo docker run -v ""${PWD}/input"":""/input"" -v ""${PWD}/REF"":""/ref"" -v ""${PWD}""/output:""/output"" google/deepvariant:""1.6.1"" make_examples --mode training --ref ""/ref/GRCh38.p14.genome.fa"" --reads ""/input/26_r_groups.bam"" --examples ""/output/training_set.gz"" --truth_variants ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.vcf.gz"" --confident_regions ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.bed""`. _Create examples for validation set_. `sudo docker run -v ""${PWD}/input"":""/input"" -v ""${PWD}/REF"":""/ref"" -v ""${PWD}""/output:""/output"" google/deepvariant:""1.6.1"" make_examples --mode training --ref ""/ref/GRCh38.p14.genome.fa"" --reads ""/input/27_r_groups.bam"" --examples ""/output/validation_set.gz"" --truth_variants ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.vcf.gz"" --confident_regions ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.bed"" `. _Trainning Shuffling_. `python3 scripts/shuffle_tfrecords_beam.py --input_pattern_list=output/training_set.gz --output_pattern_prefix=""output/training_shuffled"" --output_dataset_name=""26"" --output_dataset_config_pbtxt=""output/training.pbtxt"" --job_name=shuffle-tfrecords`. _Validation Shuffling_. `python3 scripts/shuf",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:5020,integrability,depend,dependencies,5020,"py:2958] example_shape = [100, 221, 7]. I0822 07:52:09.283712 133276175411008 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 19]. I0822 07:52:09.283882 133276175411008 make_examples_core.py:301] Task 8/20: Found 17371 candidate variants. I0822 07:52:09.283904 133276175411008 make_examples_core.py:301] Task 8/20: Created 18820 examples. real 34m15.728s. user 624m43.553s. sys 2m24.932s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@20.gz"" --checkpoint ""/output/checkpoints/ckpt-679"". /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: . TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). . For more information see: https://github.com/tensorflow/addons/issues/2807 . warnings.warn(. I0822 07:52:10.812179 127086447671104 call_variants.py:563] Total 1 writing processes started. I0822 07:52:10.813103 127086447671104 dv_utils.py:370] From /output/intermediate_results_dir/make_examples.tfrecord-00000-of-00020.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0822 07:52:10.813141 127086447671104 call_variants.py:588] Shape of input examples: [100, 221, 7]. I0822 07:52:10.813338 127086447671104 call_variants.py:592] Use saved model: True. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 789, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:5044,integrability,repositor,repositories,5044," [100, 221, 7]. I0822 07:52:09.283712 133276175411008 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 19]. I0822 07:52:09.283882 133276175411008 make_examples_core.py:301] Task 8/20: Found 17371 candidate variants. I0822 07:52:09.283904 133276175411008 make_examples_core.py:301] Task 8/20: Created 18820 examples. real 34m15.728s. user 624m43.553s. sys 2m24.932s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@20.gz"" --checkpoint ""/output/checkpoints/ckpt-679"". /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: . TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). . For more information see: https://github.com/tensorflow/addons/issues/2807 . warnings.warn(. I0822 07:52:10.812179 127086447671104 call_variants.py:563] Total 1 writing processes started. I0822 07:52:10.813103 127086447671104 dv_utils.py:370] From /output/intermediate_results_dir/make_examples.tfrecord-00000-of-00020.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0822 07:52:10.813141 127086447671104 call_variants.py:588] Shape of input examples: [100, 221, 7]. I0822 07:52:10.813338 127086447671104 call_variants.py:592] Use saved model: True. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 789, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_5v5",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:7609,integrability,queue,queues,7609,"ll last):. File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 789, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 768, in main. call_variants(. File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 598, in call_variants. model_example_shape = dv_utils.get_shape_and_channels_from_json(. File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvariant/deepvariant/dv_utils.py"", line 367, in get_shape_and_channels_from_json. example_info = json.load(f). File ""/usr/lib/python3.8/json/__init__.py"", line 293, in load. return loads(fp.read(),. File ""/usr/lib/python3.8/json/__init__.py"", line 357, in loads. return _default_decoder.decode(s). File ""/usr/lib/python3.8/json/decoder.py"", line 337, in decode. obj, end = self.raw_decode(s, idx=_w(s, 0).end()). File ""/usr/lib/python3.8/json/decoder.py"", line 355, in raw_decode. raise JSONDecodeError(""Expecting value"", s, err.value) from None. json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0). Process ForkProcess-1:. Traceback (most recent call last):. File ""/usr/lib/python3.8/multiprocessing/process.py"", line 315, in _bootstrap. self.run(). File ""/usr/lib/python3.8/multiprocessing/process.py"", line 108, in run. self._target(*self._args, **self._kwargs). File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 454, in post_processing. item = output_queue.get(timeout=180). File ""/usr/lib/python3.8/multiprocessing/queues.py"", line 108, in get. raise Empty. _queue.Empty. real 3m2.335s. user 0m7.450s. sys 0m4.274s`. **Does the quick start test work on your system?**. Yes.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:5044,interoperability,repositor,repositories,5044," [100, 221, 7]. I0822 07:52:09.283712 133276175411008 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 19]. I0822 07:52:09.283882 133276175411008 make_examples_core.py:301] Task 8/20: Found 17371 candidate variants. I0822 07:52:09.283904 133276175411008 make_examples_core.py:301] Task 8/20: Created 18820 examples. real 34m15.728s. user 624m43.553s. sys 2m24.932s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@20.gz"" --checkpoint ""/output/checkpoints/ckpt-679"". /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: . TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). . For more information see: https://github.com/tensorflow/addons/issues/2807 . warnings.warn(. I0822 07:52:10.812179 127086447671104 call_variants.py:563] Total 1 writing processes started. I0822 07:52:10.813103 127086447671104 dv_utils.py:370] From /output/intermediate_results_dir/make_examples.tfrecord-00000-of-00020.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0822 07:52:10.813141 127086447671104 call_variants.py:588] Shape of input examples: [100, 221, 7]. I0822 07:52:10.813338 127086447671104 call_variants.py:592] Use saved model: True. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 789, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_5v5",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:666,modifiability,version,version,666,"No output vcf obtained from custom model; **ISSUE**. First of all, I found DeepVariant to be a very good and innovative tool. I'm considering including it in my exome analysis pipeline. I followed the tutorial (DeepVariant worked correctly with the Complete Genomics model), and I created my own model using Genome in a Bottle samples. To do this, I sequenced the same reference sample three times to use each BAM file for training, validation, and testing. I didn't encounter any errors during the model creation process, but when I tried to test it, the process got stuck at the call_variants step. **Setup**. - Operating system: Ubuntu 22.04.4 LTS. - DeepVariant version:1.6.1. - Installation method:docker. - Type of data: MGI DNBSEQ 400, exome sequencing. **Steps to reproduce:**. - Command:. _Create examples for trainning set_. `sudo docker run -v ""${PWD}/input"":""/input"" -v ""${PWD}/REF"":""/ref"" -v ""${PWD}""/output:""/output"" google/deepvariant:""1.6.1"" make_examples --mode training --ref ""/ref/GRCh38.p14.genome.fa"" --reads ""/input/26_r_groups.bam"" --examples ""/output/training_set.gz"" --truth_variants ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.vcf.gz"" --confident_regions ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.bed""`. _Create examples for validation set_. `sudo docker run -v ""${PWD}/input"":""/input"" -v ""${PWD}/REF"":""/ref"" -v ""${PWD}""/output:""/output"" google/deepvariant:""1.6.1"" make_examples --mode training --ref ""/ref/GRCh38.p14.genome.fa"" --reads ""/input/27_r_groups.bam"" --examples ""/output/validation_set.gz"" --truth_variants ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.vcf.gz"" --confident_regions ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.bed"" `. _Trainning Shuffling_. `python3 scripts/shuffle_tfrecords_beam.py --input_pattern_list=output/training_set.gz --output_pattern_prefix=""output/training_shuffled"" --output_dataset_name=""26"" --output_dataset_config_pbtxt=""output/training.pbtxt"" --job_name=shuffle-tfrecords`. _Validation Shuffling_. `python3 scripts/shuf",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:4734,modifiability,pac,packages,4734,"] Task 17/20: Created 18817 examples. I0822 07:52:09.283522 133276175411008 make_examples_core.py:301] Task 8/20: Writing example info to /output/intermediate_results_dir/make_examples.tfrecord-00008-of-00020.gz.example_info.json. I0822 07:52:09.283617 133276175411008 make_examples_core.py:2958] example_shape = [100, 221, 7]. I0822 07:52:09.283712 133276175411008 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 19]. I0822 07:52:09.283882 133276175411008 make_examples_core.py:301] Task 8/20: Found 17371 candidate variants. I0822 07:52:09.283904 133276175411008 make_examples_core.py:301] Task 8/20: Created 18820 examples. real 34m15.728s. user 624m43.553s. sys 2m24.932s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@20.gz"" --checkpoint ""/output/checkpoints/ckpt-679"". /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: . TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). . For more information see: https://github.com/tensorflow/addons/issues/2807 . warnings.warn(. I0822 07:52:10.812179 127086447671104 call_variants.py:563] Total 1 writing processes started. I0822 07:52:10.813103 127086447671104 dv_utils.py:370] From /output/intermediate_results_dir/make_examples.tfrecord-00000-of-00020.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0822 07:52:10.813141 127086447671104 call_variants.py:588] Shape of input examples: [100, 221, 7]. I0822 07:52:10.813338 127086447671104 call_variants.py:592] Use saved model: Tr",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:5020,modifiability,depend,dependencies,5020,"py:2958] example_shape = [100, 221, 7]. I0822 07:52:09.283712 133276175411008 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 19]. I0822 07:52:09.283882 133276175411008 make_examples_core.py:301] Task 8/20: Found 17371 candidate variants. I0822 07:52:09.283904 133276175411008 make_examples_core.py:301] Task 8/20: Created 18820 examples. real 34m15.728s. user 624m43.553s. sys 2m24.932s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@20.gz"" --checkpoint ""/output/checkpoints/ckpt-679"". /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: . TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). . For more information see: https://github.com/tensorflow/addons/issues/2807 . warnings.warn(. I0822 07:52:10.812179 127086447671104 call_variants.py:563] Total 1 writing processes started. I0822 07:52:10.813103 127086447671104 dv_utils.py:370] From /output/intermediate_results_dir/make_examples.tfrecord-00000-of-00020.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0822 07:52:10.813141 127086447671104 call_variants.py:588] Shape of input examples: [100, 221, 7]. I0822 07:52:10.813338 127086447671104 call_variants.py:592] Use saved model: True. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 789, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:5890,modifiability,modul,module,5890,"red a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). . For more information see: https://github.com/tensorflow/addons/issues/2807 . warnings.warn(. I0822 07:52:10.812179 127086447671104 call_variants.py:563] Total 1 writing processes started. I0822 07:52:10.813103 127086447671104 dv_utils.py:370] From /output/intermediate_results_dir/make_examples.tfrecord-00000-of-00020.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0822 07:52:10.813141 127086447671104 call_variants.py:588] Shape of input examples: [100, 221, 7]. I0822 07:52:10.813338 127086447671104 call_variants.py:592] Use saved model: True. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 789, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 768, in main. call_variants(. File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 598, in call_variants. model_example_shape = dv_utils.get_shape_and_channels_from_json(. File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvariant/deepvariant/dv_utils.py"", line 367, in get_shape_and_channels_from_json. example_info = json.load(f). File ""/usr/lib/python3.8/json/__init__.py"", line 293, in load. return loads(fp.read(),. File ""/usr/lib/python3.8/json/__init__.py"", line 357, in loads. return _default_decoder.decode(s). File ""/usr/lib/python3.8/json/decoder.py"", line 337, in decode. obj, end = self",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:6803,modifiability,deco,decode,6803,"ll last):. File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 789, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 768, in main. call_variants(. File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 598, in call_variants. model_example_shape = dv_utils.get_shape_and_channels_from_json(. File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvariant/deepvariant/dv_utils.py"", line 367, in get_shape_and_channels_from_json. example_info = json.load(f). File ""/usr/lib/python3.8/json/__init__.py"", line 293, in load. return loads(fp.read(),. File ""/usr/lib/python3.8/json/__init__.py"", line 357, in loads. return _default_decoder.decode(s). File ""/usr/lib/python3.8/json/decoder.py"", line 337, in decode. obj, end = self.raw_decode(s, idx=_w(s, 0).end()). File ""/usr/lib/python3.8/json/decoder.py"", line 355, in raw_decode. raise JSONDecodeError(""Expecting value"", s, err.value) from None. json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0). Process ForkProcess-1:. Traceback (most recent call last):. File ""/usr/lib/python3.8/multiprocessing/process.py"", line 315, in _bootstrap. self.run(). File ""/usr/lib/python3.8/multiprocessing/process.py"", line 108, in run. self._target(*self._args, **self._kwargs). File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 454, in post_processing. item = output_queue.get(timeout=180). File ""/usr/lib/python3.8/multiprocessing/queues.py"", line 108, in get. raise Empty. _queue.Empty. real 3m2.335s. user 0m7.450s. sys 0m4.274s`. **Does the quick start test work on your system?**. Yes.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:6844,modifiability,deco,decoder,6844,"ll last):. File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 789, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 768, in main. call_variants(. File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 598, in call_variants. model_example_shape = dv_utils.get_shape_and_channels_from_json(. File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvariant/deepvariant/dv_utils.py"", line 367, in get_shape_and_channels_from_json. example_info = json.load(f). File ""/usr/lib/python3.8/json/__init__.py"", line 293, in load. return loads(fp.read(),. File ""/usr/lib/python3.8/json/__init__.py"", line 357, in loads. return _default_decoder.decode(s). File ""/usr/lib/python3.8/json/decoder.py"", line 337, in decode. obj, end = self.raw_decode(s, idx=_w(s, 0).end()). File ""/usr/lib/python3.8/json/decoder.py"", line 355, in raw_decode. raise JSONDecodeError(""Expecting value"", s, err.value) from None. json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0). Process ForkProcess-1:. Traceback (most recent call last):. File ""/usr/lib/python3.8/multiprocessing/process.py"", line 315, in _bootstrap. self.run(). File ""/usr/lib/python3.8/multiprocessing/process.py"", line 108, in run. self._target(*self._args, **self._kwargs). File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 454, in post_processing. item = output_queue.get(timeout=180). File ""/usr/lib/python3.8/multiprocessing/queues.py"", line 108, in get. raise Empty. _queue.Empty. real 3m2.335s. user 0m7.450s. sys 0m4.274s`. **Does the quick start test work on your system?**. Yes.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:6870,modifiability,deco,decode,6870,"ll last):. File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 789, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 768, in main. call_variants(. File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 598, in call_variants. model_example_shape = dv_utils.get_shape_and_channels_from_json(. File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvariant/deepvariant/dv_utils.py"", line 367, in get_shape_and_channels_from_json. example_info = json.load(f). File ""/usr/lib/python3.8/json/__init__.py"", line 293, in load. return loads(fp.read(),. File ""/usr/lib/python3.8/json/__init__.py"", line 357, in loads. return _default_decoder.decode(s). File ""/usr/lib/python3.8/json/decoder.py"", line 337, in decode. obj, end = self.raw_decode(s, idx=_w(s, 0).end()). File ""/usr/lib/python3.8/json/decoder.py"", line 355, in raw_decode. raise JSONDecodeError(""Expecting value"", s, err.value) from None. json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0). Process ForkProcess-1:. Traceback (most recent call last):. File ""/usr/lib/python3.8/multiprocessing/process.py"", line 315, in _bootstrap. self.run(). File ""/usr/lib/python3.8/multiprocessing/process.py"", line 108, in run. self._target(*self._args, **self._kwargs). File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 454, in post_processing. item = output_queue.get(timeout=180). File ""/usr/lib/python3.8/multiprocessing/queues.py"", line 108, in get. raise Empty. _queue.Empty. real 3m2.335s. user 0m7.450s. sys 0m4.274s`. **Does the quick start test work on your system?**. Yes.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:6959,modifiability,deco,decoder,6959,"ll last):. File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 789, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 768, in main. call_variants(. File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 598, in call_variants. model_example_shape = dv_utils.get_shape_and_channels_from_json(. File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvariant/deepvariant/dv_utils.py"", line 367, in get_shape_and_channels_from_json. example_info = json.load(f). File ""/usr/lib/python3.8/json/__init__.py"", line 293, in load. return loads(fp.read(),. File ""/usr/lib/python3.8/json/__init__.py"", line 357, in loads. return _default_decoder.decode(s). File ""/usr/lib/python3.8/json/decoder.py"", line 337, in decode. obj, end = self.raw_decode(s, idx=_w(s, 0).end()). File ""/usr/lib/python3.8/json/decoder.py"", line 355, in raw_decode. raise JSONDecodeError(""Expecting value"", s, err.value) from None. json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0). Process ForkProcess-1:. Traceback (most recent call last):. File ""/usr/lib/python3.8/multiprocessing/process.py"", line 315, in _bootstrap. self.run(). File ""/usr/lib/python3.8/multiprocessing/process.py"", line 108, in run. self._target(*self._args, **self._kwargs). File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 454, in post_processing. item = output_queue.get(timeout=180). File ""/usr/lib/python3.8/multiprocessing/queues.py"", line 108, in get. raise Empty. _queue.Empty. real 3m2.335s. user 0m7.450s. sys 0m4.274s`. **Does the quick start test work on your system?**. Yes.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:7068,modifiability,deco,decoder,7068,"ll last):. File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 789, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 768, in main. call_variants(. File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 598, in call_variants. model_example_shape = dv_utils.get_shape_and_channels_from_json(. File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvariant/deepvariant/dv_utils.py"", line 367, in get_shape_and_channels_from_json. example_info = json.load(f). File ""/usr/lib/python3.8/json/__init__.py"", line 293, in load. return loads(fp.read(),. File ""/usr/lib/python3.8/json/__init__.py"", line 357, in loads. return _default_decoder.decode(s). File ""/usr/lib/python3.8/json/decoder.py"", line 337, in decode. obj, end = self.raw_decode(s, idx=_w(s, 0).end()). File ""/usr/lib/python3.8/json/decoder.py"", line 355, in raw_decode. raise JSONDecodeError(""Expecting value"", s, err.value) from None. json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0). Process ForkProcess-1:. Traceback (most recent call last):. File ""/usr/lib/python3.8/multiprocessing/process.py"", line 315, in _bootstrap. self.run(). File ""/usr/lib/python3.8/multiprocessing/process.py"", line 108, in run. self._target(*self._args, **self._kwargs). File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 454, in post_processing. item = output_queue.get(timeout=180). File ""/usr/lib/python3.8/multiprocessing/queues.py"", line 108, in get. raise Empty. _queue.Empty. real 3m2.335s. user 0m7.450s. sys 0m4.274s`. **Does the quick start test work on your system?**. Yes.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:392,performance,time,times,392,"No output vcf obtained from custom model; **ISSUE**. First of all, I found DeepVariant to be a very good and innovative tool. I'm considering including it in my exome analysis pipeline. I followed the tutorial (DeepVariant worked correctly with the Complete Genomics model), and I created my own model using Genome in a Bottle samples. To do this, I sequenced the same reference sample three times to use each BAM file for training, validation, and testing. I didn't encounter any errors during the model creation process, but when I tried to test it, the process got stuck at the call_variants step. **Setup**. - Operating system: Ubuntu 22.04.4 LTS. - DeepVariant version:1.6.1. - Installation method:docker. - Type of data: MGI DNBSEQ 400, exome sequencing. **Steps to reproduce:**. - Command:. _Create examples for trainning set_. `sudo docker run -v ""${PWD}/input"":""/input"" -v ""${PWD}/REF"":""/ref"" -v ""${PWD}""/output:""/output"" google/deepvariant:""1.6.1"" make_examples --mode training --ref ""/ref/GRCh38.p14.genome.fa"" --reads ""/input/26_r_groups.bam"" --examples ""/output/training_set.gz"" --truth_variants ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.vcf.gz"" --confident_regions ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.bed""`. _Create examples for validation set_. `sudo docker run -v ""${PWD}/input"":""/input"" -v ""${PWD}/REF"":""/ref"" -v ""${PWD}""/output:""/output"" google/deepvariant:""1.6.1"" make_examples --mode training --ref ""/ref/GRCh38.p14.genome.fa"" --reads ""/input/27_r_groups.bam"" --examples ""/output/validation_set.gz"" --truth_variants ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.vcf.gz"" --confident_regions ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.bed"" `. _Trainning Shuffling_. `python3 scripts/shuffle_tfrecords_beam.py --input_pattern_list=output/training_set.gz --output_pattern_prefix=""output/training_shuffled"" --output_dataset_name=""26"" --output_dataset_config_pbtxt=""output/training.pbtxt"" --job_name=shuffle-tfrecords`. _Validation Shuffling_. `python3 scripts/shuf",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:481,performance,error,errors,481,"No output vcf obtained from custom model; **ISSUE**. First of all, I found DeepVariant to be a very good and innovative tool. I'm considering including it in my exome analysis pipeline. I followed the tutorial (DeepVariant worked correctly with the Complete Genomics model), and I created my own model using Genome in a Bottle samples. To do this, I sequenced the same reference sample three times to use each BAM file for training, validation, and testing. I didn't encounter any errors during the model creation process, but when I tried to test it, the process got stuck at the call_variants step. **Setup**. - Operating system: Ubuntu 22.04.4 LTS. - DeepVariant version:1.6.1. - Installation method:docker. - Type of data: MGI DNBSEQ 400, exome sequencing. **Steps to reproduce:**. - Command:. _Create examples for trainning set_. `sudo docker run -v ""${PWD}/input"":""/input"" -v ""${PWD}/REF"":""/ref"" -v ""${PWD}""/output:""/output"" google/deepvariant:""1.6.1"" make_examples --mode training --ref ""/ref/GRCh38.p14.genome.fa"" --reads ""/input/26_r_groups.bam"" --examples ""/output/training_set.gz"" --truth_variants ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.vcf.gz"" --confident_regions ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.bed""`. _Create examples for validation set_. `sudo docker run -v ""${PWD}/input"":""/input"" -v ""${PWD}/REF"":""/ref"" -v ""${PWD}""/output:""/output"" google/deepvariant:""1.6.1"" make_examples --mode training --ref ""/ref/GRCh38.p14.genome.fa"" --reads ""/input/27_r_groups.bam"" --examples ""/output/validation_set.gz"" --truth_variants ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.vcf.gz"" --confident_regions ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.bed"" `. _Trainning Shuffling_. `python3 scripts/shuffle_tfrecords_beam.py --input_pattern_list=output/training_set.gz --output_pattern_prefix=""output/training_shuffled"" --output_dataset_name=""26"" --output_dataset_config_pbtxt=""output/training.pbtxt"" --job_name=shuffle-tfrecords`. _Validation Shuffling_. `python3 scripts/shuf",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:3147,performance,Error,Error,3147,"output_dataset_config_pbtxt=""output/validation.pbtxt"" --job_name=shuffle-tfrecords `. _Model trainning_. `sudo docker run -v ""${PWD}/input"":""/input"" -v ""${PWD}/REF"":""/ref"" -v ""${PWD}""/output:""/output"" google/deepvariant:""1.6.1"" train --config=/input/dv_config.py:base --config.train_dataset_pbtxt=""/output/training.pbtxt"" --config.tune_dataset_pbtxt=""/output/validation.pbtxt"" --config.num_epochs=10 --config.learning_rate=0.0001 --config.num_validation_examples=0 --strategy=mirrored --experiment_dir=""/output/"" --config.batch_size=512`. _Model test_. `sudo docker run -v ""${PWD}/input"":""/input"" -v ""${PWD}/REF"":""/ref"" -v ""${PWD}""/output:""/output"" google/deepvariant:""1.6.1"" /opt/deepvariant/bin/run_deepvariant --model_type WES --customized_model ""/output/checkpoints/ckpt-679"" --ref ""/ref/GRCh38.p14.genome.fa"" --reads ""/input/33_r_groups.bam"" --output_vcf ""/output/33.vcf.gz"" --output_gvcf ""/output/33.g.vcf.gz"" -intermediate_results_dir ""/output/intermediate_results_dir"" --num_shards 10`. - Error trace: . ` - I0822 07:51:54.272576 127450974123840 make_examples_core.py:301] Task 17/20: Writing example info to /output/intermediate_results_dir/make_examples.tfrecord-00017-of-00020.gz.example_info.json. I0822 07:51:54.272647 127450974123840 make_examples_core.py:2958] example_shape = [100, 221, 7]. I0822 07:51:54.272740 127450974123840 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 19]. I0822 07:51:54.272911 127450974123840 make_examples_core.py:301] Task 17/20: Found 17451 candidate variants. I0822 07:51:54.272932 127450974123840 make_examples_core.py:301] Task 17/20: Created 18817 examples. I0822 07:52:09.283522 133276175411008 make_examples_core.py:301] Task 8/20: Writing example info to /output/intermediate_results_dir/make_examples.tfrecord-00008-of-00020.gz.example_info.json. I0822 07:52:09.283617 133276175411008 make_examples_core.py:2958] example_shape = [100, 221, 7]. I0822 07:52:09.283712 133276175411008 make_examples_core.py:2959] example_channels =",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:4466,performance,time,time,4466,":54.272740 127450974123840 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 19]. I0822 07:51:54.272911 127450974123840 make_examples_core.py:301] Task 17/20: Found 17451 candidate variants. I0822 07:51:54.272932 127450974123840 make_examples_core.py:301] Task 17/20: Created 18817 examples. I0822 07:52:09.283522 133276175411008 make_examples_core.py:301] Task 8/20: Writing example info to /output/intermediate_results_dir/make_examples.tfrecord-00008-of-00020.gz.example_info.json. I0822 07:52:09.283617 133276175411008 make_examples_core.py:2958] example_shape = [100, 221, 7]. I0822 07:52:09.283712 133276175411008 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 19]. I0822 07:52:09.283882 133276175411008 make_examples_core.py:301] Task 8/20: Found 17371 candidate variants. I0822 07:52:09.283904 133276175411008 make_examples_core.py:301] Task 8/20: Created 18820 examples. real 34m15.728s. user 624m43.553s. sys 2m24.932s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@20.gz"" --checkpoint ""/output/checkpoints/ckpt-679"". /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: . TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). . For more information see: https://github.com/tensorflow/addons/issues/2807 . warnings.warn(. I0822 07:52:10.812179 127086447671104 call_variants.py:563] Total 1 writing processes started. I0822 07:52:10.813103 127086447671104 dv_utils.py:370] From /output/intermediate_results_dir/make_examples.tfrecord-00000-of-00020.gz.example_info.json: S",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:6618,performance,load,load,6618,"hape of input examples: [100, 221, 7]. I0822 07:52:10.813338 127086447671104 call_variants.py:592] Use saved model: True. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 789, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 768, in main. call_variants(. File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 598, in call_variants. model_example_shape = dv_utils.get_shape_and_channels_from_json(. File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvariant/deepvariant/dv_utils.py"", line 367, in get_shape_and_channels_from_json. example_info = json.load(f). File ""/usr/lib/python3.8/json/__init__.py"", line 293, in load. return loads(fp.read(),. File ""/usr/lib/python3.8/json/__init__.py"", line 357, in loads. return _default_decoder.decode(s). File ""/usr/lib/python3.8/json/decoder.py"", line 337, in decode. obj, end = self.raw_decode(s, idx=_w(s, 0).end()). File ""/usr/lib/python3.8/json/decoder.py"", line 355, in raw_decode. raise JSONDecodeError(""Expecting value"", s, err.value) from None. json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0). Process ForkProcess-1:. Traceback (most recent call last):. File ""/usr/lib/python3.8/multiprocessing/process.py"", line 315, in _bootstrap. self.run(). File ""/usr/lib/python3.8/multiprocessing/process.py"", line 108, in run. self._target(*self._args, **self._kwargs). File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 454, in post_processing. item = output_queue.get(timeout=180). File ""/usr/lib/python3.8/multiprocessing/queues.py"",",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:6684,performance,load,load,6684,"6447671104 call_variants.py:592] Use saved model: True. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 789, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 768, in main. call_variants(. File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 598, in call_variants. model_example_shape = dv_utils.get_shape_and_channels_from_json(. File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvariant/deepvariant/dv_utils.py"", line 367, in get_shape_and_channels_from_json. example_info = json.load(f). File ""/usr/lib/python3.8/json/__init__.py"", line 293, in load. return loads(fp.read(),. File ""/usr/lib/python3.8/json/__init__.py"", line 357, in loads. return _default_decoder.decode(s). File ""/usr/lib/python3.8/json/decoder.py"", line 337, in decode. obj, end = self.raw_decode(s, idx=_w(s, 0).end()). File ""/usr/lib/python3.8/json/decoder.py"", line 355, in raw_decode. raise JSONDecodeError(""Expecting value"", s, err.value) from None. json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0). Process ForkProcess-1:. Traceback (most recent call last):. File ""/usr/lib/python3.8/multiprocessing/process.py"", line 315, in _bootstrap. self.run(). File ""/usr/lib/python3.8/multiprocessing/process.py"", line 108, in run. self._target(*self._args, **self._kwargs). File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 454, in post_processing. item = output_queue.get(timeout=180). File ""/usr/lib/python3.8/multiprocessing/queues.py"", line 108, in get. raise Empty. _queue.Empty. real 3m2.335s. user ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:6697,performance,load,loads,6697,"l_variants.py:592] Use saved model: True. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 789, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 768, in main. call_variants(. File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 598, in call_variants. model_example_shape = dv_utils.get_shape_and_channels_from_json(. File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvariant/deepvariant/dv_utils.py"", line 367, in get_shape_and_channels_from_json. example_info = json.load(f). File ""/usr/lib/python3.8/json/__init__.py"", line 293, in load. return loads(fp.read(),. File ""/usr/lib/python3.8/json/__init__.py"", line 357, in loads. return _default_decoder.decode(s). File ""/usr/lib/python3.8/json/decoder.py"", line 337, in decode. obj, end = self.raw_decode(s, idx=_w(s, 0).end()). File ""/usr/lib/python3.8/json/decoder.py"", line 355, in raw_decode. raise JSONDecodeError(""Expecting value"", s, err.value) from None. json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0). Process ForkProcess-1:. Traceback (most recent call last):. File ""/usr/lib/python3.8/multiprocessing/process.py"", line 315, in _bootstrap. self.run(). File ""/usr/lib/python3.8/multiprocessing/process.py"", line 108, in run. self._target(*self._args, **self._kwargs). File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 454, in post_processing. item = output_queue.get(timeout=180). File ""/usr/lib/python3.8/multiprocessing/queues.py"", line 108, in get. raise Empty. _queue.Empty. real 3m2.335s. user 0m7.450s. sys ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:6772,performance,load,loads,6772,"ll last):. File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 789, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 768, in main. call_variants(. File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 598, in call_variants. model_example_shape = dv_utils.get_shape_and_channels_from_json(. File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvariant/deepvariant/dv_utils.py"", line 367, in get_shape_and_channels_from_json. example_info = json.load(f). File ""/usr/lib/python3.8/json/__init__.py"", line 293, in load. return loads(fp.read(),. File ""/usr/lib/python3.8/json/__init__.py"", line 357, in loads. return _default_decoder.decode(s). File ""/usr/lib/python3.8/json/decoder.py"", line 337, in decode. obj, end = self.raw_decode(s, idx=_w(s, 0).end()). File ""/usr/lib/python3.8/json/decoder.py"", line 355, in raw_decode. raise JSONDecodeError(""Expecting value"", s, err.value) from None. json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0). Process ForkProcess-1:. Traceback (most recent call last):. File ""/usr/lib/python3.8/multiprocessing/process.py"", line 315, in _bootstrap. self.run(). File ""/usr/lib/python3.8/multiprocessing/process.py"", line 108, in run. self._target(*self._args, **self._kwargs). File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 454, in post_processing. item = output_queue.get(timeout=180). File ""/usr/lib/python3.8/multiprocessing/queues.py"", line 108, in get. raise Empty. _queue.Empty. real 3m2.335s. user 0m7.450s. sys 0m4.274s`. **Does the quick start test work on your system?**. Yes.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:7554,performance,time,timeout,7554,"ll last):. File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 789, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 768, in main. call_variants(. File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 598, in call_variants. model_example_shape = dv_utils.get_shape_and_channels_from_json(. File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvariant/deepvariant/dv_utils.py"", line 367, in get_shape_and_channels_from_json. example_info = json.load(f). File ""/usr/lib/python3.8/json/__init__.py"", line 293, in load. return loads(fp.read(),. File ""/usr/lib/python3.8/json/__init__.py"", line 357, in loads. return _default_decoder.decode(s). File ""/usr/lib/python3.8/json/decoder.py"", line 337, in decode. obj, end = self.raw_decode(s, idx=_w(s, 0).end()). File ""/usr/lib/python3.8/json/decoder.py"", line 355, in raw_decode. raise JSONDecodeError(""Expecting value"", s, err.value) from None. json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0). Process ForkProcess-1:. Traceback (most recent call last):. File ""/usr/lib/python3.8/multiprocessing/process.py"", line 315, in _bootstrap. self.run(). File ""/usr/lib/python3.8/multiprocessing/process.py"", line 108, in run. self._target(*self._args, **self._kwargs). File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 454, in post_processing. item = output_queue.get(timeout=180). File ""/usr/lib/python3.8/multiprocessing/queues.py"", line 108, in get. raise Empty. _queue.Empty. real 3m2.335s. user 0m7.450s. sys 0m4.274s`. **Does the quick start test work on your system?**. Yes.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:7609,performance,queue,queues,7609,"ll last):. File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 789, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 768, in main. call_variants(. File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 598, in call_variants. model_example_shape = dv_utils.get_shape_and_channels_from_json(. File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvariant/deepvariant/dv_utils.py"", line 367, in get_shape_and_channels_from_json. example_info = json.load(f). File ""/usr/lib/python3.8/json/__init__.py"", line 293, in load. return loads(fp.read(),. File ""/usr/lib/python3.8/json/__init__.py"", line 357, in loads. return _default_decoder.decode(s). File ""/usr/lib/python3.8/json/decoder.py"", line 337, in decode. obj, end = self.raw_decode(s, idx=_w(s, 0).end()). File ""/usr/lib/python3.8/json/decoder.py"", line 355, in raw_decode. raise JSONDecodeError(""Expecting value"", s, err.value) from None. json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0). Process ForkProcess-1:. Traceback (most recent call last):. File ""/usr/lib/python3.8/multiprocessing/process.py"", line 315, in _bootstrap. self.run(). File ""/usr/lib/python3.8/multiprocessing/process.py"", line 108, in run. self._target(*self._args, **self._kwargs). File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 454, in post_processing. item = output_queue.get(timeout=180). File ""/usr/lib/python3.8/multiprocessing/queues.py"", line 108, in get. raise Empty. _queue.Empty. real 3m2.335s. user 0m7.450s. sys 0m4.274s`. **Does the quick start test work on your system?**. Yes.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:2908,reliability,checkpoint,checkpoints,2908,"ng.pbtxt"" --job_name=shuffle-tfrecords`. _Validation Shuffling_. `python3 scripts/shuffle_tfrecords_beam.py --input_pattern_list=output/validation_set.gz --output_pattern_prefix=""output/validation_shuffled"" --output_dataset_name=""27"" --output_dataset_config_pbtxt=""output/validation.pbtxt"" --job_name=shuffle-tfrecords `. _Model trainning_. `sudo docker run -v ""${PWD}/input"":""/input"" -v ""${PWD}/REF"":""/ref"" -v ""${PWD}""/output:""/output"" google/deepvariant:""1.6.1"" train --config=/input/dv_config.py:base --config.train_dataset_pbtxt=""/output/training.pbtxt"" --config.tune_dataset_pbtxt=""/output/validation.pbtxt"" --config.num_epochs=10 --config.learning_rate=0.0001 --config.num_validation_examples=0 --strategy=mirrored --experiment_dir=""/output/"" --config.batch_size=512`. _Model test_. `sudo docker run -v ""${PWD}/input"":""/input"" -v ""${PWD}/REF"":""/ref"" -v ""${PWD}""/output:""/output"" google/deepvariant:""1.6.1"" /opt/deepvariant/bin/run_deepvariant --model_type WES --customized_model ""/output/checkpoints/ckpt-679"" --ref ""/ref/GRCh38.p14.genome.fa"" --reads ""/input/33_r_groups.bam"" --output_vcf ""/output/33.vcf.gz"" --output_gvcf ""/output/33.g.vcf.gz"" -intermediate_results_dir ""/output/intermediate_results_dir"" --num_shards 10`. - Error trace: . ` - I0822 07:51:54.272576 127450974123840 make_examples_core.py:301] Task 17/20: Writing example info to /output/intermediate_results_dir/make_examples.tfrecord-00017-of-00020.gz.example_info.json. I0822 07:51:54.272647 127450974123840 make_examples_core.py:2958] example_shape = [100, 221, 7]. I0822 07:51:54.272740 127450974123840 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 19]. I0822 07:51:54.272911 127450974123840 make_examples_core.py:301] Task 17/20: Found 17451 candidate variants. I0822 07:51:54.272932 127450974123840 make_examples_core.py:301] Task 17/20: Created 18817 examples. I0822 07:52:09.283522 133276175411008 make_examples_core.py:301] Task 8/20: Writing example info to /output/intermediate_results_dir/make_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:4661,reliability,checkpoint,checkpoint,4661,"ariants. I0822 07:51:54.272932 127450974123840 make_examples_core.py:301] Task 17/20: Created 18817 examples. I0822 07:52:09.283522 133276175411008 make_examples_core.py:301] Task 8/20: Writing example info to /output/intermediate_results_dir/make_examples.tfrecord-00008-of-00020.gz.example_info.json. I0822 07:52:09.283617 133276175411008 make_examples_core.py:2958] example_shape = [100, 221, 7]. I0822 07:52:09.283712 133276175411008 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 19]. I0822 07:52:09.283882 133276175411008 make_examples_core.py:301] Task 8/20: Found 17371 candidate variants. I0822 07:52:09.283904 133276175411008 make_examples_core.py:301] Task 8/20: Created 18820 examples. real 34m15.728s. user 624m43.553s. sys 2m24.932s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@20.gz"" --checkpoint ""/output/checkpoints/ckpt-679"". /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: . TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). . For more information see: https://github.com/tensorflow/addons/issues/2807 . warnings.warn(. I0822 07:52:10.812179 127086447671104 call_variants.py:563] Total 1 writing processes started. I0822 07:52:10.813103 127086447671104 dv_utils.py:370] From /output/intermediate_results_dir/make_examples.tfrecord-00000-of-00020.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0822 07:52:10.813141 127086447671104 call_variants.py:588] Shape of input examples: [100, 221, 7]. I0822 0",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:4681,reliability,checkpoint,checkpoints,4681,"54.272932 127450974123840 make_examples_core.py:301] Task 17/20: Created 18817 examples. I0822 07:52:09.283522 133276175411008 make_examples_core.py:301] Task 8/20: Writing example info to /output/intermediate_results_dir/make_examples.tfrecord-00008-of-00020.gz.example_info.json. I0822 07:52:09.283617 133276175411008 make_examples_core.py:2958] example_shape = [100, 221, 7]. I0822 07:52:09.283712 133276175411008 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 19]. I0822 07:52:09.283882 133276175411008 make_examples_core.py:301] Task 8/20: Found 17371 candidate variants. I0822 07:52:09.283904 133276175411008 make_examples_core.py:301] Task 8/20: Created 18820 examples. real 34m15.728s. user 624m43.553s. sys 2m24.932s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@20.gz"" --checkpoint ""/output/checkpoints/ckpt-679"". /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: . TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). . For more information see: https://github.com/tensorflow/addons/issues/2807 . warnings.warn(. I0822 07:52:10.812179 127086447671104 call_variants.py:563] Total 1 writing processes started. I0822 07:52:10.813103 127086447671104 dv_utils.py:370] From /output/intermediate_results_dir/make_examples.tfrecord-00000-of-00020.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0822 07:52:10.813141 127086447671104 call_variants.py:588] Shape of input examples: [100, 221, 7]. I0822 07:52:10.813338 127086",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:4907,reliability,mainten,maintenance,4907,"_examples.tfrecord-00008-of-00020.gz.example_info.json. I0822 07:52:09.283617 133276175411008 make_examples_core.py:2958] example_shape = [100, 221, 7]. I0822 07:52:09.283712 133276175411008 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 19]. I0822 07:52:09.283882 133276175411008 make_examples_core.py:301] Task 8/20: Found 17371 candidate variants. I0822 07:52:09.283904 133276175411008 make_examples_core.py:301] Task 8/20: Created 18820 examples. real 34m15.728s. user 624m43.553s. sys 2m24.932s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@20.gz"" --checkpoint ""/output/checkpoints/ckpt-679"". /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: . TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). . For more information see: https://github.com/tensorflow/addons/issues/2807 . warnings.warn(. I0822 07:52:10.812179 127086447671104 call_variants.py:563] Total 1 writing processes started. I0822 07:52:10.813103 127086447671104 dv_utils.py:370] From /output/intermediate_results_dir/make_examples.tfrecord-00000-of-00020.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0822 07:52:10.813141 127086447671104 call_variants.py:588] Shape of input examples: [100, 221, 7]. I0822 07:52:10.813338 127086447671104 call_variants.py:592] Use saved model: True. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 789, in <module>. app.run(main).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:7713,reliability,Doe,Does,7713,"ll last):. File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 789, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 768, in main. call_variants(. File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 598, in call_variants. model_example_shape = dv_utils.get_shape_and_channels_from_json(. File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvariant/deepvariant/dv_utils.py"", line 367, in get_shape_and_channels_from_json. example_info = json.load(f). File ""/usr/lib/python3.8/json/__init__.py"", line 293, in load. return loads(fp.read(),. File ""/usr/lib/python3.8/json/__init__.py"", line 357, in loads. return _default_decoder.decode(s). File ""/usr/lib/python3.8/json/decoder.py"", line 337, in decode. obj, end = self.raw_decode(s, idx=_w(s, 0).end()). File ""/usr/lib/python3.8/json/decoder.py"", line 355, in raw_decode. raise JSONDecodeError(""Expecting value"", s, err.value) from None. json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0). Process ForkProcess-1:. Traceback (most recent call last):. File ""/usr/lib/python3.8/multiprocessing/process.py"", line 315, in _bootstrap. self.run(). File ""/usr/lib/python3.8/multiprocessing/process.py"", line 108, in run. self._target(*self._args, **self._kwargs). File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 454, in post_processing. item = output_queue.get(timeout=180). File ""/usr/lib/python3.8/multiprocessing/queues.py"", line 108, in get. raise Empty. _queue.Empty. real 3m2.335s. user 0m7.450s. sys 0m4.274s`. **Does the quick start test work on your system?**. Yes.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:249,safety,Compl,Complete,249,"No output vcf obtained from custom model; **ISSUE**. First of all, I found DeepVariant to be a very good and innovative tool. I'm considering including it in my exome analysis pipeline. I followed the tutorial (DeepVariant worked correctly with the Complete Genomics model), and I created my own model using Genome in a Bottle samples. To do this, I sequenced the same reference sample three times to use each BAM file for training, validation, and testing. I didn't encounter any errors during the model creation process, but when I tried to test it, the process got stuck at the call_variants step. **Setup**. - Operating system: Ubuntu 22.04.4 LTS. - DeepVariant version:1.6.1. - Installation method:docker. - Type of data: MGI DNBSEQ 400, exome sequencing. **Steps to reproduce:**. - Command:. _Create examples for trainning set_. `sudo docker run -v ""${PWD}/input"":""/input"" -v ""${PWD}/REF"":""/ref"" -v ""${PWD}""/output:""/output"" google/deepvariant:""1.6.1"" make_examples --mode training --ref ""/ref/GRCh38.p14.genome.fa"" --reads ""/input/26_r_groups.bam"" --examples ""/output/training_set.gz"" --truth_variants ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.vcf.gz"" --confident_regions ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.bed""`. _Create examples for validation set_. `sudo docker run -v ""${PWD}/input"":""/input"" -v ""${PWD}/REF"":""/ref"" -v ""${PWD}""/output:""/output"" google/deepvariant:""1.6.1"" make_examples --mode training --ref ""/ref/GRCh38.p14.genome.fa"" --reads ""/input/27_r_groups.bam"" --examples ""/output/validation_set.gz"" --truth_variants ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.vcf.gz"" --confident_regions ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.bed"" `. _Trainning Shuffling_. `python3 scripts/shuffle_tfrecords_beam.py --input_pattern_list=output/training_set.gz --output_pattern_prefix=""output/training_shuffled"" --output_dataset_name=""26"" --output_dataset_config_pbtxt=""output/training.pbtxt"" --job_name=shuffle-tfrecords`. _Validation Shuffling_. `python3 scripts/shuf",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:433,safety,valid,validation,433,"No output vcf obtained from custom model; **ISSUE**. First of all, I found DeepVariant to be a very good and innovative tool. I'm considering including it in my exome analysis pipeline. I followed the tutorial (DeepVariant worked correctly with the Complete Genomics model), and I created my own model using Genome in a Bottle samples. To do this, I sequenced the same reference sample three times to use each BAM file for training, validation, and testing. I didn't encounter any errors during the model creation process, but when I tried to test it, the process got stuck at the call_variants step. **Setup**. - Operating system: Ubuntu 22.04.4 LTS. - DeepVariant version:1.6.1. - Installation method:docker. - Type of data: MGI DNBSEQ 400, exome sequencing. **Steps to reproduce:**. - Command:. _Create examples for trainning set_. `sudo docker run -v ""${PWD}/input"":""/input"" -v ""${PWD}/REF"":""/ref"" -v ""${PWD}""/output:""/output"" google/deepvariant:""1.6.1"" make_examples --mode training --ref ""/ref/GRCh38.p14.genome.fa"" --reads ""/input/26_r_groups.bam"" --examples ""/output/training_set.gz"" --truth_variants ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.vcf.gz"" --confident_regions ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.bed""`. _Create examples for validation set_. `sudo docker run -v ""${PWD}/input"":""/input"" -v ""${PWD}/REF"":""/ref"" -v ""${PWD}""/output:""/output"" google/deepvariant:""1.6.1"" make_examples --mode training --ref ""/ref/GRCh38.p14.genome.fa"" --reads ""/input/27_r_groups.bam"" --examples ""/output/validation_set.gz"" --truth_variants ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.vcf.gz"" --confident_regions ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.bed"" `. _Trainning Shuffling_. `python3 scripts/shuffle_tfrecords_beam.py --input_pattern_list=output/training_set.gz --output_pattern_prefix=""output/training_shuffled"" --output_dataset_name=""26"" --output_dataset_config_pbtxt=""output/training.pbtxt"" --job_name=shuffle-tfrecords`. _Validation Shuffling_. `python3 scripts/shuf",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:449,safety,test,testing,449,"No output vcf obtained from custom model; **ISSUE**. First of all, I found DeepVariant to be a very good and innovative tool. I'm considering including it in my exome analysis pipeline. I followed the tutorial (DeepVariant worked correctly with the Complete Genomics model), and I created my own model using Genome in a Bottle samples. To do this, I sequenced the same reference sample three times to use each BAM file for training, validation, and testing. I didn't encounter any errors during the model creation process, but when I tried to test it, the process got stuck at the call_variants step. **Setup**. - Operating system: Ubuntu 22.04.4 LTS. - DeepVariant version:1.6.1. - Installation method:docker. - Type of data: MGI DNBSEQ 400, exome sequencing. **Steps to reproduce:**. - Command:. _Create examples for trainning set_. `sudo docker run -v ""${PWD}/input"":""/input"" -v ""${PWD}/REF"":""/ref"" -v ""${PWD}""/output:""/output"" google/deepvariant:""1.6.1"" make_examples --mode training --ref ""/ref/GRCh38.p14.genome.fa"" --reads ""/input/26_r_groups.bam"" --examples ""/output/training_set.gz"" --truth_variants ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.vcf.gz"" --confident_regions ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.bed""`. _Create examples for validation set_. `sudo docker run -v ""${PWD}/input"":""/input"" -v ""${PWD}/REF"":""/ref"" -v ""${PWD}""/output:""/output"" google/deepvariant:""1.6.1"" make_examples --mode training --ref ""/ref/GRCh38.p14.genome.fa"" --reads ""/input/27_r_groups.bam"" --examples ""/output/validation_set.gz"" --truth_variants ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.vcf.gz"" --confident_regions ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.bed"" `. _Trainning Shuffling_. `python3 scripts/shuffle_tfrecords_beam.py --input_pattern_list=output/training_set.gz --output_pattern_prefix=""output/training_shuffled"" --output_dataset_name=""26"" --output_dataset_config_pbtxt=""output/training.pbtxt"" --job_name=shuffle-tfrecords`. _Validation Shuffling_. `python3 scripts/shuf",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:481,safety,error,errors,481,"No output vcf obtained from custom model; **ISSUE**. First of all, I found DeepVariant to be a very good and innovative tool. I'm considering including it in my exome analysis pipeline. I followed the tutorial (DeepVariant worked correctly with the Complete Genomics model), and I created my own model using Genome in a Bottle samples. To do this, I sequenced the same reference sample three times to use each BAM file for training, validation, and testing. I didn't encounter any errors during the model creation process, but when I tried to test it, the process got stuck at the call_variants step. **Setup**. - Operating system: Ubuntu 22.04.4 LTS. - DeepVariant version:1.6.1. - Installation method:docker. - Type of data: MGI DNBSEQ 400, exome sequencing. **Steps to reproduce:**. - Command:. _Create examples for trainning set_. `sudo docker run -v ""${PWD}/input"":""/input"" -v ""${PWD}/REF"":""/ref"" -v ""${PWD}""/output:""/output"" google/deepvariant:""1.6.1"" make_examples --mode training --ref ""/ref/GRCh38.p14.genome.fa"" --reads ""/input/26_r_groups.bam"" --examples ""/output/training_set.gz"" --truth_variants ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.vcf.gz"" --confident_regions ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.bed""`. _Create examples for validation set_. `sudo docker run -v ""${PWD}/input"":""/input"" -v ""${PWD}/REF"":""/ref"" -v ""${PWD}""/output:""/output"" google/deepvariant:""1.6.1"" make_examples --mode training --ref ""/ref/GRCh38.p14.genome.fa"" --reads ""/input/27_r_groups.bam"" --examples ""/output/validation_set.gz"" --truth_variants ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.vcf.gz"" --confident_regions ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.bed"" `. _Trainning Shuffling_. `python3 scripts/shuffle_tfrecords_beam.py --input_pattern_list=output/training_set.gz --output_pattern_prefix=""output/training_shuffled"" --output_dataset_name=""26"" --output_dataset_config_pbtxt=""output/training.pbtxt"" --job_name=shuffle-tfrecords`. _Validation Shuffling_. `python3 scripts/shuf",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:543,safety,test,test,543,"No output vcf obtained from custom model; **ISSUE**. First of all, I found DeepVariant to be a very good and innovative tool. I'm considering including it in my exome analysis pipeline. I followed the tutorial (DeepVariant worked correctly with the Complete Genomics model), and I created my own model using Genome in a Bottle samples. To do this, I sequenced the same reference sample three times to use each BAM file for training, validation, and testing. I didn't encounter any errors during the model creation process, but when I tried to test it, the process got stuck at the call_variants step. **Setup**. - Operating system: Ubuntu 22.04.4 LTS. - DeepVariant version:1.6.1. - Installation method:docker. - Type of data: MGI DNBSEQ 400, exome sequencing. **Steps to reproduce:**. - Command:. _Create examples for trainning set_. `sudo docker run -v ""${PWD}/input"":""/input"" -v ""${PWD}/REF"":""/ref"" -v ""${PWD}""/output:""/output"" google/deepvariant:""1.6.1"" make_examples --mode training --ref ""/ref/GRCh38.p14.genome.fa"" --reads ""/input/26_r_groups.bam"" --examples ""/output/training_set.gz"" --truth_variants ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.vcf.gz"" --confident_regions ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.bed""`. _Create examples for validation set_. `sudo docker run -v ""${PWD}/input"":""/input"" -v ""${PWD}/REF"":""/ref"" -v ""${PWD}""/output:""/output"" google/deepvariant:""1.6.1"" make_examples --mode training --ref ""/ref/GRCh38.p14.genome.fa"" --reads ""/input/27_r_groups.bam"" --examples ""/output/validation_set.gz"" --truth_variants ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.vcf.gz"" --confident_regions ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.bed"" `. _Trainning Shuffling_. `python3 scripts/shuffle_tfrecords_beam.py --input_pattern_list=output/training_set.gz --output_pattern_prefix=""output/training_shuffled"" --output_dataset_name=""26"" --output_dataset_config_pbtxt=""output/training.pbtxt"" --job_name=shuffle-tfrecords`. _Validation Shuffling_. `python3 scripts/shuf",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:863,safety,input,input,863,"No output vcf obtained from custom model; **ISSUE**. First of all, I found DeepVariant to be a very good and innovative tool. I'm considering including it in my exome analysis pipeline. I followed the tutorial (DeepVariant worked correctly with the Complete Genomics model), and I created my own model using Genome in a Bottle samples. To do this, I sequenced the same reference sample three times to use each BAM file for training, validation, and testing. I didn't encounter any errors during the model creation process, but when I tried to test it, the process got stuck at the call_variants step. **Setup**. - Operating system: Ubuntu 22.04.4 LTS. - DeepVariant version:1.6.1. - Installation method:docker. - Type of data: MGI DNBSEQ 400, exome sequencing. **Steps to reproduce:**. - Command:. _Create examples for trainning set_. `sudo docker run -v ""${PWD}/input"":""/input"" -v ""${PWD}/REF"":""/ref"" -v ""${PWD}""/output:""/output"" google/deepvariant:""1.6.1"" make_examples --mode training --ref ""/ref/GRCh38.p14.genome.fa"" --reads ""/input/26_r_groups.bam"" --examples ""/output/training_set.gz"" --truth_variants ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.vcf.gz"" --confident_regions ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.bed""`. _Create examples for validation set_. `sudo docker run -v ""${PWD}/input"":""/input"" -v ""${PWD}/REF"":""/ref"" -v ""${PWD}""/output:""/output"" google/deepvariant:""1.6.1"" make_examples --mode training --ref ""/ref/GRCh38.p14.genome.fa"" --reads ""/input/27_r_groups.bam"" --examples ""/output/validation_set.gz"" --truth_variants ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.vcf.gz"" --confident_regions ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.bed"" `. _Trainning Shuffling_. `python3 scripts/shuffle_tfrecords_beam.py --input_pattern_list=output/training_set.gz --output_pattern_prefix=""output/training_shuffled"" --output_dataset_name=""26"" --output_dataset_config_pbtxt=""output/training.pbtxt"" --job_name=shuffle-tfrecords`. _Validation Shuffling_. `python3 scripts/shuf",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:872,safety,input,input,872,"No output vcf obtained from custom model; **ISSUE**. First of all, I found DeepVariant to be a very good and innovative tool. I'm considering including it in my exome analysis pipeline. I followed the tutorial (DeepVariant worked correctly with the Complete Genomics model), and I created my own model using Genome in a Bottle samples. To do this, I sequenced the same reference sample three times to use each BAM file for training, validation, and testing. I didn't encounter any errors during the model creation process, but when I tried to test it, the process got stuck at the call_variants step. **Setup**. - Operating system: Ubuntu 22.04.4 LTS. - DeepVariant version:1.6.1. - Installation method:docker. - Type of data: MGI DNBSEQ 400, exome sequencing. **Steps to reproduce:**. - Command:. _Create examples for trainning set_. `sudo docker run -v ""${PWD}/input"":""/input"" -v ""${PWD}/REF"":""/ref"" -v ""${PWD}""/output:""/output"" google/deepvariant:""1.6.1"" make_examples --mode training --ref ""/ref/GRCh38.p14.genome.fa"" --reads ""/input/26_r_groups.bam"" --examples ""/output/training_set.gz"" --truth_variants ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.vcf.gz"" --confident_regions ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.bed""`. _Create examples for validation set_. `sudo docker run -v ""${PWD}/input"":""/input"" -v ""${PWD}/REF"":""/ref"" -v ""${PWD}""/output:""/output"" google/deepvariant:""1.6.1"" make_examples --mode training --ref ""/ref/GRCh38.p14.genome.fa"" --reads ""/input/27_r_groups.bam"" --examples ""/output/validation_set.gz"" --truth_variants ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.vcf.gz"" --confident_regions ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.bed"" `. _Trainning Shuffling_. `python3 scripts/shuffle_tfrecords_beam.py --input_pattern_list=output/training_set.gz --output_pattern_prefix=""output/training_shuffled"" --output_dataset_name=""26"" --output_dataset_config_pbtxt=""output/training.pbtxt"" --job_name=shuffle-tfrecords`. _Validation Shuffling_. `python3 scripts/shuf",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:1032,safety,input,input,1032,"model; **ISSUE**. First of all, I found DeepVariant to be a very good and innovative tool. I'm considering including it in my exome analysis pipeline. I followed the tutorial (DeepVariant worked correctly with the Complete Genomics model), and I created my own model using Genome in a Bottle samples. To do this, I sequenced the same reference sample three times to use each BAM file for training, validation, and testing. I didn't encounter any errors during the model creation process, but when I tried to test it, the process got stuck at the call_variants step. **Setup**. - Operating system: Ubuntu 22.04.4 LTS. - DeepVariant version:1.6.1. - Installation method:docker. - Type of data: MGI DNBSEQ 400, exome sequencing. **Steps to reproduce:**. - Command:. _Create examples for trainning set_. `sudo docker run -v ""${PWD}/input"":""/input"" -v ""${PWD}/REF"":""/ref"" -v ""${PWD}""/output:""/output"" google/deepvariant:""1.6.1"" make_examples --mode training --ref ""/ref/GRCh38.p14.genome.fa"" --reads ""/input/26_r_groups.bam"" --examples ""/output/training_set.gz"" --truth_variants ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.vcf.gz"" --confident_regions ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.bed""`. _Create examples for validation set_. `sudo docker run -v ""${PWD}/input"":""/input"" -v ""${PWD}/REF"":""/ref"" -v ""${PWD}""/output:""/output"" google/deepvariant:""1.6.1"" make_examples --mode training --ref ""/ref/GRCh38.p14.genome.fa"" --reads ""/input/27_r_groups.bam"" --examples ""/output/validation_set.gz"" --truth_variants ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.vcf.gz"" --confident_regions ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.bed"" `. _Trainning Shuffling_. `python3 scripts/shuffle_tfrecords_beam.py --input_pattern_list=output/training_set.gz --output_pattern_prefix=""output/training_shuffled"" --output_dataset_name=""26"" --output_dataset_config_pbtxt=""output/training.pbtxt"" --job_name=shuffle-tfrecords`. _Validation Shuffling_. `python3 scripts/shuffle_tfrecords_beam.py --input_patte",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:1259,safety,valid,validation,1259,"cs model), and I created my own model using Genome in a Bottle samples. To do this, I sequenced the same reference sample three times to use each BAM file for training, validation, and testing. I didn't encounter any errors during the model creation process, but when I tried to test it, the process got stuck at the call_variants step. **Setup**. - Operating system: Ubuntu 22.04.4 LTS. - DeepVariant version:1.6.1. - Installation method:docker. - Type of data: MGI DNBSEQ 400, exome sequencing. **Steps to reproduce:**. - Command:. _Create examples for trainning set_. `sudo docker run -v ""${PWD}/input"":""/input"" -v ""${PWD}/REF"":""/ref"" -v ""${PWD}""/output:""/output"" google/deepvariant:""1.6.1"" make_examples --mode training --ref ""/ref/GRCh38.p14.genome.fa"" --reads ""/input/26_r_groups.bam"" --examples ""/output/training_set.gz"" --truth_variants ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.vcf.gz"" --confident_regions ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.bed""`. _Create examples for validation set_. `sudo docker run -v ""${PWD}/input"":""/input"" -v ""${PWD}/REF"":""/ref"" -v ""${PWD}""/output:""/output"" google/deepvariant:""1.6.1"" make_examples --mode training --ref ""/ref/GRCh38.p14.genome.fa"" --reads ""/input/27_r_groups.bam"" --examples ""/output/validation_set.gz"" --truth_variants ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.vcf.gz"" --confident_regions ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.bed"" `. _Trainning Shuffling_. `python3 scripts/shuffle_tfrecords_beam.py --input_pattern_list=output/training_set.gz --output_pattern_prefix=""output/training_shuffled"" --output_dataset_name=""26"" --output_dataset_config_pbtxt=""output/training.pbtxt"" --job_name=shuffle-tfrecords`. _Validation Shuffling_. `python3 scripts/shuffle_tfrecords_beam.py --input_pattern_list=output/validation_set.gz --output_pattern_prefix=""output/validation_shuffled"" --output_dataset_name=""27"" --output_dataset_config_pbtxt=""output/validation.pbtxt"" --job_name=shuffle-tfrecords `. _Model trainning_. `sudo doc",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:1304,safety,input,input,1304," Genome in a Bottle samples. To do this, I sequenced the same reference sample three times to use each BAM file for training, validation, and testing. I didn't encounter any errors during the model creation process, but when I tried to test it, the process got stuck at the call_variants step. **Setup**. - Operating system: Ubuntu 22.04.4 LTS. - DeepVariant version:1.6.1. - Installation method:docker. - Type of data: MGI DNBSEQ 400, exome sequencing. **Steps to reproduce:**. - Command:. _Create examples for trainning set_. `sudo docker run -v ""${PWD}/input"":""/input"" -v ""${PWD}/REF"":""/ref"" -v ""${PWD}""/output:""/output"" google/deepvariant:""1.6.1"" make_examples --mode training --ref ""/ref/GRCh38.p14.genome.fa"" --reads ""/input/26_r_groups.bam"" --examples ""/output/training_set.gz"" --truth_variants ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.vcf.gz"" --confident_regions ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.bed""`. _Create examples for validation set_. `sudo docker run -v ""${PWD}/input"":""/input"" -v ""${PWD}/REF"":""/ref"" -v ""${PWD}""/output:""/output"" google/deepvariant:""1.6.1"" make_examples --mode training --ref ""/ref/GRCh38.p14.genome.fa"" --reads ""/input/27_r_groups.bam"" --examples ""/output/validation_set.gz"" --truth_variants ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.vcf.gz"" --confident_regions ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.bed"" `. _Trainning Shuffling_. `python3 scripts/shuffle_tfrecords_beam.py --input_pattern_list=output/training_set.gz --output_pattern_prefix=""output/training_shuffled"" --output_dataset_name=""26"" --output_dataset_config_pbtxt=""output/training.pbtxt"" --job_name=shuffle-tfrecords`. _Validation Shuffling_. `python3 scripts/shuffle_tfrecords_beam.py --input_pattern_list=output/validation_set.gz --output_pattern_prefix=""output/validation_shuffled"" --output_dataset_name=""27"" --output_dataset_config_pbtxt=""output/validation.pbtxt"" --job_name=shuffle-tfrecords `. _Model trainning_. `sudo docker run -v ""${PWD}/input"":""/input"" -v ""${PW",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:1313,safety,input,input,1313,"n a Bottle samples. To do this, I sequenced the same reference sample three times to use each BAM file for training, validation, and testing. I didn't encounter any errors during the model creation process, but when I tried to test it, the process got stuck at the call_variants step. **Setup**. - Operating system: Ubuntu 22.04.4 LTS. - DeepVariant version:1.6.1. - Installation method:docker. - Type of data: MGI DNBSEQ 400, exome sequencing. **Steps to reproduce:**. - Command:. _Create examples for trainning set_. `sudo docker run -v ""${PWD}/input"":""/input"" -v ""${PWD}/REF"":""/ref"" -v ""${PWD}""/output:""/output"" google/deepvariant:""1.6.1"" make_examples --mode training --ref ""/ref/GRCh38.p14.genome.fa"" --reads ""/input/26_r_groups.bam"" --examples ""/output/training_set.gz"" --truth_variants ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.vcf.gz"" --confident_regions ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.bed""`. _Create examples for validation set_. `sudo docker run -v ""${PWD}/input"":""/input"" -v ""${PWD}/REF"":""/ref"" -v ""${PWD}""/output:""/output"" google/deepvariant:""1.6.1"" make_examples --mode training --ref ""/ref/GRCh38.p14.genome.fa"" --reads ""/input/27_r_groups.bam"" --examples ""/output/validation_set.gz"" --truth_variants ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.vcf.gz"" --confident_regions ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.bed"" `. _Trainning Shuffling_. `python3 scripts/shuffle_tfrecords_beam.py --input_pattern_list=output/training_set.gz --output_pattern_prefix=""output/training_shuffled"" --output_dataset_name=""26"" --output_dataset_config_pbtxt=""output/training.pbtxt"" --job_name=shuffle-tfrecords`. _Validation Shuffling_. `python3 scripts/shuffle_tfrecords_beam.py --input_pattern_list=output/validation_set.gz --output_pattern_prefix=""output/validation_shuffled"" --output_dataset_name=""27"" --output_dataset_config_pbtxt=""output/validation.pbtxt"" --job_name=shuffle-tfrecords `. _Model trainning_. `sudo docker run -v ""${PWD}/input"":""/input"" -v ""${PWD}/REF"":""",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:1473,safety,input,input,1473," any errors during the model creation process, but when I tried to test it, the process got stuck at the call_variants step. **Setup**. - Operating system: Ubuntu 22.04.4 LTS. - DeepVariant version:1.6.1. - Installation method:docker. - Type of data: MGI DNBSEQ 400, exome sequencing. **Steps to reproduce:**. - Command:. _Create examples for trainning set_. `sudo docker run -v ""${PWD}/input"":""/input"" -v ""${PWD}/REF"":""/ref"" -v ""${PWD}""/output:""/output"" google/deepvariant:""1.6.1"" make_examples --mode training --ref ""/ref/GRCh38.p14.genome.fa"" --reads ""/input/26_r_groups.bam"" --examples ""/output/training_set.gz"" --truth_variants ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.vcf.gz"" --confident_regions ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.bed""`. _Create examples for validation set_. `sudo docker run -v ""${PWD}/input"":""/input"" -v ""${PWD}/REF"":""/ref"" -v ""${PWD}""/output:""/output"" google/deepvariant:""1.6.1"" make_examples --mode training --ref ""/ref/GRCh38.p14.genome.fa"" --reads ""/input/27_r_groups.bam"" --examples ""/output/validation_set.gz"" --truth_variants ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.vcf.gz"" --confident_regions ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.bed"" `. _Trainning Shuffling_. `python3 scripts/shuffle_tfrecords_beam.py --input_pattern_list=output/training_set.gz --output_pattern_prefix=""output/training_shuffled"" --output_dataset_name=""26"" --output_dataset_config_pbtxt=""output/training.pbtxt"" --job_name=shuffle-tfrecords`. _Validation Shuffling_. `python3 scripts/shuffle_tfrecords_beam.py --input_pattern_list=output/validation_set.gz --output_pattern_prefix=""output/validation_shuffled"" --output_dataset_name=""27"" --output_dataset_config_pbtxt=""output/validation.pbtxt"" --job_name=shuffle-tfrecords `. _Model trainning_. `sudo docker run -v ""${PWD}/input"":""/input"" -v ""${PWD}/REF"":""/ref"" -v ""${PWD}""/output:""/output"" google/deepvariant:""1.6.1"" train --config=/input/dv_config.py:base --config.train_dataset_pbtxt=""/output/training.pbtxt"" --co",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:2186,safety,valid,validation,2186,"G001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.bed""`. _Create examples for validation set_. `sudo docker run -v ""${PWD}/input"":""/input"" -v ""${PWD}/REF"":""/ref"" -v ""${PWD}""/output:""/output"" google/deepvariant:""1.6.1"" make_examples --mode training --ref ""/ref/GRCh38.p14.genome.fa"" --reads ""/input/27_r_groups.bam"" --examples ""/output/validation_set.gz"" --truth_variants ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.vcf.gz"" --confident_regions ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.bed"" `. _Trainning Shuffling_. `python3 scripts/shuffle_tfrecords_beam.py --input_pattern_list=output/training_set.gz --output_pattern_prefix=""output/training_shuffled"" --output_dataset_name=""26"" --output_dataset_config_pbtxt=""output/training.pbtxt"" --job_name=shuffle-tfrecords`. _Validation Shuffling_. `python3 scripts/shuffle_tfrecords_beam.py --input_pattern_list=output/validation_set.gz --output_pattern_prefix=""output/validation_shuffled"" --output_dataset_name=""27"" --output_dataset_config_pbtxt=""output/validation.pbtxt"" --job_name=shuffle-tfrecords `. _Model trainning_. `sudo docker run -v ""${PWD}/input"":""/input"" -v ""${PWD}/REF"":""/ref"" -v ""${PWD}""/output:""/output"" google/deepvariant:""1.6.1"" train --config=/input/dv_config.py:base --config.train_dataset_pbtxt=""/output/training.pbtxt"" --config.tune_dataset_pbtxt=""/output/validation.pbtxt"" --config.num_epochs=10 --config.learning_rate=0.0001 --config.num_validation_examples=0 --strategy=mirrored --experiment_dir=""/output/"" --config.batch_size=512`. _Model test_. `sudo docker run -v ""${PWD}/input"":""/input"" -v ""${PWD}/REF"":""/ref"" -v ""${PWD}""/output:""/output"" google/deepvariant:""1.6.1"" /opt/deepvariant/bin/run_deepvariant --model_type WES --customized_model ""/output/checkpoints/ckpt-679"" --ref ""/ref/GRCh38.p14.genome.fa"" --reads ""/input/33_r_groups.bam"" --output_vcf ""/output/33.vcf.gz"" --output_gvcf ""/output/33.g.vcf.gz"" -intermediate_results_dir ""/output/intermediate_results_dir"" --num_shards 10`. - Error trace: . ` - I0822 07:51:54.272576 127",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:2283,safety,input,input,2283,"er run -v ""${PWD}/input"":""/input"" -v ""${PWD}/REF"":""/ref"" -v ""${PWD}""/output:""/output"" google/deepvariant:""1.6.1"" make_examples --mode training --ref ""/ref/GRCh38.p14.genome.fa"" --reads ""/input/27_r_groups.bam"" --examples ""/output/validation_set.gz"" --truth_variants ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.vcf.gz"" --confident_regions ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.bed"" `. _Trainning Shuffling_. `python3 scripts/shuffle_tfrecords_beam.py --input_pattern_list=output/training_set.gz --output_pattern_prefix=""output/training_shuffled"" --output_dataset_name=""26"" --output_dataset_config_pbtxt=""output/training.pbtxt"" --job_name=shuffle-tfrecords`. _Validation Shuffling_. `python3 scripts/shuffle_tfrecords_beam.py --input_pattern_list=output/validation_set.gz --output_pattern_prefix=""output/validation_shuffled"" --output_dataset_name=""27"" --output_dataset_config_pbtxt=""output/validation.pbtxt"" --job_name=shuffle-tfrecords `. _Model trainning_. `sudo docker run -v ""${PWD}/input"":""/input"" -v ""${PWD}/REF"":""/ref"" -v ""${PWD}""/output:""/output"" google/deepvariant:""1.6.1"" train --config=/input/dv_config.py:base --config.train_dataset_pbtxt=""/output/training.pbtxt"" --config.tune_dataset_pbtxt=""/output/validation.pbtxt"" --config.num_epochs=10 --config.learning_rate=0.0001 --config.num_validation_examples=0 --strategy=mirrored --experiment_dir=""/output/"" --config.batch_size=512`. _Model test_. `sudo docker run -v ""${PWD}/input"":""/input"" -v ""${PWD}/REF"":""/ref"" -v ""${PWD}""/output:""/output"" google/deepvariant:""1.6.1"" /opt/deepvariant/bin/run_deepvariant --model_type WES --customized_model ""/output/checkpoints/ckpt-679"" --ref ""/ref/GRCh38.p14.genome.fa"" --reads ""/input/33_r_groups.bam"" --output_vcf ""/output/33.vcf.gz"" --output_gvcf ""/output/33.g.vcf.gz"" -intermediate_results_dir ""/output/intermediate_results_dir"" --num_shards 10`. - Error trace: . ` - I0822 07:51:54.272576 127450974123840 make_examples_core.py:301] Task 17/20: Writing example info to /output/intermediat",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:2292,safety,input,input,2292," ""${PWD}/input"":""/input"" -v ""${PWD}/REF"":""/ref"" -v ""${PWD}""/output:""/output"" google/deepvariant:""1.6.1"" make_examples --mode training --ref ""/ref/GRCh38.p14.genome.fa"" --reads ""/input/27_r_groups.bam"" --examples ""/output/validation_set.gz"" --truth_variants ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.vcf.gz"" --confident_regions ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.bed"" `. _Trainning Shuffling_. `python3 scripts/shuffle_tfrecords_beam.py --input_pattern_list=output/training_set.gz --output_pattern_prefix=""output/training_shuffled"" --output_dataset_name=""26"" --output_dataset_config_pbtxt=""output/training.pbtxt"" --job_name=shuffle-tfrecords`. _Validation Shuffling_. `python3 scripts/shuffle_tfrecords_beam.py --input_pattern_list=output/validation_set.gz --output_pattern_prefix=""output/validation_shuffled"" --output_dataset_name=""27"" --output_dataset_config_pbtxt=""output/validation.pbtxt"" --job_name=shuffle-tfrecords `. _Model trainning_. `sudo docker run -v ""${PWD}/input"":""/input"" -v ""${PWD}/REF"":""/ref"" -v ""${PWD}""/output:""/output"" google/deepvariant:""1.6.1"" train --config=/input/dv_config.py:base --config.train_dataset_pbtxt=""/output/training.pbtxt"" --config.tune_dataset_pbtxt=""/output/validation.pbtxt"" --config.num_epochs=10 --config.learning_rate=0.0001 --config.num_validation_examples=0 --strategy=mirrored --experiment_dir=""/output/"" --config.batch_size=512`. _Model test_. `sudo docker run -v ""${PWD}/input"":""/input"" -v ""${PWD}/REF"":""/ref"" -v ""${PWD}""/output:""/output"" google/deepvariant:""1.6.1"" /opt/deepvariant/bin/run_deepvariant --model_type WES --customized_model ""/output/checkpoints/ckpt-679"" --ref ""/ref/GRCh38.p14.genome.fa"" --reads ""/input/33_r_groups.bam"" --output_vcf ""/output/33.vcf.gz"" --output_gvcf ""/output/33.g.vcf.gz"" -intermediate_results_dir ""/output/intermediate_results_dir"" --num_shards 10`. - Error trace: . ` - I0822 07:51:54.272576 127450974123840 make_examples_core.py:301] Task 17/20: Writing example info to /output/intermediate_results",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:2394,safety,input,input,2394,""" make_examples --mode training --ref ""/ref/GRCh38.p14.genome.fa"" --reads ""/input/27_r_groups.bam"" --examples ""/output/validation_set.gz"" --truth_variants ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.vcf.gz"" --confident_regions ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.bed"" `. _Trainning Shuffling_. `python3 scripts/shuffle_tfrecords_beam.py --input_pattern_list=output/training_set.gz --output_pattern_prefix=""output/training_shuffled"" --output_dataset_name=""26"" --output_dataset_config_pbtxt=""output/training.pbtxt"" --job_name=shuffle-tfrecords`. _Validation Shuffling_. `python3 scripts/shuffle_tfrecords_beam.py --input_pattern_list=output/validation_set.gz --output_pattern_prefix=""output/validation_shuffled"" --output_dataset_name=""27"" --output_dataset_config_pbtxt=""output/validation.pbtxt"" --job_name=shuffle-tfrecords `. _Model trainning_. `sudo docker run -v ""${PWD}/input"":""/input"" -v ""${PWD}/REF"":""/ref"" -v ""${PWD}""/output:""/output"" google/deepvariant:""1.6.1"" train --config=/input/dv_config.py:base --config.train_dataset_pbtxt=""/output/training.pbtxt"" --config.tune_dataset_pbtxt=""/output/validation.pbtxt"" --config.num_epochs=10 --config.learning_rate=0.0001 --config.num_validation_examples=0 --strategy=mirrored --experiment_dir=""/output/"" --config.batch_size=512`. _Model test_. `sudo docker run -v ""${PWD}/input"":""/input"" -v ""${PWD}/REF"":""/ref"" -v ""${PWD}""/output:""/output"" google/deepvariant:""1.6.1"" /opt/deepvariant/bin/run_deepvariant --model_type WES --customized_model ""/output/checkpoints/ckpt-679"" --ref ""/ref/GRCh38.p14.genome.fa"" --reads ""/input/33_r_groups.bam"" --output_vcf ""/output/33.vcf.gz"" --output_gvcf ""/output/33.g.vcf.gz"" -intermediate_results_dir ""/output/intermediate_results_dir"" --num_shards 10`. - Error trace: . ` - I0822 07:51:54.272576 127450974123840 make_examples_core.py:301] Task 17/20: Writing example info to /output/intermediate_results_dir/make_examples.tfrecord-00017-of-00020.gz.example_info.json. I0822 07:51:54.272647 127450974123840",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:2509,safety,valid,validation,2509,"t/validation_set.gz"" --truth_variants ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.vcf.gz"" --confident_regions ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.bed"" `. _Trainning Shuffling_. `python3 scripts/shuffle_tfrecords_beam.py --input_pattern_list=output/training_set.gz --output_pattern_prefix=""output/training_shuffled"" --output_dataset_name=""26"" --output_dataset_config_pbtxt=""output/training.pbtxt"" --job_name=shuffle-tfrecords`. _Validation Shuffling_. `python3 scripts/shuffle_tfrecords_beam.py --input_pattern_list=output/validation_set.gz --output_pattern_prefix=""output/validation_shuffled"" --output_dataset_name=""27"" --output_dataset_config_pbtxt=""output/validation.pbtxt"" --job_name=shuffle-tfrecords `. _Model trainning_. `sudo docker run -v ""${PWD}/input"":""/input"" -v ""${PWD}/REF"":""/ref"" -v ""${PWD}""/output:""/output"" google/deepvariant:""1.6.1"" train --config=/input/dv_config.py:base --config.train_dataset_pbtxt=""/output/training.pbtxt"" --config.tune_dataset_pbtxt=""/output/validation.pbtxt"" --config.num_epochs=10 --config.learning_rate=0.0001 --config.num_validation_examples=0 --strategy=mirrored --experiment_dir=""/output/"" --config.batch_size=512`. _Model test_. `sudo docker run -v ""${PWD}/input"":""/input"" -v ""${PWD}/REF"":""/ref"" -v ""${PWD}""/output:""/output"" google/deepvariant:""1.6.1"" /opt/deepvariant/bin/run_deepvariant --model_type WES --customized_model ""/output/checkpoints/ckpt-679"" --ref ""/ref/GRCh38.p14.genome.fa"" --reads ""/input/33_r_groups.bam"" --output_vcf ""/output/33.vcf.gz"" --output_gvcf ""/output/33.g.vcf.gz"" -intermediate_results_dir ""/output/intermediate_results_dir"" --num_shards 10`. - Error trace: . ` - I0822 07:51:54.272576 127450974123840 make_examples_core.py:301] Task 17/20: Writing example info to /output/intermediate_results_dir/make_examples.tfrecord-00017-of-00020.gz.example_info.json. I0822 07:51:54.272647 127450974123840 make_examples_core.py:2958] example_shape = [100, 221, 7]. I0822 07:51:54.272740 127450974123840 make_examples_core.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:2731,safety,input,input,2731,"cords_beam.py --input_pattern_list=output/training_set.gz --output_pattern_prefix=""output/training_shuffled"" --output_dataset_name=""26"" --output_dataset_config_pbtxt=""output/training.pbtxt"" --job_name=shuffle-tfrecords`. _Validation Shuffling_. `python3 scripts/shuffle_tfrecords_beam.py --input_pattern_list=output/validation_set.gz --output_pattern_prefix=""output/validation_shuffled"" --output_dataset_name=""27"" --output_dataset_config_pbtxt=""output/validation.pbtxt"" --job_name=shuffle-tfrecords `. _Model trainning_. `sudo docker run -v ""${PWD}/input"":""/input"" -v ""${PWD}/REF"":""/ref"" -v ""${PWD}""/output:""/output"" google/deepvariant:""1.6.1"" train --config=/input/dv_config.py:base --config.train_dataset_pbtxt=""/output/training.pbtxt"" --config.tune_dataset_pbtxt=""/output/validation.pbtxt"" --config.num_epochs=10 --config.learning_rate=0.0001 --config.num_validation_examples=0 --strategy=mirrored --experiment_dir=""/output/"" --config.batch_size=512`. _Model test_. `sudo docker run -v ""${PWD}/input"":""/input"" -v ""${PWD}/REF"":""/ref"" -v ""${PWD}""/output:""/output"" google/deepvariant:""1.6.1"" /opt/deepvariant/bin/run_deepvariant --model_type WES --customized_model ""/output/checkpoints/ckpt-679"" --ref ""/ref/GRCh38.p14.genome.fa"" --reads ""/input/33_r_groups.bam"" --output_vcf ""/output/33.vcf.gz"" --output_gvcf ""/output/33.g.vcf.gz"" -intermediate_results_dir ""/output/intermediate_results_dir"" --num_shards 10`. - Error trace: . ` - I0822 07:51:54.272576 127450974123840 make_examples_core.py:301] Task 17/20: Writing example info to /output/intermediate_results_dir/make_examples.tfrecord-00017-of-00020.gz.example_info.json. I0822 07:51:54.272647 127450974123840 make_examples_core.py:2958] example_shape = [100, 221, 7]. I0822 07:51:54.272740 127450974123840 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 19]. I0822 07:51:54.272911 127450974123840 make_examples_core.py:301] Task 17/20: Found 17451 candidate variants. I0822 07:51:54.272932 127450974123840 make_examples_core.py",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:2740,safety,input,input,2740,"m.py --input_pattern_list=output/training_set.gz --output_pattern_prefix=""output/training_shuffled"" --output_dataset_name=""26"" --output_dataset_config_pbtxt=""output/training.pbtxt"" --job_name=shuffle-tfrecords`. _Validation Shuffling_. `python3 scripts/shuffle_tfrecords_beam.py --input_pattern_list=output/validation_set.gz --output_pattern_prefix=""output/validation_shuffled"" --output_dataset_name=""27"" --output_dataset_config_pbtxt=""output/validation.pbtxt"" --job_name=shuffle-tfrecords `. _Model trainning_. `sudo docker run -v ""${PWD}/input"":""/input"" -v ""${PWD}/REF"":""/ref"" -v ""${PWD}""/output:""/output"" google/deepvariant:""1.6.1"" train --config=/input/dv_config.py:base --config.train_dataset_pbtxt=""/output/training.pbtxt"" --config.tune_dataset_pbtxt=""/output/validation.pbtxt"" --config.num_epochs=10 --config.learning_rate=0.0001 --config.num_validation_examples=0 --strategy=mirrored --experiment_dir=""/output/"" --config.batch_size=512`. _Model test_. `sudo docker run -v ""${PWD}/input"":""/input"" -v ""${PWD}/REF"":""/ref"" -v ""${PWD}""/output:""/output"" google/deepvariant:""1.6.1"" /opt/deepvariant/bin/run_deepvariant --model_type WES --customized_model ""/output/checkpoints/ckpt-679"" --ref ""/ref/GRCh38.p14.genome.fa"" --reads ""/input/33_r_groups.bam"" --output_vcf ""/output/33.vcf.gz"" --output_gvcf ""/output/33.g.vcf.gz"" -intermediate_results_dir ""/output/intermediate_results_dir"" --num_shards 10`. - Error trace: . ` - I0822 07:51:54.272576 127450974123840 make_examples_core.py:301] Task 17/20: Writing example info to /output/intermediate_results_dir/make_examples.tfrecord-00017-of-00020.gz.example_info.json. I0822 07:51:54.272647 127450974123840 make_examples_core.py:2958] example_shape = [100, 221, 7]. I0822 07:51:54.272740 127450974123840 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 19]. I0822 07:51:54.272911 127450974123840 make_examples_core.py:301] Task 17/20: Found 17451 candidate variants. I0822 07:51:54.272932 127450974123840 make_examples_core.py:301] Tas",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:2974,safety,input,input,2974,". `python3 scripts/shuffle_tfrecords_beam.py --input_pattern_list=output/validation_set.gz --output_pattern_prefix=""output/validation_shuffled"" --output_dataset_name=""27"" --output_dataset_config_pbtxt=""output/validation.pbtxt"" --job_name=shuffle-tfrecords `. _Model trainning_. `sudo docker run -v ""${PWD}/input"":""/input"" -v ""${PWD}/REF"":""/ref"" -v ""${PWD}""/output:""/output"" google/deepvariant:""1.6.1"" train --config=/input/dv_config.py:base --config.train_dataset_pbtxt=""/output/training.pbtxt"" --config.tune_dataset_pbtxt=""/output/validation.pbtxt"" --config.num_epochs=10 --config.learning_rate=0.0001 --config.num_validation_examples=0 --strategy=mirrored --experiment_dir=""/output/"" --config.batch_size=512`. _Model test_. `sudo docker run -v ""${PWD}/input"":""/input"" -v ""${PWD}/REF"":""/ref"" -v ""${PWD}""/output:""/output"" google/deepvariant:""1.6.1"" /opt/deepvariant/bin/run_deepvariant --model_type WES --customized_model ""/output/checkpoints/ckpt-679"" --ref ""/ref/GRCh38.p14.genome.fa"" --reads ""/input/33_r_groups.bam"" --output_vcf ""/output/33.vcf.gz"" --output_gvcf ""/output/33.g.vcf.gz"" -intermediate_results_dir ""/output/intermediate_results_dir"" --num_shards 10`. - Error trace: . ` - I0822 07:51:54.272576 127450974123840 make_examples_core.py:301] Task 17/20: Writing example info to /output/intermediate_results_dir/make_examples.tfrecord-00017-of-00020.gz.example_info.json. I0822 07:51:54.272647 127450974123840 make_examples_core.py:2958] example_shape = [100, 221, 7]. I0822 07:51:54.272740 127450974123840 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 19]. I0822 07:51:54.272911 127450974123840 make_examples_core.py:301] Task 17/20: Found 17451 candidate variants. I0822 07:51:54.272932 127450974123840 make_examples_core.py:301] Task 17/20: Created 18817 examples. I0822 07:52:09.283522 133276175411008 make_examples_core.py:301] Task 8/20: Writing example info to /output/intermediate_results_dir/make_examples.tfrecord-00008-of-00020.gz.example_info.json. I0822 07",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:3147,safety,Error,Error,3147,"output_dataset_config_pbtxt=""output/validation.pbtxt"" --job_name=shuffle-tfrecords `. _Model trainning_. `sudo docker run -v ""${PWD}/input"":""/input"" -v ""${PWD}/REF"":""/ref"" -v ""${PWD}""/output:""/output"" google/deepvariant:""1.6.1"" train --config=/input/dv_config.py:base --config.train_dataset_pbtxt=""/output/training.pbtxt"" --config.tune_dataset_pbtxt=""/output/validation.pbtxt"" --config.num_epochs=10 --config.learning_rate=0.0001 --config.num_validation_examples=0 --strategy=mirrored --experiment_dir=""/output/"" --config.batch_size=512`. _Model test_. `sudo docker run -v ""${PWD}/input"":""/input"" -v ""${PWD}/REF"":""/ref"" -v ""${PWD}""/output:""/output"" google/deepvariant:""1.6.1"" /opt/deepvariant/bin/run_deepvariant --model_type WES --customized_model ""/output/checkpoints/ckpt-679"" --ref ""/ref/GRCh38.p14.genome.fa"" --reads ""/input/33_r_groups.bam"" --output_vcf ""/output/33.vcf.gz"" --output_gvcf ""/output/33.g.vcf.gz"" -intermediate_results_dir ""/output/intermediate_results_dir"" --num_shards 10`. - Error trace: . ` - I0822 07:51:54.272576 127450974123840 make_examples_core.py:301] Task 17/20: Writing example info to /output/intermediate_results_dir/make_examples.tfrecord-00017-of-00020.gz.example_info.json. I0822 07:51:54.272647 127450974123840 make_examples_core.py:2958] example_shape = [100, 221, 7]. I0822 07:51:54.272740 127450974123840 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 19]. I0822 07:51:54.272911 127450974123840 make_examples_core.py:301] Task 17/20: Found 17451 candidate variants. I0822 07:51:54.272932 127450974123840 make_examples_core.py:301] Task 17/20: Created 18817 examples. I0822 07:52:09.283522 133276175411008 make_examples_core.py:301] Task 8/20: Writing example info to /output/intermediate_results_dir/make_examples.tfrecord-00008-of-00020.gz.example_info.json. I0822 07:52:09.283617 133276175411008 make_examples_core.py:2958] example_shape = [100, 221, 7]. I0822 07:52:09.283712 133276175411008 make_examples_core.py:2959] example_channels =",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:5020,safety,depend,dependencies,5020,"py:2958] example_shape = [100, 221, 7]. I0822 07:52:09.283712 133276175411008 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 19]. I0822 07:52:09.283882 133276175411008 make_examples_core.py:301] Task 8/20: Found 17371 candidate variants. I0822 07:52:09.283904 133276175411008 make_examples_core.py:301] Task 8/20: Created 18820 examples. real 34m15.728s. user 624m43.553s. sys 2m24.932s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@20.gz"" --checkpoint ""/output/checkpoints/ckpt-679"". /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: . TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). . For more information see: https://github.com/tensorflow/addons/issues/2807 . warnings.warn(. I0822 07:52:10.812179 127086447671104 call_variants.py:563] Total 1 writing processes started. I0822 07:52:10.813103 127086447671104 dv_utils.py:370] From /output/intermediate_results_dir/make_examples.tfrecord-00000-of-00020.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0822 07:52:10.813141 127086447671104 call_variants.py:588] Shape of input examples: [100, 221, 7]. I0822 07:52:10.813338 127086447671104 call_variants.py:592] Use saved model: True. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 789, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:5476,safety,input,input,5476,"pvariant/bin/call_variants --outfile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@20.gz"" --checkpoint ""/output/checkpoints/ckpt-679"". /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: . TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). . For more information see: https://github.com/tensorflow/addons/issues/2807 . warnings.warn(. I0822 07:52:10.812179 127086447671104 call_variants.py:563] Total 1 writing processes started. I0822 07:52:10.813103 127086447671104 dv_utils.py:370] From /output/intermediate_results_dir/make_examples.tfrecord-00000-of-00020.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0822 07:52:10.813141 127086447671104 call_variants.py:588] Shape of input examples: [100, 221, 7]. I0822 07:52:10.813338 127086447671104 call_variants.py:592] Use saved model: True. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 789, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 768, in main. call_variants(. File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 598, in call_variants. model_example_shape = dv_utils.get_shape_and_channels_from_json(. File ""/tmp/Bazel.runf",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:5519,safety,input,input,5519,"ut/intermediate_results_dir/call_variants_output.tfrecord.gz"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@20.gz"" --checkpoint ""/output/checkpoints/ckpt-679"". /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: . TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). . For more information see: https://github.com/tensorflow/addons/issues/2807 . warnings.warn(. I0822 07:52:10.812179 127086447671104 call_variants.py:563] Total 1 writing processes started. I0822 07:52:10.813103 127086447671104 dv_utils.py:370] From /output/intermediate_results_dir/make_examples.tfrecord-00000-of-00020.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0822 07:52:10.813141 127086447671104 call_variants.py:588] Shape of input examples: [100, 221, 7]. I0822 07:52:10.813338 127086447671104 call_variants.py:592] Use saved model: True. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 789, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 768, in main. call_variants(. File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 598, in call_variants. model_example_shape = dv_utils.get_shape_and_channels_from_json(. File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvaria",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:5628,safety,input,input,5628,"ke_examples.tfrecord@20.gz"" --checkpoint ""/output/checkpoints/ckpt-679"". /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: . TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). . For more information see: https://github.com/tensorflow/addons/issues/2807 . warnings.warn(. I0822 07:52:10.812179 127086447671104 call_variants.py:563] Total 1 writing processes started. I0822 07:52:10.813103 127086447671104 dv_utils.py:370] From /output/intermediate_results_dir/make_examples.tfrecord-00000-of-00020.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0822 07:52:10.813141 127086447671104 call_variants.py:588] Shape of input examples: [100, 221, 7]. I0822 07:52:10.813338 127086447671104 call_variants.py:592] Use saved model: True. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 789, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 768, in main. call_variants(. File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 598, in call_variants. model_example_shape = dv_utils.get_shape_and_channels_from_json(. File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvariant/deepvariant/dv_utils.py"", line 367, in get_shape_and_channels_from_json. example_info = json.load(f). File",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:5890,safety,modul,module,5890,"red a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). . For more information see: https://github.com/tensorflow/addons/issues/2807 . warnings.warn(. I0822 07:52:10.812179 127086447671104 call_variants.py:563] Total 1 writing processes started. I0822 07:52:10.813103 127086447671104 dv_utils.py:370] From /output/intermediate_results_dir/make_examples.tfrecord-00000-of-00020.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0822 07:52:10.813141 127086447671104 call_variants.py:588] Shape of input examples: [100, 221, 7]. I0822 07:52:10.813338 127086447671104 call_variants.py:592] Use saved model: True. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 789, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 768, in main. call_variants(. File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 598, in call_variants. model_example_shape = dv_utils.get_shape_and_channels_from_json(. File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvariant/deepvariant/dv_utils.py"", line 367, in get_shape_and_channels_from_json. example_info = json.load(f). File ""/usr/lib/python3.8/json/__init__.py"", line 293, in load. return loads(fp.read(),. File ""/usr/lib/python3.8/json/__init__.py"", line 357, in loads. return _default_decoder.decode(s). File ""/usr/lib/python3.8/json/decoder.py"", line 337, in decode. obj, end = self",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:7554,safety,timeout,timeout,7554,"ll last):. File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 789, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 768, in main. call_variants(. File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 598, in call_variants. model_example_shape = dv_utils.get_shape_and_channels_from_json(. File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvariant/deepvariant/dv_utils.py"", line 367, in get_shape_and_channels_from_json. example_info = json.load(f). File ""/usr/lib/python3.8/json/__init__.py"", line 293, in load. return loads(fp.read(),. File ""/usr/lib/python3.8/json/__init__.py"", line 357, in loads. return _default_decoder.decode(s). File ""/usr/lib/python3.8/json/decoder.py"", line 337, in decode. obj, end = self.raw_decode(s, idx=_w(s, 0).end()). File ""/usr/lib/python3.8/json/decoder.py"", line 355, in raw_decode. raise JSONDecodeError(""Expecting value"", s, err.value) from None. json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0). Process ForkProcess-1:. Traceback (most recent call last):. File ""/usr/lib/python3.8/multiprocessing/process.py"", line 315, in _bootstrap. self.run(). File ""/usr/lib/python3.8/multiprocessing/process.py"", line 108, in run. self._target(*self._args, **self._kwargs). File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 454, in post_processing. item = output_queue.get(timeout=180). File ""/usr/lib/python3.8/multiprocessing/queues.py"", line 108, in get. raise Empty. _queue.Empty. real 3m2.335s. user 0m7.450s. sys 0m4.274s`. **Does the quick start test work on your system?**. Yes.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:7734,safety,test,test,7734,"ll last):. File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 789, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 768, in main. call_variants(. File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 598, in call_variants. model_example_shape = dv_utils.get_shape_and_channels_from_json(. File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvariant/deepvariant/dv_utils.py"", line 367, in get_shape_and_channels_from_json. example_info = json.load(f). File ""/usr/lib/python3.8/json/__init__.py"", line 293, in load. return loads(fp.read(),. File ""/usr/lib/python3.8/json/__init__.py"", line 357, in loads. return _default_decoder.decode(s). File ""/usr/lib/python3.8/json/decoder.py"", line 337, in decode. obj, end = self.raw_decode(s, idx=_w(s, 0).end()). File ""/usr/lib/python3.8/json/decoder.py"", line 355, in raw_decode. raise JSONDecodeError(""Expecting value"", s, err.value) from None. json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0). Process ForkProcess-1:. Traceback (most recent call last):. File ""/usr/lib/python3.8/multiprocessing/process.py"", line 315, in _bootstrap. self.run(). File ""/usr/lib/python3.8/multiprocessing/process.py"", line 108, in run. self._target(*self._args, **self._kwargs). File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 454, in post_processing. item = output_queue.get(timeout=180). File ""/usr/lib/python3.8/multiprocessing/queues.py"", line 108, in get. raise Empty. _queue.Empty. real 3m2.335s. user 0m7.450s. sys 0m4.274s`. **Does the quick start test work on your system?**. Yes.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:35,security,model,model,35,"No output vcf obtained from custom model; **ISSUE**. First of all, I found DeepVariant to be a very good and innovative tool. I'm considering including it in my exome analysis pipeline. I followed the tutorial (DeepVariant worked correctly with the Complete Genomics model), and I created my own model using Genome in a Bottle samples. To do this, I sequenced the same reference sample three times to use each BAM file for training, validation, and testing. I didn't encounter any errors during the model creation process, but when I tried to test it, the process got stuck at the call_variants step. **Setup**. - Operating system: Ubuntu 22.04.4 LTS. - DeepVariant version:1.6.1. - Installation method:docker. - Type of data: MGI DNBSEQ 400, exome sequencing. **Steps to reproduce:**. - Command:. _Create examples for trainning set_. `sudo docker run -v ""${PWD}/input"":""/input"" -v ""${PWD}/REF"":""/ref"" -v ""${PWD}""/output:""/output"" google/deepvariant:""1.6.1"" make_examples --mode training --ref ""/ref/GRCh38.p14.genome.fa"" --reads ""/input/26_r_groups.bam"" --examples ""/output/training_set.gz"" --truth_variants ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.vcf.gz"" --confident_regions ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.bed""`. _Create examples for validation set_. `sudo docker run -v ""${PWD}/input"":""/input"" -v ""${PWD}/REF"":""/ref"" -v ""${PWD}""/output:""/output"" google/deepvariant:""1.6.1"" make_examples --mode training --ref ""/ref/GRCh38.p14.genome.fa"" --reads ""/input/27_r_groups.bam"" --examples ""/output/validation_set.gz"" --truth_variants ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.vcf.gz"" --confident_regions ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.bed"" `. _Trainning Shuffling_. `python3 scripts/shuffle_tfrecords_beam.py --input_pattern_list=output/training_set.gz --output_pattern_prefix=""output/training_shuffled"" --output_dataset_name=""26"" --output_dataset_config_pbtxt=""output/training.pbtxt"" --job_name=shuffle-tfrecords`. _Validation Shuffling_. `python3 scripts/shuf",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:249,security,Compl,Complete,249,"No output vcf obtained from custom model; **ISSUE**. First of all, I found DeepVariant to be a very good and innovative tool. I'm considering including it in my exome analysis pipeline. I followed the tutorial (DeepVariant worked correctly with the Complete Genomics model), and I created my own model using Genome in a Bottle samples. To do this, I sequenced the same reference sample three times to use each BAM file for training, validation, and testing. I didn't encounter any errors during the model creation process, but when I tried to test it, the process got stuck at the call_variants step. **Setup**. - Operating system: Ubuntu 22.04.4 LTS. - DeepVariant version:1.6.1. - Installation method:docker. - Type of data: MGI DNBSEQ 400, exome sequencing. **Steps to reproduce:**. - Command:. _Create examples for trainning set_. `sudo docker run -v ""${PWD}/input"":""/input"" -v ""${PWD}/REF"":""/ref"" -v ""${PWD}""/output:""/output"" google/deepvariant:""1.6.1"" make_examples --mode training --ref ""/ref/GRCh38.p14.genome.fa"" --reads ""/input/26_r_groups.bam"" --examples ""/output/training_set.gz"" --truth_variants ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.vcf.gz"" --confident_regions ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.bed""`. _Create examples for validation set_. `sudo docker run -v ""${PWD}/input"":""/input"" -v ""${PWD}/REF"":""/ref"" -v ""${PWD}""/output:""/output"" google/deepvariant:""1.6.1"" make_examples --mode training --ref ""/ref/GRCh38.p14.genome.fa"" --reads ""/input/27_r_groups.bam"" --examples ""/output/validation_set.gz"" --truth_variants ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.vcf.gz"" --confident_regions ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.bed"" `. _Trainning Shuffling_. `python3 scripts/shuffle_tfrecords_beam.py --input_pattern_list=output/training_set.gz --output_pattern_prefix=""output/training_shuffled"" --output_dataset_name=""26"" --output_dataset_config_pbtxt=""output/training.pbtxt"" --job_name=shuffle-tfrecords`. _Validation Shuffling_. `python3 scripts/shuf",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:267,security,model,model,267,"No output vcf obtained from custom model; **ISSUE**. First of all, I found DeepVariant to be a very good and innovative tool. I'm considering including it in my exome analysis pipeline. I followed the tutorial (DeepVariant worked correctly with the Complete Genomics model), and I created my own model using Genome in a Bottle samples. To do this, I sequenced the same reference sample three times to use each BAM file for training, validation, and testing. I didn't encounter any errors during the model creation process, but when I tried to test it, the process got stuck at the call_variants step. **Setup**. - Operating system: Ubuntu 22.04.4 LTS. - DeepVariant version:1.6.1. - Installation method:docker. - Type of data: MGI DNBSEQ 400, exome sequencing. **Steps to reproduce:**. - Command:. _Create examples for trainning set_. `sudo docker run -v ""${PWD}/input"":""/input"" -v ""${PWD}/REF"":""/ref"" -v ""${PWD}""/output:""/output"" google/deepvariant:""1.6.1"" make_examples --mode training --ref ""/ref/GRCh38.p14.genome.fa"" --reads ""/input/26_r_groups.bam"" --examples ""/output/training_set.gz"" --truth_variants ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.vcf.gz"" --confident_regions ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.bed""`. _Create examples for validation set_. `sudo docker run -v ""${PWD}/input"":""/input"" -v ""${PWD}/REF"":""/ref"" -v ""${PWD}""/output:""/output"" google/deepvariant:""1.6.1"" make_examples --mode training --ref ""/ref/GRCh38.p14.genome.fa"" --reads ""/input/27_r_groups.bam"" --examples ""/output/validation_set.gz"" --truth_variants ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.vcf.gz"" --confident_regions ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.bed"" `. _Trainning Shuffling_. `python3 scripts/shuffle_tfrecords_beam.py --input_pattern_list=output/training_set.gz --output_pattern_prefix=""output/training_shuffled"" --output_dataset_name=""26"" --output_dataset_config_pbtxt=""output/training.pbtxt"" --job_name=shuffle-tfrecords`. _Validation Shuffling_. `python3 scripts/shuf",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:296,security,model,model,296,"No output vcf obtained from custom model; **ISSUE**. First of all, I found DeepVariant to be a very good and innovative tool. I'm considering including it in my exome analysis pipeline. I followed the tutorial (DeepVariant worked correctly with the Complete Genomics model), and I created my own model using Genome in a Bottle samples. To do this, I sequenced the same reference sample three times to use each BAM file for training, validation, and testing. I didn't encounter any errors during the model creation process, but when I tried to test it, the process got stuck at the call_variants step. **Setup**. - Operating system: Ubuntu 22.04.4 LTS. - DeepVariant version:1.6.1. - Installation method:docker. - Type of data: MGI DNBSEQ 400, exome sequencing. **Steps to reproduce:**. - Command:. _Create examples for trainning set_. `sudo docker run -v ""${PWD}/input"":""/input"" -v ""${PWD}/REF"":""/ref"" -v ""${PWD}""/output:""/output"" google/deepvariant:""1.6.1"" make_examples --mode training --ref ""/ref/GRCh38.p14.genome.fa"" --reads ""/input/26_r_groups.bam"" --examples ""/output/training_set.gz"" --truth_variants ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.vcf.gz"" --confident_regions ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.bed""`. _Create examples for validation set_. `sudo docker run -v ""${PWD}/input"":""/input"" -v ""${PWD}/REF"":""/ref"" -v ""${PWD}""/output:""/output"" google/deepvariant:""1.6.1"" make_examples --mode training --ref ""/ref/GRCh38.p14.genome.fa"" --reads ""/input/27_r_groups.bam"" --examples ""/output/validation_set.gz"" --truth_variants ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.vcf.gz"" --confident_regions ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.bed"" `. _Trainning Shuffling_. `python3 scripts/shuffle_tfrecords_beam.py --input_pattern_list=output/training_set.gz --output_pattern_prefix=""output/training_shuffled"" --output_dataset_name=""26"" --output_dataset_config_pbtxt=""output/training.pbtxt"" --job_name=shuffle-tfrecords`. _Validation Shuffling_. `python3 scripts/shuf",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:433,security,validat,validation,433,"No output vcf obtained from custom model; **ISSUE**. First of all, I found DeepVariant to be a very good and innovative tool. I'm considering including it in my exome analysis pipeline. I followed the tutorial (DeepVariant worked correctly with the Complete Genomics model), and I created my own model using Genome in a Bottle samples. To do this, I sequenced the same reference sample three times to use each BAM file for training, validation, and testing. I didn't encounter any errors during the model creation process, but when I tried to test it, the process got stuck at the call_variants step. **Setup**. - Operating system: Ubuntu 22.04.4 LTS. - DeepVariant version:1.6.1. - Installation method:docker. - Type of data: MGI DNBSEQ 400, exome sequencing. **Steps to reproduce:**. - Command:. _Create examples for trainning set_. `sudo docker run -v ""${PWD}/input"":""/input"" -v ""${PWD}/REF"":""/ref"" -v ""${PWD}""/output:""/output"" google/deepvariant:""1.6.1"" make_examples --mode training --ref ""/ref/GRCh38.p14.genome.fa"" --reads ""/input/26_r_groups.bam"" --examples ""/output/training_set.gz"" --truth_variants ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.vcf.gz"" --confident_regions ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.bed""`. _Create examples for validation set_. `sudo docker run -v ""${PWD}/input"":""/input"" -v ""${PWD}/REF"":""/ref"" -v ""${PWD}""/output:""/output"" google/deepvariant:""1.6.1"" make_examples --mode training --ref ""/ref/GRCh38.p14.genome.fa"" --reads ""/input/27_r_groups.bam"" --examples ""/output/validation_set.gz"" --truth_variants ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.vcf.gz"" --confident_regions ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.bed"" `. _Trainning Shuffling_. `python3 scripts/shuffle_tfrecords_beam.py --input_pattern_list=output/training_set.gz --output_pattern_prefix=""output/training_shuffled"" --output_dataset_name=""26"" --output_dataset_config_pbtxt=""output/training.pbtxt"" --job_name=shuffle-tfrecords`. _Validation Shuffling_. `python3 scripts/shuf",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:499,security,model,model,499,"No output vcf obtained from custom model; **ISSUE**. First of all, I found DeepVariant to be a very good and innovative tool. I'm considering including it in my exome analysis pipeline. I followed the tutorial (DeepVariant worked correctly with the Complete Genomics model), and I created my own model using Genome in a Bottle samples. To do this, I sequenced the same reference sample three times to use each BAM file for training, validation, and testing. I didn't encounter any errors during the model creation process, but when I tried to test it, the process got stuck at the call_variants step. **Setup**. - Operating system: Ubuntu 22.04.4 LTS. - DeepVariant version:1.6.1. - Installation method:docker. - Type of data: MGI DNBSEQ 400, exome sequencing. **Steps to reproduce:**. - Command:. _Create examples for trainning set_. `sudo docker run -v ""${PWD}/input"":""/input"" -v ""${PWD}/REF"":""/ref"" -v ""${PWD}""/output:""/output"" google/deepvariant:""1.6.1"" make_examples --mode training --ref ""/ref/GRCh38.p14.genome.fa"" --reads ""/input/26_r_groups.bam"" --examples ""/output/training_set.gz"" --truth_variants ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.vcf.gz"" --confident_regions ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.bed""`. _Create examples for validation set_. `sudo docker run -v ""${PWD}/input"":""/input"" -v ""${PWD}/REF"":""/ref"" -v ""${PWD}""/output:""/output"" google/deepvariant:""1.6.1"" make_examples --mode training --ref ""/ref/GRCh38.p14.genome.fa"" --reads ""/input/27_r_groups.bam"" --examples ""/output/validation_set.gz"" --truth_variants ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.vcf.gz"" --confident_regions ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.bed"" `. _Trainning Shuffling_. `python3 scripts/shuffle_tfrecords_beam.py --input_pattern_list=output/training_set.gz --output_pattern_prefix=""output/training_shuffled"" --output_dataset_name=""26"" --output_dataset_config_pbtxt=""output/training.pbtxt"" --job_name=shuffle-tfrecords`. _Validation Shuffling_. `python3 scripts/shuf",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:1259,security,validat,validation,1259,"cs model), and I created my own model using Genome in a Bottle samples. To do this, I sequenced the same reference sample three times to use each BAM file for training, validation, and testing. I didn't encounter any errors during the model creation process, but when I tried to test it, the process got stuck at the call_variants step. **Setup**. - Operating system: Ubuntu 22.04.4 LTS. - DeepVariant version:1.6.1. - Installation method:docker. - Type of data: MGI DNBSEQ 400, exome sequencing. **Steps to reproduce:**. - Command:. _Create examples for trainning set_. `sudo docker run -v ""${PWD}/input"":""/input"" -v ""${PWD}/REF"":""/ref"" -v ""${PWD}""/output:""/output"" google/deepvariant:""1.6.1"" make_examples --mode training --ref ""/ref/GRCh38.p14.genome.fa"" --reads ""/input/26_r_groups.bam"" --examples ""/output/training_set.gz"" --truth_variants ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.vcf.gz"" --confident_regions ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.bed""`. _Create examples for validation set_. `sudo docker run -v ""${PWD}/input"":""/input"" -v ""${PWD}/REF"":""/ref"" -v ""${PWD}""/output:""/output"" google/deepvariant:""1.6.1"" make_examples --mode training --ref ""/ref/GRCh38.p14.genome.fa"" --reads ""/input/27_r_groups.bam"" --examples ""/output/validation_set.gz"" --truth_variants ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.vcf.gz"" --confident_regions ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.bed"" `. _Trainning Shuffling_. `python3 scripts/shuffle_tfrecords_beam.py --input_pattern_list=output/training_set.gz --output_pattern_prefix=""output/training_shuffled"" --output_dataset_name=""26"" --output_dataset_config_pbtxt=""output/training.pbtxt"" --job_name=shuffle-tfrecords`. _Validation Shuffling_. `python3 scripts/shuffle_tfrecords_beam.py --input_pattern_list=output/validation_set.gz --output_pattern_prefix=""output/validation_shuffled"" --output_dataset_name=""27"" --output_dataset_config_pbtxt=""output/validation.pbtxt"" --job_name=shuffle-tfrecords `. _Model trainning_. `sudo doc",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:2186,security,validat,validation,2186,"G001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.bed""`. _Create examples for validation set_. `sudo docker run -v ""${PWD}/input"":""/input"" -v ""${PWD}/REF"":""/ref"" -v ""${PWD}""/output:""/output"" google/deepvariant:""1.6.1"" make_examples --mode training --ref ""/ref/GRCh38.p14.genome.fa"" --reads ""/input/27_r_groups.bam"" --examples ""/output/validation_set.gz"" --truth_variants ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.vcf.gz"" --confident_regions ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.bed"" `. _Trainning Shuffling_. `python3 scripts/shuffle_tfrecords_beam.py --input_pattern_list=output/training_set.gz --output_pattern_prefix=""output/training_shuffled"" --output_dataset_name=""26"" --output_dataset_config_pbtxt=""output/training.pbtxt"" --job_name=shuffle-tfrecords`. _Validation Shuffling_. `python3 scripts/shuffle_tfrecords_beam.py --input_pattern_list=output/validation_set.gz --output_pattern_prefix=""output/validation_shuffled"" --output_dataset_name=""27"" --output_dataset_config_pbtxt=""output/validation.pbtxt"" --job_name=shuffle-tfrecords `. _Model trainning_. `sudo docker run -v ""${PWD}/input"":""/input"" -v ""${PWD}/REF"":""/ref"" -v ""${PWD}""/output:""/output"" google/deepvariant:""1.6.1"" train --config=/input/dv_config.py:base --config.train_dataset_pbtxt=""/output/training.pbtxt"" --config.tune_dataset_pbtxt=""/output/validation.pbtxt"" --config.num_epochs=10 --config.learning_rate=0.0001 --config.num_validation_examples=0 --strategy=mirrored --experiment_dir=""/output/"" --config.batch_size=512`. _Model test_. `sudo docker run -v ""${PWD}/input"":""/input"" -v ""${PWD}/REF"":""/ref"" -v ""${PWD}""/output:""/output"" google/deepvariant:""1.6.1"" /opt/deepvariant/bin/run_deepvariant --model_type WES --customized_model ""/output/checkpoints/ckpt-679"" --ref ""/ref/GRCh38.p14.genome.fa"" --reads ""/input/33_r_groups.bam"" --output_vcf ""/output/33.vcf.gz"" --output_gvcf ""/output/33.g.vcf.gz"" -intermediate_results_dir ""/output/intermediate_results_dir"" --num_shards 10`. - Error trace: . ` - I0822 07:51:54.272576 127",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:2509,security,validat,validation,2509,"t/validation_set.gz"" --truth_variants ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.vcf.gz"" --confident_regions ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.bed"" `. _Trainning Shuffling_. `python3 scripts/shuffle_tfrecords_beam.py --input_pattern_list=output/training_set.gz --output_pattern_prefix=""output/training_shuffled"" --output_dataset_name=""26"" --output_dataset_config_pbtxt=""output/training.pbtxt"" --job_name=shuffle-tfrecords`. _Validation Shuffling_. `python3 scripts/shuffle_tfrecords_beam.py --input_pattern_list=output/validation_set.gz --output_pattern_prefix=""output/validation_shuffled"" --output_dataset_name=""27"" --output_dataset_config_pbtxt=""output/validation.pbtxt"" --job_name=shuffle-tfrecords `. _Model trainning_. `sudo docker run -v ""${PWD}/input"":""/input"" -v ""${PWD}/REF"":""/ref"" -v ""${PWD}""/output:""/output"" google/deepvariant:""1.6.1"" train --config=/input/dv_config.py:base --config.train_dataset_pbtxt=""/output/training.pbtxt"" --config.tune_dataset_pbtxt=""/output/validation.pbtxt"" --config.num_epochs=10 --config.learning_rate=0.0001 --config.num_validation_examples=0 --strategy=mirrored --experiment_dir=""/output/"" --config.batch_size=512`. _Model test_. `sudo docker run -v ""${PWD}/input"":""/input"" -v ""${PWD}/REF"":""/ref"" -v ""${PWD}""/output:""/output"" google/deepvariant:""1.6.1"" /opt/deepvariant/bin/run_deepvariant --model_type WES --customized_model ""/output/checkpoints/ckpt-679"" --ref ""/ref/GRCh38.p14.genome.fa"" --reads ""/input/33_r_groups.bam"" --output_vcf ""/output/33.vcf.gz"" --output_gvcf ""/output/33.g.vcf.gz"" -intermediate_results_dir ""/output/intermediate_results_dir"" --num_shards 10`. - Error trace: . ` - I0822 07:51:54.272576 127450974123840 make_examples_core.py:301] Task 17/20: Writing example info to /output/intermediate_results_dir/make_examples.tfrecord-00017-of-00020.gz.example_info.json. I0822 07:51:54.272647 127450974123840 make_examples_core.py:2958] example_shape = [100, 221, 7]. I0822 07:51:54.272740 127450974123840 make_examples_core.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:4984,security,modif,modify,4984,"617 133276175411008 make_examples_core.py:2958] example_shape = [100, 221, 7]. I0822 07:52:09.283712 133276175411008 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 19]. I0822 07:52:09.283882 133276175411008 make_examples_core.py:301] Task 8/20: Found 17371 candidate variants. I0822 07:52:09.283904 133276175411008 make_examples_core.py:301] Task 8/20: Created 18820 examples. real 34m15.728s. user 624m43.553s. sys 2m24.932s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@20.gz"" --checkpoint ""/output/checkpoints/ckpt-679"". /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: . TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). . For more information see: https://github.com/tensorflow/addons/issues/2807 . warnings.warn(. I0822 07:52:10.812179 127086447671104 call_variants.py:563] Total 1 writing processes started. I0822 07:52:10.813103 127086447671104 dv_utils.py:370] From /output/intermediate_results_dir/make_examples.tfrecord-00000-of-00020.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0822 07:52:10.813141 127086447671104 call_variants.py:588] Shape of input examples: [100, 221, 7]. I0822 07:52:10.813338 127086447671104 call_variants.py:592] Use saved model: True. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 789, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/absl_py/absl/app.py"", line 31",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:5729,security,model,model,5729,"t-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: . TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). . For more information see: https://github.com/tensorflow/addons/issues/2807 . warnings.warn(. I0822 07:52:10.812179 127086447671104 call_variants.py:563] Total 1 writing processes started. I0822 07:52:10.813103 127086447671104 dv_utils.py:370] From /output/intermediate_results_dir/make_examples.tfrecord-00000-of-00020.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0822 07:52:10.813141 127086447671104 call_variants.py:588] Shape of input examples: [100, 221, 7]. I0822 07:52:10.813338 127086447671104 call_variants.py:592] Use saved model: True. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 789, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 768, in main. call_variants(. File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 598, in call_variants. model_example_shape = dv_utils.get_shape_and_channels_from_json(. File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvariant/deepvariant/dv_utils.py"", line 367, in get_shape_and_channels_from_json. example_info = json.load(f). File ""/usr/lib/python3.8/json/__init__.py"", line 293, in load. return loads(fp.read(),. File ""/usr/lib/py",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:449,testability,test,testing,449,"No output vcf obtained from custom model; **ISSUE**. First of all, I found DeepVariant to be a very good and innovative tool. I'm considering including it in my exome analysis pipeline. I followed the tutorial (DeepVariant worked correctly with the Complete Genomics model), and I created my own model using Genome in a Bottle samples. To do this, I sequenced the same reference sample three times to use each BAM file for training, validation, and testing. I didn't encounter any errors during the model creation process, but when I tried to test it, the process got stuck at the call_variants step. **Setup**. - Operating system: Ubuntu 22.04.4 LTS. - DeepVariant version:1.6.1. - Installation method:docker. - Type of data: MGI DNBSEQ 400, exome sequencing. **Steps to reproduce:**. - Command:. _Create examples for trainning set_. `sudo docker run -v ""${PWD}/input"":""/input"" -v ""${PWD}/REF"":""/ref"" -v ""${PWD}""/output:""/output"" google/deepvariant:""1.6.1"" make_examples --mode training --ref ""/ref/GRCh38.p14.genome.fa"" --reads ""/input/26_r_groups.bam"" --examples ""/output/training_set.gz"" --truth_variants ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.vcf.gz"" --confident_regions ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.bed""`. _Create examples for validation set_. `sudo docker run -v ""${PWD}/input"":""/input"" -v ""${PWD}/REF"":""/ref"" -v ""${PWD}""/output:""/output"" google/deepvariant:""1.6.1"" make_examples --mode training --ref ""/ref/GRCh38.p14.genome.fa"" --reads ""/input/27_r_groups.bam"" --examples ""/output/validation_set.gz"" --truth_variants ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.vcf.gz"" --confident_regions ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.bed"" `. _Trainning Shuffling_. `python3 scripts/shuffle_tfrecords_beam.py --input_pattern_list=output/training_set.gz --output_pattern_prefix=""output/training_shuffled"" --output_dataset_name=""26"" --output_dataset_config_pbtxt=""output/training.pbtxt"" --job_name=shuffle-tfrecords`. _Validation Shuffling_. `python3 scripts/shuf",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:543,testability,test,test,543,"No output vcf obtained from custom model; **ISSUE**. First of all, I found DeepVariant to be a very good and innovative tool. I'm considering including it in my exome analysis pipeline. I followed the tutorial (DeepVariant worked correctly with the Complete Genomics model), and I created my own model using Genome in a Bottle samples. To do this, I sequenced the same reference sample three times to use each BAM file for training, validation, and testing. I didn't encounter any errors during the model creation process, but when I tried to test it, the process got stuck at the call_variants step. **Setup**. - Operating system: Ubuntu 22.04.4 LTS. - DeepVariant version:1.6.1. - Installation method:docker. - Type of data: MGI DNBSEQ 400, exome sequencing. **Steps to reproduce:**. - Command:. _Create examples for trainning set_. `sudo docker run -v ""${PWD}/input"":""/input"" -v ""${PWD}/REF"":""/ref"" -v ""${PWD}""/output:""/output"" google/deepvariant:""1.6.1"" make_examples --mode training --ref ""/ref/GRCh38.p14.genome.fa"" --reads ""/input/26_r_groups.bam"" --examples ""/output/training_set.gz"" --truth_variants ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.vcf.gz"" --confident_regions ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.bed""`. _Create examples for validation set_. `sudo docker run -v ""${PWD}/input"":""/input"" -v ""${PWD}/REF"":""/ref"" -v ""${PWD}""/output:""/output"" google/deepvariant:""1.6.1"" make_examples --mode training --ref ""/ref/GRCh38.p14.genome.fa"" --reads ""/input/27_r_groups.bam"" --examples ""/output/validation_set.gz"" --truth_variants ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.vcf.gz"" --confident_regions ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.bed"" `. _Trainning Shuffling_. `python3 scripts/shuffle_tfrecords_beam.py --input_pattern_list=output/training_set.gz --output_pattern_prefix=""output/training_shuffled"" --output_dataset_name=""26"" --output_dataset_config_pbtxt=""output/training.pbtxt"" --job_name=shuffle-tfrecords`. _Validation Shuffling_. `python3 scripts/shuf",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:3153,testability,trace,trace,3153,"_dataset_config_pbtxt=""output/validation.pbtxt"" --job_name=shuffle-tfrecords `. _Model trainning_. `sudo docker run -v ""${PWD}/input"":""/input"" -v ""${PWD}/REF"":""/ref"" -v ""${PWD}""/output:""/output"" google/deepvariant:""1.6.1"" train --config=/input/dv_config.py:base --config.train_dataset_pbtxt=""/output/training.pbtxt"" --config.tune_dataset_pbtxt=""/output/validation.pbtxt"" --config.num_epochs=10 --config.learning_rate=0.0001 --config.num_validation_examples=0 --strategy=mirrored --experiment_dir=""/output/"" --config.batch_size=512`. _Model test_. `sudo docker run -v ""${PWD}/input"":""/input"" -v ""${PWD}/REF"":""/ref"" -v ""${PWD}""/output:""/output"" google/deepvariant:""1.6.1"" /opt/deepvariant/bin/run_deepvariant --model_type WES --customized_model ""/output/checkpoints/ckpt-679"" --ref ""/ref/GRCh38.p14.genome.fa"" --reads ""/input/33_r_groups.bam"" --output_vcf ""/output/33.vcf.gz"" --output_gvcf ""/output/33.g.vcf.gz"" -intermediate_results_dir ""/output/intermediate_results_dir"" --num_shards 10`. - Error trace: . ` - I0822 07:51:54.272576 127450974123840 make_examples_core.py:301] Task 17/20: Writing example info to /output/intermediate_results_dir/make_examples.tfrecord-00017-of-00020.gz.example_info.json. I0822 07:51:54.272647 127450974123840 make_examples_core.py:2958] example_shape = [100, 221, 7]. I0822 07:51:54.272740 127450974123840 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 19]. I0822 07:51:54.272911 127450974123840 make_examples_core.py:301] Task 17/20: Found 17451 candidate variants. I0822 07:51:54.272932 127450974123840 make_examples_core.py:301] Task 17/20: Created 18817 examples. I0822 07:52:09.283522 133276175411008 make_examples_core.py:301] Task 8/20: Writing example info to /output/intermediate_results_dir/make_examples.tfrecord-00008-of-00020.gz.example_info.json. I0822 07:52:09.283617 133276175411008 make_examples_core.py:2958] example_shape = [100, 221, 7]. I0822 07:52:09.283712 133276175411008 make_examples_core.py:2959] example_channels = [1, 2",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:4944,testability,plan,planned,4944,"z.example_info.json. I0822 07:52:09.283617 133276175411008 make_examples_core.py:2958] example_shape = [100, 221, 7]. I0822 07:52:09.283712 133276175411008 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 19]. I0822 07:52:09.283882 133276175411008 make_examples_core.py:301] Task 8/20: Found 17371 candidate variants. I0822 07:52:09.283904 133276175411008 make_examples_core.py:301] Task 8/20: Created 18820 examples. real 34m15.728s. user 624m43.553s. sys 2m24.932s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@20.gz"" --checkpoint ""/output/checkpoints/ckpt-679"". /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: . TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). . For more information see: https://github.com/tensorflow/addons/issues/2807 . warnings.warn(. I0822 07:52:10.812179 127086447671104 call_variants.py:563] Total 1 writing processes started. I0822 07:52:10.813103 127086447671104 dv_utils.py:370] From /output/intermediate_results_dir/make_examples.tfrecord-00000-of-00020.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0822 07:52:10.813141 127086447671104 call_variants.py:588] Shape of input examples: [100, 221, 7]. I0822 07:52:10.813338 127086447671104 call_variants.py:592] Use saved model: True. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 789, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_5v5s5_vp",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:5020,testability,depend,dependencies,5020,"py:2958] example_shape = [100, 221, 7]. I0822 07:52:09.283712 133276175411008 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 19]. I0822 07:52:09.283882 133276175411008 make_examples_core.py:301] Task 8/20: Found 17371 candidate variants. I0822 07:52:09.283904 133276175411008 make_examples_core.py:301] Task 8/20: Created 18820 examples. real 34m15.728s. user 624m43.553s. sys 2m24.932s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@20.gz"" --checkpoint ""/output/checkpoints/ckpt-679"". /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: . TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). . For more information see: https://github.com/tensorflow/addons/issues/2807 . warnings.warn(. I0822 07:52:10.812179 127086447671104 call_variants.py:563] Total 1 writing processes started. I0822 07:52:10.813103 127086447671104 dv_utils.py:370] From /output/intermediate_results_dir/make_examples.tfrecord-00000-of-00020.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0822 07:52:10.813141 127086447671104 call_variants.py:588] Shape of input examples: [100, 221, 7]. I0822 07:52:10.813338 127086447671104 call_variants.py:592] Use saved model: True. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 789, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:5742,testability,Trace,Traceback,5742,"orflow_addons/utils/tfa_eol_msg.py:23: UserWarning: . TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). . For more information see: https://github.com/tensorflow/addons/issues/2807 . warnings.warn(. I0822 07:52:10.812179 127086447671104 call_variants.py:563] Total 1 writing processes started. I0822 07:52:10.813103 127086447671104 dv_utils.py:370] From /output/intermediate_results_dir/make_examples.tfrecord-00000-of-00020.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0822 07:52:10.813141 127086447671104 call_variants.py:588] Shape of input examples: [100, 221, 7]. I0822 07:52:10.813338 127086447671104 call_variants.py:592] Use saved model: True. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 789, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 768, in main. call_variants(. File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 598, in call_variants. model_example_shape = dv_utils.get_shape_and_channels_from_json(. File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvariant/deepvariant/dv_utils.py"", line 367, in get_shape_and_channels_from_json. example_info = json.load(f). File ""/usr/lib/python3.8/json/__init__.py"", line 293, in load. return loads(fp.read(),. File ""/usr/lib/python3.8/json/__",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:7160,testability,Trace,Traceback,7160,"ll last):. File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 789, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 768, in main. call_variants(. File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 598, in call_variants. model_example_shape = dv_utils.get_shape_and_channels_from_json(. File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvariant/deepvariant/dv_utils.py"", line 367, in get_shape_and_channels_from_json. example_info = json.load(f). File ""/usr/lib/python3.8/json/__init__.py"", line 293, in load. return loads(fp.read(),. File ""/usr/lib/python3.8/json/__init__.py"", line 357, in loads. return _default_decoder.decode(s). File ""/usr/lib/python3.8/json/decoder.py"", line 337, in decode. obj, end = self.raw_decode(s, idx=_w(s, 0).end()). File ""/usr/lib/python3.8/json/decoder.py"", line 355, in raw_decode. raise JSONDecodeError(""Expecting value"", s, err.value) from None. json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0). Process ForkProcess-1:. Traceback (most recent call last):. File ""/usr/lib/python3.8/multiprocessing/process.py"", line 315, in _bootstrap. self.run(). File ""/usr/lib/python3.8/multiprocessing/process.py"", line 108, in run. self._target(*self._args, **self._kwargs). File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 454, in post_processing. item = output_queue.get(timeout=180). File ""/usr/lib/python3.8/multiprocessing/queues.py"", line 108, in get. raise Empty. _queue.Empty. real 3m2.335s. user 0m7.450s. sys 0m4.274s`. **Does the quick start test work on your system?**. Yes.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:7734,testability,test,test,7734,"ll last):. File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 789, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 768, in main. call_variants(. File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 598, in call_variants. model_example_shape = dv_utils.get_shape_and_channels_from_json(. File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvariant/deepvariant/dv_utils.py"", line 367, in get_shape_and_channels_from_json. example_info = json.load(f). File ""/usr/lib/python3.8/json/__init__.py"", line 293, in load. return loads(fp.read(),. File ""/usr/lib/python3.8/json/__init__.py"", line 357, in loads. return _default_decoder.decode(s). File ""/usr/lib/python3.8/json/decoder.py"", line 337, in decode. obj, end = self.raw_decode(s, idx=_w(s, 0).end()). File ""/usr/lib/python3.8/json/decoder.py"", line 355, in raw_decode. raise JSONDecodeError(""Expecting value"", s, err.value) from None. json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0). Process ForkProcess-1:. Traceback (most recent call last):. File ""/usr/lib/python3.8/multiprocessing/process.py"", line 315, in _bootstrap. self.run(). File ""/usr/lib/python3.8/multiprocessing/process.py"", line 108, in run. self._target(*self._args, **self._kwargs). File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 454, in post_processing. item = output_queue.get(timeout=180). File ""/usr/lib/python3.8/multiprocessing/queues.py"", line 108, in get. raise Empty. _queue.Empty. real 3m2.335s. user 0m7.450s. sys 0m4.274s`. **Does the quick start test work on your system?**. Yes.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:28,usability,custom,custom,28,"No output vcf obtained from custom model; **ISSUE**. First of all, I found DeepVariant to be a very good and innovative tool. I'm considering including it in my exome analysis pipeline. I followed the tutorial (DeepVariant worked correctly with the Complete Genomics model), and I created my own model using Genome in a Bottle samples. To do this, I sequenced the same reference sample three times to use each BAM file for training, validation, and testing. I didn't encounter any errors during the model creation process, but when I tried to test it, the process got stuck at the call_variants step. **Setup**. - Operating system: Ubuntu 22.04.4 LTS. - DeepVariant version:1.6.1. - Installation method:docker. - Type of data: MGI DNBSEQ 400, exome sequencing. **Steps to reproduce:**. - Command:. _Create examples for trainning set_. `sudo docker run -v ""${PWD}/input"":""/input"" -v ""${PWD}/REF"":""/ref"" -v ""${PWD}""/output:""/output"" google/deepvariant:""1.6.1"" make_examples --mode training --ref ""/ref/GRCh38.p14.genome.fa"" --reads ""/input/26_r_groups.bam"" --examples ""/output/training_set.gz"" --truth_variants ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.vcf.gz"" --confident_regions ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.bed""`. _Create examples for validation set_. `sudo docker run -v ""${PWD}/input"":""/input"" -v ""${PWD}/REF"":""/ref"" -v ""${PWD}""/output:""/output"" google/deepvariant:""1.6.1"" make_examples --mode training --ref ""/ref/GRCh38.p14.genome.fa"" --reads ""/input/27_r_groups.bam"" --examples ""/output/validation_set.gz"" --truth_variants ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.vcf.gz"" --confident_regions ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.bed"" `. _Trainning Shuffling_. `python3 scripts/shuffle_tfrecords_beam.py --input_pattern_list=output/training_set.gz --output_pattern_prefix=""output/training_shuffled"" --output_dataset_name=""26"" --output_dataset_config_pbtxt=""output/training.pbtxt"" --job_name=shuffle-tfrecords`. _Validation Shuffling_. `python3 scripts/shuf",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:120,usability,tool,tool,120,"No output vcf obtained from custom model; **ISSUE**. First of all, I found DeepVariant to be a very good and innovative tool. I'm considering including it in my exome analysis pipeline. I followed the tutorial (DeepVariant worked correctly with the Complete Genomics model), and I created my own model using Genome in a Bottle samples. To do this, I sequenced the same reference sample three times to use each BAM file for training, validation, and testing. I didn't encounter any errors during the model creation process, but when I tried to test it, the process got stuck at the call_variants step. **Setup**. - Operating system: Ubuntu 22.04.4 LTS. - DeepVariant version:1.6.1. - Installation method:docker. - Type of data: MGI DNBSEQ 400, exome sequencing. **Steps to reproduce:**. - Command:. _Create examples for trainning set_. `sudo docker run -v ""${PWD}/input"":""/input"" -v ""${PWD}/REF"":""/ref"" -v ""${PWD}""/output:""/output"" google/deepvariant:""1.6.1"" make_examples --mode training --ref ""/ref/GRCh38.p14.genome.fa"" --reads ""/input/26_r_groups.bam"" --examples ""/output/training_set.gz"" --truth_variants ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.vcf.gz"" --confident_regions ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.bed""`. _Create examples for validation set_. `sudo docker run -v ""${PWD}/input"":""/input"" -v ""${PWD}/REF"":""/ref"" -v ""${PWD}""/output:""/output"" google/deepvariant:""1.6.1"" make_examples --mode training --ref ""/ref/GRCh38.p14.genome.fa"" --reads ""/input/27_r_groups.bam"" --examples ""/output/validation_set.gz"" --truth_variants ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.vcf.gz"" --confident_regions ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.bed"" `. _Trainning Shuffling_. `python3 scripts/shuffle_tfrecords_beam.py --input_pattern_list=output/training_set.gz --output_pattern_prefix=""output/training_shuffled"" --output_dataset_name=""26"" --output_dataset_config_pbtxt=""output/training.pbtxt"" --job_name=shuffle-tfrecords`. _Validation Shuffling_. `python3 scripts/shuf",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:481,usability,error,errors,481,"No output vcf obtained from custom model; **ISSUE**. First of all, I found DeepVariant to be a very good and innovative tool. I'm considering including it in my exome analysis pipeline. I followed the tutorial (DeepVariant worked correctly with the Complete Genomics model), and I created my own model using Genome in a Bottle samples. To do this, I sequenced the same reference sample three times to use each BAM file for training, validation, and testing. I didn't encounter any errors during the model creation process, but when I tried to test it, the process got stuck at the call_variants step. **Setup**. - Operating system: Ubuntu 22.04.4 LTS. - DeepVariant version:1.6.1. - Installation method:docker. - Type of data: MGI DNBSEQ 400, exome sequencing. **Steps to reproduce:**. - Command:. _Create examples for trainning set_. `sudo docker run -v ""${PWD}/input"":""/input"" -v ""${PWD}/REF"":""/ref"" -v ""${PWD}""/output:""/output"" google/deepvariant:""1.6.1"" make_examples --mode training --ref ""/ref/GRCh38.p14.genome.fa"" --reads ""/input/26_r_groups.bam"" --examples ""/output/training_set.gz"" --truth_variants ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.vcf.gz"" --confident_regions ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.bed""`. _Create examples for validation set_. `sudo docker run -v ""${PWD}/input"":""/input"" -v ""${PWD}/REF"":""/ref"" -v ""${PWD}""/output:""/output"" google/deepvariant:""1.6.1"" make_examples --mode training --ref ""/ref/GRCh38.p14.genome.fa"" --reads ""/input/27_r_groups.bam"" --examples ""/output/validation_set.gz"" --truth_variants ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.vcf.gz"" --confident_regions ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.bed"" `. _Trainning Shuffling_. `python3 scripts/shuffle_tfrecords_beam.py --input_pattern_list=output/training_set.gz --output_pattern_prefix=""output/training_shuffled"" --output_dataset_name=""26"" --output_dataset_config_pbtxt=""output/training.pbtxt"" --job_name=shuffle-tfrecords`. _Validation Shuffling_. `python3 scripts/shuf",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:788,usability,Command,Command,788,"No output vcf obtained from custom model; **ISSUE**. First of all, I found DeepVariant to be a very good and innovative tool. I'm considering including it in my exome analysis pipeline. I followed the tutorial (DeepVariant worked correctly with the Complete Genomics model), and I created my own model using Genome in a Bottle samples. To do this, I sequenced the same reference sample three times to use each BAM file for training, validation, and testing. I didn't encounter any errors during the model creation process, but when I tried to test it, the process got stuck at the call_variants step. **Setup**. - Operating system: Ubuntu 22.04.4 LTS. - DeepVariant version:1.6.1. - Installation method:docker. - Type of data: MGI DNBSEQ 400, exome sequencing. **Steps to reproduce:**. - Command:. _Create examples for trainning set_. `sudo docker run -v ""${PWD}/input"":""/input"" -v ""${PWD}/REF"":""/ref"" -v ""${PWD}""/output:""/output"" google/deepvariant:""1.6.1"" make_examples --mode training --ref ""/ref/GRCh38.p14.genome.fa"" --reads ""/input/26_r_groups.bam"" --examples ""/output/training_set.gz"" --truth_variants ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.vcf.gz"" --confident_regions ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.bed""`. _Create examples for validation set_. `sudo docker run -v ""${PWD}/input"":""/input"" -v ""${PWD}/REF"":""/ref"" -v ""${PWD}""/output:""/output"" google/deepvariant:""1.6.1"" make_examples --mode training --ref ""/ref/GRCh38.p14.genome.fa"" --reads ""/input/27_r_groups.bam"" --examples ""/output/validation_set.gz"" --truth_variants ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.vcf.gz"" --confident_regions ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.bed"" `. _Trainning Shuffling_. `python3 scripts/shuffle_tfrecords_beam.py --input_pattern_list=output/training_set.gz --output_pattern_prefix=""output/training_shuffled"" --output_dataset_name=""26"" --output_dataset_config_pbtxt=""output/training.pbtxt"" --job_name=shuffle-tfrecords`. _Validation Shuffling_. `python3 scripts/shuf",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:863,usability,input,input,863,"No output vcf obtained from custom model; **ISSUE**. First of all, I found DeepVariant to be a very good and innovative tool. I'm considering including it in my exome analysis pipeline. I followed the tutorial (DeepVariant worked correctly with the Complete Genomics model), and I created my own model using Genome in a Bottle samples. To do this, I sequenced the same reference sample three times to use each BAM file for training, validation, and testing. I didn't encounter any errors during the model creation process, but when I tried to test it, the process got stuck at the call_variants step. **Setup**. - Operating system: Ubuntu 22.04.4 LTS. - DeepVariant version:1.6.1. - Installation method:docker. - Type of data: MGI DNBSEQ 400, exome sequencing. **Steps to reproduce:**. - Command:. _Create examples for trainning set_. `sudo docker run -v ""${PWD}/input"":""/input"" -v ""${PWD}/REF"":""/ref"" -v ""${PWD}""/output:""/output"" google/deepvariant:""1.6.1"" make_examples --mode training --ref ""/ref/GRCh38.p14.genome.fa"" --reads ""/input/26_r_groups.bam"" --examples ""/output/training_set.gz"" --truth_variants ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.vcf.gz"" --confident_regions ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.bed""`. _Create examples for validation set_. `sudo docker run -v ""${PWD}/input"":""/input"" -v ""${PWD}/REF"":""/ref"" -v ""${PWD}""/output:""/output"" google/deepvariant:""1.6.1"" make_examples --mode training --ref ""/ref/GRCh38.p14.genome.fa"" --reads ""/input/27_r_groups.bam"" --examples ""/output/validation_set.gz"" --truth_variants ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.vcf.gz"" --confident_regions ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.bed"" `. _Trainning Shuffling_. `python3 scripts/shuffle_tfrecords_beam.py --input_pattern_list=output/training_set.gz --output_pattern_prefix=""output/training_shuffled"" --output_dataset_name=""26"" --output_dataset_config_pbtxt=""output/training.pbtxt"" --job_name=shuffle-tfrecords`. _Validation Shuffling_. `python3 scripts/shuf",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:872,usability,input,input,872,"No output vcf obtained from custom model; **ISSUE**. First of all, I found DeepVariant to be a very good and innovative tool. I'm considering including it in my exome analysis pipeline. I followed the tutorial (DeepVariant worked correctly with the Complete Genomics model), and I created my own model using Genome in a Bottle samples. To do this, I sequenced the same reference sample three times to use each BAM file for training, validation, and testing. I didn't encounter any errors during the model creation process, but when I tried to test it, the process got stuck at the call_variants step. **Setup**. - Operating system: Ubuntu 22.04.4 LTS. - DeepVariant version:1.6.1. - Installation method:docker. - Type of data: MGI DNBSEQ 400, exome sequencing. **Steps to reproduce:**. - Command:. _Create examples for trainning set_. `sudo docker run -v ""${PWD}/input"":""/input"" -v ""${PWD}/REF"":""/ref"" -v ""${PWD}""/output:""/output"" google/deepvariant:""1.6.1"" make_examples --mode training --ref ""/ref/GRCh38.p14.genome.fa"" --reads ""/input/26_r_groups.bam"" --examples ""/output/training_set.gz"" --truth_variants ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.vcf.gz"" --confident_regions ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.bed""`. _Create examples for validation set_. `sudo docker run -v ""${PWD}/input"":""/input"" -v ""${PWD}/REF"":""/ref"" -v ""${PWD}""/output:""/output"" google/deepvariant:""1.6.1"" make_examples --mode training --ref ""/ref/GRCh38.p14.genome.fa"" --reads ""/input/27_r_groups.bam"" --examples ""/output/validation_set.gz"" --truth_variants ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.vcf.gz"" --confident_regions ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.bed"" `. _Trainning Shuffling_. `python3 scripts/shuffle_tfrecords_beam.py --input_pattern_list=output/training_set.gz --output_pattern_prefix=""output/training_shuffled"" --output_dataset_name=""26"" --output_dataset_config_pbtxt=""output/training.pbtxt"" --job_name=shuffle-tfrecords`. _Validation Shuffling_. `python3 scripts/shuf",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:1032,usability,input,input,1032,"model; **ISSUE**. First of all, I found DeepVariant to be a very good and innovative tool. I'm considering including it in my exome analysis pipeline. I followed the tutorial (DeepVariant worked correctly with the Complete Genomics model), and I created my own model using Genome in a Bottle samples. To do this, I sequenced the same reference sample three times to use each BAM file for training, validation, and testing. I didn't encounter any errors during the model creation process, but when I tried to test it, the process got stuck at the call_variants step. **Setup**. - Operating system: Ubuntu 22.04.4 LTS. - DeepVariant version:1.6.1. - Installation method:docker. - Type of data: MGI DNBSEQ 400, exome sequencing. **Steps to reproduce:**. - Command:. _Create examples for trainning set_. `sudo docker run -v ""${PWD}/input"":""/input"" -v ""${PWD}/REF"":""/ref"" -v ""${PWD}""/output:""/output"" google/deepvariant:""1.6.1"" make_examples --mode training --ref ""/ref/GRCh38.p14.genome.fa"" --reads ""/input/26_r_groups.bam"" --examples ""/output/training_set.gz"" --truth_variants ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.vcf.gz"" --confident_regions ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.bed""`. _Create examples for validation set_. `sudo docker run -v ""${PWD}/input"":""/input"" -v ""${PWD}/REF"":""/ref"" -v ""${PWD}""/output:""/output"" google/deepvariant:""1.6.1"" make_examples --mode training --ref ""/ref/GRCh38.p14.genome.fa"" --reads ""/input/27_r_groups.bam"" --examples ""/output/validation_set.gz"" --truth_variants ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.vcf.gz"" --confident_regions ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.bed"" `. _Trainning Shuffling_. `python3 scripts/shuffle_tfrecords_beam.py --input_pattern_list=output/training_set.gz --output_pattern_prefix=""output/training_shuffled"" --output_dataset_name=""26"" --output_dataset_config_pbtxt=""output/training.pbtxt"" --job_name=shuffle-tfrecords`. _Validation Shuffling_. `python3 scripts/shuffle_tfrecords_beam.py --input_patte",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:1304,usability,input,input,1304," Genome in a Bottle samples. To do this, I sequenced the same reference sample three times to use each BAM file for training, validation, and testing. I didn't encounter any errors during the model creation process, but when I tried to test it, the process got stuck at the call_variants step. **Setup**. - Operating system: Ubuntu 22.04.4 LTS. - DeepVariant version:1.6.1. - Installation method:docker. - Type of data: MGI DNBSEQ 400, exome sequencing. **Steps to reproduce:**. - Command:. _Create examples for trainning set_. `sudo docker run -v ""${PWD}/input"":""/input"" -v ""${PWD}/REF"":""/ref"" -v ""${PWD}""/output:""/output"" google/deepvariant:""1.6.1"" make_examples --mode training --ref ""/ref/GRCh38.p14.genome.fa"" --reads ""/input/26_r_groups.bam"" --examples ""/output/training_set.gz"" --truth_variants ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.vcf.gz"" --confident_regions ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.bed""`. _Create examples for validation set_. `sudo docker run -v ""${PWD}/input"":""/input"" -v ""${PWD}/REF"":""/ref"" -v ""${PWD}""/output:""/output"" google/deepvariant:""1.6.1"" make_examples --mode training --ref ""/ref/GRCh38.p14.genome.fa"" --reads ""/input/27_r_groups.bam"" --examples ""/output/validation_set.gz"" --truth_variants ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.vcf.gz"" --confident_regions ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.bed"" `. _Trainning Shuffling_. `python3 scripts/shuffle_tfrecords_beam.py --input_pattern_list=output/training_set.gz --output_pattern_prefix=""output/training_shuffled"" --output_dataset_name=""26"" --output_dataset_config_pbtxt=""output/training.pbtxt"" --job_name=shuffle-tfrecords`. _Validation Shuffling_. `python3 scripts/shuffle_tfrecords_beam.py --input_pattern_list=output/validation_set.gz --output_pattern_prefix=""output/validation_shuffled"" --output_dataset_name=""27"" --output_dataset_config_pbtxt=""output/validation.pbtxt"" --job_name=shuffle-tfrecords `. _Model trainning_. `sudo docker run -v ""${PWD}/input"":""/input"" -v ""${PW",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:1313,usability,input,input,1313,"n a Bottle samples. To do this, I sequenced the same reference sample three times to use each BAM file for training, validation, and testing. I didn't encounter any errors during the model creation process, but when I tried to test it, the process got stuck at the call_variants step. **Setup**. - Operating system: Ubuntu 22.04.4 LTS. - DeepVariant version:1.6.1. - Installation method:docker. - Type of data: MGI DNBSEQ 400, exome sequencing. **Steps to reproduce:**. - Command:. _Create examples for trainning set_. `sudo docker run -v ""${PWD}/input"":""/input"" -v ""${PWD}/REF"":""/ref"" -v ""${PWD}""/output:""/output"" google/deepvariant:""1.6.1"" make_examples --mode training --ref ""/ref/GRCh38.p14.genome.fa"" --reads ""/input/26_r_groups.bam"" --examples ""/output/training_set.gz"" --truth_variants ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.vcf.gz"" --confident_regions ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.bed""`. _Create examples for validation set_. `sudo docker run -v ""${PWD}/input"":""/input"" -v ""${PWD}/REF"":""/ref"" -v ""${PWD}""/output:""/output"" google/deepvariant:""1.6.1"" make_examples --mode training --ref ""/ref/GRCh38.p14.genome.fa"" --reads ""/input/27_r_groups.bam"" --examples ""/output/validation_set.gz"" --truth_variants ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.vcf.gz"" --confident_regions ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.bed"" `. _Trainning Shuffling_. `python3 scripts/shuffle_tfrecords_beam.py --input_pattern_list=output/training_set.gz --output_pattern_prefix=""output/training_shuffled"" --output_dataset_name=""26"" --output_dataset_config_pbtxt=""output/training.pbtxt"" --job_name=shuffle-tfrecords`. _Validation Shuffling_. `python3 scripts/shuffle_tfrecords_beam.py --input_pattern_list=output/validation_set.gz --output_pattern_prefix=""output/validation_shuffled"" --output_dataset_name=""27"" --output_dataset_config_pbtxt=""output/validation.pbtxt"" --job_name=shuffle-tfrecords `. _Model trainning_. `sudo docker run -v ""${PWD}/input"":""/input"" -v ""${PWD}/REF"":""",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:1473,usability,input,input,1473," any errors during the model creation process, but when I tried to test it, the process got stuck at the call_variants step. **Setup**. - Operating system: Ubuntu 22.04.4 LTS. - DeepVariant version:1.6.1. - Installation method:docker. - Type of data: MGI DNBSEQ 400, exome sequencing. **Steps to reproduce:**. - Command:. _Create examples for trainning set_. `sudo docker run -v ""${PWD}/input"":""/input"" -v ""${PWD}/REF"":""/ref"" -v ""${PWD}""/output:""/output"" google/deepvariant:""1.6.1"" make_examples --mode training --ref ""/ref/GRCh38.p14.genome.fa"" --reads ""/input/26_r_groups.bam"" --examples ""/output/training_set.gz"" --truth_variants ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.vcf.gz"" --confident_regions ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.bed""`. _Create examples for validation set_. `sudo docker run -v ""${PWD}/input"":""/input"" -v ""${PWD}/REF"":""/ref"" -v ""${PWD}""/output:""/output"" google/deepvariant:""1.6.1"" make_examples --mode training --ref ""/ref/GRCh38.p14.genome.fa"" --reads ""/input/27_r_groups.bam"" --examples ""/output/validation_set.gz"" --truth_variants ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.vcf.gz"" --confident_regions ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.bed"" `. _Trainning Shuffling_. `python3 scripts/shuffle_tfrecords_beam.py --input_pattern_list=output/training_set.gz --output_pattern_prefix=""output/training_shuffled"" --output_dataset_name=""26"" --output_dataset_config_pbtxt=""output/training.pbtxt"" --job_name=shuffle-tfrecords`. _Validation Shuffling_. `python3 scripts/shuffle_tfrecords_beam.py --input_pattern_list=output/validation_set.gz --output_pattern_prefix=""output/validation_shuffled"" --output_dataset_name=""27"" --output_dataset_config_pbtxt=""output/validation.pbtxt"" --job_name=shuffle-tfrecords `. _Model trainning_. `sudo docker run -v ""${PWD}/input"":""/input"" -v ""${PWD}/REF"":""/ref"" -v ""${PWD}""/output:""/output"" google/deepvariant:""1.6.1"" train --config=/input/dv_config.py:base --config.train_dataset_pbtxt=""/output/training.pbtxt"" --co",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:2283,usability,input,input,2283,"er run -v ""${PWD}/input"":""/input"" -v ""${PWD}/REF"":""/ref"" -v ""${PWD}""/output:""/output"" google/deepvariant:""1.6.1"" make_examples --mode training --ref ""/ref/GRCh38.p14.genome.fa"" --reads ""/input/27_r_groups.bam"" --examples ""/output/validation_set.gz"" --truth_variants ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.vcf.gz"" --confident_regions ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.bed"" `. _Trainning Shuffling_. `python3 scripts/shuffle_tfrecords_beam.py --input_pattern_list=output/training_set.gz --output_pattern_prefix=""output/training_shuffled"" --output_dataset_name=""26"" --output_dataset_config_pbtxt=""output/training.pbtxt"" --job_name=shuffle-tfrecords`. _Validation Shuffling_. `python3 scripts/shuffle_tfrecords_beam.py --input_pattern_list=output/validation_set.gz --output_pattern_prefix=""output/validation_shuffled"" --output_dataset_name=""27"" --output_dataset_config_pbtxt=""output/validation.pbtxt"" --job_name=shuffle-tfrecords `. _Model trainning_. `sudo docker run -v ""${PWD}/input"":""/input"" -v ""${PWD}/REF"":""/ref"" -v ""${PWD}""/output:""/output"" google/deepvariant:""1.6.1"" train --config=/input/dv_config.py:base --config.train_dataset_pbtxt=""/output/training.pbtxt"" --config.tune_dataset_pbtxt=""/output/validation.pbtxt"" --config.num_epochs=10 --config.learning_rate=0.0001 --config.num_validation_examples=0 --strategy=mirrored --experiment_dir=""/output/"" --config.batch_size=512`. _Model test_. `sudo docker run -v ""${PWD}/input"":""/input"" -v ""${PWD}/REF"":""/ref"" -v ""${PWD}""/output:""/output"" google/deepvariant:""1.6.1"" /opt/deepvariant/bin/run_deepvariant --model_type WES --customized_model ""/output/checkpoints/ckpt-679"" --ref ""/ref/GRCh38.p14.genome.fa"" --reads ""/input/33_r_groups.bam"" --output_vcf ""/output/33.vcf.gz"" --output_gvcf ""/output/33.g.vcf.gz"" -intermediate_results_dir ""/output/intermediate_results_dir"" --num_shards 10`. - Error trace: . ` - I0822 07:51:54.272576 127450974123840 make_examples_core.py:301] Task 17/20: Writing example info to /output/intermediat",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:2292,usability,input,input,2292," ""${PWD}/input"":""/input"" -v ""${PWD}/REF"":""/ref"" -v ""${PWD}""/output:""/output"" google/deepvariant:""1.6.1"" make_examples --mode training --ref ""/ref/GRCh38.p14.genome.fa"" --reads ""/input/27_r_groups.bam"" --examples ""/output/validation_set.gz"" --truth_variants ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.vcf.gz"" --confident_regions ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.bed"" `. _Trainning Shuffling_. `python3 scripts/shuffle_tfrecords_beam.py --input_pattern_list=output/training_set.gz --output_pattern_prefix=""output/training_shuffled"" --output_dataset_name=""26"" --output_dataset_config_pbtxt=""output/training.pbtxt"" --job_name=shuffle-tfrecords`. _Validation Shuffling_. `python3 scripts/shuffle_tfrecords_beam.py --input_pattern_list=output/validation_set.gz --output_pattern_prefix=""output/validation_shuffled"" --output_dataset_name=""27"" --output_dataset_config_pbtxt=""output/validation.pbtxt"" --job_name=shuffle-tfrecords `. _Model trainning_. `sudo docker run -v ""${PWD}/input"":""/input"" -v ""${PWD}/REF"":""/ref"" -v ""${PWD}""/output:""/output"" google/deepvariant:""1.6.1"" train --config=/input/dv_config.py:base --config.train_dataset_pbtxt=""/output/training.pbtxt"" --config.tune_dataset_pbtxt=""/output/validation.pbtxt"" --config.num_epochs=10 --config.learning_rate=0.0001 --config.num_validation_examples=0 --strategy=mirrored --experiment_dir=""/output/"" --config.batch_size=512`. _Model test_. `sudo docker run -v ""${PWD}/input"":""/input"" -v ""${PWD}/REF"":""/ref"" -v ""${PWD}""/output:""/output"" google/deepvariant:""1.6.1"" /opt/deepvariant/bin/run_deepvariant --model_type WES --customized_model ""/output/checkpoints/ckpt-679"" --ref ""/ref/GRCh38.p14.genome.fa"" --reads ""/input/33_r_groups.bam"" --output_vcf ""/output/33.vcf.gz"" --output_gvcf ""/output/33.g.vcf.gz"" -intermediate_results_dir ""/output/intermediate_results_dir"" --num_shards 10`. - Error trace: . ` - I0822 07:51:54.272576 127450974123840 make_examples_core.py:301] Task 17/20: Writing example info to /output/intermediate_results",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:2394,usability,input,input,2394,""" make_examples --mode training --ref ""/ref/GRCh38.p14.genome.fa"" --reads ""/input/27_r_groups.bam"" --examples ""/output/validation_set.gz"" --truth_variants ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.vcf.gz"" --confident_regions ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.bed"" `. _Trainning Shuffling_. `python3 scripts/shuffle_tfrecords_beam.py --input_pattern_list=output/training_set.gz --output_pattern_prefix=""output/training_shuffled"" --output_dataset_name=""26"" --output_dataset_config_pbtxt=""output/training.pbtxt"" --job_name=shuffle-tfrecords`. _Validation Shuffling_. `python3 scripts/shuffle_tfrecords_beam.py --input_pattern_list=output/validation_set.gz --output_pattern_prefix=""output/validation_shuffled"" --output_dataset_name=""27"" --output_dataset_config_pbtxt=""output/validation.pbtxt"" --job_name=shuffle-tfrecords `. _Model trainning_. `sudo docker run -v ""${PWD}/input"":""/input"" -v ""${PWD}/REF"":""/ref"" -v ""${PWD}""/output:""/output"" google/deepvariant:""1.6.1"" train --config=/input/dv_config.py:base --config.train_dataset_pbtxt=""/output/training.pbtxt"" --config.tune_dataset_pbtxt=""/output/validation.pbtxt"" --config.num_epochs=10 --config.learning_rate=0.0001 --config.num_validation_examples=0 --strategy=mirrored --experiment_dir=""/output/"" --config.batch_size=512`. _Model test_. `sudo docker run -v ""${PWD}/input"":""/input"" -v ""${PWD}/REF"":""/ref"" -v ""${PWD}""/output:""/output"" google/deepvariant:""1.6.1"" /opt/deepvariant/bin/run_deepvariant --model_type WES --customized_model ""/output/checkpoints/ckpt-679"" --ref ""/ref/GRCh38.p14.genome.fa"" --reads ""/input/33_r_groups.bam"" --output_vcf ""/output/33.vcf.gz"" --output_gvcf ""/output/33.g.vcf.gz"" -intermediate_results_dir ""/output/intermediate_results_dir"" --num_shards 10`. - Error trace: . ` - I0822 07:51:54.272576 127450974123840 make_examples_core.py:301] Task 17/20: Writing example info to /output/intermediate_results_dir/make_examples.tfrecord-00017-of-00020.gz.example_info.json. I0822 07:51:54.272647 127450974123840",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:2731,usability,input,input,2731,"cords_beam.py --input_pattern_list=output/training_set.gz --output_pattern_prefix=""output/training_shuffled"" --output_dataset_name=""26"" --output_dataset_config_pbtxt=""output/training.pbtxt"" --job_name=shuffle-tfrecords`. _Validation Shuffling_. `python3 scripts/shuffle_tfrecords_beam.py --input_pattern_list=output/validation_set.gz --output_pattern_prefix=""output/validation_shuffled"" --output_dataset_name=""27"" --output_dataset_config_pbtxt=""output/validation.pbtxt"" --job_name=shuffle-tfrecords `. _Model trainning_. `sudo docker run -v ""${PWD}/input"":""/input"" -v ""${PWD}/REF"":""/ref"" -v ""${PWD}""/output:""/output"" google/deepvariant:""1.6.1"" train --config=/input/dv_config.py:base --config.train_dataset_pbtxt=""/output/training.pbtxt"" --config.tune_dataset_pbtxt=""/output/validation.pbtxt"" --config.num_epochs=10 --config.learning_rate=0.0001 --config.num_validation_examples=0 --strategy=mirrored --experiment_dir=""/output/"" --config.batch_size=512`. _Model test_. `sudo docker run -v ""${PWD}/input"":""/input"" -v ""${PWD}/REF"":""/ref"" -v ""${PWD}""/output:""/output"" google/deepvariant:""1.6.1"" /opt/deepvariant/bin/run_deepvariant --model_type WES --customized_model ""/output/checkpoints/ckpt-679"" --ref ""/ref/GRCh38.p14.genome.fa"" --reads ""/input/33_r_groups.bam"" --output_vcf ""/output/33.vcf.gz"" --output_gvcf ""/output/33.g.vcf.gz"" -intermediate_results_dir ""/output/intermediate_results_dir"" --num_shards 10`. - Error trace: . ` - I0822 07:51:54.272576 127450974123840 make_examples_core.py:301] Task 17/20: Writing example info to /output/intermediate_results_dir/make_examples.tfrecord-00017-of-00020.gz.example_info.json. I0822 07:51:54.272647 127450974123840 make_examples_core.py:2958] example_shape = [100, 221, 7]. I0822 07:51:54.272740 127450974123840 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 19]. I0822 07:51:54.272911 127450974123840 make_examples_core.py:301] Task 17/20: Found 17451 candidate variants. I0822 07:51:54.272932 127450974123840 make_examples_core.py",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:2740,usability,input,input,2740,"m.py --input_pattern_list=output/training_set.gz --output_pattern_prefix=""output/training_shuffled"" --output_dataset_name=""26"" --output_dataset_config_pbtxt=""output/training.pbtxt"" --job_name=shuffle-tfrecords`. _Validation Shuffling_. `python3 scripts/shuffle_tfrecords_beam.py --input_pattern_list=output/validation_set.gz --output_pattern_prefix=""output/validation_shuffled"" --output_dataset_name=""27"" --output_dataset_config_pbtxt=""output/validation.pbtxt"" --job_name=shuffle-tfrecords `. _Model trainning_. `sudo docker run -v ""${PWD}/input"":""/input"" -v ""${PWD}/REF"":""/ref"" -v ""${PWD}""/output:""/output"" google/deepvariant:""1.6.1"" train --config=/input/dv_config.py:base --config.train_dataset_pbtxt=""/output/training.pbtxt"" --config.tune_dataset_pbtxt=""/output/validation.pbtxt"" --config.num_epochs=10 --config.learning_rate=0.0001 --config.num_validation_examples=0 --strategy=mirrored --experiment_dir=""/output/"" --config.batch_size=512`. _Model test_. `sudo docker run -v ""${PWD}/input"":""/input"" -v ""${PWD}/REF"":""/ref"" -v ""${PWD}""/output:""/output"" google/deepvariant:""1.6.1"" /opt/deepvariant/bin/run_deepvariant --model_type WES --customized_model ""/output/checkpoints/ckpt-679"" --ref ""/ref/GRCh38.p14.genome.fa"" --reads ""/input/33_r_groups.bam"" --output_vcf ""/output/33.vcf.gz"" --output_gvcf ""/output/33.g.vcf.gz"" -intermediate_results_dir ""/output/intermediate_results_dir"" --num_shards 10`. - Error trace: . ` - I0822 07:51:54.272576 127450974123840 make_examples_core.py:301] Task 17/20: Writing example info to /output/intermediate_results_dir/make_examples.tfrecord-00017-of-00020.gz.example_info.json. I0822 07:51:54.272647 127450974123840 make_examples_core.py:2958] example_shape = [100, 221, 7]. I0822 07:51:54.272740 127450974123840 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 19]. I0822 07:51:54.272911 127450974123840 make_examples_core.py:301] Task 17/20: Found 17451 candidate variants. I0822 07:51:54.272932 127450974123840 make_examples_core.py:301] Tas",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:2974,usability,input,input,2974,". `python3 scripts/shuffle_tfrecords_beam.py --input_pattern_list=output/validation_set.gz --output_pattern_prefix=""output/validation_shuffled"" --output_dataset_name=""27"" --output_dataset_config_pbtxt=""output/validation.pbtxt"" --job_name=shuffle-tfrecords `. _Model trainning_. `sudo docker run -v ""${PWD}/input"":""/input"" -v ""${PWD}/REF"":""/ref"" -v ""${PWD}""/output:""/output"" google/deepvariant:""1.6.1"" train --config=/input/dv_config.py:base --config.train_dataset_pbtxt=""/output/training.pbtxt"" --config.tune_dataset_pbtxt=""/output/validation.pbtxt"" --config.num_epochs=10 --config.learning_rate=0.0001 --config.num_validation_examples=0 --strategy=mirrored --experiment_dir=""/output/"" --config.batch_size=512`. _Model test_. `sudo docker run -v ""${PWD}/input"":""/input"" -v ""${PWD}/REF"":""/ref"" -v ""${PWD}""/output:""/output"" google/deepvariant:""1.6.1"" /opt/deepvariant/bin/run_deepvariant --model_type WES --customized_model ""/output/checkpoints/ckpt-679"" --ref ""/ref/GRCh38.p14.genome.fa"" --reads ""/input/33_r_groups.bam"" --output_vcf ""/output/33.vcf.gz"" --output_gvcf ""/output/33.g.vcf.gz"" -intermediate_results_dir ""/output/intermediate_results_dir"" --num_shards 10`. - Error trace: . ` - I0822 07:51:54.272576 127450974123840 make_examples_core.py:301] Task 17/20: Writing example info to /output/intermediate_results_dir/make_examples.tfrecord-00017-of-00020.gz.example_info.json. I0822 07:51:54.272647 127450974123840 make_examples_core.py:2958] example_shape = [100, 221, 7]. I0822 07:51:54.272740 127450974123840 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 19]. I0822 07:51:54.272911 127450974123840 make_examples_core.py:301] Task 17/20: Found 17451 candidate variants. I0822 07:51:54.272932 127450974123840 make_examples_core.py:301] Task 17/20: Created 18817 examples. I0822 07:52:09.283522 133276175411008 make_examples_core.py:301] Task 8/20: Writing example info to /output/intermediate_results_dir/make_examples.tfrecord-00008-of-00020.gz.example_info.json. I0822 07",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:3147,usability,Error,Error,3147,"output_dataset_config_pbtxt=""output/validation.pbtxt"" --job_name=shuffle-tfrecords `. _Model trainning_. `sudo docker run -v ""${PWD}/input"":""/input"" -v ""${PWD}/REF"":""/ref"" -v ""${PWD}""/output:""/output"" google/deepvariant:""1.6.1"" train --config=/input/dv_config.py:base --config.train_dataset_pbtxt=""/output/training.pbtxt"" --config.tune_dataset_pbtxt=""/output/validation.pbtxt"" --config.num_epochs=10 --config.learning_rate=0.0001 --config.num_validation_examples=0 --strategy=mirrored --experiment_dir=""/output/"" --config.batch_size=512`. _Model test_. `sudo docker run -v ""${PWD}/input"":""/input"" -v ""${PWD}/REF"":""/ref"" -v ""${PWD}""/output:""/output"" google/deepvariant:""1.6.1"" /opt/deepvariant/bin/run_deepvariant --model_type WES --customized_model ""/output/checkpoints/ckpt-679"" --ref ""/ref/GRCh38.p14.genome.fa"" --reads ""/input/33_r_groups.bam"" --output_vcf ""/output/33.vcf.gz"" --output_gvcf ""/output/33.g.vcf.gz"" -intermediate_results_dir ""/output/intermediate_results_dir"" --num_shards 10`. - Error trace: . ` - I0822 07:51:54.272576 127450974123840 make_examples_core.py:301] Task 17/20: Writing example info to /output/intermediate_results_dir/make_examples.tfrecord-00017-of-00020.gz.example_info.json. I0822 07:51:54.272647 127450974123840 make_examples_core.py:2958] example_shape = [100, 221, 7]. I0822 07:51:54.272740 127450974123840 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 19]. I0822 07:51:54.272911 127450974123840 make_examples_core.py:301] Task 17/20: Found 17451 candidate variants. I0822 07:51:54.272932 127450974123840 make_examples_core.py:301] Task 17/20: Created 18817 examples. I0822 07:52:09.283522 133276175411008 make_examples_core.py:301] Task 8/20: Writing example info to /output/intermediate_results_dir/make_examples.tfrecord-00008-of-00020.gz.example_info.json. I0822 07:52:09.283617 133276175411008 make_examples_core.py:2958] example_shape = [100, 221, 7]. I0822 07:52:09.283712 133276175411008 make_examples_core.py:2959] example_channels =",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:4400,usability,user,user,4400,"_examples_core.py:2958] example_shape = [100, 221, 7]. I0822 07:51:54.272740 127450974123840 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 19]. I0822 07:51:54.272911 127450974123840 make_examples_core.py:301] Task 17/20: Found 17451 candidate variants. I0822 07:51:54.272932 127450974123840 make_examples_core.py:301] Task 17/20: Created 18817 examples. I0822 07:52:09.283522 133276175411008 make_examples_core.py:301] Task 8/20: Writing example info to /output/intermediate_results_dir/make_examples.tfrecord-00008-of-00020.gz.example_info.json. I0822 07:52:09.283617 133276175411008 make_examples_core.py:2958] example_shape = [100, 221, 7]. I0822 07:52:09.283712 133276175411008 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 19]. I0822 07:52:09.283882 133276175411008 make_examples_core.py:301] Task 8/20: Found 17371 candidate variants. I0822 07:52:09.283904 133276175411008 make_examples_core.py:301] Task 8/20: Created 18820 examples. real 34m15.728s. user 624m43.553s. sys 2m24.932s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@20.gz"" --checkpoint ""/output/checkpoints/ckpt-679"". /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: . TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). . For more information see: https://github.com/tensorflow/addons/issues/2807 . warnings.warn(. I0822 07:52:10.812179 127086447671104 call_variants.py:563] Total 1 writing processes started. I0822 07:52:10.813103 127086447671104 dv_utils.py:370] From /output/intermediate_results",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:4451,usability,command,command,4451,". I0822 07:51:54.272740 127450974123840 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 19]. I0822 07:51:54.272911 127450974123840 make_examples_core.py:301] Task 17/20: Found 17451 candidate variants. I0822 07:51:54.272932 127450974123840 make_examples_core.py:301] Task 17/20: Created 18817 examples. I0822 07:52:09.283522 133276175411008 make_examples_core.py:301] Task 8/20: Writing example info to /output/intermediate_results_dir/make_examples.tfrecord-00008-of-00020.gz.example_info.json. I0822 07:52:09.283617 133276175411008 make_examples_core.py:2958] example_shape = [100, 221, 7]. I0822 07:52:09.283712 133276175411008 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 19]. I0822 07:52:09.283882 133276175411008 make_examples_core.py:301] Task 8/20: Found 17371 candidate variants. I0822 07:52:09.283904 133276175411008 make_examples_core.py:301] Task 8/20: Created 18820 examples. real 34m15.728s. user 624m43.553s. sys 2m24.932s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@20.gz"" --checkpoint ""/output/checkpoints/ckpt-679"". /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: . TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). . For more information see: https://github.com/tensorflow/addons/issues/2807 . warnings.warn(. I0822 07:52:10.812179 127086447671104 call_variants.py:563] Total 1 writing processes started. I0822 07:52:10.813103 127086447671104 dv_utils.py:370] From /output/intermediate_results_dir/make_examples.tfrecord-00000-of-00020.gz.example",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:4786,usability,User,UserWarning,4786,"83522 133276175411008 make_examples_core.py:301] Task 8/20: Writing example info to /output/intermediate_results_dir/make_examples.tfrecord-00008-of-00020.gz.example_info.json. I0822 07:52:09.283617 133276175411008 make_examples_core.py:2958] example_shape = [100, 221, 7]. I0822 07:52:09.283712 133276175411008 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 19]. I0822 07:52:09.283882 133276175411008 make_examples_core.py:301] Task 8/20: Found 17371 candidate variants. I0822 07:52:09.283904 133276175411008 make_examples_core.py:301] Task 8/20: Created 18820 examples. real 34m15.728s. user 624m43.553s. sys 2m24.932s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@20.gz"" --checkpoint ""/output/checkpoints/ckpt-679"". /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: . TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). . For more information see: https://github.com/tensorflow/addons/issues/2807 . warnings.warn(. I0822 07:52:10.812179 127086447671104 call_variants.py:563] Total 1 writing processes started. I0822 07:52:10.813103 127086447671104 dv_utils.py:370] From /output/intermediate_results_dir/make_examples.tfrecord-00000-of-00020.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0822 07:52:10.813141 127086447671104 call_variants.py:588] Shape of input examples: [100, 221, 7]. I0822 07:52:10.813338 127086447671104 call_variants.py:592] Use saved model: True. Traceback (most recent call last):. File ""/tmp/Baz",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:4899,usability,minim,minimal,4899,"s_dir/make_examples.tfrecord-00008-of-00020.gz.example_info.json. I0822 07:52:09.283617 133276175411008 make_examples_core.py:2958] example_shape = [100, 221, 7]. I0822 07:52:09.283712 133276175411008 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 19]. I0822 07:52:09.283882 133276175411008 make_examples_core.py:301] Task 8/20: Found 17371 candidate variants. I0822 07:52:09.283904 133276175411008 make_examples_core.py:301] Task 8/20: Created 18820 examples. real 34m15.728s. user 624m43.553s. sys 2m24.932s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@20.gz"" --checkpoint ""/output/checkpoints/ckpt-679"". /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: . TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). . For more information see: https://github.com/tensorflow/addons/issues/2807 . warnings.warn(. I0822 07:52:10.812179 127086447671104 call_variants.py:563] Total 1 writing processes started. I0822 07:52:10.813103 127086447671104 dv_utils.py:370] From /output/intermediate_results_dir/make_examples.tfrecord-00000-of-00020.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0822 07:52:10.813141 127086447671104 call_variants.py:588] Shape of input examples: [100, 221, 7]. I0822 07:52:10.813338 127086447671104 call_variants.py:592] Use saved model: True. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 789, in <module>. app.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:5476,usability,input,input,5476,"pvariant/bin/call_variants --outfile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@20.gz"" --checkpoint ""/output/checkpoints/ckpt-679"". /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: . TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). . For more information see: https://github.com/tensorflow/addons/issues/2807 . warnings.warn(. I0822 07:52:10.812179 127086447671104 call_variants.py:563] Total 1 writing processes started. I0822 07:52:10.813103 127086447671104 dv_utils.py:370] From /output/intermediate_results_dir/make_examples.tfrecord-00000-of-00020.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0822 07:52:10.813141 127086447671104 call_variants.py:588] Shape of input examples: [100, 221, 7]. I0822 07:52:10.813338 127086447671104 call_variants.py:592] Use saved model: True. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 789, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 768, in main. call_variants(. File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 598, in call_variants. model_example_shape = dv_utils.get_shape_and_channels_from_json(. File ""/tmp/Bazel.runf",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:5519,usability,input,input,5519,"ut/intermediate_results_dir/call_variants_output.tfrecord.gz"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@20.gz"" --checkpoint ""/output/checkpoints/ckpt-679"". /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: . TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). . For more information see: https://github.com/tensorflow/addons/issues/2807 . warnings.warn(. I0822 07:52:10.812179 127086447671104 call_variants.py:563] Total 1 writing processes started. I0822 07:52:10.813103 127086447671104 dv_utils.py:370] From /output/intermediate_results_dir/make_examples.tfrecord-00000-of-00020.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0822 07:52:10.813141 127086447671104 call_variants.py:588] Shape of input examples: [100, 221, 7]. I0822 07:52:10.813338 127086447671104 call_variants.py:592] Use saved model: True. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 789, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 768, in main. call_variants(. File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 598, in call_variants. model_example_shape = dv_utils.get_shape_and_channels_from_json(. File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvaria",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:5628,usability,input,input,5628,"ke_examples.tfrecord@20.gz"" --checkpoint ""/output/checkpoints/ckpt-679"". /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: . TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). . For more information see: https://github.com/tensorflow/addons/issues/2807 . warnings.warn(. I0822 07:52:10.812179 127086447671104 call_variants.py:563] Total 1 writing processes started. I0822 07:52:10.813103 127086447671104 dv_utils.py:370] From /output/intermediate_results_dir/make_examples.tfrecord-00000-of-00020.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0822 07:52:10.813141 127086447671104 call_variants.py:588] Shape of input examples: [100, 221, 7]. I0822 07:52:10.813338 127086447671104 call_variants.py:592] Use saved model: True. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 789, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 768, in main. call_variants(. File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 598, in call_variants. model_example_shape = dv_utils.get_shape_and_channels_from_json(. File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvariant/deepvariant/dv_utils.py"", line 367, in get_shape_and_channels_from_json. example_info = json.load(f). File",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:7681,usability,user,user,7681,"ll last):. File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 789, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 768, in main. call_variants(. File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 598, in call_variants. model_example_shape = dv_utils.get_shape_and_channels_from_json(. File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvariant/deepvariant/dv_utils.py"", line 367, in get_shape_and_channels_from_json. example_info = json.load(f). File ""/usr/lib/python3.8/json/__init__.py"", line 293, in load. return loads(fp.read(),. File ""/usr/lib/python3.8/json/__init__.py"", line 357, in loads. return _default_decoder.decode(s). File ""/usr/lib/python3.8/json/decoder.py"", line 337, in decode. obj, end = self.raw_decode(s, idx=_w(s, 0).end()). File ""/usr/lib/python3.8/json/decoder.py"", line 355, in raw_decode. raise JSONDecodeError(""Expecting value"", s, err.value) from None. json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0). Process ForkProcess-1:. Traceback (most recent call last):. File ""/usr/lib/python3.8/multiprocessing/process.py"", line 315, in _bootstrap. self.run(). File ""/usr/lib/python3.8/multiprocessing/process.py"", line 108, in run. self._target(*self._args, **self._kwargs). File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 454, in post_processing. item = output_queue.get(timeout=180). File ""/usr/lib/python3.8/multiprocessing/queues.py"", line 108, in get. raise Empty. _queue.Empty. real 3m2.335s. user 0m7.450s. sys 0m4.274s`. **Does the quick start test work on your system?**. Yes.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/870:13,availability,ERROR,ERROR,13,"[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/wire_format_lite.cc:584]; Hi, so sorry for asking something again. But I really want to use mostly DeepVariant for variant calling. . **Setup**. - Operating system: Red Hat Enterprise Linux 9. - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): Docker. - Type of data: WES mapped to hg19. **My code:**. - Commands: . ```. #!/bin/bash. #$ -l m_mem_free=200G. #$ -l os=rhel9. #$ -m bea. #$ -cwd. #$ -pe smp 2. #$ -o deepvariant_output.log. #$ -e deepvariant_error.log. cd path/to/deepvariant. BAM_DIR=. VCF_DIR=deepvariant_output/. REFERENCE=Reference_HLA/human_g1k_v37_decoy.fasta. export SINGULARITY_CACHEDIR=""path/to/deepvariant/.singularity-$(whoami)"". export SINGULARITY_TMPDIR=""path/to/deepvariant/.singularity-$(whoami)"". BIN_VERSION=""1.6.1"". for BAM_FILE in ""${BAM_DIR}""/*.bam; do. # Extract the base name of the BAM file (without the directory and extension). BASE_NAME=$(basename ""${BAM_FILE}"" .bam). # Define the output VCF file name. VCF_FILE=""${VCF_DIR}/${BASE_NAME}.vcf.gz"". echo $BAM_FILE. echo $VCF_FILE. singularity exec --bind /usr/lib/locale/ \. docker://google/deepvariant:${BIN_VERSION} \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref $REFERENCE \. --reads $BAM_FILE \. --regions 6:32509320-32669663 \. --output_vcf $VCF_FILE \. --num_shards 12. done. ``` . - Error trace: . ```. ***** Running the command:*****. time seq 0 11 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""Reference_HLA/chr6_hg19.fa"" --reads ""./MDC05_1463_3.final.bam"" --examples ""/tmp/7361351.1.gpu.q/tmpzsp9g_vq/make_examples.tfrecord@12.gz"" --channels ""insert_size"" --regions ""chr6:32509320-32669663"" --task {}. [libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/wire_format_lite.cc:584] String field 'nucleus.genomics.v1.Program.command_line' contains invalid UTF-8 data when serializing a protocol buffer. Use the 'bytes",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/870
https://github.com/google/deepvariant/issues/870:215,availability,Operat,Operating,215,"[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/wire_format_lite.cc:584]; Hi, so sorry for asking something again. But I really want to use mostly DeepVariant for variant calling. . **Setup**. - Operating system: Red Hat Enterprise Linux 9. - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): Docker. - Type of data: WES mapped to hg19. **My code:**. - Commands: . ```. #!/bin/bash. #$ -l m_mem_free=200G. #$ -l os=rhel9. #$ -m bea. #$ -cwd. #$ -pe smp 2. #$ -o deepvariant_output.log. #$ -e deepvariant_error.log. cd path/to/deepvariant. BAM_DIR=. VCF_DIR=deepvariant_output/. REFERENCE=Reference_HLA/human_g1k_v37_decoy.fasta. export SINGULARITY_CACHEDIR=""path/to/deepvariant/.singularity-$(whoami)"". export SINGULARITY_TMPDIR=""path/to/deepvariant/.singularity-$(whoami)"". BIN_VERSION=""1.6.1"". for BAM_FILE in ""${BAM_DIR}""/*.bam; do. # Extract the base name of the BAM file (without the directory and extension). BASE_NAME=$(basename ""${BAM_FILE}"" .bam). # Define the output VCF file name. VCF_FILE=""${VCF_DIR}/${BASE_NAME}.vcf.gz"". echo $BAM_FILE. echo $VCF_FILE. singularity exec --bind /usr/lib/locale/ \. docker://google/deepvariant:${BIN_VERSION} \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref $REFERENCE \. --reads $BAM_FILE \. --regions 6:32509320-32669663 \. --output_vcf $VCF_FILE \. --num_shards 12. done. ``` . - Error trace: . ```. ***** Running the command:*****. time seq 0 11 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""Reference_HLA/chr6_hg19.fa"" --reads ""./MDC05_1463_3.final.bam"" --examples ""/tmp/7361351.1.gpu.q/tmpzsp9g_vq/make_examples.tfrecord@12.gz"" --channels ""insert_size"" --regions ""chr6:32509320-32669663"" --task {}. [libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/wire_format_lite.cc:584] String field 'nucleus.genomics.v1.Program.command_line' contains invalid UTF-8 data when serializing a protocol buffer. Use the 'bytes",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/870
https://github.com/google/deepvariant/issues/870:1090,availability,echo,echo,1090,"; Hi, so sorry for asking something again. But I really want to use mostly DeepVariant for variant calling. . **Setup**. - Operating system: Red Hat Enterprise Linux 9. - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): Docker. - Type of data: WES mapped to hg19. **My code:**. - Commands: . ```. #!/bin/bash. #$ -l m_mem_free=200G. #$ -l os=rhel9. #$ -m bea. #$ -cwd. #$ -pe smp 2. #$ -o deepvariant_output.log. #$ -e deepvariant_error.log. cd path/to/deepvariant. BAM_DIR=. VCF_DIR=deepvariant_output/. REFERENCE=Reference_HLA/human_g1k_v37_decoy.fasta. export SINGULARITY_CACHEDIR=""path/to/deepvariant/.singularity-$(whoami)"". export SINGULARITY_TMPDIR=""path/to/deepvariant/.singularity-$(whoami)"". BIN_VERSION=""1.6.1"". for BAM_FILE in ""${BAM_DIR}""/*.bam; do. # Extract the base name of the BAM file (without the directory and extension). BASE_NAME=$(basename ""${BAM_FILE}"" .bam). # Define the output VCF file name. VCF_FILE=""${VCF_DIR}/${BASE_NAME}.vcf.gz"". echo $BAM_FILE. echo $VCF_FILE. singularity exec --bind /usr/lib/locale/ \. docker://google/deepvariant:${BIN_VERSION} \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref $REFERENCE \. --reads $BAM_FILE \. --regions 6:32509320-32669663 \. --output_vcf $VCF_FILE \. --num_shards 12. done. ``` . - Error trace: . ```. ***** Running the command:*****. time seq 0 11 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""Reference_HLA/chr6_hg19.fa"" --reads ""./MDC05_1463_3.final.bam"" --examples ""/tmp/7361351.1.gpu.q/tmpzsp9g_vq/make_examples.tfrecord@12.gz"" --channels ""insert_size"" --regions ""chr6:32509320-32669663"" --task {}. [libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/wire_format_lite.cc:584] String field 'nucleus.genomics.v1.Program.command_line' contains invalid UTF-8 data when serializing a protocol buffer. Use the 'bytes' type if you intend to send raw bytes. [libprotobuf ERROR external/com_google_protobuf/src/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/870
https://github.com/google/deepvariant/issues/870:1106,availability,echo,echo,1106,"or asking something again. But I really want to use mostly DeepVariant for variant calling. . **Setup**. - Operating system: Red Hat Enterprise Linux 9. - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): Docker. - Type of data: WES mapped to hg19. **My code:**. - Commands: . ```. #!/bin/bash. #$ -l m_mem_free=200G. #$ -l os=rhel9. #$ -m bea. #$ -cwd. #$ -pe smp 2. #$ -o deepvariant_output.log. #$ -e deepvariant_error.log. cd path/to/deepvariant. BAM_DIR=. VCF_DIR=deepvariant_output/. REFERENCE=Reference_HLA/human_g1k_v37_decoy.fasta. export SINGULARITY_CACHEDIR=""path/to/deepvariant/.singularity-$(whoami)"". export SINGULARITY_TMPDIR=""path/to/deepvariant/.singularity-$(whoami)"". BIN_VERSION=""1.6.1"". for BAM_FILE in ""${BAM_DIR}""/*.bam; do. # Extract the base name of the BAM file (without the directory and extension). BASE_NAME=$(basename ""${BAM_FILE}"" .bam). # Define the output VCF file name. VCF_FILE=""${VCF_DIR}/${BASE_NAME}.vcf.gz"". echo $BAM_FILE. echo $VCF_FILE. singularity exec --bind /usr/lib/locale/ \. docker://google/deepvariant:${BIN_VERSION} \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref $REFERENCE \. --reads $BAM_FILE \. --regions 6:32509320-32669663 \. --output_vcf $VCF_FILE \. --num_shards 12. done. ``` . - Error trace: . ```. ***** Running the command:*****. time seq 0 11 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""Reference_HLA/chr6_hg19.fa"" --reads ""./MDC05_1463_3.final.bam"" --examples ""/tmp/7361351.1.gpu.q/tmpzsp9g_vq/make_examples.tfrecord@12.gz"" --channels ""insert_size"" --regions ""chr6:32509320-32669663"" --task {}. [libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/wire_format_lite.cc:584] String field 'nucleus.genomics.v1.Program.command_line' contains invalid UTF-8 data when serializing a protocol buffer. Use the 'bytes' type if you intend to send raw bytes. [libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/870
https://github.com/google/deepvariant/issues/870:1403,availability,Error,Error,1403,"- Commands: . ```. #!/bin/bash. #$ -l m_mem_free=200G. #$ -l os=rhel9. #$ -m bea. #$ -cwd. #$ -pe smp 2. #$ -o deepvariant_output.log. #$ -e deepvariant_error.log. cd path/to/deepvariant. BAM_DIR=. VCF_DIR=deepvariant_output/. REFERENCE=Reference_HLA/human_g1k_v37_decoy.fasta. export SINGULARITY_CACHEDIR=""path/to/deepvariant/.singularity-$(whoami)"". export SINGULARITY_TMPDIR=""path/to/deepvariant/.singularity-$(whoami)"". BIN_VERSION=""1.6.1"". for BAM_FILE in ""${BAM_DIR}""/*.bam; do. # Extract the base name of the BAM file (without the directory and extension). BASE_NAME=$(basename ""${BAM_FILE}"" .bam). # Define the output VCF file name. VCF_FILE=""${VCF_DIR}/${BASE_NAME}.vcf.gz"". echo $BAM_FILE. echo $VCF_FILE. singularity exec --bind /usr/lib/locale/ \. docker://google/deepvariant:${BIN_VERSION} \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref $REFERENCE \. --reads $BAM_FILE \. --regions 6:32509320-32669663 \. --output_vcf $VCF_FILE \. --num_shards 12. done. ``` . - Error trace: . ```. ***** Running the command:*****. time seq 0 11 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""Reference_HLA/chr6_hg19.fa"" --reads ""./MDC05_1463_3.final.bam"" --examples ""/tmp/7361351.1.gpu.q/tmpzsp9g_vq/make_examples.tfrecord@12.gz"" --channels ""insert_size"" --regions ""chr6:32509320-32669663"" --task {}. [libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/wire_format_lite.cc:584] String field 'nucleus.genomics.v1.Program.command_line' contains invalid UTF-8 data when serializing a protocol buffer. Use the 'bytes' type if you intend to send raw bytes. [libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/wire_format_lite.cc:584] String field 'nucleus.genomics.v1.Program.command_line' contains invalid UTF-8 data when parsing a protocol buffer. Use the 'bytes' type if you intend to send raw bytes. Traceback (most recent call last):. File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_goo",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/870
https://github.com/google/deepvariant/issues/870:1786,availability,ERROR,ERROR,1786,"/to/deepvariant/.singularity-$(whoami)"". BIN_VERSION=""1.6.1"". for BAM_FILE in ""${BAM_DIR}""/*.bam; do. # Extract the base name of the BAM file (without the directory and extension). BASE_NAME=$(basename ""${BAM_FILE}"" .bam). # Define the output VCF file name. VCF_FILE=""${VCF_DIR}/${BASE_NAME}.vcf.gz"". echo $BAM_FILE. echo $VCF_FILE. singularity exec --bind /usr/lib/locale/ \. docker://google/deepvariant:${BIN_VERSION} \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref $REFERENCE \. --reads $BAM_FILE \. --regions 6:32509320-32669663 \. --output_vcf $VCF_FILE \. --num_shards 12. done. ``` . - Error trace: . ```. ***** Running the command:*****. time seq 0 11 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""Reference_HLA/chr6_hg19.fa"" --reads ""./MDC05_1463_3.final.bam"" --examples ""/tmp/7361351.1.gpu.q/tmpzsp9g_vq/make_examples.tfrecord@12.gz"" --channels ""insert_size"" --regions ""chr6:32509320-32669663"" --task {}. [libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/wire_format_lite.cc:584] String field 'nucleus.genomics.v1.Program.command_line' contains invalid UTF-8 data when serializing a protocol buffer. Use the 'bytes' type if you intend to send raw bytes. [libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/wire_format_lite.cc:584] String field 'nucleus.genomics.v1.Program.command_line' contains invalid UTF-8 data when parsing a protocol buffer. Use the 'bytes' type if you intend to send raw bytes. Traceback (most recent call last):. File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 234, in <module>. app.run(main). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/870
https://github.com/google/deepvariant/issues/870:2053,availability,ERROR,ERROR,2053,"""${VCF_DIR}/${BASE_NAME}.vcf.gz"". echo $BAM_FILE. echo $VCF_FILE. singularity exec --bind /usr/lib/locale/ \. docker://google/deepvariant:${BIN_VERSION} \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref $REFERENCE \. --reads $BAM_FILE \. --regions 6:32509320-32669663 \. --output_vcf $VCF_FILE \. --num_shards 12. done. ``` . - Error trace: . ```. ***** Running the command:*****. time seq 0 11 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""Reference_HLA/chr6_hg19.fa"" --reads ""./MDC05_1463_3.final.bam"" --examples ""/tmp/7361351.1.gpu.q/tmpzsp9g_vq/make_examples.tfrecord@12.gz"" --channels ""insert_size"" --regions ""chr6:32509320-32669663"" --task {}. [libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/wire_format_lite.cc:584] String field 'nucleus.genomics.v1.Program.command_line' contains invalid UTF-8 data when serializing a protocol buffer. Use the 'bytes' type if you intend to send raw bytes. [libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/wire_format_lite.cc:584] String field 'nucleus.genomics.v1.Program.command_line' contains invalid UTF-8 data when parsing a protocol buffer. Use the 'bytes' type if you intend to send raw bytes. Traceback (most recent call last):. File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 234, in <module>. app.run(main). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 220, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 15",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/870
https://github.com/google/deepvariant/issues/870:4174,availability,Error,Error,4174,"ys.exit(main(argv)). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 220, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 157, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 109, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 170, in assign_sample_name. with sam.SamReader(reads_filenames.split(',')[0]) as sam_reader:. File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 260, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 240, in __init__. self.header = self._reader.header. google.protobuf.message.DecodeError: Error parsing message. ```. I ran the WES example from you with no problem, but I experience issues with my own data (I have the same setup when running singularity). . I checked the reference and input bam files, they don't seem to be corrupted... but just googling the error did not help much. Cannot think of anything else, maybe you have some suggestions where the problem could be coming from? Otherwise I will try to find the raw data for my .bam files and do remapping to hg38 and use the ref that worked previously. . Thanks again!! Alisa.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/870
https://github.com/google/deepvariant/issues/870:4445,availability,error,error,4445,"ys.exit(main(argv)). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 220, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 157, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 109, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 170, in assign_sample_name. with sam.SamReader(reads_filenames.split(',')[0]) as sam_reader:. File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 260, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 240, in __init__. self.header = self._reader.header. google.protobuf.message.DecodeError: Error parsing message. ```. I ran the WES example from you with no problem, but I experience issues with my own data (I have the same setup when running singularity). . I checked the reference and input bam files, they don't seem to be corrupted... but just googling the error did not help much. Cannot think of anything else, maybe you have some suggestions where the problem could be coming from? Otherwise I will try to find the raw data for my .bam files and do remapping to hg38 and use the ref that worked previously. . Thanks again!! Alisa.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/870
https://github.com/google/deepvariant/issues/870:275,deployability,version,version,275,"[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/wire_format_lite.cc:584]; Hi, so sorry for asking something again. But I really want to use mostly DeepVariant for variant calling. . **Setup**. - Operating system: Red Hat Enterprise Linux 9. - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): Docker. - Type of data: WES mapped to hg19. **My code:**. - Commands: . ```. #!/bin/bash. #$ -l m_mem_free=200G. #$ -l os=rhel9. #$ -m bea. #$ -cwd. #$ -pe smp 2. #$ -o deepvariant_output.log. #$ -e deepvariant_error.log. cd path/to/deepvariant. BAM_DIR=. VCF_DIR=deepvariant_output/. REFERENCE=Reference_HLA/human_g1k_v37_decoy.fasta. export SINGULARITY_CACHEDIR=""path/to/deepvariant/.singularity-$(whoami)"". export SINGULARITY_TMPDIR=""path/to/deepvariant/.singularity-$(whoami)"". BIN_VERSION=""1.6.1"". for BAM_FILE in ""${BAM_DIR}""/*.bam; do. # Extract the base name of the BAM file (without the directory and extension). BASE_NAME=$(basename ""${BAM_FILE}"" .bam). # Define the output VCF file name. VCF_FILE=""${VCF_DIR}/${BASE_NAME}.vcf.gz"". echo $BAM_FILE. echo $VCF_FILE. singularity exec --bind /usr/lib/locale/ \. docker://google/deepvariant:${BIN_VERSION} \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref $REFERENCE \. --reads $BAM_FILE \. --regions 6:32509320-32669663 \. --output_vcf $VCF_FILE \. --num_shards 12. done. ``` . - Error trace: . ```. ***** Running the command:*****. time seq 0 11 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""Reference_HLA/chr6_hg19.fa"" --reads ""./MDC05_1463_3.final.bam"" --examples ""/tmp/7361351.1.gpu.q/tmpzsp9g_vq/make_examples.tfrecord@12.gz"" --channels ""insert_size"" --regions ""chr6:32509320-32669663"" --task {}. [libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/wire_format_lite.cc:584] String field 'nucleus.genomics.v1.Program.command_line' contains invalid UTF-8 data when serializing a protocol buffer. Use the 'bytes",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/870
https://github.com/google/deepvariant/issues/870:293,deployability,Instal,Installation,293,"[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/wire_format_lite.cc:584]; Hi, so sorry for asking something again. But I really want to use mostly DeepVariant for variant calling. . **Setup**. - Operating system: Red Hat Enterprise Linux 9. - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): Docker. - Type of data: WES mapped to hg19. **My code:**. - Commands: . ```. #!/bin/bash. #$ -l m_mem_free=200G. #$ -l os=rhel9. #$ -m bea. #$ -cwd. #$ -pe smp 2. #$ -o deepvariant_output.log. #$ -e deepvariant_error.log. cd path/to/deepvariant. BAM_DIR=. VCF_DIR=deepvariant_output/. REFERENCE=Reference_HLA/human_g1k_v37_decoy.fasta. export SINGULARITY_CACHEDIR=""path/to/deepvariant/.singularity-$(whoami)"". export SINGULARITY_TMPDIR=""path/to/deepvariant/.singularity-$(whoami)"". BIN_VERSION=""1.6.1"". for BAM_FILE in ""${BAM_DIR}""/*.bam; do. # Extract the base name of the BAM file (without the directory and extension). BASE_NAME=$(basename ""${BAM_FILE}"" .bam). # Define the output VCF file name. VCF_FILE=""${VCF_DIR}/${BASE_NAME}.vcf.gz"". echo $BAM_FILE. echo $VCF_FILE. singularity exec --bind /usr/lib/locale/ \. docker://google/deepvariant:${BIN_VERSION} \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref $REFERENCE \. --reads $BAM_FILE \. --regions 6:32509320-32669663 \. --output_vcf $VCF_FILE \. --num_shards 12. done. ``` . - Error trace: . ```. ***** Running the command:*****. time seq 0 11 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""Reference_HLA/chr6_hg19.fa"" --reads ""./MDC05_1463_3.final.bam"" --examples ""/tmp/7361351.1.gpu.q/tmpzsp9g_vq/make_examples.tfrecord@12.gz"" --channels ""insert_size"" --regions ""chr6:32509320-32669663"" --task {}. [libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/wire_format_lite.cc:584] String field 'nucleus.genomics.v1.Program.command_line' contains invalid UTF-8 data when serializing a protocol buffer. Use the 'bytes",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/870
https://github.com/google/deepvariant/issues/870:536,deployability,log,log,536,"[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/wire_format_lite.cc:584]; Hi, so sorry for asking something again. But I really want to use mostly DeepVariant for variant calling. . **Setup**. - Operating system: Red Hat Enterprise Linux 9. - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): Docker. - Type of data: WES mapped to hg19. **My code:**. - Commands: . ```. #!/bin/bash. #$ -l m_mem_free=200G. #$ -l os=rhel9. #$ -m bea. #$ -cwd. #$ -pe smp 2. #$ -o deepvariant_output.log. #$ -e deepvariant_error.log. cd path/to/deepvariant. BAM_DIR=. VCF_DIR=deepvariant_output/. REFERENCE=Reference_HLA/human_g1k_v37_decoy.fasta. export SINGULARITY_CACHEDIR=""path/to/deepvariant/.singularity-$(whoami)"". export SINGULARITY_TMPDIR=""path/to/deepvariant/.singularity-$(whoami)"". BIN_VERSION=""1.6.1"". for BAM_FILE in ""${BAM_DIR}""/*.bam; do. # Extract the base name of the BAM file (without the directory and extension). BASE_NAME=$(basename ""${BAM_FILE}"" .bam). # Define the output VCF file name. VCF_FILE=""${VCF_DIR}/${BASE_NAME}.vcf.gz"". echo $BAM_FILE. echo $VCF_FILE. singularity exec --bind /usr/lib/locale/ \. docker://google/deepvariant:${BIN_VERSION} \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref $REFERENCE \. --reads $BAM_FILE \. --regions 6:32509320-32669663 \. --output_vcf $VCF_FILE \. --num_shards 12. done. ``` . - Error trace: . ```. ***** Running the command:*****. time seq 0 11 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""Reference_HLA/chr6_hg19.fa"" --reads ""./MDC05_1463_3.final.bam"" --examples ""/tmp/7361351.1.gpu.q/tmpzsp9g_vq/make_examples.tfrecord@12.gz"" --channels ""insert_size"" --regions ""chr6:32509320-32669663"" --task {}. [libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/wire_format_lite.cc:584] String field 'nucleus.genomics.v1.Program.command_line' contains invalid UTF-8 data when serializing a protocol buffer. Use the 'bytes",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/870
https://github.com/google/deepvariant/issues/870:565,deployability,log,log,565,"[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/wire_format_lite.cc:584]; Hi, so sorry for asking something again. But I really want to use mostly DeepVariant for variant calling. . **Setup**. - Operating system: Red Hat Enterprise Linux 9. - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): Docker. - Type of data: WES mapped to hg19. **My code:**. - Commands: . ```. #!/bin/bash. #$ -l m_mem_free=200G. #$ -l os=rhel9. #$ -m bea. #$ -cwd. #$ -pe smp 2. #$ -o deepvariant_output.log. #$ -e deepvariant_error.log. cd path/to/deepvariant. BAM_DIR=. VCF_DIR=deepvariant_output/. REFERENCE=Reference_HLA/human_g1k_v37_decoy.fasta. export SINGULARITY_CACHEDIR=""path/to/deepvariant/.singularity-$(whoami)"". export SINGULARITY_TMPDIR=""path/to/deepvariant/.singularity-$(whoami)"". BIN_VERSION=""1.6.1"". for BAM_FILE in ""${BAM_DIR}""/*.bam; do. # Extract the base name of the BAM file (without the directory and extension). BASE_NAME=$(basename ""${BAM_FILE}"" .bam). # Define the output VCF file name. VCF_FILE=""${VCF_DIR}/${BASE_NAME}.vcf.gz"". echo $BAM_FILE. echo $VCF_FILE. singularity exec --bind /usr/lib/locale/ \. docker://google/deepvariant:${BIN_VERSION} \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref $REFERENCE \. --reads $BAM_FILE \. --regions 6:32509320-32669663 \. --output_vcf $VCF_FILE \. --num_shards 12. done. ``` . - Error trace: . ```. ***** Running the command:*****. time seq 0 11 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""Reference_HLA/chr6_hg19.fa"" --reads ""./MDC05_1463_3.final.bam"" --examples ""/tmp/7361351.1.gpu.q/tmpzsp9g_vq/make_examples.tfrecord@12.gz"" --channels ""insert_size"" --regions ""chr6:32509320-32669663"" --task {}. [libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/wire_format_lite.cc:584] String field 'nucleus.genomics.v1.Program.command_line' contains invalid UTF-8 data when serializing a protocol buffer. Use the 'bytes",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/870
https://github.com/google/deepvariant/issues/870:1922,deployability,contain,contains,1922,"file (without the directory and extension). BASE_NAME=$(basename ""${BAM_FILE}"" .bam). # Define the output VCF file name. VCF_FILE=""${VCF_DIR}/${BASE_NAME}.vcf.gz"". echo $BAM_FILE. echo $VCF_FILE. singularity exec --bind /usr/lib/locale/ \. docker://google/deepvariant:${BIN_VERSION} \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref $REFERENCE \. --reads $BAM_FILE \. --regions 6:32509320-32669663 \. --output_vcf $VCF_FILE \. --num_shards 12. done. ``` . - Error trace: . ```. ***** Running the command:*****. time seq 0 11 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""Reference_HLA/chr6_hg19.fa"" --reads ""./MDC05_1463_3.final.bam"" --examples ""/tmp/7361351.1.gpu.q/tmpzsp9g_vq/make_examples.tfrecord@12.gz"" --channels ""insert_size"" --regions ""chr6:32509320-32669663"" --task {}. [libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/wire_format_lite.cc:584] String field 'nucleus.genomics.v1.Program.command_line' contains invalid UTF-8 data when serializing a protocol buffer. Use the 'bytes' type if you intend to send raw bytes. [libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/wire_format_lite.cc:584] String field 'nucleus.genomics.v1.Program.command_line' contains invalid UTF-8 data when parsing a protocol buffer. Use the 'bytes' type if you intend to send raw bytes. Traceback (most recent call last):. File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 234, in <module>. app.run(main). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 220, in main. options = default_options(add_flags=True, flags_obj",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/870
https://github.com/google/deepvariant/issues/870:2189,deployability,contain,contains,2189,":${BIN_VERSION} \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref $REFERENCE \. --reads $BAM_FILE \. --regions 6:32509320-32669663 \. --output_vcf $VCF_FILE \. --num_shards 12. done. ``` . - Error trace: . ```. ***** Running the command:*****. time seq 0 11 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""Reference_HLA/chr6_hg19.fa"" --reads ""./MDC05_1463_3.final.bam"" --examples ""/tmp/7361351.1.gpu.q/tmpzsp9g_vq/make_examples.tfrecord@12.gz"" --channels ""insert_size"" --regions ""chr6:32509320-32669663"" --task {}. [libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/wire_format_lite.cc:584] String field 'nucleus.genomics.v1.Program.command_line' contains invalid UTF-8 data when serializing a protocol buffer. Use the 'bytes' type if you intend to send raw bytes. [libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/wire_format_lite.cc:584] String field 'nucleus.genomics.v1.Program.command_line' contains invalid UTF-8 data when parsing a protocol buffer. Use the 'bytes' type if you intend to send raw bytes. Traceback (most recent call last):. File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 234, in <module>. app.run(main). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 220, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 157, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mq",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/870
https://github.com/google/deepvariant/issues/870:2467,deployability,modul,module,2467,"| parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""Reference_HLA/chr6_hg19.fa"" --reads ""./MDC05_1463_3.final.bam"" --examples ""/tmp/7361351.1.gpu.q/tmpzsp9g_vq/make_examples.tfrecord@12.gz"" --channels ""insert_size"" --regions ""chr6:32509320-32669663"" --task {}. [libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/wire_format_lite.cc:584] String field 'nucleus.genomics.v1.Program.command_line' contains invalid UTF-8 data when serializing a protocol buffer. Use the 'bytes' type if you intend to send raw bytes. [libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/wire_format_lite.cc:584] String field 'nucleus.genomics.v1.Program.command_line' contains invalid UTF-8 data when parsing a protocol buffer. Use the 'bytes' type if you intend to send raw bytes. Traceback (most recent call last):. File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 234, in <module>. app.run(main). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 220, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 157, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 109, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", lin",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/870
https://github.com/google/deepvariant/issues/870:1654,energy efficiency,gpu,gpu,1654,"/human_g1k_v37_decoy.fasta. export SINGULARITY_CACHEDIR=""path/to/deepvariant/.singularity-$(whoami)"". export SINGULARITY_TMPDIR=""path/to/deepvariant/.singularity-$(whoami)"". BIN_VERSION=""1.6.1"". for BAM_FILE in ""${BAM_DIR}""/*.bam; do. # Extract the base name of the BAM file (without the directory and extension). BASE_NAME=$(basename ""${BAM_FILE}"" .bam). # Define the output VCF file name. VCF_FILE=""${VCF_DIR}/${BASE_NAME}.vcf.gz"". echo $BAM_FILE. echo $VCF_FILE. singularity exec --bind /usr/lib/locale/ \. docker://google/deepvariant:${BIN_VERSION} \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref $REFERENCE \. --reads $BAM_FILE \. --regions 6:32509320-32669663 \. --output_vcf $VCF_FILE \. --num_shards 12. done. ``` . - Error trace: . ```. ***** Running the command:*****. time seq 0 11 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""Reference_HLA/chr6_hg19.fa"" --reads ""./MDC05_1463_3.final.bam"" --examples ""/tmp/7361351.1.gpu.q/tmpzsp9g_vq/make_examples.tfrecord@12.gz"" --channels ""insert_size"" --regions ""chr6:32509320-32669663"" --task {}. [libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/wire_format_lite.cc:584] String field 'nucleus.genomics.v1.Program.command_line' contains invalid UTF-8 data when serializing a protocol buffer. Use the 'bytes' type if you intend to send raw bytes. [libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/wire_format_lite.cc:584] String field 'nucleus.genomics.v1.Program.command_line' contains invalid UTF-8 data when parsing a protocol buffer. Use the 'bytes' type if you intend to send raw bytes. Traceback (most recent call last):. File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 234, in <module>. app.run(main). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/870
https://github.com/google/deepvariant/issues/870:2360,energy efficiency,gpu,gpu,2360,"F_FILE \. --num_shards 12. done. ``` . - Error trace: . ```. ***** Running the command:*****. time seq 0 11 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""Reference_HLA/chr6_hg19.fa"" --reads ""./MDC05_1463_3.final.bam"" --examples ""/tmp/7361351.1.gpu.q/tmpzsp9g_vq/make_examples.tfrecord@12.gz"" --channels ""insert_size"" --regions ""chr6:32509320-32669663"" --task {}. [libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/wire_format_lite.cc:584] String field 'nucleus.genomics.v1.Program.command_line' contains invalid UTF-8 data when serializing a protocol buffer. Use the 'bytes' type if you intend to send raw bytes. [libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/wire_format_lite.cc:584] String field 'nucleus.genomics.v1.Program.command_line' contains invalid UTF-8 data when parsing a protocol buffer. Use the 'bytes' type if you intend to send raw bytes. Traceback (most recent call last):. File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 234, in <module>. app.run(main). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 220, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 157, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 109, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/736",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/870
https://github.com/google/deepvariant/issues/870:2512,energy efficiency,gpu,gpu,2512,"epvariant/bin/make_examples --mode calling --ref ""Reference_HLA/chr6_hg19.fa"" --reads ""./MDC05_1463_3.final.bam"" --examples ""/tmp/7361351.1.gpu.q/tmpzsp9g_vq/make_examples.tfrecord@12.gz"" --channels ""insert_size"" --regions ""chr6:32509320-32669663"" --task {}. [libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/wire_format_lite.cc:584] String field 'nucleus.genomics.v1.Program.command_line' contains invalid UTF-8 data when serializing a protocol buffer. Use the 'bytes' type if you intend to send raw bytes. [libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/wire_format_lite.cc:584] String field 'nucleus.genomics.v1.Program.command_line' contains invalid UTF-8 data when parsing a protocol buffer. Use the 'bytes' type if you intend to send raw bytes. Traceback (most recent call last):. File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 234, in <module>. app.run(main). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 220, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 157, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 109, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 170, in assign_sample_name. with sam.SamRe",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/870
https://github.com/google/deepvariant/issues/870:2635,energy efficiency,gpu,gpu,2635," ""/tmp/7361351.1.gpu.q/tmpzsp9g_vq/make_examples.tfrecord@12.gz"" --channels ""insert_size"" --regions ""chr6:32509320-32669663"" --task {}. [libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/wire_format_lite.cc:584] String field 'nucleus.genomics.v1.Program.command_line' contains invalid UTF-8 data when serializing a protocol buffer. Use the 'bytes' type if you intend to send raw bytes. [libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/wire_format_lite.cc:584] String field 'nucleus.genomics.v1.Program.command_line' contains invalid UTF-8 data when parsing a protocol buffer. Use the 'bytes' type if you intend to send raw bytes. Traceback (most recent call last):. File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 234, in <module>. app.run(main). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 220, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 157, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 109, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 170, in assign_sample_name. with sam.SamReader(reads_filenames.split(',')[0]) as sam_reader:. File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/870
https://github.com/google/deepvariant/issues/870:2763,energy efficiency,gpu,gpu,2763,"ask {}. [libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/wire_format_lite.cc:584] String field 'nucleus.genomics.v1.Program.command_line' contains invalid UTF-8 data when serializing a protocol buffer. Use the 'bytes' type if you intend to send raw bytes. [libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/wire_format_lite.cc:584] String field 'nucleus.genomics.v1.Program.command_line' contains invalid UTF-8 data when parsing a protocol buffer. Use the 'bytes' type if you intend to send raw bytes. Traceback (most recent call last):. File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 234, in <module>. app.run(main). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 220, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 157, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 109, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 170, in assign_sample_name. with sam.SamReader(reads_filenames.split(',')[0]) as sam_reader:. File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/870
https://github.com/google/deepvariant/issues/870:2956,energy efficiency,gpu,gpu,2956,"ializing a protocol buffer. Use the 'bytes' type if you intend to send raw bytes. [libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/wire_format_lite.cc:584] String field 'nucleus.genomics.v1.Program.command_line' contains invalid UTF-8 data when parsing a protocol buffer. Use the 'bytes' type if you intend to send raw bytes. Traceback (most recent call last):. File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 234, in <module>. app.run(main). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 220, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 157, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 109, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 170, in assign_sample_name. with sam.SamReader(reads_filenames.split(',')[0]) as sam_reader:. File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 260, in _native_reader. return NativeSamReader(input_path, **kwa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/870
https://github.com/google/deepvariant/issues/870:3165,energy efficiency,gpu,gpu,3165,"Program.command_line' contains invalid UTF-8 data when parsing a protocol buffer. Use the 'bytes' type if you intend to send raw bytes. Traceback (most recent call last):. File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 234, in <module>. app.run(main). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 220, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 157, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 109, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 170, in assign_sample_name. with sam.SamReader(reads_filenames.split(',')[0]) as sam_reader:. File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 260, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 240, in __init__. self.header = self._reader.header. google.protobuf.message.Decode",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/870
https://github.com/google/deepvariant/issues/870:3369,energy efficiency,gpu,gpu,3369,".runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 234, in <module>. app.run(main). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 220, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 157, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 109, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 170, in assign_sample_name. with sam.SamReader(reads_filenames.split(',')[0]) as sam_reader:. File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 260, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 240, in __init__. self.header = self._reader.header. google.protobuf.message.DecodeError: Error parsing message. ```. I ran the WES example from you with no problem, but I experience issues with my own data (I have the same setup when running singularity). . I checked the reference and ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/870
https://github.com/google/deepvariant/issues/870:3587,energy efficiency,gpu,gpu,3587,". _run_main(main, args). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 220, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 157, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 109, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 170, in assign_sample_name. with sam.SamReader(reads_filenames.split(',')[0]) as sam_reader:. File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 260, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 240, in __init__. self.header = self._reader.header. google.protobuf.message.DecodeError: Error parsing message. ```. I ran the WES example from you with no problem, but I experience issues with my own data (I have the same setup when running singularity). . I checked the reference and input bam files, they don't seem to be corrupted... but just googling the error did not help much. Cannot think of anything else, maybe you have some suggestions where the problem could be coming from? Otherwise I will",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/870
https://github.com/google/deepvariant/issues/870:3795,energy efficiency,gpu,gpu,3795,"ys.exit(main(argv)). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 220, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 157, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 109, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 170, in assign_sample_name. with sam.SamReader(reads_filenames.split(',')[0]) as sam_reader:. File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 260, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 240, in __init__. self.header = self._reader.header. google.protobuf.message.DecodeError: Error parsing message. ```. I ran the WES example from you with no problem, but I experience issues with my own data (I have the same setup when running singularity). . I checked the reference and input bam files, they don't seem to be corrupted... but just googling the error did not help much. Cannot think of anything else, maybe you have some suggestions where the problem could be coming from? Otherwise I will try to find the raw data for my .bam files and do remapping to hg38 and use the ref that worked previously. . Thanks again!! Alisa.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/870
https://github.com/google/deepvariant/issues/870:3985,energy efficiency,gpu,gpu,3985,"ys.exit(main(argv)). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 220, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 157, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 109, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 170, in assign_sample_name. with sam.SamReader(reads_filenames.split(',')[0]) as sam_reader:. File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 260, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 240, in __init__. self.header = self._reader.header. google.protobuf.message.DecodeError: Error parsing message. ```. I ran the WES example from you with no problem, but I experience issues with my own data (I have the same setup when running singularity). . I checked the reference and input bam files, they don't seem to be corrupted... but just googling the error did not help much. Cannot think of anything else, maybe you have some suggestions where the problem could be coming from? Otherwise I will try to find the raw data for my .bam files and do remapping to hg38 and use the ref that worked previously. . Thanks again!! Alisa.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/870
https://github.com/google/deepvariant/issues/870:275,integrability,version,version,275,"[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/wire_format_lite.cc:584]; Hi, so sorry for asking something again. But I really want to use mostly DeepVariant for variant calling. . **Setup**. - Operating system: Red Hat Enterprise Linux 9. - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): Docker. - Type of data: WES mapped to hg19. **My code:**. - Commands: . ```. #!/bin/bash. #$ -l m_mem_free=200G. #$ -l os=rhel9. #$ -m bea. #$ -cwd. #$ -pe smp 2. #$ -o deepvariant_output.log. #$ -e deepvariant_error.log. cd path/to/deepvariant. BAM_DIR=. VCF_DIR=deepvariant_output/. REFERENCE=Reference_HLA/human_g1k_v37_decoy.fasta. export SINGULARITY_CACHEDIR=""path/to/deepvariant/.singularity-$(whoami)"". export SINGULARITY_TMPDIR=""path/to/deepvariant/.singularity-$(whoami)"". BIN_VERSION=""1.6.1"". for BAM_FILE in ""${BAM_DIR}""/*.bam; do. # Extract the base name of the BAM file (without the directory and extension). BASE_NAME=$(basename ""${BAM_FILE}"" .bam). # Define the output VCF file name. VCF_FILE=""${VCF_DIR}/${BASE_NAME}.vcf.gz"". echo $BAM_FILE. echo $VCF_FILE. singularity exec --bind /usr/lib/locale/ \. docker://google/deepvariant:${BIN_VERSION} \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref $REFERENCE \. --reads $BAM_FILE \. --regions 6:32509320-32669663 \. --output_vcf $VCF_FILE \. --num_shards 12. done. ``` . - Error trace: . ```. ***** Running the command:*****. time seq 0 11 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""Reference_HLA/chr6_hg19.fa"" --reads ""./MDC05_1463_3.final.bam"" --examples ""/tmp/7361351.1.gpu.q/tmpzsp9g_vq/make_examples.tfrecord@12.gz"" --channels ""insert_size"" --regions ""chr6:32509320-32669663"" --task {}. [libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/wire_format_lite.cc:584] String field 'nucleus.genomics.v1.Program.command_line' contains invalid UTF-8 data when serializing a protocol buffer. Use the 'bytes",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/870
https://github.com/google/deepvariant/issues/870:1500,integrability,buffer,buffer,1500," smp 2. #$ -o deepvariant_output.log. #$ -e deepvariant_error.log. cd path/to/deepvariant. BAM_DIR=. VCF_DIR=deepvariant_output/. REFERENCE=Reference_HLA/human_g1k_v37_decoy.fasta. export SINGULARITY_CACHEDIR=""path/to/deepvariant/.singularity-$(whoami)"". export SINGULARITY_TMPDIR=""path/to/deepvariant/.singularity-$(whoami)"". BIN_VERSION=""1.6.1"". for BAM_FILE in ""${BAM_DIR}""/*.bam; do. # Extract the base name of the BAM file (without the directory and extension). BASE_NAME=$(basename ""${BAM_FILE}"" .bam). # Define the output VCF file name. VCF_FILE=""${VCF_DIR}/${BASE_NAME}.vcf.gz"". echo $BAM_FILE. echo $VCF_FILE. singularity exec --bind /usr/lib/locale/ \. docker://google/deepvariant:${BIN_VERSION} \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref $REFERENCE \. --reads $BAM_FILE \. --regions 6:32509320-32669663 \. --output_vcf $VCF_FILE \. --num_shards 12. done. ``` . - Error trace: . ```. ***** Running the command:*****. time seq 0 11 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""Reference_HLA/chr6_hg19.fa"" --reads ""./MDC05_1463_3.final.bam"" --examples ""/tmp/7361351.1.gpu.q/tmpzsp9g_vq/make_examples.tfrecord@12.gz"" --channels ""insert_size"" --regions ""chr6:32509320-32669663"" --task {}. [libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/wire_format_lite.cc:584] String field 'nucleus.genomics.v1.Program.command_line' contains invalid UTF-8 data when serializing a protocol buffer. Use the 'bytes' type if you intend to send raw bytes. [libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/wire_format_lite.cc:584] String field 'nucleus.genomics.v1.Program.command_line' contains invalid UTF-8 data when parsing a protocol buffer. Use the 'bytes' type if you intend to send raw bytes. Traceback (most recent call last):. File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 234, in <module>. app.run(main). File ""/tmp/7",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/870
https://github.com/google/deepvariant/issues/870:1969,integrability,protocol,protocol,1969,"E_NAME=$(basename ""${BAM_FILE}"" .bam). # Define the output VCF file name. VCF_FILE=""${VCF_DIR}/${BASE_NAME}.vcf.gz"". echo $BAM_FILE. echo $VCF_FILE. singularity exec --bind /usr/lib/locale/ \. docker://google/deepvariant:${BIN_VERSION} \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref $REFERENCE \. --reads $BAM_FILE \. --regions 6:32509320-32669663 \. --output_vcf $VCF_FILE \. --num_shards 12. done. ``` . - Error trace: . ```. ***** Running the command:*****. time seq 0 11 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""Reference_HLA/chr6_hg19.fa"" --reads ""./MDC05_1463_3.final.bam"" --examples ""/tmp/7361351.1.gpu.q/tmpzsp9g_vq/make_examples.tfrecord@12.gz"" --channels ""insert_size"" --regions ""chr6:32509320-32669663"" --task {}. [libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/wire_format_lite.cc:584] String field 'nucleus.genomics.v1.Program.command_line' contains invalid UTF-8 data when serializing a protocol buffer. Use the 'bytes' type if you intend to send raw bytes. [libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/wire_format_lite.cc:584] String field 'nucleus.genomics.v1.Program.command_line' contains invalid UTF-8 data when parsing a protocol buffer. Use the 'bytes' type if you intend to send raw bytes. Traceback (most recent call last):. File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 234, in <module>. app.run(main). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 220, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/7361351.1.gpu.q/Bazel.runfi",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/870
https://github.com/google/deepvariant/issues/870:1978,integrability,buffer,buffer,1978,"(basename ""${BAM_FILE}"" .bam). # Define the output VCF file name. VCF_FILE=""${VCF_DIR}/${BASE_NAME}.vcf.gz"". echo $BAM_FILE. echo $VCF_FILE. singularity exec --bind /usr/lib/locale/ \. docker://google/deepvariant:${BIN_VERSION} \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref $REFERENCE \. --reads $BAM_FILE \. --regions 6:32509320-32669663 \. --output_vcf $VCF_FILE \. --num_shards 12. done. ``` . - Error trace: . ```. ***** Running the command:*****. time seq 0 11 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""Reference_HLA/chr6_hg19.fa"" --reads ""./MDC05_1463_3.final.bam"" --examples ""/tmp/7361351.1.gpu.q/tmpzsp9g_vq/make_examples.tfrecord@12.gz"" --channels ""insert_size"" --regions ""chr6:32509320-32669663"" --task {}. [libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/wire_format_lite.cc:584] String field 'nucleus.genomics.v1.Program.command_line' contains invalid UTF-8 data when serializing a protocol buffer. Use the 'bytes' type if you intend to send raw bytes. [libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/wire_format_lite.cc:584] String field 'nucleus.genomics.v1.Program.command_line' contains invalid UTF-8 data when parsing a protocol buffer. Use the 'bytes' type if you intend to send raw bytes. Traceback (most recent call last):. File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 234, in <module>. app.run(main). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 220, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/870
https://github.com/google/deepvariant/issues/870:2232,integrability,protocol,protocol,2232,"_deepvariant \. --model_type WES \. --ref $REFERENCE \. --reads $BAM_FILE \. --regions 6:32509320-32669663 \. --output_vcf $VCF_FILE \. --num_shards 12. done. ``` . - Error trace: . ```. ***** Running the command:*****. time seq 0 11 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""Reference_HLA/chr6_hg19.fa"" --reads ""./MDC05_1463_3.final.bam"" --examples ""/tmp/7361351.1.gpu.q/tmpzsp9g_vq/make_examples.tfrecord@12.gz"" --channels ""insert_size"" --regions ""chr6:32509320-32669663"" --task {}. [libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/wire_format_lite.cc:584] String field 'nucleus.genomics.v1.Program.command_line' contains invalid UTF-8 data when serializing a protocol buffer. Use the 'bytes' type if you intend to send raw bytes. [libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/wire_format_lite.cc:584] String field 'nucleus.genomics.v1.Program.command_line' contains invalid UTF-8 data when parsing a protocol buffer. Use the 'bytes' type if you intend to send raw bytes. Traceback (most recent call last):. File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 234, in <module>. app.run(main). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 220, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 157, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvaria",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/870
https://github.com/google/deepvariant/issues/870:2241,integrability,buffer,buffer,2241,"iant \. --model_type WES \. --ref $REFERENCE \. --reads $BAM_FILE \. --regions 6:32509320-32669663 \. --output_vcf $VCF_FILE \. --num_shards 12. done. ``` . - Error trace: . ```. ***** Running the command:*****. time seq 0 11 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""Reference_HLA/chr6_hg19.fa"" --reads ""./MDC05_1463_3.final.bam"" --examples ""/tmp/7361351.1.gpu.q/tmpzsp9g_vq/make_examples.tfrecord@12.gz"" --channels ""insert_size"" --regions ""chr6:32509320-32669663"" --task {}. [libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/wire_format_lite.cc:584] String field 'nucleus.genomics.v1.Program.command_line' contains invalid UTF-8 data when serializing a protocol buffer. Use the 'bytes' type if you intend to send raw bytes. [libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/wire_format_lite.cc:584] String field 'nucleus.genomics.v1.Program.command_line' contains invalid UTF-8 data when parsing a protocol buffer. Use the 'bytes' type if you intend to send raw bytes. Traceback (most recent call last):. File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 234, in <module>. app.run(main). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 220, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 157, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/870
https://github.com/google/deepvariant/issues/870:4153,integrability,messag,message,4153,"ys.exit(main(argv)). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 220, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 157, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 109, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 170, in assign_sample_name. with sam.SamReader(reads_filenames.split(',')[0]) as sam_reader:. File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 260, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 240, in __init__. self.header = self._reader.header. google.protobuf.message.DecodeError: Error parsing message. ```. I ran the WES example from you with no problem, but I experience issues with my own data (I have the same setup when running singularity). . I checked the reference and input bam files, they don't seem to be corrupted... but just googling the error did not help much. Cannot think of anything else, maybe you have some suggestions where the problem could be coming from? Otherwise I will try to find the raw data for my .bam files and do remapping to hg38 and use the ref that worked previously. . Thanks again!! Alisa.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/870
https://github.com/google/deepvariant/issues/870:4188,integrability,messag,message,4188,"ys.exit(main(argv)). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 220, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 157, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 109, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 170, in assign_sample_name. with sam.SamReader(reads_filenames.split(',')[0]) as sam_reader:. File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 260, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 240, in __init__. self.header = self._reader.header. google.protobuf.message.DecodeError: Error parsing message. ```. I ran the WES example from you with no problem, but I experience issues with my own data (I have the same setup when running singularity). . I checked the reference and input bam files, they don't seem to be corrupted... but just googling the error did not help much. Cannot think of anything else, maybe you have some suggestions where the problem could be coming from? Otherwise I will try to find the raw data for my .bam files and do remapping to hg38 and use the ref that worked previously. . Thanks again!! Alisa.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/870
https://github.com/google/deepvariant/issues/870:1141,interoperability,bind,bind,1141,"ally want to use mostly DeepVariant for variant calling. . **Setup**. - Operating system: Red Hat Enterprise Linux 9. - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): Docker. - Type of data: WES mapped to hg19. **My code:**. - Commands: . ```. #!/bin/bash. #$ -l m_mem_free=200G. #$ -l os=rhel9. #$ -m bea. #$ -cwd. #$ -pe smp 2. #$ -o deepvariant_output.log. #$ -e deepvariant_error.log. cd path/to/deepvariant. BAM_DIR=. VCF_DIR=deepvariant_output/. REFERENCE=Reference_HLA/human_g1k_v37_decoy.fasta. export SINGULARITY_CACHEDIR=""path/to/deepvariant/.singularity-$(whoami)"". export SINGULARITY_TMPDIR=""path/to/deepvariant/.singularity-$(whoami)"". BIN_VERSION=""1.6.1"". for BAM_FILE in ""${BAM_DIR}""/*.bam; do. # Extract the base name of the BAM file (without the directory and extension). BASE_NAME=$(basename ""${BAM_FILE}"" .bam). # Define the output VCF file name. VCF_FILE=""${VCF_DIR}/${BASE_NAME}.vcf.gz"". echo $BAM_FILE. echo $VCF_FILE. singularity exec --bind /usr/lib/locale/ \. docker://google/deepvariant:${BIN_VERSION} \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref $REFERENCE \. --reads $BAM_FILE \. --regions 6:32509320-32669663 \. --output_vcf $VCF_FILE \. --num_shards 12. done. ``` . - Error trace: . ```. ***** Running the command:*****. time seq 0 11 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""Reference_HLA/chr6_hg19.fa"" --reads ""./MDC05_1463_3.final.bam"" --examples ""/tmp/7361351.1.gpu.q/tmpzsp9g_vq/make_examples.tfrecord@12.gz"" --channels ""insert_size"" --regions ""chr6:32509320-32669663"" --task {}. [libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/wire_format_lite.cc:584] String field 'nucleus.genomics.v1.Program.command_line' contains invalid UTF-8 data when serializing a protocol buffer. Use the 'bytes' type if you intend to send raw bytes. [libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/wire_format_lite.cc:584] String fie",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/870
https://github.com/google/deepvariant/issues/870:1969,interoperability,protocol,protocol,1969,"E_NAME=$(basename ""${BAM_FILE}"" .bam). # Define the output VCF file name. VCF_FILE=""${VCF_DIR}/${BASE_NAME}.vcf.gz"". echo $BAM_FILE. echo $VCF_FILE. singularity exec --bind /usr/lib/locale/ \. docker://google/deepvariant:${BIN_VERSION} \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref $REFERENCE \. --reads $BAM_FILE \. --regions 6:32509320-32669663 \. --output_vcf $VCF_FILE \. --num_shards 12. done. ``` . - Error trace: . ```. ***** Running the command:*****. time seq 0 11 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""Reference_HLA/chr6_hg19.fa"" --reads ""./MDC05_1463_3.final.bam"" --examples ""/tmp/7361351.1.gpu.q/tmpzsp9g_vq/make_examples.tfrecord@12.gz"" --channels ""insert_size"" --regions ""chr6:32509320-32669663"" --task {}. [libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/wire_format_lite.cc:584] String field 'nucleus.genomics.v1.Program.command_line' contains invalid UTF-8 data when serializing a protocol buffer. Use the 'bytes' type if you intend to send raw bytes. [libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/wire_format_lite.cc:584] String field 'nucleus.genomics.v1.Program.command_line' contains invalid UTF-8 data when parsing a protocol buffer. Use the 'bytes' type if you intend to send raw bytes. Traceback (most recent call last):. File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 234, in <module>. app.run(main). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 220, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/7361351.1.gpu.q/Bazel.runfi",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/870
https://github.com/google/deepvariant/issues/870:2232,interoperability,protocol,protocol,2232,"_deepvariant \. --model_type WES \. --ref $REFERENCE \. --reads $BAM_FILE \. --regions 6:32509320-32669663 \. --output_vcf $VCF_FILE \. --num_shards 12. done. ``` . - Error trace: . ```. ***** Running the command:*****. time seq 0 11 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""Reference_HLA/chr6_hg19.fa"" --reads ""./MDC05_1463_3.final.bam"" --examples ""/tmp/7361351.1.gpu.q/tmpzsp9g_vq/make_examples.tfrecord@12.gz"" --channels ""insert_size"" --regions ""chr6:32509320-32669663"" --task {}. [libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/wire_format_lite.cc:584] String field 'nucleus.genomics.v1.Program.command_line' contains invalid UTF-8 data when serializing a protocol buffer. Use the 'bytes' type if you intend to send raw bytes. [libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/wire_format_lite.cc:584] String field 'nucleus.genomics.v1.Program.command_line' contains invalid UTF-8 data when parsing a protocol buffer. Use the 'bytes' type if you intend to send raw bytes. Traceback (most recent call last):. File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 234, in <module>. app.run(main). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 220, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 157, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvaria",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/870
https://github.com/google/deepvariant/issues/870:4153,interoperability,messag,message,4153,"ys.exit(main(argv)). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 220, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 157, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 109, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 170, in assign_sample_name. with sam.SamReader(reads_filenames.split(',')[0]) as sam_reader:. File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 260, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 240, in __init__. self.header = self._reader.header. google.protobuf.message.DecodeError: Error parsing message. ```. I ran the WES example from you with no problem, but I experience issues with my own data (I have the same setup when running singularity). . I checked the reference and input bam files, they don't seem to be corrupted... but just googling the error did not help much. Cannot think of anything else, maybe you have some suggestions where the problem could be coming from? Otherwise I will try to find the raw data for my .bam files and do remapping to hg38 and use the ref that worked previously. . Thanks again!! Alisa.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/870
https://github.com/google/deepvariant/issues/870:4188,interoperability,messag,message,4188,"ys.exit(main(argv)). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 220, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 157, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 109, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 170, in assign_sample_name. with sam.SamReader(reads_filenames.split(',')[0]) as sam_reader:. File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 260, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 240, in __init__. self.header = self._reader.header. google.protobuf.message.DecodeError: Error parsing message. ```. I ran the WES example from you with no problem, but I experience issues with my own data (I have the same setup when running singularity). . I checked the reference and input bam files, they don't seem to be corrupted... but just googling the error did not help much. Cannot think of anything else, maybe you have some suggestions where the problem could be coming from? Otherwise I will try to find the raw data for my .bam files and do remapping to hg38 and use the ref that worked previously. . Thanks again!! Alisa.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/870
https://github.com/google/deepvariant/issues/870:275,modifiability,version,version,275,"[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/wire_format_lite.cc:584]; Hi, so sorry for asking something again. But I really want to use mostly DeepVariant for variant calling. . **Setup**. - Operating system: Red Hat Enterprise Linux 9. - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): Docker. - Type of data: WES mapped to hg19. **My code:**. - Commands: . ```. #!/bin/bash. #$ -l m_mem_free=200G. #$ -l os=rhel9. #$ -m bea. #$ -cwd. #$ -pe smp 2. #$ -o deepvariant_output.log. #$ -e deepvariant_error.log. cd path/to/deepvariant. BAM_DIR=. VCF_DIR=deepvariant_output/. REFERENCE=Reference_HLA/human_g1k_v37_decoy.fasta. export SINGULARITY_CACHEDIR=""path/to/deepvariant/.singularity-$(whoami)"". export SINGULARITY_TMPDIR=""path/to/deepvariant/.singularity-$(whoami)"". BIN_VERSION=""1.6.1"". for BAM_FILE in ""${BAM_DIR}""/*.bam; do. # Extract the base name of the BAM file (without the directory and extension). BASE_NAME=$(basename ""${BAM_FILE}"" .bam). # Define the output VCF file name. VCF_FILE=""${VCF_DIR}/${BASE_NAME}.vcf.gz"". echo $BAM_FILE. echo $VCF_FILE. singularity exec --bind /usr/lib/locale/ \. docker://google/deepvariant:${BIN_VERSION} \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref $REFERENCE \. --reads $BAM_FILE \. --regions 6:32509320-32669663 \. --output_vcf $VCF_FILE \. --num_shards 12. done. ``` . - Error trace: . ```. ***** Running the command:*****. time seq 0 11 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""Reference_HLA/chr6_hg19.fa"" --reads ""./MDC05_1463_3.final.bam"" --examples ""/tmp/7361351.1.gpu.q/tmpzsp9g_vq/make_examples.tfrecord@12.gz"" --channels ""insert_size"" --regions ""chr6:32509320-32669663"" --task {}. [libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/wire_format_lite.cc:584] String field 'nucleus.genomics.v1.Program.command_line' contains invalid UTF-8 data when serializing a protocol buffer. Use the 'bytes",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/870
https://github.com/google/deepvariant/issues/870:958,modifiability,extens,extension,958,"[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/wire_format_lite.cc:584]; Hi, so sorry for asking something again. But I really want to use mostly DeepVariant for variant calling. . **Setup**. - Operating system: Red Hat Enterprise Linux 9. - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): Docker. - Type of data: WES mapped to hg19. **My code:**. - Commands: . ```. #!/bin/bash. #$ -l m_mem_free=200G. #$ -l os=rhel9. #$ -m bea. #$ -cwd. #$ -pe smp 2. #$ -o deepvariant_output.log. #$ -e deepvariant_error.log. cd path/to/deepvariant. BAM_DIR=. VCF_DIR=deepvariant_output/. REFERENCE=Reference_HLA/human_g1k_v37_decoy.fasta. export SINGULARITY_CACHEDIR=""path/to/deepvariant/.singularity-$(whoami)"". export SINGULARITY_TMPDIR=""path/to/deepvariant/.singularity-$(whoami)"". BIN_VERSION=""1.6.1"". for BAM_FILE in ""${BAM_DIR}""/*.bam; do. # Extract the base name of the BAM file (without the directory and extension). BASE_NAME=$(basename ""${BAM_FILE}"" .bam). # Define the output VCF file name. VCF_FILE=""${VCF_DIR}/${BASE_NAME}.vcf.gz"". echo $BAM_FILE. echo $VCF_FILE. singularity exec --bind /usr/lib/locale/ \. docker://google/deepvariant:${BIN_VERSION} \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref $REFERENCE \. --reads $BAM_FILE \. --regions 6:32509320-32669663 \. --output_vcf $VCF_FILE \. --num_shards 12. done. ``` . - Error trace: . ```. ***** Running the command:*****. time seq 0 11 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""Reference_HLA/chr6_hg19.fa"" --reads ""./MDC05_1463_3.final.bam"" --examples ""/tmp/7361351.1.gpu.q/tmpzsp9g_vq/make_examples.tfrecord@12.gz"" --channels ""insert_size"" --regions ""chr6:32509320-32669663"" --task {}. [libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/wire_format_lite.cc:584] String field 'nucleus.genomics.v1.Program.command_line' contains invalid UTF-8 data when serializing a protocol buffer. Use the 'bytes",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/870
https://github.com/google/deepvariant/issues/870:1141,modifiability,bind,bind,1141,"ally want to use mostly DeepVariant for variant calling. . **Setup**. - Operating system: Red Hat Enterprise Linux 9. - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): Docker. - Type of data: WES mapped to hg19. **My code:**. - Commands: . ```. #!/bin/bash. #$ -l m_mem_free=200G. #$ -l os=rhel9. #$ -m bea. #$ -cwd. #$ -pe smp 2. #$ -o deepvariant_output.log. #$ -e deepvariant_error.log. cd path/to/deepvariant. BAM_DIR=. VCF_DIR=deepvariant_output/. REFERENCE=Reference_HLA/human_g1k_v37_decoy.fasta. export SINGULARITY_CACHEDIR=""path/to/deepvariant/.singularity-$(whoami)"". export SINGULARITY_TMPDIR=""path/to/deepvariant/.singularity-$(whoami)"". BIN_VERSION=""1.6.1"". for BAM_FILE in ""${BAM_DIR}""/*.bam; do. # Extract the base name of the BAM file (without the directory and extension). BASE_NAME=$(basename ""${BAM_FILE}"" .bam). # Define the output VCF file name. VCF_FILE=""${VCF_DIR}/${BASE_NAME}.vcf.gz"". echo $BAM_FILE. echo $VCF_FILE. singularity exec --bind /usr/lib/locale/ \. docker://google/deepvariant:${BIN_VERSION} \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref $REFERENCE \. --reads $BAM_FILE \. --regions 6:32509320-32669663 \. --output_vcf $VCF_FILE \. --num_shards 12. done. ``` . - Error trace: . ```. ***** Running the command:*****. time seq 0 11 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""Reference_HLA/chr6_hg19.fa"" --reads ""./MDC05_1463_3.final.bam"" --examples ""/tmp/7361351.1.gpu.q/tmpzsp9g_vq/make_examples.tfrecord@12.gz"" --channels ""insert_size"" --regions ""chr6:32509320-32669663"" --task {}. [libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/wire_format_lite.cc:584] String field 'nucleus.genomics.v1.Program.command_line' contains invalid UTF-8 data when serializing a protocol buffer. Use the 'bytes' type if you intend to send raw bytes. [libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/wire_format_lite.cc:584] String fie",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/870
https://github.com/google/deepvariant/issues/870:2467,modifiability,modul,module,2467,"| parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""Reference_HLA/chr6_hg19.fa"" --reads ""./MDC05_1463_3.final.bam"" --examples ""/tmp/7361351.1.gpu.q/tmpzsp9g_vq/make_examples.tfrecord@12.gz"" --channels ""insert_size"" --regions ""chr6:32509320-32669663"" --task {}. [libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/wire_format_lite.cc:584] String field 'nucleus.genomics.v1.Program.command_line' contains invalid UTF-8 data when serializing a protocol buffer. Use the 'bytes' type if you intend to send raw bytes. [libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/wire_format_lite.cc:584] String field 'nucleus.genomics.v1.Program.command_line' contains invalid UTF-8 data when parsing a protocol buffer. Use the 'bytes' type if you intend to send raw bytes. Traceback (most recent call last):. File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 234, in <module>. app.run(main). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 220, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 157, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 109, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", lin",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/870
https://github.com/google/deepvariant/issues/870:4161,modifiability,Deco,DecodeError,4161,"ys.exit(main(argv)). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 220, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 157, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 109, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 170, in assign_sample_name. with sam.SamReader(reads_filenames.split(',')[0]) as sam_reader:. File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 260, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 240, in __init__. self.header = self._reader.header. google.protobuf.message.DecodeError: Error parsing message. ```. I ran the WES example from you with no problem, but I experience issues with my own data (I have the same setup when running singularity). . I checked the reference and input bam files, they don't seem to be corrupted... but just googling the error did not help much. Cannot think of anything else, maybe you have some suggestions where the problem could be coming from? Otherwise I will try to find the raw data for my .bam files and do remapping to hg38 and use the ref that worked previously. . Thanks again!! Alisa.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/870
https://github.com/google/deepvariant/issues/870:13,performance,ERROR,ERROR,13,"[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/wire_format_lite.cc:584]; Hi, so sorry for asking something again. But I really want to use mostly DeepVariant for variant calling. . **Setup**. - Operating system: Red Hat Enterprise Linux 9. - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): Docker. - Type of data: WES mapped to hg19. **My code:**. - Commands: . ```. #!/bin/bash. #$ -l m_mem_free=200G. #$ -l os=rhel9. #$ -m bea. #$ -cwd. #$ -pe smp 2. #$ -o deepvariant_output.log. #$ -e deepvariant_error.log. cd path/to/deepvariant. BAM_DIR=. VCF_DIR=deepvariant_output/. REFERENCE=Reference_HLA/human_g1k_v37_decoy.fasta. export SINGULARITY_CACHEDIR=""path/to/deepvariant/.singularity-$(whoami)"". export SINGULARITY_TMPDIR=""path/to/deepvariant/.singularity-$(whoami)"". BIN_VERSION=""1.6.1"". for BAM_FILE in ""${BAM_DIR}""/*.bam; do. # Extract the base name of the BAM file (without the directory and extension). BASE_NAME=$(basename ""${BAM_FILE}"" .bam). # Define the output VCF file name. VCF_FILE=""${VCF_DIR}/${BASE_NAME}.vcf.gz"". echo $BAM_FILE. echo $VCF_FILE. singularity exec --bind /usr/lib/locale/ \. docker://google/deepvariant:${BIN_VERSION} \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref $REFERENCE \. --reads $BAM_FILE \. --regions 6:32509320-32669663 \. --output_vcf $VCF_FILE \. --num_shards 12. done. ``` . - Error trace: . ```. ***** Running the command:*****. time seq 0 11 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""Reference_HLA/chr6_hg19.fa"" --reads ""./MDC05_1463_3.final.bam"" --examples ""/tmp/7361351.1.gpu.q/tmpzsp9g_vq/make_examples.tfrecord@12.gz"" --channels ""insert_size"" --regions ""chr6:32509320-32669663"" --task {}. [libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/wire_format_lite.cc:584] String field 'nucleus.genomics.v1.Program.command_line' contains invalid UTF-8 data when serializing a protocol buffer. Use the 'bytes",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/870
https://github.com/google/deepvariant/issues/870:1403,performance,Error,Error,1403,"- Commands: . ```. #!/bin/bash. #$ -l m_mem_free=200G. #$ -l os=rhel9. #$ -m bea. #$ -cwd. #$ -pe smp 2. #$ -o deepvariant_output.log. #$ -e deepvariant_error.log. cd path/to/deepvariant. BAM_DIR=. VCF_DIR=deepvariant_output/. REFERENCE=Reference_HLA/human_g1k_v37_decoy.fasta. export SINGULARITY_CACHEDIR=""path/to/deepvariant/.singularity-$(whoami)"". export SINGULARITY_TMPDIR=""path/to/deepvariant/.singularity-$(whoami)"". BIN_VERSION=""1.6.1"". for BAM_FILE in ""${BAM_DIR}""/*.bam; do. # Extract the base name of the BAM file (without the directory and extension). BASE_NAME=$(basename ""${BAM_FILE}"" .bam). # Define the output VCF file name. VCF_FILE=""${VCF_DIR}/${BASE_NAME}.vcf.gz"". echo $BAM_FILE. echo $VCF_FILE. singularity exec --bind /usr/lib/locale/ \. docker://google/deepvariant:${BIN_VERSION} \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref $REFERENCE \. --reads $BAM_FILE \. --regions 6:32509320-32669663 \. --output_vcf $VCF_FILE \. --num_shards 12. done. ``` . - Error trace: . ```. ***** Running the command:*****. time seq 0 11 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""Reference_HLA/chr6_hg19.fa"" --reads ""./MDC05_1463_3.final.bam"" --examples ""/tmp/7361351.1.gpu.q/tmpzsp9g_vq/make_examples.tfrecord@12.gz"" --channels ""insert_size"" --regions ""chr6:32509320-32669663"" --task {}. [libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/wire_format_lite.cc:584] String field 'nucleus.genomics.v1.Program.command_line' contains invalid UTF-8 data when serializing a protocol buffer. Use the 'bytes' type if you intend to send raw bytes. [libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/wire_format_lite.cc:584] String field 'nucleus.genomics.v1.Program.command_line' contains invalid UTF-8 data when parsing a protocol buffer. Use the 'bytes' type if you intend to send raw bytes. Traceback (most recent call last):. File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_goo",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/870
https://github.com/google/deepvariant/issues/870:1456,performance,time,time,1456,"G. #$ -l os=rhel9. #$ -m bea. #$ -cwd. #$ -pe smp 2. #$ -o deepvariant_output.log. #$ -e deepvariant_error.log. cd path/to/deepvariant. BAM_DIR=. VCF_DIR=deepvariant_output/. REFERENCE=Reference_HLA/human_g1k_v37_decoy.fasta. export SINGULARITY_CACHEDIR=""path/to/deepvariant/.singularity-$(whoami)"". export SINGULARITY_TMPDIR=""path/to/deepvariant/.singularity-$(whoami)"". BIN_VERSION=""1.6.1"". for BAM_FILE in ""${BAM_DIR}""/*.bam; do. # Extract the base name of the BAM file (without the directory and extension). BASE_NAME=$(basename ""${BAM_FILE}"" .bam). # Define the output VCF file name. VCF_FILE=""${VCF_DIR}/${BASE_NAME}.vcf.gz"". echo $BAM_FILE. echo $VCF_FILE. singularity exec --bind /usr/lib/locale/ \. docker://google/deepvariant:${BIN_VERSION} \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref $REFERENCE \. --reads $BAM_FILE \. --regions 6:32509320-32669663 \. --output_vcf $VCF_FILE \. --num_shards 12. done. ``` . - Error trace: . ```. ***** Running the command:*****. time seq 0 11 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""Reference_HLA/chr6_hg19.fa"" --reads ""./MDC05_1463_3.final.bam"" --examples ""/tmp/7361351.1.gpu.q/tmpzsp9g_vq/make_examples.tfrecord@12.gz"" --channels ""insert_size"" --regions ""chr6:32509320-32669663"" --task {}. [libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/wire_format_lite.cc:584] String field 'nucleus.genomics.v1.Program.command_line' contains invalid UTF-8 data when serializing a protocol buffer. Use the 'bytes' type if you intend to send raw bytes. [libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/wire_format_lite.cc:584] String field 'nucleus.genomics.v1.Program.command_line' contains invalid UTF-8 data when parsing a protocol buffer. Use the 'bytes' type if you intend to send raw bytes. Traceback (most recent call last):. File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/870
https://github.com/google/deepvariant/issues/870:1472,performance,parallel,parallel,1472," #$ -m bea. #$ -cwd. #$ -pe smp 2. #$ -o deepvariant_output.log. #$ -e deepvariant_error.log. cd path/to/deepvariant. BAM_DIR=. VCF_DIR=deepvariant_output/. REFERENCE=Reference_HLA/human_g1k_v37_decoy.fasta. export SINGULARITY_CACHEDIR=""path/to/deepvariant/.singularity-$(whoami)"". export SINGULARITY_TMPDIR=""path/to/deepvariant/.singularity-$(whoami)"". BIN_VERSION=""1.6.1"". for BAM_FILE in ""${BAM_DIR}""/*.bam; do. # Extract the base name of the BAM file (without the directory and extension). BASE_NAME=$(basename ""${BAM_FILE}"" .bam). # Define the output VCF file name. VCF_FILE=""${VCF_DIR}/${BASE_NAME}.vcf.gz"". echo $BAM_FILE. echo $VCF_FILE. singularity exec --bind /usr/lib/locale/ \. docker://google/deepvariant:${BIN_VERSION} \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref $REFERENCE \. --reads $BAM_FILE \. --regions 6:32509320-32669663 \. --output_vcf $VCF_FILE \. --num_shards 12. done. ``` . - Error trace: . ```. ***** Running the command:*****. time seq 0 11 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""Reference_HLA/chr6_hg19.fa"" --reads ""./MDC05_1463_3.final.bam"" --examples ""/tmp/7361351.1.gpu.q/tmpzsp9g_vq/make_examples.tfrecord@12.gz"" --channels ""insert_size"" --regions ""chr6:32509320-32669663"" --task {}. [libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/wire_format_lite.cc:584] String field 'nucleus.genomics.v1.Program.command_line' contains invalid UTF-8 data when serializing a protocol buffer. Use the 'bytes' type if you intend to send raw bytes. [libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/wire_format_lite.cc:584] String field 'nucleus.genomics.v1.Program.command_line' contains invalid UTF-8 data when parsing a protocol buffer. Use the 'bytes' type if you intend to send raw bytes. Traceback (most recent call last):. File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 234, in <module>. ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/870
https://github.com/google/deepvariant/issues/870:1654,performance,gpu,gpu,1654,"/human_g1k_v37_decoy.fasta. export SINGULARITY_CACHEDIR=""path/to/deepvariant/.singularity-$(whoami)"". export SINGULARITY_TMPDIR=""path/to/deepvariant/.singularity-$(whoami)"". BIN_VERSION=""1.6.1"". for BAM_FILE in ""${BAM_DIR}""/*.bam; do. # Extract the base name of the BAM file (without the directory and extension). BASE_NAME=$(basename ""${BAM_FILE}"" .bam). # Define the output VCF file name. VCF_FILE=""${VCF_DIR}/${BASE_NAME}.vcf.gz"". echo $BAM_FILE. echo $VCF_FILE. singularity exec --bind /usr/lib/locale/ \. docker://google/deepvariant:${BIN_VERSION} \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref $REFERENCE \. --reads $BAM_FILE \. --regions 6:32509320-32669663 \. --output_vcf $VCF_FILE \. --num_shards 12. done. ``` . - Error trace: . ```. ***** Running the command:*****. time seq 0 11 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""Reference_HLA/chr6_hg19.fa"" --reads ""./MDC05_1463_3.final.bam"" --examples ""/tmp/7361351.1.gpu.q/tmpzsp9g_vq/make_examples.tfrecord@12.gz"" --channels ""insert_size"" --regions ""chr6:32509320-32669663"" --task {}. [libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/wire_format_lite.cc:584] String field 'nucleus.genomics.v1.Program.command_line' contains invalid UTF-8 data when serializing a protocol buffer. Use the 'bytes' type if you intend to send raw bytes. [libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/wire_format_lite.cc:584] String field 'nucleus.genomics.v1.Program.command_line' contains invalid UTF-8 data when parsing a protocol buffer. Use the 'bytes' type if you intend to send raw bytes. Traceback (most recent call last):. File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 234, in <module>. app.run(main). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/870
https://github.com/google/deepvariant/issues/870:1786,performance,ERROR,ERROR,1786,"/to/deepvariant/.singularity-$(whoami)"". BIN_VERSION=""1.6.1"". for BAM_FILE in ""${BAM_DIR}""/*.bam; do. # Extract the base name of the BAM file (without the directory and extension). BASE_NAME=$(basename ""${BAM_FILE}"" .bam). # Define the output VCF file name. VCF_FILE=""${VCF_DIR}/${BASE_NAME}.vcf.gz"". echo $BAM_FILE. echo $VCF_FILE. singularity exec --bind /usr/lib/locale/ \. docker://google/deepvariant:${BIN_VERSION} \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref $REFERENCE \. --reads $BAM_FILE \. --regions 6:32509320-32669663 \. --output_vcf $VCF_FILE \. --num_shards 12. done. ``` . - Error trace: . ```. ***** Running the command:*****. time seq 0 11 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""Reference_HLA/chr6_hg19.fa"" --reads ""./MDC05_1463_3.final.bam"" --examples ""/tmp/7361351.1.gpu.q/tmpzsp9g_vq/make_examples.tfrecord@12.gz"" --channels ""insert_size"" --regions ""chr6:32509320-32669663"" --task {}. [libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/wire_format_lite.cc:584] String field 'nucleus.genomics.v1.Program.command_line' contains invalid UTF-8 data when serializing a protocol buffer. Use the 'bytes' type if you intend to send raw bytes. [libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/wire_format_lite.cc:584] String field 'nucleus.genomics.v1.Program.command_line' contains invalid UTF-8 data when parsing a protocol buffer. Use the 'bytes' type if you intend to send raw bytes. Traceback (most recent call last):. File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 234, in <module>. app.run(main). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/870
https://github.com/google/deepvariant/issues/870:2053,performance,ERROR,ERROR,2053,"""${VCF_DIR}/${BASE_NAME}.vcf.gz"". echo $BAM_FILE. echo $VCF_FILE. singularity exec --bind /usr/lib/locale/ \. docker://google/deepvariant:${BIN_VERSION} \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref $REFERENCE \. --reads $BAM_FILE \. --regions 6:32509320-32669663 \. --output_vcf $VCF_FILE \. --num_shards 12. done. ``` . - Error trace: . ```. ***** Running the command:*****. time seq 0 11 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""Reference_HLA/chr6_hg19.fa"" --reads ""./MDC05_1463_3.final.bam"" --examples ""/tmp/7361351.1.gpu.q/tmpzsp9g_vq/make_examples.tfrecord@12.gz"" --channels ""insert_size"" --regions ""chr6:32509320-32669663"" --task {}. [libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/wire_format_lite.cc:584] String field 'nucleus.genomics.v1.Program.command_line' contains invalid UTF-8 data when serializing a protocol buffer. Use the 'bytes' type if you intend to send raw bytes. [libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/wire_format_lite.cc:584] String field 'nucleus.genomics.v1.Program.command_line' contains invalid UTF-8 data when parsing a protocol buffer. Use the 'bytes' type if you intend to send raw bytes. Traceback (most recent call last):. File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 234, in <module>. app.run(main). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 220, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 15",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/870
https://github.com/google/deepvariant/issues/870:2360,performance,gpu,gpu,2360,"F_FILE \. --num_shards 12. done. ``` . - Error trace: . ```. ***** Running the command:*****. time seq 0 11 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""Reference_HLA/chr6_hg19.fa"" --reads ""./MDC05_1463_3.final.bam"" --examples ""/tmp/7361351.1.gpu.q/tmpzsp9g_vq/make_examples.tfrecord@12.gz"" --channels ""insert_size"" --regions ""chr6:32509320-32669663"" --task {}. [libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/wire_format_lite.cc:584] String field 'nucleus.genomics.v1.Program.command_line' contains invalid UTF-8 data when serializing a protocol buffer. Use the 'bytes' type if you intend to send raw bytes. [libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/wire_format_lite.cc:584] String field 'nucleus.genomics.v1.Program.command_line' contains invalid UTF-8 data when parsing a protocol buffer. Use the 'bytes' type if you intend to send raw bytes. Traceback (most recent call last):. File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 234, in <module>. app.run(main). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 220, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 157, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 109, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/736",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/870
https://github.com/google/deepvariant/issues/870:2512,performance,gpu,gpu,2512,"epvariant/bin/make_examples --mode calling --ref ""Reference_HLA/chr6_hg19.fa"" --reads ""./MDC05_1463_3.final.bam"" --examples ""/tmp/7361351.1.gpu.q/tmpzsp9g_vq/make_examples.tfrecord@12.gz"" --channels ""insert_size"" --regions ""chr6:32509320-32669663"" --task {}. [libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/wire_format_lite.cc:584] String field 'nucleus.genomics.v1.Program.command_line' contains invalid UTF-8 data when serializing a protocol buffer. Use the 'bytes' type if you intend to send raw bytes. [libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/wire_format_lite.cc:584] String field 'nucleus.genomics.v1.Program.command_line' contains invalid UTF-8 data when parsing a protocol buffer. Use the 'bytes' type if you intend to send raw bytes. Traceback (most recent call last):. File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 234, in <module>. app.run(main). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 220, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 157, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 109, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 170, in assign_sample_name. with sam.SamRe",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/870
https://github.com/google/deepvariant/issues/870:2635,performance,gpu,gpu,2635," ""/tmp/7361351.1.gpu.q/tmpzsp9g_vq/make_examples.tfrecord@12.gz"" --channels ""insert_size"" --regions ""chr6:32509320-32669663"" --task {}. [libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/wire_format_lite.cc:584] String field 'nucleus.genomics.v1.Program.command_line' contains invalid UTF-8 data when serializing a protocol buffer. Use the 'bytes' type if you intend to send raw bytes. [libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/wire_format_lite.cc:584] String field 'nucleus.genomics.v1.Program.command_line' contains invalid UTF-8 data when parsing a protocol buffer. Use the 'bytes' type if you intend to send raw bytes. Traceback (most recent call last):. File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 234, in <module>. app.run(main). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 220, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 157, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 109, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 170, in assign_sample_name. with sam.SamReader(reads_filenames.split(',')[0]) as sam_reader:. File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/870
https://github.com/google/deepvariant/issues/870:2763,performance,gpu,gpu,2763,"ask {}. [libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/wire_format_lite.cc:584] String field 'nucleus.genomics.v1.Program.command_line' contains invalid UTF-8 data when serializing a protocol buffer. Use the 'bytes' type if you intend to send raw bytes. [libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/wire_format_lite.cc:584] String field 'nucleus.genomics.v1.Program.command_line' contains invalid UTF-8 data when parsing a protocol buffer. Use the 'bytes' type if you intend to send raw bytes. Traceback (most recent call last):. File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 234, in <module>. app.run(main). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 220, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 157, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 109, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 170, in assign_sample_name. with sam.SamReader(reads_filenames.split(',')[0]) as sam_reader:. File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/870
https://github.com/google/deepvariant/issues/870:2956,performance,gpu,gpu,2956,"ializing a protocol buffer. Use the 'bytes' type if you intend to send raw bytes. [libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/wire_format_lite.cc:584] String field 'nucleus.genomics.v1.Program.command_line' contains invalid UTF-8 data when parsing a protocol buffer. Use the 'bytes' type if you intend to send raw bytes. Traceback (most recent call last):. File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 234, in <module>. app.run(main). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 220, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 157, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 109, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 170, in assign_sample_name. with sam.SamReader(reads_filenames.split(',')[0]) as sam_reader:. File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 260, in _native_reader. return NativeSamReader(input_path, **kwa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/870
https://github.com/google/deepvariant/issues/870:3165,performance,gpu,gpu,3165,"Program.command_line' contains invalid UTF-8 data when parsing a protocol buffer. Use the 'bytes' type if you intend to send raw bytes. Traceback (most recent call last):. File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 234, in <module>. app.run(main). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 220, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 157, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 109, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 170, in assign_sample_name. with sam.SamReader(reads_filenames.split(',')[0]) as sam_reader:. File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 260, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 240, in __init__. self.header = self._reader.header. google.protobuf.message.Decode",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/870
https://github.com/google/deepvariant/issues/870:3369,performance,gpu,gpu,3369,".runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 234, in <module>. app.run(main). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 220, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 157, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 109, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 170, in assign_sample_name. with sam.SamReader(reads_filenames.split(',')[0]) as sam_reader:. File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 260, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 240, in __init__. self.header = self._reader.header. google.protobuf.message.DecodeError: Error parsing message. ```. I ran the WES example from you with no problem, but I experience issues with my own data (I have the same setup when running singularity). . I checked the reference and ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/870
https://github.com/google/deepvariant/issues/870:3587,performance,gpu,gpu,3587,". _run_main(main, args). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 220, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 157, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 109, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 170, in assign_sample_name. with sam.SamReader(reads_filenames.split(',')[0]) as sam_reader:. File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 260, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 240, in __init__. self.header = self._reader.header. google.protobuf.message.DecodeError: Error parsing message. ```. I ran the WES example from you with no problem, but I experience issues with my own data (I have the same setup when running singularity). . I checked the reference and input bam files, they don't seem to be corrupted... but just googling the error did not help much. Cannot think of anything else, maybe you have some suggestions where the problem could be coming from? Otherwise I will",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/870
https://github.com/google/deepvariant/issues/870:3795,performance,gpu,gpu,3795,"ys.exit(main(argv)). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 220, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 157, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 109, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 170, in assign_sample_name. with sam.SamReader(reads_filenames.split(',')[0]) as sam_reader:. File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 260, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 240, in __init__. self.header = self._reader.header. google.protobuf.message.DecodeError: Error parsing message. ```. I ran the WES example from you with no problem, but I experience issues with my own data (I have the same setup when running singularity). . I checked the reference and input bam files, they don't seem to be corrupted... but just googling the error did not help much. Cannot think of anything else, maybe you have some suggestions where the problem could be coming from? Otherwise I will try to find the raw data for my .bam files and do remapping to hg38 and use the ref that worked previously. . Thanks again!! Alisa.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/870
https://github.com/google/deepvariant/issues/870:3985,performance,gpu,gpu,3985,"ys.exit(main(argv)). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 220, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 157, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 109, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 170, in assign_sample_name. with sam.SamReader(reads_filenames.split(',')[0]) as sam_reader:. File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 260, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 240, in __init__. self.header = self._reader.header. google.protobuf.message.DecodeError: Error parsing message. ```. I ran the WES example from you with no problem, but I experience issues with my own data (I have the same setup when running singularity). . I checked the reference and input bam files, they don't seem to be corrupted... but just googling the error did not help much. Cannot think of anything else, maybe you have some suggestions where the problem could be coming from? Otherwise I will try to find the raw data for my .bam files and do remapping to hg38 and use the ref that worked previously. . Thanks again!! Alisa.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/870
https://github.com/google/deepvariant/issues/870:4174,performance,Error,Error,4174,"ys.exit(main(argv)). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 220, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 157, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 109, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 170, in assign_sample_name. with sam.SamReader(reads_filenames.split(',')[0]) as sam_reader:. File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 260, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 240, in __init__. self.header = self._reader.header. google.protobuf.message.DecodeError: Error parsing message. ```. I ran the WES example from you with no problem, but I experience issues with my own data (I have the same setup when running singularity). . I checked the reference and input bam files, they don't seem to be corrupted... but just googling the error did not help much. Cannot think of anything else, maybe you have some suggestions where the problem could be coming from? Otherwise I will try to find the raw data for my .bam files and do remapping to hg38 and use the ref that worked previously. . Thanks again!! Alisa.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/870
https://github.com/google/deepvariant/issues/870:4445,performance,error,error,4445,"ys.exit(main(argv)). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 220, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 157, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 109, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 170, in assign_sample_name. with sam.SamReader(reads_filenames.split(',')[0]) as sam_reader:. File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 260, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 240, in __init__. self.header = self._reader.header. google.protobuf.message.DecodeError: Error parsing message. ```. I ran the WES example from you with no problem, but I experience issues with my own data (I have the same setup when running singularity). . I checked the reference and input bam files, they don't seem to be corrupted... but just googling the error did not help much. Cannot think of anything else, maybe you have some suggestions where the problem could be coming from? Otherwise I will try to find the raw data for my .bam files and do remapping to hg38 and use the ref that worked previously. . Thanks again!! Alisa.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/870
https://github.com/google/deepvariant/issues/870:13,safety,ERROR,ERROR,13,"[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/wire_format_lite.cc:584]; Hi, so sorry for asking something again. But I really want to use mostly DeepVariant for variant calling. . **Setup**. - Operating system: Red Hat Enterprise Linux 9. - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): Docker. - Type of data: WES mapped to hg19. **My code:**. - Commands: . ```. #!/bin/bash. #$ -l m_mem_free=200G. #$ -l os=rhel9. #$ -m bea. #$ -cwd. #$ -pe smp 2. #$ -o deepvariant_output.log. #$ -e deepvariant_error.log. cd path/to/deepvariant. BAM_DIR=. VCF_DIR=deepvariant_output/. REFERENCE=Reference_HLA/human_g1k_v37_decoy.fasta. export SINGULARITY_CACHEDIR=""path/to/deepvariant/.singularity-$(whoami)"". export SINGULARITY_TMPDIR=""path/to/deepvariant/.singularity-$(whoami)"". BIN_VERSION=""1.6.1"". for BAM_FILE in ""${BAM_DIR}""/*.bam; do. # Extract the base name of the BAM file (without the directory and extension). BASE_NAME=$(basename ""${BAM_FILE}"" .bam). # Define the output VCF file name. VCF_FILE=""${VCF_DIR}/${BASE_NAME}.vcf.gz"". echo $BAM_FILE. echo $VCF_FILE. singularity exec --bind /usr/lib/locale/ \. docker://google/deepvariant:${BIN_VERSION} \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref $REFERENCE \. --reads $BAM_FILE \. --regions 6:32509320-32669663 \. --output_vcf $VCF_FILE \. --num_shards 12. done. ``` . - Error trace: . ```. ***** Running the command:*****. time seq 0 11 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""Reference_HLA/chr6_hg19.fa"" --reads ""./MDC05_1463_3.final.bam"" --examples ""/tmp/7361351.1.gpu.q/tmpzsp9g_vq/make_examples.tfrecord@12.gz"" --channels ""insert_size"" --regions ""chr6:32509320-32669663"" --task {}. [libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/wire_format_lite.cc:584] String field 'nucleus.genomics.v1.Program.command_line' contains invalid UTF-8 data when serializing a protocol buffer. Use the 'bytes",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/870
https://github.com/google/deepvariant/issues/870:536,safety,log,log,536,"[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/wire_format_lite.cc:584]; Hi, so sorry for asking something again. But I really want to use mostly DeepVariant for variant calling. . **Setup**. - Operating system: Red Hat Enterprise Linux 9. - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): Docker. - Type of data: WES mapped to hg19. **My code:**. - Commands: . ```. #!/bin/bash. #$ -l m_mem_free=200G. #$ -l os=rhel9. #$ -m bea. #$ -cwd. #$ -pe smp 2. #$ -o deepvariant_output.log. #$ -e deepvariant_error.log. cd path/to/deepvariant. BAM_DIR=. VCF_DIR=deepvariant_output/. REFERENCE=Reference_HLA/human_g1k_v37_decoy.fasta. export SINGULARITY_CACHEDIR=""path/to/deepvariant/.singularity-$(whoami)"". export SINGULARITY_TMPDIR=""path/to/deepvariant/.singularity-$(whoami)"". BIN_VERSION=""1.6.1"". for BAM_FILE in ""${BAM_DIR}""/*.bam; do. # Extract the base name of the BAM file (without the directory and extension). BASE_NAME=$(basename ""${BAM_FILE}"" .bam). # Define the output VCF file name. VCF_FILE=""${VCF_DIR}/${BASE_NAME}.vcf.gz"". echo $BAM_FILE. echo $VCF_FILE. singularity exec --bind /usr/lib/locale/ \. docker://google/deepvariant:${BIN_VERSION} \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref $REFERENCE \. --reads $BAM_FILE \. --regions 6:32509320-32669663 \. --output_vcf $VCF_FILE \. --num_shards 12. done. ``` . - Error trace: . ```. ***** Running the command:*****. time seq 0 11 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""Reference_HLA/chr6_hg19.fa"" --reads ""./MDC05_1463_3.final.bam"" --examples ""/tmp/7361351.1.gpu.q/tmpzsp9g_vq/make_examples.tfrecord@12.gz"" --channels ""insert_size"" --regions ""chr6:32509320-32669663"" --task {}. [libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/wire_format_lite.cc:584] String field 'nucleus.genomics.v1.Program.command_line' contains invalid UTF-8 data when serializing a protocol buffer. Use the 'bytes",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/870
https://github.com/google/deepvariant/issues/870:565,safety,log,log,565,"[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/wire_format_lite.cc:584]; Hi, so sorry for asking something again. But I really want to use mostly DeepVariant for variant calling. . **Setup**. - Operating system: Red Hat Enterprise Linux 9. - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): Docker. - Type of data: WES mapped to hg19. **My code:**. - Commands: . ```. #!/bin/bash. #$ -l m_mem_free=200G. #$ -l os=rhel9. #$ -m bea. #$ -cwd. #$ -pe smp 2. #$ -o deepvariant_output.log. #$ -e deepvariant_error.log. cd path/to/deepvariant. BAM_DIR=. VCF_DIR=deepvariant_output/. REFERENCE=Reference_HLA/human_g1k_v37_decoy.fasta. export SINGULARITY_CACHEDIR=""path/to/deepvariant/.singularity-$(whoami)"". export SINGULARITY_TMPDIR=""path/to/deepvariant/.singularity-$(whoami)"". BIN_VERSION=""1.6.1"". for BAM_FILE in ""${BAM_DIR}""/*.bam; do. # Extract the base name of the BAM file (without the directory and extension). BASE_NAME=$(basename ""${BAM_FILE}"" .bam). # Define the output VCF file name. VCF_FILE=""${VCF_DIR}/${BASE_NAME}.vcf.gz"". echo $BAM_FILE. echo $VCF_FILE. singularity exec --bind /usr/lib/locale/ \. docker://google/deepvariant:${BIN_VERSION} \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref $REFERENCE \. --reads $BAM_FILE \. --regions 6:32509320-32669663 \. --output_vcf $VCF_FILE \. --num_shards 12. done. ``` . - Error trace: . ```. ***** Running the command:*****. time seq 0 11 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""Reference_HLA/chr6_hg19.fa"" --reads ""./MDC05_1463_3.final.bam"" --examples ""/tmp/7361351.1.gpu.q/tmpzsp9g_vq/make_examples.tfrecord@12.gz"" --channels ""insert_size"" --regions ""chr6:32509320-32669663"" --task {}. [libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/wire_format_lite.cc:584] String field 'nucleus.genomics.v1.Program.command_line' contains invalid UTF-8 data when serializing a protocol buffer. Use the 'bytes",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/870
https://github.com/google/deepvariant/issues/870:1403,safety,Error,Error,1403,"- Commands: . ```. #!/bin/bash. #$ -l m_mem_free=200G. #$ -l os=rhel9. #$ -m bea. #$ -cwd. #$ -pe smp 2. #$ -o deepvariant_output.log. #$ -e deepvariant_error.log. cd path/to/deepvariant. BAM_DIR=. VCF_DIR=deepvariant_output/. REFERENCE=Reference_HLA/human_g1k_v37_decoy.fasta. export SINGULARITY_CACHEDIR=""path/to/deepvariant/.singularity-$(whoami)"". export SINGULARITY_TMPDIR=""path/to/deepvariant/.singularity-$(whoami)"". BIN_VERSION=""1.6.1"". for BAM_FILE in ""${BAM_DIR}""/*.bam; do. # Extract the base name of the BAM file (without the directory and extension). BASE_NAME=$(basename ""${BAM_FILE}"" .bam). # Define the output VCF file name. VCF_FILE=""${VCF_DIR}/${BASE_NAME}.vcf.gz"". echo $BAM_FILE. echo $VCF_FILE. singularity exec --bind /usr/lib/locale/ \. docker://google/deepvariant:${BIN_VERSION} \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref $REFERENCE \. --reads $BAM_FILE \. --regions 6:32509320-32669663 \. --output_vcf $VCF_FILE \. --num_shards 12. done. ``` . - Error trace: . ```. ***** Running the command:*****. time seq 0 11 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""Reference_HLA/chr6_hg19.fa"" --reads ""./MDC05_1463_3.final.bam"" --examples ""/tmp/7361351.1.gpu.q/tmpzsp9g_vq/make_examples.tfrecord@12.gz"" --channels ""insert_size"" --regions ""chr6:32509320-32669663"" --task {}. [libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/wire_format_lite.cc:584] String field 'nucleus.genomics.v1.Program.command_line' contains invalid UTF-8 data when serializing a protocol buffer. Use the 'bytes' type if you intend to send raw bytes. [libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/wire_format_lite.cc:584] String field 'nucleus.genomics.v1.Program.command_line' contains invalid UTF-8 data when parsing a protocol buffer. Use the 'bytes' type if you intend to send raw bytes. Traceback (most recent call last):. File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_goo",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/870
https://github.com/google/deepvariant/issues/870:1786,safety,ERROR,ERROR,1786,"/to/deepvariant/.singularity-$(whoami)"". BIN_VERSION=""1.6.1"". for BAM_FILE in ""${BAM_DIR}""/*.bam; do. # Extract the base name of the BAM file (without the directory and extension). BASE_NAME=$(basename ""${BAM_FILE}"" .bam). # Define the output VCF file name. VCF_FILE=""${VCF_DIR}/${BASE_NAME}.vcf.gz"". echo $BAM_FILE. echo $VCF_FILE. singularity exec --bind /usr/lib/locale/ \. docker://google/deepvariant:${BIN_VERSION} \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref $REFERENCE \. --reads $BAM_FILE \. --regions 6:32509320-32669663 \. --output_vcf $VCF_FILE \. --num_shards 12. done. ``` . - Error trace: . ```. ***** Running the command:*****. time seq 0 11 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""Reference_HLA/chr6_hg19.fa"" --reads ""./MDC05_1463_3.final.bam"" --examples ""/tmp/7361351.1.gpu.q/tmpzsp9g_vq/make_examples.tfrecord@12.gz"" --channels ""insert_size"" --regions ""chr6:32509320-32669663"" --task {}. [libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/wire_format_lite.cc:584] String field 'nucleus.genomics.v1.Program.command_line' contains invalid UTF-8 data when serializing a protocol buffer. Use the 'bytes' type if you intend to send raw bytes. [libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/wire_format_lite.cc:584] String field 'nucleus.genomics.v1.Program.command_line' contains invalid UTF-8 data when parsing a protocol buffer. Use the 'bytes' type if you intend to send raw bytes. Traceback (most recent call last):. File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 234, in <module>. app.run(main). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/870
https://github.com/google/deepvariant/issues/870:2053,safety,ERROR,ERROR,2053,"""${VCF_DIR}/${BASE_NAME}.vcf.gz"". echo $BAM_FILE. echo $VCF_FILE. singularity exec --bind /usr/lib/locale/ \. docker://google/deepvariant:${BIN_VERSION} \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref $REFERENCE \. --reads $BAM_FILE \. --regions 6:32509320-32669663 \. --output_vcf $VCF_FILE \. --num_shards 12. done. ``` . - Error trace: . ```. ***** Running the command:*****. time seq 0 11 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""Reference_HLA/chr6_hg19.fa"" --reads ""./MDC05_1463_3.final.bam"" --examples ""/tmp/7361351.1.gpu.q/tmpzsp9g_vq/make_examples.tfrecord@12.gz"" --channels ""insert_size"" --regions ""chr6:32509320-32669663"" --task {}. [libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/wire_format_lite.cc:584] String field 'nucleus.genomics.v1.Program.command_line' contains invalid UTF-8 data when serializing a protocol buffer. Use the 'bytes' type if you intend to send raw bytes. [libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/wire_format_lite.cc:584] String field 'nucleus.genomics.v1.Program.command_line' contains invalid UTF-8 data when parsing a protocol buffer. Use the 'bytes' type if you intend to send raw bytes. Traceback (most recent call last):. File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 234, in <module>. app.run(main). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 220, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 15",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/870
https://github.com/google/deepvariant/issues/870:2467,safety,modul,module,2467,"| parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""Reference_HLA/chr6_hg19.fa"" --reads ""./MDC05_1463_3.final.bam"" --examples ""/tmp/7361351.1.gpu.q/tmpzsp9g_vq/make_examples.tfrecord@12.gz"" --channels ""insert_size"" --regions ""chr6:32509320-32669663"" --task {}. [libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/wire_format_lite.cc:584] String field 'nucleus.genomics.v1.Program.command_line' contains invalid UTF-8 data when serializing a protocol buffer. Use the 'bytes' type if you intend to send raw bytes. [libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/wire_format_lite.cc:584] String field 'nucleus.genomics.v1.Program.command_line' contains invalid UTF-8 data when parsing a protocol buffer. Use the 'bytes' type if you intend to send raw bytes. Traceback (most recent call last):. File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 234, in <module>. app.run(main). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 220, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 157, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 109, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", lin",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/870
https://github.com/google/deepvariant/issues/870:4174,safety,Error,Error,4174,"ys.exit(main(argv)). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 220, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 157, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 109, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 170, in assign_sample_name. with sam.SamReader(reads_filenames.split(',')[0]) as sam_reader:. File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 260, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 240, in __init__. self.header = self._reader.header. google.protobuf.message.DecodeError: Error parsing message. ```. I ran the WES example from you with no problem, but I experience issues with my own data (I have the same setup when running singularity). . I checked the reference and input bam files, they don't seem to be corrupted... but just googling the error did not help much. Cannot think of anything else, maybe you have some suggestions where the problem could be coming from? Otherwise I will try to find the raw data for my .bam files and do remapping to hg38 and use the ref that worked previously. . Thanks again!! Alisa.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/870
https://github.com/google/deepvariant/issues/870:4371,safety,input,input,4371,"ys.exit(main(argv)). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 220, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 157, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 109, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 170, in assign_sample_name. with sam.SamReader(reads_filenames.split(',')[0]) as sam_reader:. File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 260, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 240, in __init__. self.header = self._reader.header. google.protobuf.message.DecodeError: Error parsing message. ```. I ran the WES example from you with no problem, but I experience issues with my own data (I have the same setup when running singularity). . I checked the reference and input bam files, they don't seem to be corrupted... but just googling the error did not help much. Cannot think of anything else, maybe you have some suggestions where the problem could be coming from? Otherwise I will try to find the raw data for my .bam files and do remapping to hg38 and use the ref that worked previously. . Thanks again!! Alisa.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/870
https://github.com/google/deepvariant/issues/870:4445,safety,error,error,4445,"ys.exit(main(argv)). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 220, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 157, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 109, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 170, in assign_sample_name. with sam.SamReader(reads_filenames.split(',')[0]) as sam_reader:. File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 260, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 240, in __init__. self.header = self._reader.header. google.protobuf.message.DecodeError: Error parsing message. ```. I ran the WES example from you with no problem, but I experience issues with my own data (I have the same setup when running singularity). . I checked the reference and input bam files, they don't seem to be corrupted... but just googling the error did not help much. Cannot think of anything else, maybe you have some suggestions where the problem could be coming from? Otherwise I will try to find the raw data for my .bam files and do remapping to hg38 and use the ref that worked previously. . Thanks again!! Alisa.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/870
https://github.com/google/deepvariant/issues/870:536,security,log,log,536,"[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/wire_format_lite.cc:584]; Hi, so sorry for asking something again. But I really want to use mostly DeepVariant for variant calling. . **Setup**. - Operating system: Red Hat Enterprise Linux 9. - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): Docker. - Type of data: WES mapped to hg19. **My code:**. - Commands: . ```. #!/bin/bash. #$ -l m_mem_free=200G. #$ -l os=rhel9. #$ -m bea. #$ -cwd. #$ -pe smp 2. #$ -o deepvariant_output.log. #$ -e deepvariant_error.log. cd path/to/deepvariant. BAM_DIR=. VCF_DIR=deepvariant_output/. REFERENCE=Reference_HLA/human_g1k_v37_decoy.fasta. export SINGULARITY_CACHEDIR=""path/to/deepvariant/.singularity-$(whoami)"". export SINGULARITY_TMPDIR=""path/to/deepvariant/.singularity-$(whoami)"". BIN_VERSION=""1.6.1"". for BAM_FILE in ""${BAM_DIR}""/*.bam; do. # Extract the base name of the BAM file (without the directory and extension). BASE_NAME=$(basename ""${BAM_FILE}"" .bam). # Define the output VCF file name. VCF_FILE=""${VCF_DIR}/${BASE_NAME}.vcf.gz"". echo $BAM_FILE. echo $VCF_FILE. singularity exec --bind /usr/lib/locale/ \. docker://google/deepvariant:${BIN_VERSION} \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref $REFERENCE \. --reads $BAM_FILE \. --regions 6:32509320-32669663 \. --output_vcf $VCF_FILE \. --num_shards 12. done. ``` . - Error trace: . ```. ***** Running the command:*****. time seq 0 11 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""Reference_HLA/chr6_hg19.fa"" --reads ""./MDC05_1463_3.final.bam"" --examples ""/tmp/7361351.1.gpu.q/tmpzsp9g_vq/make_examples.tfrecord@12.gz"" --channels ""insert_size"" --regions ""chr6:32509320-32669663"" --task {}. [libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/wire_format_lite.cc:584] String field 'nucleus.genomics.v1.Program.command_line' contains invalid UTF-8 data when serializing a protocol buffer. Use the 'bytes",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/870
https://github.com/google/deepvariant/issues/870:565,security,log,log,565,"[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/wire_format_lite.cc:584]; Hi, so sorry for asking something again. But I really want to use mostly DeepVariant for variant calling. . **Setup**. - Operating system: Red Hat Enterprise Linux 9. - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): Docker. - Type of data: WES mapped to hg19. **My code:**. - Commands: . ```. #!/bin/bash. #$ -l m_mem_free=200G. #$ -l os=rhel9. #$ -m bea. #$ -cwd. #$ -pe smp 2. #$ -o deepvariant_output.log. #$ -e deepvariant_error.log. cd path/to/deepvariant. BAM_DIR=. VCF_DIR=deepvariant_output/. REFERENCE=Reference_HLA/human_g1k_v37_decoy.fasta. export SINGULARITY_CACHEDIR=""path/to/deepvariant/.singularity-$(whoami)"". export SINGULARITY_TMPDIR=""path/to/deepvariant/.singularity-$(whoami)"". BIN_VERSION=""1.6.1"". for BAM_FILE in ""${BAM_DIR}""/*.bam; do. # Extract the base name of the BAM file (without the directory and extension). BASE_NAME=$(basename ""${BAM_FILE}"" .bam). # Define the output VCF file name. VCF_FILE=""${VCF_DIR}/${BASE_NAME}.vcf.gz"". echo $BAM_FILE. echo $VCF_FILE. singularity exec --bind /usr/lib/locale/ \. docker://google/deepvariant:${BIN_VERSION} \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref $REFERENCE \. --reads $BAM_FILE \. --regions 6:32509320-32669663 \. --output_vcf $VCF_FILE \. --num_shards 12. done. ``` . - Error trace: . ```. ***** Running the command:*****. time seq 0 11 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""Reference_HLA/chr6_hg19.fa"" --reads ""./MDC05_1463_3.final.bam"" --examples ""/tmp/7361351.1.gpu.q/tmpzsp9g_vq/make_examples.tfrecord@12.gz"" --channels ""insert_size"" --regions ""chr6:32509320-32669663"" --task {}. [libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/wire_format_lite.cc:584] String field 'nucleus.genomics.v1.Program.command_line' contains invalid UTF-8 data when serializing a protocol buffer. Use the 'bytes",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/870
https://github.com/google/deepvariant/issues/870:536,testability,log,log,536,"[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/wire_format_lite.cc:584]; Hi, so sorry for asking something again. But I really want to use mostly DeepVariant for variant calling. . **Setup**. - Operating system: Red Hat Enterprise Linux 9. - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): Docker. - Type of data: WES mapped to hg19. **My code:**. - Commands: . ```. #!/bin/bash. #$ -l m_mem_free=200G. #$ -l os=rhel9. #$ -m bea. #$ -cwd. #$ -pe smp 2. #$ -o deepvariant_output.log. #$ -e deepvariant_error.log. cd path/to/deepvariant. BAM_DIR=. VCF_DIR=deepvariant_output/. REFERENCE=Reference_HLA/human_g1k_v37_decoy.fasta. export SINGULARITY_CACHEDIR=""path/to/deepvariant/.singularity-$(whoami)"". export SINGULARITY_TMPDIR=""path/to/deepvariant/.singularity-$(whoami)"". BIN_VERSION=""1.6.1"". for BAM_FILE in ""${BAM_DIR}""/*.bam; do. # Extract the base name of the BAM file (without the directory and extension). BASE_NAME=$(basename ""${BAM_FILE}"" .bam). # Define the output VCF file name. VCF_FILE=""${VCF_DIR}/${BASE_NAME}.vcf.gz"". echo $BAM_FILE. echo $VCF_FILE. singularity exec --bind /usr/lib/locale/ \. docker://google/deepvariant:${BIN_VERSION} \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref $REFERENCE \. --reads $BAM_FILE \. --regions 6:32509320-32669663 \. --output_vcf $VCF_FILE \. --num_shards 12. done. ``` . - Error trace: . ```. ***** Running the command:*****. time seq 0 11 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""Reference_HLA/chr6_hg19.fa"" --reads ""./MDC05_1463_3.final.bam"" --examples ""/tmp/7361351.1.gpu.q/tmpzsp9g_vq/make_examples.tfrecord@12.gz"" --channels ""insert_size"" --regions ""chr6:32509320-32669663"" --task {}. [libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/wire_format_lite.cc:584] String field 'nucleus.genomics.v1.Program.command_line' contains invalid UTF-8 data when serializing a protocol buffer. Use the 'bytes",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/870
https://github.com/google/deepvariant/issues/870:565,testability,log,log,565,"[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/wire_format_lite.cc:584]; Hi, so sorry for asking something again. But I really want to use mostly DeepVariant for variant calling. . **Setup**. - Operating system: Red Hat Enterprise Linux 9. - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): Docker. - Type of data: WES mapped to hg19. **My code:**. - Commands: . ```. #!/bin/bash. #$ -l m_mem_free=200G. #$ -l os=rhel9. #$ -m bea. #$ -cwd. #$ -pe smp 2. #$ -o deepvariant_output.log. #$ -e deepvariant_error.log. cd path/to/deepvariant. BAM_DIR=. VCF_DIR=deepvariant_output/. REFERENCE=Reference_HLA/human_g1k_v37_decoy.fasta. export SINGULARITY_CACHEDIR=""path/to/deepvariant/.singularity-$(whoami)"". export SINGULARITY_TMPDIR=""path/to/deepvariant/.singularity-$(whoami)"". BIN_VERSION=""1.6.1"". for BAM_FILE in ""${BAM_DIR}""/*.bam; do. # Extract the base name of the BAM file (without the directory and extension). BASE_NAME=$(basename ""${BAM_FILE}"" .bam). # Define the output VCF file name. VCF_FILE=""${VCF_DIR}/${BASE_NAME}.vcf.gz"". echo $BAM_FILE. echo $VCF_FILE. singularity exec --bind /usr/lib/locale/ \. docker://google/deepvariant:${BIN_VERSION} \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref $REFERENCE \. --reads $BAM_FILE \. --regions 6:32509320-32669663 \. --output_vcf $VCF_FILE \. --num_shards 12. done. ``` . - Error trace: . ```. ***** Running the command:*****. time seq 0 11 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""Reference_HLA/chr6_hg19.fa"" --reads ""./MDC05_1463_3.final.bam"" --examples ""/tmp/7361351.1.gpu.q/tmpzsp9g_vq/make_examples.tfrecord@12.gz"" --channels ""insert_size"" --regions ""chr6:32509320-32669663"" --task {}. [libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/wire_format_lite.cc:584] String field 'nucleus.genomics.v1.Program.command_line' contains invalid UTF-8 data when serializing a protocol buffer. Use the 'bytes",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/870
https://github.com/google/deepvariant/issues/870:1409,testability,trace,trace,1409,"ands: . ```. #!/bin/bash. #$ -l m_mem_free=200G. #$ -l os=rhel9. #$ -m bea. #$ -cwd. #$ -pe smp 2. #$ -o deepvariant_output.log. #$ -e deepvariant_error.log. cd path/to/deepvariant. BAM_DIR=. VCF_DIR=deepvariant_output/. REFERENCE=Reference_HLA/human_g1k_v37_decoy.fasta. export SINGULARITY_CACHEDIR=""path/to/deepvariant/.singularity-$(whoami)"". export SINGULARITY_TMPDIR=""path/to/deepvariant/.singularity-$(whoami)"". BIN_VERSION=""1.6.1"". for BAM_FILE in ""${BAM_DIR}""/*.bam; do. # Extract the base name of the BAM file (without the directory and extension). BASE_NAME=$(basename ""${BAM_FILE}"" .bam). # Define the output VCF file name. VCF_FILE=""${VCF_DIR}/${BASE_NAME}.vcf.gz"". echo $BAM_FILE. echo $VCF_FILE. singularity exec --bind /usr/lib/locale/ \. docker://google/deepvariant:${BIN_VERSION} \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref $REFERENCE \. --reads $BAM_FILE \. --regions 6:32509320-32669663 \. --output_vcf $VCF_FILE \. --num_shards 12. done. ``` . - Error trace: . ```. ***** Running the command:*****. time seq 0 11 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""Reference_HLA/chr6_hg19.fa"" --reads ""./MDC05_1463_3.final.bam"" --examples ""/tmp/7361351.1.gpu.q/tmpzsp9g_vq/make_examples.tfrecord@12.gz"" --channels ""insert_size"" --regions ""chr6:32509320-32669663"" --task {}. [libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/wire_format_lite.cc:584] String field 'nucleus.genomics.v1.Program.command_line' contains invalid UTF-8 data when serializing a protocol buffer. Use the 'bytes' type if you intend to send raw bytes. [libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/wire_format_lite.cc:584] String field 'nucleus.genomics.v1.Program.command_line' contains invalid UTF-8 data when parsing a protocol buffer. Use the 'bytes' type if you intend to send raw bytes. Traceback (most recent call last):. File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_de",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/870
https://github.com/google/deepvariant/issues/870:2303,testability,Trace,Traceback,2303,"E \. --regions 6:32509320-32669663 \. --output_vcf $VCF_FILE \. --num_shards 12. done. ``` . - Error trace: . ```. ***** Running the command:*****. time seq 0 11 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""Reference_HLA/chr6_hg19.fa"" --reads ""./MDC05_1463_3.final.bam"" --examples ""/tmp/7361351.1.gpu.q/tmpzsp9g_vq/make_examples.tfrecord@12.gz"" --channels ""insert_size"" --regions ""chr6:32509320-32669663"" --task {}. [libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/wire_format_lite.cc:584] String field 'nucleus.genomics.v1.Program.command_line' contains invalid UTF-8 data when serializing a protocol buffer. Use the 'bytes' type if you intend to send raw bytes. [libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/wire_format_lite.cc:584] String field 'nucleus.genomics.v1.Program.command_line' contains invalid UTF-8 data when parsing a protocol buffer. Use the 'bytes' type if you intend to send raw bytes. Traceback (most recent call last):. File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 234, in <module>. app.run(main). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 220, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 157, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 109, in one_sample_from_flags. sample_name = ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/870
https://github.com/google/deepvariant/issues/870:13,usability,ERROR,ERROR,13,"[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/wire_format_lite.cc:584]; Hi, so sorry for asking something again. But I really want to use mostly DeepVariant for variant calling. . **Setup**. - Operating system: Red Hat Enterprise Linux 9. - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): Docker. - Type of data: WES mapped to hg19. **My code:**. - Commands: . ```. #!/bin/bash. #$ -l m_mem_free=200G. #$ -l os=rhel9. #$ -m bea. #$ -cwd. #$ -pe smp 2. #$ -o deepvariant_output.log. #$ -e deepvariant_error.log. cd path/to/deepvariant. BAM_DIR=. VCF_DIR=deepvariant_output/. REFERENCE=Reference_HLA/human_g1k_v37_decoy.fasta. export SINGULARITY_CACHEDIR=""path/to/deepvariant/.singularity-$(whoami)"". export SINGULARITY_TMPDIR=""path/to/deepvariant/.singularity-$(whoami)"". BIN_VERSION=""1.6.1"". for BAM_FILE in ""${BAM_DIR}""/*.bam; do. # Extract the base name of the BAM file (without the directory and extension). BASE_NAME=$(basename ""${BAM_FILE}"" .bam). # Define the output VCF file name. VCF_FILE=""${VCF_DIR}/${BASE_NAME}.vcf.gz"". echo $BAM_FILE. echo $VCF_FILE. singularity exec --bind /usr/lib/locale/ \. docker://google/deepvariant:${BIN_VERSION} \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref $REFERENCE \. --reads $BAM_FILE \. --regions 6:32509320-32669663 \. --output_vcf $VCF_FILE \. --num_shards 12. done. ``` . - Error trace: . ```. ***** Running the command:*****. time seq 0 11 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""Reference_HLA/chr6_hg19.fa"" --reads ""./MDC05_1463_3.final.bam"" --examples ""/tmp/7361351.1.gpu.q/tmpzsp9g_vq/make_examples.tfrecord@12.gz"" --channels ""insert_size"" --regions ""chr6:32509320-32669663"" --task {}. [libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/wire_format_lite.cc:584] String field 'nucleus.genomics.v1.Program.command_line' contains invalid UTF-8 data when serializing a protocol buffer. Use the 'bytes",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/870
https://github.com/google/deepvariant/issues/870:408,usability,Command,Commands,408,"[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/wire_format_lite.cc:584]; Hi, so sorry for asking something again. But I really want to use mostly DeepVariant for variant calling. . **Setup**. - Operating system: Red Hat Enterprise Linux 9. - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): Docker. - Type of data: WES mapped to hg19. **My code:**. - Commands: . ```. #!/bin/bash. #$ -l m_mem_free=200G. #$ -l os=rhel9. #$ -m bea. #$ -cwd. #$ -pe smp 2. #$ -o deepvariant_output.log. #$ -e deepvariant_error.log. cd path/to/deepvariant. BAM_DIR=. VCF_DIR=deepvariant_output/. REFERENCE=Reference_HLA/human_g1k_v37_decoy.fasta. export SINGULARITY_CACHEDIR=""path/to/deepvariant/.singularity-$(whoami)"". export SINGULARITY_TMPDIR=""path/to/deepvariant/.singularity-$(whoami)"". BIN_VERSION=""1.6.1"". for BAM_FILE in ""${BAM_DIR}""/*.bam; do. # Extract the base name of the BAM file (without the directory and extension). BASE_NAME=$(basename ""${BAM_FILE}"" .bam). # Define the output VCF file name. VCF_FILE=""${VCF_DIR}/${BASE_NAME}.vcf.gz"". echo $BAM_FILE. echo $VCF_FILE. singularity exec --bind /usr/lib/locale/ \. docker://google/deepvariant:${BIN_VERSION} \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref $REFERENCE \. --reads $BAM_FILE \. --regions 6:32509320-32669663 \. --output_vcf $VCF_FILE \. --num_shards 12. done. ``` . - Error trace: . ```. ***** Running the command:*****. time seq 0 11 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""Reference_HLA/chr6_hg19.fa"" --reads ""./MDC05_1463_3.final.bam"" --examples ""/tmp/7361351.1.gpu.q/tmpzsp9g_vq/make_examples.tfrecord@12.gz"" --channels ""insert_size"" --regions ""chr6:32509320-32669663"" --task {}. [libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/wire_format_lite.cc:584] String field 'nucleus.genomics.v1.Program.command_line' contains invalid UTF-8 data when serializing a protocol buffer. Use the 'bytes",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/870
https://github.com/google/deepvariant/issues/870:1403,usability,Error,Error,1403,"- Commands: . ```. #!/bin/bash. #$ -l m_mem_free=200G. #$ -l os=rhel9. #$ -m bea. #$ -cwd. #$ -pe smp 2. #$ -o deepvariant_output.log. #$ -e deepvariant_error.log. cd path/to/deepvariant. BAM_DIR=. VCF_DIR=deepvariant_output/. REFERENCE=Reference_HLA/human_g1k_v37_decoy.fasta. export SINGULARITY_CACHEDIR=""path/to/deepvariant/.singularity-$(whoami)"". export SINGULARITY_TMPDIR=""path/to/deepvariant/.singularity-$(whoami)"". BIN_VERSION=""1.6.1"". for BAM_FILE in ""${BAM_DIR}""/*.bam; do. # Extract the base name of the BAM file (without the directory and extension). BASE_NAME=$(basename ""${BAM_FILE}"" .bam). # Define the output VCF file name. VCF_FILE=""${VCF_DIR}/${BASE_NAME}.vcf.gz"". echo $BAM_FILE. echo $VCF_FILE. singularity exec --bind /usr/lib/locale/ \. docker://google/deepvariant:${BIN_VERSION} \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref $REFERENCE \. --reads $BAM_FILE \. --regions 6:32509320-32669663 \. --output_vcf $VCF_FILE \. --num_shards 12. done. ``` . - Error trace: . ```. ***** Running the command:*****. time seq 0 11 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""Reference_HLA/chr6_hg19.fa"" --reads ""./MDC05_1463_3.final.bam"" --examples ""/tmp/7361351.1.gpu.q/tmpzsp9g_vq/make_examples.tfrecord@12.gz"" --channels ""insert_size"" --regions ""chr6:32509320-32669663"" --task {}. [libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/wire_format_lite.cc:584] String field 'nucleus.genomics.v1.Program.command_line' contains invalid UTF-8 data when serializing a protocol buffer. Use the 'bytes' type if you intend to send raw bytes. [libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/wire_format_lite.cc:584] String field 'nucleus.genomics.v1.Program.command_line' contains invalid UTF-8 data when parsing a protocol buffer. Use the 'bytes' type if you intend to send raw bytes. Traceback (most recent call last):. File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_goo",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/870
https://github.com/google/deepvariant/issues/870:1441,usability,command,command,1441,"_mem_free=200G. #$ -l os=rhel9. #$ -m bea. #$ -cwd. #$ -pe smp 2. #$ -o deepvariant_output.log. #$ -e deepvariant_error.log. cd path/to/deepvariant. BAM_DIR=. VCF_DIR=deepvariant_output/. REFERENCE=Reference_HLA/human_g1k_v37_decoy.fasta. export SINGULARITY_CACHEDIR=""path/to/deepvariant/.singularity-$(whoami)"". export SINGULARITY_TMPDIR=""path/to/deepvariant/.singularity-$(whoami)"". BIN_VERSION=""1.6.1"". for BAM_FILE in ""${BAM_DIR}""/*.bam; do. # Extract the base name of the BAM file (without the directory and extension). BASE_NAME=$(basename ""${BAM_FILE}"" .bam). # Define the output VCF file name. VCF_FILE=""${VCF_DIR}/${BASE_NAME}.vcf.gz"". echo $BAM_FILE. echo $VCF_FILE. singularity exec --bind /usr/lib/locale/ \. docker://google/deepvariant:${BIN_VERSION} \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref $REFERENCE \. --reads $BAM_FILE \. --regions 6:32509320-32669663 \. --output_vcf $VCF_FILE \. --num_shards 12. done. ``` . - Error trace: . ```. ***** Running the command:*****. time seq 0 11 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""Reference_HLA/chr6_hg19.fa"" --reads ""./MDC05_1463_3.final.bam"" --examples ""/tmp/7361351.1.gpu.q/tmpzsp9g_vq/make_examples.tfrecord@12.gz"" --channels ""insert_size"" --regions ""chr6:32509320-32669663"" --task {}. [libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/wire_format_lite.cc:584] String field 'nucleus.genomics.v1.Program.command_line' contains invalid UTF-8 data when serializing a protocol buffer. Use the 'bytes' type if you intend to send raw bytes. [libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/wire_format_lite.cc:584] String field 'nucleus.genomics.v1.Program.command_line' contains invalid UTF-8 data when parsing a protocol buffer. Use the 'bytes' type if you intend to send raw bytes. Traceback (most recent call last):. File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_exampl",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/870
https://github.com/google/deepvariant/issues/870:1786,usability,ERROR,ERROR,1786,"/to/deepvariant/.singularity-$(whoami)"". BIN_VERSION=""1.6.1"". for BAM_FILE in ""${BAM_DIR}""/*.bam; do. # Extract the base name of the BAM file (without the directory and extension). BASE_NAME=$(basename ""${BAM_FILE}"" .bam). # Define the output VCF file name. VCF_FILE=""${VCF_DIR}/${BASE_NAME}.vcf.gz"". echo $BAM_FILE. echo $VCF_FILE. singularity exec --bind /usr/lib/locale/ \. docker://google/deepvariant:${BIN_VERSION} \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref $REFERENCE \. --reads $BAM_FILE \. --regions 6:32509320-32669663 \. --output_vcf $VCF_FILE \. --num_shards 12. done. ``` . - Error trace: . ```. ***** Running the command:*****. time seq 0 11 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""Reference_HLA/chr6_hg19.fa"" --reads ""./MDC05_1463_3.final.bam"" --examples ""/tmp/7361351.1.gpu.q/tmpzsp9g_vq/make_examples.tfrecord@12.gz"" --channels ""insert_size"" --regions ""chr6:32509320-32669663"" --task {}. [libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/wire_format_lite.cc:584] String field 'nucleus.genomics.v1.Program.command_line' contains invalid UTF-8 data when serializing a protocol buffer. Use the 'bytes' type if you intend to send raw bytes. [libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/wire_format_lite.cc:584] String field 'nucleus.genomics.v1.Program.command_line' contains invalid UTF-8 data when parsing a protocol buffer. Use the 'bytes' type if you intend to send raw bytes. Traceback (most recent call last):. File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 234, in <module>. app.run(main). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/870
https://github.com/google/deepvariant/issues/870:2053,usability,ERROR,ERROR,2053,"""${VCF_DIR}/${BASE_NAME}.vcf.gz"". echo $BAM_FILE. echo $VCF_FILE. singularity exec --bind /usr/lib/locale/ \. docker://google/deepvariant:${BIN_VERSION} \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref $REFERENCE \. --reads $BAM_FILE \. --regions 6:32509320-32669663 \. --output_vcf $VCF_FILE \. --num_shards 12. done. ``` . - Error trace: . ```. ***** Running the command:*****. time seq 0 11 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""Reference_HLA/chr6_hg19.fa"" --reads ""./MDC05_1463_3.final.bam"" --examples ""/tmp/7361351.1.gpu.q/tmpzsp9g_vq/make_examples.tfrecord@12.gz"" --channels ""insert_size"" --regions ""chr6:32509320-32669663"" --task {}. [libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/wire_format_lite.cc:584] String field 'nucleus.genomics.v1.Program.command_line' contains invalid UTF-8 data when serializing a protocol buffer. Use the 'bytes' type if you intend to send raw bytes. [libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/wire_format_lite.cc:584] String field 'nucleus.genomics.v1.Program.command_line' contains invalid UTF-8 data when parsing a protocol buffer. Use the 'bytes' type if you intend to send raw bytes. Traceback (most recent call last):. File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 234, in <module>. app.run(main). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 220, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 15",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/870
https://github.com/google/deepvariant/issues/870:4174,usability,Error,Error,4174,"ys.exit(main(argv)). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 220, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 157, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 109, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 170, in assign_sample_name. with sam.SamReader(reads_filenames.split(',')[0]) as sam_reader:. File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 260, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 240, in __init__. self.header = self._reader.header. google.protobuf.message.DecodeError: Error parsing message. ```. I ran the WES example from you with no problem, but I experience issues with my own data (I have the same setup when running singularity). . I checked the reference and input bam files, they don't seem to be corrupted... but just googling the error did not help much. Cannot think of anything else, maybe you have some suggestions where the problem could be coming from? Otherwise I will try to find the raw data for my .bam files and do remapping to hg38 and use the ref that worked previously. . Thanks again!! Alisa.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/870
https://github.com/google/deepvariant/issues/870:4256,usability,experien,experience,4256,"ys.exit(main(argv)). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 220, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 157, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 109, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 170, in assign_sample_name. with sam.SamReader(reads_filenames.split(',')[0]) as sam_reader:. File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 260, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 240, in __init__. self.header = self._reader.header. google.protobuf.message.DecodeError: Error parsing message. ```. I ran the WES example from you with no problem, but I experience issues with my own data (I have the same setup when running singularity). . I checked the reference and input bam files, they don't seem to be corrupted... but just googling the error did not help much. Cannot think of anything else, maybe you have some suggestions where the problem could be coming from? Otherwise I will try to find the raw data for my .bam files and do remapping to hg38 and use the ref that worked previously. . Thanks again!! Alisa.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/870
https://github.com/google/deepvariant/issues/870:4371,usability,input,input,4371,"ys.exit(main(argv)). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 220, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 157, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 109, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 170, in assign_sample_name. with sam.SamReader(reads_filenames.split(',')[0]) as sam_reader:. File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 260, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 240, in __init__. self.header = self._reader.header. google.protobuf.message.DecodeError: Error parsing message. ```. I ran the WES example from you with no problem, but I experience issues with my own data (I have the same setup when running singularity). . I checked the reference and input bam files, they don't seem to be corrupted... but just googling the error did not help much. Cannot think of anything else, maybe you have some suggestions where the problem could be coming from? Otherwise I will try to find the raw data for my .bam files and do remapping to hg38 and use the ref that worked previously. . Thanks again!! Alisa.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/870
https://github.com/google/deepvariant/issues/870:4445,usability,error,error,4445,"ys.exit(main(argv)). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 220, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 157, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 109, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 170, in assign_sample_name. with sam.SamReader(reads_filenames.split(',')[0]) as sam_reader:. File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 260, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 240, in __init__. self.header = self._reader.header. google.protobuf.message.DecodeError: Error parsing message. ```. I ran the WES example from you with no problem, but I experience issues with my own data (I have the same setup when running singularity). . I checked the reference and input bam files, they don't seem to be corrupted... but just googling the error did not help much. Cannot think of anything else, maybe you have some suggestions where the problem could be coming from? Otherwise I will try to find the raw data for my .bam files and do remapping to hg38 and use the ref that worked previously. . Thanks again!! Alisa.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/870
https://github.com/google/deepvariant/issues/870:4459,usability,help,help,4459,"ys.exit(main(argv)). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 220, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 157, in default_options. samples_in_order, sample_role_to_train = one_sample_from_flags(. File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 109, in one_sample_from_flags. sample_name = make_examples_core.assign_sample_name(. File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 170, in assign_sample_name. with sam.SamReader(reads_filenames.split(',')[0]) as sam_reader:. File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 260, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/7361351.1.gpu.q/Bazel.runfiles_ii4x9mqm/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 240, in __init__. self.header = self._reader.header. google.protobuf.message.DecodeError: Error parsing message. ```. I ran the WES example from you with no problem, but I experience issues with my own data (I have the same setup when running singularity). . I checked the reference and input bam files, they don't seem to be corrupted... but just googling the error did not help much. Cannot think of anything else, maybe you have some suggestions where the problem could be coming from? Otherwise I will try to find the raw data for my .bam files and do remapping to hg38 and use the ref that worked previously. . Thanks again!! Alisa.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/870
https://github.com/google/deepvariant/issues/871:459,availability,Error,Error,459,"Troubleshooting Dockerfile for DeepVariant on Mac M1: Issues with Bazel ; Im new to working with computers tools like DeepVariant. Im trying to build DeepVariant using Docker on a Mac M1 and am encountering issues with the Dockerfile during the Bazel build process. I want to ensure compatibility with ARM64 architecture. **Docker version**: Docker version 27.1.1, build 6312585. **Bazel Version**: 7.3.1. **MacBook Model**: M1 chip (ARM64 architecture). **Error**: . ![IMG_3267](https://github.com/user-attachments/assets/11e28824-b941-42cc-9d33-7e9155a03543). ![IMG_3268](https://github.com/user-attachments/assets/4e923de6-99d5-43ee-80c6-29b32504527d). **My Dockerfilee code**:. ```. # Base image suitable for ARM64 architecture. FROM arm64v8/ubuntu:latest AS base. # Prevent interactive prompts. ENV DEBIAN_FRONTEND=noninteractive. # Install necessary packages. RUN apt-get update && \. apt-get install -y \. git \. curl \. unzip \. wget \. openjdk-17-jdk \. build-essential \. bzip2 \. python3-pip \. parallel && \. apt-get clean && \. rm -rf /var/lib/apt/lists/*. # Install Bazel (adjust version as needed). RUN curl -LO ""https://github.com/bazelbuild/bazel/releases/download/7.3.1/bazel-7.3.1-linux-arm64"" && \. chmod +x bazel-7.3.1-linux-arm64 && \. mv bazel-7.3.1-linux-arm64 /usr/local/bin/bazel. # Install Conda. RUN curl -LO ""https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-aarch64.sh"" && \. bash Miniconda3-latest-Linux-aarch64.sh -b -p /opt/miniconda && \. rm Miniconda3-latest-Linux-aarch64.sh. # Setup Conda environment. ENV PATH=""/opt/miniconda/bin:${PATH}"". RUN conda config --add channels defaults && \. conda config --add channels bioconda && \. conda config --add channels conda-forge && \. conda create -n bio bioconda::bcftools bioconda::samtools -y && \. conda clean -a. # Clone DeepVariant and build. FROM base AS builder. # Clone the DeepVariant repository. RUN git clone https://github.com/google/deepvariant.git /opt/deepvariant && \. cd /opt/deepvariant && ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/871
https://github.com/google/deepvariant/issues/871:1175,availability,down,download,1175," a Mac M1 and am encountering issues with the Dockerfile during the Bazel build process. I want to ensure compatibility with ARM64 architecture. **Docker version**: Docker version 27.1.1, build 6312585. **Bazel Version**: 7.3.1. **MacBook Model**: M1 chip (ARM64 architecture). **Error**: . ![IMG_3267](https://github.com/user-attachments/assets/11e28824-b941-42cc-9d33-7e9155a03543). ![IMG_3268](https://github.com/user-attachments/assets/4e923de6-99d5-43ee-80c6-29b32504527d). **My Dockerfilee code**:. ```. # Base image suitable for ARM64 architecture. FROM arm64v8/ubuntu:latest AS base. # Prevent interactive prompts. ENV DEBIAN_FRONTEND=noninteractive. # Install necessary packages. RUN apt-get update && \. apt-get install -y \. git \. curl \. unzip \. wget \. openjdk-17-jdk \. build-essential \. bzip2 \. python3-pip \. parallel && \. apt-get clean && \. rm -rf /var/lib/apt/lists/*. # Install Bazel (adjust version as needed). RUN curl -LO ""https://github.com/bazelbuild/bazel/releases/download/7.3.1/bazel-7.3.1-linux-arm64"" && \. chmod +x bazel-7.3.1-linux-arm64 && \. mv bazel-7.3.1-linux-arm64 /usr/local/bin/bazel. # Install Conda. RUN curl -LO ""https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-aarch64.sh"" && \. bash Miniconda3-latest-Linux-aarch64.sh -b -p /opt/miniconda && \. rm Miniconda3-latest-Linux-aarch64.sh. # Setup Conda environment. ENV PATH=""/opt/miniconda/bin:${PATH}"". RUN conda config --add channels defaults && \. conda config --add channels bioconda && \. conda config --add channels conda-forge && \. conda create -n bio bioconda::bcftools bioconda::samtools -y && \. conda clean -a. # Clone DeepVariant and build. FROM base AS builder. # Clone the DeepVariant repository. RUN git clone https://github.com/google/deepvariant.git /opt/deepvariant && \. cd /opt/deepvariant && \. git checkout tags/v1.6.1. # Run Bazel build with additional flags to skip problematic configurations. RUN bazel build -c opt --noincremental --experimental_action_listener= //d",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/871
https://github.com/google/deepvariant/issues/871:2275,availability,echo,echo,2275,"nux-arm64 /usr/local/bin/bazel. # Install Conda. RUN curl -LO ""https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-aarch64.sh"" && \. bash Miniconda3-latest-Linux-aarch64.sh -b -p /opt/miniconda && \. rm Miniconda3-latest-Linux-aarch64.sh. # Setup Conda environment. ENV PATH=""/opt/miniconda/bin:${PATH}"". RUN conda config --add channels defaults && \. conda config --add channels bioconda && \. conda config --add channels conda-forge && \. conda create -n bio bioconda::bcftools bioconda::samtools -y && \. conda clean -a. # Clone DeepVariant and build. FROM base AS builder. # Clone the DeepVariant repository. RUN git clone https://github.com/google/deepvariant.git /opt/deepvariant && \. cd /opt/deepvariant && \. git checkout tags/v1.6.1. # Run Bazel build with additional flags to skip problematic configurations. RUN bazel build -c opt --noincremental --experimental_action_listener= //deepvariant:make_examples //deepvariant:call_variants //deepvariant:postprocess_variants || { \. echo ""Bazel build failed""; \. exit 1; }. # Final image. FROM base AS final. # Set environment variables. ENV VERSION=1.6.0. ENV PYTHON_VERSION=3.8. ENV PATH=""/opt/miniconda/bin:${PATH}"". # Install Python packages. RUN pip install --upgrade pip setuptools wheel --timeout=120 && \. pip install jaxlib jax --timeout=120 --extra-index-url https://storage.googleapis.com/jax-releases/jax_releases.html. # Copy DeepVariant binaries from the builder stage. COPY --from=builder /opt/deepvariant /opt/deepvariant. WORKDIR /opt/deepvariant. # Ensure executable scripts are correctly set up. RUN BASH_HEADER='#!/bin/bash' && \. for script in make_examples call_variants call_variants_slim postprocess_variants vcf_stats_report show_examples runtime_by_region_vis multisample_make_examples labeled_examples_to_vcf make_examples_somatic train run_deepvariant run_deepsomatic; do \. printf ""%s\n%s\n"" ""${BASH_HEADER}"" ""python3 /opt/deepvariant/bin/${script}.zip \""$@\"""" > /opt/deepvariant/bin/${script} && \. chmod ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/871
https://github.com/google/deepvariant/issues/871:146,deployability,build,build,146,"Troubleshooting Dockerfile for DeepVariant on Mac M1: Issues with Bazel ; Im new to working with computers tools like DeepVariant. Im trying to build DeepVariant using Docker on a Mac M1 and am encountering issues with the Dockerfile during the Bazel build process. I want to ensure compatibility with ARM64 architecture. **Docker version**: Docker version 27.1.1, build 6312585. **Bazel Version**: 7.3.1. **MacBook Model**: M1 chip (ARM64 architecture). **Error**: . ![IMG_3267](https://github.com/user-attachments/assets/11e28824-b941-42cc-9d33-7e9155a03543). ![IMG_3268](https://github.com/user-attachments/assets/4e923de6-99d5-43ee-80c6-29b32504527d). **My Dockerfilee code**:. ```. # Base image suitable for ARM64 architecture. FROM arm64v8/ubuntu:latest AS base. # Prevent interactive prompts. ENV DEBIAN_FRONTEND=noninteractive. # Install necessary packages. RUN apt-get update && \. apt-get install -y \. git \. curl \. unzip \. wget \. openjdk-17-jdk \. build-essential \. bzip2 \. python3-pip \. parallel && \. apt-get clean && \. rm -rf /var/lib/apt/lists/*. # Install Bazel (adjust version as needed). RUN curl -LO ""https://github.com/bazelbuild/bazel/releases/download/7.3.1/bazel-7.3.1-linux-arm64"" && \. chmod +x bazel-7.3.1-linux-arm64 && \. mv bazel-7.3.1-linux-arm64 /usr/local/bin/bazel. # Install Conda. RUN curl -LO ""https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-aarch64.sh"" && \. bash Miniconda3-latest-Linux-aarch64.sh -b -p /opt/miniconda && \. rm Miniconda3-latest-Linux-aarch64.sh. # Setup Conda environment. ENV PATH=""/opt/miniconda/bin:${PATH}"". RUN conda config --add channels defaults && \. conda config --add channels bioconda && \. conda config --add channels conda-forge && \. conda create -n bio bioconda::bcftools bioconda::samtools -y && \. conda clean -a. # Clone DeepVariant and build. FROM base AS builder. # Clone the DeepVariant repository. RUN git clone https://github.com/google/deepvariant.git /opt/deepvariant && \. cd /opt/deepvariant && ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/871
https://github.com/google/deepvariant/issues/871:253,deployability,build,build,253,"Troubleshooting Dockerfile for DeepVariant on Mac M1: Issues with Bazel ; Im new to working with computers tools like DeepVariant. Im trying to build DeepVariant using Docker on a Mac M1 and am encountering issues with the Dockerfile during the Bazel build process. I want to ensure compatibility with ARM64 architecture. **Docker version**: Docker version 27.1.1, build 6312585. **Bazel Version**: 7.3.1. **MacBook Model**: M1 chip (ARM64 architecture). **Error**: . ![IMG_3267](https://github.com/user-attachments/assets/11e28824-b941-42cc-9d33-7e9155a03543). ![IMG_3268](https://github.com/user-attachments/assets/4e923de6-99d5-43ee-80c6-29b32504527d). **My Dockerfilee code**:. ```. # Base image suitable for ARM64 architecture. FROM arm64v8/ubuntu:latest AS base. # Prevent interactive prompts. ENV DEBIAN_FRONTEND=noninteractive. # Install necessary packages. RUN apt-get update && \. apt-get install -y \. git \. curl \. unzip \. wget \. openjdk-17-jdk \. build-essential \. bzip2 \. python3-pip \. parallel && \. apt-get clean && \. rm -rf /var/lib/apt/lists/*. # Install Bazel (adjust version as needed). RUN curl -LO ""https://github.com/bazelbuild/bazel/releases/download/7.3.1/bazel-7.3.1-linux-arm64"" && \. chmod +x bazel-7.3.1-linux-arm64 && \. mv bazel-7.3.1-linux-arm64 /usr/local/bin/bazel. # Install Conda. RUN curl -LO ""https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-aarch64.sh"" && \. bash Miniconda3-latest-Linux-aarch64.sh -b -p /opt/miniconda && \. rm Miniconda3-latest-Linux-aarch64.sh. # Setup Conda environment. ENV PATH=""/opt/miniconda/bin:${PATH}"". RUN conda config --add channels defaults && \. conda config --add channels bioconda && \. conda config --add channels conda-forge && \. conda create -n bio bioconda::bcftools bioconda::samtools -y && \. conda clean -a. # Clone DeepVariant and build. FROM base AS builder. # Clone the DeepVariant repository. RUN git clone https://github.com/google/deepvariant.git /opt/deepvariant && \. cd /opt/deepvariant && ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/871
https://github.com/google/deepvariant/issues/871:333,deployability,version,version,333,"Troubleshooting Dockerfile for DeepVariant on Mac M1: Issues with Bazel ; Im new to working with computers tools like DeepVariant. Im trying to build DeepVariant using Docker on a Mac M1 and am encountering issues with the Dockerfile during the Bazel build process. I want to ensure compatibility with ARM64 architecture. **Docker version**: Docker version 27.1.1, build 6312585. **Bazel Version**: 7.3.1. **MacBook Model**: M1 chip (ARM64 architecture). **Error**: . ![IMG_3267](https://github.com/user-attachments/assets/11e28824-b941-42cc-9d33-7e9155a03543). ![IMG_3268](https://github.com/user-attachments/assets/4e923de6-99d5-43ee-80c6-29b32504527d). **My Dockerfilee code**:. ```. # Base image suitable for ARM64 architecture. FROM arm64v8/ubuntu:latest AS base. # Prevent interactive prompts. ENV DEBIAN_FRONTEND=noninteractive. # Install necessary packages. RUN apt-get update && \. apt-get install -y \. git \. curl \. unzip \. wget \. openjdk-17-jdk \. build-essential \. bzip2 \. python3-pip \. parallel && \. apt-get clean && \. rm -rf /var/lib/apt/lists/*. # Install Bazel (adjust version as needed). RUN curl -LO ""https://github.com/bazelbuild/bazel/releases/download/7.3.1/bazel-7.3.1-linux-arm64"" && \. chmod +x bazel-7.3.1-linux-arm64 && \. mv bazel-7.3.1-linux-arm64 /usr/local/bin/bazel. # Install Conda. RUN curl -LO ""https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-aarch64.sh"" && \. bash Miniconda3-latest-Linux-aarch64.sh -b -p /opt/miniconda && \. rm Miniconda3-latest-Linux-aarch64.sh. # Setup Conda environment. ENV PATH=""/opt/miniconda/bin:${PATH}"". RUN conda config --add channels defaults && \. conda config --add channels bioconda && \. conda config --add channels conda-forge && \. conda create -n bio bioconda::bcftools bioconda::samtools -y && \. conda clean -a. # Clone DeepVariant and build. FROM base AS builder. # Clone the DeepVariant repository. RUN git clone https://github.com/google/deepvariant.git /opt/deepvariant && \. cd /opt/deepvariant && ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/871
https://github.com/google/deepvariant/issues/871:351,deployability,version,version,351,"Troubleshooting Dockerfile for DeepVariant on Mac M1: Issues with Bazel ; Im new to working with computers tools like DeepVariant. Im trying to build DeepVariant using Docker on a Mac M1 and am encountering issues with the Dockerfile during the Bazel build process. I want to ensure compatibility with ARM64 architecture. **Docker version**: Docker version 27.1.1, build 6312585. **Bazel Version**: 7.3.1. **MacBook Model**: M1 chip (ARM64 architecture). **Error**: . ![IMG_3267](https://github.com/user-attachments/assets/11e28824-b941-42cc-9d33-7e9155a03543). ![IMG_3268](https://github.com/user-attachments/assets/4e923de6-99d5-43ee-80c6-29b32504527d). **My Dockerfilee code**:. ```. # Base image suitable for ARM64 architecture. FROM arm64v8/ubuntu:latest AS base. # Prevent interactive prompts. ENV DEBIAN_FRONTEND=noninteractive. # Install necessary packages. RUN apt-get update && \. apt-get install -y \. git \. curl \. unzip \. wget \. openjdk-17-jdk \. build-essential \. bzip2 \. python3-pip \. parallel && \. apt-get clean && \. rm -rf /var/lib/apt/lists/*. # Install Bazel (adjust version as needed). RUN curl -LO ""https://github.com/bazelbuild/bazel/releases/download/7.3.1/bazel-7.3.1-linux-arm64"" && \. chmod +x bazel-7.3.1-linux-arm64 && \. mv bazel-7.3.1-linux-arm64 /usr/local/bin/bazel. # Install Conda. RUN curl -LO ""https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-aarch64.sh"" && \. bash Miniconda3-latest-Linux-aarch64.sh -b -p /opt/miniconda && \. rm Miniconda3-latest-Linux-aarch64.sh. # Setup Conda environment. ENV PATH=""/opt/miniconda/bin:${PATH}"". RUN conda config --add channels defaults && \. conda config --add channels bioconda && \. conda config --add channels conda-forge && \. conda create -n bio bioconda::bcftools bioconda::samtools -y && \. conda clean -a. # Clone DeepVariant and build. FROM base AS builder. # Clone the DeepVariant repository. RUN git clone https://github.com/google/deepvariant.git /opt/deepvariant && \. cd /opt/deepvariant && ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/871
https://github.com/google/deepvariant/issues/871:367,deployability,build,build,367,"Troubleshooting Dockerfile for DeepVariant on Mac M1: Issues with Bazel ; Im new to working with computers tools like DeepVariant. Im trying to build DeepVariant using Docker on a Mac M1 and am encountering issues with the Dockerfile during the Bazel build process. I want to ensure compatibility with ARM64 architecture. **Docker version**: Docker version 27.1.1, build 6312585. **Bazel Version**: 7.3.1. **MacBook Model**: M1 chip (ARM64 architecture). **Error**: . ![IMG_3267](https://github.com/user-attachments/assets/11e28824-b941-42cc-9d33-7e9155a03543). ![IMG_3268](https://github.com/user-attachments/assets/4e923de6-99d5-43ee-80c6-29b32504527d). **My Dockerfilee code**:. ```. # Base image suitable for ARM64 architecture. FROM arm64v8/ubuntu:latest AS base. # Prevent interactive prompts. ENV DEBIAN_FRONTEND=noninteractive. # Install necessary packages. RUN apt-get update && \. apt-get install -y \. git \. curl \. unzip \. wget \. openjdk-17-jdk \. build-essential \. bzip2 \. python3-pip \. parallel && \. apt-get clean && \. rm -rf /var/lib/apt/lists/*. # Install Bazel (adjust version as needed). RUN curl -LO ""https://github.com/bazelbuild/bazel/releases/download/7.3.1/bazel-7.3.1-linux-arm64"" && \. chmod +x bazel-7.3.1-linux-arm64 && \. mv bazel-7.3.1-linux-arm64 /usr/local/bin/bazel. # Install Conda. RUN curl -LO ""https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-aarch64.sh"" && \. bash Miniconda3-latest-Linux-aarch64.sh -b -p /opt/miniconda && \. rm Miniconda3-latest-Linux-aarch64.sh. # Setup Conda environment. ENV PATH=""/opt/miniconda/bin:${PATH}"". RUN conda config --add channels defaults && \. conda config --add channels bioconda && \. conda config --add channels conda-forge && \. conda create -n bio bioconda::bcftools bioconda::samtools -y && \. conda clean -a. # Clone DeepVariant and build. FROM base AS builder. # Clone the DeepVariant repository. RUN git clone https://github.com/google/deepvariant.git /opt/deepvariant && \. cd /opt/deepvariant && ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/871
https://github.com/google/deepvariant/issues/871:390,deployability,Version,Version,390,"Troubleshooting Dockerfile for DeepVariant on Mac M1: Issues with Bazel ; Im new to working with computers tools like DeepVariant. Im trying to build DeepVariant using Docker on a Mac M1 and am encountering issues with the Dockerfile during the Bazel build process. I want to ensure compatibility with ARM64 architecture. **Docker version**: Docker version 27.1.1, build 6312585. **Bazel Version**: 7.3.1. **MacBook Model**: M1 chip (ARM64 architecture). **Error**: . ![IMG_3267](https://github.com/user-attachments/assets/11e28824-b941-42cc-9d33-7e9155a03543). ![IMG_3268](https://github.com/user-attachments/assets/4e923de6-99d5-43ee-80c6-29b32504527d). **My Dockerfilee code**:. ```. # Base image suitable for ARM64 architecture. FROM arm64v8/ubuntu:latest AS base. # Prevent interactive prompts. ENV DEBIAN_FRONTEND=noninteractive. # Install necessary packages. RUN apt-get update && \. apt-get install -y \. git \. curl \. unzip \. wget \. openjdk-17-jdk \. build-essential \. bzip2 \. python3-pip \. parallel && \. apt-get clean && \. rm -rf /var/lib/apt/lists/*. # Install Bazel (adjust version as needed). RUN curl -LO ""https://github.com/bazelbuild/bazel/releases/download/7.3.1/bazel-7.3.1-linux-arm64"" && \. chmod +x bazel-7.3.1-linux-arm64 && \. mv bazel-7.3.1-linux-arm64 /usr/local/bin/bazel. # Install Conda. RUN curl -LO ""https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-aarch64.sh"" && \. bash Miniconda3-latest-Linux-aarch64.sh -b -p /opt/miniconda && \. rm Miniconda3-latest-Linux-aarch64.sh. # Setup Conda environment. ENV PATH=""/opt/miniconda/bin:${PATH}"". RUN conda config --add channels defaults && \. conda config --add channels bioconda && \. conda config --add channels conda-forge && \. conda create -n bio bioconda::bcftools bioconda::samtools -y && \. conda clean -a. # Clone DeepVariant and build. FROM base AS builder. # Clone the DeepVariant repository. RUN git clone https://github.com/google/deepvariant.git /opt/deepvariant && \. cd /opt/deepvariant && ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/871
https://github.com/google/deepvariant/issues/871:840,deployability,Instal,Install,840,"Troubleshooting Dockerfile for DeepVariant on Mac M1: Issues with Bazel ; Im new to working with computers tools like DeepVariant. Im trying to build DeepVariant using Docker on a Mac M1 and am encountering issues with the Dockerfile during the Bazel build process. I want to ensure compatibility with ARM64 architecture. **Docker version**: Docker version 27.1.1, build 6312585. **Bazel Version**: 7.3.1. **MacBook Model**: M1 chip (ARM64 architecture). **Error**: . ![IMG_3267](https://github.com/user-attachments/assets/11e28824-b941-42cc-9d33-7e9155a03543). ![IMG_3268](https://github.com/user-attachments/assets/4e923de6-99d5-43ee-80c6-29b32504527d). **My Dockerfilee code**:. ```. # Base image suitable for ARM64 architecture. FROM arm64v8/ubuntu:latest AS base. # Prevent interactive prompts. ENV DEBIAN_FRONTEND=noninteractive. # Install necessary packages. RUN apt-get update && \. apt-get install -y \. git \. curl \. unzip \. wget \. openjdk-17-jdk \. build-essential \. bzip2 \. python3-pip \. parallel && \. apt-get clean && \. rm -rf /var/lib/apt/lists/*. # Install Bazel (adjust version as needed). RUN curl -LO ""https://github.com/bazelbuild/bazel/releases/download/7.3.1/bazel-7.3.1-linux-arm64"" && \. chmod +x bazel-7.3.1-linux-arm64 && \. mv bazel-7.3.1-linux-arm64 /usr/local/bin/bazel. # Install Conda. RUN curl -LO ""https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-aarch64.sh"" && \. bash Miniconda3-latest-Linux-aarch64.sh -b -p /opt/miniconda && \. rm Miniconda3-latest-Linux-aarch64.sh. # Setup Conda environment. ENV PATH=""/opt/miniconda/bin:${PATH}"". RUN conda config --add channels defaults && \. conda config --add channels bioconda && \. conda config --add channels conda-forge && \. conda create -n bio bioconda::bcftools bioconda::samtools -y && \. conda clean -a. # Clone DeepVariant and build. FROM base AS builder. # Clone the DeepVariant repository. RUN git clone https://github.com/google/deepvariant.git /opt/deepvariant && \. cd /opt/deepvariant && ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/871
https://github.com/google/deepvariant/issues/871:880,deployability,updat,update,880,"Troubleshooting Dockerfile for DeepVariant on Mac M1: Issues with Bazel ; Im new to working with computers tools like DeepVariant. Im trying to build DeepVariant using Docker on a Mac M1 and am encountering issues with the Dockerfile during the Bazel build process. I want to ensure compatibility with ARM64 architecture. **Docker version**: Docker version 27.1.1, build 6312585. **Bazel Version**: 7.3.1. **MacBook Model**: M1 chip (ARM64 architecture). **Error**: . ![IMG_3267](https://github.com/user-attachments/assets/11e28824-b941-42cc-9d33-7e9155a03543). ![IMG_3268](https://github.com/user-attachments/assets/4e923de6-99d5-43ee-80c6-29b32504527d). **My Dockerfilee code**:. ```. # Base image suitable for ARM64 architecture. FROM arm64v8/ubuntu:latest AS base. # Prevent interactive prompts. ENV DEBIAN_FRONTEND=noninteractive. # Install necessary packages. RUN apt-get update && \. apt-get install -y \. git \. curl \. unzip \. wget \. openjdk-17-jdk \. build-essential \. bzip2 \. python3-pip \. parallel && \. apt-get clean && \. rm -rf /var/lib/apt/lists/*. # Install Bazel (adjust version as needed). RUN curl -LO ""https://github.com/bazelbuild/bazel/releases/download/7.3.1/bazel-7.3.1-linux-arm64"" && \. chmod +x bazel-7.3.1-linux-arm64 && \. mv bazel-7.3.1-linux-arm64 /usr/local/bin/bazel. # Install Conda. RUN curl -LO ""https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-aarch64.sh"" && \. bash Miniconda3-latest-Linux-aarch64.sh -b -p /opt/miniconda && \. rm Miniconda3-latest-Linux-aarch64.sh. # Setup Conda environment. ENV PATH=""/opt/miniconda/bin:${PATH}"". RUN conda config --add channels defaults && \. conda config --add channels bioconda && \. conda config --add channels conda-forge && \. conda create -n bio bioconda::bcftools bioconda::samtools -y && \. conda clean -a. # Clone DeepVariant and build. FROM base AS builder. # Clone the DeepVariant repository. RUN git clone https://github.com/google/deepvariant.git /opt/deepvariant && \. cd /opt/deepvariant && ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/871
https://github.com/google/deepvariant/issues/871:901,deployability,instal,install,901,"Troubleshooting Dockerfile for DeepVariant on Mac M1: Issues with Bazel ; Im new to working with computers tools like DeepVariant. Im trying to build DeepVariant using Docker on a Mac M1 and am encountering issues with the Dockerfile during the Bazel build process. I want to ensure compatibility with ARM64 architecture. **Docker version**: Docker version 27.1.1, build 6312585. **Bazel Version**: 7.3.1. **MacBook Model**: M1 chip (ARM64 architecture). **Error**: . ![IMG_3267](https://github.com/user-attachments/assets/11e28824-b941-42cc-9d33-7e9155a03543). ![IMG_3268](https://github.com/user-attachments/assets/4e923de6-99d5-43ee-80c6-29b32504527d). **My Dockerfilee code**:. ```. # Base image suitable for ARM64 architecture. FROM arm64v8/ubuntu:latest AS base. # Prevent interactive prompts. ENV DEBIAN_FRONTEND=noninteractive. # Install necessary packages. RUN apt-get update && \. apt-get install -y \. git \. curl \. unzip \. wget \. openjdk-17-jdk \. build-essential \. bzip2 \. python3-pip \. parallel && \. apt-get clean && \. rm -rf /var/lib/apt/lists/*. # Install Bazel (adjust version as needed). RUN curl -LO ""https://github.com/bazelbuild/bazel/releases/download/7.3.1/bazel-7.3.1-linux-arm64"" && \. chmod +x bazel-7.3.1-linux-arm64 && \. mv bazel-7.3.1-linux-arm64 /usr/local/bin/bazel. # Install Conda. RUN curl -LO ""https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-aarch64.sh"" && \. bash Miniconda3-latest-Linux-aarch64.sh -b -p /opt/miniconda && \. rm Miniconda3-latest-Linux-aarch64.sh. # Setup Conda environment. ENV PATH=""/opt/miniconda/bin:${PATH}"". RUN conda config --add channels defaults && \. conda config --add channels bioconda && \. conda config --add channels conda-forge && \. conda create -n bio bioconda::bcftools bioconda::samtools -y && \. conda clean -a. # Clone DeepVariant and build. FROM base AS builder. # Clone the DeepVariant repository. RUN git clone https://github.com/google/deepvariant.git /opt/deepvariant && \. cd /opt/deepvariant && ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/871
https://github.com/google/deepvariant/issues/871:965,deployability,build,build-essential,965,"Troubleshooting Dockerfile for DeepVariant on Mac M1: Issues with Bazel ; Im new to working with computers tools like DeepVariant. Im trying to build DeepVariant using Docker on a Mac M1 and am encountering issues with the Dockerfile during the Bazel build process. I want to ensure compatibility with ARM64 architecture. **Docker version**: Docker version 27.1.1, build 6312585. **Bazel Version**: 7.3.1. **MacBook Model**: M1 chip (ARM64 architecture). **Error**: . ![IMG_3267](https://github.com/user-attachments/assets/11e28824-b941-42cc-9d33-7e9155a03543). ![IMG_3268](https://github.com/user-attachments/assets/4e923de6-99d5-43ee-80c6-29b32504527d). **My Dockerfilee code**:. ```. # Base image suitable for ARM64 architecture. FROM arm64v8/ubuntu:latest AS base. # Prevent interactive prompts. ENV DEBIAN_FRONTEND=noninteractive. # Install necessary packages. RUN apt-get update && \. apt-get install -y \. git \. curl \. unzip \. wget \. openjdk-17-jdk \. build-essential \. bzip2 \. python3-pip \. parallel && \. apt-get clean && \. rm -rf /var/lib/apt/lists/*. # Install Bazel (adjust version as needed). RUN curl -LO ""https://github.com/bazelbuild/bazel/releases/download/7.3.1/bazel-7.3.1-linux-arm64"" && \. chmod +x bazel-7.3.1-linux-arm64 && \. mv bazel-7.3.1-linux-arm64 /usr/local/bin/bazel. # Install Conda. RUN curl -LO ""https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-aarch64.sh"" && \. bash Miniconda3-latest-Linux-aarch64.sh -b -p /opt/miniconda && \. rm Miniconda3-latest-Linux-aarch64.sh. # Setup Conda environment. ENV PATH=""/opt/miniconda/bin:${PATH}"". RUN conda config --add channels defaults && \. conda config --add channels bioconda && \. conda config --add channels conda-forge && \. conda create -n bio bioconda::bcftools bioconda::samtools -y && \. conda clean -a. # Clone DeepVariant and build. FROM base AS builder. # Clone the DeepVariant repository. RUN git clone https://github.com/google/deepvariant.git /opt/deepvariant && \. cd /opt/deepvariant && ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/871
https://github.com/google/deepvariant/issues/871:1074,deployability,Instal,Install,1074,"new to working with computers tools like DeepVariant. Im trying to build DeepVariant using Docker on a Mac M1 and am encountering issues with the Dockerfile during the Bazel build process. I want to ensure compatibility with ARM64 architecture. **Docker version**: Docker version 27.1.1, build 6312585. **Bazel Version**: 7.3.1. **MacBook Model**: M1 chip (ARM64 architecture). **Error**: . ![IMG_3267](https://github.com/user-attachments/assets/11e28824-b941-42cc-9d33-7e9155a03543). ![IMG_3268](https://github.com/user-attachments/assets/4e923de6-99d5-43ee-80c6-29b32504527d). **My Dockerfilee code**:. ```. # Base image suitable for ARM64 architecture. FROM arm64v8/ubuntu:latest AS base. # Prevent interactive prompts. ENV DEBIAN_FRONTEND=noninteractive. # Install necessary packages. RUN apt-get update && \. apt-get install -y \. git \. curl \. unzip \. wget \. openjdk-17-jdk \. build-essential \. bzip2 \. python3-pip \. parallel && \. apt-get clean && \. rm -rf /var/lib/apt/lists/*. # Install Bazel (adjust version as needed). RUN curl -LO ""https://github.com/bazelbuild/bazel/releases/download/7.3.1/bazel-7.3.1-linux-arm64"" && \. chmod +x bazel-7.3.1-linux-arm64 && \. mv bazel-7.3.1-linux-arm64 /usr/local/bin/bazel. # Install Conda. RUN curl -LO ""https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-aarch64.sh"" && \. bash Miniconda3-latest-Linux-aarch64.sh -b -p /opt/miniconda && \. rm Miniconda3-latest-Linux-aarch64.sh. # Setup Conda environment. ENV PATH=""/opt/miniconda/bin:${PATH}"". RUN conda config --add channels defaults && \. conda config --add channels bioconda && \. conda config --add channels conda-forge && \. conda create -n bio bioconda::bcftools bioconda::samtools -y && \. conda clean -a. # Clone DeepVariant and build. FROM base AS builder. # Clone the DeepVariant repository. RUN git clone https://github.com/google/deepvariant.git /opt/deepvariant && \. cd /opt/deepvariant && \. git checkout tags/v1.6.1. # Run Bazel build with additional flags to skip p",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/871
https://github.com/google/deepvariant/issues/871:1096,deployability,version,version,1096,"mputers tools like DeepVariant. Im trying to build DeepVariant using Docker on a Mac M1 and am encountering issues with the Dockerfile during the Bazel build process. I want to ensure compatibility with ARM64 architecture. **Docker version**: Docker version 27.1.1, build 6312585. **Bazel Version**: 7.3.1. **MacBook Model**: M1 chip (ARM64 architecture). **Error**: . ![IMG_3267](https://github.com/user-attachments/assets/11e28824-b941-42cc-9d33-7e9155a03543). ![IMG_3268](https://github.com/user-attachments/assets/4e923de6-99d5-43ee-80c6-29b32504527d). **My Dockerfilee code**:. ```. # Base image suitable for ARM64 architecture. FROM arm64v8/ubuntu:latest AS base. # Prevent interactive prompts. ENV DEBIAN_FRONTEND=noninteractive. # Install necessary packages. RUN apt-get update && \. apt-get install -y \. git \. curl \. unzip \. wget \. openjdk-17-jdk \. build-essential \. bzip2 \. python3-pip \. parallel && \. apt-get clean && \. rm -rf /var/lib/apt/lists/*. # Install Bazel (adjust version as needed). RUN curl -LO ""https://github.com/bazelbuild/bazel/releases/download/7.3.1/bazel-7.3.1-linux-arm64"" && \. chmod +x bazel-7.3.1-linux-arm64 && \. mv bazel-7.3.1-linux-arm64 /usr/local/bin/bazel. # Install Conda. RUN curl -LO ""https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-aarch64.sh"" && \. bash Miniconda3-latest-Linux-aarch64.sh -b -p /opt/miniconda && \. rm Miniconda3-latest-Linux-aarch64.sh. # Setup Conda environment. ENV PATH=""/opt/miniconda/bin:${PATH}"". RUN conda config --add channels defaults && \. conda config --add channels bioconda && \. conda config --add channels conda-forge && \. conda create -n bio bioconda::bcftools bioconda::samtools -y && \. conda clean -a. # Clone DeepVariant and build. FROM base AS builder. # Clone the DeepVariant repository. RUN git clone https://github.com/google/deepvariant.git /opt/deepvariant && \. cd /opt/deepvariant && \. git checkout tags/v1.6.1. # Run Bazel build with additional flags to skip problematic configurati",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/871
https://github.com/google/deepvariant/issues/871:1166,deployability,releas,releases,1166,"Docker on a Mac M1 and am encountering issues with the Dockerfile during the Bazel build process. I want to ensure compatibility with ARM64 architecture. **Docker version**: Docker version 27.1.1, build 6312585. **Bazel Version**: 7.3.1. **MacBook Model**: M1 chip (ARM64 architecture). **Error**: . ![IMG_3267](https://github.com/user-attachments/assets/11e28824-b941-42cc-9d33-7e9155a03543). ![IMG_3268](https://github.com/user-attachments/assets/4e923de6-99d5-43ee-80c6-29b32504527d). **My Dockerfilee code**:. ```. # Base image suitable for ARM64 architecture. FROM arm64v8/ubuntu:latest AS base. # Prevent interactive prompts. ENV DEBIAN_FRONTEND=noninteractive. # Install necessary packages. RUN apt-get update && \. apt-get install -y \. git \. curl \. unzip \. wget \. openjdk-17-jdk \. build-essential \. bzip2 \. python3-pip \. parallel && \. apt-get clean && \. rm -rf /var/lib/apt/lists/*. # Install Bazel (adjust version as needed). RUN curl -LO ""https://github.com/bazelbuild/bazel/releases/download/7.3.1/bazel-7.3.1-linux-arm64"" && \. chmod +x bazel-7.3.1-linux-arm64 && \. mv bazel-7.3.1-linux-arm64 /usr/local/bin/bazel. # Install Conda. RUN curl -LO ""https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-aarch64.sh"" && \. bash Miniconda3-latest-Linux-aarch64.sh -b -p /opt/miniconda && \. rm Miniconda3-latest-Linux-aarch64.sh. # Setup Conda environment. ENV PATH=""/opt/miniconda/bin:${PATH}"". RUN conda config --add channels defaults && \. conda config --add channels bioconda && \. conda config --add channels conda-forge && \. conda create -n bio bioconda::bcftools bioconda::samtools -y && \. conda clean -a. # Clone DeepVariant and build. FROM base AS builder. # Clone the DeepVariant repository. RUN git clone https://github.com/google/deepvariant.git /opt/deepvariant && \. cd /opt/deepvariant && \. git checkout tags/v1.6.1. # Run Bazel build with additional flags to skip problematic configurations. RUN bazel build -c opt --noincremental --experimental_action_list",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/871
https://github.com/google/deepvariant/issues/871:1311,deployability,Instal,Install,1311,"tecture. **Docker version**: Docker version 27.1.1, build 6312585. **Bazel Version**: 7.3.1. **MacBook Model**: M1 chip (ARM64 architecture). **Error**: . ![IMG_3267](https://github.com/user-attachments/assets/11e28824-b941-42cc-9d33-7e9155a03543). ![IMG_3268](https://github.com/user-attachments/assets/4e923de6-99d5-43ee-80c6-29b32504527d). **My Dockerfilee code**:. ```. # Base image suitable for ARM64 architecture. FROM arm64v8/ubuntu:latest AS base. # Prevent interactive prompts. ENV DEBIAN_FRONTEND=noninteractive. # Install necessary packages. RUN apt-get update && \. apt-get install -y \. git \. curl \. unzip \. wget \. openjdk-17-jdk \. build-essential \. bzip2 \. python3-pip \. parallel && \. apt-get clean && \. rm -rf /var/lib/apt/lists/*. # Install Bazel (adjust version as needed). RUN curl -LO ""https://github.com/bazelbuild/bazel/releases/download/7.3.1/bazel-7.3.1-linux-arm64"" && \. chmod +x bazel-7.3.1-linux-arm64 && \. mv bazel-7.3.1-linux-arm64 /usr/local/bin/bazel. # Install Conda. RUN curl -LO ""https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-aarch64.sh"" && \. bash Miniconda3-latest-Linux-aarch64.sh -b -p /opt/miniconda && \. rm Miniconda3-latest-Linux-aarch64.sh. # Setup Conda environment. ENV PATH=""/opt/miniconda/bin:${PATH}"". RUN conda config --add channels defaults && \. conda config --add channels bioconda && \. conda config --add channels conda-forge && \. conda create -n bio bioconda::bcftools bioconda::samtools -y && \. conda clean -a. # Clone DeepVariant and build. FROM base AS builder. # Clone the DeepVariant repository. RUN git clone https://github.com/google/deepvariant.git /opt/deepvariant && \. cd /opt/deepvariant && \. git checkout tags/v1.6.1. # Run Bazel build with additional flags to skip problematic configurations. RUN bazel build -c opt --noincremental --experimental_action_listener= //deepvariant:make_examples //deepvariant:call_variants //deepvariant:postprocess_variants || { \. echo ""Bazel build failed""; \. exit 1; }.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/871
https://github.com/google/deepvariant/issues/871:1833,deployability,build,build,1833,". # Install necessary packages. RUN apt-get update && \. apt-get install -y \. git \. curl \. unzip \. wget \. openjdk-17-jdk \. build-essential \. bzip2 \. python3-pip \. parallel && \. apt-get clean && \. rm -rf /var/lib/apt/lists/*. # Install Bazel (adjust version as needed). RUN curl -LO ""https://github.com/bazelbuild/bazel/releases/download/7.3.1/bazel-7.3.1-linux-arm64"" && \. chmod +x bazel-7.3.1-linux-arm64 && \. mv bazel-7.3.1-linux-arm64 /usr/local/bin/bazel. # Install Conda. RUN curl -LO ""https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-aarch64.sh"" && \. bash Miniconda3-latest-Linux-aarch64.sh -b -p /opt/miniconda && \. rm Miniconda3-latest-Linux-aarch64.sh. # Setup Conda environment. ENV PATH=""/opt/miniconda/bin:${PATH}"". RUN conda config --add channels defaults && \. conda config --add channels bioconda && \. conda config --add channels conda-forge && \. conda create -n bio bioconda::bcftools bioconda::samtools -y && \. conda clean -a. # Clone DeepVariant and build. FROM base AS builder. # Clone the DeepVariant repository. RUN git clone https://github.com/google/deepvariant.git /opt/deepvariant && \. cd /opt/deepvariant && \. git checkout tags/v1.6.1. # Run Bazel build with additional flags to skip problematic configurations. RUN bazel build -c opt --noincremental --experimental_action_listener= //deepvariant:make_examples //deepvariant:call_variants //deepvariant:postprocess_variants || { \. echo ""Bazel build failed""; \. exit 1; }. # Final image. FROM base AS final. # Set environment variables. ENV VERSION=1.6.0. ENV PYTHON_VERSION=3.8. ENV PATH=""/opt/miniconda/bin:${PATH}"". # Install Python packages. RUN pip install --upgrade pip setuptools wheel --timeout=120 && \. pip install jaxlib jax --timeout=120 --extra-index-url https://storage.googleapis.com/jax-releases/jax_releases.html. # Copy DeepVariant binaries from the builder stage. COPY --from=builder /opt/deepvariant /opt/deepvariant. WORKDIR /opt/deepvariant. # Ensure executable scripts a",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/871
https://github.com/google/deepvariant/issues/871:1853,deployability,build,builder,1853," packages. RUN apt-get update && \. apt-get install -y \. git \. curl \. unzip \. wget \. openjdk-17-jdk \. build-essential \. bzip2 \. python3-pip \. parallel && \. apt-get clean && \. rm -rf /var/lib/apt/lists/*. # Install Bazel (adjust version as needed). RUN curl -LO ""https://github.com/bazelbuild/bazel/releases/download/7.3.1/bazel-7.3.1-linux-arm64"" && \. chmod +x bazel-7.3.1-linux-arm64 && \. mv bazel-7.3.1-linux-arm64 /usr/local/bin/bazel. # Install Conda. RUN curl -LO ""https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-aarch64.sh"" && \. bash Miniconda3-latest-Linux-aarch64.sh -b -p /opt/miniconda && \. rm Miniconda3-latest-Linux-aarch64.sh. # Setup Conda environment. ENV PATH=""/opt/miniconda/bin:${PATH}"". RUN conda config --add channels defaults && \. conda config --add channels bioconda && \. conda config --add channels conda-forge && \. conda create -n bio bioconda::bcftools bioconda::samtools -y && \. conda clean -a. # Clone DeepVariant and build. FROM base AS builder. # Clone the DeepVariant repository. RUN git clone https://github.com/google/deepvariant.git /opt/deepvariant && \. cd /opt/deepvariant && \. git checkout tags/v1.6.1. # Run Bazel build with additional flags to skip problematic configurations. RUN bazel build -c opt --noincremental --experimental_action_listener= //deepvariant:make_examples //deepvariant:call_variants //deepvariant:postprocess_variants || { \. echo ""Bazel build failed""; \. exit 1; }. # Final image. FROM base AS final. # Set environment variables. ENV VERSION=1.6.0. ENV PYTHON_VERSION=3.8. ENV PATH=""/opt/miniconda/bin:${PATH}"". # Install Python packages. RUN pip install --upgrade pip setuptools wheel --timeout=120 && \. pip install jaxlib jax --timeout=120 --extra-index-url https://storage.googleapis.com/jax-releases/jax_releases.html. # Copy DeepVariant binaries from the builder stage. COPY --from=builder /opt/deepvariant /opt/deepvariant. WORKDIR /opt/deepvariant. # Ensure executable scripts are correctly set up. ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/871
https://github.com/google/deepvariant/issues/871:2041,deployability,build,build,2041,"m -rf /var/lib/apt/lists/*. # Install Bazel (adjust version as needed). RUN curl -LO ""https://github.com/bazelbuild/bazel/releases/download/7.3.1/bazel-7.3.1-linux-arm64"" && \. chmod +x bazel-7.3.1-linux-arm64 && \. mv bazel-7.3.1-linux-arm64 /usr/local/bin/bazel. # Install Conda. RUN curl -LO ""https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-aarch64.sh"" && \. bash Miniconda3-latest-Linux-aarch64.sh -b -p /opt/miniconda && \. rm Miniconda3-latest-Linux-aarch64.sh. # Setup Conda environment. ENV PATH=""/opt/miniconda/bin:${PATH}"". RUN conda config --add channels defaults && \. conda config --add channels bioconda && \. conda config --add channels conda-forge && \. conda create -n bio bioconda::bcftools bioconda::samtools -y && \. conda clean -a. # Clone DeepVariant and build. FROM base AS builder. # Clone the DeepVariant repository. RUN git clone https://github.com/google/deepvariant.git /opt/deepvariant && \. cd /opt/deepvariant && \. git checkout tags/v1.6.1. # Run Bazel build with additional flags to skip problematic configurations. RUN bazel build -c opt --noincremental --experimental_action_listener= //deepvariant:make_examples //deepvariant:call_variants //deepvariant:postprocess_variants || { \. echo ""Bazel build failed""; \. exit 1; }. # Final image. FROM base AS final. # Set environment variables. ENV VERSION=1.6.0. ENV PYTHON_VERSION=3.8. ENV PATH=""/opt/miniconda/bin:${PATH}"". # Install Python packages. RUN pip install --upgrade pip setuptools wheel --timeout=120 && \. pip install jaxlib jax --timeout=120 --extra-index-url https://storage.googleapis.com/jax-releases/jax_releases.html. # Copy DeepVariant binaries from the builder stage. COPY --from=builder /opt/deepvariant /opt/deepvariant. WORKDIR /opt/deepvariant. # Ensure executable scripts are correctly set up. RUN BASH_HEADER='#!/bin/bash' && \. for script in make_examples call_variants call_variants_slim postprocess_variants vcf_stats_report show_examples runtime_by_region_vis multisample_make",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/871
https://github.com/google/deepvariant/issues/871:2089,deployability,configurat,configurations,2089,"version as needed). RUN curl -LO ""https://github.com/bazelbuild/bazel/releases/download/7.3.1/bazel-7.3.1-linux-arm64"" && \. chmod +x bazel-7.3.1-linux-arm64 && \. mv bazel-7.3.1-linux-arm64 /usr/local/bin/bazel. # Install Conda. RUN curl -LO ""https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-aarch64.sh"" && \. bash Miniconda3-latest-Linux-aarch64.sh -b -p /opt/miniconda && \. rm Miniconda3-latest-Linux-aarch64.sh. # Setup Conda environment. ENV PATH=""/opt/miniconda/bin:${PATH}"". RUN conda config --add channels defaults && \. conda config --add channels bioconda && \. conda config --add channels conda-forge && \. conda create -n bio bioconda::bcftools bioconda::samtools -y && \. conda clean -a. # Clone DeepVariant and build. FROM base AS builder. # Clone the DeepVariant repository. RUN git clone https://github.com/google/deepvariant.git /opt/deepvariant && \. cd /opt/deepvariant && \. git checkout tags/v1.6.1. # Run Bazel build with additional flags to skip problematic configurations. RUN bazel build -c opt --noincremental --experimental_action_listener= //deepvariant:make_examples //deepvariant:call_variants //deepvariant:postprocess_variants || { \. echo ""Bazel build failed""; \. exit 1; }. # Final image. FROM base AS final. # Set environment variables. ENV VERSION=1.6.0. ENV PYTHON_VERSION=3.8. ENV PATH=""/opt/miniconda/bin:${PATH}"". # Install Python packages. RUN pip install --upgrade pip setuptools wheel --timeout=120 && \. pip install jaxlib jax --timeout=120 --extra-index-url https://storage.googleapis.com/jax-releases/jax_releases.html. # Copy DeepVariant binaries from the builder stage. COPY --from=builder /opt/deepvariant /opt/deepvariant. WORKDIR /opt/deepvariant. # Ensure executable scripts are correctly set up. RUN BASH_HEADER='#!/bin/bash' && \. for script in make_examples call_variants call_variants_slim postprocess_variants vcf_stats_report show_examples runtime_by_region_vis multisample_make_examples labeled_examples_to_vcf make_examples_soma",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/871
https://github.com/google/deepvariant/issues/871:2115,deployability,build,build,2115,"N curl -LO ""https://github.com/bazelbuild/bazel/releases/download/7.3.1/bazel-7.3.1-linux-arm64"" && \. chmod +x bazel-7.3.1-linux-arm64 && \. mv bazel-7.3.1-linux-arm64 /usr/local/bin/bazel. # Install Conda. RUN curl -LO ""https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-aarch64.sh"" && \. bash Miniconda3-latest-Linux-aarch64.sh -b -p /opt/miniconda && \. rm Miniconda3-latest-Linux-aarch64.sh. # Setup Conda environment. ENV PATH=""/opt/miniconda/bin:${PATH}"". RUN conda config --add channels defaults && \. conda config --add channels bioconda && \. conda config --add channels conda-forge && \. conda create -n bio bioconda::bcftools bioconda::samtools -y && \. conda clean -a. # Clone DeepVariant and build. FROM base AS builder. # Clone the DeepVariant repository. RUN git clone https://github.com/google/deepvariant.git /opt/deepvariant && \. cd /opt/deepvariant && \. git checkout tags/v1.6.1. # Run Bazel build with additional flags to skip problematic configurations. RUN bazel build -c opt --noincremental --experimental_action_listener= //deepvariant:make_examples //deepvariant:call_variants //deepvariant:postprocess_variants || { \. echo ""Bazel build failed""; \. exit 1; }. # Final image. FROM base AS final. # Set environment variables. ENV VERSION=1.6.0. ENV PYTHON_VERSION=3.8. ENV PATH=""/opt/miniconda/bin:${PATH}"". # Install Python packages. RUN pip install --upgrade pip setuptools wheel --timeout=120 && \. pip install jaxlib jax --timeout=120 --extra-index-url https://storage.googleapis.com/jax-releases/jax_releases.html. # Copy DeepVariant binaries from the builder stage. COPY --from=builder /opt/deepvariant /opt/deepvariant. WORKDIR /opt/deepvariant. # Ensure executable scripts are correctly set up. RUN BASH_HEADER='#!/bin/bash' && \. for script in make_examples call_variants call_variants_slim postprocess_variants vcf_stats_report show_examples runtime_by_region_vis multisample_make_examples labeled_examples_to_vcf make_examples_somatic train run_deepvari",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/871
https://github.com/google/deepvariant/issues/871:2287,deployability,build,build,2287,"r/local/bin/bazel. # Install Conda. RUN curl -LO ""https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-aarch64.sh"" && \. bash Miniconda3-latest-Linux-aarch64.sh -b -p /opt/miniconda && \. rm Miniconda3-latest-Linux-aarch64.sh. # Setup Conda environment. ENV PATH=""/opt/miniconda/bin:${PATH}"". RUN conda config --add channels defaults && \. conda config --add channels bioconda && \. conda config --add channels conda-forge && \. conda create -n bio bioconda::bcftools bioconda::samtools -y && \. conda clean -a. # Clone DeepVariant and build. FROM base AS builder. # Clone the DeepVariant repository. RUN git clone https://github.com/google/deepvariant.git /opt/deepvariant && \. cd /opt/deepvariant && \. git checkout tags/v1.6.1. # Run Bazel build with additional flags to skip problematic configurations. RUN bazel build -c opt --noincremental --experimental_action_listener= //deepvariant:make_examples //deepvariant:call_variants //deepvariant:postprocess_variants || { \. echo ""Bazel build failed""; \. exit 1; }. # Final image. FROM base AS final. # Set environment variables. ENV VERSION=1.6.0. ENV PYTHON_VERSION=3.8. ENV PATH=""/opt/miniconda/bin:${PATH}"". # Install Python packages. RUN pip install --upgrade pip setuptools wheel --timeout=120 && \. pip install jaxlib jax --timeout=120 --extra-index-url https://storage.googleapis.com/jax-releases/jax_releases.html. # Copy DeepVariant binaries from the builder stage. COPY --from=builder /opt/deepvariant /opt/deepvariant. WORKDIR /opt/deepvariant. # Ensure executable scripts are correctly set up. RUN BASH_HEADER='#!/bin/bash' && \. for script in make_examples call_variants call_variants_slim postprocess_variants vcf_stats_report show_examples runtime_by_region_vis multisample_make_examples labeled_examples_to_vcf make_examples_somatic train run_deepvariant run_deepsomatic; do \. printf ""%s\n%s\n"" ""${BASH_HEADER}"" ""python3 /opt/deepvariant/bin/${script}.zip \""$@\"""" > /opt/deepvariant/bin/${script} && \. chmod +x /opt/deepv",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/871
https://github.com/google/deepvariant/issues/871:2293,deployability,fail,failed,2293,"l/bin/bazel. # Install Conda. RUN curl -LO ""https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-aarch64.sh"" && \. bash Miniconda3-latest-Linux-aarch64.sh -b -p /opt/miniconda && \. rm Miniconda3-latest-Linux-aarch64.sh. # Setup Conda environment. ENV PATH=""/opt/miniconda/bin:${PATH}"". RUN conda config --add channels defaults && \. conda config --add channels bioconda && \. conda config --add channels conda-forge && \. conda create -n bio bioconda::bcftools bioconda::samtools -y && \. conda clean -a. # Clone DeepVariant and build. FROM base AS builder. # Clone the DeepVariant repository. RUN git clone https://github.com/google/deepvariant.git /opt/deepvariant && \. cd /opt/deepvariant && \. git checkout tags/v1.6.1. # Run Bazel build with additional flags to skip problematic configurations. RUN bazel build -c opt --noincremental --experimental_action_listener= //deepvariant:make_examples //deepvariant:call_variants //deepvariant:postprocess_variants || { \. echo ""Bazel build failed""; \. exit 1; }. # Final image. FROM base AS final. # Set environment variables. ENV VERSION=1.6.0. ENV PYTHON_VERSION=3.8. ENV PATH=""/opt/miniconda/bin:${PATH}"". # Install Python packages. RUN pip install --upgrade pip setuptools wheel --timeout=120 && \. pip install jaxlib jax --timeout=120 --extra-index-url https://storage.googleapis.com/jax-releases/jax_releases.html. # Copy DeepVariant binaries from the builder stage. COPY --from=builder /opt/deepvariant /opt/deepvariant. WORKDIR /opt/deepvariant. # Ensure executable scripts are correctly set up. RUN BASH_HEADER='#!/bin/bash' && \. for script in make_examples call_variants call_variants_slim postprocess_variants vcf_stats_report show_examples runtime_by_region_vis multisample_make_examples labeled_examples_to_vcf make_examples_somatic train run_deepvariant run_deepsomatic; do \. printf ""%s\n%s\n"" ""${BASH_HEADER}"" ""python3 /opt/deepvariant/bin/${script}.zip \""$@\"""" > /opt/deepvariant/bin/${script} && \. chmod +x /opt/deepvariant",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/871
https://github.com/google/deepvariant/issues/871:2384,deployability,VERSION,VERSION,2384,"atest-Linux-aarch64.sh"" && \. bash Miniconda3-latest-Linux-aarch64.sh -b -p /opt/miniconda && \. rm Miniconda3-latest-Linux-aarch64.sh. # Setup Conda environment. ENV PATH=""/opt/miniconda/bin:${PATH}"". RUN conda config --add channels defaults && \. conda config --add channels bioconda && \. conda config --add channels conda-forge && \. conda create -n bio bioconda::bcftools bioconda::samtools -y && \. conda clean -a. # Clone DeepVariant and build. FROM base AS builder. # Clone the DeepVariant repository. RUN git clone https://github.com/google/deepvariant.git /opt/deepvariant && \. cd /opt/deepvariant && \. git checkout tags/v1.6.1. # Run Bazel build with additional flags to skip problematic configurations. RUN bazel build -c opt --noincremental --experimental_action_listener= //deepvariant:make_examples //deepvariant:call_variants //deepvariant:postprocess_variants || { \. echo ""Bazel build failed""; \. exit 1; }. # Final image. FROM base AS final. # Set environment variables. ENV VERSION=1.6.0. ENV PYTHON_VERSION=3.8. ENV PATH=""/opt/miniconda/bin:${PATH}"". # Install Python packages. RUN pip install --upgrade pip setuptools wheel --timeout=120 && \. pip install jaxlib jax --timeout=120 --extra-index-url https://storage.googleapis.com/jax-releases/jax_releases.html. # Copy DeepVariant binaries from the builder stage. COPY --from=builder /opt/deepvariant /opt/deepvariant. WORKDIR /opt/deepvariant. # Ensure executable scripts are correctly set up. RUN BASH_HEADER='#!/bin/bash' && \. for script in make_examples call_variants call_variants_slim postprocess_variants vcf_stats_report show_examples runtime_by_region_vis multisample_make_examples labeled_examples_to_vcf make_examples_somatic train run_deepvariant run_deepsomatic; do \. printf ""%s\n%s\n"" ""${BASH_HEADER}"" ""python3 /opt/deepvariant/bin/${script}.zip \""$@\"""" > /opt/deepvariant/bin/${script} && \. chmod +x /opt/deepvariant/bin/${script}; \. done. # Copy licenses and other necessary files. # Ensure these paths and",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/871
https://github.com/google/deepvariant/issues/871:2464,deployability,Instal,Install,2464,"/miniconda && \. rm Miniconda3-latest-Linux-aarch64.sh. # Setup Conda environment. ENV PATH=""/opt/miniconda/bin:${PATH}"". RUN conda config --add channels defaults && \. conda config --add channels bioconda && \. conda config --add channels conda-forge && \. conda create -n bio bioconda::bcftools bioconda::samtools -y && \. conda clean -a. # Clone DeepVariant and build. FROM base AS builder. # Clone the DeepVariant repository. RUN git clone https://github.com/google/deepvariant.git /opt/deepvariant && \. cd /opt/deepvariant && \. git checkout tags/v1.6.1. # Run Bazel build with additional flags to skip problematic configurations. RUN bazel build -c opt --noincremental --experimental_action_listener= //deepvariant:make_examples //deepvariant:call_variants //deepvariant:postprocess_variants || { \. echo ""Bazel build failed""; \. exit 1; }. # Final image. FROM base AS final. # Set environment variables. ENV VERSION=1.6.0. ENV PYTHON_VERSION=3.8. ENV PATH=""/opt/miniconda/bin:${PATH}"". # Install Python packages. RUN pip install --upgrade pip setuptools wheel --timeout=120 && \. pip install jaxlib jax --timeout=120 --extra-index-url https://storage.googleapis.com/jax-releases/jax_releases.html. # Copy DeepVariant binaries from the builder stage. COPY --from=builder /opt/deepvariant /opt/deepvariant. WORKDIR /opt/deepvariant. # Ensure executable scripts are correctly set up. RUN BASH_HEADER='#!/bin/bash' && \. for script in make_examples call_variants call_variants_slim postprocess_variants vcf_stats_report show_examples runtime_by_region_vis multisample_make_examples labeled_examples_to_vcf make_examples_somatic train run_deepvariant run_deepsomatic; do \. printf ""%s\n%s\n"" ""${BASH_HEADER}"" ""python3 /opt/deepvariant/bin/${script}.zip \""$@\"""" > /opt/deepvariant/bin/${script} && \. chmod +x /opt/deepvariant/bin/${script}; \. done. # Copy licenses and other necessary files. # Ensure these paths and URLs are correct and accessible. # Replace with valid URLs or remove if not nee",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/871
https://github.com/google/deepvariant/issues/871:2497,deployability,instal,install,2497,"test-Linux-aarch64.sh. # Setup Conda environment. ENV PATH=""/opt/miniconda/bin:${PATH}"". RUN conda config --add channels defaults && \. conda config --add channels bioconda && \. conda config --add channels conda-forge && \. conda create -n bio bioconda::bcftools bioconda::samtools -y && \. conda clean -a. # Clone DeepVariant and build. FROM base AS builder. # Clone the DeepVariant repository. RUN git clone https://github.com/google/deepvariant.git /opt/deepvariant && \. cd /opt/deepvariant && \. git checkout tags/v1.6.1. # Run Bazel build with additional flags to skip problematic configurations. RUN bazel build -c opt --noincremental --experimental_action_listener= //deepvariant:make_examples //deepvariant:call_variants //deepvariant:postprocess_variants || { \. echo ""Bazel build failed""; \. exit 1; }. # Final image. FROM base AS final. # Set environment variables. ENV VERSION=1.6.0. ENV PYTHON_VERSION=3.8. ENV PATH=""/opt/miniconda/bin:${PATH}"". # Install Python packages. RUN pip install --upgrade pip setuptools wheel --timeout=120 && \. pip install jaxlib jax --timeout=120 --extra-index-url https://storage.googleapis.com/jax-releases/jax_releases.html. # Copy DeepVariant binaries from the builder stage. COPY --from=builder /opt/deepvariant /opt/deepvariant. WORKDIR /opt/deepvariant. # Ensure executable scripts are correctly set up. RUN BASH_HEADER='#!/bin/bash' && \. for script in make_examples call_variants call_variants_slim postprocess_variants vcf_stats_report show_examples runtime_by_region_vis multisample_make_examples labeled_examples_to_vcf make_examples_somatic train run_deepvariant run_deepsomatic; do \. printf ""%s\n%s\n"" ""${BASH_HEADER}"" ""python3 /opt/deepvariant/bin/${script}.zip \""$@\"""" > /opt/deepvariant/bin/${script} && \. chmod +x /opt/deepvariant/bin/${script}; \. done. # Copy licenses and other necessary files. # Ensure these paths and URLs are correct and accessible. # Replace with valid URLs or remove if not needed. ADD https://storage.googleap",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/871
https://github.com/google/deepvariant/issues/871:2507,deployability,upgrad,upgrade,2507,"-aarch64.sh. # Setup Conda environment. ENV PATH=""/opt/miniconda/bin:${PATH}"". RUN conda config --add channels defaults && \. conda config --add channels bioconda && \. conda config --add channels conda-forge && \. conda create -n bio bioconda::bcftools bioconda::samtools -y && \. conda clean -a. # Clone DeepVariant and build. FROM base AS builder. # Clone the DeepVariant repository. RUN git clone https://github.com/google/deepvariant.git /opt/deepvariant && \. cd /opt/deepvariant && \. git checkout tags/v1.6.1. # Run Bazel build with additional flags to skip problematic configurations. RUN bazel build -c opt --noincremental --experimental_action_listener= //deepvariant:make_examples //deepvariant:call_variants //deepvariant:postprocess_variants || { \. echo ""Bazel build failed""; \. exit 1; }. # Final image. FROM base AS final. # Set environment variables. ENV VERSION=1.6.0. ENV PYTHON_VERSION=3.8. ENV PATH=""/opt/miniconda/bin:${PATH}"". # Install Python packages. RUN pip install --upgrade pip setuptools wheel --timeout=120 && \. pip install jaxlib jax --timeout=120 --extra-index-url https://storage.googleapis.com/jax-releases/jax_releases.html. # Copy DeepVariant binaries from the builder stage. COPY --from=builder /opt/deepvariant /opt/deepvariant. WORKDIR /opt/deepvariant. # Ensure executable scripts are correctly set up. RUN BASH_HEADER='#!/bin/bash' && \. for script in make_examples call_variants call_variants_slim postprocess_variants vcf_stats_report show_examples runtime_by_region_vis multisample_make_examples labeled_examples_to_vcf make_examples_somatic train run_deepvariant run_deepsomatic; do \. printf ""%s\n%s\n"" ""${BASH_HEADER}"" ""python3 /opt/deepvariant/bin/${script}.zip \""$@\"""" > /opt/deepvariant/bin/${script} && \. chmod +x /opt/deepvariant/bin/${script}; \. done. # Copy licenses and other necessary files. # Ensure these paths and URLs are correct and accessible. # Replace with valid URLs or remove if not needed. ADD https://storage.googleapis.com/dee",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/871
https://github.com/google/deepvariant/issues/871:2560,deployability,instal,install,2560,"t/miniconda/bin:${PATH}"". RUN conda config --add channels defaults && \. conda config --add channels bioconda && \. conda config --add channels conda-forge && \. conda create -n bio bioconda::bcftools bioconda::samtools -y && \. conda clean -a. # Clone DeepVariant and build. FROM base AS builder. # Clone the DeepVariant repository. RUN git clone https://github.com/google/deepvariant.git /opt/deepvariant && \. cd /opt/deepvariant && \. git checkout tags/v1.6.1. # Run Bazel build with additional flags to skip problematic configurations. RUN bazel build -c opt --noincremental --experimental_action_listener= //deepvariant:make_examples //deepvariant:call_variants //deepvariant:postprocess_variants || { \. echo ""Bazel build failed""; \. exit 1; }. # Final image. FROM base AS final. # Set environment variables. ENV VERSION=1.6.0. ENV PYTHON_VERSION=3.8. ENV PATH=""/opt/miniconda/bin:${PATH}"". # Install Python packages. RUN pip install --upgrade pip setuptools wheel --timeout=120 && \. pip install jaxlib jax --timeout=120 --extra-index-url https://storage.googleapis.com/jax-releases/jax_releases.html. # Copy DeepVariant binaries from the builder stage. COPY --from=builder /opt/deepvariant /opt/deepvariant. WORKDIR /opt/deepvariant. # Ensure executable scripts are correctly set up. RUN BASH_HEADER='#!/bin/bash' && \. for script in make_examples call_variants call_variants_slim postprocess_variants vcf_stats_report show_examples runtime_by_region_vis multisample_make_examples labeled_examples_to_vcf make_examples_somatic train run_deepvariant run_deepsomatic; do \. printf ""%s\n%s\n"" ""${BASH_HEADER}"" ""python3 /opt/deepvariant/bin/${script}.zip \""$@\"""" > /opt/deepvariant/bin/${script} && \. chmod +x /opt/deepvariant/bin/${script}; \. done. # Copy licenses and other necessary files. # Ensure these paths and URLs are correct and accessible. # Replace with valid URLs or remove if not needed. ADD https://storage.googleapis.com/deepvariant/models/DeepVariant/1.6.0/savedmodels/deepvar",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/871
https://github.com/google/deepvariant/issues/871:2646,deployability,releas,releases,2646,"--add channels bioconda && \. conda config --add channels conda-forge && \. conda create -n bio bioconda::bcftools bioconda::samtools -y && \. conda clean -a. # Clone DeepVariant and build. FROM base AS builder. # Clone the DeepVariant repository. RUN git clone https://github.com/google/deepvariant.git /opt/deepvariant && \. cd /opt/deepvariant && \. git checkout tags/v1.6.1. # Run Bazel build with additional flags to skip problematic configurations. RUN bazel build -c opt --noincremental --experimental_action_listener= //deepvariant:make_examples //deepvariant:call_variants //deepvariant:postprocess_variants || { \. echo ""Bazel build failed""; \. exit 1; }. # Final image. FROM base AS final. # Set environment variables. ENV VERSION=1.6.0. ENV PYTHON_VERSION=3.8. ENV PATH=""/opt/miniconda/bin:${PATH}"". # Install Python packages. RUN pip install --upgrade pip setuptools wheel --timeout=120 && \. pip install jaxlib jax --timeout=120 --extra-index-url https://storage.googleapis.com/jax-releases/jax_releases.html. # Copy DeepVariant binaries from the builder stage. COPY --from=builder /opt/deepvariant /opt/deepvariant. WORKDIR /opt/deepvariant. # Ensure executable scripts are correctly set up. RUN BASH_HEADER='#!/bin/bash' && \. for script in make_examples call_variants call_variants_slim postprocess_variants vcf_stats_report show_examples runtime_by_region_vis multisample_make_examples labeled_examples_to_vcf make_examples_somatic train run_deepvariant run_deepsomatic; do \. printf ""%s\n%s\n"" ""${BASH_HEADER}"" ""python3 /opt/deepvariant/bin/${script}.zip \""$@\"""" > /opt/deepvariant/bin/${script} && \. chmod +x /opt/deepvariant/bin/${script}; \. done. # Copy licenses and other necessary files. # Ensure these paths and URLs are correct and accessible. # Replace with valid URLs or remove if not needed. ADD https://storage.googleapis.com/deepvariant/models/DeepVariant/1.6.0/savedmodels/deepvariant.hybrid.savedmodel/saved_model.pb /models/. WORKDIR /opt/deepvariant/bin/. COPY --",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/871
https://github.com/google/deepvariant/issues/871:2711,deployability,build,builder,2711,"orge && \. conda create -n bio bioconda::bcftools bioconda::samtools -y && \. conda clean -a. # Clone DeepVariant and build. FROM base AS builder. # Clone the DeepVariant repository. RUN git clone https://github.com/google/deepvariant.git /opt/deepvariant && \. cd /opt/deepvariant && \. git checkout tags/v1.6.1. # Run Bazel build with additional flags to skip problematic configurations. RUN bazel build -c opt --noincremental --experimental_action_listener= //deepvariant:make_examples //deepvariant:call_variants //deepvariant:postprocess_variants || { \. echo ""Bazel build failed""; \. exit 1; }. # Final image. FROM base AS final. # Set environment variables. ENV VERSION=1.6.0. ENV PYTHON_VERSION=3.8. ENV PATH=""/opt/miniconda/bin:${PATH}"". # Install Python packages. RUN pip install --upgrade pip setuptools wheel --timeout=120 && \. pip install jaxlib jax --timeout=120 --extra-index-url https://storage.googleapis.com/jax-releases/jax_releases.html. # Copy DeepVariant binaries from the builder stage. COPY --from=builder /opt/deepvariant /opt/deepvariant. WORKDIR /opt/deepvariant. # Ensure executable scripts are correctly set up. RUN BASH_HEADER='#!/bin/bash' && \. for script in make_examples call_variants call_variants_slim postprocess_variants vcf_stats_report show_examples runtime_by_region_vis multisample_make_examples labeled_examples_to_vcf make_examples_somatic train run_deepvariant run_deepsomatic; do \. printf ""%s\n%s\n"" ""${BASH_HEADER}"" ""python3 /opt/deepvariant/bin/${script}.zip \""$@\"""" > /opt/deepvariant/bin/${script} && \. chmod +x /opt/deepvariant/bin/${script}; \. done. # Copy licenses and other necessary files. # Ensure these paths and URLs are correct and accessible. # Replace with valid URLs or remove if not needed. ADD https://storage.googleapis.com/deepvariant/models/DeepVariant/1.6.0/savedmodels/deepvariant.hybrid.savedmodel/saved_model.pb /models/. WORKDIR /opt/deepvariant/bin/. COPY --from=builder /opt/conda /opt/conda. COPY --from=builder /opt/deep",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/871
https://github.com/google/deepvariant/issues/871:2719,deployability,stage,stage,2719," \. conda create -n bio bioconda::bcftools bioconda::samtools -y && \. conda clean -a. # Clone DeepVariant and build. FROM base AS builder. # Clone the DeepVariant repository. RUN git clone https://github.com/google/deepvariant.git /opt/deepvariant && \. cd /opt/deepvariant && \. git checkout tags/v1.6.1. # Run Bazel build with additional flags to skip problematic configurations. RUN bazel build -c opt --noincremental --experimental_action_listener= //deepvariant:make_examples //deepvariant:call_variants //deepvariant:postprocess_variants || { \. echo ""Bazel build failed""; \. exit 1; }. # Final image. FROM base AS final. # Set environment variables. ENV VERSION=1.6.0. ENV PYTHON_VERSION=3.8. ENV PATH=""/opt/miniconda/bin:${PATH}"". # Install Python packages. RUN pip install --upgrade pip setuptools wheel --timeout=120 && \. pip install jaxlib jax --timeout=120 --extra-index-url https://storage.googleapis.com/jax-releases/jax_releases.html. # Copy DeepVariant binaries from the builder stage. COPY --from=builder /opt/deepvariant /opt/deepvariant. WORKDIR /opt/deepvariant. # Ensure executable scripts are correctly set up. RUN BASH_HEADER='#!/bin/bash' && \. for script in make_examples call_variants call_variants_slim postprocess_variants vcf_stats_report show_examples runtime_by_region_vis multisample_make_examples labeled_examples_to_vcf make_examples_somatic train run_deepvariant run_deepsomatic; do \. printf ""%s\n%s\n"" ""${BASH_HEADER}"" ""python3 /opt/deepvariant/bin/${script}.zip \""$@\"""" > /opt/deepvariant/bin/${script} && \. chmod +x /opt/deepvariant/bin/${script}; \. done. # Copy licenses and other necessary files. # Ensure these paths and URLs are correct and accessible. # Replace with valid URLs or remove if not needed. ADD https://storage.googleapis.com/deepvariant/models/DeepVariant/1.6.0/savedmodels/deepvariant.hybrid.savedmodel/saved_model.pb /models/. WORKDIR /opt/deepvariant/bin/. COPY --from=builder /opt/conda /opt/conda. COPY --from=builder /opt/deepvariant",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/871
https://github.com/google/deepvariant/issues/871:2738,deployability,build,builder,2738,"bio bioconda::bcftools bioconda::samtools -y && \. conda clean -a. # Clone DeepVariant and build. FROM base AS builder. # Clone the DeepVariant repository. RUN git clone https://github.com/google/deepvariant.git /opt/deepvariant && \. cd /opt/deepvariant && \. git checkout tags/v1.6.1. # Run Bazel build with additional flags to skip problematic configurations. RUN bazel build -c opt --noincremental --experimental_action_listener= //deepvariant:make_examples //deepvariant:call_variants //deepvariant:postprocess_variants || { \. echo ""Bazel build failed""; \. exit 1; }. # Final image. FROM base AS final. # Set environment variables. ENV VERSION=1.6.0. ENV PYTHON_VERSION=3.8. ENV PATH=""/opt/miniconda/bin:${PATH}"". # Install Python packages. RUN pip install --upgrade pip setuptools wheel --timeout=120 && \. pip install jaxlib jax --timeout=120 --extra-index-url https://storage.googleapis.com/jax-releases/jax_releases.html. # Copy DeepVariant binaries from the builder stage. COPY --from=builder /opt/deepvariant /opt/deepvariant. WORKDIR /opt/deepvariant. # Ensure executable scripts are correctly set up. RUN BASH_HEADER='#!/bin/bash' && \. for script in make_examples call_variants call_variants_slim postprocess_variants vcf_stats_report show_examples runtime_by_region_vis multisample_make_examples labeled_examples_to_vcf make_examples_somatic train run_deepvariant run_deepsomatic; do \. printf ""%s\n%s\n"" ""${BASH_HEADER}"" ""python3 /opt/deepvariant/bin/${script}.zip \""$@\"""" > /opt/deepvariant/bin/${script} && \. chmod +x /opt/deepvariant/bin/${script}; \. done. # Copy licenses and other necessary files. # Ensure these paths and URLs are correct and accessible. # Replace with valid URLs or remove if not needed. ADD https://storage.googleapis.com/deepvariant/models/DeepVariant/1.6.0/savedmodels/deepvariant.hybrid.savedmodel/saved_model.pb /models/. WORKDIR /opt/deepvariant/bin/. COPY --from=builder /opt/conda /opt/conda. COPY --from=builder /opt/deepvariant/run-prereq.sh . COP",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/871
https://github.com/google/deepvariant/issues/871:3655,deployability,build,builder,3655,"releases.html. # Copy DeepVariant binaries from the builder stage. COPY --from=builder /opt/deepvariant /opt/deepvariant. WORKDIR /opt/deepvariant. # Ensure executable scripts are correctly set up. RUN BASH_HEADER='#!/bin/bash' && \. for script in make_examples call_variants call_variants_slim postprocess_variants vcf_stats_report show_examples runtime_by_region_vis multisample_make_examples labeled_examples_to_vcf make_examples_somatic train run_deepvariant run_deepsomatic; do \. printf ""%s\n%s\n"" ""${BASH_HEADER}"" ""python3 /opt/deepvariant/bin/${script}.zip \""$@\"""" > /opt/deepvariant/bin/${script} && \. chmod +x /opt/deepvariant/bin/${script}; \. done. # Copy licenses and other necessary files. # Ensure these paths and URLs are correct and accessible. # Replace with valid URLs or remove if not needed. ADD https://storage.googleapis.com/deepvariant/models/DeepVariant/1.6.0/savedmodels/deepvariant.hybrid.savedmodel/saved_model.pb /models/. WORKDIR /opt/deepvariant/bin/. COPY --from=builder /opt/conda /opt/conda. COPY --from=builder /opt/deepvariant/run-prereq.sh . COPY --from=builder /opt/deepvariant/settings.sh . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/make_examples.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/call_variants.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/call_variants_slim.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/postprocess_variants.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/vcf_stats_report.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/show_examples.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/runtime_by_region_vis.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/multisample_make_examples.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/labeler/labeled_examples_to_vcf.zip . COPY -",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/871
https://github.com/google/deepvariant/issues/871:3698,deployability,build,builder,3698,"from the builder stage. COPY --from=builder /opt/deepvariant /opt/deepvariant. WORKDIR /opt/deepvariant. # Ensure executable scripts are correctly set up. RUN BASH_HEADER='#!/bin/bash' && \. for script in make_examples call_variants call_variants_slim postprocess_variants vcf_stats_report show_examples runtime_by_region_vis multisample_make_examples labeled_examples_to_vcf make_examples_somatic train run_deepvariant run_deepsomatic; do \. printf ""%s\n%s\n"" ""${BASH_HEADER}"" ""python3 /opt/deepvariant/bin/${script}.zip \""$@\"""" > /opt/deepvariant/bin/${script} && \. chmod +x /opt/deepvariant/bin/${script}; \. done. # Copy licenses and other necessary files. # Ensure these paths and URLs are correct and accessible. # Replace with valid URLs or remove if not needed. ADD https://storage.googleapis.com/deepvariant/models/DeepVariant/1.6.0/savedmodels/deepvariant.hybrid.savedmodel/saved_model.pb /models/. WORKDIR /opt/deepvariant/bin/. COPY --from=builder /opt/conda /opt/conda. COPY --from=builder /opt/deepvariant/run-prereq.sh . COPY --from=builder /opt/deepvariant/settings.sh . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/make_examples.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/call_variants.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/call_variants_slim.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/postprocess_variants.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/vcf_stats_report.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/show_examples.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/runtime_by_region_vis.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/multisample_make_examples.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/labeler/labeled_examples_to_vcf.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/871
https://github.com/google/deepvariant/issues/871:3751,deployability,build,builder,3751,"variant /opt/deepvariant. WORKDIR /opt/deepvariant. # Ensure executable scripts are correctly set up. RUN BASH_HEADER='#!/bin/bash' && \. for script in make_examples call_variants call_variants_slim postprocess_variants vcf_stats_report show_examples runtime_by_region_vis multisample_make_examples labeled_examples_to_vcf make_examples_somatic train run_deepvariant run_deepsomatic; do \. printf ""%s\n%s\n"" ""${BASH_HEADER}"" ""python3 /opt/deepvariant/bin/${script}.zip \""$@\"""" > /opt/deepvariant/bin/${script} && \. chmod +x /opt/deepvariant/bin/${script}; \. done. # Copy licenses and other necessary files. # Ensure these paths and URLs are correct and accessible. # Replace with valid URLs or remove if not needed. ADD https://storage.googleapis.com/deepvariant/models/DeepVariant/1.6.0/savedmodels/deepvariant.hybrid.savedmodel/saved_model.pb /models/. WORKDIR /opt/deepvariant/bin/. COPY --from=builder /opt/conda /opt/conda. COPY --from=builder /opt/deepvariant/run-prereq.sh . COPY --from=builder /opt/deepvariant/settings.sh . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/make_examples.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/call_variants.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/call_variants_slim.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/postprocess_variants.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/vcf_stats_report.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/show_examples.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/runtime_by_region_vis.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/multisample_make_examples.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/labeler/labeled_examples_to_vcf.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/make_examples_somatic.zip . COPY",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/871
https://github.com/google/deepvariant/issues/871:3802,deployability,build,builder,3802," # Ensure executable scripts are correctly set up. RUN BASH_HEADER='#!/bin/bash' && \. for script in make_examples call_variants call_variants_slim postprocess_variants vcf_stats_report show_examples runtime_by_region_vis multisample_make_examples labeled_examples_to_vcf make_examples_somatic train run_deepvariant run_deepsomatic; do \. printf ""%s\n%s\n"" ""${BASH_HEADER}"" ""python3 /opt/deepvariant/bin/${script}.zip \""$@\"""" > /opt/deepvariant/bin/${script} && \. chmod +x /opt/deepvariant/bin/${script}; \. done. # Copy licenses and other necessary files. # Ensure these paths and URLs are correct and accessible. # Replace with valid URLs or remove if not needed. ADD https://storage.googleapis.com/deepvariant/models/DeepVariant/1.6.0/savedmodels/deepvariant.hybrid.savedmodel/saved_model.pb /models/. WORKDIR /opt/deepvariant/bin/. COPY --from=builder /opt/conda /opt/conda. COPY --from=builder /opt/deepvariant/run-prereq.sh . COPY --from=builder /opt/deepvariant/settings.sh . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/make_examples.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/call_variants.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/call_variants_slim.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/postprocess_variants.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/vcf_stats_report.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/show_examples.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/runtime_by_region_vis.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/multisample_make_examples.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/labeler/labeled_examples_to_vcf.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/make_examples_somatic.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/b",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/871
https://github.com/google/deepvariant/issues/871:3892,deployability,build,builder,3892," script in make_examples call_variants call_variants_slim postprocess_variants vcf_stats_report show_examples runtime_by_region_vis multisample_make_examples labeled_examples_to_vcf make_examples_somatic train run_deepvariant run_deepsomatic; do \. printf ""%s\n%s\n"" ""${BASH_HEADER}"" ""python3 /opt/deepvariant/bin/${script}.zip \""$@\"""" > /opt/deepvariant/bin/${script} && \. chmod +x /opt/deepvariant/bin/${script}; \. done. # Copy licenses and other necessary files. # Ensure these paths and URLs are correct and accessible. # Replace with valid URLs or remove if not needed. ADD https://storage.googleapis.com/deepvariant/models/DeepVariant/1.6.0/savedmodels/deepvariant.hybrid.savedmodel/saved_model.pb /models/. WORKDIR /opt/deepvariant/bin/. COPY --from=builder /opt/conda /opt/conda. COPY --from=builder /opt/deepvariant/run-prereq.sh . COPY --from=builder /opt/deepvariant/settings.sh . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/make_examples.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/call_variants.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/call_variants_slim.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/postprocess_variants.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/vcf_stats_report.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/show_examples.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/runtime_by_region_vis.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/multisample_make_examples.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/labeler/labeled_examples_to_vcf.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/make_examples_somatic.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/train.zip . COPY --from=builder /opt/deepvariant/scripts/run_deepvariant.py",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/871
https://github.com/google/deepvariant/issues/871:3982,deployability,build,builder,3982,"eport show_examples runtime_by_region_vis multisample_make_examples labeled_examples_to_vcf make_examples_somatic train run_deepvariant run_deepsomatic; do \. printf ""%s\n%s\n"" ""${BASH_HEADER}"" ""python3 /opt/deepvariant/bin/${script}.zip \""$@\"""" > /opt/deepvariant/bin/${script} && \. chmod +x /opt/deepvariant/bin/${script}; \. done. # Copy licenses and other necessary files. # Ensure these paths and URLs are correct and accessible. # Replace with valid URLs or remove if not needed. ADD https://storage.googleapis.com/deepvariant/models/DeepVariant/1.6.0/savedmodels/deepvariant.hybrid.savedmodel/saved_model.pb /models/. WORKDIR /opt/deepvariant/bin/. COPY --from=builder /opt/conda /opt/conda. COPY --from=builder /opt/deepvariant/run-prereq.sh . COPY --from=builder /opt/deepvariant/settings.sh . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/make_examples.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/call_variants.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/call_variants_slim.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/postprocess_variants.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/vcf_stats_report.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/show_examples.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/runtime_by_region_vis.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/multisample_make_examples.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/labeler/labeled_examples_to_vcf.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/make_examples_somatic.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/train.zip . COPY --from=builder /opt/deepvariant/scripts/run_deepvariant.py . COPY --from=builder /opt/deepvariant/scripts/run_deepsomatic.py . RUN ./run-prereq.sh. ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/871
https://github.com/google/deepvariant/issues/871:4077,deployability,build,builder,4077,"e_examples_somatic train run_deepvariant run_deepsomatic; do \. printf ""%s\n%s\n"" ""${BASH_HEADER}"" ""python3 /opt/deepvariant/bin/${script}.zip \""$@\"""" > /opt/deepvariant/bin/${script} && \. chmod +x /opt/deepvariant/bin/${script}; \. done. # Copy licenses and other necessary files. # Ensure these paths and URLs are correct and accessible. # Replace with valid URLs or remove if not needed. ADD https://storage.googleapis.com/deepvariant/models/DeepVariant/1.6.0/savedmodels/deepvariant.hybrid.savedmodel/saved_model.pb /models/. WORKDIR /opt/deepvariant/bin/. COPY --from=builder /opt/conda /opt/conda. COPY --from=builder /opt/deepvariant/run-prereq.sh . COPY --from=builder /opt/deepvariant/settings.sh . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/make_examples.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/call_variants.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/call_variants_slim.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/postprocess_variants.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/vcf_stats_report.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/show_examples.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/runtime_by_region_vis.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/multisample_make_examples.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/labeler/labeled_examples_to_vcf.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/make_examples_somatic.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/train.zip . COPY --from=builder /opt/deepvariant/scripts/run_deepvariant.py . COPY --from=builder /opt/deepvariant/scripts/run_deepsomatic.py . RUN ./run-prereq.sh. RUN update-alternatives --install /usr/bin/python3 python3 /usr/bin/python${PYTHON_VERSION} 0 &",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/871
https://github.com/google/deepvariant/issues/871:4174,deployability,build,builder,4174,""" ""python3 /opt/deepvariant/bin/${script}.zip \""$@\"""" > /opt/deepvariant/bin/${script} && \. chmod +x /opt/deepvariant/bin/${script}; \. done. # Copy licenses and other necessary files. # Ensure these paths and URLs are correct and accessible. # Replace with valid URLs or remove if not needed. ADD https://storage.googleapis.com/deepvariant/models/DeepVariant/1.6.0/savedmodels/deepvariant.hybrid.savedmodel/saved_model.pb /models/. WORKDIR /opt/deepvariant/bin/. COPY --from=builder /opt/conda /opt/conda. COPY --from=builder /opt/deepvariant/run-prereq.sh . COPY --from=builder /opt/deepvariant/settings.sh . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/make_examples.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/call_variants.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/call_variants_slim.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/postprocess_variants.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/vcf_stats_report.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/show_examples.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/runtime_by_region_vis.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/multisample_make_examples.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/labeler/labeled_examples_to_vcf.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/make_examples_somatic.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/train.zip . COPY --from=builder /opt/deepvariant/scripts/run_deepvariant.py . COPY --from=builder /opt/deepvariant/scripts/run_deepsomatic.py . RUN ./run-prereq.sh. RUN update-alternatives --install /usr/bin/python3 python3 /usr/bin/python${PYTHON_VERSION} 0 && \. 	update-alternatives --install /usr/bin/python python /usr/bin/python${PYTHON_VERSION} 0. # ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/871
https://github.com/google/deepvariant/issues/871:4267,deployability,build,builder,4267,chmod +x /opt/deepvariant/bin/${script}; \. done. # Copy licenses and other necessary files. # Ensure these paths and URLs are correct and accessible. # Replace with valid URLs or remove if not needed. ADD https://storage.googleapis.com/deepvariant/models/DeepVariant/1.6.0/savedmodels/deepvariant.hybrid.savedmodel/saved_model.pb /models/. WORKDIR /opt/deepvariant/bin/. COPY --from=builder /opt/conda /opt/conda. COPY --from=builder /opt/deepvariant/run-prereq.sh . COPY --from=builder /opt/deepvariant/settings.sh . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/make_examples.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/call_variants.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/call_variants_slim.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/postprocess_variants.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/vcf_stats_report.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/show_examples.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/runtime_by_region_vis.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/multisample_make_examples.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/labeler/labeled_examples_to_vcf.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/make_examples_somatic.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/train.zip . COPY --from=builder /opt/deepvariant/scripts/run_deepvariant.py . COPY --from=builder /opt/deepvariant/scripts/run_deepsomatic.py . RUN ./run-prereq.sh. RUN update-alternatives --install /usr/bin/python3 python3 /usr/bin/python${PYTHON_VERSION} 0 && \. 	update-alternatives --install /usr/bin/python python /usr/bin/python${PYTHON_VERSION} 0. # Create shell wrappers for python zip files for easier use. RUN \. BASH_HEADER='#!/bin/bash' &,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/871
https://github.com/google/deepvariant/issues/871:4357,deployability,build,builder,4357,"s. # Ensure these paths and URLs are correct and accessible. # Replace with valid URLs or remove if not needed. ADD https://storage.googleapis.com/deepvariant/models/DeepVariant/1.6.0/savedmodels/deepvariant.hybrid.savedmodel/saved_model.pb /models/. WORKDIR /opt/deepvariant/bin/. COPY --from=builder /opt/conda /opt/conda. COPY --from=builder /opt/deepvariant/run-prereq.sh . COPY --from=builder /opt/deepvariant/settings.sh . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/make_examples.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/call_variants.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/call_variants_slim.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/postprocess_variants.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/vcf_stats_report.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/show_examples.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/runtime_by_region_vis.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/multisample_make_examples.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/labeler/labeled_examples_to_vcf.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/make_examples_somatic.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/train.zip . COPY --from=builder /opt/deepvariant/scripts/run_deepvariant.py . COPY --from=builder /opt/deepvariant/scripts/run_deepsomatic.py . RUN ./run-prereq.sh. RUN update-alternatives --install /usr/bin/python3 python3 /usr/bin/python${PYTHON_VERSION} 0 && \. 	update-alternatives --install /usr/bin/python python /usr/bin/python${PYTHON_VERSION} 0. # Create shell wrappers for python zip files for easier use. RUN \. BASH_HEADER='#!/bin/bash' && \. printf ""%s\n%s\n"" \. 	""${BASH_HEADER}"" \. 	'python3 /opt/deepvariant/bin/make_example",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/871
https://github.com/google/deepvariant/issues/871:4455,deployability,build,builder,4455,"f not needed. ADD https://storage.googleapis.com/deepvariant/models/DeepVariant/1.6.0/savedmodels/deepvariant.hybrid.savedmodel/saved_model.pb /models/. WORKDIR /opt/deepvariant/bin/. COPY --from=builder /opt/conda /opt/conda. COPY --from=builder /opt/deepvariant/run-prereq.sh . COPY --from=builder /opt/deepvariant/settings.sh . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/make_examples.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/call_variants.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/call_variants_slim.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/postprocess_variants.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/vcf_stats_report.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/show_examples.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/runtime_by_region_vis.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/multisample_make_examples.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/labeler/labeled_examples_to_vcf.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/make_examples_somatic.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/train.zip . COPY --from=builder /opt/deepvariant/scripts/run_deepvariant.py . COPY --from=builder /opt/deepvariant/scripts/run_deepsomatic.py . RUN ./run-prereq.sh. RUN update-alternatives --install /usr/bin/python3 python3 /usr/bin/python${PYTHON_VERSION} 0 && \. 	update-alternatives --install /usr/bin/python python /usr/bin/python${PYTHON_VERSION} 0. # Create shell wrappers for python zip files for easier use. RUN \. BASH_HEADER='#!/bin/bash' && \. printf ""%s\n%s\n"" \. 	""${BASH_HEADER}"" \. 	'python3 /opt/deepvariant/bin/make_examples.zip ""$@""' > \. 	/opt/deepvariant/bin/make_examples && \. printf ""%s\n%s\n"" \. 	""${BASH_HEADER}"" ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/871
https://github.com/google/deepvariant/issues/871:4557,deployability,build,builder,4557,"variant.hybrid.savedmodel/saved_model.pb /models/. WORKDIR /opt/deepvariant/bin/. COPY --from=builder /opt/conda /opt/conda. COPY --from=builder /opt/deepvariant/run-prereq.sh . COPY --from=builder /opt/deepvariant/settings.sh . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/make_examples.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/call_variants.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/call_variants_slim.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/postprocess_variants.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/vcf_stats_report.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/show_examples.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/runtime_by_region_vis.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/multisample_make_examples.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/labeler/labeled_examples_to_vcf.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/make_examples_somatic.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/train.zip . COPY --from=builder /opt/deepvariant/scripts/run_deepvariant.py . COPY --from=builder /opt/deepvariant/scripts/run_deepsomatic.py . RUN ./run-prereq.sh. RUN update-alternatives --install /usr/bin/python3 python3 /usr/bin/python${PYTHON_VERSION} 0 && \. 	update-alternatives --install /usr/bin/python python /usr/bin/python${PYTHON_VERSION} 0. # Create shell wrappers for python zip files for easier use. RUN \. BASH_HEADER='#!/bin/bash' && \. printf ""%s\n%s\n"" \. 	""${BASH_HEADER}"" \. 	'python3 /opt/deepvariant/bin/make_examples.zip ""$@""' > \. 	/opt/deepvariant/bin/make_examples && \. printf ""%s\n%s\n"" \. 	""${BASH_HEADER}"" \. 	'python3 /opt/deepvariant/bin/call_variants.zip ""$@""' > \. 	/opt/deepvariant/bin/call_variants && ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/871
https://github.com/google/deepvariant/issues/871:4665,deployability,build,builder,4665,"onda /opt/conda. COPY --from=builder /opt/deepvariant/run-prereq.sh . COPY --from=builder /opt/deepvariant/settings.sh . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/make_examples.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/call_variants.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/call_variants_slim.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/postprocess_variants.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/vcf_stats_report.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/show_examples.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/runtime_by_region_vis.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/multisample_make_examples.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/labeler/labeled_examples_to_vcf.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/make_examples_somatic.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/train.zip . COPY --from=builder /opt/deepvariant/scripts/run_deepvariant.py . COPY --from=builder /opt/deepvariant/scripts/run_deepsomatic.py . RUN ./run-prereq.sh. RUN update-alternatives --install /usr/bin/python3 python3 /usr/bin/python${PYTHON_VERSION} 0 && \. 	update-alternatives --install /usr/bin/python python /usr/bin/python${PYTHON_VERSION} 0. # Create shell wrappers for python zip files for easier use. RUN \. BASH_HEADER='#!/bin/bash' && \. printf ""%s\n%s\n"" \. 	""${BASH_HEADER}"" \. 	'python3 /opt/deepvariant/bin/make_examples.zip ""$@""' > \. 	/opt/deepvariant/bin/make_examples && \. printf ""%s\n%s\n"" \. 	""${BASH_HEADER}"" \. 	'python3 /opt/deepvariant/bin/call_variants.zip ""$@""' > \. 	/opt/deepvariant/bin/call_variants && \. printf ""%s\n%s\n"" \. 	""${BASH_HEADER}"" \. 	'python3 /opt/deepvariant/bin/call_variants_slim.zip ""$@""' > \",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/871
https://github.com/google/deepvariant/issues/871:4763,deployability,build,builder,4763,"pvariant/settings.sh . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/make_examples.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/call_variants.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/call_variants_slim.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/postprocess_variants.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/vcf_stats_report.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/show_examples.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/runtime_by_region_vis.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/multisample_make_examples.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/labeler/labeled_examples_to_vcf.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/make_examples_somatic.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/train.zip . COPY --from=builder /opt/deepvariant/scripts/run_deepvariant.py . COPY --from=builder /opt/deepvariant/scripts/run_deepsomatic.py . RUN ./run-prereq.sh. RUN update-alternatives --install /usr/bin/python3 python3 /usr/bin/python${PYTHON_VERSION} 0 && \. 	update-alternatives --install /usr/bin/python python /usr/bin/python${PYTHON_VERSION} 0. # Create shell wrappers for python zip files for easier use. RUN \. BASH_HEADER='#!/bin/bash' && \. printf ""%s\n%s\n"" \. 	""${BASH_HEADER}"" \. 	'python3 /opt/deepvariant/bin/make_examples.zip ""$@""' > \. 	/opt/deepvariant/bin/make_examples && \. printf ""%s\n%s\n"" \. 	""${BASH_HEADER}"" \. 	'python3 /opt/deepvariant/bin/call_variants.zip ""$@""' > \. 	/opt/deepvariant/bin/call_variants && \. printf ""%s\n%s\n"" \. 	""${BASH_HEADER}"" \. 	'python3 /opt/deepvariant/bin/call_variants_slim.zip ""$@""' > \. 	/opt/deepvariant/bin/call_variants_slim && \. printf ""%s\n%s\n"" \. 	""${BASH_HEADER}"" \. 	'pytho",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/871
https://github.com/google/deepvariant/issues/871:4845,deployability,build,builder,4845,"eepvariant/make_examples.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/call_variants.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/call_variants_slim.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/postprocess_variants.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/vcf_stats_report.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/show_examples.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/runtime_by_region_vis.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/multisample_make_examples.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/labeler/labeled_examples_to_vcf.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/make_examples_somatic.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/train.zip . COPY --from=builder /opt/deepvariant/scripts/run_deepvariant.py . COPY --from=builder /opt/deepvariant/scripts/run_deepsomatic.py . RUN ./run-prereq.sh. RUN update-alternatives --install /usr/bin/python3 python3 /usr/bin/python${PYTHON_VERSION} 0 && \. 	update-alternatives --install /usr/bin/python python /usr/bin/python${PYTHON_VERSION} 0. # Create shell wrappers for python zip files for easier use. RUN \. BASH_HEADER='#!/bin/bash' && \. printf ""%s\n%s\n"" \. 	""${BASH_HEADER}"" \. 	'python3 /opt/deepvariant/bin/make_examples.zip ""$@""' > \. 	/opt/deepvariant/bin/make_examples && \. printf ""%s\n%s\n"" \. 	""${BASH_HEADER}"" \. 	'python3 /opt/deepvariant/bin/call_variants.zip ""$@""' > \. 	/opt/deepvariant/bin/call_variants && \. printf ""%s\n%s\n"" \. 	""${BASH_HEADER}"" \. 	'python3 /opt/deepvariant/bin/call_variants_slim.zip ""$@""' > \. 	/opt/deepvariant/bin/call_variants_slim && \. printf ""%s\n%s\n"" \. 	""${BASH_HEADER}"" \. 	'python3 /opt/deepvariant/bin/postprocess_variants.zip ""$@""' > \. 	/opt/deepvariant/bin/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/871
https://github.com/google/deepvariant/issues/871:4911,deployability,build,builder,4911,"t/bazel-out/k8-opt/bin/deepvariant/call_variants.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/call_variants_slim.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/postprocess_variants.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/vcf_stats_report.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/show_examples.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/runtime_by_region_vis.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/multisample_make_examples.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/labeler/labeled_examples_to_vcf.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/make_examples_somatic.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/train.zip . COPY --from=builder /opt/deepvariant/scripts/run_deepvariant.py . COPY --from=builder /opt/deepvariant/scripts/run_deepsomatic.py . RUN ./run-prereq.sh. RUN update-alternatives --install /usr/bin/python3 python3 /usr/bin/python${PYTHON_VERSION} 0 && \. 	update-alternatives --install /usr/bin/python python /usr/bin/python${PYTHON_VERSION} 0. # Create shell wrappers for python zip files for easier use. RUN \. BASH_HEADER='#!/bin/bash' && \. printf ""%s\n%s\n"" \. 	""${BASH_HEADER}"" \. 	'python3 /opt/deepvariant/bin/make_examples.zip ""$@""' > \. 	/opt/deepvariant/bin/make_examples && \. printf ""%s\n%s\n"" \. 	""${BASH_HEADER}"" \. 	'python3 /opt/deepvariant/bin/call_variants.zip ""$@""' > \. 	/opt/deepvariant/bin/call_variants && \. printf ""%s\n%s\n"" \. 	""${BASH_HEADER}"" \. 	'python3 /opt/deepvariant/bin/call_variants_slim.zip ""$@""' > \. 	/opt/deepvariant/bin/call_variants_slim && \. printf ""%s\n%s\n"" \. 	""${BASH_HEADER}"" \. 	'python3 /opt/deepvariant/bin/postprocess_variants.zip ""$@""' > \. 	/opt/deepvariant/bin/postprocess_variants && \. printf ""%s\n%s\n"" \. 	""${BASH_HEADER}"" ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/871
https://github.com/google/deepvariant/issues/871:4990,deployability,updat,update-alternatives,4990,"ariant/bazel-out/k8-opt/bin/deepvariant/call_variants_slim.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/postprocess_variants.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/vcf_stats_report.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/show_examples.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/runtime_by_region_vis.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/multisample_make_examples.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/labeler/labeled_examples_to_vcf.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/make_examples_somatic.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/train.zip . COPY --from=builder /opt/deepvariant/scripts/run_deepvariant.py . COPY --from=builder /opt/deepvariant/scripts/run_deepsomatic.py . RUN ./run-prereq.sh. RUN update-alternatives --install /usr/bin/python3 python3 /usr/bin/python${PYTHON_VERSION} 0 && \. 	update-alternatives --install /usr/bin/python python /usr/bin/python${PYTHON_VERSION} 0. # Create shell wrappers for python zip files for easier use. RUN \. BASH_HEADER='#!/bin/bash' && \. printf ""%s\n%s\n"" \. 	""${BASH_HEADER}"" \. 	'python3 /opt/deepvariant/bin/make_examples.zip ""$@""' > \. 	/opt/deepvariant/bin/make_examples && \. printf ""%s\n%s\n"" \. 	""${BASH_HEADER}"" \. 	'python3 /opt/deepvariant/bin/call_variants.zip ""$@""' > \. 	/opt/deepvariant/bin/call_variants && \. printf ""%s\n%s\n"" \. 	""${BASH_HEADER}"" \. 	'python3 /opt/deepvariant/bin/call_variants_slim.zip ""$@""' > \. 	/opt/deepvariant/bin/call_variants_slim && \. printf ""%s\n%s\n"" \. 	""${BASH_HEADER}"" \. 	'python3 /opt/deepvariant/bin/postprocess_variants.zip ""$@""' > \. 	/opt/deepvariant/bin/postprocess_variants && \. printf ""%s\n%s\n"" \. 	""${BASH_HEADER}"" \. 	'python3 /opt/deepvariant/bin/vcf_stats_report.zip ""$@""' > \. 	/opt/deepvariant/b",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/871
https://github.com/google/deepvariant/issues/871:5012,deployability,instal,install,5012,"/k8-opt/bin/deepvariant/call_variants_slim.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/postprocess_variants.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/vcf_stats_report.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/show_examples.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/runtime_by_region_vis.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/multisample_make_examples.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/labeler/labeled_examples_to_vcf.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/make_examples_somatic.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/train.zip . COPY --from=builder /opt/deepvariant/scripts/run_deepvariant.py . COPY --from=builder /opt/deepvariant/scripts/run_deepsomatic.py . RUN ./run-prereq.sh. RUN update-alternatives --install /usr/bin/python3 python3 /usr/bin/python${PYTHON_VERSION} 0 && \. 	update-alternatives --install /usr/bin/python python /usr/bin/python${PYTHON_VERSION} 0. # Create shell wrappers for python zip files for easier use. RUN \. BASH_HEADER='#!/bin/bash' && \. printf ""%s\n%s\n"" \. 	""${BASH_HEADER}"" \. 	'python3 /opt/deepvariant/bin/make_examples.zip ""$@""' > \. 	/opt/deepvariant/bin/make_examples && \. printf ""%s\n%s\n"" \. 	""${BASH_HEADER}"" \. 	'python3 /opt/deepvariant/bin/call_variants.zip ""$@""' > \. 	/opt/deepvariant/bin/call_variants && \. printf ""%s\n%s\n"" \. 	""${BASH_HEADER}"" \. 	'python3 /opt/deepvariant/bin/call_variants_slim.zip ""$@""' > \. 	/opt/deepvariant/bin/call_variants_slim && \. printf ""%s\n%s\n"" \. 	""${BASH_HEADER}"" \. 	'python3 /opt/deepvariant/bin/postprocess_variants.zip ""$@""' > \. 	/opt/deepvariant/bin/postprocess_variants && \. printf ""%s\n%s\n"" \. 	""${BASH_HEADER}"" \. 	'python3 /opt/deepvariant/bin/vcf_stats_report.zip ""$@""' > \. 	/opt/deepvariant/bin/vcf_stats_rep",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/871
https://github.com/google/deepvariant/issues/871:5087,deployability,updat,update-alternatives,5087,"iant/bazel-out/k8-opt/bin/deepvariant/postprocess_variants.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/vcf_stats_report.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/show_examples.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/runtime_by_region_vis.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/multisample_make_examples.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/labeler/labeled_examples_to_vcf.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/make_examples_somatic.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/train.zip . COPY --from=builder /opt/deepvariant/scripts/run_deepvariant.py . COPY --from=builder /opt/deepvariant/scripts/run_deepsomatic.py . RUN ./run-prereq.sh. RUN update-alternatives --install /usr/bin/python3 python3 /usr/bin/python${PYTHON_VERSION} 0 && \. 	update-alternatives --install /usr/bin/python python /usr/bin/python${PYTHON_VERSION} 0. # Create shell wrappers for python zip files for easier use. RUN \. BASH_HEADER='#!/bin/bash' && \. printf ""%s\n%s\n"" \. 	""${BASH_HEADER}"" \. 	'python3 /opt/deepvariant/bin/make_examples.zip ""$@""' > \. 	/opt/deepvariant/bin/make_examples && \. printf ""%s\n%s\n"" \. 	""${BASH_HEADER}"" \. 	'python3 /opt/deepvariant/bin/call_variants.zip ""$@""' > \. 	/opt/deepvariant/bin/call_variants && \. printf ""%s\n%s\n"" \. 	""${BASH_HEADER}"" \. 	'python3 /opt/deepvariant/bin/call_variants_slim.zip ""$@""' > \. 	/opt/deepvariant/bin/call_variants_slim && \. printf ""%s\n%s\n"" \. 	""${BASH_HEADER}"" \. 	'python3 /opt/deepvariant/bin/postprocess_variants.zip ""$@""' > \. 	/opt/deepvariant/bin/postprocess_variants && \. printf ""%s\n%s\n"" \. 	""${BASH_HEADER}"" \. 	'python3 /opt/deepvariant/bin/vcf_stats_report.zip ""$@""' > \. 	/opt/deepvariant/bin/vcf_stats_report && \. printf ""%s\n%s\n"" \. 	""${BASH_HEADER}"" \. 	'python3 /opt/deepvariant/bi",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/871
https://github.com/google/deepvariant/issues/871:5109,deployability,instal,install,5109,"8-opt/bin/deepvariant/postprocess_variants.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/vcf_stats_report.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/show_examples.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/runtime_by_region_vis.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/multisample_make_examples.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/labeler/labeled_examples_to_vcf.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/make_examples_somatic.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/train.zip . COPY --from=builder /opt/deepvariant/scripts/run_deepvariant.py . COPY --from=builder /opt/deepvariant/scripts/run_deepsomatic.py . RUN ./run-prereq.sh. RUN update-alternatives --install /usr/bin/python3 python3 /usr/bin/python${PYTHON_VERSION} 0 && \. 	update-alternatives --install /usr/bin/python python /usr/bin/python${PYTHON_VERSION} 0. # Create shell wrappers for python zip files for easier use. RUN \. BASH_HEADER='#!/bin/bash' && \. printf ""%s\n%s\n"" \. 	""${BASH_HEADER}"" \. 	'python3 /opt/deepvariant/bin/make_examples.zip ""$@""' > \. 	/opt/deepvariant/bin/make_examples && \. printf ""%s\n%s\n"" \. 	""${BASH_HEADER}"" \. 	'python3 /opt/deepvariant/bin/call_variants.zip ""$@""' > \. 	/opt/deepvariant/bin/call_variants && \. printf ""%s\n%s\n"" \. 	""${BASH_HEADER}"" \. 	'python3 /opt/deepvariant/bin/call_variants_slim.zip ""$@""' > \. 	/opt/deepvariant/bin/call_variants_slim && \. printf ""%s\n%s\n"" \. 	""${BASH_HEADER}"" \. 	'python3 /opt/deepvariant/bin/postprocess_variants.zip ""$@""' > \. 	/opt/deepvariant/bin/postprocess_variants && \. printf ""%s\n%s\n"" \. 	""${BASH_HEADER}"" \. 	'python3 /opt/deepvariant/bin/vcf_stats_report.zip ""$@""' > \. 	/opt/deepvariant/bin/vcf_stats_report && \. printf ""%s\n%s\n"" \. 	""${BASH_HEADER}"" \. 	'python3 /opt/deepvariant/bin/show_examples.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/871
https://github.com/google/deepvariant/issues/871:418,energy efficiency,Model,Model,418,"Troubleshooting Dockerfile for DeepVariant on Mac M1: Issues with Bazel ; Im new to working with computers tools like DeepVariant. Im trying to build DeepVariant using Docker on a Mac M1 and am encountering issues with the Dockerfile during the Bazel build process. I want to ensure compatibility with ARM64 architecture. **Docker version**: Docker version 27.1.1, build 6312585. **Bazel Version**: 7.3.1. **MacBook Model**: M1 chip (ARM64 architecture). **Error**: . ![IMG_3267](https://github.com/user-attachments/assets/11e28824-b941-42cc-9d33-7e9155a03543). ![IMG_3268](https://github.com/user-attachments/assets/4e923de6-99d5-43ee-80c6-29b32504527d). **My Dockerfilee code**:. ```. # Base image suitable for ARM64 architecture. FROM arm64v8/ubuntu:latest AS base. # Prevent interactive prompts. ENV DEBIAN_FRONTEND=noninteractive. # Install necessary packages. RUN apt-get update && \. apt-get install -y \. git \. curl \. unzip \. wget \. openjdk-17-jdk \. build-essential \. bzip2 \. python3-pip \. parallel && \. apt-get clean && \. rm -rf /var/lib/apt/lists/*. # Install Bazel (adjust version as needed). RUN curl -LO ""https://github.com/bazelbuild/bazel/releases/download/7.3.1/bazel-7.3.1-linux-arm64"" && \. chmod +x bazel-7.3.1-linux-arm64 && \. mv bazel-7.3.1-linux-arm64 /usr/local/bin/bazel. # Install Conda. RUN curl -LO ""https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-aarch64.sh"" && \. bash Miniconda3-latest-Linux-aarch64.sh -b -p /opt/miniconda && \. rm Miniconda3-latest-Linux-aarch64.sh. # Setup Conda environment. ENV PATH=""/opt/miniconda/bin:${PATH}"". RUN conda config --add channels defaults && \. conda config --add channels bioconda && \. conda config --add channels conda-forge && \. conda create -n bio bioconda::bcftools bioconda::samtools -y && \. conda clean -a. # Clone DeepVariant and build. FROM base AS builder. # Clone the DeepVariant repository. RUN git clone https://github.com/google/deepvariant.git /opt/deepvariant && \. cd /opt/deepvariant && ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/871
https://github.com/google/deepvariant/issues/871:3520,energy efficiency,model,models,3520,"ptools wheel --timeout=120 && \. pip install jaxlib jax --timeout=120 --extra-index-url https://storage.googleapis.com/jax-releases/jax_releases.html. # Copy DeepVariant binaries from the builder stage. COPY --from=builder /opt/deepvariant /opt/deepvariant. WORKDIR /opt/deepvariant. # Ensure executable scripts are correctly set up. RUN BASH_HEADER='#!/bin/bash' && \. for script in make_examples call_variants call_variants_slim postprocess_variants vcf_stats_report show_examples runtime_by_region_vis multisample_make_examples labeled_examples_to_vcf make_examples_somatic train run_deepvariant run_deepsomatic; do \. printf ""%s\n%s\n"" ""${BASH_HEADER}"" ""python3 /opt/deepvariant/bin/${script}.zip \""$@\"""" > /opt/deepvariant/bin/${script} && \. chmod +x /opt/deepvariant/bin/${script}; \. done. # Copy licenses and other necessary files. # Ensure these paths and URLs are correct and accessible. # Replace with valid URLs or remove if not needed. ADD https://storage.googleapis.com/deepvariant/models/DeepVariant/1.6.0/savedmodels/deepvariant.hybrid.savedmodel/saved_model.pb /models/. WORKDIR /opt/deepvariant/bin/. COPY --from=builder /opt/conda /opt/conda. COPY --from=builder /opt/deepvariant/run-prereq.sh . COPY --from=builder /opt/deepvariant/settings.sh . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/make_examples.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/call_variants.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/call_variants_slim.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/postprocess_variants.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/vcf_stats_report.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/show_examples.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/runtime_by_region_vis.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/multisampl",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/871
https://github.com/google/deepvariant/issues/871:3603,energy efficiency,model,models,3603,"-url https://storage.googleapis.com/jax-releases/jax_releases.html. # Copy DeepVariant binaries from the builder stage. COPY --from=builder /opt/deepvariant /opt/deepvariant. WORKDIR /opt/deepvariant. # Ensure executable scripts are correctly set up. RUN BASH_HEADER='#!/bin/bash' && \. for script in make_examples call_variants call_variants_slim postprocess_variants vcf_stats_report show_examples runtime_by_region_vis multisample_make_examples labeled_examples_to_vcf make_examples_somatic train run_deepvariant run_deepsomatic; do \. printf ""%s\n%s\n"" ""${BASH_HEADER}"" ""python3 /opt/deepvariant/bin/${script}.zip \""$@\"""" > /opt/deepvariant/bin/${script} && \. chmod +x /opt/deepvariant/bin/${script}; \. done. # Copy licenses and other necessary files. # Ensure these paths and URLs are correct and accessible. # Replace with valid URLs or remove if not needed. ADD https://storage.googleapis.com/deepvariant/models/DeepVariant/1.6.0/savedmodels/deepvariant.hybrid.savedmodel/saved_model.pb /models/. WORKDIR /opt/deepvariant/bin/. COPY --from=builder /opt/conda /opt/conda. COPY --from=builder /opt/deepvariant/run-prereq.sh . COPY --from=builder /opt/deepvariant/settings.sh . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/make_examples.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/call_variants.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/call_variants_slim.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/postprocess_variants.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/vcf_stats_report.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/show_examples.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/runtime_by_region_vis.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/multisample_make_examples.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/dee",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/871
https://github.com/google/deepvariant/issues/871:333,integrability,version,version,333,"Troubleshooting Dockerfile for DeepVariant on Mac M1: Issues with Bazel ; Im new to working with computers tools like DeepVariant. Im trying to build DeepVariant using Docker on a Mac M1 and am encountering issues with the Dockerfile during the Bazel build process. I want to ensure compatibility with ARM64 architecture. **Docker version**: Docker version 27.1.1, build 6312585. **Bazel Version**: 7.3.1. **MacBook Model**: M1 chip (ARM64 architecture). **Error**: . ![IMG_3267](https://github.com/user-attachments/assets/11e28824-b941-42cc-9d33-7e9155a03543). ![IMG_3268](https://github.com/user-attachments/assets/4e923de6-99d5-43ee-80c6-29b32504527d). **My Dockerfilee code**:. ```. # Base image suitable for ARM64 architecture. FROM arm64v8/ubuntu:latest AS base. # Prevent interactive prompts. ENV DEBIAN_FRONTEND=noninteractive. # Install necessary packages. RUN apt-get update && \. apt-get install -y \. git \. curl \. unzip \. wget \. openjdk-17-jdk \. build-essential \. bzip2 \. python3-pip \. parallel && \. apt-get clean && \. rm -rf /var/lib/apt/lists/*. # Install Bazel (adjust version as needed). RUN curl -LO ""https://github.com/bazelbuild/bazel/releases/download/7.3.1/bazel-7.3.1-linux-arm64"" && \. chmod +x bazel-7.3.1-linux-arm64 && \. mv bazel-7.3.1-linux-arm64 /usr/local/bin/bazel. # Install Conda. RUN curl -LO ""https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-aarch64.sh"" && \. bash Miniconda3-latest-Linux-aarch64.sh -b -p /opt/miniconda && \. rm Miniconda3-latest-Linux-aarch64.sh. # Setup Conda environment. ENV PATH=""/opt/miniconda/bin:${PATH}"". RUN conda config --add channels defaults && \. conda config --add channels bioconda && \. conda config --add channels conda-forge && \. conda create -n bio bioconda::bcftools bioconda::samtools -y && \. conda clean -a. # Clone DeepVariant and build. FROM base AS builder. # Clone the DeepVariant repository. RUN git clone https://github.com/google/deepvariant.git /opt/deepvariant && \. cd /opt/deepvariant && ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/871
https://github.com/google/deepvariant/issues/871:351,integrability,version,version,351,"Troubleshooting Dockerfile for DeepVariant on Mac M1: Issues with Bazel ; Im new to working with computers tools like DeepVariant. Im trying to build DeepVariant using Docker on a Mac M1 and am encountering issues with the Dockerfile during the Bazel build process. I want to ensure compatibility with ARM64 architecture. **Docker version**: Docker version 27.1.1, build 6312585. **Bazel Version**: 7.3.1. **MacBook Model**: M1 chip (ARM64 architecture). **Error**: . ![IMG_3267](https://github.com/user-attachments/assets/11e28824-b941-42cc-9d33-7e9155a03543). ![IMG_3268](https://github.com/user-attachments/assets/4e923de6-99d5-43ee-80c6-29b32504527d). **My Dockerfilee code**:. ```. # Base image suitable for ARM64 architecture. FROM arm64v8/ubuntu:latest AS base. # Prevent interactive prompts. ENV DEBIAN_FRONTEND=noninteractive. # Install necessary packages. RUN apt-get update && \. apt-get install -y \. git \. curl \. unzip \. wget \. openjdk-17-jdk \. build-essential \. bzip2 \. python3-pip \. parallel && \. apt-get clean && \. rm -rf /var/lib/apt/lists/*. # Install Bazel (adjust version as needed). RUN curl -LO ""https://github.com/bazelbuild/bazel/releases/download/7.3.1/bazel-7.3.1-linux-arm64"" && \. chmod +x bazel-7.3.1-linux-arm64 && \. mv bazel-7.3.1-linux-arm64 /usr/local/bin/bazel. # Install Conda. RUN curl -LO ""https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-aarch64.sh"" && \. bash Miniconda3-latest-Linux-aarch64.sh -b -p /opt/miniconda && \. rm Miniconda3-latest-Linux-aarch64.sh. # Setup Conda environment. ENV PATH=""/opt/miniconda/bin:${PATH}"". RUN conda config --add channels defaults && \. conda config --add channels bioconda && \. conda config --add channels conda-forge && \. conda create -n bio bioconda::bcftools bioconda::samtools -y && \. conda clean -a. # Clone DeepVariant and build. FROM base AS builder. # Clone the DeepVariant repository. RUN git clone https://github.com/google/deepvariant.git /opt/deepvariant && \. cd /opt/deepvariant && ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/871
https://github.com/google/deepvariant/issues/871:390,integrability,Version,Version,390,"Troubleshooting Dockerfile for DeepVariant on Mac M1: Issues with Bazel ; Im new to working with computers tools like DeepVariant. Im trying to build DeepVariant using Docker on a Mac M1 and am encountering issues with the Dockerfile during the Bazel build process. I want to ensure compatibility with ARM64 architecture. **Docker version**: Docker version 27.1.1, build 6312585. **Bazel Version**: 7.3.1. **MacBook Model**: M1 chip (ARM64 architecture). **Error**: . ![IMG_3267](https://github.com/user-attachments/assets/11e28824-b941-42cc-9d33-7e9155a03543). ![IMG_3268](https://github.com/user-attachments/assets/4e923de6-99d5-43ee-80c6-29b32504527d). **My Dockerfilee code**:. ```. # Base image suitable for ARM64 architecture. FROM arm64v8/ubuntu:latest AS base. # Prevent interactive prompts. ENV DEBIAN_FRONTEND=noninteractive. # Install necessary packages. RUN apt-get update && \. apt-get install -y \. git \. curl \. unzip \. wget \. openjdk-17-jdk \. build-essential \. bzip2 \. python3-pip \. parallel && \. apt-get clean && \. rm -rf /var/lib/apt/lists/*. # Install Bazel (adjust version as needed). RUN curl -LO ""https://github.com/bazelbuild/bazel/releases/download/7.3.1/bazel-7.3.1-linux-arm64"" && \. chmod +x bazel-7.3.1-linux-arm64 && \. mv bazel-7.3.1-linux-arm64 /usr/local/bin/bazel. # Install Conda. RUN curl -LO ""https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-aarch64.sh"" && \. bash Miniconda3-latest-Linux-aarch64.sh -b -p /opt/miniconda && \. rm Miniconda3-latest-Linux-aarch64.sh. # Setup Conda environment. ENV PATH=""/opt/miniconda/bin:${PATH}"". RUN conda config --add channels defaults && \. conda config --add channels bioconda && \. conda config --add channels conda-forge && \. conda create -n bio bioconda::bcftools bioconda::samtools -y && \. conda clean -a. # Clone DeepVariant and build. FROM base AS builder. # Clone the DeepVariant repository. RUN git clone https://github.com/google/deepvariant.git /opt/deepvariant && \. cd /opt/deepvariant && ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/871
https://github.com/google/deepvariant/issues/871:1096,integrability,version,version,1096,"mputers tools like DeepVariant. Im trying to build DeepVariant using Docker on a Mac M1 and am encountering issues with the Dockerfile during the Bazel build process. I want to ensure compatibility with ARM64 architecture. **Docker version**: Docker version 27.1.1, build 6312585. **Bazel Version**: 7.3.1. **MacBook Model**: M1 chip (ARM64 architecture). **Error**: . ![IMG_3267](https://github.com/user-attachments/assets/11e28824-b941-42cc-9d33-7e9155a03543). ![IMG_3268](https://github.com/user-attachments/assets/4e923de6-99d5-43ee-80c6-29b32504527d). **My Dockerfilee code**:. ```. # Base image suitable for ARM64 architecture. FROM arm64v8/ubuntu:latest AS base. # Prevent interactive prompts. ENV DEBIAN_FRONTEND=noninteractive. # Install necessary packages. RUN apt-get update && \. apt-get install -y \. git \. curl \. unzip \. wget \. openjdk-17-jdk \. build-essential \. bzip2 \. python3-pip \. parallel && \. apt-get clean && \. rm -rf /var/lib/apt/lists/*. # Install Bazel (adjust version as needed). RUN curl -LO ""https://github.com/bazelbuild/bazel/releases/download/7.3.1/bazel-7.3.1-linux-arm64"" && \. chmod +x bazel-7.3.1-linux-arm64 && \. mv bazel-7.3.1-linux-arm64 /usr/local/bin/bazel. # Install Conda. RUN curl -LO ""https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-aarch64.sh"" && \. bash Miniconda3-latest-Linux-aarch64.sh -b -p /opt/miniconda && \. rm Miniconda3-latest-Linux-aarch64.sh. # Setup Conda environment. ENV PATH=""/opt/miniconda/bin:${PATH}"". RUN conda config --add channels defaults && \. conda config --add channels bioconda && \. conda config --add channels conda-forge && \. conda create -n bio bioconda::bcftools bioconda::samtools -y && \. conda clean -a. # Clone DeepVariant and build. FROM base AS builder. # Clone the DeepVariant repository. RUN git clone https://github.com/google/deepvariant.git /opt/deepvariant && \. cd /opt/deepvariant && \. git checkout tags/v1.6.1. # Run Bazel build with additional flags to skip problematic configurati",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/871
https://github.com/google/deepvariant/issues/871:1886,integrability,repositor,repository,1886,". apt-get install -y \. git \. curl \. unzip \. wget \. openjdk-17-jdk \. build-essential \. bzip2 \. python3-pip \. parallel && \. apt-get clean && \. rm -rf /var/lib/apt/lists/*. # Install Bazel (adjust version as needed). RUN curl -LO ""https://github.com/bazelbuild/bazel/releases/download/7.3.1/bazel-7.3.1-linux-arm64"" && \. chmod +x bazel-7.3.1-linux-arm64 && \. mv bazel-7.3.1-linux-arm64 /usr/local/bin/bazel. # Install Conda. RUN curl -LO ""https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-aarch64.sh"" && \. bash Miniconda3-latest-Linux-aarch64.sh -b -p /opt/miniconda && \. rm Miniconda3-latest-Linux-aarch64.sh. # Setup Conda environment. ENV PATH=""/opt/miniconda/bin:${PATH}"". RUN conda config --add channels defaults && \. conda config --add channels bioconda && \. conda config --add channels conda-forge && \. conda create -n bio bioconda::bcftools bioconda::samtools -y && \. conda clean -a. # Clone DeepVariant and build. FROM base AS builder. # Clone the DeepVariant repository. RUN git clone https://github.com/google/deepvariant.git /opt/deepvariant && \. cd /opt/deepvariant && \. git checkout tags/v1.6.1. # Run Bazel build with additional flags to skip problematic configurations. RUN bazel build -c opt --noincremental --experimental_action_listener= //deepvariant:make_examples //deepvariant:call_variants //deepvariant:postprocess_variants || { \. echo ""Bazel build failed""; \. exit 1; }. # Final image. FROM base AS final. # Set environment variables. ENV VERSION=1.6.0. ENV PYTHON_VERSION=3.8. ENV PATH=""/opt/miniconda/bin:${PATH}"". # Install Python packages. RUN pip install --upgrade pip setuptools wheel --timeout=120 && \. pip install jaxlib jax --timeout=120 --extra-index-url https://storage.googleapis.com/jax-releases/jax_releases.html. # Copy DeepVariant binaries from the builder stage. COPY --from=builder /opt/deepvariant /opt/deepvariant. WORKDIR /opt/deepvariant. # Ensure executable scripts are correctly set up. RUN BASH_HEADER='#!/bin/bash' && \",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/871
https://github.com/google/deepvariant/issues/871:2089,integrability,configur,configurations,2089,"version as needed). RUN curl -LO ""https://github.com/bazelbuild/bazel/releases/download/7.3.1/bazel-7.3.1-linux-arm64"" && \. chmod +x bazel-7.3.1-linux-arm64 && \. mv bazel-7.3.1-linux-arm64 /usr/local/bin/bazel. # Install Conda. RUN curl -LO ""https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-aarch64.sh"" && \. bash Miniconda3-latest-Linux-aarch64.sh -b -p /opt/miniconda && \. rm Miniconda3-latest-Linux-aarch64.sh. # Setup Conda environment. ENV PATH=""/opt/miniconda/bin:${PATH}"". RUN conda config --add channels defaults && \. conda config --add channels bioconda && \. conda config --add channels conda-forge && \. conda create -n bio bioconda::bcftools bioconda::samtools -y && \. conda clean -a. # Clone DeepVariant and build. FROM base AS builder. # Clone the DeepVariant repository. RUN git clone https://github.com/google/deepvariant.git /opt/deepvariant && \. cd /opt/deepvariant && \. git checkout tags/v1.6.1. # Run Bazel build with additional flags to skip problematic configurations. RUN bazel build -c opt --noincremental --experimental_action_listener= //deepvariant:make_examples //deepvariant:call_variants //deepvariant:postprocess_variants || { \. echo ""Bazel build failed""; \. exit 1; }. # Final image. FROM base AS final. # Set environment variables. ENV VERSION=1.6.0. ENV PYTHON_VERSION=3.8. ENV PATH=""/opt/miniconda/bin:${PATH}"". # Install Python packages. RUN pip install --upgrade pip setuptools wheel --timeout=120 && \. pip install jaxlib jax --timeout=120 --extra-index-url https://storage.googleapis.com/jax-releases/jax_releases.html. # Copy DeepVariant binaries from the builder stage. COPY --from=builder /opt/deepvariant /opt/deepvariant. WORKDIR /opt/deepvariant. # Ensure executable scripts are correctly set up. RUN BASH_HEADER='#!/bin/bash' && \. for script in make_examples call_variants call_variants_slim postprocess_variants vcf_stats_report show_examples runtime_by_region_vis multisample_make_examples labeled_examples_to_vcf make_examples_soma",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/871
https://github.com/google/deepvariant/issues/871:2384,integrability,VERSION,VERSION,2384,"atest-Linux-aarch64.sh"" && \. bash Miniconda3-latest-Linux-aarch64.sh -b -p /opt/miniconda && \. rm Miniconda3-latest-Linux-aarch64.sh. # Setup Conda environment. ENV PATH=""/opt/miniconda/bin:${PATH}"". RUN conda config --add channels defaults && \. conda config --add channels bioconda && \. conda config --add channels conda-forge && \. conda create -n bio bioconda::bcftools bioconda::samtools -y && \. conda clean -a. # Clone DeepVariant and build. FROM base AS builder. # Clone the DeepVariant repository. RUN git clone https://github.com/google/deepvariant.git /opt/deepvariant && \. cd /opt/deepvariant && \. git checkout tags/v1.6.1. # Run Bazel build with additional flags to skip problematic configurations. RUN bazel build -c opt --noincremental --experimental_action_listener= //deepvariant:make_examples //deepvariant:call_variants //deepvariant:postprocess_variants || { \. echo ""Bazel build failed""; \. exit 1; }. # Final image. FROM base AS final. # Set environment variables. ENV VERSION=1.6.0. ENV PYTHON_VERSION=3.8. ENV PATH=""/opt/miniconda/bin:${PATH}"". # Install Python packages. RUN pip install --upgrade pip setuptools wheel --timeout=120 && \. pip install jaxlib jax --timeout=120 --extra-index-url https://storage.googleapis.com/jax-releases/jax_releases.html. # Copy DeepVariant binaries from the builder stage. COPY --from=builder /opt/deepvariant /opt/deepvariant. WORKDIR /opt/deepvariant. # Ensure executable scripts are correctly set up. RUN BASH_HEADER='#!/bin/bash' && \. for script in make_examples call_variants call_variants_slim postprocess_variants vcf_stats_report show_examples runtime_by_region_vis multisample_make_examples labeled_examples_to_vcf make_examples_somatic train run_deepvariant run_deepsomatic; do \. printf ""%s\n%s\n"" ""${BASH_HEADER}"" ""python3 /opt/deepvariant/bin/${script}.zip \""$@\"""" > /opt/deepvariant/bin/${script} && \. chmod +x /opt/deepvariant/bin/${script}; \. done. # Copy licenses and other necessary files. # Ensure these paths and",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/871
https://github.com/google/deepvariant/issues/871:5191,integrability,wrap,wrappers,5191,"ant/bazel-out/k8-opt/bin/deepvariant/vcf_stats_report.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/show_examples.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/runtime_by_region_vis.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/multisample_make_examples.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/labeler/labeled_examples_to_vcf.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/make_examples_somatic.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/train.zip . COPY --from=builder /opt/deepvariant/scripts/run_deepvariant.py . COPY --from=builder /opt/deepvariant/scripts/run_deepsomatic.py . RUN ./run-prereq.sh. RUN update-alternatives --install /usr/bin/python3 python3 /usr/bin/python${PYTHON_VERSION} 0 && \. 	update-alternatives --install /usr/bin/python python /usr/bin/python${PYTHON_VERSION} 0. # Create shell wrappers for python zip files for easier use. RUN \. BASH_HEADER='#!/bin/bash' && \. printf ""%s\n%s\n"" \. 	""${BASH_HEADER}"" \. 	'python3 /opt/deepvariant/bin/make_examples.zip ""$@""' > \. 	/opt/deepvariant/bin/make_examples && \. printf ""%s\n%s\n"" \. 	""${BASH_HEADER}"" \. 	'python3 /opt/deepvariant/bin/call_variants.zip ""$@""' > \. 	/opt/deepvariant/bin/call_variants && \. printf ""%s\n%s\n"" \. 	""${BASH_HEADER}"" \. 	'python3 /opt/deepvariant/bin/call_variants_slim.zip ""$@""' > \. 	/opt/deepvariant/bin/call_variants_slim && \. printf ""%s\n%s\n"" \. 	""${BASH_HEADER}"" \. 	'python3 /opt/deepvariant/bin/postprocess_variants.zip ""$@""' > \. 	/opt/deepvariant/bin/postprocess_variants && \. printf ""%s\n%s\n"" \. 	""${BASH_HEADER}"" \. 	'python3 /opt/deepvariant/bin/vcf_stats_report.zip ""$@""' > \. 	/opt/deepvariant/bin/vcf_stats_report && \. printf ""%s\n%s\n"" \. 	""${BASH_HEADER}"" \. 	'python3 /opt/deepvariant/bin/show_examples.zip ""$@""' > \. 	/opt/deepvariant/bin/show_examples && \. printf ""%s\n%s\n"" \. 	""${",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/871
https://github.com/google/deepvariant/issues/871:285,interoperability,compatib,compatibility,285,"Troubleshooting Dockerfile for DeepVariant on Mac M1: Issues with Bazel ; Im new to working with computers tools like DeepVariant. Im trying to build DeepVariant using Docker on a Mac M1 and am encountering issues with the Dockerfile during the Bazel build process. I want to ensure compatibility with ARM64 architecture. **Docker version**: Docker version 27.1.1, build 6312585. **Bazel Version**: 7.3.1. **MacBook Model**: M1 chip (ARM64 architecture). **Error**: . ![IMG_3267](https://github.com/user-attachments/assets/11e28824-b941-42cc-9d33-7e9155a03543). ![IMG_3268](https://github.com/user-attachments/assets/4e923de6-99d5-43ee-80c6-29b32504527d). **My Dockerfilee code**:. ```. # Base image suitable for ARM64 architecture. FROM arm64v8/ubuntu:latest AS base. # Prevent interactive prompts. ENV DEBIAN_FRONTEND=noninteractive. # Install necessary packages. RUN apt-get update && \. apt-get install -y \. git \. curl \. unzip \. wget \. openjdk-17-jdk \. build-essential \. bzip2 \. python3-pip \. parallel && \. apt-get clean && \. rm -rf /var/lib/apt/lists/*. # Install Bazel (adjust version as needed). RUN curl -LO ""https://github.com/bazelbuild/bazel/releases/download/7.3.1/bazel-7.3.1-linux-arm64"" && \. chmod +x bazel-7.3.1-linux-arm64 && \. mv bazel-7.3.1-linux-arm64 /usr/local/bin/bazel. # Install Conda. RUN curl -LO ""https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-aarch64.sh"" && \. bash Miniconda3-latest-Linux-aarch64.sh -b -p /opt/miniconda && \. rm Miniconda3-latest-Linux-aarch64.sh. # Setup Conda environment. ENV PATH=""/opt/miniconda/bin:${PATH}"". RUN conda config --add channels defaults && \. conda config --add channels bioconda && \. conda config --add channels conda-forge && \. conda create -n bio bioconda::bcftools bioconda::samtools -y && \. conda clean -a. # Clone DeepVariant and build. FROM base AS builder. # Clone the DeepVariant repository. RUN git clone https://github.com/google/deepvariant.git /opt/deepvariant && \. cd /opt/deepvariant && ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/871
https://github.com/google/deepvariant/issues/871:310,interoperability,architectur,architecture,310,"Troubleshooting Dockerfile for DeepVariant on Mac M1: Issues with Bazel ; Im new to working with computers tools like DeepVariant. Im trying to build DeepVariant using Docker on a Mac M1 and am encountering issues with the Dockerfile during the Bazel build process. I want to ensure compatibility with ARM64 architecture. **Docker version**: Docker version 27.1.1, build 6312585. **Bazel Version**: 7.3.1. **MacBook Model**: M1 chip (ARM64 architecture). **Error**: . ![IMG_3267](https://github.com/user-attachments/assets/11e28824-b941-42cc-9d33-7e9155a03543). ![IMG_3268](https://github.com/user-attachments/assets/4e923de6-99d5-43ee-80c6-29b32504527d). **My Dockerfilee code**:. ```. # Base image suitable for ARM64 architecture. FROM arm64v8/ubuntu:latest AS base. # Prevent interactive prompts. ENV DEBIAN_FRONTEND=noninteractive. # Install necessary packages. RUN apt-get update && \. apt-get install -y \. git \. curl \. unzip \. wget \. openjdk-17-jdk \. build-essential \. bzip2 \. python3-pip \. parallel && \. apt-get clean && \. rm -rf /var/lib/apt/lists/*. # Install Bazel (adjust version as needed). RUN curl -LO ""https://github.com/bazelbuild/bazel/releases/download/7.3.1/bazel-7.3.1-linux-arm64"" && \. chmod +x bazel-7.3.1-linux-arm64 && \. mv bazel-7.3.1-linux-arm64 /usr/local/bin/bazel. # Install Conda. RUN curl -LO ""https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-aarch64.sh"" && \. bash Miniconda3-latest-Linux-aarch64.sh -b -p /opt/miniconda && \. rm Miniconda3-latest-Linux-aarch64.sh. # Setup Conda environment. ENV PATH=""/opt/miniconda/bin:${PATH}"". RUN conda config --add channels defaults && \. conda config --add channels bioconda && \. conda config --add channels conda-forge && \. conda create -n bio bioconda::bcftools bioconda::samtools -y && \. conda clean -a. # Clone DeepVariant and build. FROM base AS builder. # Clone the DeepVariant repository. RUN git clone https://github.com/google/deepvariant.git /opt/deepvariant && \. cd /opt/deepvariant && ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/871
https://github.com/google/deepvariant/issues/871:442,interoperability,architectur,architecture,442,"Troubleshooting Dockerfile for DeepVariant on Mac M1: Issues with Bazel ; Im new to working with computers tools like DeepVariant. Im trying to build DeepVariant using Docker on a Mac M1 and am encountering issues with the Dockerfile during the Bazel build process. I want to ensure compatibility with ARM64 architecture. **Docker version**: Docker version 27.1.1, build 6312585. **Bazel Version**: 7.3.1. **MacBook Model**: M1 chip (ARM64 architecture). **Error**: . ![IMG_3267](https://github.com/user-attachments/assets/11e28824-b941-42cc-9d33-7e9155a03543). ![IMG_3268](https://github.com/user-attachments/assets/4e923de6-99d5-43ee-80c6-29b32504527d). **My Dockerfilee code**:. ```. # Base image suitable for ARM64 architecture. FROM arm64v8/ubuntu:latest AS base. # Prevent interactive prompts. ENV DEBIAN_FRONTEND=noninteractive. # Install necessary packages. RUN apt-get update && \. apt-get install -y \. git \. curl \. unzip \. wget \. openjdk-17-jdk \. build-essential \. bzip2 \. python3-pip \. parallel && \. apt-get clean && \. rm -rf /var/lib/apt/lists/*. # Install Bazel (adjust version as needed). RUN curl -LO ""https://github.com/bazelbuild/bazel/releases/download/7.3.1/bazel-7.3.1-linux-arm64"" && \. chmod +x bazel-7.3.1-linux-arm64 && \. mv bazel-7.3.1-linux-arm64 /usr/local/bin/bazel. # Install Conda. RUN curl -LO ""https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-aarch64.sh"" && \. bash Miniconda3-latest-Linux-aarch64.sh -b -p /opt/miniconda && \. rm Miniconda3-latest-Linux-aarch64.sh. # Setup Conda environment. ENV PATH=""/opt/miniconda/bin:${PATH}"". RUN conda config --add channels defaults && \. conda config --add channels bioconda && \. conda config --add channels conda-forge && \. conda create -n bio bioconda::bcftools bioconda::samtools -y && \. conda clean -a. # Clone DeepVariant and build. FROM base AS builder. # Clone the DeepVariant repository. RUN git clone https://github.com/google/deepvariant.git /opt/deepvariant && \. cd /opt/deepvariant && ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/871
https://github.com/google/deepvariant/issues/871:721,interoperability,architectur,architecture,721,"Troubleshooting Dockerfile for DeepVariant on Mac M1: Issues with Bazel ; Im new to working with computers tools like DeepVariant. Im trying to build DeepVariant using Docker on a Mac M1 and am encountering issues with the Dockerfile during the Bazel build process. I want to ensure compatibility with ARM64 architecture. **Docker version**: Docker version 27.1.1, build 6312585. **Bazel Version**: 7.3.1. **MacBook Model**: M1 chip (ARM64 architecture). **Error**: . ![IMG_3267](https://github.com/user-attachments/assets/11e28824-b941-42cc-9d33-7e9155a03543). ![IMG_3268](https://github.com/user-attachments/assets/4e923de6-99d5-43ee-80c6-29b32504527d). **My Dockerfilee code**:. ```. # Base image suitable for ARM64 architecture. FROM arm64v8/ubuntu:latest AS base. # Prevent interactive prompts. ENV DEBIAN_FRONTEND=noninteractive. # Install necessary packages. RUN apt-get update && \. apt-get install -y \. git \. curl \. unzip \. wget \. openjdk-17-jdk \. build-essential \. bzip2 \. python3-pip \. parallel && \. apt-get clean && \. rm -rf /var/lib/apt/lists/*. # Install Bazel (adjust version as needed). RUN curl -LO ""https://github.com/bazelbuild/bazel/releases/download/7.3.1/bazel-7.3.1-linux-arm64"" && \. chmod +x bazel-7.3.1-linux-arm64 && \. mv bazel-7.3.1-linux-arm64 /usr/local/bin/bazel. # Install Conda. RUN curl -LO ""https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-aarch64.sh"" && \. bash Miniconda3-latest-Linux-aarch64.sh -b -p /opt/miniconda && \. rm Miniconda3-latest-Linux-aarch64.sh. # Setup Conda environment. ENV PATH=""/opt/miniconda/bin:${PATH}"". RUN conda config --add channels defaults && \. conda config --add channels bioconda && \. conda config --add channels conda-forge && \. conda create -n bio bioconda::bcftools bioconda::samtools -y && \. conda clean -a. # Clone DeepVariant and build. FROM base AS builder. # Clone the DeepVariant repository. RUN git clone https://github.com/google/deepvariant.git /opt/deepvariant && \. cd /opt/deepvariant && ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/871
https://github.com/google/deepvariant/issues/871:1886,interoperability,repositor,repository,1886,". apt-get install -y \. git \. curl \. unzip \. wget \. openjdk-17-jdk \. build-essential \. bzip2 \. python3-pip \. parallel && \. apt-get clean && \. rm -rf /var/lib/apt/lists/*. # Install Bazel (adjust version as needed). RUN curl -LO ""https://github.com/bazelbuild/bazel/releases/download/7.3.1/bazel-7.3.1-linux-arm64"" && \. chmod +x bazel-7.3.1-linux-arm64 && \. mv bazel-7.3.1-linux-arm64 /usr/local/bin/bazel. # Install Conda. RUN curl -LO ""https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-aarch64.sh"" && \. bash Miniconda3-latest-Linux-aarch64.sh -b -p /opt/miniconda && \. rm Miniconda3-latest-Linux-aarch64.sh. # Setup Conda environment. ENV PATH=""/opt/miniconda/bin:${PATH}"". RUN conda config --add channels defaults && \. conda config --add channels bioconda && \. conda config --add channels conda-forge && \. conda create -n bio bioconda::bcftools bioconda::samtools -y && \. conda clean -a. # Clone DeepVariant and build. FROM base AS builder. # Clone the DeepVariant repository. RUN git clone https://github.com/google/deepvariant.git /opt/deepvariant && \. cd /opt/deepvariant && \. git checkout tags/v1.6.1. # Run Bazel build with additional flags to skip problematic configurations. RUN bazel build -c opt --noincremental --experimental_action_listener= //deepvariant:make_examples //deepvariant:call_variants //deepvariant:postprocess_variants || { \. echo ""Bazel build failed""; \. exit 1; }. # Final image. FROM base AS final. # Set environment variables. ENV VERSION=1.6.0. ENV PYTHON_VERSION=3.8. ENV PATH=""/opt/miniconda/bin:${PATH}"". # Install Python packages. RUN pip install --upgrade pip setuptools wheel --timeout=120 && \. pip install jaxlib jax --timeout=120 --extra-index-url https://storage.googleapis.com/jax-releases/jax_releases.html. # Copy DeepVariant binaries from the builder stage. COPY --from=builder /opt/deepvariant /opt/deepvariant. WORKDIR /opt/deepvariant. # Ensure executable scripts are correctly set up. RUN BASH_HEADER='#!/bin/bash' && \",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/871
https://github.com/google/deepvariant/issues/871:5191,interoperability,wrapper,wrappers,5191,"ant/bazel-out/k8-opt/bin/deepvariant/vcf_stats_report.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/show_examples.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/runtime_by_region_vis.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/multisample_make_examples.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/labeler/labeled_examples_to_vcf.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/make_examples_somatic.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/train.zip . COPY --from=builder /opt/deepvariant/scripts/run_deepvariant.py . COPY --from=builder /opt/deepvariant/scripts/run_deepsomatic.py . RUN ./run-prereq.sh. RUN update-alternatives --install /usr/bin/python3 python3 /usr/bin/python${PYTHON_VERSION} 0 && \. 	update-alternatives --install /usr/bin/python python /usr/bin/python${PYTHON_VERSION} 0. # Create shell wrappers for python zip files for easier use. RUN \. BASH_HEADER='#!/bin/bash' && \. printf ""%s\n%s\n"" \. 	""${BASH_HEADER}"" \. 	'python3 /opt/deepvariant/bin/make_examples.zip ""$@""' > \. 	/opt/deepvariant/bin/make_examples && \. printf ""%s\n%s\n"" \. 	""${BASH_HEADER}"" \. 	'python3 /opt/deepvariant/bin/call_variants.zip ""$@""' > \. 	/opt/deepvariant/bin/call_variants && \. printf ""%s\n%s\n"" \. 	""${BASH_HEADER}"" \. 	'python3 /opt/deepvariant/bin/call_variants_slim.zip ""$@""' > \. 	/opt/deepvariant/bin/call_variants_slim && \. printf ""%s\n%s\n"" \. 	""${BASH_HEADER}"" \. 	'python3 /opt/deepvariant/bin/postprocess_variants.zip ""$@""' > \. 	/opt/deepvariant/bin/postprocess_variants && \. printf ""%s\n%s\n"" \. 	""${BASH_HEADER}"" \. 	'python3 /opt/deepvariant/bin/vcf_stats_report.zip ""$@""' > \. 	/opt/deepvariant/bin/vcf_stats_report && \. printf ""%s\n%s\n"" \. 	""${BASH_HEADER}"" \. 	'python3 /opt/deepvariant/bin/show_examples.zip ""$@""' > \. 	/opt/deepvariant/bin/show_examples && \. printf ""%s\n%s\n"" \. 	""${",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/871
https://github.com/google/deepvariant/issues/871:333,modifiability,version,version,333,"Troubleshooting Dockerfile for DeepVariant on Mac M1: Issues with Bazel ; Im new to working with computers tools like DeepVariant. Im trying to build DeepVariant using Docker on a Mac M1 and am encountering issues with the Dockerfile during the Bazel build process. I want to ensure compatibility with ARM64 architecture. **Docker version**: Docker version 27.1.1, build 6312585. **Bazel Version**: 7.3.1. **MacBook Model**: M1 chip (ARM64 architecture). **Error**: . ![IMG_3267](https://github.com/user-attachments/assets/11e28824-b941-42cc-9d33-7e9155a03543). ![IMG_3268](https://github.com/user-attachments/assets/4e923de6-99d5-43ee-80c6-29b32504527d). **My Dockerfilee code**:. ```. # Base image suitable for ARM64 architecture. FROM arm64v8/ubuntu:latest AS base. # Prevent interactive prompts. ENV DEBIAN_FRONTEND=noninteractive. # Install necessary packages. RUN apt-get update && \. apt-get install -y \. git \. curl \. unzip \. wget \. openjdk-17-jdk \. build-essential \. bzip2 \. python3-pip \. parallel && \. apt-get clean && \. rm -rf /var/lib/apt/lists/*. # Install Bazel (adjust version as needed). RUN curl -LO ""https://github.com/bazelbuild/bazel/releases/download/7.3.1/bazel-7.3.1-linux-arm64"" && \. chmod +x bazel-7.3.1-linux-arm64 && \. mv bazel-7.3.1-linux-arm64 /usr/local/bin/bazel. # Install Conda. RUN curl -LO ""https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-aarch64.sh"" && \. bash Miniconda3-latest-Linux-aarch64.sh -b -p /opt/miniconda && \. rm Miniconda3-latest-Linux-aarch64.sh. # Setup Conda environment. ENV PATH=""/opt/miniconda/bin:${PATH}"". RUN conda config --add channels defaults && \. conda config --add channels bioconda && \. conda config --add channels conda-forge && \. conda create -n bio bioconda::bcftools bioconda::samtools -y && \. conda clean -a. # Clone DeepVariant and build. FROM base AS builder. # Clone the DeepVariant repository. RUN git clone https://github.com/google/deepvariant.git /opt/deepvariant && \. cd /opt/deepvariant && ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/871
https://github.com/google/deepvariant/issues/871:351,modifiability,version,version,351,"Troubleshooting Dockerfile for DeepVariant on Mac M1: Issues with Bazel ; Im new to working with computers tools like DeepVariant. Im trying to build DeepVariant using Docker on a Mac M1 and am encountering issues with the Dockerfile during the Bazel build process. I want to ensure compatibility with ARM64 architecture. **Docker version**: Docker version 27.1.1, build 6312585. **Bazel Version**: 7.3.1. **MacBook Model**: M1 chip (ARM64 architecture). **Error**: . ![IMG_3267](https://github.com/user-attachments/assets/11e28824-b941-42cc-9d33-7e9155a03543). ![IMG_3268](https://github.com/user-attachments/assets/4e923de6-99d5-43ee-80c6-29b32504527d). **My Dockerfilee code**:. ```. # Base image suitable for ARM64 architecture. FROM arm64v8/ubuntu:latest AS base. # Prevent interactive prompts. ENV DEBIAN_FRONTEND=noninteractive. # Install necessary packages. RUN apt-get update && \. apt-get install -y \. git \. curl \. unzip \. wget \. openjdk-17-jdk \. build-essential \. bzip2 \. python3-pip \. parallel && \. apt-get clean && \. rm -rf /var/lib/apt/lists/*. # Install Bazel (adjust version as needed). RUN curl -LO ""https://github.com/bazelbuild/bazel/releases/download/7.3.1/bazel-7.3.1-linux-arm64"" && \. chmod +x bazel-7.3.1-linux-arm64 && \. mv bazel-7.3.1-linux-arm64 /usr/local/bin/bazel. # Install Conda. RUN curl -LO ""https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-aarch64.sh"" && \. bash Miniconda3-latest-Linux-aarch64.sh -b -p /opt/miniconda && \. rm Miniconda3-latest-Linux-aarch64.sh. # Setup Conda environment. ENV PATH=""/opt/miniconda/bin:${PATH}"". RUN conda config --add channels defaults && \. conda config --add channels bioconda && \. conda config --add channels conda-forge && \. conda create -n bio bioconda::bcftools bioconda::samtools -y && \. conda clean -a. # Clone DeepVariant and build. FROM base AS builder. # Clone the DeepVariant repository. RUN git clone https://github.com/google/deepvariant.git /opt/deepvariant && \. cd /opt/deepvariant && ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/871
https://github.com/google/deepvariant/issues/871:390,modifiability,Version,Version,390,"Troubleshooting Dockerfile for DeepVariant on Mac M1: Issues with Bazel ; Im new to working with computers tools like DeepVariant. Im trying to build DeepVariant using Docker on a Mac M1 and am encountering issues with the Dockerfile during the Bazel build process. I want to ensure compatibility with ARM64 architecture. **Docker version**: Docker version 27.1.1, build 6312585. **Bazel Version**: 7.3.1. **MacBook Model**: M1 chip (ARM64 architecture). **Error**: . ![IMG_3267](https://github.com/user-attachments/assets/11e28824-b941-42cc-9d33-7e9155a03543). ![IMG_3268](https://github.com/user-attachments/assets/4e923de6-99d5-43ee-80c6-29b32504527d). **My Dockerfilee code**:. ```. # Base image suitable for ARM64 architecture. FROM arm64v8/ubuntu:latest AS base. # Prevent interactive prompts. ENV DEBIAN_FRONTEND=noninteractive. # Install necessary packages. RUN apt-get update && \. apt-get install -y \. git \. curl \. unzip \. wget \. openjdk-17-jdk \. build-essential \. bzip2 \. python3-pip \. parallel && \. apt-get clean && \. rm -rf /var/lib/apt/lists/*. # Install Bazel (adjust version as needed). RUN curl -LO ""https://github.com/bazelbuild/bazel/releases/download/7.3.1/bazel-7.3.1-linux-arm64"" && \. chmod +x bazel-7.3.1-linux-arm64 && \. mv bazel-7.3.1-linux-arm64 /usr/local/bin/bazel. # Install Conda. RUN curl -LO ""https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-aarch64.sh"" && \. bash Miniconda3-latest-Linux-aarch64.sh -b -p /opt/miniconda && \. rm Miniconda3-latest-Linux-aarch64.sh. # Setup Conda environment. ENV PATH=""/opt/miniconda/bin:${PATH}"". RUN conda config --add channels defaults && \. conda config --add channels bioconda && \. conda config --add channels conda-forge && \. conda create -n bio bioconda::bcftools bioconda::samtools -y && \. conda clean -a. # Clone DeepVariant and build. FROM base AS builder. # Clone the DeepVariant repository. RUN git clone https://github.com/google/deepvariant.git /opt/deepvariant && \. cd /opt/deepvariant && ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/871
https://github.com/google/deepvariant/issues/871:858,modifiability,pac,packages,858,"Troubleshooting Dockerfile for DeepVariant on Mac M1: Issues with Bazel ; Im new to working with computers tools like DeepVariant. Im trying to build DeepVariant using Docker on a Mac M1 and am encountering issues with the Dockerfile during the Bazel build process. I want to ensure compatibility with ARM64 architecture. **Docker version**: Docker version 27.1.1, build 6312585. **Bazel Version**: 7.3.1. **MacBook Model**: M1 chip (ARM64 architecture). **Error**: . ![IMG_3267](https://github.com/user-attachments/assets/11e28824-b941-42cc-9d33-7e9155a03543). ![IMG_3268](https://github.com/user-attachments/assets/4e923de6-99d5-43ee-80c6-29b32504527d). **My Dockerfilee code**:. ```. # Base image suitable for ARM64 architecture. FROM arm64v8/ubuntu:latest AS base. # Prevent interactive prompts. ENV DEBIAN_FRONTEND=noninteractive. # Install necessary packages. RUN apt-get update && \. apt-get install -y \. git \. curl \. unzip \. wget \. openjdk-17-jdk \. build-essential \. bzip2 \. python3-pip \. parallel && \. apt-get clean && \. rm -rf /var/lib/apt/lists/*. # Install Bazel (adjust version as needed). RUN curl -LO ""https://github.com/bazelbuild/bazel/releases/download/7.3.1/bazel-7.3.1-linux-arm64"" && \. chmod +x bazel-7.3.1-linux-arm64 && \. mv bazel-7.3.1-linux-arm64 /usr/local/bin/bazel. # Install Conda. RUN curl -LO ""https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-aarch64.sh"" && \. bash Miniconda3-latest-Linux-aarch64.sh -b -p /opt/miniconda && \. rm Miniconda3-latest-Linux-aarch64.sh. # Setup Conda environment. ENV PATH=""/opt/miniconda/bin:${PATH}"". RUN conda config --add channels defaults && \. conda config --add channels bioconda && \. conda config --add channels conda-forge && \. conda create -n bio bioconda::bcftools bioconda::samtools -y && \. conda clean -a. # Clone DeepVariant and build. FROM base AS builder. # Clone the DeepVariant repository. RUN git clone https://github.com/google/deepvariant.git /opt/deepvariant && \. cd /opt/deepvariant && ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/871
https://github.com/google/deepvariant/issues/871:1096,modifiability,version,version,1096,"mputers tools like DeepVariant. Im trying to build DeepVariant using Docker on a Mac M1 and am encountering issues with the Dockerfile during the Bazel build process. I want to ensure compatibility with ARM64 architecture. **Docker version**: Docker version 27.1.1, build 6312585. **Bazel Version**: 7.3.1. **MacBook Model**: M1 chip (ARM64 architecture). **Error**: . ![IMG_3267](https://github.com/user-attachments/assets/11e28824-b941-42cc-9d33-7e9155a03543). ![IMG_3268](https://github.com/user-attachments/assets/4e923de6-99d5-43ee-80c6-29b32504527d). **My Dockerfilee code**:. ```. # Base image suitable for ARM64 architecture. FROM arm64v8/ubuntu:latest AS base. # Prevent interactive prompts. ENV DEBIAN_FRONTEND=noninteractive. # Install necessary packages. RUN apt-get update && \. apt-get install -y \. git \. curl \. unzip \. wget \. openjdk-17-jdk \. build-essential \. bzip2 \. python3-pip \. parallel && \. apt-get clean && \. rm -rf /var/lib/apt/lists/*. # Install Bazel (adjust version as needed). RUN curl -LO ""https://github.com/bazelbuild/bazel/releases/download/7.3.1/bazel-7.3.1-linux-arm64"" && \. chmod +x bazel-7.3.1-linux-arm64 && \. mv bazel-7.3.1-linux-arm64 /usr/local/bin/bazel. # Install Conda. RUN curl -LO ""https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-aarch64.sh"" && \. bash Miniconda3-latest-Linux-aarch64.sh -b -p /opt/miniconda && \. rm Miniconda3-latest-Linux-aarch64.sh. # Setup Conda environment. ENV PATH=""/opt/miniconda/bin:${PATH}"". RUN conda config --add channels defaults && \. conda config --add channels bioconda && \. conda config --add channels conda-forge && \. conda create -n bio bioconda::bcftools bioconda::samtools -y && \. conda clean -a. # Clone DeepVariant and build. FROM base AS builder. # Clone the DeepVariant repository. RUN git clone https://github.com/google/deepvariant.git /opt/deepvariant && \. cd /opt/deepvariant && \. git checkout tags/v1.6.1. # Run Bazel build with additional flags to skip problematic configurati",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/871
https://github.com/google/deepvariant/issues/871:2089,modifiability,configur,configurations,2089,"version as needed). RUN curl -LO ""https://github.com/bazelbuild/bazel/releases/download/7.3.1/bazel-7.3.1-linux-arm64"" && \. chmod +x bazel-7.3.1-linux-arm64 && \. mv bazel-7.3.1-linux-arm64 /usr/local/bin/bazel. # Install Conda. RUN curl -LO ""https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-aarch64.sh"" && \. bash Miniconda3-latest-Linux-aarch64.sh -b -p /opt/miniconda && \. rm Miniconda3-latest-Linux-aarch64.sh. # Setup Conda environment. ENV PATH=""/opt/miniconda/bin:${PATH}"". RUN conda config --add channels defaults && \. conda config --add channels bioconda && \. conda config --add channels conda-forge && \. conda create -n bio bioconda::bcftools bioconda::samtools -y && \. conda clean -a. # Clone DeepVariant and build. FROM base AS builder. # Clone the DeepVariant repository. RUN git clone https://github.com/google/deepvariant.git /opt/deepvariant && \. cd /opt/deepvariant && \. git checkout tags/v1.6.1. # Run Bazel build with additional flags to skip problematic configurations. RUN bazel build -c opt --noincremental --experimental_action_listener= //deepvariant:make_examples //deepvariant:call_variants //deepvariant:postprocess_variants || { \. echo ""Bazel build failed""; \. exit 1; }. # Final image. FROM base AS final. # Set environment variables. ENV VERSION=1.6.0. ENV PYTHON_VERSION=3.8. ENV PATH=""/opt/miniconda/bin:${PATH}"". # Install Python packages. RUN pip install --upgrade pip setuptools wheel --timeout=120 && \. pip install jaxlib jax --timeout=120 --extra-index-url https://storage.googleapis.com/jax-releases/jax_releases.html. # Copy DeepVariant binaries from the builder stage. COPY --from=builder /opt/deepvariant /opt/deepvariant. WORKDIR /opt/deepvariant. # Ensure executable scripts are correctly set up. RUN BASH_HEADER='#!/bin/bash' && \. for script in make_examples call_variants call_variants_slim postprocess_variants vcf_stats_report show_examples runtime_by_region_vis multisample_make_examples labeled_examples_to_vcf make_examples_soma",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/871
https://github.com/google/deepvariant/issues/871:2369,modifiability,variab,variables,2369,"a/Miniconda3-latest-Linux-aarch64.sh"" && \. bash Miniconda3-latest-Linux-aarch64.sh -b -p /opt/miniconda && \. rm Miniconda3-latest-Linux-aarch64.sh. # Setup Conda environment. ENV PATH=""/opt/miniconda/bin:${PATH}"". RUN conda config --add channels defaults && \. conda config --add channels bioconda && \. conda config --add channels conda-forge && \. conda create -n bio bioconda::bcftools bioconda::samtools -y && \. conda clean -a. # Clone DeepVariant and build. FROM base AS builder. # Clone the DeepVariant repository. RUN git clone https://github.com/google/deepvariant.git /opt/deepvariant && \. cd /opt/deepvariant && \. git checkout tags/v1.6.1. # Run Bazel build with additional flags to skip problematic configurations. RUN bazel build -c opt --noincremental --experimental_action_listener= //deepvariant:make_examples //deepvariant:call_variants //deepvariant:postprocess_variants || { \. echo ""Bazel build failed""; \. exit 1; }. # Final image. FROM base AS final. # Set environment variables. ENV VERSION=1.6.0. ENV PYTHON_VERSION=3.8. ENV PATH=""/opt/miniconda/bin:${PATH}"". # Install Python packages. RUN pip install --upgrade pip setuptools wheel --timeout=120 && \. pip install jaxlib jax --timeout=120 --extra-index-url https://storage.googleapis.com/jax-releases/jax_releases.html. # Copy DeepVariant binaries from the builder stage. COPY --from=builder /opt/deepvariant /opt/deepvariant. WORKDIR /opt/deepvariant. # Ensure executable scripts are correctly set up. RUN BASH_HEADER='#!/bin/bash' && \. for script in make_examples call_variants call_variants_slim postprocess_variants vcf_stats_report show_examples runtime_by_region_vis multisample_make_examples labeled_examples_to_vcf make_examples_somatic train run_deepvariant run_deepsomatic; do \. printf ""%s\n%s\n"" ""${BASH_HEADER}"" ""python3 /opt/deepvariant/bin/${script}.zip \""$@\"""" > /opt/deepvariant/bin/${script} && \. chmod +x /opt/deepvariant/bin/${script}; \. done. # Copy licenses and other necessary files. # Ensure t",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/871
https://github.com/google/deepvariant/issues/871:2384,modifiability,VERSION,VERSION,2384,"atest-Linux-aarch64.sh"" && \. bash Miniconda3-latest-Linux-aarch64.sh -b -p /opt/miniconda && \. rm Miniconda3-latest-Linux-aarch64.sh. # Setup Conda environment. ENV PATH=""/opt/miniconda/bin:${PATH}"". RUN conda config --add channels defaults && \. conda config --add channels bioconda && \. conda config --add channels conda-forge && \. conda create -n bio bioconda::bcftools bioconda::samtools -y && \. conda clean -a. # Clone DeepVariant and build. FROM base AS builder. # Clone the DeepVariant repository. RUN git clone https://github.com/google/deepvariant.git /opt/deepvariant && \. cd /opt/deepvariant && \. git checkout tags/v1.6.1. # Run Bazel build with additional flags to skip problematic configurations. RUN bazel build -c opt --noincremental --experimental_action_listener= //deepvariant:make_examples //deepvariant:call_variants //deepvariant:postprocess_variants || { \. echo ""Bazel build failed""; \. exit 1; }. # Final image. FROM base AS final. # Set environment variables. ENV VERSION=1.6.0. ENV PYTHON_VERSION=3.8. ENV PATH=""/opt/miniconda/bin:${PATH}"". # Install Python packages. RUN pip install --upgrade pip setuptools wheel --timeout=120 && \. pip install jaxlib jax --timeout=120 --extra-index-url https://storage.googleapis.com/jax-releases/jax_releases.html. # Copy DeepVariant binaries from the builder stage. COPY --from=builder /opt/deepvariant /opt/deepvariant. WORKDIR /opt/deepvariant. # Ensure executable scripts are correctly set up. RUN BASH_HEADER='#!/bin/bash' && \. for script in make_examples call_variants call_variants_slim postprocess_variants vcf_stats_report show_examples runtime_by_region_vis multisample_make_examples labeled_examples_to_vcf make_examples_somatic train run_deepvariant run_deepsomatic; do \. printf ""%s\n%s\n"" ""${BASH_HEADER}"" ""python3 /opt/deepvariant/bin/${script}.zip \""$@\"""" > /opt/deepvariant/bin/${script} && \. chmod +x /opt/deepvariant/bin/${script}; \. done. # Copy licenses and other necessary files. # Ensure these paths and",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/871
https://github.com/google/deepvariant/issues/871:2479,modifiability,pac,packages,2479,". rm Miniconda3-latest-Linux-aarch64.sh. # Setup Conda environment. ENV PATH=""/opt/miniconda/bin:${PATH}"". RUN conda config --add channels defaults && \. conda config --add channels bioconda && \. conda config --add channels conda-forge && \. conda create -n bio bioconda::bcftools bioconda::samtools -y && \. conda clean -a. # Clone DeepVariant and build. FROM base AS builder. # Clone the DeepVariant repository. RUN git clone https://github.com/google/deepvariant.git /opt/deepvariant && \. cd /opt/deepvariant && \. git checkout tags/v1.6.1. # Run Bazel build with additional flags to skip problematic configurations. RUN bazel build -c opt --noincremental --experimental_action_listener= //deepvariant:make_examples //deepvariant:call_variants //deepvariant:postprocess_variants || { \. echo ""Bazel build failed""; \. exit 1; }. # Final image. FROM base AS final. # Set environment variables. ENV VERSION=1.6.0. ENV PYTHON_VERSION=3.8. ENV PATH=""/opt/miniconda/bin:${PATH}"". # Install Python packages. RUN pip install --upgrade pip setuptools wheel --timeout=120 && \. pip install jaxlib jax --timeout=120 --extra-index-url https://storage.googleapis.com/jax-releases/jax_releases.html. # Copy DeepVariant binaries from the builder stage. COPY --from=builder /opt/deepvariant /opt/deepvariant. WORKDIR /opt/deepvariant. # Ensure executable scripts are correctly set up. RUN BASH_HEADER='#!/bin/bash' && \. for script in make_examples call_variants call_variants_slim postprocess_variants vcf_stats_report show_examples runtime_by_region_vis multisample_make_examples labeled_examples_to_vcf make_examples_somatic train run_deepvariant run_deepsomatic; do \. printf ""%s\n%s\n"" ""${BASH_HEADER}"" ""python3 /opt/deepvariant/bin/${script}.zip \""$@\"""" > /opt/deepvariant/bin/${script} && \. chmod +x /opt/deepvariant/bin/${script}; \. done. # Copy licenses and other necessary files. # Ensure these paths and URLs are correct and accessible. # Replace with valid URLs or remove if not needed. ADD https:",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/871
https://github.com/google/deepvariant/issues/871:2507,modifiability,upgrad,upgrade,2507,"-aarch64.sh. # Setup Conda environment. ENV PATH=""/opt/miniconda/bin:${PATH}"". RUN conda config --add channels defaults && \. conda config --add channels bioconda && \. conda config --add channels conda-forge && \. conda create -n bio bioconda::bcftools bioconda::samtools -y && \. conda clean -a. # Clone DeepVariant and build. FROM base AS builder. # Clone the DeepVariant repository. RUN git clone https://github.com/google/deepvariant.git /opt/deepvariant && \. cd /opt/deepvariant && \. git checkout tags/v1.6.1. # Run Bazel build with additional flags to skip problematic configurations. RUN bazel build -c opt --noincremental --experimental_action_listener= //deepvariant:make_examples //deepvariant:call_variants //deepvariant:postprocess_variants || { \. echo ""Bazel build failed""; \. exit 1; }. # Final image. FROM base AS final. # Set environment variables. ENV VERSION=1.6.0. ENV PYTHON_VERSION=3.8. ENV PATH=""/opt/miniconda/bin:${PATH}"". # Install Python packages. RUN pip install --upgrade pip setuptools wheel --timeout=120 && \. pip install jaxlib jax --timeout=120 --extra-index-url https://storage.googleapis.com/jax-releases/jax_releases.html. # Copy DeepVariant binaries from the builder stage. COPY --from=builder /opt/deepvariant /opt/deepvariant. WORKDIR /opt/deepvariant. # Ensure executable scripts are correctly set up. RUN BASH_HEADER='#!/bin/bash' && \. for script in make_examples call_variants call_variants_slim postprocess_variants vcf_stats_report show_examples runtime_by_region_vis multisample_make_examples labeled_examples_to_vcf make_examples_somatic train run_deepvariant run_deepsomatic; do \. printf ""%s\n%s\n"" ""${BASH_HEADER}"" ""python3 /opt/deepvariant/bin/${script}.zip \""$@\"""" > /opt/deepvariant/bin/${script} && \. chmod +x /opt/deepvariant/bin/${script}; \. done. # Copy licenses and other necessary files. # Ensure these paths and URLs are correct and accessible. # Replace with valid URLs or remove if not needed. ADD https://storage.googleapis.com/dee",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/871
https://github.com/google/deepvariant/issues/871:459,performance,Error,Error,459,"Troubleshooting Dockerfile for DeepVariant on Mac M1: Issues with Bazel ; Im new to working with computers tools like DeepVariant. Im trying to build DeepVariant using Docker on a Mac M1 and am encountering issues with the Dockerfile during the Bazel build process. I want to ensure compatibility with ARM64 architecture. **Docker version**: Docker version 27.1.1, build 6312585. **Bazel Version**: 7.3.1. **MacBook Model**: M1 chip (ARM64 architecture). **Error**: . ![IMG_3267](https://github.com/user-attachments/assets/11e28824-b941-42cc-9d33-7e9155a03543). ![IMG_3268](https://github.com/user-attachments/assets/4e923de6-99d5-43ee-80c6-29b32504527d). **My Dockerfilee code**:. ```. # Base image suitable for ARM64 architecture. FROM arm64v8/ubuntu:latest AS base. # Prevent interactive prompts. ENV DEBIAN_FRONTEND=noninteractive. # Install necessary packages. RUN apt-get update && \. apt-get install -y \. git \. curl \. unzip \. wget \. openjdk-17-jdk \. build-essential \. bzip2 \. python3-pip \. parallel && \. apt-get clean && \. rm -rf /var/lib/apt/lists/*. # Install Bazel (adjust version as needed). RUN curl -LO ""https://github.com/bazelbuild/bazel/releases/download/7.3.1/bazel-7.3.1-linux-arm64"" && \. chmod +x bazel-7.3.1-linux-arm64 && \. mv bazel-7.3.1-linux-arm64 /usr/local/bin/bazel. # Install Conda. RUN curl -LO ""https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-aarch64.sh"" && \. bash Miniconda3-latest-Linux-aarch64.sh -b -p /opt/miniconda && \. rm Miniconda3-latest-Linux-aarch64.sh. # Setup Conda environment. ENV PATH=""/opt/miniconda/bin:${PATH}"". RUN conda config --add channels defaults && \. conda config --add channels bioconda && \. conda config --add channels conda-forge && \. conda create -n bio bioconda::bcftools bioconda::samtools -y && \. conda clean -a. # Clone DeepVariant and build. FROM base AS builder. # Clone the DeepVariant repository. RUN git clone https://github.com/google/deepvariant.git /opt/deepvariant && \. cd /opt/deepvariant && ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/871
https://github.com/google/deepvariant/issues/871:1008,performance,parallel,parallel,1008,"ing Dockerfile for DeepVariant on Mac M1: Issues with Bazel ; Im new to working with computers tools like DeepVariant. Im trying to build DeepVariant using Docker on a Mac M1 and am encountering issues with the Dockerfile during the Bazel build process. I want to ensure compatibility with ARM64 architecture. **Docker version**: Docker version 27.1.1, build 6312585. **Bazel Version**: 7.3.1. **MacBook Model**: M1 chip (ARM64 architecture). **Error**: . ![IMG_3267](https://github.com/user-attachments/assets/11e28824-b941-42cc-9d33-7e9155a03543). ![IMG_3268](https://github.com/user-attachments/assets/4e923de6-99d5-43ee-80c6-29b32504527d). **My Dockerfilee code**:. ```. # Base image suitable for ARM64 architecture. FROM arm64v8/ubuntu:latest AS base. # Prevent interactive prompts. ENV DEBIAN_FRONTEND=noninteractive. # Install necessary packages. RUN apt-get update && \. apt-get install -y \. git \. curl \. unzip \. wget \. openjdk-17-jdk \. build-essential \. bzip2 \. python3-pip \. parallel && \. apt-get clean && \. rm -rf /var/lib/apt/lists/*. # Install Bazel (adjust version as needed). RUN curl -LO ""https://github.com/bazelbuild/bazel/releases/download/7.3.1/bazel-7.3.1-linux-arm64"" && \. chmod +x bazel-7.3.1-linux-arm64 && \. mv bazel-7.3.1-linux-arm64 /usr/local/bin/bazel. # Install Conda. RUN curl -LO ""https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-aarch64.sh"" && \. bash Miniconda3-latest-Linux-aarch64.sh -b -p /opt/miniconda && \. rm Miniconda3-latest-Linux-aarch64.sh. # Setup Conda environment. ENV PATH=""/opt/miniconda/bin:${PATH}"". RUN conda config --add channels defaults && \. conda config --add channels bioconda && \. conda config --add channels conda-forge && \. conda create -n bio bioconda::bcftools bioconda::samtools -y && \. conda clean -a. # Clone DeepVariant and build. FROM base AS builder. # Clone the DeepVariant repository. RUN git clone https://github.com/google/deepvariant.git /opt/deepvariant && \. cd /opt/deepvariant && \. git check",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/871
https://github.com/google/deepvariant/issues/871:2538,performance,time,timeout,2538,"ronment. ENV PATH=""/opt/miniconda/bin:${PATH}"". RUN conda config --add channels defaults && \. conda config --add channels bioconda && \. conda config --add channels conda-forge && \. conda create -n bio bioconda::bcftools bioconda::samtools -y && \. conda clean -a. # Clone DeepVariant and build. FROM base AS builder. # Clone the DeepVariant repository. RUN git clone https://github.com/google/deepvariant.git /opt/deepvariant && \. cd /opt/deepvariant && \. git checkout tags/v1.6.1. # Run Bazel build with additional flags to skip problematic configurations. RUN bazel build -c opt --noincremental --experimental_action_listener= //deepvariant:make_examples //deepvariant:call_variants //deepvariant:postprocess_variants || { \. echo ""Bazel build failed""; \. exit 1; }. # Final image. FROM base AS final. # Set environment variables. ENV VERSION=1.6.0. ENV PYTHON_VERSION=3.8. ENV PATH=""/opt/miniconda/bin:${PATH}"". # Install Python packages. RUN pip install --upgrade pip setuptools wheel --timeout=120 && \. pip install jaxlib jax --timeout=120 --extra-index-url https://storage.googleapis.com/jax-releases/jax_releases.html. # Copy DeepVariant binaries from the builder stage. COPY --from=builder /opt/deepvariant /opt/deepvariant. WORKDIR /opt/deepvariant. # Ensure executable scripts are correctly set up. RUN BASH_HEADER='#!/bin/bash' && \. for script in make_examples call_variants call_variants_slim postprocess_variants vcf_stats_report show_examples runtime_by_region_vis multisample_make_examples labeled_examples_to_vcf make_examples_somatic train run_deepvariant run_deepsomatic; do \. printf ""%s\n%s\n"" ""${BASH_HEADER}"" ""python3 /opt/deepvariant/bin/${script}.zip \""$@\"""" > /opt/deepvariant/bin/${script} && \. chmod +x /opt/deepvariant/bin/${script}; \. done. # Copy licenses and other necessary files. # Ensure these paths and URLs are correct and accessible. # Replace with valid URLs or remove if not needed. ADD https://storage.googleapis.com/deepvariant/models/DeepVariant/1.6",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/871
https://github.com/google/deepvariant/issues/871:2581,performance,time,timeout,2581,"H}"". RUN conda config --add channels defaults && \. conda config --add channels bioconda && \. conda config --add channels conda-forge && \. conda create -n bio bioconda::bcftools bioconda::samtools -y && \. conda clean -a. # Clone DeepVariant and build. FROM base AS builder. # Clone the DeepVariant repository. RUN git clone https://github.com/google/deepvariant.git /opt/deepvariant && \. cd /opt/deepvariant && \. git checkout tags/v1.6.1. # Run Bazel build with additional flags to skip problematic configurations. RUN bazel build -c opt --noincremental --experimental_action_listener= //deepvariant:make_examples //deepvariant:call_variants //deepvariant:postprocess_variants || { \. echo ""Bazel build failed""; \. exit 1; }. # Final image. FROM base AS final. # Set environment variables. ENV VERSION=1.6.0. ENV PYTHON_VERSION=3.8. ENV PATH=""/opt/miniconda/bin:${PATH}"". # Install Python packages. RUN pip install --upgrade pip setuptools wheel --timeout=120 && \. pip install jaxlib jax --timeout=120 --extra-index-url https://storage.googleapis.com/jax-releases/jax_releases.html. # Copy DeepVariant binaries from the builder stage. COPY --from=builder /opt/deepvariant /opt/deepvariant. WORKDIR /opt/deepvariant. # Ensure executable scripts are correctly set up. RUN BASH_HEADER='#!/bin/bash' && \. for script in make_examples call_variants call_variants_slim postprocess_variants vcf_stats_report show_examples runtime_by_region_vis multisample_make_examples labeled_examples_to_vcf make_examples_somatic train run_deepvariant run_deepsomatic; do \. printf ""%s\n%s\n"" ""${BASH_HEADER}"" ""python3 /opt/deepvariant/bin/${script}.zip \""$@\"""" > /opt/deepvariant/bin/${script} && \. chmod +x /opt/deepvariant/bin/${script}; \. done. # Copy licenses and other necessary files. # Ensure these paths and URLs are correct and accessible. # Replace with valid URLs or remove if not needed. ADD https://storage.googleapis.com/deepvariant/models/DeepVariant/1.6.0/savedmodels/deepvariant.hybrid.savedmode",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/871
https://github.com/google/deepvariant/issues/871:2293,reliability,fail,failed,2293,"l/bin/bazel. # Install Conda. RUN curl -LO ""https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-aarch64.sh"" && \. bash Miniconda3-latest-Linux-aarch64.sh -b -p /opt/miniconda && \. rm Miniconda3-latest-Linux-aarch64.sh. # Setup Conda environment. ENV PATH=""/opt/miniconda/bin:${PATH}"". RUN conda config --add channels defaults && \. conda config --add channels bioconda && \. conda config --add channels conda-forge && \. conda create -n bio bioconda::bcftools bioconda::samtools -y && \. conda clean -a. # Clone DeepVariant and build. FROM base AS builder. # Clone the DeepVariant repository. RUN git clone https://github.com/google/deepvariant.git /opt/deepvariant && \. cd /opt/deepvariant && \. git checkout tags/v1.6.1. # Run Bazel build with additional flags to skip problematic configurations. RUN bazel build -c opt --noincremental --experimental_action_listener= //deepvariant:make_examples //deepvariant:call_variants //deepvariant:postprocess_variants || { \. echo ""Bazel build failed""; \. exit 1; }. # Final image. FROM base AS final. # Set environment variables. ENV VERSION=1.6.0. ENV PYTHON_VERSION=3.8. ENV PATH=""/opt/miniconda/bin:${PATH}"". # Install Python packages. RUN pip install --upgrade pip setuptools wheel --timeout=120 && \. pip install jaxlib jax --timeout=120 --extra-index-url https://storage.googleapis.com/jax-releases/jax_releases.html. # Copy DeepVariant binaries from the builder stage. COPY --from=builder /opt/deepvariant /opt/deepvariant. WORKDIR /opt/deepvariant. # Ensure executable scripts are correctly set up. RUN BASH_HEADER='#!/bin/bash' && \. for script in make_examples call_variants call_variants_slim postprocess_variants vcf_stats_report show_examples runtime_by_region_vis multisample_make_examples labeled_examples_to_vcf make_examples_somatic train run_deepvariant run_deepsomatic; do \. printf ""%s\n%s\n"" ""${BASH_HEADER}"" ""python3 /opt/deepvariant/bin/${script}.zip \""$@\"""" > /opt/deepvariant/bin/${script} && \. chmod +x /opt/deepvariant",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/871
https://github.com/google/deepvariant/issues/871:459,safety,Error,Error,459,"Troubleshooting Dockerfile for DeepVariant on Mac M1: Issues with Bazel ; Im new to working with computers tools like DeepVariant. Im trying to build DeepVariant using Docker on a Mac M1 and am encountering issues with the Dockerfile during the Bazel build process. I want to ensure compatibility with ARM64 architecture. **Docker version**: Docker version 27.1.1, build 6312585. **Bazel Version**: 7.3.1. **MacBook Model**: M1 chip (ARM64 architecture). **Error**: . ![IMG_3267](https://github.com/user-attachments/assets/11e28824-b941-42cc-9d33-7e9155a03543). ![IMG_3268](https://github.com/user-attachments/assets/4e923de6-99d5-43ee-80c6-29b32504527d). **My Dockerfilee code**:. ```. # Base image suitable for ARM64 architecture. FROM arm64v8/ubuntu:latest AS base. # Prevent interactive prompts. ENV DEBIAN_FRONTEND=noninteractive. # Install necessary packages. RUN apt-get update && \. apt-get install -y \. git \. curl \. unzip \. wget \. openjdk-17-jdk \. build-essential \. bzip2 \. python3-pip \. parallel && \. apt-get clean && \. rm -rf /var/lib/apt/lists/*. # Install Bazel (adjust version as needed). RUN curl -LO ""https://github.com/bazelbuild/bazel/releases/download/7.3.1/bazel-7.3.1-linux-arm64"" && \. chmod +x bazel-7.3.1-linux-arm64 && \. mv bazel-7.3.1-linux-arm64 /usr/local/bin/bazel. # Install Conda. RUN curl -LO ""https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-aarch64.sh"" && \. bash Miniconda3-latest-Linux-aarch64.sh -b -p /opt/miniconda && \. rm Miniconda3-latest-Linux-aarch64.sh. # Setup Conda environment. ENV PATH=""/opt/miniconda/bin:${PATH}"". RUN conda config --add channels defaults && \. conda config --add channels bioconda && \. conda config --add channels conda-forge && \. conda create -n bio bioconda::bcftools bioconda::samtools -y && \. conda clean -a. # Clone DeepVariant and build. FROM base AS builder. # Clone the DeepVariant repository. RUN git clone https://github.com/google/deepvariant.git /opt/deepvariant && \. cd /opt/deepvariant && ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/871
https://github.com/google/deepvariant/issues/871:773,safety,Prevent,Prevent,773,"Troubleshooting Dockerfile for DeepVariant on Mac M1: Issues with Bazel ; Im new to working with computers tools like DeepVariant. Im trying to build DeepVariant using Docker on a Mac M1 and am encountering issues with the Dockerfile during the Bazel build process. I want to ensure compatibility with ARM64 architecture. **Docker version**: Docker version 27.1.1, build 6312585. **Bazel Version**: 7.3.1. **MacBook Model**: M1 chip (ARM64 architecture). **Error**: . ![IMG_3267](https://github.com/user-attachments/assets/11e28824-b941-42cc-9d33-7e9155a03543). ![IMG_3268](https://github.com/user-attachments/assets/4e923de6-99d5-43ee-80c6-29b32504527d). **My Dockerfilee code**:. ```. # Base image suitable for ARM64 architecture. FROM arm64v8/ubuntu:latest AS base. # Prevent interactive prompts. ENV DEBIAN_FRONTEND=noninteractive. # Install necessary packages. RUN apt-get update && \. apt-get install -y \. git \. curl \. unzip \. wget \. openjdk-17-jdk \. build-essential \. bzip2 \. python3-pip \. parallel && \. apt-get clean && \. rm -rf /var/lib/apt/lists/*. # Install Bazel (adjust version as needed). RUN curl -LO ""https://github.com/bazelbuild/bazel/releases/download/7.3.1/bazel-7.3.1-linux-arm64"" && \. chmod +x bazel-7.3.1-linux-arm64 && \. mv bazel-7.3.1-linux-arm64 /usr/local/bin/bazel. # Install Conda. RUN curl -LO ""https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-aarch64.sh"" && \. bash Miniconda3-latest-Linux-aarch64.sh -b -p /opt/miniconda && \. rm Miniconda3-latest-Linux-aarch64.sh. # Setup Conda environment. ENV PATH=""/opt/miniconda/bin:${PATH}"". RUN conda config --add channels defaults && \. conda config --add channels bioconda && \. conda config --add channels conda-forge && \. conda create -n bio bioconda::bcftools bioconda::samtools -y && \. conda clean -a. # Clone DeepVariant and build. FROM base AS builder. # Clone the DeepVariant repository. RUN git clone https://github.com/google/deepvariant.git /opt/deepvariant && \. cd /opt/deepvariant && ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/871
https://github.com/google/deepvariant/issues/871:880,safety,updat,update,880,"Troubleshooting Dockerfile for DeepVariant on Mac M1: Issues with Bazel ; Im new to working with computers tools like DeepVariant. Im trying to build DeepVariant using Docker on a Mac M1 and am encountering issues with the Dockerfile during the Bazel build process. I want to ensure compatibility with ARM64 architecture. **Docker version**: Docker version 27.1.1, build 6312585. **Bazel Version**: 7.3.1. **MacBook Model**: M1 chip (ARM64 architecture). **Error**: . ![IMG_3267](https://github.com/user-attachments/assets/11e28824-b941-42cc-9d33-7e9155a03543). ![IMG_3268](https://github.com/user-attachments/assets/4e923de6-99d5-43ee-80c6-29b32504527d). **My Dockerfilee code**:. ```. # Base image suitable for ARM64 architecture. FROM arm64v8/ubuntu:latest AS base. # Prevent interactive prompts. ENV DEBIAN_FRONTEND=noninteractive. # Install necessary packages. RUN apt-get update && \. apt-get install -y \. git \. curl \. unzip \. wget \. openjdk-17-jdk \. build-essential \. bzip2 \. python3-pip \. parallel && \. apt-get clean && \. rm -rf /var/lib/apt/lists/*. # Install Bazel (adjust version as needed). RUN curl -LO ""https://github.com/bazelbuild/bazel/releases/download/7.3.1/bazel-7.3.1-linux-arm64"" && \. chmod +x bazel-7.3.1-linux-arm64 && \. mv bazel-7.3.1-linux-arm64 /usr/local/bin/bazel. # Install Conda. RUN curl -LO ""https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-aarch64.sh"" && \. bash Miniconda3-latest-Linux-aarch64.sh -b -p /opt/miniconda && \. rm Miniconda3-latest-Linux-aarch64.sh. # Setup Conda environment. ENV PATH=""/opt/miniconda/bin:${PATH}"". RUN conda config --add channels defaults && \. conda config --add channels bioconda && \. conda config --add channels conda-forge && \. conda create -n bio bioconda::bcftools bioconda::samtools -y && \. conda clean -a. # Clone DeepVariant and build. FROM base AS builder. # Clone the DeepVariant repository. RUN git clone https://github.com/google/deepvariant.git /opt/deepvariant && \. cd /opt/deepvariant && ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/871
https://github.com/google/deepvariant/issues/871:2538,safety,timeout,timeout,2538,"ronment. ENV PATH=""/opt/miniconda/bin:${PATH}"". RUN conda config --add channels defaults && \. conda config --add channels bioconda && \. conda config --add channels conda-forge && \. conda create -n bio bioconda::bcftools bioconda::samtools -y && \. conda clean -a. # Clone DeepVariant and build. FROM base AS builder. # Clone the DeepVariant repository. RUN git clone https://github.com/google/deepvariant.git /opt/deepvariant && \. cd /opt/deepvariant && \. git checkout tags/v1.6.1. # Run Bazel build with additional flags to skip problematic configurations. RUN bazel build -c opt --noincremental --experimental_action_listener= //deepvariant:make_examples //deepvariant:call_variants //deepvariant:postprocess_variants || { \. echo ""Bazel build failed""; \. exit 1; }. # Final image. FROM base AS final. # Set environment variables. ENV VERSION=1.6.0. ENV PYTHON_VERSION=3.8. ENV PATH=""/opt/miniconda/bin:${PATH}"". # Install Python packages. RUN pip install --upgrade pip setuptools wheel --timeout=120 && \. pip install jaxlib jax --timeout=120 --extra-index-url https://storage.googleapis.com/jax-releases/jax_releases.html. # Copy DeepVariant binaries from the builder stage. COPY --from=builder /opt/deepvariant /opt/deepvariant. WORKDIR /opt/deepvariant. # Ensure executable scripts are correctly set up. RUN BASH_HEADER='#!/bin/bash' && \. for script in make_examples call_variants call_variants_slim postprocess_variants vcf_stats_report show_examples runtime_by_region_vis multisample_make_examples labeled_examples_to_vcf make_examples_somatic train run_deepvariant run_deepsomatic; do \. printf ""%s\n%s\n"" ""${BASH_HEADER}"" ""python3 /opt/deepvariant/bin/${script}.zip \""$@\"""" > /opt/deepvariant/bin/${script} && \. chmod +x /opt/deepvariant/bin/${script}; \. done. # Copy licenses and other necessary files. # Ensure these paths and URLs are correct and accessible. # Replace with valid URLs or remove if not needed. ADD https://storage.googleapis.com/deepvariant/models/DeepVariant/1.6",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/871
https://github.com/google/deepvariant/issues/871:2581,safety,timeout,timeout,2581,"H}"". RUN conda config --add channels defaults && \. conda config --add channels bioconda && \. conda config --add channels conda-forge && \. conda create -n bio bioconda::bcftools bioconda::samtools -y && \. conda clean -a. # Clone DeepVariant and build. FROM base AS builder. # Clone the DeepVariant repository. RUN git clone https://github.com/google/deepvariant.git /opt/deepvariant && \. cd /opt/deepvariant && \. git checkout tags/v1.6.1. # Run Bazel build with additional flags to skip problematic configurations. RUN bazel build -c opt --noincremental --experimental_action_listener= //deepvariant:make_examples //deepvariant:call_variants //deepvariant:postprocess_variants || { \. echo ""Bazel build failed""; \. exit 1; }. # Final image. FROM base AS final. # Set environment variables. ENV VERSION=1.6.0. ENV PYTHON_VERSION=3.8. ENV PATH=""/opt/miniconda/bin:${PATH}"". # Install Python packages. RUN pip install --upgrade pip setuptools wheel --timeout=120 && \. pip install jaxlib jax --timeout=120 --extra-index-url https://storage.googleapis.com/jax-releases/jax_releases.html. # Copy DeepVariant binaries from the builder stage. COPY --from=builder /opt/deepvariant /opt/deepvariant. WORKDIR /opt/deepvariant. # Ensure executable scripts are correctly set up. RUN BASH_HEADER='#!/bin/bash' && \. for script in make_examples call_variants call_variants_slim postprocess_variants vcf_stats_report show_examples runtime_by_region_vis multisample_make_examples labeled_examples_to_vcf make_examples_somatic train run_deepvariant run_deepsomatic; do \. printf ""%s\n%s\n"" ""${BASH_HEADER}"" ""python3 /opt/deepvariant/bin/${script}.zip \""$@\"""" > /opt/deepvariant/bin/${script} && \. chmod +x /opt/deepvariant/bin/${script}; \. done. # Copy licenses and other necessary files. # Ensure these paths and URLs are correct and accessible. # Replace with valid URLs or remove if not needed. ADD https://storage.googleapis.com/deepvariant/models/DeepVariant/1.6.0/savedmodels/deepvariant.hybrid.savedmode",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/871
https://github.com/google/deepvariant/issues/871:3437,safety,valid,valid,3437,"niconda/bin:${PATH}"". # Install Python packages. RUN pip install --upgrade pip setuptools wheel --timeout=120 && \. pip install jaxlib jax --timeout=120 --extra-index-url https://storage.googleapis.com/jax-releases/jax_releases.html. # Copy DeepVariant binaries from the builder stage. COPY --from=builder /opt/deepvariant /opt/deepvariant. WORKDIR /opt/deepvariant. # Ensure executable scripts are correctly set up. RUN BASH_HEADER='#!/bin/bash' && \. for script in make_examples call_variants call_variants_slim postprocess_variants vcf_stats_report show_examples runtime_by_region_vis multisample_make_examples labeled_examples_to_vcf make_examples_somatic train run_deepvariant run_deepsomatic; do \. printf ""%s\n%s\n"" ""${BASH_HEADER}"" ""python3 /opt/deepvariant/bin/${script}.zip \""$@\"""" > /opt/deepvariant/bin/${script} && \. chmod +x /opt/deepvariant/bin/${script}; \. done. # Copy licenses and other necessary files. # Ensure these paths and URLs are correct and accessible. # Replace with valid URLs or remove if not needed. ADD https://storage.googleapis.com/deepvariant/models/DeepVariant/1.6.0/savedmodels/deepvariant.hybrid.savedmodel/saved_model.pb /models/. WORKDIR /opt/deepvariant/bin/. COPY --from=builder /opt/conda /opt/conda. COPY --from=builder /opt/deepvariant/run-prereq.sh . COPY --from=builder /opt/deepvariant/settings.sh . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/make_examples.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/call_variants.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/call_variants_slim.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/postprocess_variants.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/vcf_stats_report.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/show_examples.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/runtime_by_region_vis.zip",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/871
https://github.com/google/deepvariant/issues/871:4990,safety,updat,update-alternatives,4990,"ariant/bazel-out/k8-opt/bin/deepvariant/call_variants_slim.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/postprocess_variants.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/vcf_stats_report.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/show_examples.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/runtime_by_region_vis.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/multisample_make_examples.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/labeler/labeled_examples_to_vcf.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/make_examples_somatic.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/train.zip . COPY --from=builder /opt/deepvariant/scripts/run_deepvariant.py . COPY --from=builder /opt/deepvariant/scripts/run_deepsomatic.py . RUN ./run-prereq.sh. RUN update-alternatives --install /usr/bin/python3 python3 /usr/bin/python${PYTHON_VERSION} 0 && \. 	update-alternatives --install /usr/bin/python python /usr/bin/python${PYTHON_VERSION} 0. # Create shell wrappers for python zip files for easier use. RUN \. BASH_HEADER='#!/bin/bash' && \. printf ""%s\n%s\n"" \. 	""${BASH_HEADER}"" \. 	'python3 /opt/deepvariant/bin/make_examples.zip ""$@""' > \. 	/opt/deepvariant/bin/make_examples && \. printf ""%s\n%s\n"" \. 	""${BASH_HEADER}"" \. 	'python3 /opt/deepvariant/bin/call_variants.zip ""$@""' > \. 	/opt/deepvariant/bin/call_variants && \. printf ""%s\n%s\n"" \. 	""${BASH_HEADER}"" \. 	'python3 /opt/deepvariant/bin/call_variants_slim.zip ""$@""' > \. 	/opt/deepvariant/bin/call_variants_slim && \. printf ""%s\n%s\n"" \. 	""${BASH_HEADER}"" \. 	'python3 /opt/deepvariant/bin/postprocess_variants.zip ""$@""' > \. 	/opt/deepvariant/bin/postprocess_variants && \. printf ""%s\n%s\n"" \. 	""${BASH_HEADER}"" \. 	'python3 /opt/deepvariant/bin/vcf_stats_report.zip ""$@""' > \. 	/opt/deepvariant/b",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/871
https://github.com/google/deepvariant/issues/871:5087,safety,updat,update-alternatives,5087,"iant/bazel-out/k8-opt/bin/deepvariant/postprocess_variants.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/vcf_stats_report.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/show_examples.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/runtime_by_region_vis.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/multisample_make_examples.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/labeler/labeled_examples_to_vcf.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/make_examples_somatic.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/train.zip . COPY --from=builder /opt/deepvariant/scripts/run_deepvariant.py . COPY --from=builder /opt/deepvariant/scripts/run_deepsomatic.py . RUN ./run-prereq.sh. RUN update-alternatives --install /usr/bin/python3 python3 /usr/bin/python${PYTHON_VERSION} 0 && \. 	update-alternatives --install /usr/bin/python python /usr/bin/python${PYTHON_VERSION} 0. # Create shell wrappers for python zip files for easier use. RUN \. BASH_HEADER='#!/bin/bash' && \. printf ""%s\n%s\n"" \. 	""${BASH_HEADER}"" \. 	'python3 /opt/deepvariant/bin/make_examples.zip ""$@""' > \. 	/opt/deepvariant/bin/make_examples && \. printf ""%s\n%s\n"" \. 	""${BASH_HEADER}"" \. 	'python3 /opt/deepvariant/bin/call_variants.zip ""$@""' > \. 	/opt/deepvariant/bin/call_variants && \. printf ""%s\n%s\n"" \. 	""${BASH_HEADER}"" \. 	'python3 /opt/deepvariant/bin/call_variants_slim.zip ""$@""' > \. 	/opt/deepvariant/bin/call_variants_slim && \. printf ""%s\n%s\n"" \. 	""${BASH_HEADER}"" \. 	'python3 /opt/deepvariant/bin/postprocess_variants.zip ""$@""' > \. 	/opt/deepvariant/bin/postprocess_variants && \. printf ""%s\n%s\n"" \. 	""${BASH_HEADER}"" \. 	'python3 /opt/deepvariant/bin/vcf_stats_report.zip ""$@""' > \. 	/opt/deepvariant/bin/vcf_stats_report && \. printf ""%s\n%s\n"" \. 	""${BASH_HEADER}"" \. 	'python3 /opt/deepvariant/bi",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/871
https://github.com/google/deepvariant/issues/871:418,security,Model,Model,418,"Troubleshooting Dockerfile for DeepVariant on Mac M1: Issues with Bazel ; Im new to working with computers tools like DeepVariant. Im trying to build DeepVariant using Docker on a Mac M1 and am encountering issues with the Dockerfile during the Bazel build process. I want to ensure compatibility with ARM64 architecture. **Docker version**: Docker version 27.1.1, build 6312585. **Bazel Version**: 7.3.1. **MacBook Model**: M1 chip (ARM64 architecture). **Error**: . ![IMG_3267](https://github.com/user-attachments/assets/11e28824-b941-42cc-9d33-7e9155a03543). ![IMG_3268](https://github.com/user-attachments/assets/4e923de6-99d5-43ee-80c6-29b32504527d). **My Dockerfilee code**:. ```. # Base image suitable for ARM64 architecture. FROM arm64v8/ubuntu:latest AS base. # Prevent interactive prompts. ENV DEBIAN_FRONTEND=noninteractive. # Install necessary packages. RUN apt-get update && \. apt-get install -y \. git \. curl \. unzip \. wget \. openjdk-17-jdk \. build-essential \. bzip2 \. python3-pip \. parallel && \. apt-get clean && \. rm -rf /var/lib/apt/lists/*. # Install Bazel (adjust version as needed). RUN curl -LO ""https://github.com/bazelbuild/bazel/releases/download/7.3.1/bazel-7.3.1-linux-arm64"" && \. chmod +x bazel-7.3.1-linux-arm64 && \. mv bazel-7.3.1-linux-arm64 /usr/local/bin/bazel. # Install Conda. RUN curl -LO ""https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-aarch64.sh"" && \. bash Miniconda3-latest-Linux-aarch64.sh -b -p /opt/miniconda && \. rm Miniconda3-latest-Linux-aarch64.sh. # Setup Conda environment. ENV PATH=""/opt/miniconda/bin:${PATH}"". RUN conda config --add channels defaults && \. conda config --add channels bioconda && \. conda config --add channels conda-forge && \. conda create -n bio bioconda::bcftools bioconda::samtools -y && \. conda clean -a. # Clone DeepVariant and build. FROM base AS builder. # Clone the DeepVariant repository. RUN git clone https://github.com/google/deepvariant.git /opt/deepvariant && \. cd /opt/deepvariant && ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/871
https://github.com/google/deepvariant/issues/871:773,security,Preven,Prevent,773,"Troubleshooting Dockerfile for DeepVariant on Mac M1: Issues with Bazel ; Im new to working with computers tools like DeepVariant. Im trying to build DeepVariant using Docker on a Mac M1 and am encountering issues with the Dockerfile during the Bazel build process. I want to ensure compatibility with ARM64 architecture. **Docker version**: Docker version 27.1.1, build 6312585. **Bazel Version**: 7.3.1. **MacBook Model**: M1 chip (ARM64 architecture). **Error**: . ![IMG_3267](https://github.com/user-attachments/assets/11e28824-b941-42cc-9d33-7e9155a03543). ![IMG_3268](https://github.com/user-attachments/assets/4e923de6-99d5-43ee-80c6-29b32504527d). **My Dockerfilee code**:. ```. # Base image suitable for ARM64 architecture. FROM arm64v8/ubuntu:latest AS base. # Prevent interactive prompts. ENV DEBIAN_FRONTEND=noninteractive. # Install necessary packages. RUN apt-get update && \. apt-get install -y \. git \. curl \. unzip \. wget \. openjdk-17-jdk \. build-essential \. bzip2 \. python3-pip \. parallel && \. apt-get clean && \. rm -rf /var/lib/apt/lists/*. # Install Bazel (adjust version as needed). RUN curl -LO ""https://github.com/bazelbuild/bazel/releases/download/7.3.1/bazel-7.3.1-linux-arm64"" && \. chmod +x bazel-7.3.1-linux-arm64 && \. mv bazel-7.3.1-linux-arm64 /usr/local/bin/bazel. # Install Conda. RUN curl -LO ""https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-aarch64.sh"" && \. bash Miniconda3-latest-Linux-aarch64.sh -b -p /opt/miniconda && \. rm Miniconda3-latest-Linux-aarch64.sh. # Setup Conda environment. ENV PATH=""/opt/miniconda/bin:${PATH}"". RUN conda config --add channels defaults && \. conda config --add channels bioconda && \. conda config --add channels conda-forge && \. conda create -n bio bioconda::bcftools bioconda::samtools -y && \. conda clean -a. # Clone DeepVariant and build. FROM base AS builder. # Clone the DeepVariant repository. RUN git clone https://github.com/google/deepvariant.git /opt/deepvariant && \. cd /opt/deepvariant && ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/871
https://github.com/google/deepvariant/issues/871:872,security,apt,apt-get,872,"Troubleshooting Dockerfile for DeepVariant on Mac M1: Issues with Bazel ; Im new to working with computers tools like DeepVariant. Im trying to build DeepVariant using Docker on a Mac M1 and am encountering issues with the Dockerfile during the Bazel build process. I want to ensure compatibility with ARM64 architecture. **Docker version**: Docker version 27.1.1, build 6312585. **Bazel Version**: 7.3.1. **MacBook Model**: M1 chip (ARM64 architecture). **Error**: . ![IMG_3267](https://github.com/user-attachments/assets/11e28824-b941-42cc-9d33-7e9155a03543). ![IMG_3268](https://github.com/user-attachments/assets/4e923de6-99d5-43ee-80c6-29b32504527d). **My Dockerfilee code**:. ```. # Base image suitable for ARM64 architecture. FROM arm64v8/ubuntu:latest AS base. # Prevent interactive prompts. ENV DEBIAN_FRONTEND=noninteractive. # Install necessary packages. RUN apt-get update && \. apt-get install -y \. git \. curl \. unzip \. wget \. openjdk-17-jdk \. build-essential \. bzip2 \. python3-pip \. parallel && \. apt-get clean && \. rm -rf /var/lib/apt/lists/*. # Install Bazel (adjust version as needed). RUN curl -LO ""https://github.com/bazelbuild/bazel/releases/download/7.3.1/bazel-7.3.1-linux-arm64"" && \. chmod +x bazel-7.3.1-linux-arm64 && \. mv bazel-7.3.1-linux-arm64 /usr/local/bin/bazel. # Install Conda. RUN curl -LO ""https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-aarch64.sh"" && \. bash Miniconda3-latest-Linux-aarch64.sh -b -p /opt/miniconda && \. rm Miniconda3-latest-Linux-aarch64.sh. # Setup Conda environment. ENV PATH=""/opt/miniconda/bin:${PATH}"". RUN conda config --add channels defaults && \. conda config --add channels bioconda && \. conda config --add channels conda-forge && \. conda create -n bio bioconda::bcftools bioconda::samtools -y && \. conda clean -a. # Clone DeepVariant and build. FROM base AS builder. # Clone the DeepVariant repository. RUN git clone https://github.com/google/deepvariant.git /opt/deepvariant && \. cd /opt/deepvariant && ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/871
https://github.com/google/deepvariant/issues/871:880,security,updat,update,880,"Troubleshooting Dockerfile for DeepVariant on Mac M1: Issues with Bazel ; Im new to working with computers tools like DeepVariant. Im trying to build DeepVariant using Docker on a Mac M1 and am encountering issues with the Dockerfile during the Bazel build process. I want to ensure compatibility with ARM64 architecture. **Docker version**: Docker version 27.1.1, build 6312585. **Bazel Version**: 7.3.1. **MacBook Model**: M1 chip (ARM64 architecture). **Error**: . ![IMG_3267](https://github.com/user-attachments/assets/11e28824-b941-42cc-9d33-7e9155a03543). ![IMG_3268](https://github.com/user-attachments/assets/4e923de6-99d5-43ee-80c6-29b32504527d). **My Dockerfilee code**:. ```. # Base image suitable for ARM64 architecture. FROM arm64v8/ubuntu:latest AS base. # Prevent interactive prompts. ENV DEBIAN_FRONTEND=noninteractive. # Install necessary packages. RUN apt-get update && \. apt-get install -y \. git \. curl \. unzip \. wget \. openjdk-17-jdk \. build-essential \. bzip2 \. python3-pip \. parallel && \. apt-get clean && \. rm -rf /var/lib/apt/lists/*. # Install Bazel (adjust version as needed). RUN curl -LO ""https://github.com/bazelbuild/bazel/releases/download/7.3.1/bazel-7.3.1-linux-arm64"" && \. chmod +x bazel-7.3.1-linux-arm64 && \. mv bazel-7.3.1-linux-arm64 /usr/local/bin/bazel. # Install Conda. RUN curl -LO ""https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-aarch64.sh"" && \. bash Miniconda3-latest-Linux-aarch64.sh -b -p /opt/miniconda && \. rm Miniconda3-latest-Linux-aarch64.sh. # Setup Conda environment. ENV PATH=""/opt/miniconda/bin:${PATH}"". RUN conda config --add channels defaults && \. conda config --add channels bioconda && \. conda config --add channels conda-forge && \. conda create -n bio bioconda::bcftools bioconda::samtools -y && \. conda clean -a. # Clone DeepVariant and build. FROM base AS builder. # Clone the DeepVariant repository. RUN git clone https://github.com/google/deepvariant.git /opt/deepvariant && \. cd /opt/deepvariant && ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/871
https://github.com/google/deepvariant/issues/871:893,security,apt,apt-get,893,"Troubleshooting Dockerfile for DeepVariant on Mac M1: Issues with Bazel ; Im new to working with computers tools like DeepVariant. Im trying to build DeepVariant using Docker on a Mac M1 and am encountering issues with the Dockerfile during the Bazel build process. I want to ensure compatibility with ARM64 architecture. **Docker version**: Docker version 27.1.1, build 6312585. **Bazel Version**: 7.3.1. **MacBook Model**: M1 chip (ARM64 architecture). **Error**: . ![IMG_3267](https://github.com/user-attachments/assets/11e28824-b941-42cc-9d33-7e9155a03543). ![IMG_3268](https://github.com/user-attachments/assets/4e923de6-99d5-43ee-80c6-29b32504527d). **My Dockerfilee code**:. ```. # Base image suitable for ARM64 architecture. FROM arm64v8/ubuntu:latest AS base. # Prevent interactive prompts. ENV DEBIAN_FRONTEND=noninteractive. # Install necessary packages. RUN apt-get update && \. apt-get install -y \. git \. curl \. unzip \. wget \. openjdk-17-jdk \. build-essential \. bzip2 \. python3-pip \. parallel && \. apt-get clean && \. rm -rf /var/lib/apt/lists/*. # Install Bazel (adjust version as needed). RUN curl -LO ""https://github.com/bazelbuild/bazel/releases/download/7.3.1/bazel-7.3.1-linux-arm64"" && \. chmod +x bazel-7.3.1-linux-arm64 && \. mv bazel-7.3.1-linux-arm64 /usr/local/bin/bazel. # Install Conda. RUN curl -LO ""https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-aarch64.sh"" && \. bash Miniconda3-latest-Linux-aarch64.sh -b -p /opt/miniconda && \. rm Miniconda3-latest-Linux-aarch64.sh. # Setup Conda environment. ENV PATH=""/opt/miniconda/bin:${PATH}"". RUN conda config --add channels defaults && \. conda config --add channels bioconda && \. conda config --add channels conda-forge && \. conda create -n bio bioconda::bcftools bioconda::samtools -y && \. conda clean -a. # Clone DeepVariant and build. FROM base AS builder. # Clone the DeepVariant repository. RUN git clone https://github.com/google/deepvariant.git /opt/deepvariant && \. cd /opt/deepvariant && ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/871
https://github.com/google/deepvariant/issues/871:1023,security,apt,apt-get,1023,"for DeepVariant on Mac M1: Issues with Bazel ; Im new to working with computers tools like DeepVariant. Im trying to build DeepVariant using Docker on a Mac M1 and am encountering issues with the Dockerfile during the Bazel build process. I want to ensure compatibility with ARM64 architecture. **Docker version**: Docker version 27.1.1, build 6312585. **Bazel Version**: 7.3.1. **MacBook Model**: M1 chip (ARM64 architecture). **Error**: . ![IMG_3267](https://github.com/user-attachments/assets/11e28824-b941-42cc-9d33-7e9155a03543). ![IMG_3268](https://github.com/user-attachments/assets/4e923de6-99d5-43ee-80c6-29b32504527d). **My Dockerfilee code**:. ```. # Base image suitable for ARM64 architecture. FROM arm64v8/ubuntu:latest AS base. # Prevent interactive prompts. ENV DEBIAN_FRONTEND=noninteractive. # Install necessary packages. RUN apt-get update && \. apt-get install -y \. git \. curl \. unzip \. wget \. openjdk-17-jdk \. build-essential \. bzip2 \. python3-pip \. parallel && \. apt-get clean && \. rm -rf /var/lib/apt/lists/*. # Install Bazel (adjust version as needed). RUN curl -LO ""https://github.com/bazelbuild/bazel/releases/download/7.3.1/bazel-7.3.1-linux-arm64"" && \. chmod +x bazel-7.3.1-linux-arm64 && \. mv bazel-7.3.1-linux-arm64 /usr/local/bin/bazel. # Install Conda. RUN curl -LO ""https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-aarch64.sh"" && \. bash Miniconda3-latest-Linux-aarch64.sh -b -p /opt/miniconda && \. rm Miniconda3-latest-Linux-aarch64.sh. # Setup Conda environment. ENV PATH=""/opt/miniconda/bin:${PATH}"". RUN conda config --add channels defaults && \. conda config --add channels bioconda && \. conda config --add channels conda-forge && \. conda create -n bio bioconda::bcftools bioconda::samtools -y && \. conda clean -a. # Clone DeepVariant and build. FROM base AS builder. # Clone the DeepVariant repository. RUN git clone https://github.com/google/deepvariant.git /opt/deepvariant && \. cd /opt/deepvariant && \. git checkout tags/v1.6.1",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/871
https://github.com/google/deepvariant/issues/871:1059,security,apt,apt,1059,"with Bazel ; Im new to working with computers tools like DeepVariant. Im trying to build DeepVariant using Docker on a Mac M1 and am encountering issues with the Dockerfile during the Bazel build process. I want to ensure compatibility with ARM64 architecture. **Docker version**: Docker version 27.1.1, build 6312585. **Bazel Version**: 7.3.1. **MacBook Model**: M1 chip (ARM64 architecture). **Error**: . ![IMG_3267](https://github.com/user-attachments/assets/11e28824-b941-42cc-9d33-7e9155a03543). ![IMG_3268](https://github.com/user-attachments/assets/4e923de6-99d5-43ee-80c6-29b32504527d). **My Dockerfilee code**:. ```. # Base image suitable for ARM64 architecture. FROM arm64v8/ubuntu:latest AS base. # Prevent interactive prompts. ENV DEBIAN_FRONTEND=noninteractive. # Install necessary packages. RUN apt-get update && \. apt-get install -y \. git \. curl \. unzip \. wget \. openjdk-17-jdk \. build-essential \. bzip2 \. python3-pip \. parallel && \. apt-get clean && \. rm -rf /var/lib/apt/lists/*. # Install Bazel (adjust version as needed). RUN curl -LO ""https://github.com/bazelbuild/bazel/releases/download/7.3.1/bazel-7.3.1-linux-arm64"" && \. chmod +x bazel-7.3.1-linux-arm64 && \. mv bazel-7.3.1-linux-arm64 /usr/local/bin/bazel. # Install Conda. RUN curl -LO ""https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-aarch64.sh"" && \. bash Miniconda3-latest-Linux-aarch64.sh -b -p /opt/miniconda && \. rm Miniconda3-latest-Linux-aarch64.sh. # Setup Conda environment. ENV PATH=""/opt/miniconda/bin:${PATH}"". RUN conda config --add channels defaults && \. conda config --add channels bioconda && \. conda config --add channels conda-forge && \. conda create -n bio bioconda::bcftools bioconda::samtools -y && \. conda clean -a. # Clone DeepVariant and build. FROM base AS builder. # Clone the DeepVariant repository. RUN git clone https://github.com/google/deepvariant.git /opt/deepvariant && \. cd /opt/deepvariant && \. git checkout tags/v1.6.1. # Run Bazel build with additiona",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/871
https://github.com/google/deepvariant/issues/871:2089,security,configur,configurations,2089,"version as needed). RUN curl -LO ""https://github.com/bazelbuild/bazel/releases/download/7.3.1/bazel-7.3.1-linux-arm64"" && \. chmod +x bazel-7.3.1-linux-arm64 && \. mv bazel-7.3.1-linux-arm64 /usr/local/bin/bazel. # Install Conda. RUN curl -LO ""https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-aarch64.sh"" && \. bash Miniconda3-latest-Linux-aarch64.sh -b -p /opt/miniconda && \. rm Miniconda3-latest-Linux-aarch64.sh. # Setup Conda environment. ENV PATH=""/opt/miniconda/bin:${PATH}"". RUN conda config --add channels defaults && \. conda config --add channels bioconda && \. conda config --add channels conda-forge && \. conda create -n bio bioconda::bcftools bioconda::samtools -y && \. conda clean -a. # Clone DeepVariant and build. FROM base AS builder. # Clone the DeepVariant repository. RUN git clone https://github.com/google/deepvariant.git /opt/deepvariant && \. cd /opt/deepvariant && \. git checkout tags/v1.6.1. # Run Bazel build with additional flags to skip problematic configurations. RUN bazel build -c opt --noincremental --experimental_action_listener= //deepvariant:make_examples //deepvariant:call_variants //deepvariant:postprocess_variants || { \. echo ""Bazel build failed""; \. exit 1; }. # Final image. FROM base AS final. # Set environment variables. ENV VERSION=1.6.0. ENV PYTHON_VERSION=3.8. ENV PATH=""/opt/miniconda/bin:${PATH}"". # Install Python packages. RUN pip install --upgrade pip setuptools wheel --timeout=120 && \. pip install jaxlib jax --timeout=120 --extra-index-url https://storage.googleapis.com/jax-releases/jax_releases.html. # Copy DeepVariant binaries from the builder stage. COPY --from=builder /opt/deepvariant /opt/deepvariant. WORKDIR /opt/deepvariant. # Ensure executable scripts are correctly set up. RUN BASH_HEADER='#!/bin/bash' && \. for script in make_examples call_variants call_variants_slim postprocess_variants vcf_stats_report show_examples runtime_by_region_vis multisample_make_examples labeled_examples_to_vcf make_examples_soma",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/871
https://github.com/google/deepvariant/issues/871:3410,security,access,accessible,3410,"ON=3.8. ENV PATH=""/opt/miniconda/bin:${PATH}"". # Install Python packages. RUN pip install --upgrade pip setuptools wheel --timeout=120 && \. pip install jaxlib jax --timeout=120 --extra-index-url https://storage.googleapis.com/jax-releases/jax_releases.html. # Copy DeepVariant binaries from the builder stage. COPY --from=builder /opt/deepvariant /opt/deepvariant. WORKDIR /opt/deepvariant. # Ensure executable scripts are correctly set up. RUN BASH_HEADER='#!/bin/bash' && \. for script in make_examples call_variants call_variants_slim postprocess_variants vcf_stats_report show_examples runtime_by_region_vis multisample_make_examples labeled_examples_to_vcf make_examples_somatic train run_deepvariant run_deepsomatic; do \. printf ""%s\n%s\n"" ""${BASH_HEADER}"" ""python3 /opt/deepvariant/bin/${script}.zip \""$@\"""" > /opt/deepvariant/bin/${script} && \. chmod +x /opt/deepvariant/bin/${script}; \. done. # Copy licenses and other necessary files. # Ensure these paths and URLs are correct and accessible. # Replace with valid URLs or remove if not needed. ADD https://storage.googleapis.com/deepvariant/models/DeepVariant/1.6.0/savedmodels/deepvariant.hybrid.savedmodel/saved_model.pb /models/. WORKDIR /opt/deepvariant/bin/. COPY --from=builder /opt/conda /opt/conda. COPY --from=builder /opt/deepvariant/run-prereq.sh . COPY --from=builder /opt/deepvariant/settings.sh . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/make_examples.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/call_variants.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/call_variants_slim.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/postprocess_variants.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/vcf_stats_report.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/show_examples.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/871
https://github.com/google/deepvariant/issues/871:3520,security,model,models,3520,"ptools wheel --timeout=120 && \. pip install jaxlib jax --timeout=120 --extra-index-url https://storage.googleapis.com/jax-releases/jax_releases.html. # Copy DeepVariant binaries from the builder stage. COPY --from=builder /opt/deepvariant /opt/deepvariant. WORKDIR /opt/deepvariant. # Ensure executable scripts are correctly set up. RUN BASH_HEADER='#!/bin/bash' && \. for script in make_examples call_variants call_variants_slim postprocess_variants vcf_stats_report show_examples runtime_by_region_vis multisample_make_examples labeled_examples_to_vcf make_examples_somatic train run_deepvariant run_deepsomatic; do \. printf ""%s\n%s\n"" ""${BASH_HEADER}"" ""python3 /opt/deepvariant/bin/${script}.zip \""$@\"""" > /opt/deepvariant/bin/${script} && \. chmod +x /opt/deepvariant/bin/${script}; \. done. # Copy licenses and other necessary files. # Ensure these paths and URLs are correct and accessible. # Replace with valid URLs or remove if not needed. ADD https://storage.googleapis.com/deepvariant/models/DeepVariant/1.6.0/savedmodels/deepvariant.hybrid.savedmodel/saved_model.pb /models/. WORKDIR /opt/deepvariant/bin/. COPY --from=builder /opt/conda /opt/conda. COPY --from=builder /opt/deepvariant/run-prereq.sh . COPY --from=builder /opt/deepvariant/settings.sh . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/make_examples.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/call_variants.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/call_variants_slim.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/postprocess_variants.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/vcf_stats_report.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/show_examples.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/runtime_by_region_vis.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/multisampl",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/871
https://github.com/google/deepvariant/issues/871:3603,security,model,models,3603,"-url https://storage.googleapis.com/jax-releases/jax_releases.html. # Copy DeepVariant binaries from the builder stage. COPY --from=builder /opt/deepvariant /opt/deepvariant. WORKDIR /opt/deepvariant. # Ensure executable scripts are correctly set up. RUN BASH_HEADER='#!/bin/bash' && \. for script in make_examples call_variants call_variants_slim postprocess_variants vcf_stats_report show_examples runtime_by_region_vis multisample_make_examples labeled_examples_to_vcf make_examples_somatic train run_deepvariant run_deepsomatic; do \. printf ""%s\n%s\n"" ""${BASH_HEADER}"" ""python3 /opt/deepvariant/bin/${script}.zip \""$@\"""" > /opt/deepvariant/bin/${script} && \. chmod +x /opt/deepvariant/bin/${script}; \. done. # Copy licenses and other necessary files. # Ensure these paths and URLs are correct and accessible. # Replace with valid URLs or remove if not needed. ADD https://storage.googleapis.com/deepvariant/models/DeepVariant/1.6.0/savedmodels/deepvariant.hybrid.savedmodel/saved_model.pb /models/. WORKDIR /opt/deepvariant/bin/. COPY --from=builder /opt/conda /opt/conda. COPY --from=builder /opt/deepvariant/run-prereq.sh . COPY --from=builder /opt/deepvariant/settings.sh . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/make_examples.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/call_variants.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/call_variants_slim.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/postprocess_variants.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/vcf_stats_report.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/show_examples.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/runtime_by_region_vis.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/multisample_make_examples.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/dee",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/871
https://github.com/google/deepvariant/issues/871:4990,security,updat,update-alternatives,4990,"ariant/bazel-out/k8-opt/bin/deepvariant/call_variants_slim.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/postprocess_variants.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/vcf_stats_report.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/show_examples.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/runtime_by_region_vis.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/multisample_make_examples.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/labeler/labeled_examples_to_vcf.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/make_examples_somatic.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/train.zip . COPY --from=builder /opt/deepvariant/scripts/run_deepvariant.py . COPY --from=builder /opt/deepvariant/scripts/run_deepsomatic.py . RUN ./run-prereq.sh. RUN update-alternatives --install /usr/bin/python3 python3 /usr/bin/python${PYTHON_VERSION} 0 && \. 	update-alternatives --install /usr/bin/python python /usr/bin/python${PYTHON_VERSION} 0. # Create shell wrappers for python zip files for easier use. RUN \. BASH_HEADER='#!/bin/bash' && \. printf ""%s\n%s\n"" \. 	""${BASH_HEADER}"" \. 	'python3 /opt/deepvariant/bin/make_examples.zip ""$@""' > \. 	/opt/deepvariant/bin/make_examples && \. printf ""%s\n%s\n"" \. 	""${BASH_HEADER}"" \. 	'python3 /opt/deepvariant/bin/call_variants.zip ""$@""' > \. 	/opt/deepvariant/bin/call_variants && \. printf ""%s\n%s\n"" \. 	""${BASH_HEADER}"" \. 	'python3 /opt/deepvariant/bin/call_variants_slim.zip ""$@""' > \. 	/opt/deepvariant/bin/call_variants_slim && \. printf ""%s\n%s\n"" \. 	""${BASH_HEADER}"" \. 	'python3 /opt/deepvariant/bin/postprocess_variants.zip ""$@""' > \. 	/opt/deepvariant/bin/postprocess_variants && \. printf ""%s\n%s\n"" \. 	""${BASH_HEADER}"" \. 	'python3 /opt/deepvariant/bin/vcf_stats_report.zip ""$@""' > \. 	/opt/deepvariant/b",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/871
https://github.com/google/deepvariant/issues/871:5087,security,updat,update-alternatives,5087,"iant/bazel-out/k8-opt/bin/deepvariant/postprocess_variants.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/vcf_stats_report.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/show_examples.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/runtime_by_region_vis.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/multisample_make_examples.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/labeler/labeled_examples_to_vcf.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/make_examples_somatic.zip . COPY --from=builder /opt/deepvariant/bazel-out/k8-opt/bin/deepvariant/train.zip . COPY --from=builder /opt/deepvariant/scripts/run_deepvariant.py . COPY --from=builder /opt/deepvariant/scripts/run_deepsomatic.py . RUN ./run-prereq.sh. RUN update-alternatives --install /usr/bin/python3 python3 /usr/bin/python${PYTHON_VERSION} 0 && \. 	update-alternatives --install /usr/bin/python python /usr/bin/python${PYTHON_VERSION} 0. # Create shell wrappers for python zip files for easier use. RUN \. BASH_HEADER='#!/bin/bash' && \. printf ""%s\n%s\n"" \. 	""${BASH_HEADER}"" \. 	'python3 /opt/deepvariant/bin/make_examples.zip ""$@""' > \. 	/opt/deepvariant/bin/make_examples && \. printf ""%s\n%s\n"" \. 	""${BASH_HEADER}"" \. 	'python3 /opt/deepvariant/bin/call_variants.zip ""$@""' > \. 	/opt/deepvariant/bin/call_variants && \. printf ""%s\n%s\n"" \. 	""${BASH_HEADER}"" \. 	'python3 /opt/deepvariant/bin/call_variants_slim.zip ""$@""' > \. 	/opt/deepvariant/bin/call_variants_slim && \. printf ""%s\n%s\n"" \. 	""${BASH_HEADER}"" \. 	'python3 /opt/deepvariant/bin/postprocess_variants.zip ""$@""' > \. 	/opt/deepvariant/bin/postprocess_variants && \. printf ""%s\n%s\n"" \. 	""${BASH_HEADER}"" \. 	'python3 /opt/deepvariant/bin/vcf_stats_report.zip ""$@""' > \. 	/opt/deepvariant/bin/vcf_stats_report && \. printf ""%s\n%s\n"" \. 	""${BASH_HEADER}"" \. 	'python3 /opt/deepvariant/bi",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/871
https://github.com/google/deepvariant/issues/871:108,usability,tool,tools,108,"Troubleshooting Dockerfile for DeepVariant on Mac M1: Issues with Bazel ; Im new to working with computers tools like DeepVariant. Im trying to build DeepVariant using Docker on a Mac M1 and am encountering issues with the Dockerfile during the Bazel build process. I want to ensure compatibility with ARM64 architecture. **Docker version**: Docker version 27.1.1, build 6312585. **Bazel Version**: 7.3.1. **MacBook Model**: M1 chip (ARM64 architecture). **Error**: . ![IMG_3267](https://github.com/user-attachments/assets/11e28824-b941-42cc-9d33-7e9155a03543). ![IMG_3268](https://github.com/user-attachments/assets/4e923de6-99d5-43ee-80c6-29b32504527d). **My Dockerfilee code**:. ```. # Base image suitable for ARM64 architecture. FROM arm64v8/ubuntu:latest AS base. # Prevent interactive prompts. ENV DEBIAN_FRONTEND=noninteractive. # Install necessary packages. RUN apt-get update && \. apt-get install -y \. git \. curl \. unzip \. wget \. openjdk-17-jdk \. build-essential \. bzip2 \. python3-pip \. parallel && \. apt-get clean && \. rm -rf /var/lib/apt/lists/*. # Install Bazel (adjust version as needed). RUN curl -LO ""https://github.com/bazelbuild/bazel/releases/download/7.3.1/bazel-7.3.1-linux-arm64"" && \. chmod +x bazel-7.3.1-linux-arm64 && \. mv bazel-7.3.1-linux-arm64 /usr/local/bin/bazel. # Install Conda. RUN curl -LO ""https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-aarch64.sh"" && \. bash Miniconda3-latest-Linux-aarch64.sh -b -p /opt/miniconda && \. rm Miniconda3-latest-Linux-aarch64.sh. # Setup Conda environment. ENV PATH=""/opt/miniconda/bin:${PATH}"". RUN conda config --add channels defaults && \. conda config --add channels bioconda && \. conda config --add channels conda-forge && \. conda create -n bio bioconda::bcftools bioconda::samtools -y && \. conda clean -a. # Clone DeepVariant and build. FROM base AS builder. # Clone the DeepVariant repository. RUN git clone https://github.com/google/deepvariant.git /opt/deepvariant && \. cd /opt/deepvariant && ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/871
https://github.com/google/deepvariant/issues/871:459,usability,Error,Error,459,"Troubleshooting Dockerfile for DeepVariant on Mac M1: Issues with Bazel ; Im new to working with computers tools like DeepVariant. Im trying to build DeepVariant using Docker on a Mac M1 and am encountering issues with the Dockerfile during the Bazel build process. I want to ensure compatibility with ARM64 architecture. **Docker version**: Docker version 27.1.1, build 6312585. **Bazel Version**: 7.3.1. **MacBook Model**: M1 chip (ARM64 architecture). **Error**: . ![IMG_3267](https://github.com/user-attachments/assets/11e28824-b941-42cc-9d33-7e9155a03543). ![IMG_3268](https://github.com/user-attachments/assets/4e923de6-99d5-43ee-80c6-29b32504527d). **My Dockerfilee code**:. ```. # Base image suitable for ARM64 architecture. FROM arm64v8/ubuntu:latest AS base. # Prevent interactive prompts. ENV DEBIAN_FRONTEND=noninteractive. # Install necessary packages. RUN apt-get update && \. apt-get install -y \. git \. curl \. unzip \. wget \. openjdk-17-jdk \. build-essential \. bzip2 \. python3-pip \. parallel && \. apt-get clean && \. rm -rf /var/lib/apt/lists/*. # Install Bazel (adjust version as needed). RUN curl -LO ""https://github.com/bazelbuild/bazel/releases/download/7.3.1/bazel-7.3.1-linux-arm64"" && \. chmod +x bazel-7.3.1-linux-arm64 && \. mv bazel-7.3.1-linux-arm64 /usr/local/bin/bazel. # Install Conda. RUN curl -LO ""https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-aarch64.sh"" && \. bash Miniconda3-latest-Linux-aarch64.sh -b -p /opt/miniconda && \. rm Miniconda3-latest-Linux-aarch64.sh. # Setup Conda environment. ENV PATH=""/opt/miniconda/bin:${PATH}"". RUN conda config --add channels defaults && \. conda config --add channels bioconda && \. conda config --add channels conda-forge && \. conda create -n bio bioconda::bcftools bioconda::samtools -y && \. conda clean -a. # Clone DeepVariant and build. FROM base AS builder. # Clone the DeepVariant repository. RUN git clone https://github.com/google/deepvariant.git /opt/deepvariant && \. cd /opt/deepvariant && ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/871
https://github.com/google/deepvariant/issues/871:501,usability,user,user-attachments,501,"Troubleshooting Dockerfile for DeepVariant on Mac M1: Issues with Bazel ; Im new to working with computers tools like DeepVariant. Im trying to build DeepVariant using Docker on a Mac M1 and am encountering issues with the Dockerfile during the Bazel build process. I want to ensure compatibility with ARM64 architecture. **Docker version**: Docker version 27.1.1, build 6312585. **Bazel Version**: 7.3.1. **MacBook Model**: M1 chip (ARM64 architecture). **Error**: . ![IMG_3267](https://github.com/user-attachments/assets/11e28824-b941-42cc-9d33-7e9155a03543). ![IMG_3268](https://github.com/user-attachments/assets/4e923de6-99d5-43ee-80c6-29b32504527d). **My Dockerfilee code**:. ```. # Base image suitable for ARM64 architecture. FROM arm64v8/ubuntu:latest AS base. # Prevent interactive prompts. ENV DEBIAN_FRONTEND=noninteractive. # Install necessary packages. RUN apt-get update && \. apt-get install -y \. git \. curl \. unzip \. wget \. openjdk-17-jdk \. build-essential \. bzip2 \. python3-pip \. parallel && \. apt-get clean && \. rm -rf /var/lib/apt/lists/*. # Install Bazel (adjust version as needed). RUN curl -LO ""https://github.com/bazelbuild/bazel/releases/download/7.3.1/bazel-7.3.1-linux-arm64"" && \. chmod +x bazel-7.3.1-linux-arm64 && \. mv bazel-7.3.1-linux-arm64 /usr/local/bin/bazel. # Install Conda. RUN curl -LO ""https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-aarch64.sh"" && \. bash Miniconda3-latest-Linux-aarch64.sh -b -p /opt/miniconda && \. rm Miniconda3-latest-Linux-aarch64.sh. # Setup Conda environment. ENV PATH=""/opt/miniconda/bin:${PATH}"". RUN conda config --add channels defaults && \. conda config --add channels bioconda && \. conda config --add channels conda-forge && \. conda create -n bio bioconda::bcftools bioconda::samtools -y && \. conda clean -a. # Clone DeepVariant and build. FROM base AS builder. # Clone the DeepVariant repository. RUN git clone https://github.com/google/deepvariant.git /opt/deepvariant && \. cd /opt/deepvariant && ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/871
https://github.com/google/deepvariant/issues/871:595,usability,user,user-attachments,595,"Troubleshooting Dockerfile for DeepVariant on Mac M1: Issues with Bazel ; Im new to working with computers tools like DeepVariant. Im trying to build DeepVariant using Docker on a Mac M1 and am encountering issues with the Dockerfile during the Bazel build process. I want to ensure compatibility with ARM64 architecture. **Docker version**: Docker version 27.1.1, build 6312585. **Bazel Version**: 7.3.1. **MacBook Model**: M1 chip (ARM64 architecture). **Error**: . ![IMG_3267](https://github.com/user-attachments/assets/11e28824-b941-42cc-9d33-7e9155a03543). ![IMG_3268](https://github.com/user-attachments/assets/4e923de6-99d5-43ee-80c6-29b32504527d). **My Dockerfilee code**:. ```. # Base image suitable for ARM64 architecture. FROM arm64v8/ubuntu:latest AS base. # Prevent interactive prompts. ENV DEBIAN_FRONTEND=noninteractive. # Install necessary packages. RUN apt-get update && \. apt-get install -y \. git \. curl \. unzip \. wget \. openjdk-17-jdk \. build-essential \. bzip2 \. python3-pip \. parallel && \. apt-get clean && \. rm -rf /var/lib/apt/lists/*. # Install Bazel (adjust version as needed). RUN curl -LO ""https://github.com/bazelbuild/bazel/releases/download/7.3.1/bazel-7.3.1-linux-arm64"" && \. chmod +x bazel-7.3.1-linux-arm64 && \. mv bazel-7.3.1-linux-arm64 /usr/local/bin/bazel. # Install Conda. RUN curl -LO ""https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-aarch64.sh"" && \. bash Miniconda3-latest-Linux-aarch64.sh -b -p /opt/miniconda && \. rm Miniconda3-latest-Linux-aarch64.sh. # Setup Conda environment. ENV PATH=""/opt/miniconda/bin:${PATH}"". RUN conda config --add channels defaults && \. conda config --add channels bioconda && \. conda config --add channels conda-forge && \. conda create -n bio bioconda::bcftools bioconda::samtools -y && \. conda clean -a. # Clone DeepVariant and build. FROM base AS builder. # Clone the DeepVariant repository. RUN git clone https://github.com/google/deepvariant.git /opt/deepvariant && \. cd /opt/deepvariant && ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/871
https://github.com/google/deepvariant/issues/871:781,usability,interact,interactive,781,"Troubleshooting Dockerfile for DeepVariant on Mac M1: Issues with Bazel ; Im new to working with computers tools like DeepVariant. Im trying to build DeepVariant using Docker on a Mac M1 and am encountering issues with the Dockerfile during the Bazel build process. I want to ensure compatibility with ARM64 architecture. **Docker version**: Docker version 27.1.1, build 6312585. **Bazel Version**: 7.3.1. **MacBook Model**: M1 chip (ARM64 architecture). **Error**: . ![IMG_3267](https://github.com/user-attachments/assets/11e28824-b941-42cc-9d33-7e9155a03543). ![IMG_3268](https://github.com/user-attachments/assets/4e923de6-99d5-43ee-80c6-29b32504527d). **My Dockerfilee code**:. ```. # Base image suitable for ARM64 architecture. FROM arm64v8/ubuntu:latest AS base. # Prevent interactive prompts. ENV DEBIAN_FRONTEND=noninteractive. # Install necessary packages. RUN apt-get update && \. apt-get install -y \. git \. curl \. unzip \. wget \. openjdk-17-jdk \. build-essential \. bzip2 \. python3-pip \. parallel && \. apt-get clean && \. rm -rf /var/lib/apt/lists/*. # Install Bazel (adjust version as needed). RUN curl -LO ""https://github.com/bazelbuild/bazel/releases/download/7.3.1/bazel-7.3.1-linux-arm64"" && \. chmod +x bazel-7.3.1-linux-arm64 && \. mv bazel-7.3.1-linux-arm64 /usr/local/bin/bazel. # Install Conda. RUN curl -LO ""https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-aarch64.sh"" && \. bash Miniconda3-latest-Linux-aarch64.sh -b -p /opt/miniconda && \. rm Miniconda3-latest-Linux-aarch64.sh. # Setup Conda environment. ENV PATH=""/opt/miniconda/bin:${PATH}"". RUN conda config --add channels defaults && \. conda config --add channels bioconda && \. conda config --add channels conda-forge && \. conda create -n bio bioconda::bcftools bioconda::samtools -y && \. conda clean -a. # Clone DeepVariant and build. FROM base AS builder. # Clone the DeepVariant repository. RUN git clone https://github.com/google/deepvariant.git /opt/deepvariant && \. cd /opt/deepvariant && ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/871
https://github.com/google/deepvariant/issues/872:1251,availability,error,error,1251,"How do you see the future of CNN outside of human genomics?; Hello,. some of you might remember me. I know Deepvariant works well in human and in some species like rice, if I recall well. In short, all species with (very) low heterozygousity. I wonder if you see a use for Deepvariant in other species, like, there are marine species that are so ancient, diverse, widespread, you can have 5% heterozygosity, in shorts, SNPs everywhere. In such cases, Deepvariant has a tendency to ""ditch"" apparently at random (Sample1 Chrom3:20456 called, Sample2 same position not called, despite obvious evidence from mapping and support from long reads). Probably because it didn't learn what to do with so many SNPs. You know the issue because of your mosquito blog spot. And I have seen other issues (including mine) talking about that. The issue is to have a gold standard like in human, or trio data like in the mosquito, you need specific conditions, it seems difficult to imagine this could be doable with, let's say, a deep sea coral (just random example, I don't actually know what's their genome like). . Could a synthetic dataset help here? What if we feed Deepvariant a genome we made up based on what we can observed visually? I am aware if we make an error it will learn errors, but I wanted your opinion, because the lack of high quality reference dataset for many species, seems to be a serious limitation for this kind of program. Thanks a lot. Since it's not the first time I bring this out, I understand if you would simply close this. Have a good week everyone.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/872
https://github.com/google/deepvariant/issues/872:1271,availability,error,errors,1271,"How do you see the future of CNN outside of human genomics?; Hello,. some of you might remember me. I know Deepvariant works well in human and in some species like rice, if I recall well. In short, all species with (very) low heterozygousity. I wonder if you see a use for Deepvariant in other species, like, there are marine species that are so ancient, diverse, widespread, you can have 5% heterozygosity, in shorts, SNPs everywhere. In such cases, Deepvariant has a tendency to ""ditch"" apparently at random (Sample1 Chrom3:20456 called, Sample2 same position not called, despite obvious evidence from mapping and support from long reads). Probably because it didn't learn what to do with so many SNPs. You know the issue because of your mosquito blog spot. And I have seen other issues (including mine) talking about that. The issue is to have a gold standard like in human, or trio data like in the mosquito, you need specific conditions, it seems difficult to imagine this could be doable with, let's say, a deep sea coral (just random example, I don't actually know what's their genome like). . Could a synthetic dataset help here? What if we feed Deepvariant a genome we made up based on what we can observed visually? I am aware if we make an error it will learn errors, but I wanted your opinion, because the lack of high quality reference dataset for many species, seems to be a serious limitation for this kind of program. Thanks a lot. Since it's not the first time I bring this out, I understand if you would simply close this. Have a good week everyone.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/872
https://github.com/google/deepvariant/issues/872:1207,deployability,observ,observed,1207,"How do you see the future of CNN outside of human genomics?; Hello,. some of you might remember me. I know Deepvariant works well in human and in some species like rice, if I recall well. In short, all species with (very) low heterozygousity. I wonder if you see a use for Deepvariant in other species, like, there are marine species that are so ancient, diverse, widespread, you can have 5% heterozygosity, in shorts, SNPs everywhere. In such cases, Deepvariant has a tendency to ""ditch"" apparently at random (Sample1 Chrom3:20456 called, Sample2 same position not called, despite obvious evidence from mapping and support from long reads). Probably because it didn't learn what to do with so many SNPs. You know the issue because of your mosquito blog spot. And I have seen other issues (including mine) talking about that. The issue is to have a gold standard like in human, or trio data like in the mosquito, you need specific conditions, it seems difficult to imagine this could be doable with, let's say, a deep sea coral (just random example, I don't actually know what's their genome like). . Could a synthetic dataset help here? What if we feed Deepvariant a genome we made up based on what we can observed visually? I am aware if we make an error it will learn errors, but I wanted your opinion, because the lack of high quality reference dataset for many species, seems to be a serious limitation for this kind of program. Thanks a lot. Since it's not the first time I bring this out, I understand if you would simply close this. Have a good week everyone.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/872
https://github.com/google/deepvariant/issues/872:854,interoperability,standard,standard,854,"How do you see the future of CNN outside of human genomics?; Hello,. some of you might remember me. I know Deepvariant works well in human and in some species like rice, if I recall well. In short, all species with (very) low heterozygousity. I wonder if you see a use for Deepvariant in other species, like, there are marine species that are so ancient, diverse, widespread, you can have 5% heterozygosity, in shorts, SNPs everywhere. In such cases, Deepvariant has a tendency to ""ditch"" apparently at random (Sample1 Chrom3:20456 called, Sample2 same position not called, despite obvious evidence from mapping and support from long reads). Probably because it didn't learn what to do with so many SNPs. You know the issue because of your mosquito blog spot. And I have seen other issues (including mine) talking about that. The issue is to have a gold standard like in human, or trio data like in the mosquito, you need specific conditions, it seems difficult to imagine this could be doable with, let's say, a deep sea coral (just random example, I don't actually know what's their genome like). . Could a synthetic dataset help here? What if we feed Deepvariant a genome we made up based on what we can observed visually? I am aware if we make an error it will learn errors, but I wanted your opinion, because the lack of high quality reference dataset for many species, seems to be a serious limitation for this kind of program. Thanks a lot. Since it's not the first time I bring this out, I understand if you would simply close this. Have a good week everyone.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/872
https://github.com/google/deepvariant/issues/872:922,interoperability,specif,specific,922,"How do you see the future of CNN outside of human genomics?; Hello,. some of you might remember me. I know Deepvariant works well in human and in some species like rice, if I recall well. In short, all species with (very) low heterozygousity. I wonder if you see a use for Deepvariant in other species, like, there are marine species that are so ancient, diverse, widespread, you can have 5% heterozygosity, in shorts, SNPs everywhere. In such cases, Deepvariant has a tendency to ""ditch"" apparently at random (Sample1 Chrom3:20456 called, Sample2 same position not called, despite obvious evidence from mapping and support from long reads). Probably because it didn't learn what to do with so many SNPs. You know the issue because of your mosquito blog spot. And I have seen other issues (including mine) talking about that. The issue is to have a gold standard like in human, or trio data like in the mosquito, you need specific conditions, it seems difficult to imagine this could be doable with, let's say, a deep sea coral (just random example, I don't actually know what's their genome like). . Could a synthetic dataset help here? What if we feed Deepvariant a genome we made up based on what we can observed visually? I am aware if we make an error it will learn errors, but I wanted your opinion, because the lack of high quality reference dataset for many species, seems to be a serious limitation for this kind of program. Thanks a lot. Since it's not the first time I bring this out, I understand if you would simply close this. Have a good week everyone.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/872
https://github.com/google/deepvariant/issues/872:1251,performance,error,error,1251,"How do you see the future of CNN outside of human genomics?; Hello,. some of you might remember me. I know Deepvariant works well in human and in some species like rice, if I recall well. In short, all species with (very) low heterozygousity. I wonder if you see a use for Deepvariant in other species, like, there are marine species that are so ancient, diverse, widespread, you can have 5% heterozygosity, in shorts, SNPs everywhere. In such cases, Deepvariant has a tendency to ""ditch"" apparently at random (Sample1 Chrom3:20456 called, Sample2 same position not called, despite obvious evidence from mapping and support from long reads). Probably because it didn't learn what to do with so many SNPs. You know the issue because of your mosquito blog spot. And I have seen other issues (including mine) talking about that. The issue is to have a gold standard like in human, or trio data like in the mosquito, you need specific conditions, it seems difficult to imagine this could be doable with, let's say, a deep sea coral (just random example, I don't actually know what's their genome like). . Could a synthetic dataset help here? What if we feed Deepvariant a genome we made up based on what we can observed visually? I am aware if we make an error it will learn errors, but I wanted your opinion, because the lack of high quality reference dataset for many species, seems to be a serious limitation for this kind of program. Thanks a lot. Since it's not the first time I bring this out, I understand if you would simply close this. Have a good week everyone.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/872
https://github.com/google/deepvariant/issues/872:1271,performance,error,errors,1271,"How do you see the future of CNN outside of human genomics?; Hello,. some of you might remember me. I know Deepvariant works well in human and in some species like rice, if I recall well. In short, all species with (very) low heterozygousity. I wonder if you see a use for Deepvariant in other species, like, there are marine species that are so ancient, diverse, widespread, you can have 5% heterozygosity, in shorts, SNPs everywhere. In such cases, Deepvariant has a tendency to ""ditch"" apparently at random (Sample1 Chrom3:20456 called, Sample2 same position not called, despite obvious evidence from mapping and support from long reads). Probably because it didn't learn what to do with so many SNPs. You know the issue because of your mosquito blog spot. And I have seen other issues (including mine) talking about that. The issue is to have a gold standard like in human, or trio data like in the mosquito, you need specific conditions, it seems difficult to imagine this could be doable with, let's say, a deep sea coral (just random example, I don't actually know what's their genome like). . Could a synthetic dataset help here? What if we feed Deepvariant a genome we made up based on what we can observed visually? I am aware if we make an error it will learn errors, but I wanted your opinion, because the lack of high quality reference dataset for many species, seems to be a serious limitation for this kind of program. Thanks a lot. Since it's not the first time I bring this out, I understand if you would simply close this. Have a good week everyone.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/872
https://github.com/google/deepvariant/issues/872:1473,performance,time,time,1473,"How do you see the future of CNN outside of human genomics?; Hello,. some of you might remember me. I know Deepvariant works well in human and in some species like rice, if I recall well. In short, all species with (very) low heterozygousity. I wonder if you see a use for Deepvariant in other species, like, there are marine species that are so ancient, diverse, widespread, you can have 5% heterozygosity, in shorts, SNPs everywhere. In such cases, Deepvariant has a tendency to ""ditch"" apparently at random (Sample1 Chrom3:20456 called, Sample2 same position not called, despite obvious evidence from mapping and support from long reads). Probably because it didn't learn what to do with so many SNPs. You know the issue because of your mosquito blog spot. And I have seen other issues (including mine) talking about that. The issue is to have a gold standard like in human, or trio data like in the mosquito, you need specific conditions, it seems difficult to imagine this could be doable with, let's say, a deep sea coral (just random example, I don't actually know what's their genome like). . Could a synthetic dataset help here? What if we feed Deepvariant a genome we made up based on what we can observed visually? I am aware if we make an error it will learn errors, but I wanted your opinion, because the lack of high quality reference dataset for many species, seems to be a serious limitation for this kind of program. Thanks a lot. Since it's not the first time I bring this out, I understand if you would simply close this. Have a good week everyone.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/872
https://github.com/google/deepvariant/issues/872:87,safety,reme,remember,87,"How do you see the future of CNN outside of human genomics?; Hello,. some of you might remember me. I know Deepvariant works well in human and in some species like rice, if I recall well. In short, all species with (very) low heterozygousity. I wonder if you see a use for Deepvariant in other species, like, there are marine species that are so ancient, diverse, widespread, you can have 5% heterozygosity, in shorts, SNPs everywhere. In such cases, Deepvariant has a tendency to ""ditch"" apparently at random (Sample1 Chrom3:20456 called, Sample2 same position not called, despite obvious evidence from mapping and support from long reads). Probably because it didn't learn what to do with so many SNPs. You know the issue because of your mosquito blog spot. And I have seen other issues (including mine) talking about that. The issue is to have a gold standard like in human, or trio data like in the mosquito, you need specific conditions, it seems difficult to imagine this could be doable with, let's say, a deep sea coral (just random example, I don't actually know what's their genome like). . Could a synthetic dataset help here? What if we feed Deepvariant a genome we made up based on what we can observed visually? I am aware if we make an error it will learn errors, but I wanted your opinion, because the lack of high quality reference dataset for many species, seems to be a serious limitation for this kind of program. Thanks a lot. Since it's not the first time I bring this out, I understand if you would simply close this. Have a good week everyone.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/872
https://github.com/google/deepvariant/issues/872:1251,safety,error,error,1251,"How do you see the future of CNN outside of human genomics?; Hello,. some of you might remember me. I know Deepvariant works well in human and in some species like rice, if I recall well. In short, all species with (very) low heterozygousity. I wonder if you see a use for Deepvariant in other species, like, there are marine species that are so ancient, diverse, widespread, you can have 5% heterozygosity, in shorts, SNPs everywhere. In such cases, Deepvariant has a tendency to ""ditch"" apparently at random (Sample1 Chrom3:20456 called, Sample2 same position not called, despite obvious evidence from mapping and support from long reads). Probably because it didn't learn what to do with so many SNPs. You know the issue because of your mosquito blog spot. And I have seen other issues (including mine) talking about that. The issue is to have a gold standard like in human, or trio data like in the mosquito, you need specific conditions, it seems difficult to imagine this could be doable with, let's say, a deep sea coral (just random example, I don't actually know what's their genome like). . Could a synthetic dataset help here? What if we feed Deepvariant a genome we made up based on what we can observed visually? I am aware if we make an error it will learn errors, but I wanted your opinion, because the lack of high quality reference dataset for many species, seems to be a serious limitation for this kind of program. Thanks a lot. Since it's not the first time I bring this out, I understand if you would simply close this. Have a good week everyone.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/872
https://github.com/google/deepvariant/issues/872:1271,safety,error,errors,1271,"How do you see the future of CNN outside of human genomics?; Hello,. some of you might remember me. I know Deepvariant works well in human and in some species like rice, if I recall well. In short, all species with (very) low heterozygousity. I wonder if you see a use for Deepvariant in other species, like, there are marine species that are so ancient, diverse, widespread, you can have 5% heterozygosity, in shorts, SNPs everywhere. In such cases, Deepvariant has a tendency to ""ditch"" apparently at random (Sample1 Chrom3:20456 called, Sample2 same position not called, despite obvious evidence from mapping and support from long reads). Probably because it didn't learn what to do with so many SNPs. You know the issue because of your mosquito blog spot. And I have seen other issues (including mine) talking about that. The issue is to have a gold standard like in human, or trio data like in the mosquito, you need specific conditions, it seems difficult to imagine this could be doable with, let's say, a deep sea coral (just random example, I don't actually know what's their genome like). . Could a synthetic dataset help here? What if we feed Deepvariant a genome we made up based on what we can observed visually? I am aware if we make an error it will learn errors, but I wanted your opinion, because the lack of high quality reference dataset for many species, seems to be a serious limitation for this kind of program. Thanks a lot. Since it's not the first time I bring this out, I understand if you would simply close this. Have a good week everyone.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/872
https://github.com/google/deepvariant/issues/872:1207,testability,observ,observed,1207,"How do you see the future of CNN outside of human genomics?; Hello,. some of you might remember me. I know Deepvariant works well in human and in some species like rice, if I recall well. In short, all species with (very) low heterozygousity. I wonder if you see a use for Deepvariant in other species, like, there are marine species that are so ancient, diverse, widespread, you can have 5% heterozygosity, in shorts, SNPs everywhere. In such cases, Deepvariant has a tendency to ""ditch"" apparently at random (Sample1 Chrom3:20456 called, Sample2 same position not called, despite obvious evidence from mapping and support from long reads). Probably because it didn't learn what to do with so many SNPs. You know the issue because of your mosquito blog spot. And I have seen other issues (including mine) talking about that. The issue is to have a gold standard like in human, or trio data like in the mosquito, you need specific conditions, it seems difficult to imagine this could be doable with, let's say, a deep sea coral (just random example, I don't actually know what's their genome like). . Could a synthetic dataset help here? What if we feed Deepvariant a genome we made up based on what we can observed visually? I am aware if we make an error it will learn errors, but I wanted your opinion, because the lack of high quality reference dataset for many species, seems to be a serious limitation for this kind of program. Thanks a lot. Since it's not the first time I bring this out, I understand if you would simply close this. Have a good week everyone.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/872
https://github.com/google/deepvariant/issues/872:1498,testability,understand,understand,1498,"How do you see the future of CNN outside of human genomics?; Hello,. some of you might remember me. I know Deepvariant works well in human and in some species like rice, if I recall well. In short, all species with (very) low heterozygousity. I wonder if you see a use for Deepvariant in other species, like, there are marine species that are so ancient, diverse, widespread, you can have 5% heterozygosity, in shorts, SNPs everywhere. In such cases, Deepvariant has a tendency to ""ditch"" apparently at random (Sample1 Chrom3:20456 called, Sample2 same position not called, despite obvious evidence from mapping and support from long reads). Probably because it didn't learn what to do with so many SNPs. You know the issue because of your mosquito blog spot. And I have seen other issues (including mine) talking about that. The issue is to have a gold standard like in human, or trio data like in the mosquito, you need specific conditions, it seems difficult to imagine this could be doable with, let's say, a deep sea coral (just random example, I don't actually know what's their genome like). . Could a synthetic dataset help here? What if we feed Deepvariant a genome we made up based on what we can observed visually? I am aware if we make an error it will learn errors, but I wanted your opinion, because the lack of high quality reference dataset for many species, seems to be a serious limitation for this kind of program. Thanks a lot. Since it's not the first time I bring this out, I understand if you would simply close this. Have a good week everyone.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/872
https://github.com/google/deepvariant/issues/872:1522,testability,simpl,simply,1522,"How do you see the future of CNN outside of human genomics?; Hello,. some of you might remember me. I know Deepvariant works well in human and in some species like rice, if I recall well. In short, all species with (very) low heterozygousity. I wonder if you see a use for Deepvariant in other species, like, there are marine species that are so ancient, diverse, widespread, you can have 5% heterozygosity, in shorts, SNPs everywhere. In such cases, Deepvariant has a tendency to ""ditch"" apparently at random (Sample1 Chrom3:20456 called, Sample2 same position not called, despite obvious evidence from mapping and support from long reads). Probably because it didn't learn what to do with so many SNPs. You know the issue because of your mosquito blog spot. And I have seen other issues (including mine) talking about that. The issue is to have a gold standard like in human, or trio data like in the mosquito, you need specific conditions, it seems difficult to imagine this could be doable with, let's say, a deep sea coral (just random example, I don't actually know what's their genome like). . Could a synthetic dataset help here? What if we feed Deepvariant a genome we made up based on what we can observed visually? I am aware if we make an error it will learn errors, but I wanted your opinion, because the lack of high quality reference dataset for many species, seems to be a serious limitation for this kind of program. Thanks a lot. Since it's not the first time I bring this out, I understand if you would simply close this. Have a good week everyone.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/872
https://github.com/google/deepvariant/issues/872:616,usability,support,support,616,"How do you see the future of CNN outside of human genomics?; Hello,. some of you might remember me. I know Deepvariant works well in human and in some species like rice, if I recall well. In short, all species with (very) low heterozygousity. I wonder if you see a use for Deepvariant in other species, like, there are marine species that are so ancient, diverse, widespread, you can have 5% heterozygosity, in shorts, SNPs everywhere. In such cases, Deepvariant has a tendency to ""ditch"" apparently at random (Sample1 Chrom3:20456 called, Sample2 same position not called, despite obvious evidence from mapping and support from long reads). Probably because it didn't learn what to do with so many SNPs. You know the issue because of your mosquito blog spot. And I have seen other issues (including mine) talking about that. The issue is to have a gold standard like in human, or trio data like in the mosquito, you need specific conditions, it seems difficult to imagine this could be doable with, let's say, a deep sea coral (just random example, I don't actually know what's their genome like). . Could a synthetic dataset help here? What if we feed Deepvariant a genome we made up based on what we can observed visually? I am aware if we make an error it will learn errors, but I wanted your opinion, because the lack of high quality reference dataset for many species, seems to be a serious limitation for this kind of program. Thanks a lot. Since it's not the first time I bring this out, I understand if you would simply close this. Have a good week everyone.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/872
https://github.com/google/deepvariant/issues/872:669,usability,learn,learn,669,"How do you see the future of CNN outside of human genomics?; Hello,. some of you might remember me. I know Deepvariant works well in human and in some species like rice, if I recall well. In short, all species with (very) low heterozygousity. I wonder if you see a use for Deepvariant in other species, like, there are marine species that are so ancient, diverse, widespread, you can have 5% heterozygosity, in shorts, SNPs everywhere. In such cases, Deepvariant has a tendency to ""ditch"" apparently at random (Sample1 Chrom3:20456 called, Sample2 same position not called, despite obvious evidence from mapping and support from long reads). Probably because it didn't learn what to do with so many SNPs. You know the issue because of your mosquito blog spot. And I have seen other issues (including mine) talking about that. The issue is to have a gold standard like in human, or trio data like in the mosquito, you need specific conditions, it seems difficult to imagine this could be doable with, let's say, a deep sea coral (just random example, I don't actually know what's their genome like). . Could a synthetic dataset help here? What if we feed Deepvariant a genome we made up based on what we can observed visually? I am aware if we make an error it will learn errors, but I wanted your opinion, because the lack of high quality reference dataset for many species, seems to be a serious limitation for this kind of program. Thanks a lot. Since it's not the first time I bring this out, I understand if you would simply close this. Have a good week everyone.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/872
https://github.com/google/deepvariant/issues/872:1127,usability,help,help,1127,"How do you see the future of CNN outside of human genomics?; Hello,. some of you might remember me. I know Deepvariant works well in human and in some species like rice, if I recall well. In short, all species with (very) low heterozygousity. I wonder if you see a use for Deepvariant in other species, like, there are marine species that are so ancient, diverse, widespread, you can have 5% heterozygosity, in shorts, SNPs everywhere. In such cases, Deepvariant has a tendency to ""ditch"" apparently at random (Sample1 Chrom3:20456 called, Sample2 same position not called, despite obvious evidence from mapping and support from long reads). Probably because it didn't learn what to do with so many SNPs. You know the issue because of your mosquito blog spot. And I have seen other issues (including mine) talking about that. The issue is to have a gold standard like in human, or trio data like in the mosquito, you need specific conditions, it seems difficult to imagine this could be doable with, let's say, a deep sea coral (just random example, I don't actually know what's their genome like). . Could a synthetic dataset help here? What if we feed Deepvariant a genome we made up based on what we can observed visually? I am aware if we make an error it will learn errors, but I wanted your opinion, because the lack of high quality reference dataset for many species, seems to be a serious limitation for this kind of program. Thanks a lot. Since it's not the first time I bring this out, I understand if you would simply close this. Have a good week everyone.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/872
https://github.com/google/deepvariant/issues/872:1216,usability,visual,visually,1216,"How do you see the future of CNN outside of human genomics?; Hello,. some of you might remember me. I know Deepvariant works well in human and in some species like rice, if I recall well. In short, all species with (very) low heterozygousity. I wonder if you see a use for Deepvariant in other species, like, there are marine species that are so ancient, diverse, widespread, you can have 5% heterozygosity, in shorts, SNPs everywhere. In such cases, Deepvariant has a tendency to ""ditch"" apparently at random (Sample1 Chrom3:20456 called, Sample2 same position not called, despite obvious evidence from mapping and support from long reads). Probably because it didn't learn what to do with so many SNPs. You know the issue because of your mosquito blog spot. And I have seen other issues (including mine) talking about that. The issue is to have a gold standard like in human, or trio data like in the mosquito, you need specific conditions, it seems difficult to imagine this could be doable with, let's say, a deep sea coral (just random example, I don't actually know what's their genome like). . Could a synthetic dataset help here? What if we feed Deepvariant a genome we made up based on what we can observed visually? I am aware if we make an error it will learn errors, but I wanted your opinion, because the lack of high quality reference dataset for many species, seems to be a serious limitation for this kind of program. Thanks a lot. Since it's not the first time I bring this out, I understand if you would simply close this. Have a good week everyone.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/872
https://github.com/google/deepvariant/issues/872:1251,usability,error,error,1251,"How do you see the future of CNN outside of human genomics?; Hello,. some of you might remember me. I know Deepvariant works well in human and in some species like rice, if I recall well. In short, all species with (very) low heterozygousity. I wonder if you see a use for Deepvariant in other species, like, there are marine species that are so ancient, diverse, widespread, you can have 5% heterozygosity, in shorts, SNPs everywhere. In such cases, Deepvariant has a tendency to ""ditch"" apparently at random (Sample1 Chrom3:20456 called, Sample2 same position not called, despite obvious evidence from mapping and support from long reads). Probably because it didn't learn what to do with so many SNPs. You know the issue because of your mosquito blog spot. And I have seen other issues (including mine) talking about that. The issue is to have a gold standard like in human, or trio data like in the mosquito, you need specific conditions, it seems difficult to imagine this could be doable with, let's say, a deep sea coral (just random example, I don't actually know what's their genome like). . Could a synthetic dataset help here? What if we feed Deepvariant a genome we made up based on what we can observed visually? I am aware if we make an error it will learn errors, but I wanted your opinion, because the lack of high quality reference dataset for many species, seems to be a serious limitation for this kind of program. Thanks a lot. Since it's not the first time I bring this out, I understand if you would simply close this. Have a good week everyone.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/872
https://github.com/google/deepvariant/issues/872:1265,usability,learn,learn,1265,"How do you see the future of CNN outside of human genomics?; Hello,. some of you might remember me. I know Deepvariant works well in human and in some species like rice, if I recall well. In short, all species with (very) low heterozygousity. I wonder if you see a use for Deepvariant in other species, like, there are marine species that are so ancient, diverse, widespread, you can have 5% heterozygosity, in shorts, SNPs everywhere. In such cases, Deepvariant has a tendency to ""ditch"" apparently at random (Sample1 Chrom3:20456 called, Sample2 same position not called, despite obvious evidence from mapping and support from long reads). Probably because it didn't learn what to do with so many SNPs. You know the issue because of your mosquito blog spot. And I have seen other issues (including mine) talking about that. The issue is to have a gold standard like in human, or trio data like in the mosquito, you need specific conditions, it seems difficult to imagine this could be doable with, let's say, a deep sea coral (just random example, I don't actually know what's their genome like). . Could a synthetic dataset help here? What if we feed Deepvariant a genome we made up based on what we can observed visually? I am aware if we make an error it will learn errors, but I wanted your opinion, because the lack of high quality reference dataset for many species, seems to be a serious limitation for this kind of program. Thanks a lot. Since it's not the first time I bring this out, I understand if you would simply close this. Have a good week everyone.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/872
https://github.com/google/deepvariant/issues/872:1271,usability,error,errors,1271,"How do you see the future of CNN outside of human genomics?; Hello,. some of you might remember me. I know Deepvariant works well in human and in some species like rice, if I recall well. In short, all species with (very) low heterozygousity. I wonder if you see a use for Deepvariant in other species, like, there are marine species that are so ancient, diverse, widespread, you can have 5% heterozygosity, in shorts, SNPs everywhere. In such cases, Deepvariant has a tendency to ""ditch"" apparently at random (Sample1 Chrom3:20456 called, Sample2 same position not called, despite obvious evidence from mapping and support from long reads). Probably because it didn't learn what to do with so many SNPs. You know the issue because of your mosquito blog spot. And I have seen other issues (including mine) talking about that. The issue is to have a gold standard like in human, or trio data like in the mosquito, you need specific conditions, it seems difficult to imagine this could be doable with, let's say, a deep sea coral (just random example, I don't actually know what's their genome like). . Could a synthetic dataset help here? What if we feed Deepvariant a genome we made up based on what we can observed visually? I am aware if we make an error it will learn errors, but I wanted your opinion, because the lack of high quality reference dataset for many species, seems to be a serious limitation for this kind of program. Thanks a lot. Since it's not the first time I bring this out, I understand if you would simply close this. Have a good week everyone.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/872
https://github.com/google/deepvariant/issues/872:1522,usability,simpl,simply,1522,"How do you see the future of CNN outside of human genomics?; Hello,. some of you might remember me. I know Deepvariant works well in human and in some species like rice, if I recall well. In short, all species with (very) low heterozygousity. I wonder if you see a use for Deepvariant in other species, like, there are marine species that are so ancient, diverse, widespread, you can have 5% heterozygosity, in shorts, SNPs everywhere. In such cases, Deepvariant has a tendency to ""ditch"" apparently at random (Sample1 Chrom3:20456 called, Sample2 same position not called, despite obvious evidence from mapping and support from long reads). Probably because it didn't learn what to do with so many SNPs. You know the issue because of your mosquito blog spot. And I have seen other issues (including mine) talking about that. The issue is to have a gold standard like in human, or trio data like in the mosquito, you need specific conditions, it seems difficult to imagine this could be doable with, let's say, a deep sea coral (just random example, I don't actually know what's their genome like). . Could a synthetic dataset help here? What if we feed Deepvariant a genome we made up based on what we can observed visually? I am aware if we make an error it will learn errors, but I wanted your opinion, because the lack of high quality reference dataset for many species, seems to be a serious limitation for this kind of program. Thanks a lot. Since it's not the first time I bring this out, I understand if you would simply close this. Have a good week everyone.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/872
https://github.com/google/deepvariant/issues/872:1529,usability,close,close,1529,"How do you see the future of CNN outside of human genomics?; Hello,. some of you might remember me. I know Deepvariant works well in human and in some species like rice, if I recall well. In short, all species with (very) low heterozygousity. I wonder if you see a use for Deepvariant in other species, like, there are marine species that are so ancient, diverse, widespread, you can have 5% heterozygosity, in shorts, SNPs everywhere. In such cases, Deepvariant has a tendency to ""ditch"" apparently at random (Sample1 Chrom3:20456 called, Sample2 same position not called, despite obvious evidence from mapping and support from long reads). Probably because it didn't learn what to do with so many SNPs. You know the issue because of your mosquito blog spot. And I have seen other issues (including mine) talking about that. The issue is to have a gold standard like in human, or trio data like in the mosquito, you need specific conditions, it seems difficult to imagine this could be doable with, let's say, a deep sea coral (just random example, I don't actually know what's their genome like). . Could a synthetic dataset help here? What if we feed Deepvariant a genome we made up based on what we can observed visually? I am aware if we make an error it will learn errors, but I wanted your opinion, because the lack of high quality reference dataset for many species, seems to be a serious limitation for this kind of program. Thanks a lot. Since it's not the first time I bring this out, I understand if you would simply close this. Have a good week everyone.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/872
https://github.com/google/deepvariant/issues/873:149,deployability,log,logs,149,"CPU and GPU using ; Hello,. I've been using DeepTrio for de novo variant analysis, and it's been performing excellently. However, I noticed from the logs that DeepTrio uses the CPU to prepare data, which is quite time-consuming. In my case, it took 12 hours for one trio analysis, with an additional 4 hours on the GPU. Given that renting GPU servers( usually with less CPU) is more expensive than CPU servers and access to privately owned GPU servers is limited, it seems inefficient to run lengthy CPU processes on a GPU server. It feels like a bit of a waste, and sometimes I half-jokingly feel there might be someone out there with murderous intent because of it! Would it be possible in future updates to partition the DeepTrio analysis into separate steps? This way, CPU-intensive tasks could be completed on a CPU server, and then the job could be transferred to a GPU server for the remaining tasks. Alternatively, could the data preparation (CPU) and analysis (GPU) be run at the same time? This would help optimize resource usage and reduce costs. Thank you for considering these suggestions.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/873
https://github.com/google/deepvariant/issues/873:699,deployability,updat,updates,699,"CPU and GPU using ; Hello,. I've been using DeepTrio for de novo variant analysis, and it's been performing excellently. However, I noticed from the logs that DeepTrio uses the CPU to prepare data, which is quite time-consuming. In my case, it took 12 hours for one trio analysis, with an additional 4 hours on the GPU. Given that renting GPU servers( usually with less CPU) is more expensive than CPU servers and access to privately owned GPU servers is limited, it seems inefficient to run lengthy CPU processes on a GPU server. It feels like a bit of a waste, and sometimes I half-jokingly feel there might be someone out there with murderous intent because of it! Would it be possible in future updates to partition the DeepTrio analysis into separate steps? This way, CPU-intensive tasks could be completed on a CPU server, and then the job could be transferred to a GPU server for the remaining tasks. Alternatively, could the data preparation (CPU) and analysis (GPU) be run at the same time? This would help optimize resource usage and reduce costs. Thank you for considering these suggestions.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/873
https://github.com/google/deepvariant/issues/873:1025,deployability,resourc,resource,1025,"CPU and GPU using ; Hello,. I've been using DeepTrio for de novo variant analysis, and it's been performing excellently. However, I noticed from the logs that DeepTrio uses the CPU to prepare data, which is quite time-consuming. In my case, it took 12 hours for one trio analysis, with an additional 4 hours on the GPU. Given that renting GPU servers( usually with less CPU) is more expensive than CPU servers and access to privately owned GPU servers is limited, it seems inefficient to run lengthy CPU processes on a GPU server. It feels like a bit of a waste, and sometimes I half-jokingly feel there might be someone out there with murderous intent because of it! Would it be possible in future updates to partition the DeepTrio analysis into separate steps? This way, CPU-intensive tasks could be completed on a CPU server, and then the job could be transferred to a GPU server for the remaining tasks. Alternatively, could the data preparation (CPU) and analysis (GPU) be run at the same time? This would help optimize resource usage and reduce costs. Thank you for considering these suggestions.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/873
https://github.com/google/deepvariant/issues/873:0,energy efficiency,CPU,CPU,0,"CPU and GPU using ; Hello,. I've been using DeepTrio for de novo variant analysis, and it's been performing excellently. However, I noticed from the logs that DeepTrio uses the CPU to prepare data, which is quite time-consuming. In my case, it took 12 hours for one trio analysis, with an additional 4 hours on the GPU. Given that renting GPU servers( usually with less CPU) is more expensive than CPU servers and access to privately owned GPU servers is limited, it seems inefficient to run lengthy CPU processes on a GPU server. It feels like a bit of a waste, and sometimes I half-jokingly feel there might be someone out there with murderous intent because of it! Would it be possible in future updates to partition the DeepTrio analysis into separate steps? This way, CPU-intensive tasks could be completed on a CPU server, and then the job could be transferred to a GPU server for the remaining tasks. Alternatively, could the data preparation (CPU) and analysis (GPU) be run at the same time? This would help optimize resource usage and reduce costs. Thank you for considering these suggestions.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/873
https://github.com/google/deepvariant/issues/873:8,energy efficiency,GPU,GPU,8,"CPU and GPU using ; Hello,. I've been using DeepTrio for de novo variant analysis, and it's been performing excellently. However, I noticed from the logs that DeepTrio uses the CPU to prepare data, which is quite time-consuming. In my case, it took 12 hours for one trio analysis, with an additional 4 hours on the GPU. Given that renting GPU servers( usually with less CPU) is more expensive than CPU servers and access to privately owned GPU servers is limited, it seems inefficient to run lengthy CPU processes on a GPU server. It feels like a bit of a waste, and sometimes I half-jokingly feel there might be someone out there with murderous intent because of it! Would it be possible in future updates to partition the DeepTrio analysis into separate steps? This way, CPU-intensive tasks could be completed on a CPU server, and then the job could be transferred to a GPU server for the remaining tasks. Alternatively, could the data preparation (CPU) and analysis (GPU) be run at the same time? This would help optimize resource usage and reduce costs. Thank you for considering these suggestions.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/873
https://github.com/google/deepvariant/issues/873:177,energy efficiency,CPU,CPU,177,"CPU and GPU using ; Hello,. I've been using DeepTrio for de novo variant analysis, and it's been performing excellently. However, I noticed from the logs that DeepTrio uses the CPU to prepare data, which is quite time-consuming. In my case, it took 12 hours for one trio analysis, with an additional 4 hours on the GPU. Given that renting GPU servers( usually with less CPU) is more expensive than CPU servers and access to privately owned GPU servers is limited, it seems inefficient to run lengthy CPU processes on a GPU server. It feels like a bit of a waste, and sometimes I half-jokingly feel there might be someone out there with murderous intent because of it! Would it be possible in future updates to partition the DeepTrio analysis into separate steps? This way, CPU-intensive tasks could be completed on a CPU server, and then the job could be transferred to a GPU server for the remaining tasks. Alternatively, could the data preparation (CPU) and analysis (GPU) be run at the same time? This would help optimize resource usage and reduce costs. Thank you for considering these suggestions.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/873
https://github.com/google/deepvariant/issues/873:315,energy efficiency,GPU,GPU,315,"CPU and GPU using ; Hello,. I've been using DeepTrio for de novo variant analysis, and it's been performing excellently. However, I noticed from the logs that DeepTrio uses the CPU to prepare data, which is quite time-consuming. In my case, it took 12 hours for one trio analysis, with an additional 4 hours on the GPU. Given that renting GPU servers( usually with less CPU) is more expensive than CPU servers and access to privately owned GPU servers is limited, it seems inefficient to run lengthy CPU processes on a GPU server. It feels like a bit of a waste, and sometimes I half-jokingly feel there might be someone out there with murderous intent because of it! Would it be possible in future updates to partition the DeepTrio analysis into separate steps? This way, CPU-intensive tasks could be completed on a CPU server, and then the job could be transferred to a GPU server for the remaining tasks. Alternatively, could the data preparation (CPU) and analysis (GPU) be run at the same time? This would help optimize resource usage and reduce costs. Thank you for considering these suggestions.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/873
https://github.com/google/deepvariant/issues/873:339,energy efficiency,GPU,GPU,339,"CPU and GPU using ; Hello,. I've been using DeepTrio for de novo variant analysis, and it's been performing excellently. However, I noticed from the logs that DeepTrio uses the CPU to prepare data, which is quite time-consuming. In my case, it took 12 hours for one trio analysis, with an additional 4 hours on the GPU. Given that renting GPU servers( usually with less CPU) is more expensive than CPU servers and access to privately owned GPU servers is limited, it seems inefficient to run lengthy CPU processes on a GPU server. It feels like a bit of a waste, and sometimes I half-jokingly feel there might be someone out there with murderous intent because of it! Would it be possible in future updates to partition the DeepTrio analysis into separate steps? This way, CPU-intensive tasks could be completed on a CPU server, and then the job could be transferred to a GPU server for the remaining tasks. Alternatively, could the data preparation (CPU) and analysis (GPU) be run at the same time? This would help optimize resource usage and reduce costs. Thank you for considering these suggestions.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/873
https://github.com/google/deepvariant/issues/873:370,energy efficiency,CPU,CPU,370,"CPU and GPU using ; Hello,. I've been using DeepTrio for de novo variant analysis, and it's been performing excellently. However, I noticed from the logs that DeepTrio uses the CPU to prepare data, which is quite time-consuming. In my case, it took 12 hours for one trio analysis, with an additional 4 hours on the GPU. Given that renting GPU servers( usually with less CPU) is more expensive than CPU servers and access to privately owned GPU servers is limited, it seems inefficient to run lengthy CPU processes on a GPU server. It feels like a bit of a waste, and sometimes I half-jokingly feel there might be someone out there with murderous intent because of it! Would it be possible in future updates to partition the DeepTrio analysis into separate steps? This way, CPU-intensive tasks could be completed on a CPU server, and then the job could be transferred to a GPU server for the remaining tasks. Alternatively, could the data preparation (CPU) and analysis (GPU) be run at the same time? This would help optimize resource usage and reduce costs. Thank you for considering these suggestions.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/873
https://github.com/google/deepvariant/issues/873:398,energy efficiency,CPU,CPU,398,"CPU and GPU using ; Hello,. I've been using DeepTrio for de novo variant analysis, and it's been performing excellently. However, I noticed from the logs that DeepTrio uses the CPU to prepare data, which is quite time-consuming. In my case, it took 12 hours for one trio analysis, with an additional 4 hours on the GPU. Given that renting GPU servers( usually with less CPU) is more expensive than CPU servers and access to privately owned GPU servers is limited, it seems inefficient to run lengthy CPU processes on a GPU server. It feels like a bit of a waste, and sometimes I half-jokingly feel there might be someone out there with murderous intent because of it! Would it be possible in future updates to partition the DeepTrio analysis into separate steps? This way, CPU-intensive tasks could be completed on a CPU server, and then the job could be transferred to a GPU server for the remaining tasks. Alternatively, could the data preparation (CPU) and analysis (GPU) be run at the same time? This would help optimize resource usage and reduce costs. Thank you for considering these suggestions.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/873
https://github.com/google/deepvariant/issues/873:440,energy efficiency,GPU,GPU,440,"CPU and GPU using ; Hello,. I've been using DeepTrio for de novo variant analysis, and it's been performing excellently. However, I noticed from the logs that DeepTrio uses the CPU to prepare data, which is quite time-consuming. In my case, it took 12 hours for one trio analysis, with an additional 4 hours on the GPU. Given that renting GPU servers( usually with less CPU) is more expensive than CPU servers and access to privately owned GPU servers is limited, it seems inefficient to run lengthy CPU processes on a GPU server. It feels like a bit of a waste, and sometimes I half-jokingly feel there might be someone out there with murderous intent because of it! Would it be possible in future updates to partition the DeepTrio analysis into separate steps? This way, CPU-intensive tasks could be completed on a CPU server, and then the job could be transferred to a GPU server for the remaining tasks. Alternatively, could the data preparation (CPU) and analysis (GPU) be run at the same time? This would help optimize resource usage and reduce costs. Thank you for considering these suggestions.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/873
https://github.com/google/deepvariant/issues/873:500,energy efficiency,CPU,CPU,500,"CPU and GPU using ; Hello,. I've been using DeepTrio for de novo variant analysis, and it's been performing excellently. However, I noticed from the logs that DeepTrio uses the CPU to prepare data, which is quite time-consuming. In my case, it took 12 hours for one trio analysis, with an additional 4 hours on the GPU. Given that renting GPU servers( usually with less CPU) is more expensive than CPU servers and access to privately owned GPU servers is limited, it seems inefficient to run lengthy CPU processes on a GPU server. It feels like a bit of a waste, and sometimes I half-jokingly feel there might be someone out there with murderous intent because of it! Would it be possible in future updates to partition the DeepTrio analysis into separate steps? This way, CPU-intensive tasks could be completed on a CPU server, and then the job could be transferred to a GPU server for the remaining tasks. Alternatively, could the data preparation (CPU) and analysis (GPU) be run at the same time? This would help optimize resource usage and reduce costs. Thank you for considering these suggestions.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/873
https://github.com/google/deepvariant/issues/873:519,energy efficiency,GPU,GPU,519,"CPU and GPU using ; Hello,. I've been using DeepTrio for de novo variant analysis, and it's been performing excellently. However, I noticed from the logs that DeepTrio uses the CPU to prepare data, which is quite time-consuming. In my case, it took 12 hours for one trio analysis, with an additional 4 hours on the GPU. Given that renting GPU servers( usually with less CPU) is more expensive than CPU servers and access to privately owned GPU servers is limited, it seems inefficient to run lengthy CPU processes on a GPU server. It feels like a bit of a waste, and sometimes I half-jokingly feel there might be someone out there with murderous intent because of it! Would it be possible in future updates to partition the DeepTrio analysis into separate steps? This way, CPU-intensive tasks could be completed on a CPU server, and then the job could be transferred to a GPU server for the remaining tasks. Alternatively, could the data preparation (CPU) and analysis (GPU) be run at the same time? This would help optimize resource usage and reduce costs. Thank you for considering these suggestions.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/873
https://github.com/google/deepvariant/issues/873:773,energy efficiency,CPU,CPU-intensive,773,"CPU and GPU using ; Hello,. I've been using DeepTrio for de novo variant analysis, and it's been performing excellently. However, I noticed from the logs that DeepTrio uses the CPU to prepare data, which is quite time-consuming. In my case, it took 12 hours for one trio analysis, with an additional 4 hours on the GPU. Given that renting GPU servers( usually with less CPU) is more expensive than CPU servers and access to privately owned GPU servers is limited, it seems inefficient to run lengthy CPU processes on a GPU server. It feels like a bit of a waste, and sometimes I half-jokingly feel there might be someone out there with murderous intent because of it! Would it be possible in future updates to partition the DeepTrio analysis into separate steps? This way, CPU-intensive tasks could be completed on a CPU server, and then the job could be transferred to a GPU server for the remaining tasks. Alternatively, could the data preparation (CPU) and analysis (GPU) be run at the same time? This would help optimize resource usage and reduce costs. Thank you for considering these suggestions.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/873
https://github.com/google/deepvariant/issues/873:817,energy efficiency,CPU,CPU,817,"CPU and GPU using ; Hello,. I've been using DeepTrio for de novo variant analysis, and it's been performing excellently. However, I noticed from the logs that DeepTrio uses the CPU to prepare data, which is quite time-consuming. In my case, it took 12 hours for one trio analysis, with an additional 4 hours on the GPU. Given that renting GPU servers( usually with less CPU) is more expensive than CPU servers and access to privately owned GPU servers is limited, it seems inefficient to run lengthy CPU processes on a GPU server. It feels like a bit of a waste, and sometimes I half-jokingly feel there might be someone out there with murderous intent because of it! Would it be possible in future updates to partition the DeepTrio analysis into separate steps? This way, CPU-intensive tasks could be completed on a CPU server, and then the job could be transferred to a GPU server for the remaining tasks. Alternatively, could the data preparation (CPU) and analysis (GPU) be run at the same time? This would help optimize resource usage and reduce costs. Thank you for considering these suggestions.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/873
https://github.com/google/deepvariant/issues/873:872,energy efficiency,GPU,GPU,872,"CPU and GPU using ; Hello,. I've been using DeepTrio for de novo variant analysis, and it's been performing excellently. However, I noticed from the logs that DeepTrio uses the CPU to prepare data, which is quite time-consuming. In my case, it took 12 hours for one trio analysis, with an additional 4 hours on the GPU. Given that renting GPU servers( usually with less CPU) is more expensive than CPU servers and access to privately owned GPU servers is limited, it seems inefficient to run lengthy CPU processes on a GPU server. It feels like a bit of a waste, and sometimes I half-jokingly feel there might be someone out there with murderous intent because of it! Would it be possible in future updates to partition the DeepTrio analysis into separate steps? This way, CPU-intensive tasks could be completed on a CPU server, and then the job could be transferred to a GPU server for the remaining tasks. Alternatively, could the data preparation (CPU) and analysis (GPU) be run at the same time? This would help optimize resource usage and reduce costs. Thank you for considering these suggestions.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/873
https://github.com/google/deepvariant/issues/873:951,energy efficiency,CPU,CPU,951,"CPU and GPU using ; Hello,. I've been using DeepTrio for de novo variant analysis, and it's been performing excellently. However, I noticed from the logs that DeepTrio uses the CPU to prepare data, which is quite time-consuming. In my case, it took 12 hours for one trio analysis, with an additional 4 hours on the GPU. Given that renting GPU servers( usually with less CPU) is more expensive than CPU servers and access to privately owned GPU servers is limited, it seems inefficient to run lengthy CPU processes on a GPU server. It feels like a bit of a waste, and sometimes I half-jokingly feel there might be someone out there with murderous intent because of it! Would it be possible in future updates to partition the DeepTrio analysis into separate steps? This way, CPU-intensive tasks could be completed on a CPU server, and then the job could be transferred to a GPU server for the remaining tasks. Alternatively, could the data preparation (CPU) and analysis (GPU) be run at the same time? This would help optimize resource usage and reduce costs. Thank you for considering these suggestions.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/873
https://github.com/google/deepvariant/issues/873:970,energy efficiency,GPU,GPU,970,"CPU and GPU using ; Hello,. I've been using DeepTrio for de novo variant analysis, and it's been performing excellently. However, I noticed from the logs that DeepTrio uses the CPU to prepare data, which is quite time-consuming. In my case, it took 12 hours for one trio analysis, with an additional 4 hours on the GPU. Given that renting GPU servers( usually with less CPU) is more expensive than CPU servers and access to privately owned GPU servers is limited, it seems inefficient to run lengthy CPU processes on a GPU server. It feels like a bit of a waste, and sometimes I half-jokingly feel there might be someone out there with murderous intent because of it! Would it be possible in future updates to partition the DeepTrio analysis into separate steps? This way, CPU-intensive tasks could be completed on a CPU server, and then the job could be transferred to a GPU server for the remaining tasks. Alternatively, could the data preparation (CPU) and analysis (GPU) be run at the same time? This would help optimize resource usage and reduce costs. Thank you for considering these suggestions.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/873
https://github.com/google/deepvariant/issues/873:1016,energy efficiency,optim,optimize,1016,"CPU and GPU using ; Hello,. I've been using DeepTrio for de novo variant analysis, and it's been performing excellently. However, I noticed from the logs that DeepTrio uses the CPU to prepare data, which is quite time-consuming. In my case, it took 12 hours for one trio analysis, with an additional 4 hours on the GPU. Given that renting GPU servers( usually with less CPU) is more expensive than CPU servers and access to privately owned GPU servers is limited, it seems inefficient to run lengthy CPU processes on a GPU server. It feels like a bit of a waste, and sometimes I half-jokingly feel there might be someone out there with murderous intent because of it! Would it be possible in future updates to partition the DeepTrio analysis into separate steps? This way, CPU-intensive tasks could be completed on a CPU server, and then the job could be transferred to a GPU server for the remaining tasks. Alternatively, could the data preparation (CPU) and analysis (GPU) be run at the same time? This would help optimize resource usage and reduce costs. Thank you for considering these suggestions.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/873
https://github.com/google/deepvariant/issues/873:1025,energy efficiency,resource usag,resource usage,1025,"CPU and GPU using ; Hello,. I've been using DeepTrio for de novo variant analysis, and it's been performing excellently. However, I noticed from the logs that DeepTrio uses the CPU to prepare data, which is quite time-consuming. In my case, it took 12 hours for one trio analysis, with an additional 4 hours on the GPU. Given that renting GPU servers( usually with less CPU) is more expensive than CPU servers and access to privately owned GPU servers is limited, it seems inefficient to run lengthy CPU processes on a GPU server. It feels like a bit of a waste, and sometimes I half-jokingly feel there might be someone out there with murderous intent because of it! Would it be possible in future updates to partition the DeepTrio analysis into separate steps? This way, CPU-intensive tasks could be completed on a CPU server, and then the job could be transferred to a GPU server for the remaining tasks. Alternatively, could the data preparation (CPU) and analysis (GPU) be run at the same time? This would help optimize resource usage and reduce costs. Thank you for considering these suggestions.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/873
https://github.com/google/deepvariant/issues/873:1044,energy efficiency,reduc,reduce,1044,"CPU and GPU using ; Hello,. I've been using DeepTrio for de novo variant analysis, and it's been performing excellently. However, I noticed from the logs that DeepTrio uses the CPU to prepare data, which is quite time-consuming. In my case, it took 12 hours for one trio analysis, with an additional 4 hours on the GPU. Given that renting GPU servers( usually with less CPU) is more expensive than CPU servers and access to privately owned GPU servers is limited, it seems inefficient to run lengthy CPU processes on a GPU server. It feels like a bit of a waste, and sometimes I half-jokingly feel there might be someone out there with murderous intent because of it! Would it be possible in future updates to partition the DeepTrio analysis into separate steps? This way, CPU-intensive tasks could be completed on a CPU server, and then the job could be transferred to a GPU server for the remaining tasks. Alternatively, could the data preparation (CPU) and analysis (GPU) be run at the same time? This would help optimize resource usage and reduce costs. Thank you for considering these suggestions.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/873
https://github.com/google/deepvariant/issues/873:0,performance,CPU,CPU,0,"CPU and GPU using ; Hello,. I've been using DeepTrio for de novo variant analysis, and it's been performing excellently. However, I noticed from the logs that DeepTrio uses the CPU to prepare data, which is quite time-consuming. In my case, it took 12 hours for one trio analysis, with an additional 4 hours on the GPU. Given that renting GPU servers( usually with less CPU) is more expensive than CPU servers and access to privately owned GPU servers is limited, it seems inefficient to run lengthy CPU processes on a GPU server. It feels like a bit of a waste, and sometimes I half-jokingly feel there might be someone out there with murderous intent because of it! Would it be possible in future updates to partition the DeepTrio analysis into separate steps? This way, CPU-intensive tasks could be completed on a CPU server, and then the job could be transferred to a GPU server for the remaining tasks. Alternatively, could the data preparation (CPU) and analysis (GPU) be run at the same time? This would help optimize resource usage and reduce costs. Thank you for considering these suggestions.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/873
https://github.com/google/deepvariant/issues/873:8,performance,GPU,GPU,8,"CPU and GPU using ; Hello,. I've been using DeepTrio for de novo variant analysis, and it's been performing excellently. However, I noticed from the logs that DeepTrio uses the CPU to prepare data, which is quite time-consuming. In my case, it took 12 hours for one trio analysis, with an additional 4 hours on the GPU. Given that renting GPU servers( usually with less CPU) is more expensive than CPU servers and access to privately owned GPU servers is limited, it seems inefficient to run lengthy CPU processes on a GPU server. It feels like a bit of a waste, and sometimes I half-jokingly feel there might be someone out there with murderous intent because of it! Would it be possible in future updates to partition the DeepTrio analysis into separate steps? This way, CPU-intensive tasks could be completed on a CPU server, and then the job could be transferred to a GPU server for the remaining tasks. Alternatively, could the data preparation (CPU) and analysis (GPU) be run at the same time? This would help optimize resource usage and reduce costs. Thank you for considering these suggestions.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/873
https://github.com/google/deepvariant/issues/873:97,performance,perform,performing,97,"CPU and GPU using ; Hello,. I've been using DeepTrio for de novo variant analysis, and it's been performing excellently. However, I noticed from the logs that DeepTrio uses the CPU to prepare data, which is quite time-consuming. In my case, it took 12 hours for one trio analysis, with an additional 4 hours on the GPU. Given that renting GPU servers( usually with less CPU) is more expensive than CPU servers and access to privately owned GPU servers is limited, it seems inefficient to run lengthy CPU processes on a GPU server. It feels like a bit of a waste, and sometimes I half-jokingly feel there might be someone out there with murderous intent because of it! Would it be possible in future updates to partition the DeepTrio analysis into separate steps? This way, CPU-intensive tasks could be completed on a CPU server, and then the job could be transferred to a GPU server for the remaining tasks. Alternatively, could the data preparation (CPU) and analysis (GPU) be run at the same time? This would help optimize resource usage and reduce costs. Thank you for considering these suggestions.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/873
https://github.com/google/deepvariant/issues/873:177,performance,CPU,CPU,177,"CPU and GPU using ; Hello,. I've been using DeepTrio for de novo variant analysis, and it's been performing excellently. However, I noticed from the logs that DeepTrio uses the CPU to prepare data, which is quite time-consuming. In my case, it took 12 hours for one trio analysis, with an additional 4 hours on the GPU. Given that renting GPU servers( usually with less CPU) is more expensive than CPU servers and access to privately owned GPU servers is limited, it seems inefficient to run lengthy CPU processes on a GPU server. It feels like a bit of a waste, and sometimes I half-jokingly feel there might be someone out there with murderous intent because of it! Would it be possible in future updates to partition the DeepTrio analysis into separate steps? This way, CPU-intensive tasks could be completed on a CPU server, and then the job could be transferred to a GPU server for the remaining tasks. Alternatively, could the data preparation (CPU) and analysis (GPU) be run at the same time? This would help optimize resource usage and reduce costs. Thank you for considering these suggestions.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/873
https://github.com/google/deepvariant/issues/873:213,performance,time,time-consuming,213,"CPU and GPU using ; Hello,. I've been using DeepTrio for de novo variant analysis, and it's been performing excellently. However, I noticed from the logs that DeepTrio uses the CPU to prepare data, which is quite time-consuming. In my case, it took 12 hours for one trio analysis, with an additional 4 hours on the GPU. Given that renting GPU servers( usually with less CPU) is more expensive than CPU servers and access to privately owned GPU servers is limited, it seems inefficient to run lengthy CPU processes on a GPU server. It feels like a bit of a waste, and sometimes I half-jokingly feel there might be someone out there with murderous intent because of it! Would it be possible in future updates to partition the DeepTrio analysis into separate steps? This way, CPU-intensive tasks could be completed on a CPU server, and then the job could be transferred to a GPU server for the remaining tasks. Alternatively, could the data preparation (CPU) and analysis (GPU) be run at the same time? This would help optimize resource usage and reduce costs. Thank you for considering these suggestions.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/873
https://github.com/google/deepvariant/issues/873:315,performance,GPU,GPU,315,"CPU and GPU using ; Hello,. I've been using DeepTrio for de novo variant analysis, and it's been performing excellently. However, I noticed from the logs that DeepTrio uses the CPU to prepare data, which is quite time-consuming. In my case, it took 12 hours for one trio analysis, with an additional 4 hours on the GPU. Given that renting GPU servers( usually with less CPU) is more expensive than CPU servers and access to privately owned GPU servers is limited, it seems inefficient to run lengthy CPU processes on a GPU server. It feels like a bit of a waste, and sometimes I half-jokingly feel there might be someone out there with murderous intent because of it! Would it be possible in future updates to partition the DeepTrio analysis into separate steps? This way, CPU-intensive tasks could be completed on a CPU server, and then the job could be transferred to a GPU server for the remaining tasks. Alternatively, could the data preparation (CPU) and analysis (GPU) be run at the same time? This would help optimize resource usage and reduce costs. Thank you for considering these suggestions.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/873
https://github.com/google/deepvariant/issues/873:339,performance,GPU,GPU,339,"CPU and GPU using ; Hello,. I've been using DeepTrio for de novo variant analysis, and it's been performing excellently. However, I noticed from the logs that DeepTrio uses the CPU to prepare data, which is quite time-consuming. In my case, it took 12 hours for one trio analysis, with an additional 4 hours on the GPU. Given that renting GPU servers( usually with less CPU) is more expensive than CPU servers and access to privately owned GPU servers is limited, it seems inefficient to run lengthy CPU processes on a GPU server. It feels like a bit of a waste, and sometimes I half-jokingly feel there might be someone out there with murderous intent because of it! Would it be possible in future updates to partition the DeepTrio analysis into separate steps? This way, CPU-intensive tasks could be completed on a CPU server, and then the job could be transferred to a GPU server for the remaining tasks. Alternatively, could the data preparation (CPU) and analysis (GPU) be run at the same time? This would help optimize resource usage and reduce costs. Thank you for considering these suggestions.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/873
https://github.com/google/deepvariant/issues/873:370,performance,CPU,CPU,370,"CPU and GPU using ; Hello,. I've been using DeepTrio for de novo variant analysis, and it's been performing excellently. However, I noticed from the logs that DeepTrio uses the CPU to prepare data, which is quite time-consuming. In my case, it took 12 hours for one trio analysis, with an additional 4 hours on the GPU. Given that renting GPU servers( usually with less CPU) is more expensive than CPU servers and access to privately owned GPU servers is limited, it seems inefficient to run lengthy CPU processes on a GPU server. It feels like a bit of a waste, and sometimes I half-jokingly feel there might be someone out there with murderous intent because of it! Would it be possible in future updates to partition the DeepTrio analysis into separate steps? This way, CPU-intensive tasks could be completed on a CPU server, and then the job could be transferred to a GPU server for the remaining tasks. Alternatively, could the data preparation (CPU) and analysis (GPU) be run at the same time? This would help optimize resource usage and reduce costs. Thank you for considering these suggestions.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/873
https://github.com/google/deepvariant/issues/873:398,performance,CPU,CPU,398,"CPU and GPU using ; Hello,. I've been using DeepTrio for de novo variant analysis, and it's been performing excellently. However, I noticed from the logs that DeepTrio uses the CPU to prepare data, which is quite time-consuming. In my case, it took 12 hours for one trio analysis, with an additional 4 hours on the GPU. Given that renting GPU servers( usually with less CPU) is more expensive than CPU servers and access to privately owned GPU servers is limited, it seems inefficient to run lengthy CPU processes on a GPU server. It feels like a bit of a waste, and sometimes I half-jokingly feel there might be someone out there with murderous intent because of it! Would it be possible in future updates to partition the DeepTrio analysis into separate steps? This way, CPU-intensive tasks could be completed on a CPU server, and then the job could be transferred to a GPU server for the remaining tasks. Alternatively, could the data preparation (CPU) and analysis (GPU) be run at the same time? This would help optimize resource usage and reduce costs. Thank you for considering these suggestions.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/873
https://github.com/google/deepvariant/issues/873:440,performance,GPU,GPU,440,"CPU and GPU using ; Hello,. I've been using DeepTrio for de novo variant analysis, and it's been performing excellently. However, I noticed from the logs that DeepTrio uses the CPU to prepare data, which is quite time-consuming. In my case, it took 12 hours for one trio analysis, with an additional 4 hours on the GPU. Given that renting GPU servers( usually with less CPU) is more expensive than CPU servers and access to privately owned GPU servers is limited, it seems inefficient to run lengthy CPU processes on a GPU server. It feels like a bit of a waste, and sometimes I half-jokingly feel there might be someone out there with murderous intent because of it! Would it be possible in future updates to partition the DeepTrio analysis into separate steps? This way, CPU-intensive tasks could be completed on a CPU server, and then the job could be transferred to a GPU server for the remaining tasks. Alternatively, could the data preparation (CPU) and analysis (GPU) be run at the same time? This would help optimize resource usage and reduce costs. Thank you for considering these suggestions.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/873
https://github.com/google/deepvariant/issues/873:500,performance,CPU,CPU,500,"CPU and GPU using ; Hello,. I've been using DeepTrio for de novo variant analysis, and it's been performing excellently. However, I noticed from the logs that DeepTrio uses the CPU to prepare data, which is quite time-consuming. In my case, it took 12 hours for one trio analysis, with an additional 4 hours on the GPU. Given that renting GPU servers( usually with less CPU) is more expensive than CPU servers and access to privately owned GPU servers is limited, it seems inefficient to run lengthy CPU processes on a GPU server. It feels like a bit of a waste, and sometimes I half-jokingly feel there might be someone out there with murderous intent because of it! Would it be possible in future updates to partition the DeepTrio analysis into separate steps? This way, CPU-intensive tasks could be completed on a CPU server, and then the job could be transferred to a GPU server for the remaining tasks. Alternatively, could the data preparation (CPU) and analysis (GPU) be run at the same time? This would help optimize resource usage and reduce costs. Thank you for considering these suggestions.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/873
https://github.com/google/deepvariant/issues/873:519,performance,GPU,GPU,519,"CPU and GPU using ; Hello,. I've been using DeepTrio for de novo variant analysis, and it's been performing excellently. However, I noticed from the logs that DeepTrio uses the CPU to prepare data, which is quite time-consuming. In my case, it took 12 hours for one trio analysis, with an additional 4 hours on the GPU. Given that renting GPU servers( usually with less CPU) is more expensive than CPU servers and access to privately owned GPU servers is limited, it seems inefficient to run lengthy CPU processes on a GPU server. It feels like a bit of a waste, and sometimes I half-jokingly feel there might be someone out there with murderous intent because of it! Would it be possible in future updates to partition the DeepTrio analysis into separate steps? This way, CPU-intensive tasks could be completed on a CPU server, and then the job could be transferred to a GPU server for the remaining tasks. Alternatively, could the data preparation (CPU) and analysis (GPU) be run at the same time? This would help optimize resource usage and reduce costs. Thank you for considering these suggestions.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/873
https://github.com/google/deepvariant/issues/873:773,performance,CPU,CPU-intensive,773,"CPU and GPU using ; Hello,. I've been using DeepTrio for de novo variant analysis, and it's been performing excellently. However, I noticed from the logs that DeepTrio uses the CPU to prepare data, which is quite time-consuming. In my case, it took 12 hours for one trio analysis, with an additional 4 hours on the GPU. Given that renting GPU servers( usually with less CPU) is more expensive than CPU servers and access to privately owned GPU servers is limited, it seems inefficient to run lengthy CPU processes on a GPU server. It feels like a bit of a waste, and sometimes I half-jokingly feel there might be someone out there with murderous intent because of it! Would it be possible in future updates to partition the DeepTrio analysis into separate steps? This way, CPU-intensive tasks could be completed on a CPU server, and then the job could be transferred to a GPU server for the remaining tasks. Alternatively, could the data preparation (CPU) and analysis (GPU) be run at the same time? This would help optimize resource usage and reduce costs. Thank you for considering these suggestions.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/873
https://github.com/google/deepvariant/issues/873:817,performance,CPU,CPU,817,"CPU and GPU using ; Hello,. I've been using DeepTrio for de novo variant analysis, and it's been performing excellently. However, I noticed from the logs that DeepTrio uses the CPU to prepare data, which is quite time-consuming. In my case, it took 12 hours for one trio analysis, with an additional 4 hours on the GPU. Given that renting GPU servers( usually with less CPU) is more expensive than CPU servers and access to privately owned GPU servers is limited, it seems inefficient to run lengthy CPU processes on a GPU server. It feels like a bit of a waste, and sometimes I half-jokingly feel there might be someone out there with murderous intent because of it! Would it be possible in future updates to partition the DeepTrio analysis into separate steps? This way, CPU-intensive tasks could be completed on a CPU server, and then the job could be transferred to a GPU server for the remaining tasks. Alternatively, could the data preparation (CPU) and analysis (GPU) be run at the same time? This would help optimize resource usage and reduce costs. Thank you for considering these suggestions.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/873
https://github.com/google/deepvariant/issues/873:872,performance,GPU,GPU,872,"CPU and GPU using ; Hello,. I've been using DeepTrio for de novo variant analysis, and it's been performing excellently. However, I noticed from the logs that DeepTrio uses the CPU to prepare data, which is quite time-consuming. In my case, it took 12 hours for one trio analysis, with an additional 4 hours on the GPU. Given that renting GPU servers( usually with less CPU) is more expensive than CPU servers and access to privately owned GPU servers is limited, it seems inefficient to run lengthy CPU processes on a GPU server. It feels like a bit of a waste, and sometimes I half-jokingly feel there might be someone out there with murderous intent because of it! Would it be possible in future updates to partition the DeepTrio analysis into separate steps? This way, CPU-intensive tasks could be completed on a CPU server, and then the job could be transferred to a GPU server for the remaining tasks. Alternatively, could the data preparation (CPU) and analysis (GPU) be run at the same time? This would help optimize resource usage and reduce costs. Thank you for considering these suggestions.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/873
https://github.com/google/deepvariant/issues/873:951,performance,CPU,CPU,951,"CPU and GPU using ; Hello,. I've been using DeepTrio for de novo variant analysis, and it's been performing excellently. However, I noticed from the logs that DeepTrio uses the CPU to prepare data, which is quite time-consuming. In my case, it took 12 hours for one trio analysis, with an additional 4 hours on the GPU. Given that renting GPU servers( usually with less CPU) is more expensive than CPU servers and access to privately owned GPU servers is limited, it seems inefficient to run lengthy CPU processes on a GPU server. It feels like a bit of a waste, and sometimes I half-jokingly feel there might be someone out there with murderous intent because of it! Would it be possible in future updates to partition the DeepTrio analysis into separate steps? This way, CPU-intensive tasks could be completed on a CPU server, and then the job could be transferred to a GPU server for the remaining tasks. Alternatively, could the data preparation (CPU) and analysis (GPU) be run at the same time? This would help optimize resource usage and reduce costs. Thank you for considering these suggestions.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/873
https://github.com/google/deepvariant/issues/873:970,performance,GPU,GPU,970,"CPU and GPU using ; Hello,. I've been using DeepTrio for de novo variant analysis, and it's been performing excellently. However, I noticed from the logs that DeepTrio uses the CPU to prepare data, which is quite time-consuming. In my case, it took 12 hours for one trio analysis, with an additional 4 hours on the GPU. Given that renting GPU servers( usually with less CPU) is more expensive than CPU servers and access to privately owned GPU servers is limited, it seems inefficient to run lengthy CPU processes on a GPU server. It feels like a bit of a waste, and sometimes I half-jokingly feel there might be someone out there with murderous intent because of it! Would it be possible in future updates to partition the DeepTrio analysis into separate steps? This way, CPU-intensive tasks could be completed on a CPU server, and then the job could be transferred to a GPU server for the remaining tasks. Alternatively, could the data preparation (CPU) and analysis (GPU) be run at the same time? This would help optimize resource usage and reduce costs. Thank you for considering these suggestions.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/873
https://github.com/google/deepvariant/issues/873:994,performance,time,time,994,"CPU and GPU using ; Hello,. I've been using DeepTrio for de novo variant analysis, and it's been performing excellently. However, I noticed from the logs that DeepTrio uses the CPU to prepare data, which is quite time-consuming. In my case, it took 12 hours for one trio analysis, with an additional 4 hours on the GPU. Given that renting GPU servers( usually with less CPU) is more expensive than CPU servers and access to privately owned GPU servers is limited, it seems inefficient to run lengthy CPU processes on a GPU server. It feels like a bit of a waste, and sometimes I half-jokingly feel there might be someone out there with murderous intent because of it! Would it be possible in future updates to partition the DeepTrio analysis into separate steps? This way, CPU-intensive tasks could be completed on a CPU server, and then the job could be transferred to a GPU server for the remaining tasks. Alternatively, could the data preparation (CPU) and analysis (GPU) be run at the same time? This would help optimize resource usage and reduce costs. Thank you for considering these suggestions.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/873
https://github.com/google/deepvariant/issues/873:1016,performance,optimiz,optimize,1016,"CPU and GPU using ; Hello,. I've been using DeepTrio for de novo variant analysis, and it's been performing excellently. However, I noticed from the logs that DeepTrio uses the CPU to prepare data, which is quite time-consuming. In my case, it took 12 hours for one trio analysis, with an additional 4 hours on the GPU. Given that renting GPU servers( usually with less CPU) is more expensive than CPU servers and access to privately owned GPU servers is limited, it seems inefficient to run lengthy CPU processes on a GPU server. It feels like a bit of a waste, and sometimes I half-jokingly feel there might be someone out there with murderous intent because of it! Would it be possible in future updates to partition the DeepTrio analysis into separate steps? This way, CPU-intensive tasks could be completed on a CPU server, and then the job could be transferred to a GPU server for the remaining tasks. Alternatively, could the data preparation (CPU) and analysis (GPU) be run at the same time? This would help optimize resource usage and reduce costs. Thank you for considering these suggestions.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/873
https://github.com/google/deepvariant/issues/873:1025,performance,resourc,resource,1025,"CPU and GPU using ; Hello,. I've been using DeepTrio for de novo variant analysis, and it's been performing excellently. However, I noticed from the logs that DeepTrio uses the CPU to prepare data, which is quite time-consuming. In my case, it took 12 hours for one trio analysis, with an additional 4 hours on the GPU. Given that renting GPU servers( usually with less CPU) is more expensive than CPU servers and access to privately owned GPU servers is limited, it seems inefficient to run lengthy CPU processes on a GPU server. It feels like a bit of a waste, and sometimes I half-jokingly feel there might be someone out there with murderous intent because of it! Would it be possible in future updates to partition the DeepTrio analysis into separate steps? This way, CPU-intensive tasks could be completed on a CPU server, and then the job could be transferred to a GPU server for the remaining tasks. Alternatively, could the data preparation (CPU) and analysis (GPU) be run at the same time? This would help optimize resource usage and reduce costs. Thank you for considering these suggestions.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/873
https://github.com/google/deepvariant/issues/873:149,safety,log,logs,149,"CPU and GPU using ; Hello,. I've been using DeepTrio for de novo variant analysis, and it's been performing excellently. However, I noticed from the logs that DeepTrio uses the CPU to prepare data, which is quite time-consuming. In my case, it took 12 hours for one trio analysis, with an additional 4 hours on the GPU. Given that renting GPU servers( usually with less CPU) is more expensive than CPU servers and access to privately owned GPU servers is limited, it seems inefficient to run lengthy CPU processes on a GPU server. It feels like a bit of a waste, and sometimes I half-jokingly feel there might be someone out there with murderous intent because of it! Would it be possible in future updates to partition the DeepTrio analysis into separate steps? This way, CPU-intensive tasks could be completed on a CPU server, and then the job could be transferred to a GPU server for the remaining tasks. Alternatively, could the data preparation (CPU) and analysis (GPU) be run at the same time? This would help optimize resource usage and reduce costs. Thank you for considering these suggestions.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/873
https://github.com/google/deepvariant/issues/873:699,safety,updat,updates,699,"CPU and GPU using ; Hello,. I've been using DeepTrio for de novo variant analysis, and it's been performing excellently. However, I noticed from the logs that DeepTrio uses the CPU to prepare data, which is quite time-consuming. In my case, it took 12 hours for one trio analysis, with an additional 4 hours on the GPU. Given that renting GPU servers( usually with less CPU) is more expensive than CPU servers and access to privately owned GPU servers is limited, it seems inefficient to run lengthy CPU processes on a GPU server. It feels like a bit of a waste, and sometimes I half-jokingly feel there might be someone out there with murderous intent because of it! Would it be possible in future updates to partition the DeepTrio analysis into separate steps? This way, CPU-intensive tasks could be completed on a CPU server, and then the job could be transferred to a GPU server for the remaining tasks. Alternatively, could the data preparation (CPU) and analysis (GPU) be run at the same time? This would help optimize resource usage and reduce costs. Thank you for considering these suggestions.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/873
https://github.com/google/deepvariant/issues/873:802,safety,compl,completed,802,"CPU and GPU using ; Hello,. I've been using DeepTrio for de novo variant analysis, and it's been performing excellently. However, I noticed from the logs that DeepTrio uses the CPU to prepare data, which is quite time-consuming. In my case, it took 12 hours for one trio analysis, with an additional 4 hours on the GPU. Given that renting GPU servers( usually with less CPU) is more expensive than CPU servers and access to privately owned GPU servers is limited, it seems inefficient to run lengthy CPU processes on a GPU server. It feels like a bit of a waste, and sometimes I half-jokingly feel there might be someone out there with murderous intent because of it! Would it be possible in future updates to partition the DeepTrio analysis into separate steps? This way, CPU-intensive tasks could be completed on a CPU server, and then the job could be transferred to a GPU server for the remaining tasks. Alternatively, could the data preparation (CPU) and analysis (GPU) be run at the same time? This would help optimize resource usage and reduce costs. Thank you for considering these suggestions.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/873
https://github.com/google/deepvariant/issues/873:1025,safety,resourc,resource,1025,"CPU and GPU using ; Hello,. I've been using DeepTrio for de novo variant analysis, and it's been performing excellently. However, I noticed from the logs that DeepTrio uses the CPU to prepare data, which is quite time-consuming. In my case, it took 12 hours for one trio analysis, with an additional 4 hours on the GPU. Given that renting GPU servers( usually with less CPU) is more expensive than CPU servers and access to privately owned GPU servers is limited, it seems inefficient to run lengthy CPU processes on a GPU server. It feels like a bit of a waste, and sometimes I half-jokingly feel there might be someone out there with murderous intent because of it! Would it be possible in future updates to partition the DeepTrio analysis into separate steps? This way, CPU-intensive tasks could be completed on a CPU server, and then the job could be transferred to a GPU server for the remaining tasks. Alternatively, could the data preparation (CPU) and analysis (GPU) be run at the same time? This would help optimize resource usage and reduce costs. Thank you for considering these suggestions.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/873
https://github.com/google/deepvariant/issues/873:149,security,log,logs,149,"CPU and GPU using ; Hello,. I've been using DeepTrio for de novo variant analysis, and it's been performing excellently. However, I noticed from the logs that DeepTrio uses the CPU to prepare data, which is quite time-consuming. In my case, it took 12 hours for one trio analysis, with an additional 4 hours on the GPU. Given that renting GPU servers( usually with less CPU) is more expensive than CPU servers and access to privately owned GPU servers is limited, it seems inefficient to run lengthy CPU processes on a GPU server. It feels like a bit of a waste, and sometimes I half-jokingly feel there might be someone out there with murderous intent because of it! Would it be possible in future updates to partition the DeepTrio analysis into separate steps? This way, CPU-intensive tasks could be completed on a CPU server, and then the job could be transferred to a GPU server for the remaining tasks. Alternatively, could the data preparation (CPU) and analysis (GPU) be run at the same time? This would help optimize resource usage and reduce costs. Thank you for considering these suggestions.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/873
https://github.com/google/deepvariant/issues/873:414,security,access,access,414,"CPU and GPU using ; Hello,. I've been using DeepTrio for de novo variant analysis, and it's been performing excellently. However, I noticed from the logs that DeepTrio uses the CPU to prepare data, which is quite time-consuming. In my case, it took 12 hours for one trio analysis, with an additional 4 hours on the GPU. Given that renting GPU servers( usually with less CPU) is more expensive than CPU servers and access to privately owned GPU servers is limited, it seems inefficient to run lengthy CPU processes on a GPU server. It feels like a bit of a waste, and sometimes I half-jokingly feel there might be someone out there with murderous intent because of it! Would it be possible in future updates to partition the DeepTrio analysis into separate steps? This way, CPU-intensive tasks could be completed on a CPU server, and then the job could be transferred to a GPU server for the remaining tasks. Alternatively, could the data preparation (CPU) and analysis (GPU) be run at the same time? This would help optimize resource usage and reduce costs. Thank you for considering these suggestions.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/873
https://github.com/google/deepvariant/issues/873:699,security,updat,updates,699,"CPU and GPU using ; Hello,. I've been using DeepTrio for de novo variant analysis, and it's been performing excellently. However, I noticed from the logs that DeepTrio uses the CPU to prepare data, which is quite time-consuming. In my case, it took 12 hours for one trio analysis, with an additional 4 hours on the GPU. Given that renting GPU servers( usually with less CPU) is more expensive than CPU servers and access to privately owned GPU servers is limited, it seems inefficient to run lengthy CPU processes on a GPU server. It feels like a bit of a waste, and sometimes I half-jokingly feel there might be someone out there with murderous intent because of it! Would it be possible in future updates to partition the DeepTrio analysis into separate steps? This way, CPU-intensive tasks could be completed on a CPU server, and then the job could be transferred to a GPU server for the remaining tasks. Alternatively, could the data preparation (CPU) and analysis (GPU) be run at the same time? This would help optimize resource usage and reduce costs. Thank you for considering these suggestions.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/873
https://github.com/google/deepvariant/issues/873:802,security,compl,completed,802,"CPU and GPU using ; Hello,. I've been using DeepTrio for de novo variant analysis, and it's been performing excellently. However, I noticed from the logs that DeepTrio uses the CPU to prepare data, which is quite time-consuming. In my case, it took 12 hours for one trio analysis, with an additional 4 hours on the GPU. Given that renting GPU servers( usually with less CPU) is more expensive than CPU servers and access to privately owned GPU servers is limited, it seems inefficient to run lengthy CPU processes on a GPU server. It feels like a bit of a waste, and sometimes I half-jokingly feel there might be someone out there with murderous intent because of it! Would it be possible in future updates to partition the DeepTrio analysis into separate steps? This way, CPU-intensive tasks could be completed on a CPU server, and then the job could be transferred to a GPU server for the remaining tasks. Alternatively, could the data preparation (CPU) and analysis (GPU) be run at the same time? This would help optimize resource usage and reduce costs. Thank you for considering these suggestions.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/873
https://github.com/google/deepvariant/issues/873:149,testability,log,logs,149,"CPU and GPU using ; Hello,. I've been using DeepTrio for de novo variant analysis, and it's been performing excellently. However, I noticed from the logs that DeepTrio uses the CPU to prepare data, which is quite time-consuming. In my case, it took 12 hours for one trio analysis, with an additional 4 hours on the GPU. Given that renting GPU servers( usually with less CPU) is more expensive than CPU servers and access to privately owned GPU servers is limited, it seems inefficient to run lengthy CPU processes on a GPU server. It feels like a bit of a waste, and sometimes I half-jokingly feel there might be someone out there with murderous intent because of it! Would it be possible in future updates to partition the DeepTrio analysis into separate steps? This way, CPU-intensive tasks could be completed on a CPU server, and then the job could be transferred to a GPU server for the remaining tasks. Alternatively, could the data preparation (CPU) and analysis (GPU) be run at the same time? This would help optimize resource usage and reduce costs. Thank you for considering these suggestions.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/873
https://github.com/google/deepvariant/issues/873:1025,testability,resourc,resource,1025,"CPU and GPU using ; Hello,. I've been using DeepTrio for de novo variant analysis, and it's been performing excellently. However, I noticed from the logs that DeepTrio uses the CPU to prepare data, which is quite time-consuming. In my case, it took 12 hours for one trio analysis, with an additional 4 hours on the GPU. Given that renting GPU servers( usually with less CPU) is more expensive than CPU servers and access to privately owned GPU servers is limited, it seems inefficient to run lengthy CPU processes on a GPU server. It feels like a bit of a waste, and sometimes I half-jokingly feel there might be someone out there with murderous intent because of it! Would it be possible in future updates to partition the DeepTrio analysis into separate steps? This way, CPU-intensive tasks could be completed on a CPU server, and then the job could be transferred to a GPU server for the remaining tasks. Alternatively, could the data preparation (CPU) and analysis (GPU) be run at the same time? This would help optimize resource usage and reduce costs. Thank you for considering these suggestions.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/873
https://github.com/google/deepvariant/issues/873:97,usability,perform,performing,97,"CPU and GPU using ; Hello,. I've been using DeepTrio for de novo variant analysis, and it's been performing excellently. However, I noticed from the logs that DeepTrio uses the CPU to prepare data, which is quite time-consuming. In my case, it took 12 hours for one trio analysis, with an additional 4 hours on the GPU. Given that renting GPU servers( usually with less CPU) is more expensive than CPU servers and access to privately owned GPU servers is limited, it seems inefficient to run lengthy CPU processes on a GPU server. It feels like a bit of a waste, and sometimes I half-jokingly feel there might be someone out there with murderous intent because of it! Would it be possible in future updates to partition the DeepTrio analysis into separate steps? This way, CPU-intensive tasks could be completed on a CPU server, and then the job could be transferred to a GPU server for the remaining tasks. Alternatively, could the data preparation (CPU) and analysis (GPU) be run at the same time? This would help optimize resource usage and reduce costs. Thank you for considering these suggestions.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/873
https://github.com/google/deepvariant/issues/873:1011,usability,help,help,1011,"CPU and GPU using ; Hello,. I've been using DeepTrio for de novo variant analysis, and it's been performing excellently. However, I noticed from the logs that DeepTrio uses the CPU to prepare data, which is quite time-consuming. In my case, it took 12 hours for one trio analysis, with an additional 4 hours on the GPU. Given that renting GPU servers( usually with less CPU) is more expensive than CPU servers and access to privately owned GPU servers is limited, it seems inefficient to run lengthy CPU processes on a GPU server. It feels like a bit of a waste, and sometimes I half-jokingly feel there might be someone out there with murderous intent because of it! Would it be possible in future updates to partition the DeepTrio analysis into separate steps? This way, CPU-intensive tasks could be completed on a CPU server, and then the job could be transferred to a GPU server for the remaining tasks. Alternatively, could the data preparation (CPU) and analysis (GPU) be run at the same time? This would help optimize resource usage and reduce costs. Thank you for considering these suggestions.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/873
https://github.com/google/deepvariant/issues/874:194,deployability,observ,observe,194,"Deepvariant Structural Variants for ONT; Hi All,. When using the DeepVariant model type ONT_R104, does it also call structural variants (SVs), specifically ones between 0 and 30bp in length? We observe tools such as Sniffles and CuteSV typically identify SVs with a minimum length of 30bp, while Clair3 can detect SVs up to 50bp. Thank you!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/874
https://github.com/google/deepvariant/issues/874:77,energy efficiency,model,model,77,"Deepvariant Structural Variants for ONT; Hi All,. When using the DeepVariant model type ONT_R104, does it also call structural variants (SVs), specifically ones between 0 and 30bp in length? We observe tools such as Sniffles and CuteSV typically identify SVs with a minimum length of 30bp, while Clair3 can detect SVs up to 50bp. Thank you!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/874
https://github.com/google/deepvariant/issues/874:143,interoperability,specif,specifically,143,"Deepvariant Structural Variants for ONT; Hi All,. When using the DeepVariant model type ONT_R104, does it also call structural variants (SVs), specifically ones between 0 and 30bp in length? We observe tools such as Sniffles and CuteSV typically identify SVs with a minimum length of 30bp, while Clair3 can detect SVs up to 50bp. Thank you!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/874
https://github.com/google/deepvariant/issues/874:98,reliability,doe,does,98,"Deepvariant Structural Variants for ONT; Hi All,. When using the DeepVariant model type ONT_R104, does it also call structural variants (SVs), specifically ones between 0 and 30bp in length? We observe tools such as Sniffles and CuteSV typically identify SVs with a minimum length of 30bp, while Clair3 can detect SVs up to 50bp. Thank you!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/874
https://github.com/google/deepvariant/issues/874:307,safety,detect,detect,307,"Deepvariant Structural Variants for ONT; Hi All,. When using the DeepVariant model type ONT_R104, does it also call structural variants (SVs), specifically ones between 0 and 30bp in length? We observe tools such as Sniffles and CuteSV typically identify SVs with a minimum length of 30bp, while Clair3 can detect SVs up to 50bp. Thank you!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/874
https://github.com/google/deepvariant/issues/874:77,security,model,model,77,"Deepvariant Structural Variants for ONT; Hi All,. When using the DeepVariant model type ONT_R104, does it also call structural variants (SVs), specifically ones between 0 and 30bp in length? We observe tools such as Sniffles and CuteSV typically identify SVs with a minimum length of 30bp, while Clair3 can detect SVs up to 50bp. Thank you!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/874
https://github.com/google/deepvariant/issues/874:246,security,ident,identify,246,"Deepvariant Structural Variants for ONT; Hi All,. When using the DeepVariant model type ONT_R104, does it also call structural variants (SVs), specifically ones between 0 and 30bp in length? We observe tools such as Sniffles and CuteSV typically identify SVs with a minimum length of 30bp, while Clair3 can detect SVs up to 50bp. Thank you!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/874
https://github.com/google/deepvariant/issues/874:307,security,detect,detect,307,"Deepvariant Structural Variants for ONT; Hi All,. When using the DeepVariant model type ONT_R104, does it also call structural variants (SVs), specifically ones between 0 and 30bp in length? We observe tools such as Sniffles and CuteSV typically identify SVs with a minimum length of 30bp, while Clair3 can detect SVs up to 50bp. Thank you!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/874
https://github.com/google/deepvariant/issues/874:194,testability,observ,observe,194,"Deepvariant Structural Variants for ONT; Hi All,. When using the DeepVariant model type ONT_R104, does it also call structural variants (SVs), specifically ones between 0 and 30bp in length? We observe tools such as Sniffles and CuteSV typically identify SVs with a minimum length of 30bp, while Clair3 can detect SVs up to 50bp. Thank you!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/874
https://github.com/google/deepvariant/issues/874:202,usability,tool,tools,202,"Deepvariant Structural Variants for ONT; Hi All,. When using the DeepVariant model type ONT_R104, does it also call structural variants (SVs), specifically ones between 0 and 30bp in length? We observe tools such as Sniffles and CuteSV typically identify SVs with a minimum length of 30bp, while Clair3 can detect SVs up to 50bp. Thank you!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/874
https://github.com/google/deepvariant/issues/874:266,usability,minim,minimum,266,"Deepvariant Structural Variants for ONT; Hi All,. When using the DeepVariant model type ONT_R104, does it also call structural variants (SVs), specifically ones between 0 and 30bp in length? We observe tools such as Sniffles and CuteSV typically identify SVs with a minimum length of 30bp, while Clair3 can detect SVs up to 50bp. Thank you!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/874
https://github.com/google/deepvariant/issues/876:915,availability,cluster,cluster,915,"No evaluation statistics for het and homalt calls during model training; Hello DV team, and thanks for creating such a great tool! . I am currently trying to retrain the wgs model for a new species (a fish) however, during training, I see no evaluation statistics (precision, recall, f1) for either het or homalt. Or more specifically they are all 0.0. Eval stats are reported for homref though. I have now tried running the training several times with different hyperparameters but so far still no change at the het or homalt eval stats. . My first, very simple question is thus, are these eval stats truly 0 (i.e. the model is very bad) or is 0.0 some starting value and there are not enough data to calculate them initially? I am warmstarting from the 1.6.1 wgs model so I cant imagine the model is really that bad at calling variants initially, even if in a fish. . **Setup**. Running on a university computing cluster (https://hpc-unibe-ch.github.io/) . OS: Rocky 9.3 Blue Onyx. GPU: rtx4090 . Installation: Running from Docker image via singularity. DV version: 1.6.1. **Data**. I am training on examples from 5 individuals, data from Illumina NovaSeq ~20x coverage. . 17/21 chromosomes used for training (~1.45M examples). 2/21 chromosomes used for tuning (~200k examples). 2/21 chromosomes reserved for testing. . (Different chromosomes used for train/tune/test across samples - see below). <img width=""1437"" alt=""Screenshot 2024-08-07 at 09 30 23"" src=""https://github.com/user-attachments/assets/3178e87a-8cf7-47cb-84a2-0a84d15c958f"">. **Shuffling**. Performed downsampling=0.5. Shuffled globally across samples, chromosomes and downsampling. . **Command**. My latest training run was like so:. ```. apptainer run . --nv . -B $WD:/home . $DV_PATH . /opt/deepvariant/bin/train . --config=/home/dv_config.py:base . --config.train_dataset_pbtxt=""/home/examples_shuffled/train/All_samples_training_examples.dataset_config.pbtxt"" . --config.tune_dataset_pbtxt=""/home/examples_shuffled/tune/All_sa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:1570,availability,down,downsampling,1570,"hus, are these eval stats truly 0 (i.e. the model is very bad) or is 0.0 some starting value and there are not enough data to calculate them initially? I am warmstarting from the 1.6.1 wgs model so I cant imagine the model is really that bad at calling variants initially, even if in a fish. . **Setup**. Running on a university computing cluster (https://hpc-unibe-ch.github.io/) . OS: Rocky 9.3 Blue Onyx. GPU: rtx4090 . Installation: Running from Docker image via singularity. DV version: 1.6.1. **Data**. I am training on examples from 5 individuals, data from Illumina NovaSeq ~20x coverage. . 17/21 chromosomes used for training (~1.45M examples). 2/21 chromosomes used for tuning (~200k examples). 2/21 chromosomes reserved for testing. . (Different chromosomes used for train/tune/test across samples - see below). <img width=""1437"" alt=""Screenshot 2024-08-07 at 09 30 23"" src=""https://github.com/user-attachments/assets/3178e87a-8cf7-47cb-84a2-0a84d15c958f"">. **Shuffling**. Performed downsampling=0.5. Shuffled globally across samples, chromosomes and downsampling. . **Command**. My latest training run was like so:. ```. apptainer run . --nv . -B $WD:/home . $DV_PATH . /opt/deepvariant/bin/train . --config=/home/dv_config.py:base . --config.train_dataset_pbtxt=""/home/examples_shuffled/train/All_samples_training_examples.dataset_config.pbtxt"" . --config.tune_dataset_pbtxt=""/home/examples_shuffled/tune/All_samples_tune_examples.dataset_config.pbtxt"". . --config.num_epochs=1 . --config.learning_rate=0.0001 . --config.num_validation_examples=0 . --config.tune_every_steps=2000 . --experiment_dir=/home/${OUTDIR} . --strategy=mirrored . --config.batch_size=64 . --config.init_checkpoint=""/home/model_wgs_v1.6.1/deepvariant.wgs.ckpt"". ```. Though previous runs had higher learning rates (0.01) and batch sizes (128). Training proceeds as follows:. Training Examples: 1454377. Batch Size: 64. Epochs: 1. Steps per epoch: 22724. Steps per tune: 3162. Num train steps: 22724. **Log file**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:1638,availability,down,downsampling,1638," 0.0 some starting value and there are not enough data to calculate them initially? I am warmstarting from the 1.6.1 wgs model so I cant imagine the model is really that bad at calling variants initially, even if in a fish. . **Setup**. Running on a university computing cluster (https://hpc-unibe-ch.github.io/) . OS: Rocky 9.3 Blue Onyx. GPU: rtx4090 . Installation: Running from Docker image via singularity. DV version: 1.6.1. **Data**. I am training on examples from 5 individuals, data from Illumina NovaSeq ~20x coverage. . 17/21 chromosomes used for training (~1.45M examples). 2/21 chromosomes used for tuning (~200k examples). 2/21 chromosomes reserved for testing. . (Different chromosomes used for train/tune/test across samples - see below). <img width=""1437"" alt=""Screenshot 2024-08-07 at 09 30 23"" src=""https://github.com/user-attachments/assets/3178e87a-8cf7-47cb-84a2-0a84d15c958f"">. **Shuffling**. Performed downsampling=0.5. Shuffled globally across samples, chromosomes and downsampling. . **Command**. My latest training run was like so:. ```. apptainer run . --nv . -B $WD:/home . $DV_PATH . /opt/deepvariant/bin/train . --config=/home/dv_config.py:base . --config.train_dataset_pbtxt=""/home/examples_shuffled/train/All_samples_training_examples.dataset_config.pbtxt"" . --config.tune_dataset_pbtxt=""/home/examples_shuffled/tune/All_samples_tune_examples.dataset_config.pbtxt"". . --config.num_epochs=1 . --config.learning_rate=0.0001 . --config.num_validation_examples=0 . --config.tune_every_steps=2000 . --experiment_dir=/home/${OUTDIR} . --strategy=mirrored . --config.batch_size=64 . --config.init_checkpoint=""/home/model_wgs_v1.6.1/deepvariant.wgs.ckpt"". ```. Though previous runs had higher learning rates (0.01) and batch sizes (128). Training proceeds as follows:. Training Examples: 1454377. Batch Size: 64. Epochs: 1. Steps per epoch: 22724. Steps per tune: 3162. Num train steps: 22724. **Log file**. Here is the top of the log file, including some warnings in case th",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:2869,availability,mainten,maintenance,2869,"/train/All_samples_training_examples.dataset_config.pbtxt"" . --config.tune_dataset_pbtxt=""/home/examples_shuffled/tune/All_samples_tune_examples.dataset_config.pbtxt"". . --config.num_epochs=1 . --config.learning_rate=0.0001 . --config.num_validation_examples=0 . --config.tune_every_steps=2000 . --experiment_dir=/home/${OUTDIR} . --strategy=mirrored . --config.batch_size=64 . --config.init_checkpoint=""/home/model_wgs_v1.6.1/deepvariant.wgs.ckpt"". ```. Though previous runs had higher learning rates (0.01) and batch sizes (128). Training proceeds as follows:. Training Examples: 1454377. Batch Size: 64. Epochs: 1. Steps per epoch: 22724. Steps per tune: 3162. Num train steps: 22724. **Log file**. Here is the top of the log file, including some warnings in case they are relevant:. ```. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(. 2024-08-28 10:40:42.588215: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_SYSTEM_DRIVER_MISMATCH: system has unsupported display driver / cuda driver combination. I0828 10:40:42.589054 140318776715072 train.py:92] Running with debug=False. I0828 10:40:42.589343 140318776715072 train.py:100] Use TPU at local. I0828 10:40:42.589422 140318776715072 train.py:103] experiment_dir: /home/training_outs/epoch1/. WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce. W0828 10:40:42.596594 140318776715072 cross_device_ops.py:1387] There are non-GPU devices in `tf.distribute.Strategy`, not using nccl a",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:2953,availability,down,downstream,2953,"pbtxt=""/home/examples_shuffled/tune/All_samples_tune_examples.dataset_config.pbtxt"". . --config.num_epochs=1 . --config.learning_rate=0.0001 . --config.num_validation_examples=0 . --config.tune_every_steps=2000 . --experiment_dir=/home/${OUTDIR} . --strategy=mirrored . --config.batch_size=64 . --config.init_checkpoint=""/home/model_wgs_v1.6.1/deepvariant.wgs.ckpt"". ```. Though previous runs had higher learning rates (0.01) and batch sizes (128). Training proceeds as follows:. Training Examples: 1454377. Batch Size: 64. Epochs: 1. Steps per epoch: 22724. Steps per tune: 3162. Num train steps: 22724. **Log file**. Here is the top of the log file, including some warnings in case they are relevant:. ```. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(. 2024-08-28 10:40:42.588215: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_SYSTEM_DRIVER_MISMATCH: system has unsupported display driver / cuda driver combination. I0828 10:40:42.589054 140318776715072 train.py:92] Running with debug=False. I0828 10:40:42.589343 140318776715072 train.py:100] Use TPU at local. I0828 10:40:42.589422 140318776715072 train.py:103] experiment_dir: /home/training_outs/epoch1/. WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce. W0828 10:40:42.596594 140318776715072 cross_device_ops.py:1387] There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce. INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/repl",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:3954,availability,replic,replica,3954,"tream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(. 2024-08-28 10:40:42.588215: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_SYSTEM_DRIVER_MISMATCH: system has unsupported display driver / cuda driver combination. I0828 10:40:42.589054 140318776715072 train.py:92] Running with debug=False. I0828 10:40:42.589343 140318776715072 train.py:100] Use TPU at local. I0828 10:40:42.589422 140318776715072 train.py:103] experiment_dir: /home/training_outs/epoch1/. WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce. W0828 10:40:42.596594 140318776715072 cross_device_ops.py:1387] There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce. INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',). I0828 10:40:42.658734 140318776715072 mirrored_strategy.py:374] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',). /usr/local/lib/python3.8/dist-packages/keras/applications/inception_v3.py:138: UserWarning: This model usually expects 1 or 3 input channels. However, it was passed an input_shape with 7 input channels. input_shape = imagenet_utils.obtain_input_shape(. I0828 10:40:47.952382 140318776715072 keras_modeling.py:325] Number of l2 regularizers: 95. I0828 10:40:48.007193 140318776715072 keras_modeling.py:362] inceptionv3: load_weights from checkpoint: /home/training_outs/epoch1//checkpoints/ckpt-5997. I0828 10:40:49.193293 140318776715072 train.py:191] Exponential Decay: initial_learning_rate=0.0001. decay_steps=45448. learning_rate_decay_rate=0.947. I0828 10:40:49.193522 140318776715072 train.py:203] Use LinearWarmup:. warmup_steps=10000. warmup_learning_rate=1e-05. I0828 10:40:49.401860 140318776715072 keras_mode",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:4105,availability,replic,replica,4105,"e: https://github.com/tensorflow/addons/issues/2807. warnings.warn(. 2024-08-28 10:40:42.588215: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_SYSTEM_DRIVER_MISMATCH: system has unsupported display driver / cuda driver combination. I0828 10:40:42.589054 140318776715072 train.py:92] Running with debug=False. I0828 10:40:42.589343 140318776715072 train.py:100] Use TPU at local. I0828 10:40:42.589422 140318776715072 train.py:103] experiment_dir: /home/training_outs/epoch1/. WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce. W0828 10:40:42.596594 140318776715072 cross_device_ops.py:1387] There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce. INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',). I0828 10:40:42.658734 140318776715072 mirrored_strategy.py:374] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',). /usr/local/lib/python3.8/dist-packages/keras/applications/inception_v3.py:138: UserWarning: This model usually expects 1 or 3 input channels. However, it was passed an input_shape with 7 input channels. input_shape = imagenet_utils.obtain_input_shape(. I0828 10:40:47.952382 140318776715072 keras_modeling.py:325] Number of l2 regularizers: 95. I0828 10:40:48.007193 140318776715072 keras_modeling.py:362] inceptionv3: load_weights from checkpoint: /home/training_outs/epoch1//checkpoints/ckpt-5997. I0828 10:40:49.193293 140318776715072 train.py:191] Exponential Decay: initial_learning_rate=0.0001. decay_steps=45448. learning_rate_decay_rate=0.947. I0828 10:40:49.193522 140318776715072 train.py:203] Use LinearWarmup:. warmup_steps=10000. warmup_learning_rate=1e-05. I0828 10:40:49.401860 140318776715072 keras_modeling.py:472] Restored checkpoint ckpt-5997 at step=0. tune/f1_weighted=tf.Tensor(0.0, shape=(), dtype=float32). WARNING:tensorflow:From /usr/local/lib/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:4576,availability,checkpoint,checkpoint,4576,"train.py:103] experiment_dir: /home/training_outs/epoch1/. WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce. W0828 10:40:42.596594 140318776715072 cross_device_ops.py:1387] There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce. INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',). I0828 10:40:42.658734 140318776715072 mirrored_strategy.py:374] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',). /usr/local/lib/python3.8/dist-packages/keras/applications/inception_v3.py:138: UserWarning: This model usually expects 1 or 3 input channels. However, it was passed an input_shape with 7 input channels. input_shape = imagenet_utils.obtain_input_shape(. I0828 10:40:47.952382 140318776715072 keras_modeling.py:325] Number of l2 regularizers: 95. I0828 10:40:48.007193 140318776715072 keras_modeling.py:362] inceptionv3: load_weights from checkpoint: /home/training_outs/epoch1//checkpoints/ckpt-5997. I0828 10:40:49.193293 140318776715072 train.py:191] Exponential Decay: initial_learning_rate=0.0001. decay_steps=45448. learning_rate_decay_rate=0.947. I0828 10:40:49.193522 140318776715072 train.py:203] Use LinearWarmup:. warmup_steps=10000. warmup_learning_rate=1e-05. I0828 10:40:49.401860 140318776715072 keras_modeling.py:472] Restored checkpoint ckpt-5997 at step=0. tune/f1_weighted=tf.Tensor(0.0, shape=(), dtype=float32). WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23. Instructions for updating:. Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089. W0828 10:40:49.488072 140318776715072 depr",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:4616,availability,checkpoint,checkpoints,4616,"ing_outs/epoch1/. WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce. W0828 10:40:42.596594 140318776715072 cross_device_ops.py:1387] There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce. INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',). I0828 10:40:42.658734 140318776715072 mirrored_strategy.py:374] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',). /usr/local/lib/python3.8/dist-packages/keras/applications/inception_v3.py:138: UserWarning: This model usually expects 1 or 3 input channels. However, it was passed an input_shape with 7 input channels. input_shape = imagenet_utils.obtain_input_shape(. I0828 10:40:47.952382 140318776715072 keras_modeling.py:325] Number of l2 regularizers: 95. I0828 10:40:48.007193 140318776715072 keras_modeling.py:362] inceptionv3: load_weights from checkpoint: /home/training_outs/epoch1//checkpoints/ckpt-5997. I0828 10:40:49.193293 140318776715072 train.py:191] Exponential Decay: initial_learning_rate=0.0001. decay_steps=45448. learning_rate_decay_rate=0.947. I0828 10:40:49.193522 140318776715072 train.py:203] Use LinearWarmup:. warmup_steps=10000. warmup_learning_rate=1e-05. I0828 10:40:49.401860 140318776715072 keras_modeling.py:472] Restored checkpoint ckpt-5997 at step=0. tune/f1_weighted=tf.Tensor(0.0, shape=(), dtype=float32). WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23. Instructions for updating:. Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089. W0828 10:40:49.488072 140318776715072 deprecation.py:350] From /usr/local/lib/pytho",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:4971,availability,Restor,Restored,4971,"ce:CPU:0',). I0828 10:40:42.658734 140318776715072 mirrored_strategy.py:374] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',). /usr/local/lib/python3.8/dist-packages/keras/applications/inception_v3.py:138: UserWarning: This model usually expects 1 or 3 input channels. However, it was passed an input_shape with 7 input channels. input_shape = imagenet_utils.obtain_input_shape(. I0828 10:40:47.952382 140318776715072 keras_modeling.py:325] Number of l2 regularizers: 95. I0828 10:40:48.007193 140318776715072 keras_modeling.py:362] inceptionv3: load_weights from checkpoint: /home/training_outs/epoch1//checkpoints/ckpt-5997. I0828 10:40:49.193293 140318776715072 train.py:191] Exponential Decay: initial_learning_rate=0.0001. decay_steps=45448. learning_rate_decay_rate=0.947. I0828 10:40:49.193522 140318776715072 train.py:203] Use LinearWarmup:. warmup_steps=10000. warmup_learning_rate=1e-05. I0828 10:40:49.401860 140318776715072 keras_modeling.py:472] Restored checkpoint ckpt-5997 at step=0. tune/f1_weighted=tf.Tensor(0.0, shape=(), dtype=float32). WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23. Instructions for updating:. Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089. W0828 10:40:49.488072 140318776715072 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be rem>. Instructions for updating:. Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. htt",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:4980,availability,checkpoint,checkpoint,4980,"). I0828 10:40:42.658734 140318776715072 mirrored_strategy.py:374] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',). /usr/local/lib/python3.8/dist-packages/keras/applications/inception_v3.py:138: UserWarning: This model usually expects 1 or 3 input channels. However, it was passed an input_shape with 7 input channels. input_shape = imagenet_utils.obtain_input_shape(. I0828 10:40:47.952382 140318776715072 keras_modeling.py:325] Number of l2 regularizers: 95. I0828 10:40:48.007193 140318776715072 keras_modeling.py:362] inceptionv3: load_weights from checkpoint: /home/training_outs/epoch1//checkpoints/ckpt-5997. I0828 10:40:49.193293 140318776715072 train.py:191] Exponential Decay: initial_learning_rate=0.0001. decay_steps=45448. learning_rate_decay_rate=0.947. I0828 10:40:49.193522 140318776715072 train.py:203] Use LinearWarmup:. warmup_steps=10000. warmup_learning_rate=1e-05. I0828 10:40:49.401860 140318776715072 keras_modeling.py:472] Restored checkpoint ckpt-5997 at step=0. tune/f1_weighted=tf.Tensor(0.0, shape=(), dtype=float32). WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23. Instructions for updating:. Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089. W0828 10:40:49.488072 140318776715072 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be rem>. Instructions for updating:. Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://githu",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:5422,availability,state,statement,5422,"72 keras_modeling.py:325] Number of l2 regularizers: 95. I0828 10:40:48.007193 140318776715072 keras_modeling.py:362] inceptionv3: load_weights from checkpoint: /home/training_outs/epoch1//checkpoints/ckpt-5997. I0828 10:40:49.193293 140318776715072 train.py:191] Exponential Decay: initial_learning_rate=0.0001. decay_steps=45448. learning_rate_decay_rate=0.947. I0828 10:40:49.193522 140318776715072 train.py:203] Use LinearWarmup:. warmup_steps=10000. warmup_learning_rate=1e-05. I0828 10:40:49.401860 140318776715072 keras_modeling.py:472] Restored checkpoint ckpt-5997 at step=0. tune/f1_weighted=tf.Tensor(0.0, shape=(), dtype=float32). WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23. Instructions for updating:. Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089. W0828 10:40:49.488072 140318776715072 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be rem>. Instructions for updating:. Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089. 2024-08-28 10:40:49.893797: W tensorflow/core/framework/dataset.cc:769] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations. I0828 10:40:49.947995 140318776715072 train.py:316]. ```. And here is an excerpt of from a later portion of the log file including some training and tuning steps, wher",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:5910,availability,state,statement,5910," 10:40:49.401860 140318776715072 keras_modeling.py:472] Restored checkpoint ckpt-5997 at step=0. tune/f1_weighted=tf.Tensor(0.0, shape=(), dtype=float32). WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23. Instructions for updating:. Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089. W0828 10:40:49.488072 140318776715072 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be rem>. Instructions for updating:. Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089. 2024-08-28 10:40:49.893797: W tensorflow/core/framework/dataset.cc:769] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations. I0828 10:40:49.947995 140318776715072 train.py:316]. ```. And here is an excerpt of from a later portion of the log file including some training and tuning steps, where you can see the 0.0 for het and homalt eval stats. . ```. I0829 07:13:59.098341 140305134778112 logging_writer.py:48] [13700] epoch=0, train/categorical_accuracy=1.0, train/categorical_crossentropy=0.552009105682373, train/f1_het=0.0, train/f1_homalt=0.0, train/f1_homref=1.0, train/f1_macro=0.3333333432674408, train/f1_micro=1.0, train/f1_. weighted=1.0, train/false_negatives=0.0, train/false_positives=0.0, train/learning_rate=9.999999747378752e-05, train/loss=0.5520098805427551, t",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:7448,availability,uptim,uptime,7448,"r het and homalt eval stats. . ```. I0829 07:13:59.098341 140305134778112 logging_writer.py:48] [13700] epoch=0, train/categorical_accuracy=1.0, train/categorical_crossentropy=0.552009105682373, train/f1_het=0.0, train/f1_homalt=0.0, train/f1_homref=1.0, train/f1_macro=0.3333333432674408, train/f1_micro=1.0, train/f1_. weighted=1.0, train/false_negatives=0.0, train/false_positives=0.0, train/learning_rate=9.999999747378752e-05, train/loss=0.5520098805427551, train/precision=1.0, train/precision_het=0.0, train/precision_homalt=0.0, train/precision_homref=1.0, train/recall=1.0, train/recall_het=0.0,. train/recall_homalt=0.0, train/recall_homref=1.0, train/true_negatives=12800.0, train/true_positives=6400.0. I0829 07:18:37.609363 140318776715072 local.py:41] Setting work unit notes: 0.3 steps/s, 60.6% (13778/22724), ETA: 8h52m. I0829 07:18:37.611700 140305134778112 logging_writer.py:48] [13778] steps_per_sec=0.280118. I0829 07:18:37.611787 140305134778112 logging_writer.py:48] [13778] uptime=74267.6. I0829 07:19:56.116713 140305134778112 logging_writer.py:48] [13800] epoch=0, train/categorical_accuracy=1.0, train/categorical_crossentropy=0.5520044565200806, train/f1_het=0.0, train/f1_homalt=0.0, train/f1_homref=1.0, train/f1_macro=0.3333333432674408, train/f1_micro=1.0, train/f1_weighted=1.0, train/false_negatives=0.0, train/false_positives=0.0, train/learning_rate=9.999999747378752e-05, train/loss=0.5520052909851074, train/precision=1.0, train/precision_het=0.0, train/precision_homalt=0.0, train/precision_homref=1.0, train/recall=1.0, train/recall_het=0.0, train/recall_homalt=0.0, train/recall_homref=1.0, train/true_negatives=12800.0, train/true_positives=6400.0. I0829 07:23:41.076397 140318776715072 local.py:41] Setting work unit notes: 0.3 steps/s, 61.0% (13863/22724), ETA: 8h47m. I0829 07:23:41.078737 140305134778112 logging_writer.py:48] [13863] steps_per_sec=0.280096. I0829 07:23:41.078827 140305134778112 logging_writer.py:48] [13863] uptime=74571.1. I0829 07:25:",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:8423,availability,uptim,uptime,8423,"writer.py:48] [13778] uptime=74267.6. I0829 07:19:56.116713 140305134778112 logging_writer.py:48] [13800] epoch=0, train/categorical_accuracy=1.0, train/categorical_crossentropy=0.5520044565200806, train/f1_het=0.0, train/f1_homalt=0.0, train/f1_homref=1.0, train/f1_macro=0.3333333432674408, train/f1_micro=1.0, train/f1_weighted=1.0, train/false_negatives=0.0, train/false_positives=0.0, train/learning_rate=9.999999747378752e-05, train/loss=0.5520052909851074, train/precision=1.0, train/precision_het=0.0, train/precision_homalt=0.0, train/precision_homref=1.0, train/recall=1.0, train/recall_het=0.0, train/recall_homalt=0.0, train/recall_homref=1.0, train/true_negatives=12800.0, train/true_positives=6400.0. I0829 07:23:41.076397 140318776715072 local.py:41] Setting work unit notes: 0.3 steps/s, 61.0% (13863/22724), ETA: 8h47m. I0829 07:23:41.078737 140305134778112 logging_writer.py:48] [13863] steps_per_sec=0.280096. I0829 07:23:41.078827 140305134778112 logging_writer.py:48] [13863] uptime=74571.1. I0829 07:25:53.180995 140305134778112 logging_writer.py:48] [13900] epoch=0, train/categorical_accuracy=1.0, train/categorical_crossentropy=0.5519936680793762, train/f1_het=0.0, train/f1_homalt=0.0, train/f1_homref=1.0, train/f1_macro=0.3333333432674408, train/f1_micro=1.0, train/f1_weighted=1.0, train/false_negatives=0.0, train/false_positives=0.0, train/learning_rate=9.999999747378752e-05, train/loss=0.5519945025444031, train/precision=1.0, train/precision_het=0.0, train/precision_homalt=0.0, train/precision_homref=1.0, train/recall=1.0, train/recall_het=0.0, train/recall_homalt=0.0, train/recall_homref=1.0, train/true_negatives=12800.0, train/true_positives=6400.0. I0829 07:28:44.566404 140318776715072 local.py:41] Setting work unit notes: 0.3 steps/s, 61.4% (13948/22724), ETA: 8h42m. I0829 07:28:44.568708 140305134778112 logging_writer.py:48] [13948] steps_per_sec=0.280075. I0829 07:28:44.568793 140305134778112 logging_writer.py:48] [13948] uptime=74874.6. I0829 07:31:",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:9398,availability,uptim,uptime,9398,"writer.py:48] [13863] uptime=74571.1. I0829 07:25:53.180995 140305134778112 logging_writer.py:48] [13900] epoch=0, train/categorical_accuracy=1.0, train/categorical_crossentropy=0.5519936680793762, train/f1_het=0.0, train/f1_homalt=0.0, train/f1_homref=1.0, train/f1_macro=0.3333333432674408, train/f1_micro=1.0, train/f1_weighted=1.0, train/false_negatives=0.0, train/false_positives=0.0, train/learning_rate=9.999999747378752e-05, train/loss=0.5519945025444031, train/precision=1.0, train/precision_het=0.0, train/precision_homalt=0.0, train/precision_homref=1.0, train/recall=1.0, train/recall_het=0.0, train/recall_homalt=0.0, train/recall_homref=1.0, train/true_negatives=12800.0, train/true_positives=6400.0. I0829 07:28:44.566404 140318776715072 local.py:41] Setting work unit notes: 0.3 steps/s, 61.4% (13948/22724), ETA: 8h42m. I0829 07:28:44.568708 140305134778112 logging_writer.py:48] [13948] steps_per_sec=0.280075. I0829 07:28:44.568793 140305134778112 logging_writer.py:48] [13948] uptime=74874.6. I0829 07:31:25.151819 140318776715072 train.py:361] Running tune at step=13993 epoch=0. I0829 07:31:25.152109 140318776715072 train.py:366] Tune step 0 / 3162 (0.0%). I0829 07:33:17.573163 140318776715072 train.py:366] Tune step 100 / 3162 (0.0%). I0829 07:35:10.013494 140318776715072 train.py:366] Tune step 200 / 3162 (10.0%). I0829 07:37:02.497336 140318776715072 train.py:366] Tune step 300 / 3162 (10.0%). I0829 07:38:54.834164 140318776715072 train.py:366] Tune step 400 / 3162 (10.0%). I0829 07:40:47.319165 140318776715072 train.py:366] Tune step 500 / 3162 (20.0%). I0829 07:42:39.802007 140318776715072 train.py:366] Tune step 600 / 3162 (20.0%). I0829 07:44:32.297624 140318776715072 train.py:366] Tune step 700 / 3162 (20.0%). I0829 07:46:24.658610 140318776715072 train.py:366] Tune step 800 / 3162 (30.0%). I0829 07:48:17.176530 140318776715072 train.py:366] Tune step 900 / 3162 (30.0%). I0829 07:50:09.700463 140318776715072 train.py:366] Tune step 1000 / 3162 (30.0%). ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:12936,availability,checkpoint,checkpoint,12936,":366] Tune step 2900 / 3162 (90.0%). I0829 08:27:39.775715 140318776715072 train.py:366] Tune step 3000 / 3162 (90.0%). I0829 08:29:29.592094 140318776715072 train.py:366] Tune step 3100 / 3162 (100.0%). I0829 08:30:42.583051 140305134778112 logging_writer.py:48] [13993] tune/categorical_accuracy=0.9916982650756836, tune/categorical_crossentropy=0.560210645198822, tune/f1_het=0.0, tune/f1_homalt=0.0, tune/f1_homref=0.9958318471908569, tune/f1_macro=0.33194395899772644, tune/f1_micro=0.9916982650756836, tune/f1_weighted=0.9958318471908569, tune/false_negatives_1=1777.0, tune/false_positives_1=1544.0, tune/loss=0.5603554248809814, tune/precision_1=0.9923615455627441, tune/precision_het=0.0, tune/precision_homalt=0.0, tune/precision_homref=1.0, tune/recall_1=0.9912189841270447, tune/recall_het=0.0, tune/recall_homalt=0.0, tune/recall_homref=0.9912189841270447, tune/true_negatives_1=403192.0, tune/true_positives_1=200591.0. I0829 08:30:42.590469 140318776715072 train.py:471] Skipping checkpoint with tune/f1_weighted=0.99583185 < previous best tune/f1_weighted=0.99845344. I0829 08:30:42.595992 140305134778112 logging_writer.py:48] [13993] tune/early_stopping=7. I0829 08:30:46.123329 140318776715072 local.py:41] Setting work unit notes: 0.0 steps/s, 61.6% (13994/22724), ETA: 8d4h11m. I0829 08:30:46.125013 140305134778112 logging_writer.py:48] [13994] steps_per_sec=0.0123604. I0829 08:30:46.125087 140305134778112 logging_writer.py:48] [13994] uptime=78596.1. I0829 08:31:07.673585 140305134778112 logging_writer.py:48] [14000] epoch=0, train/categorical_accuracy=1.0, train/categorical_crossentropy=0.5519920587539673, train/f1_het=0.0, train/f1_homalt=0.0, train/f1_homref=1.0, train/f1_macro=0.3333333432674408, train/f1_micro=1.0, train/f1_weighted=1.0, train/false_negatives=0.0, train/false_positives=0.0, train/learning_rate=9.999999747378752e-05, train/loss=0.551992654800415, train/precision=1.0, train/precision_het=0.0, train/precision_homalt=0.0, train/precision_homref=1.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:13401,availability,uptim,uptime,13401,"899772644, tune/f1_micro=0.9916982650756836, tune/f1_weighted=0.9958318471908569, tune/false_negatives_1=1777.0, tune/false_positives_1=1544.0, tune/loss=0.5603554248809814, tune/precision_1=0.9923615455627441, tune/precision_het=0.0, tune/precision_homalt=0.0, tune/precision_homref=1.0, tune/recall_1=0.9912189841270447, tune/recall_het=0.0, tune/recall_homalt=0.0, tune/recall_homref=0.9912189841270447, tune/true_negatives_1=403192.0, tune/true_positives_1=200591.0. I0829 08:30:42.590469 140318776715072 train.py:471] Skipping checkpoint with tune/f1_weighted=0.99583185 < previous best tune/f1_weighted=0.99845344. I0829 08:30:42.595992 140305134778112 logging_writer.py:48] [13993] tune/early_stopping=7. I0829 08:30:46.123329 140318776715072 local.py:41] Setting work unit notes: 0.0 steps/s, 61.6% (13994/22724), ETA: 8d4h11m. I0829 08:30:46.125013 140305134778112 logging_writer.py:48] [13994] steps_per_sec=0.0123604. I0829 08:30:46.125087 140305134778112 logging_writer.py:48] [13994] uptime=78596.1. I0829 08:31:07.673585 140305134778112 logging_writer.py:48] [14000] epoch=0, train/categorical_accuracy=1.0, train/categorical_crossentropy=0.5519920587539673, train/f1_het=0.0, train/f1_homalt=0.0, train/f1_homref=1.0, train/f1_macro=0.3333333432674408, train/f1_micro=1.0, train/f1_weighted=1.0, train/false_negatives=0.0, train/false_positives=0.0, train/learning_rate=9.999999747378752e-05, train/loss=0.551992654800415, train/precision=1.0, train/precision_het=0.0, train/precision_homalt=0.0, train/precision_homref=1.0, train/recall=1.0, train/recall_het=0.0, train/recall_homalt=0.0, train/recall_homref=1.0, train/true_negatives=12800.0, train/true_positives=6400.0. ```. I am new to Deep Learning and am struggling to decide whether something is wrong with my training approach/scripts or whether the model just needs more time / different hyperparams. Given the number of examples, I can only run 1 epoch at a time before I hit the 24hr cluster wall-time limit. So I have only",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:14365,availability,cluster,cluster,14365,"ne/loss=0.5603554248809814, tune/precision_1=0.9923615455627441, tune/precision_het=0.0, tune/precision_homalt=0.0, tune/precision_homref=1.0, tune/recall_1=0.9912189841270447, tune/recall_het=0.0, tune/recall_homalt=0.0, tune/recall_homref=0.9912189841270447, tune/true_negatives_1=403192.0, tune/true_positives_1=200591.0. I0829 08:30:42.590469 140318776715072 train.py:471] Skipping checkpoint with tune/f1_weighted=0.99583185 < previous best tune/f1_weighted=0.99845344. I0829 08:30:42.595992 140305134778112 logging_writer.py:48] [13993] tune/early_stopping=7. I0829 08:30:46.123329 140318776715072 local.py:41] Setting work unit notes: 0.0 steps/s, 61.6% (13994/22724), ETA: 8d4h11m. I0829 08:30:46.125013 140305134778112 logging_writer.py:48] [13994] steps_per_sec=0.0123604. I0829 08:30:46.125087 140305134778112 logging_writer.py:48] [13994] uptime=78596.1. I0829 08:31:07.673585 140305134778112 logging_writer.py:48] [14000] epoch=0, train/categorical_accuracy=1.0, train/categorical_crossentropy=0.5519920587539673, train/f1_het=0.0, train/f1_homalt=0.0, train/f1_homref=1.0, train/f1_macro=0.3333333432674408, train/f1_micro=1.0, train/f1_weighted=1.0, train/false_negatives=0.0, train/false_positives=0.0, train/learning_rate=9.999999747378752e-05, train/loss=0.551992654800415, train/precision=1.0, train/precision_het=0.0, train/precision_homalt=0.0, train/precision_homref=1.0, train/recall=1.0, train/recall_het=0.0, train/recall_homalt=0.0, train/recall_homref=1.0, train/true_negatives=12800.0, train/true_positives=6400.0. ```. I am new to Deep Learning and am struggling to decide whether something is wrong with my training approach/scripts or whether the model just needs more time / different hyperparams. Given the number of examples, I can only run 1 epoch at a time before I hit the 24hr cluster wall-time limit. So I have only trained for around 30,000 steps in total across 2 epochs so far (starting from last checkpoint after 1st epoch). . All advice much appreciated! .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:14489,availability,checkpoint,checkpoint,14489,"ne/loss=0.5603554248809814, tune/precision_1=0.9923615455627441, tune/precision_het=0.0, tune/precision_homalt=0.0, tune/precision_homref=1.0, tune/recall_1=0.9912189841270447, tune/recall_het=0.0, tune/recall_homalt=0.0, tune/recall_homref=0.9912189841270447, tune/true_negatives_1=403192.0, tune/true_positives_1=200591.0. I0829 08:30:42.590469 140318776715072 train.py:471] Skipping checkpoint with tune/f1_weighted=0.99583185 < previous best tune/f1_weighted=0.99845344. I0829 08:30:42.595992 140305134778112 logging_writer.py:48] [13993] tune/early_stopping=7. I0829 08:30:46.123329 140318776715072 local.py:41] Setting work unit notes: 0.0 steps/s, 61.6% (13994/22724), ETA: 8d4h11m. I0829 08:30:46.125013 140305134778112 logging_writer.py:48] [13994] steps_per_sec=0.0123604. I0829 08:30:46.125087 140305134778112 logging_writer.py:48] [13994] uptime=78596.1. I0829 08:31:07.673585 140305134778112 logging_writer.py:48] [14000] epoch=0, train/categorical_accuracy=1.0, train/categorical_crossentropy=0.5519920587539673, train/f1_het=0.0, train/f1_homalt=0.0, train/f1_homref=1.0, train/f1_macro=0.3333333432674408, train/f1_micro=1.0, train/f1_weighted=1.0, train/false_negatives=0.0, train/false_positives=0.0, train/learning_rate=9.999999747378752e-05, train/loss=0.551992654800415, train/precision=1.0, train/precision_het=0.0, train/precision_homalt=0.0, train/precision_homref=1.0, train/recall=1.0, train/recall_het=0.0, train/recall_homalt=0.0, train/recall_homref=1.0, train/true_negatives=12800.0, train/true_positives=6400.0. ```. I am new to Deep Learning and am struggling to decide whether something is wrong with my training approach/scripts or whether the model just needs more time / different hyperparams. Given the number of examples, I can only run 1 epoch at a time before I hit the 24hr cluster wall-time limit. So I have only trained for around 30,000 steps in total across 2 epochs so far (starting from last checkpoint after 1st epoch). . All advice much appreciated! .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:915,deployability,cluster,cluster,915,"No evaluation statistics for het and homalt calls during model training; Hello DV team, and thanks for creating such a great tool! . I am currently trying to retrain the wgs model for a new species (a fish) however, during training, I see no evaluation statistics (precision, recall, f1) for either het or homalt. Or more specifically they are all 0.0. Eval stats are reported for homref though. I have now tried running the training several times with different hyperparameters but so far still no change at the het or homalt eval stats. . My first, very simple question is thus, are these eval stats truly 0 (i.e. the model is very bad) or is 0.0 some starting value and there are not enough data to calculate them initially? I am warmstarting from the 1.6.1 wgs model so I cant imagine the model is really that bad at calling variants initially, even if in a fish. . **Setup**. Running on a university computing cluster (https://hpc-unibe-ch.github.io/) . OS: Rocky 9.3 Blue Onyx. GPU: rtx4090 . Installation: Running from Docker image via singularity. DV version: 1.6.1. **Data**. I am training on examples from 5 individuals, data from Illumina NovaSeq ~20x coverage. . 17/21 chromosomes used for training (~1.45M examples). 2/21 chromosomes used for tuning (~200k examples). 2/21 chromosomes reserved for testing. . (Different chromosomes used for train/tune/test across samples - see below). <img width=""1437"" alt=""Screenshot 2024-08-07 at 09 30 23"" src=""https://github.com/user-attachments/assets/3178e87a-8cf7-47cb-84a2-0a84d15c958f"">. **Shuffling**. Performed downsampling=0.5. Shuffled globally across samples, chromosomes and downsampling. . **Command**. My latest training run was like so:. ```. apptainer run . --nv . -B $WD:/home . $DV_PATH . /opt/deepvariant/bin/train . --config=/home/dv_config.py:base . --config.train_dataset_pbtxt=""/home/examples_shuffled/train/All_samples_training_examples.dataset_config.pbtxt"" . --config.tune_dataset_pbtxt=""/home/examples_shuffled/tune/All_sa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:999,deployability,Instal,Installation,999,"aluation statistics for het and homalt calls during model training; Hello DV team, and thanks for creating such a great tool! . I am currently trying to retrain the wgs model for a new species (a fish) however, during training, I see no evaluation statistics (precision, recall, f1) for either het or homalt. Or more specifically they are all 0.0. Eval stats are reported for homref though. I have now tried running the training several times with different hyperparameters but so far still no change at the het or homalt eval stats. . My first, very simple question is thus, are these eval stats truly 0 (i.e. the model is very bad) or is 0.0 some starting value and there are not enough data to calculate them initially? I am warmstarting from the 1.6.1 wgs model so I cant imagine the model is really that bad at calling variants initially, even if in a fish. . **Setup**. Running on a university computing cluster (https://hpc-unibe-ch.github.io/) . OS: Rocky 9.3 Blue Onyx. GPU: rtx4090 . Installation: Running from Docker image via singularity. DV version: 1.6.1. **Data**. I am training on examples from 5 individuals, data from Illumina NovaSeq ~20x coverage. . 17/21 chromosomes used for training (~1.45M examples). 2/21 chromosomes used for tuning (~200k examples). 2/21 chromosomes reserved for testing. . (Different chromosomes used for train/tune/test across samples - see below). <img width=""1437"" alt=""Screenshot 2024-08-07 at 09 30 23"" src=""https://github.com/user-attachments/assets/3178e87a-8cf7-47cb-84a2-0a84d15c958f"">. **Shuffling**. Performed downsampling=0.5. Shuffled globally across samples, chromosomes and downsampling. . **Command**. My latest training run was like so:. ```. apptainer run . --nv . -B $WD:/home . $DV_PATH . /opt/deepvariant/bin/train . --config=/home/dv_config.py:base . --config.train_dataset_pbtxt=""/home/examples_shuffled/train/All_samples_training_examples.dataset_config.pbtxt"" . --config.tune_dataset_pbtxt=""/home/examples_shuffled/tune/All_samples",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:1059,deployability,version,version,1059,"training; Hello DV team, and thanks for creating such a great tool! . I am currently trying to retrain the wgs model for a new species (a fish) however, during training, I see no evaluation statistics (precision, recall, f1) for either het or homalt. Or more specifically they are all 0.0. Eval stats are reported for homref though. I have now tried running the training several times with different hyperparameters but so far still no change at the het or homalt eval stats. . My first, very simple question is thus, are these eval stats truly 0 (i.e. the model is very bad) or is 0.0 some starting value and there are not enough data to calculate them initially? I am warmstarting from the 1.6.1 wgs model so I cant imagine the model is really that bad at calling variants initially, even if in a fish. . **Setup**. Running on a university computing cluster (https://hpc-unibe-ch.github.io/) . OS: Rocky 9.3 Blue Onyx. GPU: rtx4090 . Installation: Running from Docker image via singularity. DV version: 1.6.1. **Data**. I am training on examples from 5 individuals, data from Illumina NovaSeq ~20x coverage. . 17/21 chromosomes used for training (~1.45M examples). 2/21 chromosomes used for tuning (~200k examples). 2/21 chromosomes reserved for testing. . (Different chromosomes used for train/tune/test across samples - see below). <img width=""1437"" alt=""Screenshot 2024-08-07 at 09 30 23"" src=""https://github.com/user-attachments/assets/3178e87a-8cf7-47cb-84a2-0a84d15c958f"">. **Shuffling**. Performed downsampling=0.5. Shuffled globally across samples, chromosomes and downsampling. . **Command**. My latest training run was like so:. ```. apptainer run . --nv . -B $WD:/home . $DV_PATH . /opt/deepvariant/bin/train . --config=/home/dv_config.py:base . --config.train_dataset_pbtxt=""/home/examples_shuffled/train/All_samples_training_examples.dataset_config.pbtxt"" . --config.tune_dataset_pbtxt=""/home/examples_shuffled/tune/All_samples_tune_examples.dataset_config.pbtxt"". . --config.num_epoch",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:2565,deployability,Log,Log,2565,"ed downsampling=0.5. Shuffled globally across samples, chromosomes and downsampling. . **Command**. My latest training run was like so:. ```. apptainer run . --nv . -B $WD:/home . $DV_PATH . /opt/deepvariant/bin/train . --config=/home/dv_config.py:base . --config.train_dataset_pbtxt=""/home/examples_shuffled/train/All_samples_training_examples.dataset_config.pbtxt"" . --config.tune_dataset_pbtxt=""/home/examples_shuffled/tune/All_samples_tune_examples.dataset_config.pbtxt"". . --config.num_epochs=1 . --config.learning_rate=0.0001 . --config.num_validation_examples=0 . --config.tune_every_steps=2000 . --experiment_dir=/home/${OUTDIR} . --strategy=mirrored . --config.batch_size=64 . --config.init_checkpoint=""/home/model_wgs_v1.6.1/deepvariant.wgs.ckpt"". ```. Though previous runs had higher learning rates (0.01) and batch sizes (128). Training proceeds as follows:. Training Examples: 1454377. Batch Size: 64. Epochs: 1. Steps per epoch: 22724. Steps per tune: 3162. Num train steps: 22724. **Log file**. Here is the top of the log file, including some warnings in case they are relevant:. ```. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(. 2024-08-28 10:40:42.588215: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_SYSTEM_DRIVER_MISMATCH: system has unsupported display driver / cuda driver combination. I0828 10:40:42.589054 140318776715072 train.py:92] Running with debug=False. I0828 10:40:42.589343 140318776715072 train.py:100] Use TPU at local. I0828 10:40:42.589422 14",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:2600,deployability,log,log,2600,"lly across samples, chromosomes and downsampling. . **Command**. My latest training run was like so:. ```. apptainer run . --nv . -B $WD:/home . $DV_PATH . /opt/deepvariant/bin/train . --config=/home/dv_config.py:base . --config.train_dataset_pbtxt=""/home/examples_shuffled/train/All_samples_training_examples.dataset_config.pbtxt"" . --config.tune_dataset_pbtxt=""/home/examples_shuffled/tune/All_samples_tune_examples.dataset_config.pbtxt"". . --config.num_epochs=1 . --config.learning_rate=0.0001 . --config.num_validation_examples=0 . --config.tune_every_steps=2000 . --experiment_dir=/home/${OUTDIR} . --strategy=mirrored . --config.batch_size=64 . --config.init_checkpoint=""/home/model_wgs_v1.6.1/deepvariant.wgs.ckpt"". ```. Though previous runs had higher learning rates (0.01) and batch sizes (128). Training proceeds as follows:. Training Examples: 1454377. Batch Size: 64. Epochs: 1. Steps per epoch: 22724. Steps per tune: 3162. Num train steps: 22724. **Log file**. Here is the top of the log file, including some warnings in case they are relevant:. ```. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(. 2024-08-28 10:40:42.588215: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_SYSTEM_DRIVER_MISMATCH: system has unsupported display driver / cuda driver combination. I0828 10:40:42.589054 140318776715072 train.py:92] Running with debug=False. I0828 10:40:42.589343 140318776715072 train.py:100] Use TPU at local. I0828 10:40:42.589422 140318776715072 train.py:103] experim",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:2885,deployability,releas,release,2885,"ples_training_examples.dataset_config.pbtxt"" . --config.tune_dataset_pbtxt=""/home/examples_shuffled/tune/All_samples_tune_examples.dataset_config.pbtxt"". . --config.num_epochs=1 . --config.learning_rate=0.0001 . --config.num_validation_examples=0 . --config.tune_every_steps=2000 . --experiment_dir=/home/${OUTDIR} . --strategy=mirrored . --config.batch_size=64 . --config.init_checkpoint=""/home/model_wgs_v1.6.1/deepvariant.wgs.ckpt"". ```. Though previous runs had higher learning rates (0.01) and batch sizes (128). Training proceeds as follows:. Training Examples: 1454377. Batch Size: 64. Epochs: 1. Steps per epoch: 22724. Steps per tune: 3162. Num train steps: 22724. **Log file**. Here is the top of the log file, including some warnings in case they are relevant:. ```. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(. 2024-08-28 10:40:42.588215: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_SYSTEM_DRIVER_MISMATCH: system has unsupported display driver / cuda driver combination. I0828 10:40:42.589054 140318776715072 train.py:92] Running with debug=False. I0828 10:40:42.589343 140318776715072 train.py:100] Use TPU at local. I0828 10:40:42.589422 140318776715072 train.py:103] experiment_dir: /home/training_outs/epoch1/. WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce. W0828 10:40:42.596594 140318776715072 cross_device_ops.py:1387] There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce. INFO",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:2982,deployability,depend,dependencies,2982,"/tune/All_samples_tune_examples.dataset_config.pbtxt"". . --config.num_epochs=1 . --config.learning_rate=0.0001 . --config.num_validation_examples=0 . --config.tune_every_steps=2000 . --experiment_dir=/home/${OUTDIR} . --strategy=mirrored . --config.batch_size=64 . --config.init_checkpoint=""/home/model_wgs_v1.6.1/deepvariant.wgs.ckpt"". ```. Though previous runs had higher learning rates (0.01) and batch sizes (128). Training proceeds as follows:. Training Examples: 1454377. Batch Size: 64. Epochs: 1. Steps per epoch: 22724. Steps per tune: 3162. Num train steps: 22724. **Log file**. Here is the top of the log file, including some warnings in case they are relevant:. ```. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(. 2024-08-28 10:40:42.588215: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_SYSTEM_DRIVER_MISMATCH: system has unsupported display driver / cuda driver combination. I0828 10:40:42.589054 140318776715072 train.py:92] Running with debug=False. I0828 10:40:42.589343 140318776715072 train.py:100] Use TPU at local. I0828 10:40:42.589422 140318776715072 train.py:103] experiment_dir: /home/training_outs/epoch1/. WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce. W0828 10:40:42.596594 140318776715072 cross_device_ops.py:1387] There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce. INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',). ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:3273,deployability,fail,failed,3273,"t=""/home/model_wgs_v1.6.1/deepvariant.wgs.ckpt"". ```. Though previous runs had higher learning rates (0.01) and batch sizes (128). Training proceeds as follows:. Training Examples: 1454377. Batch Size: 64. Epochs: 1. Steps per epoch: 22724. Steps per tune: 3162. Num train steps: 22724. **Log file**. Here is the top of the log file, including some warnings in case they are relevant:. ```. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(. 2024-08-28 10:40:42.588215: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_SYSTEM_DRIVER_MISMATCH: system has unsupported display driver / cuda driver combination. I0828 10:40:42.589054 140318776715072 train.py:92] Running with debug=False. I0828 10:40:42.589343 140318776715072 train.py:100] Use TPU at local. I0828 10:40:42.589422 140318776715072 train.py:103] experiment_dir: /home/training_outs/epoch1/. WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce. W0828 10:40:42.596594 140318776715072 cross_device_ops.py:1387] There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce. INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',). I0828 10:40:42.658734 140318776715072 mirrored_strategy.py:374] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',). /usr/local/lib/python3.8/dist-packages/keras/applications/inception_v3.py:138: UserWarning: This model usually expects 1 or 3 input chann",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:5353,deployability,updat,updating,5353,"magenet_utils.obtain_input_shape(. I0828 10:40:47.952382 140318776715072 keras_modeling.py:325] Number of l2 regularizers: 95. I0828 10:40:48.007193 140318776715072 keras_modeling.py:362] inceptionv3: load_weights from checkpoint: /home/training_outs/epoch1//checkpoints/ckpt-5997. I0828 10:40:49.193293 140318776715072 train.py:191] Exponential Decay: initial_learning_rate=0.0001. decay_steps=45448. learning_rate_decay_rate=0.947. I0828 10:40:49.193522 140318776715072 train.py:203] Use LinearWarmup:. warmup_steps=10000. warmup_learning_rate=1e-05. I0828 10:40:49.401860 140318776715072 keras_modeling.py:472] Restored checkpoint ckpt-5997 at step=0. tune/f1_weighted=tf.Tensor(0.0, shape=(), dtype=float32). WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23. Instructions for updating:. Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089. W0828 10:40:49.488072 140318776715072 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be rem>. Instructions for updating:. Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089. 2024-08-28 10:40:49.893797: W tensorflow/core/framework/dataset.cc:769] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations. I0828 10:40:49.947995 140318776715072 train.py:316]. ```. And here is an excerpt of from a later ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:5841,deployability,updat,updating,5841,"e LinearWarmup:. warmup_steps=10000. warmup_learning_rate=1e-05. I0828 10:40:49.401860 140318776715072 keras_modeling.py:472] Restored checkpoint ckpt-5997 at step=0. tune/f1_weighted=tf.Tensor(0.0, shape=(), dtype=float32). WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23. Instructions for updating:. Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089. W0828 10:40:49.488072 140318776715072 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be rem>. Instructions for updating:. Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089. 2024-08-28 10:40:49.893797: W tensorflow/core/framework/dataset.cc:769] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations. I0828 10:40:49.947995 140318776715072 train.py:316]. ```. And here is an excerpt of from a later portion of the log file including some training and tuning steps, where you can see the 0.0 for het and homalt eval stats. . ```. I0829 07:13:59.098341 140305134778112 logging_writer.py:48] [13700] epoch=0, train/categorical_accuracy=1.0, train/categorical_crossentropy=0.552009105682373, train/f1_het=0.0, train/f1_homalt=0.0, train/f1_homref=1.0, train/f1_macro=0.3333333432674408, train/f1_micro=1.0, train/f1_. weighted=1.0, train/false_negatives=0.0, train/false_positives=0.0, train",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:6372,deployability,log,log,6372,"tions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089. W0828 10:40:49.488072 140318776715072 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be rem>. Instructions for updating:. Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089. 2024-08-28 10:40:49.893797: W tensorflow/core/framework/dataset.cc:769] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations. I0828 10:40:49.947995 140318776715072 train.py:316]. ```. And here is an excerpt of from a later portion of the log file including some training and tuning steps, where you can see the 0.0 for het and homalt eval stats. . ```. I0829 07:13:59.098341 140305134778112 logging_writer.py:48] [13700] epoch=0, train/categorical_accuracy=1.0, train/categorical_crossentropy=0.552009105682373, train/f1_het=0.0, train/f1_homalt=0.0, train/f1_homref=1.0, train/f1_macro=0.3333333432674408, train/f1_micro=1.0, train/f1_. weighted=1.0, train/false_negatives=0.0, train/false_positives=0.0, train/learning_rate=9.999999747378752e-05, train/loss=0.5520098805427551, train/precision=1.0, train/precision_het=0.0, train/precision_homalt=0.0, train/precision_homref=1.0, train/recall=1.0, train/recall_het=0.0,. train/recall_homalt=0.0, train/recall_homref=1.0, train/true_negatives=12800.0, train/true_positives=6400.0. I0829 07:18:37.609363 140318776715072 local.py:41] Setting work unit notes: 0.3 steps/s, 60.6% (13778/22724), ETA: 8h52m. I0829 07:18:37.611700 140305134778112 logging_writer.py:48] [13778] steps_per_sec=0.28",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:14365,deployability,cluster,cluster,14365,"ne/loss=0.5603554248809814, tune/precision_1=0.9923615455627441, tune/precision_het=0.0, tune/precision_homalt=0.0, tune/precision_homref=1.0, tune/recall_1=0.9912189841270447, tune/recall_het=0.0, tune/recall_homalt=0.0, tune/recall_homref=0.9912189841270447, tune/true_negatives_1=403192.0, tune/true_positives_1=200591.0. I0829 08:30:42.590469 140318776715072 train.py:471] Skipping checkpoint with tune/f1_weighted=0.99583185 < previous best tune/f1_weighted=0.99845344. I0829 08:30:42.595992 140305134778112 logging_writer.py:48] [13993] tune/early_stopping=7. I0829 08:30:46.123329 140318776715072 local.py:41] Setting work unit notes: 0.0 steps/s, 61.6% (13994/22724), ETA: 8d4h11m. I0829 08:30:46.125013 140305134778112 logging_writer.py:48] [13994] steps_per_sec=0.0123604. I0829 08:30:46.125087 140305134778112 logging_writer.py:48] [13994] uptime=78596.1. I0829 08:31:07.673585 140305134778112 logging_writer.py:48] [14000] epoch=0, train/categorical_accuracy=1.0, train/categorical_crossentropy=0.5519920587539673, train/f1_het=0.0, train/f1_homalt=0.0, train/f1_homref=1.0, train/f1_macro=0.3333333432674408, train/f1_micro=1.0, train/f1_weighted=1.0, train/false_negatives=0.0, train/false_positives=0.0, train/learning_rate=9.999999747378752e-05, train/loss=0.551992654800415, train/precision=1.0, train/precision_het=0.0, train/precision_homalt=0.0, train/precision_homref=1.0, train/recall=1.0, train/recall_het=0.0, train/recall_homalt=0.0, train/recall_homref=1.0, train/true_negatives=12800.0, train/true_positives=6400.0. ```. I am new to Deep Learning and am struggling to decide whether something is wrong with my training approach/scripts or whether the model just needs more time / different hyperparams. Given the number of examples, I can only run 1 epoch at a time before I hit the 24hr cluster wall-time limit. So I have only trained for around 30,000 steps in total across 2 epochs so far (starting from last checkpoint after 1st epoch). . All advice much appreciated! .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:57,energy efficiency,model,model,57,"No evaluation statistics for het and homalt calls during model training; Hello DV team, and thanks for creating such a great tool! . I am currently trying to retrain the wgs model for a new species (a fish) however, during training, I see no evaluation statistics (precision, recall, f1) for either het or homalt. Or more specifically they are all 0.0. Eval stats are reported for homref though. I have now tried running the training several times with different hyperparameters but so far still no change at the het or homalt eval stats. . My first, very simple question is thus, are these eval stats truly 0 (i.e. the model is very bad) or is 0.0 some starting value and there are not enough data to calculate them initially? I am warmstarting from the 1.6.1 wgs model so I cant imagine the model is really that bad at calling variants initially, even if in a fish. . **Setup**. Running on a university computing cluster (https://hpc-unibe-ch.github.io/) . OS: Rocky 9.3 Blue Onyx. GPU: rtx4090 . Installation: Running from Docker image via singularity. DV version: 1.6.1. **Data**. I am training on examples from 5 individuals, data from Illumina NovaSeq ~20x coverage. . 17/21 chromosomes used for training (~1.45M examples). 2/21 chromosomes used for tuning (~200k examples). 2/21 chromosomes reserved for testing. . (Different chromosomes used for train/tune/test across samples - see below). <img width=""1437"" alt=""Screenshot 2024-08-07 at 09 30 23"" src=""https://github.com/user-attachments/assets/3178e87a-8cf7-47cb-84a2-0a84d15c958f"">. **Shuffling**. Performed downsampling=0.5. Shuffled globally across samples, chromosomes and downsampling. . **Command**. My latest training run was like so:. ```. apptainer run . --nv . -B $WD:/home . $DV_PATH . /opt/deepvariant/bin/train . --config=/home/dv_config.py:base . --config.train_dataset_pbtxt=""/home/examples_shuffled/train/All_samples_training_examples.dataset_config.pbtxt"" . --config.tune_dataset_pbtxt=""/home/examples_shuffled/tune/All_sa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:138,energy efficiency,current,currently,138,"No evaluation statistics for het and homalt calls during model training; Hello DV team, and thanks for creating such a great tool! . I am currently trying to retrain the wgs model for a new species (a fish) however, during training, I see no evaluation statistics (precision, recall, f1) for either het or homalt. Or more specifically they are all 0.0. Eval stats are reported for homref though. I have now tried running the training several times with different hyperparameters but so far still no change at the het or homalt eval stats. . My first, very simple question is thus, are these eval stats truly 0 (i.e. the model is very bad) or is 0.0 some starting value and there are not enough data to calculate them initially? I am warmstarting from the 1.6.1 wgs model so I cant imagine the model is really that bad at calling variants initially, even if in a fish. . **Setup**. Running on a university computing cluster (https://hpc-unibe-ch.github.io/) . OS: Rocky 9.3 Blue Onyx. GPU: rtx4090 . Installation: Running from Docker image via singularity. DV version: 1.6.1. **Data**. I am training on examples from 5 individuals, data from Illumina NovaSeq ~20x coverage. . 17/21 chromosomes used for training (~1.45M examples). 2/21 chromosomes used for tuning (~200k examples). 2/21 chromosomes reserved for testing. . (Different chromosomes used for train/tune/test across samples - see below). <img width=""1437"" alt=""Screenshot 2024-08-07 at 09 30 23"" src=""https://github.com/user-attachments/assets/3178e87a-8cf7-47cb-84a2-0a84d15c958f"">. **Shuffling**. Performed downsampling=0.5. Shuffled globally across samples, chromosomes and downsampling. . **Command**. My latest training run was like so:. ```. apptainer run . --nv . -B $WD:/home . $DV_PATH . /opt/deepvariant/bin/train . --config=/home/dv_config.py:base . --config.train_dataset_pbtxt=""/home/examples_shuffled/train/All_samples_training_examples.dataset_config.pbtxt"" . --config.tune_dataset_pbtxt=""/home/examples_shuffled/tune/All_sa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:174,energy efficiency,model,model,174,"No evaluation statistics for het and homalt calls during model training; Hello DV team, and thanks for creating such a great tool! . I am currently trying to retrain the wgs model for a new species (a fish) however, during training, I see no evaluation statistics (precision, recall, f1) for either het or homalt. Or more specifically they are all 0.0. Eval stats are reported for homref though. I have now tried running the training several times with different hyperparameters but so far still no change at the het or homalt eval stats. . My first, very simple question is thus, are these eval stats truly 0 (i.e. the model is very bad) or is 0.0 some starting value and there are not enough data to calculate them initially? I am warmstarting from the 1.6.1 wgs model so I cant imagine the model is really that bad at calling variants initially, even if in a fish. . **Setup**. Running on a university computing cluster (https://hpc-unibe-ch.github.io/) . OS: Rocky 9.3 Blue Onyx. GPU: rtx4090 . Installation: Running from Docker image via singularity. DV version: 1.6.1. **Data**. I am training on examples from 5 individuals, data from Illumina NovaSeq ~20x coverage. . 17/21 chromosomes used for training (~1.45M examples). 2/21 chromosomes used for tuning (~200k examples). 2/21 chromosomes reserved for testing. . (Different chromosomes used for train/tune/test across samples - see below). <img width=""1437"" alt=""Screenshot 2024-08-07 at 09 30 23"" src=""https://github.com/user-attachments/assets/3178e87a-8cf7-47cb-84a2-0a84d15c958f"">. **Shuffling**. Performed downsampling=0.5. Shuffled globally across samples, chromosomes and downsampling. . **Command**. My latest training run was like so:. ```. apptainer run . --nv . -B $WD:/home . $DV_PATH . /opt/deepvariant/bin/train . --config=/home/dv_config.py:base . --config.train_dataset_pbtxt=""/home/examples_shuffled/train/All_samples_training_examples.dataset_config.pbtxt"" . --config.tune_dataset_pbtxt=""/home/examples_shuffled/tune/All_sa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:620,energy efficiency,model,model,620,"No evaluation statistics for het and homalt calls during model training; Hello DV team, and thanks for creating such a great tool! . I am currently trying to retrain the wgs model for a new species (a fish) however, during training, I see no evaluation statistics (precision, recall, f1) for either het or homalt. Or more specifically they are all 0.0. Eval stats are reported for homref though. I have now tried running the training several times with different hyperparameters but so far still no change at the het or homalt eval stats. . My first, very simple question is thus, are these eval stats truly 0 (i.e. the model is very bad) or is 0.0 some starting value and there are not enough data to calculate them initially? I am warmstarting from the 1.6.1 wgs model so I cant imagine the model is really that bad at calling variants initially, even if in a fish. . **Setup**. Running on a university computing cluster (https://hpc-unibe-ch.github.io/) . OS: Rocky 9.3 Blue Onyx. GPU: rtx4090 . Installation: Running from Docker image via singularity. DV version: 1.6.1. **Data**. I am training on examples from 5 individuals, data from Illumina NovaSeq ~20x coverage. . 17/21 chromosomes used for training (~1.45M examples). 2/21 chromosomes used for tuning (~200k examples). 2/21 chromosomes reserved for testing. . (Different chromosomes used for train/tune/test across samples - see below). <img width=""1437"" alt=""Screenshot 2024-08-07 at 09 30 23"" src=""https://github.com/user-attachments/assets/3178e87a-8cf7-47cb-84a2-0a84d15c958f"">. **Shuffling**. Performed downsampling=0.5. Shuffled globally across samples, chromosomes and downsampling. . **Command**. My latest training run was like so:. ```. apptainer run . --nv . -B $WD:/home . $DV_PATH . /opt/deepvariant/bin/train . --config=/home/dv_config.py:base . --config.train_dataset_pbtxt=""/home/examples_shuffled/train/All_samples_training_examples.dataset_config.pbtxt"" . --config.tune_dataset_pbtxt=""/home/examples_shuffled/tune/All_sa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:765,energy efficiency,model,model,765,"No evaluation statistics for het and homalt calls during model training; Hello DV team, and thanks for creating such a great tool! . I am currently trying to retrain the wgs model for a new species (a fish) however, during training, I see no evaluation statistics (precision, recall, f1) for either het or homalt. Or more specifically they are all 0.0. Eval stats are reported for homref though. I have now tried running the training several times with different hyperparameters but so far still no change at the het or homalt eval stats. . My first, very simple question is thus, are these eval stats truly 0 (i.e. the model is very bad) or is 0.0 some starting value and there are not enough data to calculate them initially? I am warmstarting from the 1.6.1 wgs model so I cant imagine the model is really that bad at calling variants initially, even if in a fish. . **Setup**. Running on a university computing cluster (https://hpc-unibe-ch.github.io/) . OS: Rocky 9.3 Blue Onyx. GPU: rtx4090 . Installation: Running from Docker image via singularity. DV version: 1.6.1. **Data**. I am training on examples from 5 individuals, data from Illumina NovaSeq ~20x coverage. . 17/21 chromosomes used for training (~1.45M examples). 2/21 chromosomes used for tuning (~200k examples). 2/21 chromosomes reserved for testing. . (Different chromosomes used for train/tune/test across samples - see below). <img width=""1437"" alt=""Screenshot 2024-08-07 at 09 30 23"" src=""https://github.com/user-attachments/assets/3178e87a-8cf7-47cb-84a2-0a84d15c958f"">. **Shuffling**. Performed downsampling=0.5. Shuffled globally across samples, chromosomes and downsampling. . **Command**. My latest training run was like so:. ```. apptainer run . --nv . -B $WD:/home . $DV_PATH . /opt/deepvariant/bin/train . --config=/home/dv_config.py:base . --config.train_dataset_pbtxt=""/home/examples_shuffled/train/All_samples_training_examples.dataset_config.pbtxt"" . --config.tune_dataset_pbtxt=""/home/examples_shuffled/tune/All_sa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:793,energy efficiency,model,model,793,"No evaluation statistics for het and homalt calls during model training; Hello DV team, and thanks for creating such a great tool! . I am currently trying to retrain the wgs model for a new species (a fish) however, during training, I see no evaluation statistics (precision, recall, f1) for either het or homalt. Or more specifically they are all 0.0. Eval stats are reported for homref though. I have now tried running the training several times with different hyperparameters but so far still no change at the het or homalt eval stats. . My first, very simple question is thus, are these eval stats truly 0 (i.e. the model is very bad) or is 0.0 some starting value and there are not enough data to calculate them initially? I am warmstarting from the 1.6.1 wgs model so I cant imagine the model is really that bad at calling variants initially, even if in a fish. . **Setup**. Running on a university computing cluster (https://hpc-unibe-ch.github.io/) . OS: Rocky 9.3 Blue Onyx. GPU: rtx4090 . Installation: Running from Docker image via singularity. DV version: 1.6.1. **Data**. I am training on examples from 5 individuals, data from Illumina NovaSeq ~20x coverage. . 17/21 chromosomes used for training (~1.45M examples). 2/21 chromosomes used for tuning (~200k examples). 2/21 chromosomes reserved for testing. . (Different chromosomes used for train/tune/test across samples - see below). <img width=""1437"" alt=""Screenshot 2024-08-07 at 09 30 23"" src=""https://github.com/user-attachments/assets/3178e87a-8cf7-47cb-84a2-0a84d15c958f"">. **Shuffling**. Performed downsampling=0.5. Shuffled globally across samples, chromosomes and downsampling. . **Command**. My latest training run was like so:. ```. apptainer run . --nv . -B $WD:/home . $DV_PATH . /opt/deepvariant/bin/train . --config=/home/dv_config.py:base . --config.train_dataset_pbtxt=""/home/examples_shuffled/train/All_samples_training_examples.dataset_config.pbtxt"" . --config.tune_dataset_pbtxt=""/home/examples_shuffled/tune/All_sa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:984,energy efficiency,GPU,GPU,984,"No evaluation statistics for het and homalt calls during model training; Hello DV team, and thanks for creating such a great tool! . I am currently trying to retrain the wgs model for a new species (a fish) however, during training, I see no evaluation statistics (precision, recall, f1) for either het or homalt. Or more specifically they are all 0.0. Eval stats are reported for homref though. I have now tried running the training several times with different hyperparameters but so far still no change at the het or homalt eval stats. . My first, very simple question is thus, are these eval stats truly 0 (i.e. the model is very bad) or is 0.0 some starting value and there are not enough data to calculate them initially? I am warmstarting from the 1.6.1 wgs model so I cant imagine the model is really that bad at calling variants initially, even if in a fish. . **Setup**. Running on a university computing cluster (https://hpc-unibe-ch.github.io/) . OS: Rocky 9.3 Blue Onyx. GPU: rtx4090 . Installation: Running from Docker image via singularity. DV version: 1.6.1. **Data**. I am training on examples from 5 individuals, data from Illumina NovaSeq ~20x coverage. . 17/21 chromosomes used for training (~1.45M examples). 2/21 chromosomes used for tuning (~200k examples). 2/21 chromosomes reserved for testing. . (Different chromosomes used for train/tune/test across samples - see below). <img width=""1437"" alt=""Screenshot 2024-08-07 at 09 30 23"" src=""https://github.com/user-attachments/assets/3178e87a-8cf7-47cb-84a2-0a84d15c958f"">. **Shuffling**. Performed downsampling=0.5. Shuffled globally across samples, chromosomes and downsampling. . **Command**. My latest training run was like so:. ```. apptainer run . --nv . -B $WD:/home . $DV_PATH . /opt/deepvariant/bin/train . --config=/home/dv_config.py:base . --config.train_dataset_pbtxt=""/home/examples_shuffled/train/All_samples_training_examples.dataset_config.pbtxt"" . --config.tune_dataset_pbtxt=""/home/examples_shuffled/tune/All_sa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:3673,energy efficiency,GPU,GPU,3673,"al/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(. 2024-08-28 10:40:42.588215: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_SYSTEM_DRIVER_MISMATCH: system has unsupported display driver / cuda driver combination. I0828 10:40:42.589054 140318776715072 train.py:92] Running with debug=False. I0828 10:40:42.589343 140318776715072 train.py:100] Use TPU at local. I0828 10:40:42.589422 140318776715072 train.py:103] experiment_dir: /home/training_outs/epoch1/. WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce. W0828 10:40:42.596594 140318776715072 cross_device_ops.py:1387] There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce. INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',). I0828 10:40:42.658734 140318776715072 mirrored_strategy.py:374] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',). /usr/local/lib/python3.8/dist-packages/keras/applications/inception_v3.py:138: UserWarning: This model usually expects 1 or 3 input channels. However, it was passed an input_shape with 7 input channels. input_shape = imagenet_utils.obtain_input_shape(. I0828 10:40:47.952382 140318776715072 keras_modeling.py:325] Number of l2 regularizers: 95. I0828 10:40:48.007193 140318776715072 keras_modeling.py:362] inceptionv3: load_weights from checkpoint: /home/training_outs/epoch1//checkpoints/ckpt-5997. I0828 10:40:49.193293 14031877671507",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:3818,energy efficiency,GPU,GPU,3818,"ction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(. 2024-08-28 10:40:42.588215: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_SYSTEM_DRIVER_MISMATCH: system has unsupported display driver / cuda driver combination. I0828 10:40:42.589054 140318776715072 train.py:92] Running with debug=False. I0828 10:40:42.589343 140318776715072 train.py:100] Use TPU at local. I0828 10:40:42.589422 140318776715072 train.py:103] experiment_dir: /home/training_outs/epoch1/. WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce. W0828 10:40:42.596594 140318776715072 cross_device_ops.py:1387] There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce. INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',). I0828 10:40:42.658734 140318776715072 mirrored_strategy.py:374] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',). /usr/local/lib/python3.8/dist-packages/keras/applications/inception_v3.py:138: UserWarning: This model usually expects 1 or 3 input channels. However, it was passed an input_shape with 7 input channels. input_shape = imagenet_utils.obtain_input_shape(. I0828 10:40:47.952382 140318776715072 keras_modeling.py:325] Number of l2 regularizers: 95. I0828 10:40:48.007193 140318776715072 keras_modeling.py:362] inceptionv3: load_weights from checkpoint: /home/training_outs/epoch1//checkpoints/ckpt-5997. I0828 10:40:49.193293 140318776715072 train.py:191] Exponential Decay: initial_learning_rate=0.0001. decay_steps=45448. learning_rate_decay_rate=0.947. I0828 10:40:49.193522 1403187",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:3978,energy efficiency,CPU,CPU,3978,"e dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(. 2024-08-28 10:40:42.588215: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_SYSTEM_DRIVER_MISMATCH: system has unsupported display driver / cuda driver combination. I0828 10:40:42.589054 140318776715072 train.py:92] Running with debug=False. I0828 10:40:42.589343 140318776715072 train.py:100] Use TPU at local. I0828 10:40:42.589422 140318776715072 train.py:103] experiment_dir: /home/training_outs/epoch1/. WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce. W0828 10:40:42.596594 140318776715072 cross_device_ops.py:1387] There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce. INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',). I0828 10:40:42.658734 140318776715072 mirrored_strategy.py:374] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',). /usr/local/lib/python3.8/dist-packages/keras/applications/inception_v3.py:138: UserWarning: This model usually expects 1 or 3 input channels. However, it was passed an input_shape with 7 input channels. input_shape = imagenet_utils.obtain_input_shape(. I0828 10:40:47.952382 140318776715072 keras_modeling.py:325] Number of l2 regularizers: 95. I0828 10:40:48.007193 140318776715072 keras_modeling.py:362] inceptionv3: load_weights from checkpoint: /home/training_outs/epoch1//checkpoints/ckpt-5997. I0828 10:40:49.193293 140318776715072 train.py:191] Exponential Decay: initial_learning_rate=0.0001. decay_steps=45448. learning_rate_decay_rate=0.947. I0828 10:40:49.193522 140318776715072 train.py:203] Use LinearWarmup:. warmup_steps=10000. warmup_learning_rate=1e-05. I0828 10:40:49.401860 140318776715072 keras_modeling.py:472] Restored ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:4129,energy efficiency,CPU,CPU,4129,"tensorflow/addons/issues/2807. warnings.warn(. 2024-08-28 10:40:42.588215: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_SYSTEM_DRIVER_MISMATCH: system has unsupported display driver / cuda driver combination. I0828 10:40:42.589054 140318776715072 train.py:92] Running with debug=False. I0828 10:40:42.589343 140318776715072 train.py:100] Use TPU at local. I0828 10:40:42.589422 140318776715072 train.py:103] experiment_dir: /home/training_outs/epoch1/. WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce. W0828 10:40:42.596594 140318776715072 cross_device_ops.py:1387] There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce. INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',). I0828 10:40:42.658734 140318776715072 mirrored_strategy.py:374] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',). /usr/local/lib/python3.8/dist-packages/keras/applications/inception_v3.py:138: UserWarning: This model usually expects 1 or 3 input channels. However, it was passed an input_shape with 7 input channels. input_shape = imagenet_utils.obtain_input_shape(. I0828 10:40:47.952382 140318776715072 keras_modeling.py:325] Number of l2 regularizers: 95. I0828 10:40:48.007193 140318776715072 keras_modeling.py:362] inceptionv3: load_weights from checkpoint: /home/training_outs/epoch1//checkpoints/ckpt-5997. I0828 10:40:49.193293 140318776715072 train.py:191] Exponential Decay: initial_learning_rate=0.0001. decay_steps=45448. learning_rate_decay_rate=0.947. I0828 10:40:49.193522 140318776715072 train.py:203] Use LinearWarmup:. warmup_steps=10000. warmup_learning_rate=1e-05. I0828 10:40:49.401860 140318776715072 keras_modeling.py:472] Restored checkpoint ckpt-5997 at step=0. tune/f1_weighted=tf.Tensor(0.0, shape=(), dtype=float32). WARNING:tensorflow:From /usr/local/lib/python3.8/dist-package",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:4236,energy efficiency,model,model,4236,"executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_SYSTEM_DRIVER_MISMATCH: system has unsupported display driver / cuda driver combination. I0828 10:40:42.589054 140318776715072 train.py:92] Running with debug=False. I0828 10:40:42.589343 140318776715072 train.py:100] Use TPU at local. I0828 10:40:42.589422 140318776715072 train.py:103] experiment_dir: /home/training_outs/epoch1/. WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce. W0828 10:40:42.596594 140318776715072 cross_device_ops.py:1387] There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce. INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',). I0828 10:40:42.658734 140318776715072 mirrored_strategy.py:374] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',). /usr/local/lib/python3.8/dist-packages/keras/applications/inception_v3.py:138: UserWarning: This model usually expects 1 or 3 input channels. However, it was passed an input_shape with 7 input channels. input_shape = imagenet_utils.obtain_input_shape(. I0828 10:40:47.952382 140318776715072 keras_modeling.py:325] Number of l2 regularizers: 95. I0828 10:40:48.007193 140318776715072 keras_modeling.py:362] inceptionv3: load_weights from checkpoint: /home/training_outs/epoch1//checkpoints/ckpt-5997. I0828 10:40:49.193293 140318776715072 train.py:191] Exponential Decay: initial_learning_rate=0.0001. decay_steps=45448. learning_rate_decay_rate=0.947. I0828 10:40:49.193522 140318776715072 train.py:203] Use LinearWarmup:. warmup_steps=10000. warmup_learning_rate=1e-05. I0828 10:40:49.401860 140318776715072 keras_modeling.py:472] Restored checkpoint ckpt-5997 at step=0. tune/f1_weighted=tf.Tensor(0.0, shape=(), dtype=float32). WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.pyt",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:6068,energy efficiency,core,core,6068,"WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23. Instructions for updating:. Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089. W0828 10:40:49.488072 140318776715072 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be rem>. Instructions for updating:. Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089. 2024-08-28 10:40:49.893797: W tensorflow/core/framework/dataset.cc:769] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations. I0828 10:40:49.947995 140318776715072 train.py:316]. ```. And here is an excerpt of from a later portion of the log file including some training and tuning steps, where you can see the 0.0 for het and homalt eval stats. . ```. I0829 07:13:59.098341 140305134778112 logging_writer.py:48] [13700] epoch=0, train/categorical_accuracy=1.0, train/categorical_crossentropy=0.552009105682373, train/f1_het=0.0, train/f1_homalt=0.0, train/f1_homref=1.0, train/f1_macro=0.3333333432674408, train/f1_micro=1.0, train/f1_. weighted=1.0, train/false_negatives=0.0, train/false_positives=0.0, train/learning_rate=9.999999747378752e-05, train/loss=0.5520098805427551, train/precision=1.0, train/precision_het=0.0, train/precision_homalt=0.0, train/precision_homref=1.0, train/recall=1.0, train/recall_het=0.0,. train/recall_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:6148,energy efficiency,optim,optimized,6148,"tograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23. Instructions for updating:. Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089. W0828 10:40:49.488072 140318776715072 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be rem>. Instructions for updating:. Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089. 2024-08-28 10:40:49.893797: W tensorflow/core/framework/dataset.cc:769] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations. I0828 10:40:49.947995 140318776715072 train.py:316]. ```. And here is an excerpt of from a later portion of the log file including some training and tuning steps, where you can see the 0.0 for het and homalt eval stats. . ```. I0829 07:13:59.098341 140305134778112 logging_writer.py:48] [13700] epoch=0, train/categorical_accuracy=1.0, train/categorical_crossentropy=0.552009105682373, train/f1_het=0.0, train/f1_homalt=0.0, train/f1_homref=1.0, train/f1_macro=0.3333333432674408, train/f1_micro=1.0, train/f1_. weighted=1.0, train/false_negatives=0.0, train/false_positives=0.0, train/learning_rate=9.999999747378752e-05, train/loss=0.5520098805427551, train/precision=1.0, train/precision_het=0.0, train/precision_homalt=0.0, train/precision_homref=1.0, train/recall=1.0, train/recall_het=0.0,. train/recall_homalt=0.0, train/recall_homref=1.0, train/true_negatives=12800.0, train/true_posit",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:6245,energy efficiency,optim,optimizations,6245,".pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23. Instructions for updating:. Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089. W0828 10:40:49.488072 140318776715072 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be rem>. Instructions for updating:. Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089. 2024-08-28 10:40:49.893797: W tensorflow/core/framework/dataset.cc:769] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations. I0828 10:40:49.947995 140318776715072 train.py:316]. ```. And here is an excerpt of from a later portion of the log file including some training and tuning steps, where you can see the 0.0 for het and homalt eval stats. . ```. I0829 07:13:59.098341 140305134778112 logging_writer.py:48] [13700] epoch=0, train/categorical_accuracy=1.0, train/categorical_crossentropy=0.552009105682373, train/f1_het=0.0, train/f1_homalt=0.0, train/f1_homref=1.0, train/f1_macro=0.3333333432674408, train/f1_micro=1.0, train/f1_. weighted=1.0, train/false_negatives=0.0, train/false_positives=0.0, train/learning_rate=9.999999747378752e-05, train/loss=0.5520098805427551, train/precision=1.0, train/precision_het=0.0, train/precision_homalt=0.0, train/precision_homref=1.0, train/recall=1.0, train/recall_het=0.0,. train/recall_homalt=0.0, train/recall_homref=1.0, train/true_negatives=12800.0, train/true_positives=6400.0. I0829 07:18:37.609363 140318776715072 local.py:41] Setting work unit notes: 0.3 steps/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:14228,energy efficiency,model,model,14228,"ne/loss=0.5603554248809814, tune/precision_1=0.9923615455627441, tune/precision_het=0.0, tune/precision_homalt=0.0, tune/precision_homref=1.0, tune/recall_1=0.9912189841270447, tune/recall_het=0.0, tune/recall_homalt=0.0, tune/recall_homref=0.9912189841270447, tune/true_negatives_1=403192.0, tune/true_positives_1=200591.0. I0829 08:30:42.590469 140318776715072 train.py:471] Skipping checkpoint with tune/f1_weighted=0.99583185 < previous best tune/f1_weighted=0.99845344. I0829 08:30:42.595992 140305134778112 logging_writer.py:48] [13993] tune/early_stopping=7. I0829 08:30:46.123329 140318776715072 local.py:41] Setting work unit notes: 0.0 steps/s, 61.6% (13994/22724), ETA: 8d4h11m. I0829 08:30:46.125013 140305134778112 logging_writer.py:48] [13994] steps_per_sec=0.0123604. I0829 08:30:46.125087 140305134778112 logging_writer.py:48] [13994] uptime=78596.1. I0829 08:31:07.673585 140305134778112 logging_writer.py:48] [14000] epoch=0, train/categorical_accuracy=1.0, train/categorical_crossentropy=0.5519920587539673, train/f1_het=0.0, train/f1_homalt=0.0, train/f1_homref=1.0, train/f1_macro=0.3333333432674408, train/f1_micro=1.0, train/f1_weighted=1.0, train/false_negatives=0.0, train/false_positives=0.0, train/learning_rate=9.999999747378752e-05, train/loss=0.551992654800415, train/precision=1.0, train/precision_het=0.0, train/precision_homalt=0.0, train/precision_homref=1.0, train/recall=1.0, train/recall_het=0.0, train/recall_homalt=0.0, train/recall_homref=1.0, train/true_negatives=12800.0, train/true_positives=6400.0. ```. I am new to Deep Learning and am struggling to decide whether something is wrong with my training approach/scripts or whether the model just needs more time / different hyperparams. Given the number of examples, I can only run 1 epoch at a time before I hit the 24hr cluster wall-time limit. So I have only trained for around 30,000 steps in total across 2 epochs so far (starting from last checkpoint after 1st epoch). . All advice much appreciated! .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:1059,integrability,version,version,1059,"training; Hello DV team, and thanks for creating such a great tool! . I am currently trying to retrain the wgs model for a new species (a fish) however, during training, I see no evaluation statistics (precision, recall, f1) for either het or homalt. Or more specifically they are all 0.0. Eval stats are reported for homref though. I have now tried running the training several times with different hyperparameters but so far still no change at the het or homalt eval stats. . My first, very simple question is thus, are these eval stats truly 0 (i.e. the model is very bad) or is 0.0 some starting value and there are not enough data to calculate them initially? I am warmstarting from the 1.6.1 wgs model so I cant imagine the model is really that bad at calling variants initially, even if in a fish. . **Setup**. Running on a university computing cluster (https://hpc-unibe-ch.github.io/) . OS: Rocky 9.3 Blue Onyx. GPU: rtx4090 . Installation: Running from Docker image via singularity. DV version: 1.6.1. **Data**. I am training on examples from 5 individuals, data from Illumina NovaSeq ~20x coverage. . 17/21 chromosomes used for training (~1.45M examples). 2/21 chromosomes used for tuning (~200k examples). 2/21 chromosomes reserved for testing. . (Different chromosomes used for train/tune/test across samples - see below). <img width=""1437"" alt=""Screenshot 2024-08-07 at 09 30 23"" src=""https://github.com/user-attachments/assets/3178e87a-8cf7-47cb-84a2-0a84d15c958f"">. **Shuffling**. Performed downsampling=0.5. Shuffled globally across samples, chromosomes and downsampling. . **Command**. My latest training run was like so:. ```. apptainer run . --nv . -B $WD:/home . $DV_PATH . /opt/deepvariant/bin/train . --config=/home/dv_config.py:base . --config.train_dataset_pbtxt=""/home/examples_shuffled/train/All_samples_training_examples.dataset_config.pbtxt"" . --config.tune_dataset_pbtxt=""/home/examples_shuffled/tune/All_samples_tune_examples.dataset_config.pbtxt"". . --config.num_epoch",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:2388,integrability,batch,batch,2388,"below). <img width=""1437"" alt=""Screenshot 2024-08-07 at 09 30 23"" src=""https://github.com/user-attachments/assets/3178e87a-8cf7-47cb-84a2-0a84d15c958f"">. **Shuffling**. Performed downsampling=0.5. Shuffled globally across samples, chromosomes and downsampling. . **Command**. My latest training run was like so:. ```. apptainer run . --nv . -B $WD:/home . $DV_PATH . /opt/deepvariant/bin/train . --config=/home/dv_config.py:base . --config.train_dataset_pbtxt=""/home/examples_shuffled/train/All_samples_training_examples.dataset_config.pbtxt"" . --config.tune_dataset_pbtxt=""/home/examples_shuffled/tune/All_samples_tune_examples.dataset_config.pbtxt"". . --config.num_epochs=1 . --config.learning_rate=0.0001 . --config.num_validation_examples=0 . --config.tune_every_steps=2000 . --experiment_dir=/home/${OUTDIR} . --strategy=mirrored . --config.batch_size=64 . --config.init_checkpoint=""/home/model_wgs_v1.6.1/deepvariant.wgs.ckpt"". ```. Though previous runs had higher learning rates (0.01) and batch sizes (128). Training proceeds as follows:. Training Examples: 1454377. Batch Size: 64. Epochs: 1. Steps per epoch: 22724. Steps per tune: 3162. Num train steps: 22724. **Log file**. Here is the top of the log file, including some warnings in case they are relevant:. ```. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(. 2024-08-28 10:40:42.588215: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_SYSTEM_DRIVER_MISMATCH: system has unsupported display driver / cuda driver combinat",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:2466,integrability,Batch,Batch,2466,"/github.com/user-attachments/assets/3178e87a-8cf7-47cb-84a2-0a84d15c958f"">. **Shuffling**. Performed downsampling=0.5. Shuffled globally across samples, chromosomes and downsampling. . **Command**. My latest training run was like so:. ```. apptainer run . --nv . -B $WD:/home . $DV_PATH . /opt/deepvariant/bin/train . --config=/home/dv_config.py:base . --config.train_dataset_pbtxt=""/home/examples_shuffled/train/All_samples_training_examples.dataset_config.pbtxt"" . --config.tune_dataset_pbtxt=""/home/examples_shuffled/tune/All_samples_tune_examples.dataset_config.pbtxt"". . --config.num_epochs=1 . --config.learning_rate=0.0001 . --config.num_validation_examples=0 . --config.tune_every_steps=2000 . --experiment_dir=/home/${OUTDIR} . --strategy=mirrored . --config.batch_size=64 . --config.init_checkpoint=""/home/model_wgs_v1.6.1/deepvariant.wgs.ckpt"". ```. Though previous runs had higher learning rates (0.01) and batch sizes (128). Training proceeds as follows:. Training Examples: 1454377. Batch Size: 64. Epochs: 1. Steps per epoch: 22724. Steps per tune: 3162. Num train steps: 22724. **Log file**. Here is the top of the log file, including some warnings in case they are relevant:. ```. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(. 2024-08-28 10:40:42.588215: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_SYSTEM_DRIVER_MISMATCH: system has unsupported display driver / cuda driver combination. I0828 10:40:42.589054 140318776715072 train.py:92] Running with debug=Fal",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:2982,integrability,depend,dependencies,2982,"/tune/All_samples_tune_examples.dataset_config.pbtxt"". . --config.num_epochs=1 . --config.learning_rate=0.0001 . --config.num_validation_examples=0 . --config.tune_every_steps=2000 . --experiment_dir=/home/${OUTDIR} . --strategy=mirrored . --config.batch_size=64 . --config.init_checkpoint=""/home/model_wgs_v1.6.1/deepvariant.wgs.ckpt"". ```. Though previous runs had higher learning rates (0.01) and batch sizes (128). Training proceeds as follows:. Training Examples: 1454377. Batch Size: 64. Epochs: 1. Steps per epoch: 22724. Steps per tune: 3162. Num train steps: 22724. **Log file**. Here is the top of the log file, including some warnings in case they are relevant:. ```. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(. 2024-08-28 10:40:42.588215: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_SYSTEM_DRIVER_MISMATCH: system has unsupported display driver / cuda driver combination. I0828 10:40:42.589054 140318776715072 train.py:92] Running with debug=False. I0828 10:40:42.589343 140318776715072 train.py:100] Use TPU at local. I0828 10:40:42.589422 140318776715072 train.py:103] experiment_dir: /home/training_outs/epoch1/. WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce. W0828 10:40:42.596594 140318776715072 cross_device_ops.py:1387] There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce. INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',). ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:3006,integrability,repositor,repositories,3006,"xamples.dataset_config.pbtxt"". . --config.num_epochs=1 . --config.learning_rate=0.0001 . --config.num_validation_examples=0 . --config.tune_every_steps=2000 . --experiment_dir=/home/${OUTDIR} . --strategy=mirrored . --config.batch_size=64 . --config.init_checkpoint=""/home/model_wgs_v1.6.1/deepvariant.wgs.ckpt"". ```. Though previous runs had higher learning rates (0.01) and batch sizes (128). Training proceeds as follows:. Training Examples: 1454377. Batch Size: 64. Epochs: 1. Steps per epoch: 22724. Steps per tune: 3162. Num train steps: 22724. **Log file**. Here is the top of the log file, including some warnings in case they are relevant:. ```. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(. 2024-08-28 10:40:42.588215: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_SYSTEM_DRIVER_MISMATCH: system has unsupported display driver / cuda driver combination. I0828 10:40:42.589054 140318776715072 train.py:92] Running with debug=False. I0828 10:40:42.589343 140318776715072 train.py:100] Use TPU at local. I0828 10:40:42.589422 140318776715072 train.py:103] experiment_dir: /home/training_outs/epoch1/. WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce. W0828 10:40:42.596594 140318776715072 cross_device_ops.py:1387] There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce. INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',). I0828 10:40:42.658734 14",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:5422,integrability,state,statement,5422,"72 keras_modeling.py:325] Number of l2 regularizers: 95. I0828 10:40:48.007193 140318776715072 keras_modeling.py:362] inceptionv3: load_weights from checkpoint: /home/training_outs/epoch1//checkpoints/ckpt-5997. I0828 10:40:49.193293 140318776715072 train.py:191] Exponential Decay: initial_learning_rate=0.0001. decay_steps=45448. learning_rate_decay_rate=0.947. I0828 10:40:49.193522 140318776715072 train.py:203] Use LinearWarmup:. warmup_steps=10000. warmup_learning_rate=1e-05. I0828 10:40:49.401860 140318776715072 keras_modeling.py:472] Restored checkpoint ckpt-5997 at step=0. tune/f1_weighted=tf.Tensor(0.0, shape=(), dtype=float32). WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23. Instructions for updating:. Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089. W0828 10:40:49.488072 140318776715072 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be rem>. Instructions for updating:. Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089. 2024-08-28 10:40:49.893797: W tensorflow/core/framework/dataset.cc:769] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations. I0828 10:40:49.947995 140318776715072 train.py:316]. ```. And here is an excerpt of from a later portion of the log file including some training and tuning steps, wher",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:5910,integrability,state,statement,5910," 10:40:49.401860 140318776715072 keras_modeling.py:472] Restored checkpoint ckpt-5997 at step=0. tune/f1_weighted=tf.Tensor(0.0, shape=(), dtype=float32). WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23. Instructions for updating:. Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089. W0828 10:40:49.488072 140318776715072 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be rem>. Instructions for updating:. Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089. 2024-08-28 10:40:49.893797: W tensorflow/core/framework/dataset.cc:769] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations. I0828 10:40:49.947995 140318776715072 train.py:316]. ```. And here is an excerpt of from a later portion of the log file including some training and tuning steps, where you can see the 0.0 for het and homalt eval stats. . ```. I0829 07:13:59.098341 140305134778112 logging_writer.py:48] [13700] epoch=0, train/categorical_accuracy=1.0, train/categorical_crossentropy=0.552009105682373, train/f1_het=0.0, train/f1_homalt=0.0, train/f1_homref=1.0, train/f1_macro=0.3333333432674408, train/f1_micro=1.0, train/f1_. weighted=1.0, train/false_negatives=0.0, train/false_positives=0.0, train/learning_rate=9.999999747378752e-05, train/loss=0.5520098805427551, t",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:322,interoperability,specif,specifically,322,"No evaluation statistics for het and homalt calls during model training; Hello DV team, and thanks for creating such a great tool! . I am currently trying to retrain the wgs model for a new species (a fish) however, during training, I see no evaluation statistics (precision, recall, f1) for either het or homalt. Or more specifically they are all 0.0. Eval stats are reported for homref though. I have now tried running the training several times with different hyperparameters but so far still no change at the het or homalt eval stats. . My first, very simple question is thus, are these eval stats truly 0 (i.e. the model is very bad) or is 0.0 some starting value and there are not enough data to calculate them initially? I am warmstarting from the 1.6.1 wgs model so I cant imagine the model is really that bad at calling variants initially, even if in a fish. . **Setup**. Running on a university computing cluster (https://hpc-unibe-ch.github.io/) . OS: Rocky 9.3 Blue Onyx. GPU: rtx4090 . Installation: Running from Docker image via singularity. DV version: 1.6.1. **Data**. I am training on examples from 5 individuals, data from Illumina NovaSeq ~20x coverage. . 17/21 chromosomes used for training (~1.45M examples). 2/21 chromosomes used for tuning (~200k examples). 2/21 chromosomes reserved for testing. . (Different chromosomes used for train/tune/test across samples - see below). <img width=""1437"" alt=""Screenshot 2024-08-07 at 09 30 23"" src=""https://github.com/user-attachments/assets/3178e87a-8cf7-47cb-84a2-0a84d15c958f"">. **Shuffling**. Performed downsampling=0.5. Shuffled globally across samples, chromosomes and downsampling. . **Command**. My latest training run was like so:. ```. apptainer run . --nv . -B $WD:/home . $DV_PATH . /opt/deepvariant/bin/train . --config=/home/dv_config.py:base . --config.train_dataset_pbtxt=""/home/examples_shuffled/train/All_samples_training_examples.dataset_config.pbtxt"" . --config.tune_dataset_pbtxt=""/home/examples_shuffled/tune/All_sa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:3006,interoperability,repositor,repositories,3006,"xamples.dataset_config.pbtxt"". . --config.num_epochs=1 . --config.learning_rate=0.0001 . --config.num_validation_examples=0 . --config.tune_every_steps=2000 . --experiment_dir=/home/${OUTDIR} . --strategy=mirrored . --config.batch_size=64 . --config.init_checkpoint=""/home/model_wgs_v1.6.1/deepvariant.wgs.ckpt"". ```. Though previous runs had higher learning rates (0.01) and batch sizes (128). Training proceeds as follows:. Training Examples: 1454377. Batch Size: 64. Epochs: 1. Steps per epoch: 22724. Steps per tune: 3162. Num train steps: 22724. **Log file**. Here is the top of the log file, including some warnings in case they are relevant:. ```. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(. 2024-08-28 10:40:42.588215: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_SYSTEM_DRIVER_MISMATCH: system has unsupported display driver / cuda driver combination. I0828 10:40:42.589054 140318776715072 train.py:92] Running with debug=False. I0828 10:40:42.589343 140318776715072 train.py:100] Use TPU at local. I0828 10:40:42.589422 140318776715072 train.py:103] experiment_dir: /home/training_outs/epoch1/. WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce. W0828 10:40:42.596594 140318776715072 cross_device_ops.py:1387] There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce. INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',). I0828 10:40:42.658734 14",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:3692,interoperability,distribut,distribute,3692,"packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(. 2024-08-28 10:40:42.588215: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_SYSTEM_DRIVER_MISMATCH: system has unsupported display driver / cuda driver combination. I0828 10:40:42.589054 140318776715072 train.py:92] Running with debug=False. I0828 10:40:42.589343 140318776715072 train.py:100] Use TPU at local. I0828 10:40:42.589422 140318776715072 train.py:103] experiment_dir: /home/training_outs/epoch1/. WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce. W0828 10:40:42.596594 140318776715072 cross_device_ops.py:1387] There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce. INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',). I0828 10:40:42.658734 140318776715072 mirrored_strategy.py:374] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',). /usr/local/lib/python3.8/dist-packages/keras/applications/inception_v3.py:138: UserWarning: This model usually expects 1 or 3 input channels. However, it was passed an input_shape with 7 input channels. input_shape = imagenet_utils.obtain_input_shape(. I0828 10:40:47.952382 140318776715072 keras_modeling.py:325] Number of l2 regularizers: 95. I0828 10:40:48.007193 140318776715072 keras_modeling.py:362] inceptionv3: load_weights from checkpoint: /home/training_outs/epoch1//checkpoints/ckpt-5997. I0828 10:40:49.193293 140318776715072 train.py:191] Expone",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:3837,interoperability,distribut,distribute,3837," TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(. 2024-08-28 10:40:42.588215: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_SYSTEM_DRIVER_MISMATCH: system has unsupported display driver / cuda driver combination. I0828 10:40:42.589054 140318776715072 train.py:92] Running with debug=False. I0828 10:40:42.589343 140318776715072 train.py:100] Use TPU at local. I0828 10:40:42.589422 140318776715072 train.py:103] experiment_dir: /home/training_outs/epoch1/. WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce. W0828 10:40:42.596594 140318776715072 cross_device_ops.py:1387] There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce. INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',). I0828 10:40:42.658734 140318776715072 mirrored_strategy.py:374] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',). /usr/local/lib/python3.8/dist-packages/keras/applications/inception_v3.py:138: UserWarning: This model usually expects 1 or 3 input channels. However, it was passed an input_shape with 7 input channels. input_shape = imagenet_utils.obtain_input_shape(. I0828 10:40:47.952382 140318776715072 keras_modeling.py:325] Number of l2 regularizers: 95. I0828 10:40:48.007193 140318776715072 keras_modeling.py:362] inceptionv3: load_weights from checkpoint: /home/training_outs/epoch1//checkpoints/ckpt-5997. I0828 10:40:49.193293 140318776715072 train.py:191] Exponential Decay: initial_learning_rate=0.0001. decay_steps=45448. learning_rate_decay_rate=0.947. I0828 10:40:49.193522 140318776715072 train.py:203]",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:1059,modifiability,version,version,1059,"training; Hello DV team, and thanks for creating such a great tool! . I am currently trying to retrain the wgs model for a new species (a fish) however, during training, I see no evaluation statistics (precision, recall, f1) for either het or homalt. Or more specifically they are all 0.0. Eval stats are reported for homref though. I have now tried running the training several times with different hyperparameters but so far still no change at the het or homalt eval stats. . My first, very simple question is thus, are these eval stats truly 0 (i.e. the model is very bad) or is 0.0 some starting value and there are not enough data to calculate them initially? I am warmstarting from the 1.6.1 wgs model so I cant imagine the model is really that bad at calling variants initially, even if in a fish. . **Setup**. Running on a university computing cluster (https://hpc-unibe-ch.github.io/) . OS: Rocky 9.3 Blue Onyx. GPU: rtx4090 . Installation: Running from Docker image via singularity. DV version: 1.6.1. **Data**. I am training on examples from 5 individuals, data from Illumina NovaSeq ~20x coverage. . 17/21 chromosomes used for training (~1.45M examples). 2/21 chromosomes used for tuning (~200k examples). 2/21 chromosomes reserved for testing. . (Different chromosomes used for train/tune/test across samples - see below). <img width=""1437"" alt=""Screenshot 2024-08-07 at 09 30 23"" src=""https://github.com/user-attachments/assets/3178e87a-8cf7-47cb-84a2-0a84d15c958f"">. **Shuffling**. Performed downsampling=0.5. Shuffled globally across samples, chromosomes and downsampling. . **Command**. My latest training run was like so:. ```. apptainer run . --nv . -B $WD:/home . $DV_PATH . /opt/deepvariant/bin/train . --config=/home/dv_config.py:base . --config.train_dataset_pbtxt=""/home/examples_shuffled/train/All_samples_training_examples.dataset_config.pbtxt"" . --config.tune_dataset_pbtxt=""/home/examples_shuffled/tune/All_samples_tune_examples.dataset_config.pbtxt"". . --config.num_epoch",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:2697,modifiability,pac,packages,2697,":. ```. apptainer run . --nv . -B $WD:/home . $DV_PATH . /opt/deepvariant/bin/train . --config=/home/dv_config.py:base . --config.train_dataset_pbtxt=""/home/examples_shuffled/train/All_samples_training_examples.dataset_config.pbtxt"" . --config.tune_dataset_pbtxt=""/home/examples_shuffled/tune/All_samples_tune_examples.dataset_config.pbtxt"". . --config.num_epochs=1 . --config.learning_rate=0.0001 . --config.num_validation_examples=0 . --config.tune_every_steps=2000 . --experiment_dir=/home/${OUTDIR} . --strategy=mirrored . --config.batch_size=64 . --config.init_checkpoint=""/home/model_wgs_v1.6.1/deepvariant.wgs.ckpt"". ```. Though previous runs had higher learning rates (0.01) and batch sizes (128). Training proceeds as follows:. Training Examples: 1454377. Batch Size: 64. Epochs: 1. Steps per epoch: 22724. Steps per tune: 3162. Num train steps: 22724. **Log file**. Here is the top of the log file, including some warnings in case they are relevant:. ```. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(. 2024-08-28 10:40:42.588215: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_SYSTEM_DRIVER_MISMATCH: system has unsupported display driver / cuda driver combination. I0828 10:40:42.589054 140318776715072 train.py:92] Running with debug=False. I0828 10:40:42.589343 140318776715072 train.py:100] Use TPU at local. I0828 10:40:42.589422 140318776715072 train.py:103] experiment_dir: /home/training_outs/epoch1/. WARNING:tensorflow:There are non-GPU devices in `tf.distribut",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:2982,modifiability,depend,dependencies,2982,"/tune/All_samples_tune_examples.dataset_config.pbtxt"". . --config.num_epochs=1 . --config.learning_rate=0.0001 . --config.num_validation_examples=0 . --config.tune_every_steps=2000 . --experiment_dir=/home/${OUTDIR} . --strategy=mirrored . --config.batch_size=64 . --config.init_checkpoint=""/home/model_wgs_v1.6.1/deepvariant.wgs.ckpt"". ```. Though previous runs had higher learning rates (0.01) and batch sizes (128). Training proceeds as follows:. Training Examples: 1454377. Batch Size: 64. Epochs: 1. Steps per epoch: 22724. Steps per tune: 3162. Num train steps: 22724. **Log file**. Here is the top of the log file, including some warnings in case they are relevant:. ```. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(. 2024-08-28 10:40:42.588215: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_SYSTEM_DRIVER_MISMATCH: system has unsupported display driver / cuda driver combination. I0828 10:40:42.589054 140318776715072 train.py:92] Running with debug=False. I0828 10:40:42.589343 140318776715072 train.py:100] Use TPU at local. I0828 10:40:42.589422 140318776715072 train.py:103] experiment_dir: /home/training_outs/epoch1/. WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce. W0828 10:40:42.596594 140318776715072 cross_device_ops.py:1387] There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce. INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',). ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:4169,modifiability,pac,packages,4169,"rn(. 2024-08-28 10:40:42.588215: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_SYSTEM_DRIVER_MISMATCH: system has unsupported display driver / cuda driver combination. I0828 10:40:42.589054 140318776715072 train.py:92] Running with debug=False. I0828 10:40:42.589343 140318776715072 train.py:100] Use TPU at local. I0828 10:40:42.589422 140318776715072 train.py:103] experiment_dir: /home/training_outs/epoch1/. WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce. W0828 10:40:42.596594 140318776715072 cross_device_ops.py:1387] There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce. INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',). I0828 10:40:42.658734 140318776715072 mirrored_strategy.py:374] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',). /usr/local/lib/python3.8/dist-packages/keras/applications/inception_v3.py:138: UserWarning: This model usually expects 1 or 3 input channels. However, it was passed an input_shape with 7 input channels. input_shape = imagenet_utils.obtain_input_shape(. I0828 10:40:47.952382 140318776715072 keras_modeling.py:325] Number of l2 regularizers: 95. I0828 10:40:48.007193 140318776715072 keras_modeling.py:362] inceptionv3: load_weights from checkpoint: /home/training_outs/epoch1//checkpoints/ckpt-5997. I0828 10:40:49.193293 140318776715072 train.py:191] Exponential Decay: initial_learning_rate=0.0001. decay_steps=45448. learning_rate_decay_rate=0.947. I0828 10:40:49.193522 140318776715072 train.py:203] Use LinearWarmup:. warmup_steps=10000. warmup_learning_rate=1e-05. I0828 10:40:49.401860 140318776715072 keras_modeling.py:472] Restored checkpoint ckpt-5997 at step=0. tune/f1_weighted=tf.Tensor(0.0, shape=(), dtype=float32). WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:5124,modifiability,pac,packages,5124,":CPU:0',). /usr/local/lib/python3.8/dist-packages/keras/applications/inception_v3.py:138: UserWarning: This model usually expects 1 or 3 input channels. However, it was passed an input_shape with 7 input channels. input_shape = imagenet_utils.obtain_input_shape(. I0828 10:40:47.952382 140318776715072 keras_modeling.py:325] Number of l2 regularizers: 95. I0828 10:40:48.007193 140318776715072 keras_modeling.py:362] inceptionv3: load_weights from checkpoint: /home/training_outs/epoch1//checkpoints/ckpt-5997. I0828 10:40:49.193293 140318776715072 train.py:191] Exponential Decay: initial_learning_rate=0.0001. decay_steps=45448. learning_rate_decay_rate=0.947. I0828 10:40:49.193522 140318776715072 train.py:203] Use LinearWarmup:. warmup_steps=10000. warmup_learning_rate=1e-05. I0828 10:40:49.401860 140318776715072 keras_modeling.py:472] Restored checkpoint ckpt-5997 at step=0. tune/f1_weighted=tf.Tensor(0.0, shape=(), dtype=float32). WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23. Instructions for updating:. Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089. W0828 10:40:49.488072 140318776715072 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be rem>. Instructions for updating:. Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089. 2024-08-28 10:40:49.893797: W tensorflow/core/framework/dataset.cc:769] Input of GeneratorDatasetOp::",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:5632,modifiability,pac,packages,5632,"7. I0828 10:40:49.193293 140318776715072 train.py:191] Exponential Decay: initial_learning_rate=0.0001. decay_steps=45448. learning_rate_decay_rate=0.947. I0828 10:40:49.193522 140318776715072 train.py:203] Use LinearWarmup:. warmup_steps=10000. warmup_learning_rate=1e-05. I0828 10:40:49.401860 140318776715072 keras_modeling.py:472] Restored checkpoint ckpt-5997 at step=0. tune/f1_weighted=tf.Tensor(0.0, shape=(), dtype=float32). WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23. Instructions for updating:. Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089. W0828 10:40:49.488072 140318776715072 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be rem>. Instructions for updating:. Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089. 2024-08-28 10:40:49.893797: W tensorflow/core/framework/dataset.cc:769] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations. I0828 10:40:49.947995 140318776715072 train.py:316]. ```. And here is an excerpt of from a later portion of the log file including some training and tuning steps, where you can see the 0.0 for het and homalt eval stats. . ```. I0829 07:13:59.098341 140305134778112 logging_writer.py:48] [13700] epoch=0, train/categorical_accuracy=1.0, train/categorical_crossentropy=0.5520091",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:442,performance,time,times,442,"No evaluation statistics for het and homalt calls during model training; Hello DV team, and thanks for creating such a great tool! . I am currently trying to retrain the wgs model for a new species (a fish) however, during training, I see no evaluation statistics (precision, recall, f1) for either het or homalt. Or more specifically they are all 0.0. Eval stats are reported for homref though. I have now tried running the training several times with different hyperparameters but so far still no change at the het or homalt eval stats. . My first, very simple question is thus, are these eval stats truly 0 (i.e. the model is very bad) or is 0.0 some starting value and there are not enough data to calculate them initially? I am warmstarting from the 1.6.1 wgs model so I cant imagine the model is really that bad at calling variants initially, even if in a fish. . **Setup**. Running on a university computing cluster (https://hpc-unibe-ch.github.io/) . OS: Rocky 9.3 Blue Onyx. GPU: rtx4090 . Installation: Running from Docker image via singularity. DV version: 1.6.1. **Data**. I am training on examples from 5 individuals, data from Illumina NovaSeq ~20x coverage. . 17/21 chromosomes used for training (~1.45M examples). 2/21 chromosomes used for tuning (~200k examples). 2/21 chromosomes reserved for testing. . (Different chromosomes used for train/tune/test across samples - see below). <img width=""1437"" alt=""Screenshot 2024-08-07 at 09 30 23"" src=""https://github.com/user-attachments/assets/3178e87a-8cf7-47cb-84a2-0a84d15c958f"">. **Shuffling**. Performed downsampling=0.5. Shuffled globally across samples, chromosomes and downsampling. . **Command**. My latest training run was like so:. ```. apptainer run . --nv . -B $WD:/home . $DV_PATH . /opt/deepvariant/bin/train . --config=/home/dv_config.py:base . --config.train_dataset_pbtxt=""/home/examples_shuffled/train/All_samples_training_examples.dataset_config.pbtxt"" . --config.tune_dataset_pbtxt=""/home/examples_shuffled/tune/All_sa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:984,performance,GPU,GPU,984,"No evaluation statistics for het and homalt calls during model training; Hello DV team, and thanks for creating such a great tool! . I am currently trying to retrain the wgs model for a new species (a fish) however, during training, I see no evaluation statistics (precision, recall, f1) for either het or homalt. Or more specifically they are all 0.0. Eval stats are reported for homref though. I have now tried running the training several times with different hyperparameters but so far still no change at the het or homalt eval stats. . My first, very simple question is thus, are these eval stats truly 0 (i.e. the model is very bad) or is 0.0 some starting value and there are not enough data to calculate them initially? I am warmstarting from the 1.6.1 wgs model so I cant imagine the model is really that bad at calling variants initially, even if in a fish. . **Setup**. Running on a university computing cluster (https://hpc-unibe-ch.github.io/) . OS: Rocky 9.3 Blue Onyx. GPU: rtx4090 . Installation: Running from Docker image via singularity. DV version: 1.6.1. **Data**. I am training on examples from 5 individuals, data from Illumina NovaSeq ~20x coverage. . 17/21 chromosomes used for training (~1.45M examples). 2/21 chromosomes used for tuning (~200k examples). 2/21 chromosomes reserved for testing. . (Different chromosomes used for train/tune/test across samples - see below). <img width=""1437"" alt=""Screenshot 2024-08-07 at 09 30 23"" src=""https://github.com/user-attachments/assets/3178e87a-8cf7-47cb-84a2-0a84d15c958f"">. **Shuffling**. Performed downsampling=0.5. Shuffled globally across samples, chromosomes and downsampling. . **Command**. My latest training run was like so:. ```. apptainer run . --nv . -B $WD:/home . $DV_PATH . /opt/deepvariant/bin/train . --config=/home/dv_config.py:base . --config.train_dataset_pbtxt=""/home/examples_shuffled/train/All_samples_training_examples.dataset_config.pbtxt"" . --config.tune_dataset_pbtxt=""/home/examples_shuffled/tune/All_sa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:1360,performance,tune,tune,1360,"s are reported for homref though. I have now tried running the training several times with different hyperparameters but so far still no change at the het or homalt eval stats. . My first, very simple question is thus, are these eval stats truly 0 (i.e. the model is very bad) or is 0.0 some starting value and there are not enough data to calculate them initially? I am warmstarting from the 1.6.1 wgs model so I cant imagine the model is really that bad at calling variants initially, even if in a fish. . **Setup**. Running on a university computing cluster (https://hpc-unibe-ch.github.io/) . OS: Rocky 9.3 Blue Onyx. GPU: rtx4090 . Installation: Running from Docker image via singularity. DV version: 1.6.1. **Data**. I am training on examples from 5 individuals, data from Illumina NovaSeq ~20x coverage. . 17/21 chromosomes used for training (~1.45M examples). 2/21 chromosomes used for tuning (~200k examples). 2/21 chromosomes reserved for testing. . (Different chromosomes used for train/tune/test across samples - see below). <img width=""1437"" alt=""Screenshot 2024-08-07 at 09 30 23"" src=""https://github.com/user-attachments/assets/3178e87a-8cf7-47cb-84a2-0a84d15c958f"">. **Shuffling**. Performed downsampling=0.5. Shuffled globally across samples, chromosomes and downsampling. . **Command**. My latest training run was like so:. ```. apptainer run . --nv . -B $WD:/home . $DV_PATH . /opt/deepvariant/bin/train . --config=/home/dv_config.py:base . --config.train_dataset_pbtxt=""/home/examples_shuffled/train/All_samples_training_examples.dataset_config.pbtxt"" . --config.tune_dataset_pbtxt=""/home/examples_shuffled/tune/All_samples_tune_examples.dataset_config.pbtxt"". . --config.num_epochs=1 . --config.learning_rate=0.0001 . --config.num_validation_examples=0 . --config.tune_every_steps=2000 . --experiment_dir=/home/${OUTDIR} . --strategy=mirrored . --config.batch_size=64 . --config.init_checkpoint=""/home/model_wgs_v1.6.1/deepvariant.wgs.ckpt"". ```. Though previous runs had higher ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:1560,performance,Perform,Performed,1560,"estion is thus, are these eval stats truly 0 (i.e. the model is very bad) or is 0.0 some starting value and there are not enough data to calculate them initially? I am warmstarting from the 1.6.1 wgs model so I cant imagine the model is really that bad at calling variants initially, even if in a fish. . **Setup**. Running on a university computing cluster (https://hpc-unibe-ch.github.io/) . OS: Rocky 9.3 Blue Onyx. GPU: rtx4090 . Installation: Running from Docker image via singularity. DV version: 1.6.1. **Data**. I am training on examples from 5 individuals, data from Illumina NovaSeq ~20x coverage. . 17/21 chromosomes used for training (~1.45M examples). 2/21 chromosomes used for tuning (~200k examples). 2/21 chromosomes reserved for testing. . (Different chromosomes used for train/tune/test across samples - see below). <img width=""1437"" alt=""Screenshot 2024-08-07 at 09 30 23"" src=""https://github.com/user-attachments/assets/3178e87a-8cf7-47cb-84a2-0a84d15c958f"">. **Shuffling**. Performed downsampling=0.5. Shuffled globally across samples, chromosomes and downsampling. . **Command**. My latest training run was like so:. ```. apptainer run . --nv . -B $WD:/home . $DV_PATH . /opt/deepvariant/bin/train . --config=/home/dv_config.py:base . --config.train_dataset_pbtxt=""/home/examples_shuffled/train/All_samples_training_examples.dataset_config.pbtxt"" . --config.tune_dataset_pbtxt=""/home/examples_shuffled/tune/All_samples_tune_examples.dataset_config.pbtxt"". . --config.num_epochs=1 . --config.learning_rate=0.0001 . --config.num_validation_examples=0 . --config.tune_every_steps=2000 . --experiment_dir=/home/${OUTDIR} . --strategy=mirrored . --config.batch_size=64 . --config.init_checkpoint=""/home/model_wgs_v1.6.1/deepvariant.wgs.ckpt"". ```. Though previous runs had higher learning rates (0.01) and batch sizes (128). Training proceeds as follows:. Training Examples: 1454377. Batch Size: 64. Epochs: 1. Steps per epoch: 22724. Steps per tune: 3162. Num train steps: 22724. **",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:1989,performance,tune,tune,1989,"x4090 . Installation: Running from Docker image via singularity. DV version: 1.6.1. **Data**. I am training on examples from 5 individuals, data from Illumina NovaSeq ~20x coverage. . 17/21 chromosomes used for training (~1.45M examples). 2/21 chromosomes used for tuning (~200k examples). 2/21 chromosomes reserved for testing. . (Different chromosomes used for train/tune/test across samples - see below). <img width=""1437"" alt=""Screenshot 2024-08-07 at 09 30 23"" src=""https://github.com/user-attachments/assets/3178e87a-8cf7-47cb-84a2-0a84d15c958f"">. **Shuffling**. Performed downsampling=0.5. Shuffled globally across samples, chromosomes and downsampling. . **Command**. My latest training run was like so:. ```. apptainer run . --nv . -B $WD:/home . $DV_PATH . /opt/deepvariant/bin/train . --config=/home/dv_config.py:base . --config.train_dataset_pbtxt=""/home/examples_shuffled/train/All_samples_training_examples.dataset_config.pbtxt"" . --config.tune_dataset_pbtxt=""/home/examples_shuffled/tune/All_samples_tune_examples.dataset_config.pbtxt"". . --config.num_epochs=1 . --config.learning_rate=0.0001 . --config.num_validation_examples=0 . --config.tune_every_steps=2000 . --experiment_dir=/home/${OUTDIR} . --strategy=mirrored . --config.batch_size=64 . --config.init_checkpoint=""/home/model_wgs_v1.6.1/deepvariant.wgs.ckpt"". ```. Though previous runs had higher learning rates (0.01) and batch sizes (128). Training proceeds as follows:. Training Examples: 1454377. Batch Size: 64. Epochs: 1. Steps per epoch: 22724. Steps per tune: 3162. Num train steps: 22724. **Log file**. Here is the top of the log file, including some warnings in case they are relevant:. ```. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependenc",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:2388,performance,batch,batch,2388,"below). <img width=""1437"" alt=""Screenshot 2024-08-07 at 09 30 23"" src=""https://github.com/user-attachments/assets/3178e87a-8cf7-47cb-84a2-0a84d15c958f"">. **Shuffling**. Performed downsampling=0.5. Shuffled globally across samples, chromosomes and downsampling. . **Command**. My latest training run was like so:. ```. apptainer run . --nv . -B $WD:/home . $DV_PATH . /opt/deepvariant/bin/train . --config=/home/dv_config.py:base . --config.train_dataset_pbtxt=""/home/examples_shuffled/train/All_samples_training_examples.dataset_config.pbtxt"" . --config.tune_dataset_pbtxt=""/home/examples_shuffled/tune/All_samples_tune_examples.dataset_config.pbtxt"". . --config.num_epochs=1 . --config.learning_rate=0.0001 . --config.num_validation_examples=0 . --config.tune_every_steps=2000 . --experiment_dir=/home/${OUTDIR} . --strategy=mirrored . --config.batch_size=64 . --config.init_checkpoint=""/home/model_wgs_v1.6.1/deepvariant.wgs.ckpt"". ```. Though previous runs had higher learning rates (0.01) and batch sizes (128). Training proceeds as follows:. Training Examples: 1454377. Batch Size: 64. Epochs: 1. Steps per epoch: 22724. Steps per tune: 3162. Num train steps: 22724. **Log file**. Here is the top of the log file, including some warnings in case they are relevant:. ```. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(. 2024-08-28 10:40:42.588215: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_SYSTEM_DRIVER_MISMATCH: system has unsupported display driver / cuda driver combinat",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:2466,performance,Batch,Batch,2466,"/github.com/user-attachments/assets/3178e87a-8cf7-47cb-84a2-0a84d15c958f"">. **Shuffling**. Performed downsampling=0.5. Shuffled globally across samples, chromosomes and downsampling. . **Command**. My latest training run was like so:. ```. apptainer run . --nv . -B $WD:/home . $DV_PATH . /opt/deepvariant/bin/train . --config=/home/dv_config.py:base . --config.train_dataset_pbtxt=""/home/examples_shuffled/train/All_samples_training_examples.dataset_config.pbtxt"" . --config.tune_dataset_pbtxt=""/home/examples_shuffled/tune/All_samples_tune_examples.dataset_config.pbtxt"". . --config.num_epochs=1 . --config.learning_rate=0.0001 . --config.num_validation_examples=0 . --config.tune_every_steps=2000 . --experiment_dir=/home/${OUTDIR} . --strategy=mirrored . --config.batch_size=64 . --config.init_checkpoint=""/home/model_wgs_v1.6.1/deepvariant.wgs.ckpt"". ```. Though previous runs had higher learning rates (0.01) and batch sizes (128). Training proceeds as follows:. Training Examples: 1454377. Batch Size: 64. Epochs: 1. Steps per epoch: 22724. Steps per tune: 3162. Num train steps: 22724. **Log file**. Here is the top of the log file, including some warnings in case they are relevant:. ```. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(. 2024-08-28 10:40:42.588215: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_SYSTEM_DRIVER_MISMATCH: system has unsupported display driver / cuda driver combination. I0828 10:40:42.589054 140318776715072 train.py:92] Running with debug=Fal",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:2527,performance,tune,tune,2527,"0a84d15c958f"">. **Shuffling**. Performed downsampling=0.5. Shuffled globally across samples, chromosomes and downsampling. . **Command**. My latest training run was like so:. ```. apptainer run . --nv . -B $WD:/home . $DV_PATH . /opt/deepvariant/bin/train . --config=/home/dv_config.py:base . --config.train_dataset_pbtxt=""/home/examples_shuffled/train/All_samples_training_examples.dataset_config.pbtxt"" . --config.tune_dataset_pbtxt=""/home/examples_shuffled/tune/All_samples_tune_examples.dataset_config.pbtxt"". . --config.num_epochs=1 . --config.learning_rate=0.0001 . --config.num_validation_examples=0 . --config.tune_every_steps=2000 . --experiment_dir=/home/${OUTDIR} . --strategy=mirrored . --config.batch_size=64 . --config.init_checkpoint=""/home/model_wgs_v1.6.1/deepvariant.wgs.ckpt"". ```. Though previous runs had higher learning rates (0.01) and batch sizes (128). Training proceeds as follows:. Training Examples: 1454377. Batch Size: 64. Epochs: 1. Steps per epoch: 22724. Steps per tune: 3162. Num train steps: 22724. **Log file**. Here is the top of the log file, including some warnings in case they are relevant:. ```. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(. 2024-08-28 10:40:42.588215: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_SYSTEM_DRIVER_MISMATCH: system has unsupported display driver / cuda driver combination. I0828 10:40:42.589054 140318776715072 train.py:92] Running with debug=False. I0828 10:40:42.589343 140318776715072 train.py:100] Use ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:3673,performance,GPU,GPU,3673,"al/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(. 2024-08-28 10:40:42.588215: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_SYSTEM_DRIVER_MISMATCH: system has unsupported display driver / cuda driver combination. I0828 10:40:42.589054 140318776715072 train.py:92] Running with debug=False. I0828 10:40:42.589343 140318776715072 train.py:100] Use TPU at local. I0828 10:40:42.589422 140318776715072 train.py:103] experiment_dir: /home/training_outs/epoch1/. WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce. W0828 10:40:42.596594 140318776715072 cross_device_ops.py:1387] There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce. INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',). I0828 10:40:42.658734 140318776715072 mirrored_strategy.py:374] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',). /usr/local/lib/python3.8/dist-packages/keras/applications/inception_v3.py:138: UserWarning: This model usually expects 1 or 3 input channels. However, it was passed an input_shape with 7 input channels. input_shape = imagenet_utils.obtain_input_shape(. I0828 10:40:47.952382 140318776715072 keras_modeling.py:325] Number of l2 regularizers: 95. I0828 10:40:48.007193 140318776715072 keras_modeling.py:362] inceptionv3: load_weights from checkpoint: /home/training_outs/epoch1//checkpoints/ckpt-5997. I0828 10:40:49.193293 14031877671507",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:3818,performance,GPU,GPU,3818,"ction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(. 2024-08-28 10:40:42.588215: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_SYSTEM_DRIVER_MISMATCH: system has unsupported display driver / cuda driver combination. I0828 10:40:42.589054 140318776715072 train.py:92] Running with debug=False. I0828 10:40:42.589343 140318776715072 train.py:100] Use TPU at local. I0828 10:40:42.589422 140318776715072 train.py:103] experiment_dir: /home/training_outs/epoch1/. WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce. W0828 10:40:42.596594 140318776715072 cross_device_ops.py:1387] There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce. INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',). I0828 10:40:42.658734 140318776715072 mirrored_strategy.py:374] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',). /usr/local/lib/python3.8/dist-packages/keras/applications/inception_v3.py:138: UserWarning: This model usually expects 1 or 3 input channels. However, it was passed an input_shape with 7 input channels. input_shape = imagenet_utils.obtain_input_shape(. I0828 10:40:47.952382 140318776715072 keras_modeling.py:325] Number of l2 regularizers: 95. I0828 10:40:48.007193 140318776715072 keras_modeling.py:362] inceptionv3: load_weights from checkpoint: /home/training_outs/epoch1//checkpoints/ckpt-5997. I0828 10:40:49.193293 140318776715072 train.py:191] Exponential Decay: initial_learning_rate=0.0001. decay_steps=45448. learning_rate_decay_rate=0.947. I0828 10:40:49.193522 1403187",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:3978,performance,CPU,CPU,3978,"e dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(. 2024-08-28 10:40:42.588215: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_SYSTEM_DRIVER_MISMATCH: system has unsupported display driver / cuda driver combination. I0828 10:40:42.589054 140318776715072 train.py:92] Running with debug=False. I0828 10:40:42.589343 140318776715072 train.py:100] Use TPU at local. I0828 10:40:42.589422 140318776715072 train.py:103] experiment_dir: /home/training_outs/epoch1/. WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce. W0828 10:40:42.596594 140318776715072 cross_device_ops.py:1387] There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce. INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',). I0828 10:40:42.658734 140318776715072 mirrored_strategy.py:374] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',). /usr/local/lib/python3.8/dist-packages/keras/applications/inception_v3.py:138: UserWarning: This model usually expects 1 or 3 input channels. However, it was passed an input_shape with 7 input channels. input_shape = imagenet_utils.obtain_input_shape(. I0828 10:40:47.952382 140318776715072 keras_modeling.py:325] Number of l2 regularizers: 95. I0828 10:40:48.007193 140318776715072 keras_modeling.py:362] inceptionv3: load_weights from checkpoint: /home/training_outs/epoch1//checkpoints/ckpt-5997. I0828 10:40:49.193293 140318776715072 train.py:191] Exponential Decay: initial_learning_rate=0.0001. decay_steps=45448. learning_rate_decay_rate=0.947. I0828 10:40:49.193522 140318776715072 train.py:203] Use LinearWarmup:. warmup_steps=10000. warmup_learning_rate=1e-05. I0828 10:40:49.401860 140318776715072 keras_modeling.py:472] Restored ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:4129,performance,CPU,CPU,4129,"tensorflow/addons/issues/2807. warnings.warn(. 2024-08-28 10:40:42.588215: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_SYSTEM_DRIVER_MISMATCH: system has unsupported display driver / cuda driver combination. I0828 10:40:42.589054 140318776715072 train.py:92] Running with debug=False. I0828 10:40:42.589343 140318776715072 train.py:100] Use TPU at local. I0828 10:40:42.589422 140318776715072 train.py:103] experiment_dir: /home/training_outs/epoch1/. WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce. W0828 10:40:42.596594 140318776715072 cross_device_ops.py:1387] There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce. INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',). I0828 10:40:42.658734 140318776715072 mirrored_strategy.py:374] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',). /usr/local/lib/python3.8/dist-packages/keras/applications/inception_v3.py:138: UserWarning: This model usually expects 1 or 3 input channels. However, it was passed an input_shape with 7 input channels. input_shape = imagenet_utils.obtain_input_shape(. I0828 10:40:47.952382 140318776715072 keras_modeling.py:325] Number of l2 regularizers: 95. I0828 10:40:48.007193 140318776715072 keras_modeling.py:362] inceptionv3: load_weights from checkpoint: /home/training_outs/epoch1//checkpoints/ckpt-5997. I0828 10:40:49.193293 140318776715072 train.py:191] Exponential Decay: initial_learning_rate=0.0001. decay_steps=45448. learning_rate_decay_rate=0.947. I0828 10:40:49.193522 140318776715072 train.py:203] Use LinearWarmup:. warmup_steps=10000. warmup_learning_rate=1e-05. I0828 10:40:49.401860 140318776715072 keras_modeling.py:472] Restored checkpoint ckpt-5997 at step=0. tune/f1_weighted=tf.Tensor(0.0, shape=(), dtype=float32). WARNING:tensorflow:From /usr/local/lib/python3.8/dist-package",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:5012,performance,tune,tune,5012,"18776715072 mirrored_strategy.py:374] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',). /usr/local/lib/python3.8/dist-packages/keras/applications/inception_v3.py:138: UserWarning: This model usually expects 1 or 3 input channels. However, it was passed an input_shape with 7 input channels. input_shape = imagenet_utils.obtain_input_shape(. I0828 10:40:47.952382 140318776715072 keras_modeling.py:325] Number of l2 regularizers: 95. I0828 10:40:48.007193 140318776715072 keras_modeling.py:362] inceptionv3: load_weights from checkpoint: /home/training_outs/epoch1//checkpoints/ckpt-5997. I0828 10:40:49.193293 140318776715072 train.py:191] Exponential Decay: initial_learning_rate=0.0001. decay_steps=45448. learning_rate_decay_rate=0.947. I0828 10:40:49.193522 140318776715072 train.py:203] Use LinearWarmup:. warmup_steps=10000. warmup_learning_rate=1e-05. I0828 10:40:49.401860 140318776715072 keras_modeling.py:472] Restored checkpoint ckpt-5997 at step=0. tune/f1_weighted=tf.Tensor(0.0, shape=(), dtype=float32). WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23. Instructions for updating:. Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089. W0828 10:40:49.488072 140318776715072 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be rem>. Instructions for updating:. Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/i",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:6148,performance,optimiz,optimized,6148,"tograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23. Instructions for updating:. Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089. W0828 10:40:49.488072 140318776715072 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be rem>. Instructions for updating:. Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089. 2024-08-28 10:40:49.893797: W tensorflow/core/framework/dataset.cc:769] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations. I0828 10:40:49.947995 140318776715072 train.py:316]. ```. And here is an excerpt of from a later portion of the log file including some training and tuning steps, where you can see the 0.0 for het and homalt eval stats. . ```. I0829 07:13:59.098341 140305134778112 logging_writer.py:48] [13700] epoch=0, train/categorical_accuracy=1.0, train/categorical_crossentropy=0.552009105682373, train/f1_het=0.0, train/f1_homalt=0.0, train/f1_homref=1.0, train/f1_macro=0.3333333432674408, train/f1_micro=1.0, train/f1_. weighted=1.0, train/false_negatives=0.0, train/false_positives=0.0, train/learning_rate=9.999999747378752e-05, train/loss=0.5520098805427551, train/precision=1.0, train/precision_het=0.0, train/precision_homalt=0.0, train/precision_homref=1.0, train/recall=1.0, train/recall_het=0.0,. train/recall_homalt=0.0, train/recall_homref=1.0, train/true_negatives=12800.0, train/true_posit",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:6245,performance,optimiz,optimizations,6245,".pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23. Instructions for updating:. Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089. W0828 10:40:49.488072 140318776715072 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be rem>. Instructions for updating:. Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089. 2024-08-28 10:40:49.893797: W tensorflow/core/framework/dataset.cc:769] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations. I0828 10:40:49.947995 140318776715072 train.py:316]. ```. And here is an excerpt of from a later portion of the log file including some training and tuning steps, where you can see the 0.0 for het and homalt eval stats. . ```. I0829 07:13:59.098341 140305134778112 logging_writer.py:48] [13700] epoch=0, train/categorical_accuracy=1.0, train/categorical_crossentropy=0.552009105682373, train/f1_het=0.0, train/f1_homalt=0.0, train/f1_homref=1.0, train/f1_macro=0.3333333432674408, train/f1_micro=1.0, train/f1_. weighted=1.0, train/false_negatives=0.0, train/false_positives=0.0, train/learning_rate=9.999999747378752e-05, train/loss=0.5520098805427551, train/precision=1.0, train/precision_het=0.0, train/precision_homalt=0.0, train/precision_homref=1.0, train/recall=1.0, train/recall_het=0.0,. train/recall_homalt=0.0, train/recall_homref=1.0, train/true_negatives=12800.0, train/true_positives=6400.0. I0829 07:18:37.609363 140318776715072 local.py:41] Setting work unit notes: 0.3 steps/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:9474,performance,tune,tune,9474," logging_writer.py:48] [13900] epoch=0, train/categorical_accuracy=1.0, train/categorical_crossentropy=0.5519936680793762, train/f1_het=0.0, train/f1_homalt=0.0, train/f1_homref=1.0, train/f1_macro=0.3333333432674408, train/f1_micro=1.0, train/f1_weighted=1.0, train/false_negatives=0.0, train/false_positives=0.0, train/learning_rate=9.999999747378752e-05, train/loss=0.5519945025444031, train/precision=1.0, train/precision_het=0.0, train/precision_homalt=0.0, train/precision_homref=1.0, train/recall=1.0, train/recall_het=0.0, train/recall_homalt=0.0, train/recall_homref=1.0, train/true_negatives=12800.0, train/true_positives=6400.0. I0829 07:28:44.566404 140318776715072 local.py:41] Setting work unit notes: 0.3 steps/s, 61.4% (13948/22724), ETA: 8h42m. I0829 07:28:44.568708 140305134778112 logging_writer.py:48] [13948] steps_per_sec=0.280075. I0829 07:28:44.568793 140305134778112 logging_writer.py:48] [13948] uptime=74874.6. I0829 07:31:25.151819 140318776715072 train.py:361] Running tune at step=13993 epoch=0. I0829 07:31:25.152109 140318776715072 train.py:366] Tune step 0 / 3162 (0.0%). I0829 07:33:17.573163 140318776715072 train.py:366] Tune step 100 / 3162 (0.0%). I0829 07:35:10.013494 140318776715072 train.py:366] Tune step 200 / 3162 (10.0%). I0829 07:37:02.497336 140318776715072 train.py:366] Tune step 300 / 3162 (10.0%). I0829 07:38:54.834164 140318776715072 train.py:366] Tune step 400 / 3162 (10.0%). I0829 07:40:47.319165 140318776715072 train.py:366] Tune step 500 / 3162 (20.0%). I0829 07:42:39.802007 140318776715072 train.py:366] Tune step 600 / 3162 (20.0%). I0829 07:44:32.297624 140318776715072 train.py:366] Tune step 700 / 3162 (20.0%). I0829 07:46:24.658610 140318776715072 train.py:366] Tune step 800 / 3162 (30.0%). I0829 07:48:17.176530 140318776715072 train.py:366] Tune step 900 / 3162 (30.0%). I0829 07:50:09.700463 140318776715072 train.py:366] Tune step 1000 / 3162 (30.0%). I0829 07:52:02.226121 140318776715072 train.py:366] Tune step 1100 / 3162 (",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:9554,performance,Tune,Tune,9554,"tegorical_crossentropy=0.5519936680793762, train/f1_het=0.0, train/f1_homalt=0.0, train/f1_homref=1.0, train/f1_macro=0.3333333432674408, train/f1_micro=1.0, train/f1_weighted=1.0, train/false_negatives=0.0, train/false_positives=0.0, train/learning_rate=9.999999747378752e-05, train/loss=0.5519945025444031, train/precision=1.0, train/precision_het=0.0, train/precision_homalt=0.0, train/precision_homref=1.0, train/recall=1.0, train/recall_het=0.0, train/recall_homalt=0.0, train/recall_homref=1.0, train/true_negatives=12800.0, train/true_positives=6400.0. I0829 07:28:44.566404 140318776715072 local.py:41] Setting work unit notes: 0.3 steps/s, 61.4% (13948/22724), ETA: 8h42m. I0829 07:28:44.568708 140305134778112 logging_writer.py:48] [13948] steps_per_sec=0.280075. I0829 07:28:44.568793 140305134778112 logging_writer.py:48] [13948] uptime=74874.6. I0829 07:31:25.151819 140318776715072 train.py:361] Running tune at step=13993 epoch=0. I0829 07:31:25.152109 140318776715072 train.py:366] Tune step 0 / 3162 (0.0%). I0829 07:33:17.573163 140318776715072 train.py:366] Tune step 100 / 3162 (0.0%). I0829 07:35:10.013494 140318776715072 train.py:366] Tune step 200 / 3162 (10.0%). I0829 07:37:02.497336 140318776715072 train.py:366] Tune step 300 / 3162 (10.0%). I0829 07:38:54.834164 140318776715072 train.py:366] Tune step 400 / 3162 (10.0%). I0829 07:40:47.319165 140318776715072 train.py:366] Tune step 500 / 3162 (20.0%). I0829 07:42:39.802007 140318776715072 train.py:366] Tune step 600 / 3162 (20.0%). I0829 07:44:32.297624 140318776715072 train.py:366] Tune step 700 / 3162 (20.0%). I0829 07:46:24.658610 140318776715072 train.py:366] Tune step 800 / 3162 (30.0%). I0829 07:48:17.176530 140318776715072 train.py:366] Tune step 900 / 3162 (30.0%). I0829 07:50:09.700463 140318776715072 train.py:366] Tune step 1000 / 3162 (30.0%). I0829 07:52:02.226121 140318776715072 train.py:366] Tune step 1100 / 3162 (30.0%). I0829 07:53:54.613348 140318776715072 train.py:366] Tune step 1200 / 316",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:9633,performance,Tune,Tune,9633,"0, train/f1_homref=1.0, train/f1_macro=0.3333333432674408, train/f1_micro=1.0, train/f1_weighted=1.0, train/false_negatives=0.0, train/false_positives=0.0, train/learning_rate=9.999999747378752e-05, train/loss=0.5519945025444031, train/precision=1.0, train/precision_het=0.0, train/precision_homalt=0.0, train/precision_homref=1.0, train/recall=1.0, train/recall_het=0.0, train/recall_homalt=0.0, train/recall_homref=1.0, train/true_negatives=12800.0, train/true_positives=6400.0. I0829 07:28:44.566404 140318776715072 local.py:41] Setting work unit notes: 0.3 steps/s, 61.4% (13948/22724), ETA: 8h42m. I0829 07:28:44.568708 140305134778112 logging_writer.py:48] [13948] steps_per_sec=0.280075. I0829 07:28:44.568793 140305134778112 logging_writer.py:48] [13948] uptime=74874.6. I0829 07:31:25.151819 140318776715072 train.py:361] Running tune at step=13993 epoch=0. I0829 07:31:25.152109 140318776715072 train.py:366] Tune step 0 / 3162 (0.0%). I0829 07:33:17.573163 140318776715072 train.py:366] Tune step 100 / 3162 (0.0%). I0829 07:35:10.013494 140318776715072 train.py:366] Tune step 200 / 3162 (10.0%). I0829 07:37:02.497336 140318776715072 train.py:366] Tune step 300 / 3162 (10.0%). I0829 07:38:54.834164 140318776715072 train.py:366] Tune step 400 / 3162 (10.0%). I0829 07:40:47.319165 140318776715072 train.py:366] Tune step 500 / 3162 (20.0%). I0829 07:42:39.802007 140318776715072 train.py:366] Tune step 600 / 3162 (20.0%). I0829 07:44:32.297624 140318776715072 train.py:366] Tune step 700 / 3162 (20.0%). I0829 07:46:24.658610 140318776715072 train.py:366] Tune step 800 / 3162 (30.0%). I0829 07:48:17.176530 140318776715072 train.py:366] Tune step 900 / 3162 (30.0%). I0829 07:50:09.700463 140318776715072 train.py:366] Tune step 1000 / 3162 (30.0%). I0829 07:52:02.226121 140318776715072 train.py:366] Tune step 1100 / 3162 (30.0%). I0829 07:53:54.613348 140318776715072 train.py:366] Tune step 1200 / 3162 (40.0%). I0829 07:55:47.134974 140318776715072 train.py:366] Tune step 1300 /",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:9714,performance,Tune,Tune,9714,"ain/f1_weighted=1.0, train/false_negatives=0.0, train/false_positives=0.0, train/learning_rate=9.999999747378752e-05, train/loss=0.5519945025444031, train/precision=1.0, train/precision_het=0.0, train/precision_homalt=0.0, train/precision_homref=1.0, train/recall=1.0, train/recall_het=0.0, train/recall_homalt=0.0, train/recall_homref=1.0, train/true_negatives=12800.0, train/true_positives=6400.0. I0829 07:28:44.566404 140318776715072 local.py:41] Setting work unit notes: 0.3 steps/s, 61.4% (13948/22724), ETA: 8h42m. I0829 07:28:44.568708 140305134778112 logging_writer.py:48] [13948] steps_per_sec=0.280075. I0829 07:28:44.568793 140305134778112 logging_writer.py:48] [13948] uptime=74874.6. I0829 07:31:25.151819 140318776715072 train.py:361] Running tune at step=13993 epoch=0. I0829 07:31:25.152109 140318776715072 train.py:366] Tune step 0 / 3162 (0.0%). I0829 07:33:17.573163 140318776715072 train.py:366] Tune step 100 / 3162 (0.0%). I0829 07:35:10.013494 140318776715072 train.py:366] Tune step 200 / 3162 (10.0%). I0829 07:37:02.497336 140318776715072 train.py:366] Tune step 300 / 3162 (10.0%). I0829 07:38:54.834164 140318776715072 train.py:366] Tune step 400 / 3162 (10.0%). I0829 07:40:47.319165 140318776715072 train.py:366] Tune step 500 / 3162 (20.0%). I0829 07:42:39.802007 140318776715072 train.py:366] Tune step 600 / 3162 (20.0%). I0829 07:44:32.297624 140318776715072 train.py:366] Tune step 700 / 3162 (20.0%). I0829 07:46:24.658610 140318776715072 train.py:366] Tune step 800 / 3162 (30.0%). I0829 07:48:17.176530 140318776715072 train.py:366] Tune step 900 / 3162 (30.0%). I0829 07:50:09.700463 140318776715072 train.py:366] Tune step 1000 / 3162 (30.0%). I0829 07:52:02.226121 140318776715072 train.py:366] Tune step 1100 / 3162 (30.0%). I0829 07:53:54.613348 140318776715072 train.py:366] Tune step 1200 / 3162 (40.0%). I0829 07:55:47.134974 140318776715072 train.py:366] Tune step 1300 / 3162 (40.0%). I0829 07:57:39.682815 140318776715072 train.py:366] Tune step 1400",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:9796,performance,Tune,Tune,9796,"earning_rate=9.999999747378752e-05, train/loss=0.5519945025444031, train/precision=1.0, train/precision_het=0.0, train/precision_homalt=0.0, train/precision_homref=1.0, train/recall=1.0, train/recall_het=0.0, train/recall_homalt=0.0, train/recall_homref=1.0, train/true_negatives=12800.0, train/true_positives=6400.0. I0829 07:28:44.566404 140318776715072 local.py:41] Setting work unit notes: 0.3 steps/s, 61.4% (13948/22724), ETA: 8h42m. I0829 07:28:44.568708 140305134778112 logging_writer.py:48] [13948] steps_per_sec=0.280075. I0829 07:28:44.568793 140305134778112 logging_writer.py:48] [13948] uptime=74874.6. I0829 07:31:25.151819 140318776715072 train.py:361] Running tune at step=13993 epoch=0. I0829 07:31:25.152109 140318776715072 train.py:366] Tune step 0 / 3162 (0.0%). I0829 07:33:17.573163 140318776715072 train.py:366] Tune step 100 / 3162 (0.0%). I0829 07:35:10.013494 140318776715072 train.py:366] Tune step 200 / 3162 (10.0%). I0829 07:37:02.497336 140318776715072 train.py:366] Tune step 300 / 3162 (10.0%). I0829 07:38:54.834164 140318776715072 train.py:366] Tune step 400 / 3162 (10.0%). I0829 07:40:47.319165 140318776715072 train.py:366] Tune step 500 / 3162 (20.0%). I0829 07:42:39.802007 140318776715072 train.py:366] Tune step 600 / 3162 (20.0%). I0829 07:44:32.297624 140318776715072 train.py:366] Tune step 700 / 3162 (20.0%). I0829 07:46:24.658610 140318776715072 train.py:366] Tune step 800 / 3162 (30.0%). I0829 07:48:17.176530 140318776715072 train.py:366] Tune step 900 / 3162 (30.0%). I0829 07:50:09.700463 140318776715072 train.py:366] Tune step 1000 / 3162 (30.0%). I0829 07:52:02.226121 140318776715072 train.py:366] Tune step 1100 / 3162 (30.0%). I0829 07:53:54.613348 140318776715072 train.py:366] Tune step 1200 / 3162 (40.0%). I0829 07:55:47.134974 140318776715072 train.py:366] Tune step 1300 / 3162 (40.0%). I0829 07:57:39.682815 140318776715072 train.py:366] Tune step 1400 / 3162 (40.0%). I0829 07:59:32.215537 140318776715072 train.py:366] Tune step 150",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:9878,performance,Tune,Tune,9878,"=1.0, train/precision_het=0.0, train/precision_homalt=0.0, train/precision_homref=1.0, train/recall=1.0, train/recall_het=0.0, train/recall_homalt=0.0, train/recall_homref=1.0, train/true_negatives=12800.0, train/true_positives=6400.0. I0829 07:28:44.566404 140318776715072 local.py:41] Setting work unit notes: 0.3 steps/s, 61.4% (13948/22724), ETA: 8h42m. I0829 07:28:44.568708 140305134778112 logging_writer.py:48] [13948] steps_per_sec=0.280075. I0829 07:28:44.568793 140305134778112 logging_writer.py:48] [13948] uptime=74874.6. I0829 07:31:25.151819 140318776715072 train.py:361] Running tune at step=13993 epoch=0. I0829 07:31:25.152109 140318776715072 train.py:366] Tune step 0 / 3162 (0.0%). I0829 07:33:17.573163 140318776715072 train.py:366] Tune step 100 / 3162 (0.0%). I0829 07:35:10.013494 140318776715072 train.py:366] Tune step 200 / 3162 (10.0%). I0829 07:37:02.497336 140318776715072 train.py:366] Tune step 300 / 3162 (10.0%). I0829 07:38:54.834164 140318776715072 train.py:366] Tune step 400 / 3162 (10.0%). I0829 07:40:47.319165 140318776715072 train.py:366] Tune step 500 / 3162 (20.0%). I0829 07:42:39.802007 140318776715072 train.py:366] Tune step 600 / 3162 (20.0%). I0829 07:44:32.297624 140318776715072 train.py:366] Tune step 700 / 3162 (20.0%). I0829 07:46:24.658610 140318776715072 train.py:366] Tune step 800 / 3162 (30.0%). I0829 07:48:17.176530 140318776715072 train.py:366] Tune step 900 / 3162 (30.0%). I0829 07:50:09.700463 140318776715072 train.py:366] Tune step 1000 / 3162 (30.0%). I0829 07:52:02.226121 140318776715072 train.py:366] Tune step 1100 / 3162 (30.0%). I0829 07:53:54.613348 140318776715072 train.py:366] Tune step 1200 / 3162 (40.0%). I0829 07:55:47.134974 140318776715072 train.py:366] Tune step 1300 / 3162 (40.0%). I0829 07:57:39.682815 140318776715072 train.py:366] Tune step 1400 / 3162 (40.0%). I0829 07:59:32.215537 140318776715072 train.py:366] Tune step 1500 / 3162 (50.0%). I0829 08:01:24.651632 140318776715072 train.py:366] Tune step 16",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:9960,performance,Tune,Tune,9960,"1.0, train/recall=1.0, train/recall_het=0.0, train/recall_homalt=0.0, train/recall_homref=1.0, train/true_negatives=12800.0, train/true_positives=6400.0. I0829 07:28:44.566404 140318776715072 local.py:41] Setting work unit notes: 0.3 steps/s, 61.4% (13948/22724), ETA: 8h42m. I0829 07:28:44.568708 140305134778112 logging_writer.py:48] [13948] steps_per_sec=0.280075. I0829 07:28:44.568793 140305134778112 logging_writer.py:48] [13948] uptime=74874.6. I0829 07:31:25.151819 140318776715072 train.py:361] Running tune at step=13993 epoch=0. I0829 07:31:25.152109 140318776715072 train.py:366] Tune step 0 / 3162 (0.0%). I0829 07:33:17.573163 140318776715072 train.py:366] Tune step 100 / 3162 (0.0%). I0829 07:35:10.013494 140318776715072 train.py:366] Tune step 200 / 3162 (10.0%). I0829 07:37:02.497336 140318776715072 train.py:366] Tune step 300 / 3162 (10.0%). I0829 07:38:54.834164 140318776715072 train.py:366] Tune step 400 / 3162 (10.0%). I0829 07:40:47.319165 140318776715072 train.py:366] Tune step 500 / 3162 (20.0%). I0829 07:42:39.802007 140318776715072 train.py:366] Tune step 600 / 3162 (20.0%). I0829 07:44:32.297624 140318776715072 train.py:366] Tune step 700 / 3162 (20.0%). I0829 07:46:24.658610 140318776715072 train.py:366] Tune step 800 / 3162 (30.0%). I0829 07:48:17.176530 140318776715072 train.py:366] Tune step 900 / 3162 (30.0%). I0829 07:50:09.700463 140318776715072 train.py:366] Tune step 1000 / 3162 (30.0%). I0829 07:52:02.226121 140318776715072 train.py:366] Tune step 1100 / 3162 (30.0%). I0829 07:53:54.613348 140318776715072 train.py:366] Tune step 1200 / 3162 (40.0%). I0829 07:55:47.134974 140318776715072 train.py:366] Tune step 1300 / 3162 (40.0%). I0829 07:57:39.682815 140318776715072 train.py:366] Tune step 1400 / 3162 (40.0%). I0829 07:59:32.215537 140318776715072 train.py:366] Tune step 1500 / 3162 (50.0%). I0829 08:01:24.651632 140318776715072 train.py:366] Tune step 1600 / 3162 (50.0%). I0829 08:03:17.188146 140318776715072 train.py:366] Tune step 1",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:10042,performance,Tune,Tune,10042,"_homref=1.0, train/true_negatives=12800.0, train/true_positives=6400.0. I0829 07:28:44.566404 140318776715072 local.py:41] Setting work unit notes: 0.3 steps/s, 61.4% (13948/22724), ETA: 8h42m. I0829 07:28:44.568708 140305134778112 logging_writer.py:48] [13948] steps_per_sec=0.280075. I0829 07:28:44.568793 140305134778112 logging_writer.py:48] [13948] uptime=74874.6. I0829 07:31:25.151819 140318776715072 train.py:361] Running tune at step=13993 epoch=0. I0829 07:31:25.152109 140318776715072 train.py:366] Tune step 0 / 3162 (0.0%). I0829 07:33:17.573163 140318776715072 train.py:366] Tune step 100 / 3162 (0.0%). I0829 07:35:10.013494 140318776715072 train.py:366] Tune step 200 / 3162 (10.0%). I0829 07:37:02.497336 140318776715072 train.py:366] Tune step 300 / 3162 (10.0%). I0829 07:38:54.834164 140318776715072 train.py:366] Tune step 400 / 3162 (10.0%). I0829 07:40:47.319165 140318776715072 train.py:366] Tune step 500 / 3162 (20.0%). I0829 07:42:39.802007 140318776715072 train.py:366] Tune step 600 / 3162 (20.0%). I0829 07:44:32.297624 140318776715072 train.py:366] Tune step 700 / 3162 (20.0%). I0829 07:46:24.658610 140318776715072 train.py:366] Tune step 800 / 3162 (30.0%). I0829 07:48:17.176530 140318776715072 train.py:366] Tune step 900 / 3162 (30.0%). I0829 07:50:09.700463 140318776715072 train.py:366] Tune step 1000 / 3162 (30.0%). I0829 07:52:02.226121 140318776715072 train.py:366] Tune step 1100 / 3162 (30.0%). I0829 07:53:54.613348 140318776715072 train.py:366] Tune step 1200 / 3162 (40.0%). I0829 07:55:47.134974 140318776715072 train.py:366] Tune step 1300 / 3162 (40.0%). I0829 07:57:39.682815 140318776715072 train.py:366] Tune step 1400 / 3162 (40.0%). I0829 07:59:32.215537 140318776715072 train.py:366] Tune step 1500 / 3162 (50.0%). I0829 08:01:24.651632 140318776715072 train.py:366] Tune step 1600 / 3162 (50.0%). I0829 08:03:17.188146 140318776715072 train.py:366] Tune step 1700 / 3162 (50.0%). I0829 08:05:09.741266 140318776715072 train.py:366] Tune step ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:10124,performance,Tune,Tune,10124,"8:44.566404 140318776715072 local.py:41] Setting work unit notes: 0.3 steps/s, 61.4% (13948/22724), ETA: 8h42m. I0829 07:28:44.568708 140305134778112 logging_writer.py:48] [13948] steps_per_sec=0.280075. I0829 07:28:44.568793 140305134778112 logging_writer.py:48] [13948] uptime=74874.6. I0829 07:31:25.151819 140318776715072 train.py:361] Running tune at step=13993 epoch=0. I0829 07:31:25.152109 140318776715072 train.py:366] Tune step 0 / 3162 (0.0%). I0829 07:33:17.573163 140318776715072 train.py:366] Tune step 100 / 3162 (0.0%). I0829 07:35:10.013494 140318776715072 train.py:366] Tune step 200 / 3162 (10.0%). I0829 07:37:02.497336 140318776715072 train.py:366] Tune step 300 / 3162 (10.0%). I0829 07:38:54.834164 140318776715072 train.py:366] Tune step 400 / 3162 (10.0%). I0829 07:40:47.319165 140318776715072 train.py:366] Tune step 500 / 3162 (20.0%). I0829 07:42:39.802007 140318776715072 train.py:366] Tune step 600 / 3162 (20.0%). I0829 07:44:32.297624 140318776715072 train.py:366] Tune step 700 / 3162 (20.0%). I0829 07:46:24.658610 140318776715072 train.py:366] Tune step 800 / 3162 (30.0%). I0829 07:48:17.176530 140318776715072 train.py:366] Tune step 900 / 3162 (30.0%). I0829 07:50:09.700463 140318776715072 train.py:366] Tune step 1000 / 3162 (30.0%). I0829 07:52:02.226121 140318776715072 train.py:366] Tune step 1100 / 3162 (30.0%). I0829 07:53:54.613348 140318776715072 train.py:366] Tune step 1200 / 3162 (40.0%). I0829 07:55:47.134974 140318776715072 train.py:366] Tune step 1300 / 3162 (40.0%). I0829 07:57:39.682815 140318776715072 train.py:366] Tune step 1400 / 3162 (40.0%). I0829 07:59:32.215537 140318776715072 train.py:366] Tune step 1500 / 3162 (50.0%). I0829 08:01:24.651632 140318776715072 train.py:366] Tune step 1600 / 3162 (50.0%). I0829 08:03:17.188146 140318776715072 train.py:366] Tune step 1700 / 3162 (50.0%). I0829 08:05:09.741266 140318776715072 train.py:366] Tune step 1800 / 3162 (60.0%). I0829 08:07:02.262498 140318776715072 train.py:366] Tune step",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:10206,performance,Tune,Tune,10206,"4% (13948/22724), ETA: 8h42m. I0829 07:28:44.568708 140305134778112 logging_writer.py:48] [13948] steps_per_sec=0.280075. I0829 07:28:44.568793 140305134778112 logging_writer.py:48] [13948] uptime=74874.6. I0829 07:31:25.151819 140318776715072 train.py:361] Running tune at step=13993 epoch=0. I0829 07:31:25.152109 140318776715072 train.py:366] Tune step 0 / 3162 (0.0%). I0829 07:33:17.573163 140318776715072 train.py:366] Tune step 100 / 3162 (0.0%). I0829 07:35:10.013494 140318776715072 train.py:366] Tune step 200 / 3162 (10.0%). I0829 07:37:02.497336 140318776715072 train.py:366] Tune step 300 / 3162 (10.0%). I0829 07:38:54.834164 140318776715072 train.py:366] Tune step 400 / 3162 (10.0%). I0829 07:40:47.319165 140318776715072 train.py:366] Tune step 500 / 3162 (20.0%). I0829 07:42:39.802007 140318776715072 train.py:366] Tune step 600 / 3162 (20.0%). I0829 07:44:32.297624 140318776715072 train.py:366] Tune step 700 / 3162 (20.0%). I0829 07:46:24.658610 140318776715072 train.py:366] Tune step 800 / 3162 (30.0%). I0829 07:48:17.176530 140318776715072 train.py:366] Tune step 900 / 3162 (30.0%). I0829 07:50:09.700463 140318776715072 train.py:366] Tune step 1000 / 3162 (30.0%). I0829 07:52:02.226121 140318776715072 train.py:366] Tune step 1100 / 3162 (30.0%). I0829 07:53:54.613348 140318776715072 train.py:366] Tune step 1200 / 3162 (40.0%). I0829 07:55:47.134974 140318776715072 train.py:366] Tune step 1300 / 3162 (40.0%). I0829 07:57:39.682815 140318776715072 train.py:366] Tune step 1400 / 3162 (40.0%). I0829 07:59:32.215537 140318776715072 train.py:366] Tune step 1500 / 3162 (50.0%). I0829 08:01:24.651632 140318776715072 train.py:366] Tune step 1600 / 3162 (50.0%). I0829 08:03:17.188146 140318776715072 train.py:366] Tune step 1700 / 3162 (50.0%). I0829 08:05:09.741266 140318776715072 train.py:366] Tune step 1800 / 3162 (60.0%). I0829 08:07:02.262498 140318776715072 train.py:366] Tune step 1900 / 3162 (60.0%). I0829 08:08:54.673932 140318776715072 train.py:366] Tune ste",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:10288,performance,Tune,Tune,10288,.py:48] [13948] steps_per_sec=0.280075. I0829 07:28:44.568793 140305134778112 logging_writer.py:48] [13948] uptime=74874.6. I0829 07:31:25.151819 140318776715072 train.py:361] Running tune at step=13993 epoch=0. I0829 07:31:25.152109 140318776715072 train.py:366] Tune step 0 / 3162 (0.0%). I0829 07:33:17.573163 140318776715072 train.py:366] Tune step 100 / 3162 (0.0%). I0829 07:35:10.013494 140318776715072 train.py:366] Tune step 200 / 3162 (10.0%). I0829 07:37:02.497336 140318776715072 train.py:366] Tune step 300 / 3162 (10.0%). I0829 07:38:54.834164 140318776715072 train.py:366] Tune step 400 / 3162 (10.0%). I0829 07:40:47.319165 140318776715072 train.py:366] Tune step 500 / 3162 (20.0%). I0829 07:42:39.802007 140318776715072 train.py:366] Tune step 600 / 3162 (20.0%). I0829 07:44:32.297624 140318776715072 train.py:366] Tune step 700 / 3162 (20.0%). I0829 07:46:24.658610 140318776715072 train.py:366] Tune step 800 / 3162 (30.0%). I0829 07:48:17.176530 140318776715072 train.py:366] Tune step 900 / 3162 (30.0%). I0829 07:50:09.700463 140318776715072 train.py:366] Tune step 1000 / 3162 (30.0%). I0829 07:52:02.226121 140318776715072 train.py:366] Tune step 1100 / 3162 (30.0%). I0829 07:53:54.613348 140318776715072 train.py:366] Tune step 1200 / 3162 (40.0%). I0829 07:55:47.134974 140318776715072 train.py:366] Tune step 1300 / 3162 (40.0%). I0829 07:57:39.682815 140318776715072 train.py:366] Tune step 1400 / 3162 (40.0%). I0829 07:59:32.215537 140318776715072 train.py:366] Tune step 1500 / 3162 (50.0%). I0829 08:01:24.651632 140318776715072 train.py:366] Tune step 1600 / 3162 (50.0%). I0829 08:03:17.188146 140318776715072 train.py:366] Tune step 1700 / 3162 (50.0%). I0829 08:05:09.741266 140318776715072 train.py:366] Tune step 1800 / 3162 (60.0%). I0829 08:07:02.262498 140318776715072 train.py:366] Tune step 1900 / 3162 (60.0%). I0829 08:08:54.673932 140318776715072 train.py:366] Tune step 2000 / 3162 (60.0%). I0829 08:10:47.221370 140318776715072 train.py:366] Tune st,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:10370,performance,Tune,Tune,10370,ing_writer.py:48] [13948] uptime=74874.6. I0829 07:31:25.151819 140318776715072 train.py:361] Running tune at step=13993 epoch=0. I0829 07:31:25.152109 140318776715072 train.py:366] Tune step 0 / 3162 (0.0%). I0829 07:33:17.573163 140318776715072 train.py:366] Tune step 100 / 3162 (0.0%). I0829 07:35:10.013494 140318776715072 train.py:366] Tune step 200 / 3162 (10.0%). I0829 07:37:02.497336 140318776715072 train.py:366] Tune step 300 / 3162 (10.0%). I0829 07:38:54.834164 140318776715072 train.py:366] Tune step 400 / 3162 (10.0%). I0829 07:40:47.319165 140318776715072 train.py:366] Tune step 500 / 3162 (20.0%). I0829 07:42:39.802007 140318776715072 train.py:366] Tune step 600 / 3162 (20.0%). I0829 07:44:32.297624 140318776715072 train.py:366] Tune step 700 / 3162 (20.0%). I0829 07:46:24.658610 140318776715072 train.py:366] Tune step 800 / 3162 (30.0%). I0829 07:48:17.176530 140318776715072 train.py:366] Tune step 900 / 3162 (30.0%). I0829 07:50:09.700463 140318776715072 train.py:366] Tune step 1000 / 3162 (30.0%). I0829 07:52:02.226121 140318776715072 train.py:366] Tune step 1100 / 3162 (30.0%). I0829 07:53:54.613348 140318776715072 train.py:366] Tune step 1200 / 3162 (40.0%). I0829 07:55:47.134974 140318776715072 train.py:366] Tune step 1300 / 3162 (40.0%). I0829 07:57:39.682815 140318776715072 train.py:366] Tune step 1400 / 3162 (40.0%). I0829 07:59:32.215537 140318776715072 train.py:366] Tune step 1500 / 3162 (50.0%). I0829 08:01:24.651632 140318776715072 train.py:366] Tune step 1600 / 3162 (50.0%). I0829 08:03:17.188146 140318776715072 train.py:366] Tune step 1700 / 3162 (50.0%). I0829 08:05:09.741266 140318776715072 train.py:366] Tune step 1800 / 3162 (60.0%). I0829 08:07:02.262498 140318776715072 train.py:366] Tune step 1900 / 3162 (60.0%). I0829 08:08:54.673932 140318776715072 train.py:366] Tune step 2000 / 3162 (60.0%). I0829 08:10:47.221370 140318776715072 train.py:366] Tune step 2100 / 3162 (70.0%). I0829 08:12:39.774174 140318776715072 train.py:366] Tune s,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:10453,performance,Tune,Tune,10453,in.py:361] Running tune at step=13993 epoch=0. I0829 07:31:25.152109 140318776715072 train.py:366] Tune step 0 / 3162 (0.0%). I0829 07:33:17.573163 140318776715072 train.py:366] Tune step 100 / 3162 (0.0%). I0829 07:35:10.013494 140318776715072 train.py:366] Tune step 200 / 3162 (10.0%). I0829 07:37:02.497336 140318776715072 train.py:366] Tune step 300 / 3162 (10.0%). I0829 07:38:54.834164 140318776715072 train.py:366] Tune step 400 / 3162 (10.0%). I0829 07:40:47.319165 140318776715072 train.py:366] Tune step 500 / 3162 (20.0%). I0829 07:42:39.802007 140318776715072 train.py:366] Tune step 600 / 3162 (20.0%). I0829 07:44:32.297624 140318776715072 train.py:366] Tune step 700 / 3162 (20.0%). I0829 07:46:24.658610 140318776715072 train.py:366] Tune step 800 / 3162 (30.0%). I0829 07:48:17.176530 140318776715072 train.py:366] Tune step 900 / 3162 (30.0%). I0829 07:50:09.700463 140318776715072 train.py:366] Tune step 1000 / 3162 (30.0%). I0829 07:52:02.226121 140318776715072 train.py:366] Tune step 1100 / 3162 (30.0%). I0829 07:53:54.613348 140318776715072 train.py:366] Tune step 1200 / 3162 (40.0%). I0829 07:55:47.134974 140318776715072 train.py:366] Tune step 1300 / 3162 (40.0%). I0829 07:57:39.682815 140318776715072 train.py:366] Tune step 1400 / 3162 (40.0%). I0829 07:59:32.215537 140318776715072 train.py:366] Tune step 1500 / 3162 (50.0%). I0829 08:01:24.651632 140318776715072 train.py:366] Tune step 1600 / 3162 (50.0%). I0829 08:03:17.188146 140318776715072 train.py:366] Tune step 1700 / 3162 (50.0%). I0829 08:05:09.741266 140318776715072 train.py:366] Tune step 1800 / 3162 (60.0%). I0829 08:07:02.262498 140318776715072 train.py:366] Tune step 1900 / 3162 (60.0%). I0829 08:08:54.673932 140318776715072 train.py:366] Tune step 2000 / 3162 (60.0%). I0829 08:10:47.221370 140318776715072 train.py:366] Tune step 2100 / 3162 (70.0%). I0829 08:12:39.774174 140318776715072 train.py:366] Tune step 2200 / 3162 (70.0%). I0829 08:14:32.322385 140318776715072 train.py:366] Tune s,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:10536,performance,Tune,Tune,10536,2 train.py:366] Tune step 0 / 3162 (0.0%). I0829 07:33:17.573163 140318776715072 train.py:366] Tune step 100 / 3162 (0.0%). I0829 07:35:10.013494 140318776715072 train.py:366] Tune step 200 / 3162 (10.0%). I0829 07:37:02.497336 140318776715072 train.py:366] Tune step 300 / 3162 (10.0%). I0829 07:38:54.834164 140318776715072 train.py:366] Tune step 400 / 3162 (10.0%). I0829 07:40:47.319165 140318776715072 train.py:366] Tune step 500 / 3162 (20.0%). I0829 07:42:39.802007 140318776715072 train.py:366] Tune step 600 / 3162 (20.0%). I0829 07:44:32.297624 140318776715072 train.py:366] Tune step 700 / 3162 (20.0%). I0829 07:46:24.658610 140318776715072 train.py:366] Tune step 800 / 3162 (30.0%). I0829 07:48:17.176530 140318776715072 train.py:366] Tune step 900 / 3162 (30.0%). I0829 07:50:09.700463 140318776715072 train.py:366] Tune step 1000 / 3162 (30.0%). I0829 07:52:02.226121 140318776715072 train.py:366] Tune step 1100 / 3162 (30.0%). I0829 07:53:54.613348 140318776715072 train.py:366] Tune step 1200 / 3162 (40.0%). I0829 07:55:47.134974 140318776715072 train.py:366] Tune step 1300 / 3162 (40.0%). I0829 07:57:39.682815 140318776715072 train.py:366] Tune step 1400 / 3162 (40.0%). I0829 07:59:32.215537 140318776715072 train.py:366] Tune step 1500 / 3162 (50.0%). I0829 08:01:24.651632 140318776715072 train.py:366] Tune step 1600 / 3162 (50.0%). I0829 08:03:17.188146 140318776715072 train.py:366] Tune step 1700 / 3162 (50.0%). I0829 08:05:09.741266 140318776715072 train.py:366] Tune step 1800 / 3162 (60.0%). I0829 08:07:02.262498 140318776715072 train.py:366] Tune step 1900 / 3162 (60.0%). I0829 08:08:54.673932 140318776715072 train.py:366] Tune step 2000 / 3162 (60.0%). I0829 08:10:47.221370 140318776715072 train.py:366] Tune step 2100 / 3162 (70.0%). I0829 08:12:39.774174 140318776715072 train.py:366] Tune step 2200 / 3162 (70.0%). I0829 08:14:32.322385 140318776715072 train.py:366] Tune step 2300 / 3162 (70.0%). I0829 08:16:24.722720 140318776715072 train.py:366] Tune s,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:10619,performance,Tune,Tune,10619,ain.py:366] Tune step 100 / 3162 (0.0%). I0829 07:35:10.013494 140318776715072 train.py:366] Tune step 200 / 3162 (10.0%). I0829 07:37:02.497336 140318776715072 train.py:366] Tune step 300 / 3162 (10.0%). I0829 07:38:54.834164 140318776715072 train.py:366] Tune step 400 / 3162 (10.0%). I0829 07:40:47.319165 140318776715072 train.py:366] Tune step 500 / 3162 (20.0%). I0829 07:42:39.802007 140318776715072 train.py:366] Tune step 600 / 3162 (20.0%). I0829 07:44:32.297624 140318776715072 train.py:366] Tune step 700 / 3162 (20.0%). I0829 07:46:24.658610 140318776715072 train.py:366] Tune step 800 / 3162 (30.0%). I0829 07:48:17.176530 140318776715072 train.py:366] Tune step 900 / 3162 (30.0%). I0829 07:50:09.700463 140318776715072 train.py:366] Tune step 1000 / 3162 (30.0%). I0829 07:52:02.226121 140318776715072 train.py:366] Tune step 1100 / 3162 (30.0%). I0829 07:53:54.613348 140318776715072 train.py:366] Tune step 1200 / 3162 (40.0%). I0829 07:55:47.134974 140318776715072 train.py:366] Tune step 1300 / 3162 (40.0%). I0829 07:57:39.682815 140318776715072 train.py:366] Tune step 1400 / 3162 (40.0%). I0829 07:59:32.215537 140318776715072 train.py:366] Tune step 1500 / 3162 (50.0%). I0829 08:01:24.651632 140318776715072 train.py:366] Tune step 1600 / 3162 (50.0%). I0829 08:03:17.188146 140318776715072 train.py:366] Tune step 1700 / 3162 (50.0%). I0829 08:05:09.741266 140318776715072 train.py:366] Tune step 1800 / 3162 (60.0%). I0829 08:07:02.262498 140318776715072 train.py:366] Tune step 1900 / 3162 (60.0%). I0829 08:08:54.673932 140318776715072 train.py:366] Tune step 2000 / 3162 (60.0%). I0829 08:10:47.221370 140318776715072 train.py:366] Tune step 2100 / 3162 (70.0%). I0829 08:12:39.774174 140318776715072 train.py:366] Tune step 2200 / 3162 (70.0%). I0829 08:14:32.322385 140318776715072 train.py:366] Tune step 2300 / 3162 (70.0%). I0829 08:16:24.722720 140318776715072 train.py:366] Tune step 2400 / 3162 (80.0%). I0829 08:18:17.252759 140318776715072 train.py:366] Tune s,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:10702,performance,Tune,Tune,10702,n.py:366] Tune step 200 / 3162 (10.0%). I0829 07:37:02.497336 140318776715072 train.py:366] Tune step 300 / 3162 (10.0%). I0829 07:38:54.834164 140318776715072 train.py:366] Tune step 400 / 3162 (10.0%). I0829 07:40:47.319165 140318776715072 train.py:366] Tune step 500 / 3162 (20.0%). I0829 07:42:39.802007 140318776715072 train.py:366] Tune step 600 / 3162 (20.0%). I0829 07:44:32.297624 140318776715072 train.py:366] Tune step 700 / 3162 (20.0%). I0829 07:46:24.658610 140318776715072 train.py:366] Tune step 800 / 3162 (30.0%). I0829 07:48:17.176530 140318776715072 train.py:366] Tune step 900 / 3162 (30.0%). I0829 07:50:09.700463 140318776715072 train.py:366] Tune step 1000 / 3162 (30.0%). I0829 07:52:02.226121 140318776715072 train.py:366] Tune step 1100 / 3162 (30.0%). I0829 07:53:54.613348 140318776715072 train.py:366] Tune step 1200 / 3162 (40.0%). I0829 07:55:47.134974 140318776715072 train.py:366] Tune step 1300 / 3162 (40.0%). I0829 07:57:39.682815 140318776715072 train.py:366] Tune step 1400 / 3162 (40.0%). I0829 07:59:32.215537 140318776715072 train.py:366] Tune step 1500 / 3162 (50.0%). I0829 08:01:24.651632 140318776715072 train.py:366] Tune step 1600 / 3162 (50.0%). I0829 08:03:17.188146 140318776715072 train.py:366] Tune step 1700 / 3162 (50.0%). I0829 08:05:09.741266 140318776715072 train.py:366] Tune step 1800 / 3162 (60.0%). I0829 08:07:02.262498 140318776715072 train.py:366] Tune step 1900 / 3162 (60.0%). I0829 08:08:54.673932 140318776715072 train.py:366] Tune step 2000 / 3162 (60.0%). I0829 08:10:47.221370 140318776715072 train.py:366] Tune step 2100 / 3162 (70.0%). I0829 08:12:39.774174 140318776715072 train.py:366] Tune step 2200 / 3162 (70.0%). I0829 08:14:32.322385 140318776715072 train.py:366] Tune step 2300 / 3162 (70.0%). I0829 08:16:24.722720 140318776715072 train.py:366] Tune step 2400 / 3162 (80.0%). I0829 08:18:17.252759 140318776715072 train.py:366] Tune step 2500 / 3162 (80.0%). I0829 08:20:09.823046 140318776715072 train.py:366] Tune s,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:10785,performance,Tune,Tune,10785,.py:366] Tune step 300 / 3162 (10.0%). I0829 07:38:54.834164 140318776715072 train.py:366] Tune step 400 / 3162 (10.0%). I0829 07:40:47.319165 140318776715072 train.py:366] Tune step 500 / 3162 (20.0%). I0829 07:42:39.802007 140318776715072 train.py:366] Tune step 600 / 3162 (20.0%). I0829 07:44:32.297624 140318776715072 train.py:366] Tune step 700 / 3162 (20.0%). I0829 07:46:24.658610 140318776715072 train.py:366] Tune step 800 / 3162 (30.0%). I0829 07:48:17.176530 140318776715072 train.py:366] Tune step 900 / 3162 (30.0%). I0829 07:50:09.700463 140318776715072 train.py:366] Tune step 1000 / 3162 (30.0%). I0829 07:52:02.226121 140318776715072 train.py:366] Tune step 1100 / 3162 (30.0%). I0829 07:53:54.613348 140318776715072 train.py:366] Tune step 1200 / 3162 (40.0%). I0829 07:55:47.134974 140318776715072 train.py:366] Tune step 1300 / 3162 (40.0%). I0829 07:57:39.682815 140318776715072 train.py:366] Tune step 1400 / 3162 (40.0%). I0829 07:59:32.215537 140318776715072 train.py:366] Tune step 1500 / 3162 (50.0%). I0829 08:01:24.651632 140318776715072 train.py:366] Tune step 1600 / 3162 (50.0%). I0829 08:03:17.188146 140318776715072 train.py:366] Tune step 1700 / 3162 (50.0%). I0829 08:05:09.741266 140318776715072 train.py:366] Tune step 1800 / 3162 (60.0%). I0829 08:07:02.262498 140318776715072 train.py:366] Tune step 1900 / 3162 (60.0%). I0829 08:08:54.673932 140318776715072 train.py:366] Tune step 2000 / 3162 (60.0%). I0829 08:10:47.221370 140318776715072 train.py:366] Tune step 2100 / 3162 (70.0%). I0829 08:12:39.774174 140318776715072 train.py:366] Tune step 2200 / 3162 (70.0%). I0829 08:14:32.322385 140318776715072 train.py:366] Tune step 2300 / 3162 (70.0%). I0829 08:16:24.722720 140318776715072 train.py:366] Tune step 2400 / 3162 (80.0%). I0829 08:18:17.252759 140318776715072 train.py:366] Tune step 2500 / 3162 (80.0%). I0829 08:20:09.823046 140318776715072 train.py:366] Tune step 2600 / 3162 (80.0%). I0829 08:22:02.367495 140318776715072 train.py:366] Tune s,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:10868,performance,Tune,Tune,10868,py:366] Tune step 400 / 3162 (10.0%). I0829 07:40:47.319165 140318776715072 train.py:366] Tune step 500 / 3162 (20.0%). I0829 07:42:39.802007 140318776715072 train.py:366] Tune step 600 / 3162 (20.0%). I0829 07:44:32.297624 140318776715072 train.py:366] Tune step 700 / 3162 (20.0%). I0829 07:46:24.658610 140318776715072 train.py:366] Tune step 800 / 3162 (30.0%). I0829 07:48:17.176530 140318776715072 train.py:366] Tune step 900 / 3162 (30.0%). I0829 07:50:09.700463 140318776715072 train.py:366] Tune step 1000 / 3162 (30.0%). I0829 07:52:02.226121 140318776715072 train.py:366] Tune step 1100 / 3162 (30.0%). I0829 07:53:54.613348 140318776715072 train.py:366] Tune step 1200 / 3162 (40.0%). I0829 07:55:47.134974 140318776715072 train.py:366] Tune step 1300 / 3162 (40.0%). I0829 07:57:39.682815 140318776715072 train.py:366] Tune step 1400 / 3162 (40.0%). I0829 07:59:32.215537 140318776715072 train.py:366] Tune step 1500 / 3162 (50.0%). I0829 08:01:24.651632 140318776715072 train.py:366] Tune step 1600 / 3162 (50.0%). I0829 08:03:17.188146 140318776715072 train.py:366] Tune step 1700 / 3162 (50.0%). I0829 08:05:09.741266 140318776715072 train.py:366] Tune step 1800 / 3162 (60.0%). I0829 08:07:02.262498 140318776715072 train.py:366] Tune step 1900 / 3162 (60.0%). I0829 08:08:54.673932 140318776715072 train.py:366] Tune step 2000 / 3162 (60.0%). I0829 08:10:47.221370 140318776715072 train.py:366] Tune step 2100 / 3162 (70.0%). I0829 08:12:39.774174 140318776715072 train.py:366] Tune step 2200 / 3162 (70.0%). I0829 08:14:32.322385 140318776715072 train.py:366] Tune step 2300 / 3162 (70.0%). I0829 08:16:24.722720 140318776715072 train.py:366] Tune step 2400 / 3162 (80.0%). I0829 08:18:17.252759 140318776715072 train.py:366] Tune step 2500 / 3162 (80.0%). I0829 08:20:09.823046 140318776715072 train.py:366] Tune step 2600 / 3162 (80.0%). I0829 08:22:02.367495 140318776715072 train.py:366] Tune step 2700 / 3162 (90.0%). I0829 08:23:54.783612 140318776715072 train.py:366] Tune s,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:10951,performance,Tune,Tune,10951,y:366] Tune step 500 / 3162 (20.0%). I0829 07:42:39.802007 140318776715072 train.py:366] Tune step 600 / 3162 (20.0%). I0829 07:44:32.297624 140318776715072 train.py:366] Tune step 700 / 3162 (20.0%). I0829 07:46:24.658610 140318776715072 train.py:366] Tune step 800 / 3162 (30.0%). I0829 07:48:17.176530 140318776715072 train.py:366] Tune step 900 / 3162 (30.0%). I0829 07:50:09.700463 140318776715072 train.py:366] Tune step 1000 / 3162 (30.0%). I0829 07:52:02.226121 140318776715072 train.py:366] Tune step 1100 / 3162 (30.0%). I0829 07:53:54.613348 140318776715072 train.py:366] Tune step 1200 / 3162 (40.0%). I0829 07:55:47.134974 140318776715072 train.py:366] Tune step 1300 / 3162 (40.0%). I0829 07:57:39.682815 140318776715072 train.py:366] Tune step 1400 / 3162 (40.0%). I0829 07:59:32.215537 140318776715072 train.py:366] Tune step 1500 / 3162 (50.0%). I0829 08:01:24.651632 140318776715072 train.py:366] Tune step 1600 / 3162 (50.0%). I0829 08:03:17.188146 140318776715072 train.py:366] Tune step 1700 / 3162 (50.0%). I0829 08:05:09.741266 140318776715072 train.py:366] Tune step 1800 / 3162 (60.0%). I0829 08:07:02.262498 140318776715072 train.py:366] Tune step 1900 / 3162 (60.0%). I0829 08:08:54.673932 140318776715072 train.py:366] Tune step 2000 / 3162 (60.0%). I0829 08:10:47.221370 140318776715072 train.py:366] Tune step 2100 / 3162 (70.0%). I0829 08:12:39.774174 140318776715072 train.py:366] Tune step 2200 / 3162 (70.0%). I0829 08:14:32.322385 140318776715072 train.py:366] Tune step 2300 / 3162 (70.0%). I0829 08:16:24.722720 140318776715072 train.py:366] Tune step 2400 / 3162 (80.0%). I0829 08:18:17.252759 140318776715072 train.py:366] Tune step 2500 / 3162 (80.0%). I0829 08:20:09.823046 140318776715072 train.py:366] Tune step 2600 / 3162 (80.0%). I0829 08:22:02.367495 140318776715072 train.py:366] Tune step 2700 / 3162 (90.0%). I0829 08:23:54.783612 140318776715072 train.py:366] Tune step 2800 / 3162 (90.0%). I0829 08:25:47.336242 140318776715072 train.py:366] Tune s,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:11034,performance,Tune,Tune,11034,:366] Tune step 600 / 3162 (20.0%). I0829 07:44:32.297624 140318776715072 train.py:366] Tune step 700 / 3162 (20.0%). I0829 07:46:24.658610 140318776715072 train.py:366] Tune step 800 / 3162 (30.0%). I0829 07:48:17.176530 140318776715072 train.py:366] Tune step 900 / 3162 (30.0%). I0829 07:50:09.700463 140318776715072 train.py:366] Tune step 1000 / 3162 (30.0%). I0829 07:52:02.226121 140318776715072 train.py:366] Tune step 1100 / 3162 (30.0%). I0829 07:53:54.613348 140318776715072 train.py:366] Tune step 1200 / 3162 (40.0%). I0829 07:55:47.134974 140318776715072 train.py:366] Tune step 1300 / 3162 (40.0%). I0829 07:57:39.682815 140318776715072 train.py:366] Tune step 1400 / 3162 (40.0%). I0829 07:59:32.215537 140318776715072 train.py:366] Tune step 1500 / 3162 (50.0%). I0829 08:01:24.651632 140318776715072 train.py:366] Tune step 1600 / 3162 (50.0%). I0829 08:03:17.188146 140318776715072 train.py:366] Tune step 1700 / 3162 (50.0%). I0829 08:05:09.741266 140318776715072 train.py:366] Tune step 1800 / 3162 (60.0%). I0829 08:07:02.262498 140318776715072 train.py:366] Tune step 1900 / 3162 (60.0%). I0829 08:08:54.673932 140318776715072 train.py:366] Tune step 2000 / 3162 (60.0%). I0829 08:10:47.221370 140318776715072 train.py:366] Tune step 2100 / 3162 (70.0%). I0829 08:12:39.774174 140318776715072 train.py:366] Tune step 2200 / 3162 (70.0%). I0829 08:14:32.322385 140318776715072 train.py:366] Tune step 2300 / 3162 (70.0%). I0829 08:16:24.722720 140318776715072 train.py:366] Tune step 2400 / 3162 (80.0%). I0829 08:18:17.252759 140318776715072 train.py:366] Tune step 2500 / 3162 (80.0%). I0829 08:20:09.823046 140318776715072 train.py:366] Tune step 2600 / 3162 (80.0%). I0829 08:22:02.367495 140318776715072 train.py:366] Tune step 2700 / 3162 (90.0%). I0829 08:23:54.783612 140318776715072 train.py:366] Tune step 2800 / 3162 (90.0%). I0829 08:25:47.336242 140318776715072 train.py:366] Tune step 2900 / 3162 (90.0%). I0829 08:27:39.775715 140318776715072 train.py:366] Tune s,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:11117,performance,Tune,Tune,11117,366] Tune step 700 / 3162 (20.0%). I0829 07:46:24.658610 140318776715072 train.py:366] Tune step 800 / 3162 (30.0%). I0829 07:48:17.176530 140318776715072 train.py:366] Tune step 900 / 3162 (30.0%). I0829 07:50:09.700463 140318776715072 train.py:366] Tune step 1000 / 3162 (30.0%). I0829 07:52:02.226121 140318776715072 train.py:366] Tune step 1100 / 3162 (30.0%). I0829 07:53:54.613348 140318776715072 train.py:366] Tune step 1200 / 3162 (40.0%). I0829 07:55:47.134974 140318776715072 train.py:366] Tune step 1300 / 3162 (40.0%). I0829 07:57:39.682815 140318776715072 train.py:366] Tune step 1400 / 3162 (40.0%). I0829 07:59:32.215537 140318776715072 train.py:366] Tune step 1500 / 3162 (50.0%). I0829 08:01:24.651632 140318776715072 train.py:366] Tune step 1600 / 3162 (50.0%). I0829 08:03:17.188146 140318776715072 train.py:366] Tune step 1700 / 3162 (50.0%). I0829 08:05:09.741266 140318776715072 train.py:366] Tune step 1800 / 3162 (60.0%). I0829 08:07:02.262498 140318776715072 train.py:366] Tune step 1900 / 3162 (60.0%). I0829 08:08:54.673932 140318776715072 train.py:366] Tune step 2000 / 3162 (60.0%). I0829 08:10:47.221370 140318776715072 train.py:366] Tune step 2100 / 3162 (70.0%). I0829 08:12:39.774174 140318776715072 train.py:366] Tune step 2200 / 3162 (70.0%). I0829 08:14:32.322385 140318776715072 train.py:366] Tune step 2300 / 3162 (70.0%). I0829 08:16:24.722720 140318776715072 train.py:366] Tune step 2400 / 3162 (80.0%). I0829 08:18:17.252759 140318776715072 train.py:366] Tune step 2500 / 3162 (80.0%). I0829 08:20:09.823046 140318776715072 train.py:366] Tune step 2600 / 3162 (80.0%). I0829 08:22:02.367495 140318776715072 train.py:366] Tune step 2700 / 3162 (90.0%). I0829 08:23:54.783612 140318776715072 train.py:366] Tune step 2800 / 3162 (90.0%). I0829 08:25:47.336242 140318776715072 train.py:366] Tune step 2900 / 3162 (90.0%). I0829 08:27:39.775715 140318776715072 train.py:366] Tune step 3000 / 3162 (90.0%). I0829 08:29:29.592094 140318776715072 train.py:366] Tune s,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:11200,performance,Tune,Tune,11200,66] Tune step 800 / 3162 (30.0%). I0829 07:48:17.176530 140318776715072 train.py:366] Tune step 900 / 3162 (30.0%). I0829 07:50:09.700463 140318776715072 train.py:366] Tune step 1000 / 3162 (30.0%). I0829 07:52:02.226121 140318776715072 train.py:366] Tune step 1100 / 3162 (30.0%). I0829 07:53:54.613348 140318776715072 train.py:366] Tune step 1200 / 3162 (40.0%). I0829 07:55:47.134974 140318776715072 train.py:366] Tune step 1300 / 3162 (40.0%). I0829 07:57:39.682815 140318776715072 train.py:366] Tune step 1400 / 3162 (40.0%). I0829 07:59:32.215537 140318776715072 train.py:366] Tune step 1500 / 3162 (50.0%). I0829 08:01:24.651632 140318776715072 train.py:366] Tune step 1600 / 3162 (50.0%). I0829 08:03:17.188146 140318776715072 train.py:366] Tune step 1700 / 3162 (50.0%). I0829 08:05:09.741266 140318776715072 train.py:366] Tune step 1800 / 3162 (60.0%). I0829 08:07:02.262498 140318776715072 train.py:366] Tune step 1900 / 3162 (60.0%). I0829 08:08:54.673932 140318776715072 train.py:366] Tune step 2000 / 3162 (60.0%). I0829 08:10:47.221370 140318776715072 train.py:366] Tune step 2100 / 3162 (70.0%). I0829 08:12:39.774174 140318776715072 train.py:366] Tune step 2200 / 3162 (70.0%). I0829 08:14:32.322385 140318776715072 train.py:366] Tune step 2300 / 3162 (70.0%). I0829 08:16:24.722720 140318776715072 train.py:366] Tune step 2400 / 3162 (80.0%). I0829 08:18:17.252759 140318776715072 train.py:366] Tune step 2500 / 3162 (80.0%). I0829 08:20:09.823046 140318776715072 train.py:366] Tune step 2600 / 3162 (80.0%). I0829 08:22:02.367495 140318776715072 train.py:366] Tune step 2700 / 3162 (90.0%). I0829 08:23:54.783612 140318776715072 train.py:366] Tune step 2800 / 3162 (90.0%). I0829 08:25:47.336242 140318776715072 train.py:366] Tune step 2900 / 3162 (90.0%). I0829 08:27:39.775715 140318776715072 train.py:366] Tune step 3000 / 3162 (90.0%). I0829 08:29:29.592094 140318776715072 train.py:366] Tune step 3100 / 3162 (100.0%). I0829 08:30:42.583051 140305134778112 logging_writer.py:4,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:11283,performance,Tune,Tune,11283,"6] Tune step 900 / 3162 (30.0%). I0829 07:50:09.700463 140318776715072 train.py:366] Tune step 1000 / 3162 (30.0%). I0829 07:52:02.226121 140318776715072 train.py:366] Tune step 1100 / 3162 (30.0%). I0829 07:53:54.613348 140318776715072 train.py:366] Tune step 1200 / 3162 (40.0%). I0829 07:55:47.134974 140318776715072 train.py:366] Tune step 1300 / 3162 (40.0%). I0829 07:57:39.682815 140318776715072 train.py:366] Tune step 1400 / 3162 (40.0%). I0829 07:59:32.215537 140318776715072 train.py:366] Tune step 1500 / 3162 (50.0%). I0829 08:01:24.651632 140318776715072 train.py:366] Tune step 1600 / 3162 (50.0%). I0829 08:03:17.188146 140318776715072 train.py:366] Tune step 1700 / 3162 (50.0%). I0829 08:05:09.741266 140318776715072 train.py:366] Tune step 1800 / 3162 (60.0%). I0829 08:07:02.262498 140318776715072 train.py:366] Tune step 1900 / 3162 (60.0%). I0829 08:08:54.673932 140318776715072 train.py:366] Tune step 2000 / 3162 (60.0%). I0829 08:10:47.221370 140318776715072 train.py:366] Tune step 2100 / 3162 (70.0%). I0829 08:12:39.774174 140318776715072 train.py:366] Tune step 2200 / 3162 (70.0%). I0829 08:14:32.322385 140318776715072 train.py:366] Tune step 2300 / 3162 (70.0%). I0829 08:16:24.722720 140318776715072 train.py:366] Tune step 2400 / 3162 (80.0%). I0829 08:18:17.252759 140318776715072 train.py:366] Tune step 2500 / 3162 (80.0%). I0829 08:20:09.823046 140318776715072 train.py:366] Tune step 2600 / 3162 (80.0%). I0829 08:22:02.367495 140318776715072 train.py:366] Tune step 2700 / 3162 (90.0%). I0829 08:23:54.783612 140318776715072 train.py:366] Tune step 2800 / 3162 (90.0%). I0829 08:25:47.336242 140318776715072 train.py:366] Tune step 2900 / 3162 (90.0%). I0829 08:27:39.775715 140318776715072 train.py:366] Tune step 3000 / 3162 (90.0%). I0829 08:29:29.592094 140318776715072 train.py:366] Tune step 3100 / 3162 (100.0%). I0829 08:30:42.583051 140305134778112 logging_writer.py:48] [13993] tune/categorical_accuracy=0.9916982650756836, tune/categorical_crossentr",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:11366,performance,Tune,Tune,11366,"] Tune step 1000 / 3162 (30.0%). I0829 07:52:02.226121 140318776715072 train.py:366] Tune step 1100 / 3162 (30.0%). I0829 07:53:54.613348 140318776715072 train.py:366] Tune step 1200 / 3162 (40.0%). I0829 07:55:47.134974 140318776715072 train.py:366] Tune step 1300 / 3162 (40.0%). I0829 07:57:39.682815 140318776715072 train.py:366] Tune step 1400 / 3162 (40.0%). I0829 07:59:32.215537 140318776715072 train.py:366] Tune step 1500 / 3162 (50.0%). I0829 08:01:24.651632 140318776715072 train.py:366] Tune step 1600 / 3162 (50.0%). I0829 08:03:17.188146 140318776715072 train.py:366] Tune step 1700 / 3162 (50.0%). I0829 08:05:09.741266 140318776715072 train.py:366] Tune step 1800 / 3162 (60.0%). I0829 08:07:02.262498 140318776715072 train.py:366] Tune step 1900 / 3162 (60.0%). I0829 08:08:54.673932 140318776715072 train.py:366] Tune step 2000 / 3162 (60.0%). I0829 08:10:47.221370 140318776715072 train.py:366] Tune step 2100 / 3162 (70.0%). I0829 08:12:39.774174 140318776715072 train.py:366] Tune step 2200 / 3162 (70.0%). I0829 08:14:32.322385 140318776715072 train.py:366] Tune step 2300 / 3162 (70.0%). I0829 08:16:24.722720 140318776715072 train.py:366] Tune step 2400 / 3162 (80.0%). I0829 08:18:17.252759 140318776715072 train.py:366] Tune step 2500 / 3162 (80.0%). I0829 08:20:09.823046 140318776715072 train.py:366] Tune step 2600 / 3162 (80.0%). I0829 08:22:02.367495 140318776715072 train.py:366] Tune step 2700 / 3162 (90.0%). I0829 08:23:54.783612 140318776715072 train.py:366] Tune step 2800 / 3162 (90.0%). I0829 08:25:47.336242 140318776715072 train.py:366] Tune step 2900 / 3162 (90.0%). I0829 08:27:39.775715 140318776715072 train.py:366] Tune step 3000 / 3162 (90.0%). I0829 08:29:29.592094 140318776715072 train.py:366] Tune step 3100 / 3162 (100.0%). I0829 08:30:42.583051 140305134778112 logging_writer.py:48] [13993] tune/categorical_accuracy=0.9916982650756836, tune/categorical_crossentropy=0.560210645198822, tune/f1_het=0.0, tune/f1_homalt=0.0, tune/f1_homref=0.995831",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:11449,performance,Tune,Tune,11449,"] Tune step 1100 / 3162 (30.0%). I0829 07:53:54.613348 140318776715072 train.py:366] Tune step 1200 / 3162 (40.0%). I0829 07:55:47.134974 140318776715072 train.py:366] Tune step 1300 / 3162 (40.0%). I0829 07:57:39.682815 140318776715072 train.py:366] Tune step 1400 / 3162 (40.0%). I0829 07:59:32.215537 140318776715072 train.py:366] Tune step 1500 / 3162 (50.0%). I0829 08:01:24.651632 140318776715072 train.py:366] Tune step 1600 / 3162 (50.0%). I0829 08:03:17.188146 140318776715072 train.py:366] Tune step 1700 / 3162 (50.0%). I0829 08:05:09.741266 140318776715072 train.py:366] Tune step 1800 / 3162 (60.0%). I0829 08:07:02.262498 140318776715072 train.py:366] Tune step 1900 / 3162 (60.0%). I0829 08:08:54.673932 140318776715072 train.py:366] Tune step 2000 / 3162 (60.0%). I0829 08:10:47.221370 140318776715072 train.py:366] Tune step 2100 / 3162 (70.0%). I0829 08:12:39.774174 140318776715072 train.py:366] Tune step 2200 / 3162 (70.0%). I0829 08:14:32.322385 140318776715072 train.py:366] Tune step 2300 / 3162 (70.0%). I0829 08:16:24.722720 140318776715072 train.py:366] Tune step 2400 / 3162 (80.0%). I0829 08:18:17.252759 140318776715072 train.py:366] Tune step 2500 / 3162 (80.0%). I0829 08:20:09.823046 140318776715072 train.py:366] Tune step 2600 / 3162 (80.0%). I0829 08:22:02.367495 140318776715072 train.py:366] Tune step 2700 / 3162 (90.0%). I0829 08:23:54.783612 140318776715072 train.py:366] Tune step 2800 / 3162 (90.0%). I0829 08:25:47.336242 140318776715072 train.py:366] Tune step 2900 / 3162 (90.0%). I0829 08:27:39.775715 140318776715072 train.py:366] Tune step 3000 / 3162 (90.0%). I0829 08:29:29.592094 140318776715072 train.py:366] Tune step 3100 / 3162 (100.0%). I0829 08:30:42.583051 140305134778112 logging_writer.py:48] [13993] tune/categorical_accuracy=0.9916982650756836, tune/categorical_crossentropy=0.560210645198822, tune/f1_het=0.0, tune/f1_homalt=0.0, tune/f1_homref=0.9958318471908569, tune/f1_macro=0.33194395899772644, tune/f1_micro=0.9916982650756836, tu",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:11532,performance,Tune,Tune,11532,"] Tune step 1200 / 3162 (40.0%). I0829 07:55:47.134974 140318776715072 train.py:366] Tune step 1300 / 3162 (40.0%). I0829 07:57:39.682815 140318776715072 train.py:366] Tune step 1400 / 3162 (40.0%). I0829 07:59:32.215537 140318776715072 train.py:366] Tune step 1500 / 3162 (50.0%). I0829 08:01:24.651632 140318776715072 train.py:366] Tune step 1600 / 3162 (50.0%). I0829 08:03:17.188146 140318776715072 train.py:366] Tune step 1700 / 3162 (50.0%). I0829 08:05:09.741266 140318776715072 train.py:366] Tune step 1800 / 3162 (60.0%). I0829 08:07:02.262498 140318776715072 train.py:366] Tune step 1900 / 3162 (60.0%). I0829 08:08:54.673932 140318776715072 train.py:366] Tune step 2000 / 3162 (60.0%). I0829 08:10:47.221370 140318776715072 train.py:366] Tune step 2100 / 3162 (70.0%). I0829 08:12:39.774174 140318776715072 train.py:366] Tune step 2200 / 3162 (70.0%). I0829 08:14:32.322385 140318776715072 train.py:366] Tune step 2300 / 3162 (70.0%). I0829 08:16:24.722720 140318776715072 train.py:366] Tune step 2400 / 3162 (80.0%). I0829 08:18:17.252759 140318776715072 train.py:366] Tune step 2500 / 3162 (80.0%). I0829 08:20:09.823046 140318776715072 train.py:366] Tune step 2600 / 3162 (80.0%). I0829 08:22:02.367495 140318776715072 train.py:366] Tune step 2700 / 3162 (90.0%). I0829 08:23:54.783612 140318776715072 train.py:366] Tune step 2800 / 3162 (90.0%). I0829 08:25:47.336242 140318776715072 train.py:366] Tune step 2900 / 3162 (90.0%). I0829 08:27:39.775715 140318776715072 train.py:366] Tune step 3000 / 3162 (90.0%). I0829 08:29:29.592094 140318776715072 train.py:366] Tune step 3100 / 3162 (100.0%). I0829 08:30:42.583051 140305134778112 logging_writer.py:48] [13993] tune/categorical_accuracy=0.9916982650756836, tune/categorical_crossentropy=0.560210645198822, tune/f1_het=0.0, tune/f1_homalt=0.0, tune/f1_homref=0.9958318471908569, tune/f1_macro=0.33194395899772644, tune/f1_micro=0.9916982650756836, tune/f1_weighted=0.9958318471908569, tune/false_negatives_1=1777.0, tune/false_positi",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:11615,performance,Tune,Tune,11615,"] Tune step 1300 / 3162 (40.0%). I0829 07:57:39.682815 140318776715072 train.py:366] Tune step 1400 / 3162 (40.0%). I0829 07:59:32.215537 140318776715072 train.py:366] Tune step 1500 / 3162 (50.0%). I0829 08:01:24.651632 140318776715072 train.py:366] Tune step 1600 / 3162 (50.0%). I0829 08:03:17.188146 140318776715072 train.py:366] Tune step 1700 / 3162 (50.0%). I0829 08:05:09.741266 140318776715072 train.py:366] Tune step 1800 / 3162 (60.0%). I0829 08:07:02.262498 140318776715072 train.py:366] Tune step 1900 / 3162 (60.0%). I0829 08:08:54.673932 140318776715072 train.py:366] Tune step 2000 / 3162 (60.0%). I0829 08:10:47.221370 140318776715072 train.py:366] Tune step 2100 / 3162 (70.0%). I0829 08:12:39.774174 140318776715072 train.py:366] Tune step 2200 / 3162 (70.0%). I0829 08:14:32.322385 140318776715072 train.py:366] Tune step 2300 / 3162 (70.0%). I0829 08:16:24.722720 140318776715072 train.py:366] Tune step 2400 / 3162 (80.0%). I0829 08:18:17.252759 140318776715072 train.py:366] Tune step 2500 / 3162 (80.0%). I0829 08:20:09.823046 140318776715072 train.py:366] Tune step 2600 / 3162 (80.0%). I0829 08:22:02.367495 140318776715072 train.py:366] Tune step 2700 / 3162 (90.0%). I0829 08:23:54.783612 140318776715072 train.py:366] Tune step 2800 / 3162 (90.0%). I0829 08:25:47.336242 140318776715072 train.py:366] Tune step 2900 / 3162 (90.0%). I0829 08:27:39.775715 140318776715072 train.py:366] Tune step 3000 / 3162 (90.0%). I0829 08:29:29.592094 140318776715072 train.py:366] Tune step 3100 / 3162 (100.0%). I0829 08:30:42.583051 140305134778112 logging_writer.py:48] [13993] tune/categorical_accuracy=0.9916982650756836, tune/categorical_crossentropy=0.560210645198822, tune/f1_het=0.0, tune/f1_homalt=0.0, tune/f1_homref=0.9958318471908569, tune/f1_macro=0.33194395899772644, tune/f1_micro=0.9916982650756836, tune/f1_weighted=0.9958318471908569, tune/false_negatives_1=1777.0, tune/false_positives_1=1544.0, tune/loss=0.5603554248809814, tune/precision_1=0.9923615455627441, tu",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:11698,performance,Tune,Tune,11698,"] Tune step 1400 / 3162 (40.0%). I0829 07:59:32.215537 140318776715072 train.py:366] Tune step 1500 / 3162 (50.0%). I0829 08:01:24.651632 140318776715072 train.py:366] Tune step 1600 / 3162 (50.0%). I0829 08:03:17.188146 140318776715072 train.py:366] Tune step 1700 / 3162 (50.0%). I0829 08:05:09.741266 140318776715072 train.py:366] Tune step 1800 / 3162 (60.0%). I0829 08:07:02.262498 140318776715072 train.py:366] Tune step 1900 / 3162 (60.0%). I0829 08:08:54.673932 140318776715072 train.py:366] Tune step 2000 / 3162 (60.0%). I0829 08:10:47.221370 140318776715072 train.py:366] Tune step 2100 / 3162 (70.0%). I0829 08:12:39.774174 140318776715072 train.py:366] Tune step 2200 / 3162 (70.0%). I0829 08:14:32.322385 140318776715072 train.py:366] Tune step 2300 / 3162 (70.0%). I0829 08:16:24.722720 140318776715072 train.py:366] Tune step 2400 / 3162 (80.0%). I0829 08:18:17.252759 140318776715072 train.py:366] Tune step 2500 / 3162 (80.0%). I0829 08:20:09.823046 140318776715072 train.py:366] Tune step 2600 / 3162 (80.0%). I0829 08:22:02.367495 140318776715072 train.py:366] Tune step 2700 / 3162 (90.0%). I0829 08:23:54.783612 140318776715072 train.py:366] Tune step 2800 / 3162 (90.0%). I0829 08:25:47.336242 140318776715072 train.py:366] Tune step 2900 / 3162 (90.0%). I0829 08:27:39.775715 140318776715072 train.py:366] Tune step 3000 / 3162 (90.0%). I0829 08:29:29.592094 140318776715072 train.py:366] Tune step 3100 / 3162 (100.0%). I0829 08:30:42.583051 140305134778112 logging_writer.py:48] [13993] tune/categorical_accuracy=0.9916982650756836, tune/categorical_crossentropy=0.560210645198822, tune/f1_het=0.0, tune/f1_homalt=0.0, tune/f1_homref=0.9958318471908569, tune/f1_macro=0.33194395899772644, tune/f1_micro=0.9916982650756836, tune/f1_weighted=0.9958318471908569, tune/false_negatives_1=1777.0, tune/false_positives_1=1544.0, tune/loss=0.5603554248809814, tune/precision_1=0.9923615455627441, tune/precision_het=0.0, tune/precision_homalt=0.0, tune/precision_homref=1.0, tune/re",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:11781,performance,Tune,Tune,11781,"] Tune step 1500 / 3162 (50.0%). I0829 08:01:24.651632 140318776715072 train.py:366] Tune step 1600 / 3162 (50.0%). I0829 08:03:17.188146 140318776715072 train.py:366] Tune step 1700 / 3162 (50.0%). I0829 08:05:09.741266 140318776715072 train.py:366] Tune step 1800 / 3162 (60.0%). I0829 08:07:02.262498 140318776715072 train.py:366] Tune step 1900 / 3162 (60.0%). I0829 08:08:54.673932 140318776715072 train.py:366] Tune step 2000 / 3162 (60.0%). I0829 08:10:47.221370 140318776715072 train.py:366] Tune step 2100 / 3162 (70.0%). I0829 08:12:39.774174 140318776715072 train.py:366] Tune step 2200 / 3162 (70.0%). I0829 08:14:32.322385 140318776715072 train.py:366] Tune step 2300 / 3162 (70.0%). I0829 08:16:24.722720 140318776715072 train.py:366] Tune step 2400 / 3162 (80.0%). I0829 08:18:17.252759 140318776715072 train.py:366] Tune step 2500 / 3162 (80.0%). I0829 08:20:09.823046 140318776715072 train.py:366] Tune step 2600 / 3162 (80.0%). I0829 08:22:02.367495 140318776715072 train.py:366] Tune step 2700 / 3162 (90.0%). I0829 08:23:54.783612 140318776715072 train.py:366] Tune step 2800 / 3162 (90.0%). I0829 08:25:47.336242 140318776715072 train.py:366] Tune step 2900 / 3162 (90.0%). I0829 08:27:39.775715 140318776715072 train.py:366] Tune step 3000 / 3162 (90.0%). I0829 08:29:29.592094 140318776715072 train.py:366] Tune step 3100 / 3162 (100.0%). I0829 08:30:42.583051 140305134778112 logging_writer.py:48] [13993] tune/categorical_accuracy=0.9916982650756836, tune/categorical_crossentropy=0.560210645198822, tune/f1_het=0.0, tune/f1_homalt=0.0, tune/f1_homref=0.9958318471908569, tune/f1_macro=0.33194395899772644, tune/f1_micro=0.9916982650756836, tune/f1_weighted=0.9958318471908569, tune/false_negatives_1=1777.0, tune/false_positives_1=1544.0, tune/loss=0.5603554248809814, tune/precision_1=0.9923615455627441, tune/precision_het=0.0, tune/precision_homalt=0.0, tune/precision_homref=1.0, tune/recall_1=0.9912189841270447, tune/recall_het=0.0, tune/recall_homalt=0.0, tune/recall",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:11864,performance,Tune,Tune,11864,"] Tune step 1600 / 3162 (50.0%). I0829 08:03:17.188146 140318776715072 train.py:366] Tune step 1700 / 3162 (50.0%). I0829 08:05:09.741266 140318776715072 train.py:366] Tune step 1800 / 3162 (60.0%). I0829 08:07:02.262498 140318776715072 train.py:366] Tune step 1900 / 3162 (60.0%). I0829 08:08:54.673932 140318776715072 train.py:366] Tune step 2000 / 3162 (60.0%). I0829 08:10:47.221370 140318776715072 train.py:366] Tune step 2100 / 3162 (70.0%). I0829 08:12:39.774174 140318776715072 train.py:366] Tune step 2200 / 3162 (70.0%). I0829 08:14:32.322385 140318776715072 train.py:366] Tune step 2300 / 3162 (70.0%). I0829 08:16:24.722720 140318776715072 train.py:366] Tune step 2400 / 3162 (80.0%). I0829 08:18:17.252759 140318776715072 train.py:366] Tune step 2500 / 3162 (80.0%). I0829 08:20:09.823046 140318776715072 train.py:366] Tune step 2600 / 3162 (80.0%). I0829 08:22:02.367495 140318776715072 train.py:366] Tune step 2700 / 3162 (90.0%). I0829 08:23:54.783612 140318776715072 train.py:366] Tune step 2800 / 3162 (90.0%). I0829 08:25:47.336242 140318776715072 train.py:366] Tune step 2900 / 3162 (90.0%). I0829 08:27:39.775715 140318776715072 train.py:366] Tune step 3000 / 3162 (90.0%). I0829 08:29:29.592094 140318776715072 train.py:366] Tune step 3100 / 3162 (100.0%). I0829 08:30:42.583051 140305134778112 logging_writer.py:48] [13993] tune/categorical_accuracy=0.9916982650756836, tune/categorical_crossentropy=0.560210645198822, tune/f1_het=0.0, tune/f1_homalt=0.0, tune/f1_homref=0.9958318471908569, tune/f1_macro=0.33194395899772644, tune/f1_micro=0.9916982650756836, tune/f1_weighted=0.9958318471908569, tune/false_negatives_1=1777.0, tune/false_positives_1=1544.0, tune/loss=0.5603554248809814, tune/precision_1=0.9923615455627441, tune/precision_het=0.0, tune/precision_homalt=0.0, tune/precision_homref=1.0, tune/recall_1=0.9912189841270447, tune/recall_het=0.0, tune/recall_homalt=0.0, tune/recall_homref=0.9912189841270447, tune/true_negatives_1=403192.0, tune/true_positives_1=2",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:11947,performance,Tune,Tune,11947,"] Tune step 1700 / 3162 (50.0%). I0829 08:05:09.741266 140318776715072 train.py:366] Tune step 1800 / 3162 (60.0%). I0829 08:07:02.262498 140318776715072 train.py:366] Tune step 1900 / 3162 (60.0%). I0829 08:08:54.673932 140318776715072 train.py:366] Tune step 2000 / 3162 (60.0%). I0829 08:10:47.221370 140318776715072 train.py:366] Tune step 2100 / 3162 (70.0%). I0829 08:12:39.774174 140318776715072 train.py:366] Tune step 2200 / 3162 (70.0%). I0829 08:14:32.322385 140318776715072 train.py:366] Tune step 2300 / 3162 (70.0%). I0829 08:16:24.722720 140318776715072 train.py:366] Tune step 2400 / 3162 (80.0%). I0829 08:18:17.252759 140318776715072 train.py:366] Tune step 2500 / 3162 (80.0%). I0829 08:20:09.823046 140318776715072 train.py:366] Tune step 2600 / 3162 (80.0%). I0829 08:22:02.367495 140318776715072 train.py:366] Tune step 2700 / 3162 (90.0%). I0829 08:23:54.783612 140318776715072 train.py:366] Tune step 2800 / 3162 (90.0%). I0829 08:25:47.336242 140318776715072 train.py:366] Tune step 2900 / 3162 (90.0%). I0829 08:27:39.775715 140318776715072 train.py:366] Tune step 3000 / 3162 (90.0%). I0829 08:29:29.592094 140318776715072 train.py:366] Tune step 3100 / 3162 (100.0%). I0829 08:30:42.583051 140305134778112 logging_writer.py:48] [13993] tune/categorical_accuracy=0.9916982650756836, tune/categorical_crossentropy=0.560210645198822, tune/f1_het=0.0, tune/f1_homalt=0.0, tune/f1_homref=0.9958318471908569, tune/f1_macro=0.33194395899772644, tune/f1_micro=0.9916982650756836, tune/f1_weighted=0.9958318471908569, tune/false_negatives_1=1777.0, tune/false_positives_1=1544.0, tune/loss=0.5603554248809814, tune/precision_1=0.9923615455627441, tune/precision_het=0.0, tune/precision_homalt=0.0, tune/precision_homref=1.0, tune/recall_1=0.9912189841270447, tune/recall_het=0.0, tune/recall_homalt=0.0, tune/recall_homref=0.9912189841270447, tune/true_negatives_1=403192.0, tune/true_positives_1=200591.0. I0829 08:30:42.590469 140318776715072 train.py:471] Skipping checkpoint wi",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:12030,performance,Tune,Tune,12030,"] Tune step 1800 / 3162 (60.0%). I0829 08:07:02.262498 140318776715072 train.py:366] Tune step 1900 / 3162 (60.0%). I0829 08:08:54.673932 140318776715072 train.py:366] Tune step 2000 / 3162 (60.0%). I0829 08:10:47.221370 140318776715072 train.py:366] Tune step 2100 / 3162 (70.0%). I0829 08:12:39.774174 140318776715072 train.py:366] Tune step 2200 / 3162 (70.0%). I0829 08:14:32.322385 140318776715072 train.py:366] Tune step 2300 / 3162 (70.0%). I0829 08:16:24.722720 140318776715072 train.py:366] Tune step 2400 / 3162 (80.0%). I0829 08:18:17.252759 140318776715072 train.py:366] Tune step 2500 / 3162 (80.0%). I0829 08:20:09.823046 140318776715072 train.py:366] Tune step 2600 / 3162 (80.0%). I0829 08:22:02.367495 140318776715072 train.py:366] Tune step 2700 / 3162 (90.0%). I0829 08:23:54.783612 140318776715072 train.py:366] Tune step 2800 / 3162 (90.0%). I0829 08:25:47.336242 140318776715072 train.py:366] Tune step 2900 / 3162 (90.0%). I0829 08:27:39.775715 140318776715072 train.py:366] Tune step 3000 / 3162 (90.0%). I0829 08:29:29.592094 140318776715072 train.py:366] Tune step 3100 / 3162 (100.0%). I0829 08:30:42.583051 140305134778112 logging_writer.py:48] [13993] tune/categorical_accuracy=0.9916982650756836, tune/categorical_crossentropy=0.560210645198822, tune/f1_het=0.0, tune/f1_homalt=0.0, tune/f1_homref=0.9958318471908569, tune/f1_macro=0.33194395899772644, tune/f1_micro=0.9916982650756836, tune/f1_weighted=0.9958318471908569, tune/false_negatives_1=1777.0, tune/false_positives_1=1544.0, tune/loss=0.5603554248809814, tune/precision_1=0.9923615455627441, tune/precision_het=0.0, tune/precision_homalt=0.0, tune/precision_homref=1.0, tune/recall_1=0.9912189841270447, tune/recall_het=0.0, tune/recall_homalt=0.0, tune/recall_homref=0.9912189841270447, tune/true_negatives_1=403192.0, tune/true_positives_1=200591.0. I0829 08:30:42.590469 140318776715072 train.py:471] Skipping checkpoint with tune/f1_weighted=0.99583185 < previous best tune/f1_weighted=0.99845344. I0829 0",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:12113,performance,Tune,Tune,12113,"] Tune step 1900 / 3162 (60.0%). I0829 08:08:54.673932 140318776715072 train.py:366] Tune step 2000 / 3162 (60.0%). I0829 08:10:47.221370 140318776715072 train.py:366] Tune step 2100 / 3162 (70.0%). I0829 08:12:39.774174 140318776715072 train.py:366] Tune step 2200 / 3162 (70.0%). I0829 08:14:32.322385 140318776715072 train.py:366] Tune step 2300 / 3162 (70.0%). I0829 08:16:24.722720 140318776715072 train.py:366] Tune step 2400 / 3162 (80.0%). I0829 08:18:17.252759 140318776715072 train.py:366] Tune step 2500 / 3162 (80.0%). I0829 08:20:09.823046 140318776715072 train.py:366] Tune step 2600 / 3162 (80.0%). I0829 08:22:02.367495 140318776715072 train.py:366] Tune step 2700 / 3162 (90.0%). I0829 08:23:54.783612 140318776715072 train.py:366] Tune step 2800 / 3162 (90.0%). I0829 08:25:47.336242 140318776715072 train.py:366] Tune step 2900 / 3162 (90.0%). I0829 08:27:39.775715 140318776715072 train.py:366] Tune step 3000 / 3162 (90.0%). I0829 08:29:29.592094 140318776715072 train.py:366] Tune step 3100 / 3162 (100.0%). I0829 08:30:42.583051 140305134778112 logging_writer.py:48] [13993] tune/categorical_accuracy=0.9916982650756836, tune/categorical_crossentropy=0.560210645198822, tune/f1_het=0.0, tune/f1_homalt=0.0, tune/f1_homref=0.9958318471908569, tune/f1_macro=0.33194395899772644, tune/f1_micro=0.9916982650756836, tune/f1_weighted=0.9958318471908569, tune/false_negatives_1=1777.0, tune/false_positives_1=1544.0, tune/loss=0.5603554248809814, tune/precision_1=0.9923615455627441, tune/precision_het=0.0, tune/precision_homalt=0.0, tune/precision_homref=1.0, tune/recall_1=0.9912189841270447, tune/recall_het=0.0, tune/recall_homalt=0.0, tune/recall_homref=0.9912189841270447, tune/true_negatives_1=403192.0, tune/true_positives_1=200591.0. I0829 08:30:42.590469 140318776715072 train.py:471] Skipping checkpoint with tune/f1_weighted=0.99583185 < previous best tune/f1_weighted=0.99845344. I0829 08:30:42.595992 140305134778112 logging_writer.py:48] [13993] tune/early_stopping=7.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:12213,performance,tune,tune,12213,"/ 3162 (60.0%). I0829 08:10:47.221370 140318776715072 train.py:366] Tune step 2100 / 3162 (70.0%). I0829 08:12:39.774174 140318776715072 train.py:366] Tune step 2200 / 3162 (70.0%). I0829 08:14:32.322385 140318776715072 train.py:366] Tune step 2300 / 3162 (70.0%). I0829 08:16:24.722720 140318776715072 train.py:366] Tune step 2400 / 3162 (80.0%). I0829 08:18:17.252759 140318776715072 train.py:366] Tune step 2500 / 3162 (80.0%). I0829 08:20:09.823046 140318776715072 train.py:366] Tune step 2600 / 3162 (80.0%). I0829 08:22:02.367495 140318776715072 train.py:366] Tune step 2700 / 3162 (90.0%). I0829 08:23:54.783612 140318776715072 train.py:366] Tune step 2800 / 3162 (90.0%). I0829 08:25:47.336242 140318776715072 train.py:366] Tune step 2900 / 3162 (90.0%). I0829 08:27:39.775715 140318776715072 train.py:366] Tune step 3000 / 3162 (90.0%). I0829 08:29:29.592094 140318776715072 train.py:366] Tune step 3100 / 3162 (100.0%). I0829 08:30:42.583051 140305134778112 logging_writer.py:48] [13993] tune/categorical_accuracy=0.9916982650756836, tune/categorical_crossentropy=0.560210645198822, tune/f1_het=0.0, tune/f1_homalt=0.0, tune/f1_homref=0.9958318471908569, tune/f1_macro=0.33194395899772644, tune/f1_micro=0.9916982650756836, tune/f1_weighted=0.9958318471908569, tune/false_negatives_1=1777.0, tune/false_positives_1=1544.0, tune/loss=0.5603554248809814, tune/precision_1=0.9923615455627441, tune/precision_het=0.0, tune/precision_homalt=0.0, tune/precision_homref=1.0, tune/recall_1=0.9912189841270447, tune/recall_het=0.0, tune/recall_homalt=0.0, tune/recall_homref=0.9912189841270447, tune/true_negatives_1=403192.0, tune/true_positives_1=200591.0. I0829 08:30:42.590469 140318776715072 train.py:471] Skipping checkpoint with tune/f1_weighted=0.99583185 < previous best tune/f1_weighted=0.99845344. I0829 08:30:42.595992 140305134778112 logging_writer.py:48] [13993] tune/early_stopping=7. I0829 08:30:46.123329 140318776715072 local.py:41] Setting work unit notes: 0.0 steps/s, 61.6% (139",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:12259,performance,tune,tune,12259,"6715072 train.py:366] Tune step 2100 / 3162 (70.0%). I0829 08:12:39.774174 140318776715072 train.py:366] Tune step 2200 / 3162 (70.0%). I0829 08:14:32.322385 140318776715072 train.py:366] Tune step 2300 / 3162 (70.0%). I0829 08:16:24.722720 140318776715072 train.py:366] Tune step 2400 / 3162 (80.0%). I0829 08:18:17.252759 140318776715072 train.py:366] Tune step 2500 / 3162 (80.0%). I0829 08:20:09.823046 140318776715072 train.py:366] Tune step 2600 / 3162 (80.0%). I0829 08:22:02.367495 140318776715072 train.py:366] Tune step 2700 / 3162 (90.0%). I0829 08:23:54.783612 140318776715072 train.py:366] Tune step 2800 / 3162 (90.0%). I0829 08:25:47.336242 140318776715072 train.py:366] Tune step 2900 / 3162 (90.0%). I0829 08:27:39.775715 140318776715072 train.py:366] Tune step 3000 / 3162 (90.0%). I0829 08:29:29.592094 140318776715072 train.py:366] Tune step 3100 / 3162 (100.0%). I0829 08:30:42.583051 140305134778112 logging_writer.py:48] [13993] tune/categorical_accuracy=0.9916982650756836, tune/categorical_crossentropy=0.560210645198822, tune/f1_het=0.0, tune/f1_homalt=0.0, tune/f1_homref=0.9958318471908569, tune/f1_macro=0.33194395899772644, tune/f1_micro=0.9916982650756836, tune/f1_weighted=0.9958318471908569, tune/false_negatives_1=1777.0, tune/false_positives_1=1544.0, tune/loss=0.5603554248809814, tune/precision_1=0.9923615455627441, tune/precision_het=0.0, tune/precision_homalt=0.0, tune/precision_homref=1.0, tune/recall_1=0.9912189841270447, tune/recall_het=0.0, tune/recall_homalt=0.0, tune/recall_homref=0.9912189841270447, tune/true_negatives_1=403192.0, tune/true_positives_1=200591.0. I0829 08:30:42.590469 140318776715072 train.py:471] Skipping checkpoint with tune/f1_weighted=0.99583185 < previous best tune/f1_weighted=0.99845344. I0829 08:30:42.595992 140305134778112 logging_writer.py:48] [13993] tune/early_stopping=7. I0829 08:30:46.123329 140318776715072 local.py:41] Setting work unit notes: 0.0 steps/s, 61.6% (13994/22724), ETA: 8d4h11m. I0829 08:30:46.125013",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:12308,performance,tune,tune,12308,"%). I0829 08:12:39.774174 140318776715072 train.py:366] Tune step 2200 / 3162 (70.0%). I0829 08:14:32.322385 140318776715072 train.py:366] Tune step 2300 / 3162 (70.0%). I0829 08:16:24.722720 140318776715072 train.py:366] Tune step 2400 / 3162 (80.0%). I0829 08:18:17.252759 140318776715072 train.py:366] Tune step 2500 / 3162 (80.0%). I0829 08:20:09.823046 140318776715072 train.py:366] Tune step 2600 / 3162 (80.0%). I0829 08:22:02.367495 140318776715072 train.py:366] Tune step 2700 / 3162 (90.0%). I0829 08:23:54.783612 140318776715072 train.py:366] Tune step 2800 / 3162 (90.0%). I0829 08:25:47.336242 140318776715072 train.py:366] Tune step 2900 / 3162 (90.0%). I0829 08:27:39.775715 140318776715072 train.py:366] Tune step 3000 / 3162 (90.0%). I0829 08:29:29.592094 140318776715072 train.py:366] Tune step 3100 / 3162 (100.0%). I0829 08:30:42.583051 140305134778112 logging_writer.py:48] [13993] tune/categorical_accuracy=0.9916982650756836, tune/categorical_crossentropy=0.560210645198822, tune/f1_het=0.0, tune/f1_homalt=0.0, tune/f1_homref=0.9958318471908569, tune/f1_macro=0.33194395899772644, tune/f1_micro=0.9916982650756836, tune/f1_weighted=0.9958318471908569, tune/false_negatives_1=1777.0, tune/false_positives_1=1544.0, tune/loss=0.5603554248809814, tune/precision_1=0.9923615455627441, tune/precision_het=0.0, tune/precision_homalt=0.0, tune/precision_homref=1.0, tune/recall_1=0.9912189841270447, tune/recall_het=0.0, tune/recall_homalt=0.0, tune/recall_homref=0.9912189841270447, tune/true_negatives_1=403192.0, tune/true_positives_1=200591.0. I0829 08:30:42.590469 140318776715072 train.py:471] Skipping checkpoint with tune/f1_weighted=0.99583185 < previous best tune/f1_weighted=0.99845344. I0829 08:30:42.595992 140305134778112 logging_writer.py:48] [13993] tune/early_stopping=7. I0829 08:30:46.123329 140318776715072 local.py:41] Setting work unit notes: 0.0 steps/s, 61.6% (13994/22724), ETA: 8d4h11m. I0829 08:30:46.125013 140305134778112 logging_writer.py:48] [13994] st",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:12325,performance,tune,tune,12325,"9.774174 140318776715072 train.py:366] Tune step 2200 / 3162 (70.0%). I0829 08:14:32.322385 140318776715072 train.py:366] Tune step 2300 / 3162 (70.0%). I0829 08:16:24.722720 140318776715072 train.py:366] Tune step 2400 / 3162 (80.0%). I0829 08:18:17.252759 140318776715072 train.py:366] Tune step 2500 / 3162 (80.0%). I0829 08:20:09.823046 140318776715072 train.py:366] Tune step 2600 / 3162 (80.0%). I0829 08:22:02.367495 140318776715072 train.py:366] Tune step 2700 / 3162 (90.0%). I0829 08:23:54.783612 140318776715072 train.py:366] Tune step 2800 / 3162 (90.0%). I0829 08:25:47.336242 140318776715072 train.py:366] Tune step 2900 / 3162 (90.0%). I0829 08:27:39.775715 140318776715072 train.py:366] Tune step 3000 / 3162 (90.0%). I0829 08:29:29.592094 140318776715072 train.py:366] Tune step 3100 / 3162 (100.0%). I0829 08:30:42.583051 140305134778112 logging_writer.py:48] [13993] tune/categorical_accuracy=0.9916982650756836, tune/categorical_crossentropy=0.560210645198822, tune/f1_het=0.0, tune/f1_homalt=0.0, tune/f1_homref=0.9958318471908569, tune/f1_macro=0.33194395899772644, tune/f1_micro=0.9916982650756836, tune/f1_weighted=0.9958318471908569, tune/false_negatives_1=1777.0, tune/false_positives_1=1544.0, tune/loss=0.5603554248809814, tune/precision_1=0.9923615455627441, tune/precision_het=0.0, tune/precision_homalt=0.0, tune/precision_homref=1.0, tune/recall_1=0.9912189841270447, tune/recall_het=0.0, tune/recall_homalt=0.0, tune/recall_homref=0.9912189841270447, tune/true_negatives_1=403192.0, tune/true_positives_1=200591.0. I0829 08:30:42.590469 140318776715072 train.py:471] Skipping checkpoint with tune/f1_weighted=0.99583185 < previous best tune/f1_weighted=0.99845344. I0829 08:30:42.595992 140305134778112 logging_writer.py:48] [13993] tune/early_stopping=7. I0829 08:30:46.123329 140318776715072 local.py:41] Setting work unit notes: 0.0 steps/s, 61.6% (13994/22724), ETA: 8d4h11m. I0829 08:30:46.125013 140305134778112 logging_writer.py:48] [13994] steps_per_sec=0.012",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:12345,performance,tune,tune,12345,"5072 train.py:366] Tune step 2200 / 3162 (70.0%). I0829 08:14:32.322385 140318776715072 train.py:366] Tune step 2300 / 3162 (70.0%). I0829 08:16:24.722720 140318776715072 train.py:366] Tune step 2400 / 3162 (80.0%). I0829 08:18:17.252759 140318776715072 train.py:366] Tune step 2500 / 3162 (80.0%). I0829 08:20:09.823046 140318776715072 train.py:366] Tune step 2600 / 3162 (80.0%). I0829 08:22:02.367495 140318776715072 train.py:366] Tune step 2700 / 3162 (90.0%). I0829 08:23:54.783612 140318776715072 train.py:366] Tune step 2800 / 3162 (90.0%). I0829 08:25:47.336242 140318776715072 train.py:366] Tune step 2900 / 3162 (90.0%). I0829 08:27:39.775715 140318776715072 train.py:366] Tune step 3000 / 3162 (90.0%). I0829 08:29:29.592094 140318776715072 train.py:366] Tune step 3100 / 3162 (100.0%). I0829 08:30:42.583051 140305134778112 logging_writer.py:48] [13993] tune/categorical_accuracy=0.9916982650756836, tune/categorical_crossentropy=0.560210645198822, tune/f1_het=0.0, tune/f1_homalt=0.0, tune/f1_homref=0.9958318471908569, tune/f1_macro=0.33194395899772644, tune/f1_micro=0.9916982650756836, tune/f1_weighted=0.9958318471908569, tune/false_negatives_1=1777.0, tune/false_positives_1=1544.0, tune/loss=0.5603554248809814, tune/precision_1=0.9923615455627441, tune/precision_het=0.0, tune/precision_homalt=0.0, tune/precision_homref=1.0, tune/recall_1=0.9912189841270447, tune/recall_het=0.0, tune/recall_homalt=0.0, tune/recall_homref=0.9912189841270447, tune/true_negatives_1=403192.0, tune/true_positives_1=200591.0. I0829 08:30:42.590469 140318776715072 train.py:471] Skipping checkpoint with tune/f1_weighted=0.99583185 < previous best tune/f1_weighted=0.99845344. I0829 08:30:42.595992 140305134778112 logging_writer.py:48] [13993] tune/early_stopping=7. I0829 08:30:46.123329 140318776715072 local.py:41] Setting work unit notes: 0.0 steps/s, 61.6% (13994/22724), ETA: 8d4h11m. I0829 08:30:46.125013 140305134778112 logging_writer.py:48] [13994] steps_per_sec=0.0123604. I0829 08:30:46",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:12380,performance,tune,tune,12380," 3162 (70.0%). I0829 08:14:32.322385 140318776715072 train.py:366] Tune step 2300 / 3162 (70.0%). I0829 08:16:24.722720 140318776715072 train.py:366] Tune step 2400 / 3162 (80.0%). I0829 08:18:17.252759 140318776715072 train.py:366] Tune step 2500 / 3162 (80.0%). I0829 08:20:09.823046 140318776715072 train.py:366] Tune step 2600 / 3162 (80.0%). I0829 08:22:02.367495 140318776715072 train.py:366] Tune step 2700 / 3162 (90.0%). I0829 08:23:54.783612 140318776715072 train.py:366] Tune step 2800 / 3162 (90.0%). I0829 08:25:47.336242 140318776715072 train.py:366] Tune step 2900 / 3162 (90.0%). I0829 08:27:39.775715 140318776715072 train.py:366] Tune step 3000 / 3162 (90.0%). I0829 08:29:29.592094 140318776715072 train.py:366] Tune step 3100 / 3162 (100.0%). I0829 08:30:42.583051 140305134778112 logging_writer.py:48] [13993] tune/categorical_accuracy=0.9916982650756836, tune/categorical_crossentropy=0.560210645198822, tune/f1_het=0.0, tune/f1_homalt=0.0, tune/f1_homref=0.9958318471908569, tune/f1_macro=0.33194395899772644, tune/f1_micro=0.9916982650756836, tune/f1_weighted=0.9958318471908569, tune/false_negatives_1=1777.0, tune/false_positives_1=1544.0, tune/loss=0.5603554248809814, tune/precision_1=0.9923615455627441, tune/precision_het=0.0, tune/precision_homalt=0.0, tune/precision_homref=1.0, tune/recall_1=0.9912189841270447, tune/recall_het=0.0, tune/recall_homalt=0.0, tune/recall_homref=0.9912189841270447, tune/true_negatives_1=403192.0, tune/true_positives_1=200591.0. I0829 08:30:42.590469 140318776715072 train.py:471] Skipping checkpoint with tune/f1_weighted=0.99583185 < previous best tune/f1_weighted=0.99845344. I0829 08:30:42.595992 140305134778112 logging_writer.py:48] [13993] tune/early_stopping=7. I0829 08:30:46.123329 140318776715072 local.py:41] Setting work unit notes: 0.0 steps/s, 61.6% (13994/22724), ETA: 8d4h11m. I0829 08:30:46.125013 140305134778112 logging_writer.py:48] [13994] steps_per_sec=0.0123604. I0829 08:30:46.125087 140305134778112 logging_wri",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:12415,performance,tune,tune,12415,"5 140318776715072 train.py:366] Tune step 2300 / 3162 (70.0%). I0829 08:16:24.722720 140318776715072 train.py:366] Tune step 2400 / 3162 (80.0%). I0829 08:18:17.252759 140318776715072 train.py:366] Tune step 2500 / 3162 (80.0%). I0829 08:20:09.823046 140318776715072 train.py:366] Tune step 2600 / 3162 (80.0%). I0829 08:22:02.367495 140318776715072 train.py:366] Tune step 2700 / 3162 (90.0%). I0829 08:23:54.783612 140318776715072 train.py:366] Tune step 2800 / 3162 (90.0%). I0829 08:25:47.336242 140318776715072 train.py:366] Tune step 2900 / 3162 (90.0%). I0829 08:27:39.775715 140318776715072 train.py:366] Tune step 3000 / 3162 (90.0%). I0829 08:29:29.592094 140318776715072 train.py:366] Tune step 3100 / 3162 (100.0%). I0829 08:30:42.583051 140305134778112 logging_writer.py:48] [13993] tune/categorical_accuracy=0.9916982650756836, tune/categorical_crossentropy=0.560210645198822, tune/f1_het=0.0, tune/f1_homalt=0.0, tune/f1_homref=0.9958318471908569, tune/f1_macro=0.33194395899772644, tune/f1_micro=0.9916982650756836, tune/f1_weighted=0.9958318471908569, tune/false_negatives_1=1777.0, tune/false_positives_1=1544.0, tune/loss=0.5603554248809814, tune/precision_1=0.9923615455627441, tune/precision_het=0.0, tune/precision_homalt=0.0, tune/precision_homref=1.0, tune/recall_1=0.9912189841270447, tune/recall_het=0.0, tune/recall_homalt=0.0, tune/recall_homref=0.9912189841270447, tune/true_negatives_1=403192.0, tune/true_positives_1=200591.0. I0829 08:30:42.590469 140318776715072 train.py:471] Skipping checkpoint with tune/f1_weighted=0.99583185 < previous best tune/f1_weighted=0.99845344. I0829 08:30:42.595992 140305134778112 logging_writer.py:48] [13993] tune/early_stopping=7. I0829 08:30:46.123329 140318776715072 local.py:41] Setting work unit notes: 0.0 steps/s, 61.6% (13994/22724), ETA: 8d4h11m. I0829 08:30:46.125013 140305134778112 logging_writer.py:48] [13994] steps_per_sec=0.0123604. I0829 08:30:46.125087 140305134778112 logging_writer.py:48] [13994] uptime=78596.1. ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:12449,performance,tune,tune,12449,"ne step 2300 / 3162 (70.0%). I0829 08:16:24.722720 140318776715072 train.py:366] Tune step 2400 / 3162 (80.0%). I0829 08:18:17.252759 140318776715072 train.py:366] Tune step 2500 / 3162 (80.0%). I0829 08:20:09.823046 140318776715072 train.py:366] Tune step 2600 / 3162 (80.0%). I0829 08:22:02.367495 140318776715072 train.py:366] Tune step 2700 / 3162 (90.0%). I0829 08:23:54.783612 140318776715072 train.py:366] Tune step 2800 / 3162 (90.0%). I0829 08:25:47.336242 140318776715072 train.py:366] Tune step 2900 / 3162 (90.0%). I0829 08:27:39.775715 140318776715072 train.py:366] Tune step 3000 / 3162 (90.0%). I0829 08:29:29.592094 140318776715072 train.py:366] Tune step 3100 / 3162 (100.0%). I0829 08:30:42.583051 140305134778112 logging_writer.py:48] [13993] tune/categorical_accuracy=0.9916982650756836, tune/categorical_crossentropy=0.560210645198822, tune/f1_het=0.0, tune/f1_homalt=0.0, tune/f1_homref=0.9958318471908569, tune/f1_macro=0.33194395899772644, tune/f1_micro=0.9916982650756836, tune/f1_weighted=0.9958318471908569, tune/false_negatives_1=1777.0, tune/false_positives_1=1544.0, tune/loss=0.5603554248809814, tune/precision_1=0.9923615455627441, tune/precision_het=0.0, tune/precision_homalt=0.0, tune/precision_homref=1.0, tune/recall_1=0.9912189841270447, tune/recall_het=0.0, tune/recall_homalt=0.0, tune/recall_homref=0.9912189841270447, tune/true_negatives_1=403192.0, tune/true_positives_1=200591.0. I0829 08:30:42.590469 140318776715072 train.py:471] Skipping checkpoint with tune/f1_weighted=0.99583185 < previous best tune/f1_weighted=0.99845344. I0829 08:30:42.595992 140305134778112 logging_writer.py:48] [13993] tune/early_stopping=7. I0829 08:30:46.123329 140318776715072 local.py:41] Setting work unit notes: 0.0 steps/s, 61.6% (13994/22724), ETA: 8d4h11m. I0829 08:30:46.125013 140305134778112 logging_writer.py:48] [13994] steps_per_sec=0.0123604. I0829 08:30:46.125087 140305134778112 logging_writer.py:48] [13994] uptime=78596.1. I0829 08:31:07.673585 140305134778",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:12486,performance,tune,tune,12486,":16:24.722720 140318776715072 train.py:366] Tune step 2400 / 3162 (80.0%). I0829 08:18:17.252759 140318776715072 train.py:366] Tune step 2500 / 3162 (80.0%). I0829 08:20:09.823046 140318776715072 train.py:366] Tune step 2600 / 3162 (80.0%). I0829 08:22:02.367495 140318776715072 train.py:366] Tune step 2700 / 3162 (90.0%). I0829 08:23:54.783612 140318776715072 train.py:366] Tune step 2800 / 3162 (90.0%). I0829 08:25:47.336242 140318776715072 train.py:366] Tune step 2900 / 3162 (90.0%). I0829 08:27:39.775715 140318776715072 train.py:366] Tune step 3000 / 3162 (90.0%). I0829 08:29:29.592094 140318776715072 train.py:366] Tune step 3100 / 3162 (100.0%). I0829 08:30:42.583051 140305134778112 logging_writer.py:48] [13993] tune/categorical_accuracy=0.9916982650756836, tune/categorical_crossentropy=0.560210645198822, tune/f1_het=0.0, tune/f1_homalt=0.0, tune/f1_homref=0.9958318471908569, tune/f1_macro=0.33194395899772644, tune/f1_micro=0.9916982650756836, tune/f1_weighted=0.9958318471908569, tune/false_negatives_1=1777.0, tune/false_positives_1=1544.0, tune/loss=0.5603554248809814, tune/precision_1=0.9923615455627441, tune/precision_het=0.0, tune/precision_homalt=0.0, tune/precision_homref=1.0, tune/recall_1=0.9912189841270447, tune/recall_het=0.0, tune/recall_homalt=0.0, tune/recall_homref=0.9912189841270447, tune/true_negatives_1=403192.0, tune/true_positives_1=200591.0. I0829 08:30:42.590469 140318776715072 train.py:471] Skipping checkpoint with tune/f1_weighted=0.99583185 < previous best tune/f1_weighted=0.99845344. I0829 08:30:42.595992 140305134778112 logging_writer.py:48] [13993] tune/early_stopping=7. I0829 08:30:46.123329 140318776715072 local.py:41] Setting work unit notes: 0.0 steps/s, 61.6% (13994/22724), ETA: 8d4h11m. I0829 08:30:46.125013 140305134778112 logging_writer.py:48] [13994] steps_per_sec=0.0123604. I0829 08:30:46.125087 140305134778112 logging_writer.py:48] [13994] uptime=78596.1. I0829 08:31:07.673585 140305134778112 logging_writer.py:48] [14000] epo",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:12517,performance,tune,tune,12517,"rain.py:366] Tune step 2400 / 3162 (80.0%). I0829 08:18:17.252759 140318776715072 train.py:366] Tune step 2500 / 3162 (80.0%). I0829 08:20:09.823046 140318776715072 train.py:366] Tune step 2600 / 3162 (80.0%). I0829 08:22:02.367495 140318776715072 train.py:366] Tune step 2700 / 3162 (90.0%). I0829 08:23:54.783612 140318776715072 train.py:366] Tune step 2800 / 3162 (90.0%). I0829 08:25:47.336242 140318776715072 train.py:366] Tune step 2900 / 3162 (90.0%). I0829 08:27:39.775715 140318776715072 train.py:366] Tune step 3000 / 3162 (90.0%). I0829 08:29:29.592094 140318776715072 train.py:366] Tune step 3100 / 3162 (100.0%). I0829 08:30:42.583051 140305134778112 logging_writer.py:48] [13993] tune/categorical_accuracy=0.9916982650756836, tune/categorical_crossentropy=0.560210645198822, tune/f1_het=0.0, tune/f1_homalt=0.0, tune/f1_homref=0.9958318471908569, tune/f1_macro=0.33194395899772644, tune/f1_micro=0.9916982650756836, tune/f1_weighted=0.9958318471908569, tune/false_negatives_1=1777.0, tune/false_positives_1=1544.0, tune/loss=0.5603554248809814, tune/precision_1=0.9923615455627441, tune/precision_het=0.0, tune/precision_homalt=0.0, tune/precision_homref=1.0, tune/recall_1=0.9912189841270447, tune/recall_het=0.0, tune/recall_homalt=0.0, tune/recall_homref=0.9912189841270447, tune/true_negatives_1=403192.0, tune/true_positives_1=200591.0. I0829 08:30:42.590469 140318776715072 train.py:471] Skipping checkpoint with tune/f1_weighted=0.99583185 < previous best tune/f1_weighted=0.99845344. I0829 08:30:42.595992 140305134778112 logging_writer.py:48] [13993] tune/early_stopping=7. I0829 08:30:46.123329 140318776715072 local.py:41] Setting work unit notes: 0.0 steps/s, 61.6% (13994/22724), ETA: 8d4h11m. I0829 08:30:46.125013 140305134778112 logging_writer.py:48] [13994] steps_per_sec=0.0123604. I0829 08:30:46.125087 140305134778112 logging_writer.py:48] [13994] uptime=78596.1. I0829 08:31:07.673585 140305134778112 logging_writer.py:48] [14000] epoch=0, train/categorical_accurac",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:12548,performance,tune,tune,12548,"162 (80.0%). I0829 08:18:17.252759 140318776715072 train.py:366] Tune step 2500 / 3162 (80.0%). I0829 08:20:09.823046 140318776715072 train.py:366] Tune step 2600 / 3162 (80.0%). I0829 08:22:02.367495 140318776715072 train.py:366] Tune step 2700 / 3162 (90.0%). I0829 08:23:54.783612 140318776715072 train.py:366] Tune step 2800 / 3162 (90.0%). I0829 08:25:47.336242 140318776715072 train.py:366] Tune step 2900 / 3162 (90.0%). I0829 08:27:39.775715 140318776715072 train.py:366] Tune step 3000 / 3162 (90.0%). I0829 08:29:29.592094 140318776715072 train.py:366] Tune step 3100 / 3162 (100.0%). I0829 08:30:42.583051 140305134778112 logging_writer.py:48] [13993] tune/categorical_accuracy=0.9916982650756836, tune/categorical_crossentropy=0.560210645198822, tune/f1_het=0.0, tune/f1_homalt=0.0, tune/f1_homref=0.9958318471908569, tune/f1_macro=0.33194395899772644, tune/f1_micro=0.9916982650756836, tune/f1_weighted=0.9958318471908569, tune/false_negatives_1=1777.0, tune/false_positives_1=1544.0, tune/loss=0.5603554248809814, tune/precision_1=0.9923615455627441, tune/precision_het=0.0, tune/precision_homalt=0.0, tune/precision_homref=1.0, tune/recall_1=0.9912189841270447, tune/recall_het=0.0, tune/recall_homalt=0.0, tune/recall_homref=0.9912189841270447, tune/true_negatives_1=403192.0, tune/true_positives_1=200591.0. I0829 08:30:42.590469 140318776715072 train.py:471] Skipping checkpoint with tune/f1_weighted=0.99583185 < previous best tune/f1_weighted=0.99845344. I0829 08:30:42.595992 140305134778112 logging_writer.py:48] [13993] tune/early_stopping=7. I0829 08:30:46.123329 140318776715072 local.py:41] Setting work unit notes: 0.0 steps/s, 61.6% (13994/22724), ETA: 8d4h11m. I0829 08:30:46.125013 140305134778112 logging_writer.py:48] [13994] steps_per_sec=0.0123604. I0829 08:30:46.125087 140305134778112 logging_writer.py:48] [13994] uptime=78596.1. I0829 08:31:07.673585 140305134778112 logging_writer.py:48] [14000] epoch=0, train/categorical_accuracy=1.0, train/categorical_crosse",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:12578,performance,tune,tune,12578,"2759 140318776715072 train.py:366] Tune step 2500 / 3162 (80.0%). I0829 08:20:09.823046 140318776715072 train.py:366] Tune step 2600 / 3162 (80.0%). I0829 08:22:02.367495 140318776715072 train.py:366] Tune step 2700 / 3162 (90.0%). I0829 08:23:54.783612 140318776715072 train.py:366] Tune step 2800 / 3162 (90.0%). I0829 08:25:47.336242 140318776715072 train.py:366] Tune step 2900 / 3162 (90.0%). I0829 08:27:39.775715 140318776715072 train.py:366] Tune step 3000 / 3162 (90.0%). I0829 08:29:29.592094 140318776715072 train.py:366] Tune step 3100 / 3162 (100.0%). I0829 08:30:42.583051 140305134778112 logging_writer.py:48] [13993] tune/categorical_accuracy=0.9916982650756836, tune/categorical_crossentropy=0.560210645198822, tune/f1_het=0.0, tune/f1_homalt=0.0, tune/f1_homref=0.9958318471908569, tune/f1_macro=0.33194395899772644, tune/f1_micro=0.9916982650756836, tune/f1_weighted=0.9958318471908569, tune/false_negatives_1=1777.0, tune/false_positives_1=1544.0, tune/loss=0.5603554248809814, tune/precision_1=0.9923615455627441, tune/precision_het=0.0, tune/precision_homalt=0.0, tune/precision_homref=1.0, tune/recall_1=0.9912189841270447, tune/recall_het=0.0, tune/recall_homalt=0.0, tune/recall_homref=0.9912189841270447, tune/true_negatives_1=403192.0, tune/true_positives_1=200591.0. I0829 08:30:42.590469 140318776715072 train.py:471] Skipping checkpoint with tune/f1_weighted=0.99583185 < previous best tune/f1_weighted=0.99845344. I0829 08:30:42.595992 140305134778112 logging_writer.py:48] [13993] tune/early_stopping=7. I0829 08:30:46.123329 140318776715072 local.py:41] Setting work unit notes: 0.0 steps/s, 61.6% (13994/22724), ETA: 8d4h11m. I0829 08:30:46.125013 140305134778112 logging_writer.py:48] [13994] steps_per_sec=0.0123604. I0829 08:30:46.125087 140305134778112 logging_writer.py:48] [13994] uptime=78596.1. I0829 08:31:07.673585 140305134778112 logging_writer.py:48] [14000] epoch=0, train/categorical_accuracy=1.0, train/categorical_crossentropy=0.5519920587539673, tra",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:12615,performance,tune,tune,12615,"ne step 2500 / 3162 (80.0%). I0829 08:20:09.823046 140318776715072 train.py:366] Tune step 2600 / 3162 (80.0%). I0829 08:22:02.367495 140318776715072 train.py:366] Tune step 2700 / 3162 (90.0%). I0829 08:23:54.783612 140318776715072 train.py:366] Tune step 2800 / 3162 (90.0%). I0829 08:25:47.336242 140318776715072 train.py:366] Tune step 2900 / 3162 (90.0%). I0829 08:27:39.775715 140318776715072 train.py:366] Tune step 3000 / 3162 (90.0%). I0829 08:29:29.592094 140318776715072 train.py:366] Tune step 3100 / 3162 (100.0%). I0829 08:30:42.583051 140305134778112 logging_writer.py:48] [13993] tune/categorical_accuracy=0.9916982650756836, tune/categorical_crossentropy=0.560210645198822, tune/f1_het=0.0, tune/f1_homalt=0.0, tune/f1_homref=0.9958318471908569, tune/f1_macro=0.33194395899772644, tune/f1_micro=0.9916982650756836, tune/f1_weighted=0.9958318471908569, tune/false_negatives_1=1777.0, tune/false_positives_1=1544.0, tune/loss=0.5603554248809814, tune/precision_1=0.9923615455627441, tune/precision_het=0.0, tune/precision_homalt=0.0, tune/precision_homref=1.0, tune/recall_1=0.9912189841270447, tune/recall_het=0.0, tune/recall_homalt=0.0, tune/recall_homref=0.9912189841270447, tune/true_negatives_1=403192.0, tune/true_positives_1=200591.0. I0829 08:30:42.590469 140318776715072 train.py:471] Skipping checkpoint with tune/f1_weighted=0.99583185 < previous best tune/f1_weighted=0.99845344. I0829 08:30:42.595992 140305134778112 logging_writer.py:48] [13993] tune/early_stopping=7. I0829 08:30:46.123329 140318776715072 local.py:41] Setting work unit notes: 0.0 steps/s, 61.6% (13994/22724), ETA: 8d4h11m. I0829 08:30:46.125013 140305134778112 logging_writer.py:48] [13994] steps_per_sec=0.0123604. I0829 08:30:46.125087 140305134778112 logging_writer.py:48] [13994] uptime=78596.1. I0829 08:31:07.673585 140305134778112 logging_writer.py:48] [14000] epoch=0, train/categorical_accuracy=1.0, train/categorical_crossentropy=0.5519920587539673, train/f1_het=0.0, train/f1_homalt=0.0, t",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:12639,performance,tune,tune,12639,"0%). I0829 08:20:09.823046 140318776715072 train.py:366] Tune step 2600 / 3162 (80.0%). I0829 08:22:02.367495 140318776715072 train.py:366] Tune step 2700 / 3162 (90.0%). I0829 08:23:54.783612 140318776715072 train.py:366] Tune step 2800 / 3162 (90.0%). I0829 08:25:47.336242 140318776715072 train.py:366] Tune step 2900 / 3162 (90.0%). I0829 08:27:39.775715 140318776715072 train.py:366] Tune step 3000 / 3162 (90.0%). I0829 08:29:29.592094 140318776715072 train.py:366] Tune step 3100 / 3162 (100.0%). I0829 08:30:42.583051 140305134778112 logging_writer.py:48] [13993] tune/categorical_accuracy=0.9916982650756836, tune/categorical_crossentropy=0.560210645198822, tune/f1_het=0.0, tune/f1_homalt=0.0, tune/f1_homref=0.9958318471908569, tune/f1_macro=0.33194395899772644, tune/f1_micro=0.9916982650756836, tune/f1_weighted=0.9958318471908569, tune/false_negatives_1=1777.0, tune/false_positives_1=1544.0, tune/loss=0.5603554248809814, tune/precision_1=0.9923615455627441, tune/precision_het=0.0, tune/precision_homalt=0.0, tune/precision_homref=1.0, tune/recall_1=0.9912189841270447, tune/recall_het=0.0, tune/recall_homalt=0.0, tune/recall_homref=0.9912189841270447, tune/true_negatives_1=403192.0, tune/true_positives_1=200591.0. I0829 08:30:42.590469 140318776715072 train.py:471] Skipping checkpoint with tune/f1_weighted=0.99583185 < previous best tune/f1_weighted=0.99845344. I0829 08:30:42.595992 140305134778112 logging_writer.py:48] [13993] tune/early_stopping=7. I0829 08:30:46.123329 140318776715072 local.py:41] Setting work unit notes: 0.0 steps/s, 61.6% (13994/22724), ETA: 8d4h11m. I0829 08:30:46.125013 140305134778112 logging_writer.py:48] [13994] steps_per_sec=0.0123604. I0829 08:30:46.125087 140305134778112 logging_writer.py:48] [13994] uptime=78596.1. I0829 08:31:07.673585 140305134778112 logging_writer.py:48] [14000] epoch=0, train/categorical_accuracy=1.0, train/categorical_crossentropy=0.5519920587539673, train/f1_het=0.0, train/f1_homalt=0.0, train/f1_homref=1.0, trai",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:12666,performance,tune,tune,12666,"140318776715072 train.py:366] Tune step 2600 / 3162 (80.0%). I0829 08:22:02.367495 140318776715072 train.py:366] Tune step 2700 / 3162 (90.0%). I0829 08:23:54.783612 140318776715072 train.py:366] Tune step 2800 / 3162 (90.0%). I0829 08:25:47.336242 140318776715072 train.py:366] Tune step 2900 / 3162 (90.0%). I0829 08:27:39.775715 140318776715072 train.py:366] Tune step 3000 / 3162 (90.0%). I0829 08:29:29.592094 140318776715072 train.py:366] Tune step 3100 / 3162 (100.0%). I0829 08:30:42.583051 140305134778112 logging_writer.py:48] [13993] tune/categorical_accuracy=0.9916982650756836, tune/categorical_crossentropy=0.560210645198822, tune/f1_het=0.0, tune/f1_homalt=0.0, tune/f1_homref=0.9958318471908569, tune/f1_macro=0.33194395899772644, tune/f1_micro=0.9916982650756836, tune/f1_weighted=0.9958318471908569, tune/false_negatives_1=1777.0, tune/false_positives_1=1544.0, tune/loss=0.5603554248809814, tune/precision_1=0.9923615455627441, tune/precision_het=0.0, tune/precision_homalt=0.0, tune/precision_homref=1.0, tune/recall_1=0.9912189841270447, tune/recall_het=0.0, tune/recall_homalt=0.0, tune/recall_homref=0.9912189841270447, tune/true_negatives_1=403192.0, tune/true_positives_1=200591.0. I0829 08:30:42.590469 140318776715072 train.py:471] Skipping checkpoint with tune/f1_weighted=0.99583185 < previous best tune/f1_weighted=0.99845344. I0829 08:30:42.595992 140305134778112 logging_writer.py:48] [13993] tune/early_stopping=7. I0829 08:30:46.123329 140318776715072 local.py:41] Setting work unit notes: 0.0 steps/s, 61.6% (13994/22724), ETA: 8d4h11m. I0829 08:30:46.125013 140305134778112 logging_writer.py:48] [13994] steps_per_sec=0.0123604. I0829 08:30:46.125087 140305134778112 logging_writer.py:48] [13994] uptime=78596.1. I0829 08:31:07.673585 140305134778112 logging_writer.py:48] [14000] epoch=0, train/categorical_accuracy=1.0, train/categorical_crossentropy=0.5519920587539673, train/f1_het=0.0, train/f1_homalt=0.0, train/f1_homref=1.0, train/f1_macro=0.33333334326744",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:12693,performance,tune,tune,12693,"6] Tune step 2600 / 3162 (80.0%). I0829 08:22:02.367495 140318776715072 train.py:366] Tune step 2700 / 3162 (90.0%). I0829 08:23:54.783612 140318776715072 train.py:366] Tune step 2800 / 3162 (90.0%). I0829 08:25:47.336242 140318776715072 train.py:366] Tune step 2900 / 3162 (90.0%). I0829 08:27:39.775715 140318776715072 train.py:366] Tune step 3000 / 3162 (90.0%). I0829 08:29:29.592094 140318776715072 train.py:366] Tune step 3100 / 3162 (100.0%). I0829 08:30:42.583051 140305134778112 logging_writer.py:48] [13993] tune/categorical_accuracy=0.9916982650756836, tune/categorical_crossentropy=0.560210645198822, tune/f1_het=0.0, tune/f1_homalt=0.0, tune/f1_homref=0.9958318471908569, tune/f1_macro=0.33194395899772644, tune/f1_micro=0.9916982650756836, tune/f1_weighted=0.9958318471908569, tune/false_negatives_1=1777.0, tune/false_positives_1=1544.0, tune/loss=0.5603554248809814, tune/precision_1=0.9923615455627441, tune/precision_het=0.0, tune/precision_homalt=0.0, tune/precision_homref=1.0, tune/recall_1=0.9912189841270447, tune/recall_het=0.0, tune/recall_homalt=0.0, tune/recall_homref=0.9912189841270447, tune/true_negatives_1=403192.0, tune/true_positives_1=200591.0. I0829 08:30:42.590469 140318776715072 train.py:471] Skipping checkpoint with tune/f1_weighted=0.99583185 < previous best tune/f1_weighted=0.99845344. I0829 08:30:42.595992 140305134778112 logging_writer.py:48] [13993] tune/early_stopping=7. I0829 08:30:46.123329 140318776715072 local.py:41] Setting work unit notes: 0.0 steps/s, 61.6% (13994/22724), ETA: 8d4h11m. I0829 08:30:46.125013 140305134778112 logging_writer.py:48] [13994] steps_per_sec=0.0123604. I0829 08:30:46.125087 140305134778112 logging_writer.py:48] [13994] uptime=78596.1. I0829 08:31:07.673585 140305134778112 logging_writer.py:48] [14000] epoch=0, train/categorical_accuracy=1.0, train/categorical_crossentropy=0.5519920587539673, train/f1_het=0.0, train/f1_homalt=0.0, train/f1_homref=1.0, train/f1_macro=0.3333333432674408, train/f1_micro=1.0, tra",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:12727,performance,tune,tune,12727,"I0829 08:22:02.367495 140318776715072 train.py:366] Tune step 2700 / 3162 (90.0%). I0829 08:23:54.783612 140318776715072 train.py:366] Tune step 2800 / 3162 (90.0%). I0829 08:25:47.336242 140318776715072 train.py:366] Tune step 2900 / 3162 (90.0%). I0829 08:27:39.775715 140318776715072 train.py:366] Tune step 3000 / 3162 (90.0%). I0829 08:29:29.592094 140318776715072 train.py:366] Tune step 3100 / 3162 (100.0%). I0829 08:30:42.583051 140305134778112 logging_writer.py:48] [13993] tune/categorical_accuracy=0.9916982650756836, tune/categorical_crossentropy=0.560210645198822, tune/f1_het=0.0, tune/f1_homalt=0.0, tune/f1_homref=0.9958318471908569, tune/f1_macro=0.33194395899772644, tune/f1_micro=0.9916982650756836, tune/f1_weighted=0.9958318471908569, tune/false_negatives_1=1777.0, tune/false_positives_1=1544.0, tune/loss=0.5603554248809814, tune/precision_1=0.9923615455627441, tune/precision_het=0.0, tune/precision_homalt=0.0, tune/precision_homref=1.0, tune/recall_1=0.9912189841270447, tune/recall_het=0.0, tune/recall_homalt=0.0, tune/recall_homref=0.9912189841270447, tune/true_negatives_1=403192.0, tune/true_positives_1=200591.0. I0829 08:30:42.590469 140318776715072 train.py:471] Skipping checkpoint with tune/f1_weighted=0.99583185 < previous best tune/f1_weighted=0.99845344. I0829 08:30:42.595992 140305134778112 logging_writer.py:48] [13993] tune/early_stopping=7. I0829 08:30:46.123329 140318776715072 local.py:41] Setting work unit notes: 0.0 steps/s, 61.6% (13994/22724), ETA: 8d4h11m. I0829 08:30:46.125013 140305134778112 logging_writer.py:48] [13994] steps_per_sec=0.0123604. I0829 08:30:46.125087 140305134778112 logging_writer.py:48] [13994] uptime=78596.1. I0829 08:31:07.673585 140305134778112 logging_writer.py:48] [14000] epoch=0, train/categorical_accuracy=1.0, train/categorical_crossentropy=0.5519920587539673, train/f1_het=0.0, train/f1_homalt=0.0, train/f1_homref=1.0, train/f1_macro=0.3333333432674408, train/f1_micro=1.0, train/f1_weighted=1.0, train/false_ne",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:12748,performance,tune,tune,12748," 140318776715072 train.py:366] Tune step 2700 / 3162 (90.0%). I0829 08:23:54.783612 140318776715072 train.py:366] Tune step 2800 / 3162 (90.0%). I0829 08:25:47.336242 140318776715072 train.py:366] Tune step 2900 / 3162 (90.0%). I0829 08:27:39.775715 140318776715072 train.py:366] Tune step 3000 / 3162 (90.0%). I0829 08:29:29.592094 140318776715072 train.py:366] Tune step 3100 / 3162 (100.0%). I0829 08:30:42.583051 140305134778112 logging_writer.py:48] [13993] tune/categorical_accuracy=0.9916982650756836, tune/categorical_crossentropy=0.560210645198822, tune/f1_het=0.0, tune/f1_homalt=0.0, tune/f1_homref=0.9958318471908569, tune/f1_macro=0.33194395899772644, tune/f1_micro=0.9916982650756836, tune/f1_weighted=0.9958318471908569, tune/false_negatives_1=1777.0, tune/false_positives_1=1544.0, tune/loss=0.5603554248809814, tune/precision_1=0.9923615455627441, tune/precision_het=0.0, tune/precision_homalt=0.0, tune/precision_homref=1.0, tune/recall_1=0.9912189841270447, tune/recall_het=0.0, tune/recall_homalt=0.0, tune/recall_homref=0.9912189841270447, tune/true_negatives_1=403192.0, tune/true_positives_1=200591.0. I0829 08:30:42.590469 140318776715072 train.py:471] Skipping checkpoint with tune/f1_weighted=0.99583185 < previous best tune/f1_weighted=0.99845344. I0829 08:30:42.595992 140305134778112 logging_writer.py:48] [13993] tune/early_stopping=7. I0829 08:30:46.123329 140318776715072 local.py:41] Setting work unit notes: 0.0 steps/s, 61.6% (13994/22724), ETA: 8d4h11m. I0829 08:30:46.125013 140305134778112 logging_writer.py:48] [13994] steps_per_sec=0.0123604. I0829 08:30:46.125087 140305134778112 logging_writer.py:48] [13994] uptime=78596.1. I0829 08:31:07.673585 140305134778112 logging_writer.py:48] [14000] epoch=0, train/categorical_accuracy=1.0, train/categorical_crossentropy=0.5519920587539673, train/f1_het=0.0, train/f1_homalt=0.0, train/f1_homref=1.0, train/f1_macro=0.3333333432674408, train/f1_micro=1.0, train/f1_weighted=1.0, train/false_negatives=0.0, train/fa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:12772,performance,tune,tune,12772,"y:366] Tune step 2700 / 3162 (90.0%). I0829 08:23:54.783612 140318776715072 train.py:366] Tune step 2800 / 3162 (90.0%). I0829 08:25:47.336242 140318776715072 train.py:366] Tune step 2900 / 3162 (90.0%). I0829 08:27:39.775715 140318776715072 train.py:366] Tune step 3000 / 3162 (90.0%). I0829 08:29:29.592094 140318776715072 train.py:366] Tune step 3100 / 3162 (100.0%). I0829 08:30:42.583051 140305134778112 logging_writer.py:48] [13993] tune/categorical_accuracy=0.9916982650756836, tune/categorical_crossentropy=0.560210645198822, tune/f1_het=0.0, tune/f1_homalt=0.0, tune/f1_homref=0.9958318471908569, tune/f1_macro=0.33194395899772644, tune/f1_micro=0.9916982650756836, tune/f1_weighted=0.9958318471908569, tune/false_negatives_1=1777.0, tune/false_positives_1=1544.0, tune/loss=0.5603554248809814, tune/precision_1=0.9923615455627441, tune/precision_het=0.0, tune/precision_homalt=0.0, tune/precision_homref=1.0, tune/recall_1=0.9912189841270447, tune/recall_het=0.0, tune/recall_homalt=0.0, tune/recall_homref=0.9912189841270447, tune/true_negatives_1=403192.0, tune/true_positives_1=200591.0. I0829 08:30:42.590469 140318776715072 train.py:471] Skipping checkpoint with tune/f1_weighted=0.99583185 < previous best tune/f1_weighted=0.99845344. I0829 08:30:42.595992 140305134778112 logging_writer.py:48] [13993] tune/early_stopping=7. I0829 08:30:46.123329 140318776715072 local.py:41] Setting work unit notes: 0.0 steps/s, 61.6% (13994/22724), ETA: 8d4h11m. I0829 08:30:46.125013 140305134778112 logging_writer.py:48] [13994] steps_per_sec=0.0123604. I0829 08:30:46.125087 140305134778112 logging_writer.py:48] [13994] uptime=78596.1. I0829 08:31:07.673585 140305134778112 logging_writer.py:48] [14000] epoch=0, train/categorical_accuracy=1.0, train/categorical_crossentropy=0.5519920587539673, train/f1_het=0.0, train/f1_homalt=0.0, train/f1_homref=1.0, train/f1_macro=0.3333333432674408, train/f1_micro=1.0, train/f1_weighted=1.0, train/false_negatives=0.0, train/false_positives=0.0, train",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:12811,performance,tune,tune,12811,"0829 08:23:54.783612 140318776715072 train.py:366] Tune step 2800 / 3162 (90.0%). I0829 08:25:47.336242 140318776715072 train.py:366] Tune step 2900 / 3162 (90.0%). I0829 08:27:39.775715 140318776715072 train.py:366] Tune step 3000 / 3162 (90.0%). I0829 08:29:29.592094 140318776715072 train.py:366] Tune step 3100 / 3162 (100.0%). I0829 08:30:42.583051 140305134778112 logging_writer.py:48] [13993] tune/categorical_accuracy=0.9916982650756836, tune/categorical_crossentropy=0.560210645198822, tune/f1_het=0.0, tune/f1_homalt=0.0, tune/f1_homref=0.9958318471908569, tune/f1_macro=0.33194395899772644, tune/f1_micro=0.9916982650756836, tune/f1_weighted=0.9958318471908569, tune/false_negatives_1=1777.0, tune/false_positives_1=1544.0, tune/loss=0.5603554248809814, tune/precision_1=0.9923615455627441, tune/precision_het=0.0, tune/precision_homalt=0.0, tune/precision_homref=1.0, tune/recall_1=0.9912189841270447, tune/recall_het=0.0, tune/recall_homalt=0.0, tune/recall_homref=0.9912189841270447, tune/true_negatives_1=403192.0, tune/true_positives_1=200591.0. I0829 08:30:42.590469 140318776715072 train.py:471] Skipping checkpoint with tune/f1_weighted=0.99583185 < previous best tune/f1_weighted=0.99845344. I0829 08:30:42.595992 140305134778112 logging_writer.py:48] [13993] tune/early_stopping=7. I0829 08:30:46.123329 140318776715072 local.py:41] Setting work unit notes: 0.0 steps/s, 61.6% (13994/22724), ETA: 8d4h11m. I0829 08:30:46.125013 140305134778112 logging_writer.py:48] [13994] steps_per_sec=0.0123604. I0829 08:30:46.125087 140305134778112 logging_writer.py:48] [13994] uptime=78596.1. I0829 08:31:07.673585 140305134778112 logging_writer.py:48] [14000] epoch=0, train/categorical_accuracy=1.0, train/categorical_crossentropy=0.5519920587539673, train/f1_het=0.0, train/f1_homalt=0.0, train/f1_homref=1.0, train/f1_macro=0.3333333432674408, train/f1_micro=1.0, train/f1_weighted=1.0, train/false_negatives=0.0, train/false_positives=0.0, train/learning_rate=9.999999747378752e-05, t",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:12843,performance,tune,tune,12843,"5072 train.py:366] Tune step 2800 / 3162 (90.0%). I0829 08:25:47.336242 140318776715072 train.py:366] Tune step 2900 / 3162 (90.0%). I0829 08:27:39.775715 140318776715072 train.py:366] Tune step 3000 / 3162 (90.0%). I0829 08:29:29.592094 140318776715072 train.py:366] Tune step 3100 / 3162 (100.0%). I0829 08:30:42.583051 140305134778112 logging_writer.py:48] [13993] tune/categorical_accuracy=0.9916982650756836, tune/categorical_crossentropy=0.560210645198822, tune/f1_het=0.0, tune/f1_homalt=0.0, tune/f1_homref=0.9958318471908569, tune/f1_macro=0.33194395899772644, tune/f1_micro=0.9916982650756836, tune/f1_weighted=0.9958318471908569, tune/false_negatives_1=1777.0, tune/false_positives_1=1544.0, tune/loss=0.5603554248809814, tune/precision_1=0.9923615455627441, tune/precision_het=0.0, tune/precision_homalt=0.0, tune/precision_homref=1.0, tune/recall_1=0.9912189841270447, tune/recall_het=0.0, tune/recall_homalt=0.0, tune/recall_homref=0.9912189841270447, tune/true_negatives_1=403192.0, tune/true_positives_1=200591.0. I0829 08:30:42.590469 140318776715072 train.py:471] Skipping checkpoint with tune/f1_weighted=0.99583185 < previous best tune/f1_weighted=0.99845344. I0829 08:30:42.595992 140305134778112 logging_writer.py:48] [13993] tune/early_stopping=7. I0829 08:30:46.123329 140318776715072 local.py:41] Setting work unit notes: 0.0 steps/s, 61.6% (13994/22724), ETA: 8d4h11m. I0829 08:30:46.125013 140305134778112 logging_writer.py:48] [13994] steps_per_sec=0.0123604. I0829 08:30:46.125087 140305134778112 logging_writer.py:48] [13994] uptime=78596.1. I0829 08:31:07.673585 140305134778112 logging_writer.py:48] [14000] epoch=0, train/categorical_accuracy=1.0, train/categorical_crossentropy=0.5519920587539673, train/f1_het=0.0, train/f1_homalt=0.0, train/f1_homref=1.0, train/f1_macro=0.3333333432674408, train/f1_micro=1.0, train/f1_weighted=1.0, train/false_negatives=0.0, train/false_positives=0.0, train/learning_rate=9.999999747378752e-05, train/loss=0.551992654800415, tra",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:12952,performance,tune,tune,12952,"ep 2900 / 3162 (90.0%). I0829 08:27:39.775715 140318776715072 train.py:366] Tune step 3000 / 3162 (90.0%). I0829 08:29:29.592094 140318776715072 train.py:366] Tune step 3100 / 3162 (100.0%). I0829 08:30:42.583051 140305134778112 logging_writer.py:48] [13993] tune/categorical_accuracy=0.9916982650756836, tune/categorical_crossentropy=0.560210645198822, tune/f1_het=0.0, tune/f1_homalt=0.0, tune/f1_homref=0.9958318471908569, tune/f1_macro=0.33194395899772644, tune/f1_micro=0.9916982650756836, tune/f1_weighted=0.9958318471908569, tune/false_negatives_1=1777.0, tune/false_positives_1=1544.0, tune/loss=0.5603554248809814, tune/precision_1=0.9923615455627441, tune/precision_het=0.0, tune/precision_homalt=0.0, tune/precision_homref=1.0, tune/recall_1=0.9912189841270447, tune/recall_het=0.0, tune/recall_homalt=0.0, tune/recall_homref=0.9912189841270447, tune/true_negatives_1=403192.0, tune/true_positives_1=200591.0. I0829 08:30:42.590469 140318776715072 train.py:471] Skipping checkpoint with tune/f1_weighted=0.99583185 < previous best tune/f1_weighted=0.99845344. I0829 08:30:42.595992 140305134778112 logging_writer.py:48] [13993] tune/early_stopping=7. I0829 08:30:46.123329 140318776715072 local.py:41] Setting work unit notes: 0.0 steps/s, 61.6% (13994/22724), ETA: 8d4h11m. I0829 08:30:46.125013 140305134778112 logging_writer.py:48] [13994] steps_per_sec=0.0123604. I0829 08:30:46.125087 140305134778112 logging_writer.py:48] [13994] uptime=78596.1. I0829 08:31:07.673585 140305134778112 logging_writer.py:48] [14000] epoch=0, train/categorical_accuracy=1.0, train/categorical_crossentropy=0.5519920587539673, train/f1_het=0.0, train/f1_homalt=0.0, train/f1_homref=1.0, train/f1_macro=0.3333333432674408, train/f1_micro=1.0, train/f1_weighted=1.0, train/false_negatives=0.0, train/false_positives=0.0, train/learning_rate=9.999999747378752e-05, train/loss=0.551992654800415, train/precision=1.0, train/precision_het=0.0, train/precision_homalt=0.0, train/precision_homref=1.0, train/reca",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:12996,performance,tune,tune,12996,"5 140318776715072 train.py:366] Tune step 3000 / 3162 (90.0%). I0829 08:29:29.592094 140318776715072 train.py:366] Tune step 3100 / 3162 (100.0%). I0829 08:30:42.583051 140305134778112 logging_writer.py:48] [13993] tune/categorical_accuracy=0.9916982650756836, tune/categorical_crossentropy=0.560210645198822, tune/f1_het=0.0, tune/f1_homalt=0.0, tune/f1_homref=0.9958318471908569, tune/f1_macro=0.33194395899772644, tune/f1_micro=0.9916982650756836, tune/f1_weighted=0.9958318471908569, tune/false_negatives_1=1777.0, tune/false_positives_1=1544.0, tune/loss=0.5603554248809814, tune/precision_1=0.9923615455627441, tune/precision_het=0.0, tune/precision_homalt=0.0, tune/precision_homref=1.0, tune/recall_1=0.9912189841270447, tune/recall_het=0.0, tune/recall_homalt=0.0, tune/recall_homref=0.9912189841270447, tune/true_negatives_1=403192.0, tune/true_positives_1=200591.0. I0829 08:30:42.590469 140318776715072 train.py:471] Skipping checkpoint with tune/f1_weighted=0.99583185 < previous best tune/f1_weighted=0.99845344. I0829 08:30:42.595992 140305134778112 logging_writer.py:48] [13993] tune/early_stopping=7. I0829 08:30:46.123329 140318776715072 local.py:41] Setting work unit notes: 0.0 steps/s, 61.6% (13994/22724), ETA: 8d4h11m. I0829 08:30:46.125013 140305134778112 logging_writer.py:48] [13994] steps_per_sec=0.0123604. I0829 08:30:46.125087 140305134778112 logging_writer.py:48] [13994] uptime=78596.1. I0829 08:31:07.673585 140305134778112 logging_writer.py:48] [14000] epoch=0, train/categorical_accuracy=1.0, train/categorical_crossentropy=0.5519920587539673, train/f1_het=0.0, train/f1_homalt=0.0, train/f1_homref=1.0, train/f1_macro=0.3333333432674408, train/f1_micro=1.0, train/f1_weighted=1.0, train/false_negatives=0.0, train/false_positives=0.0, train/learning_rate=9.999999747378752e-05, train/loss=0.551992654800415, train/precision=1.0, train/precision_het=0.0, train/precision_homalt=0.0, train/precision_homref=1.0, train/recall=1.0, train/recall_het=0.0, train/recall_h",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:13093,performance,tune,tune,13093,"072 train.py:366] Tune step 3100 / 3162 (100.0%). I0829 08:30:42.583051 140305134778112 logging_writer.py:48] [13993] tune/categorical_accuracy=0.9916982650756836, tune/categorical_crossentropy=0.560210645198822, tune/f1_het=0.0, tune/f1_homalt=0.0, tune/f1_homref=0.9958318471908569, tune/f1_macro=0.33194395899772644, tune/f1_micro=0.9916982650756836, tune/f1_weighted=0.9958318471908569, tune/false_negatives_1=1777.0, tune/false_positives_1=1544.0, tune/loss=0.5603554248809814, tune/precision_1=0.9923615455627441, tune/precision_het=0.0, tune/precision_homalt=0.0, tune/precision_homref=1.0, tune/recall_1=0.9912189841270447, tune/recall_het=0.0, tune/recall_homalt=0.0, tune/recall_homref=0.9912189841270447, tune/true_negatives_1=403192.0, tune/true_positives_1=200591.0. I0829 08:30:42.590469 140318776715072 train.py:471] Skipping checkpoint with tune/f1_weighted=0.99583185 < previous best tune/f1_weighted=0.99845344. I0829 08:30:42.595992 140305134778112 logging_writer.py:48] [13993] tune/early_stopping=7. I0829 08:30:46.123329 140318776715072 local.py:41] Setting work unit notes: 0.0 steps/s, 61.6% (13994/22724), ETA: 8d4h11m. I0829 08:30:46.125013 140305134778112 logging_writer.py:48] [13994] steps_per_sec=0.0123604. I0829 08:30:46.125087 140305134778112 logging_writer.py:48] [13994] uptime=78596.1. I0829 08:31:07.673585 140305134778112 logging_writer.py:48] [14000] epoch=0, train/categorical_accuracy=1.0, train/categorical_crossentropy=0.5519920587539673, train/f1_het=0.0, train/f1_homalt=0.0, train/f1_homref=1.0, train/f1_macro=0.3333333432674408, train/f1_micro=1.0, train/f1_weighted=1.0, train/false_negatives=0.0, train/false_positives=0.0, train/learning_rate=9.999999747378752e-05, train/loss=0.551992654800415, train/precision=1.0, train/precision_het=0.0, train/precision_homalt=0.0, train/precision_homref=1.0, train/recall=1.0, train/recall_het=0.0, train/recall_homalt=0.0, train/recall_homref=1.0, train/true_negatives=12800.0, train/true_positives=6400.0. ``",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:14250,performance,time,time,14250,"ne/loss=0.5603554248809814, tune/precision_1=0.9923615455627441, tune/precision_het=0.0, tune/precision_homalt=0.0, tune/precision_homref=1.0, tune/recall_1=0.9912189841270447, tune/recall_het=0.0, tune/recall_homalt=0.0, tune/recall_homref=0.9912189841270447, tune/true_negatives_1=403192.0, tune/true_positives_1=200591.0. I0829 08:30:42.590469 140318776715072 train.py:471] Skipping checkpoint with tune/f1_weighted=0.99583185 < previous best tune/f1_weighted=0.99845344. I0829 08:30:42.595992 140305134778112 logging_writer.py:48] [13993] tune/early_stopping=7. I0829 08:30:46.123329 140318776715072 local.py:41] Setting work unit notes: 0.0 steps/s, 61.6% (13994/22724), ETA: 8d4h11m. I0829 08:30:46.125013 140305134778112 logging_writer.py:48] [13994] steps_per_sec=0.0123604. I0829 08:30:46.125087 140305134778112 logging_writer.py:48] [13994] uptime=78596.1. I0829 08:31:07.673585 140305134778112 logging_writer.py:48] [14000] epoch=0, train/categorical_accuracy=1.0, train/categorical_crossentropy=0.5519920587539673, train/f1_het=0.0, train/f1_homalt=0.0, train/f1_homref=1.0, train/f1_macro=0.3333333432674408, train/f1_micro=1.0, train/f1_weighted=1.0, train/false_negatives=0.0, train/false_positives=0.0, train/learning_rate=9.999999747378752e-05, train/loss=0.551992654800415, train/precision=1.0, train/precision_het=0.0, train/precision_homalt=0.0, train/precision_homref=1.0, train/recall=1.0, train/recall_het=0.0, train/recall_homalt=0.0, train/recall_homref=1.0, train/true_negatives=12800.0, train/true_positives=6400.0. ```. I am new to Deep Learning and am struggling to decide whether something is wrong with my training approach/scripts or whether the model just needs more time / different hyperparams. Given the number of examples, I can only run 1 epoch at a time before I hit the 24hr cluster wall-time limit. So I have only trained for around 30,000 steps in total across 2 epochs so far (starting from last checkpoint after 1st epoch). . All advice much appreciated! .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:14338,performance,time,time,14338,"ne/loss=0.5603554248809814, tune/precision_1=0.9923615455627441, tune/precision_het=0.0, tune/precision_homalt=0.0, tune/precision_homref=1.0, tune/recall_1=0.9912189841270447, tune/recall_het=0.0, tune/recall_homalt=0.0, tune/recall_homref=0.9912189841270447, tune/true_negatives_1=403192.0, tune/true_positives_1=200591.0. I0829 08:30:42.590469 140318776715072 train.py:471] Skipping checkpoint with tune/f1_weighted=0.99583185 < previous best tune/f1_weighted=0.99845344. I0829 08:30:42.595992 140305134778112 logging_writer.py:48] [13993] tune/early_stopping=7. I0829 08:30:46.123329 140318776715072 local.py:41] Setting work unit notes: 0.0 steps/s, 61.6% (13994/22724), ETA: 8d4h11m. I0829 08:30:46.125013 140305134778112 logging_writer.py:48] [13994] steps_per_sec=0.0123604. I0829 08:30:46.125087 140305134778112 logging_writer.py:48] [13994] uptime=78596.1. I0829 08:31:07.673585 140305134778112 logging_writer.py:48] [14000] epoch=0, train/categorical_accuracy=1.0, train/categorical_crossentropy=0.5519920587539673, train/f1_het=0.0, train/f1_homalt=0.0, train/f1_homref=1.0, train/f1_macro=0.3333333432674408, train/f1_micro=1.0, train/f1_weighted=1.0, train/false_negatives=0.0, train/false_positives=0.0, train/learning_rate=9.999999747378752e-05, train/loss=0.551992654800415, train/precision=1.0, train/precision_het=0.0, train/precision_homalt=0.0, train/precision_homref=1.0, train/recall=1.0, train/recall_het=0.0, train/recall_homalt=0.0, train/recall_homref=1.0, train/true_negatives=12800.0, train/true_positives=6400.0. ```. I am new to Deep Learning and am struggling to decide whether something is wrong with my training approach/scripts or whether the model just needs more time / different hyperparams. Given the number of examples, I can only run 1 epoch at a time before I hit the 24hr cluster wall-time limit. So I have only trained for around 30,000 steps in total across 2 epochs so far (starting from last checkpoint after 1st epoch). . All advice much appreciated! .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:14378,performance,time,time,14378,"ne/loss=0.5603554248809814, tune/precision_1=0.9923615455627441, tune/precision_het=0.0, tune/precision_homalt=0.0, tune/precision_homref=1.0, tune/recall_1=0.9912189841270447, tune/recall_het=0.0, tune/recall_homalt=0.0, tune/recall_homref=0.9912189841270447, tune/true_negatives_1=403192.0, tune/true_positives_1=200591.0. I0829 08:30:42.590469 140318776715072 train.py:471] Skipping checkpoint with tune/f1_weighted=0.99583185 < previous best tune/f1_weighted=0.99845344. I0829 08:30:42.595992 140305134778112 logging_writer.py:48] [13993] tune/early_stopping=7. I0829 08:30:46.123329 140318776715072 local.py:41] Setting work unit notes: 0.0 steps/s, 61.6% (13994/22724), ETA: 8d4h11m. I0829 08:30:46.125013 140305134778112 logging_writer.py:48] [13994] steps_per_sec=0.0123604. I0829 08:30:46.125087 140305134778112 logging_writer.py:48] [13994] uptime=78596.1. I0829 08:31:07.673585 140305134778112 logging_writer.py:48] [14000] epoch=0, train/categorical_accuracy=1.0, train/categorical_crossentropy=0.5519920587539673, train/f1_het=0.0, train/f1_homalt=0.0, train/f1_homref=1.0, train/f1_macro=0.3333333432674408, train/f1_micro=1.0, train/f1_weighted=1.0, train/false_negatives=0.0, train/false_positives=0.0, train/learning_rate=9.999999747378752e-05, train/loss=0.551992654800415, train/precision=1.0, train/precision_het=0.0, train/precision_homalt=0.0, train/precision_homref=1.0, train/recall=1.0, train/recall_het=0.0, train/recall_homalt=0.0, train/recall_homref=1.0, train/true_negatives=12800.0, train/true_positives=6400.0. ```. I am new to Deep Learning and am struggling to decide whether something is wrong with my training approach/scripts or whether the model just needs more time / different hyperparams. Given the number of examples, I can only run 1 epoch at a time before I hit the 24hr cluster wall-time limit. So I have only trained for around 30,000 steps in total across 2 epochs so far (starting from last checkpoint after 1st epoch). . All advice much appreciated! .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:2869,reliability,mainten,maintenance,2869,"/train/All_samples_training_examples.dataset_config.pbtxt"" . --config.tune_dataset_pbtxt=""/home/examples_shuffled/tune/All_samples_tune_examples.dataset_config.pbtxt"". . --config.num_epochs=1 . --config.learning_rate=0.0001 . --config.num_validation_examples=0 . --config.tune_every_steps=2000 . --experiment_dir=/home/${OUTDIR} . --strategy=mirrored . --config.batch_size=64 . --config.init_checkpoint=""/home/model_wgs_v1.6.1/deepvariant.wgs.ckpt"". ```. Though previous runs had higher learning rates (0.01) and batch sizes (128). Training proceeds as follows:. Training Examples: 1454377. Batch Size: 64. Epochs: 1. Steps per epoch: 22724. Steps per tune: 3162. Num train steps: 22724. **Log file**. Here is the top of the log file, including some warnings in case they are relevant:. ```. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(. 2024-08-28 10:40:42.588215: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_SYSTEM_DRIVER_MISMATCH: system has unsupported display driver / cuda driver combination. I0828 10:40:42.589054 140318776715072 train.py:92] Running with debug=False. I0828 10:40:42.589343 140318776715072 train.py:100] Use TPU at local. I0828 10:40:42.589422 140318776715072 train.py:103] experiment_dir: /home/training_outs/epoch1/. WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce. W0828 10:40:42.596594 140318776715072 cross_device_ops.py:1387] There are non-GPU devices in `tf.distribute.Strategy`, not using nccl a",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:3273,reliability,fail,failed,3273,"t=""/home/model_wgs_v1.6.1/deepvariant.wgs.ckpt"". ```. Though previous runs had higher learning rates (0.01) and batch sizes (128). Training proceeds as follows:. Training Examples: 1454377. Batch Size: 64. Epochs: 1. Steps per epoch: 22724. Steps per tune: 3162. Num train steps: 22724. **Log file**. Here is the top of the log file, including some warnings in case they are relevant:. ```. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(. 2024-08-28 10:40:42.588215: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_SYSTEM_DRIVER_MISMATCH: system has unsupported display driver / cuda driver combination. I0828 10:40:42.589054 140318776715072 train.py:92] Running with debug=False. I0828 10:40:42.589343 140318776715072 train.py:100] Use TPU at local. I0828 10:40:42.589422 140318776715072 train.py:103] experiment_dir: /home/training_outs/epoch1/. WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce. W0828 10:40:42.596594 140318776715072 cross_device_ops.py:1387] There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce. INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',). I0828 10:40:42.658734 140318776715072 mirrored_strategy.py:374] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',). /usr/local/lib/python3.8/dist-packages/keras/applications/inception_v3.py:138: UserWarning: This model usually expects 1 or 3 input chann",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:4576,reliability,checkpoint,checkpoint,4576,"train.py:103] experiment_dir: /home/training_outs/epoch1/. WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce. W0828 10:40:42.596594 140318776715072 cross_device_ops.py:1387] There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce. INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',). I0828 10:40:42.658734 140318776715072 mirrored_strategy.py:374] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',). /usr/local/lib/python3.8/dist-packages/keras/applications/inception_v3.py:138: UserWarning: This model usually expects 1 or 3 input channels. However, it was passed an input_shape with 7 input channels. input_shape = imagenet_utils.obtain_input_shape(. I0828 10:40:47.952382 140318776715072 keras_modeling.py:325] Number of l2 regularizers: 95. I0828 10:40:48.007193 140318776715072 keras_modeling.py:362] inceptionv3: load_weights from checkpoint: /home/training_outs/epoch1//checkpoints/ckpt-5997. I0828 10:40:49.193293 140318776715072 train.py:191] Exponential Decay: initial_learning_rate=0.0001. decay_steps=45448. learning_rate_decay_rate=0.947. I0828 10:40:49.193522 140318776715072 train.py:203] Use LinearWarmup:. warmup_steps=10000. warmup_learning_rate=1e-05. I0828 10:40:49.401860 140318776715072 keras_modeling.py:472] Restored checkpoint ckpt-5997 at step=0. tune/f1_weighted=tf.Tensor(0.0, shape=(), dtype=float32). WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23. Instructions for updating:. Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089. W0828 10:40:49.488072 140318776715072 depr",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:4616,reliability,checkpoint,checkpoints,4616,"ing_outs/epoch1/. WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce. W0828 10:40:42.596594 140318776715072 cross_device_ops.py:1387] There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce. INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',). I0828 10:40:42.658734 140318776715072 mirrored_strategy.py:374] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',). /usr/local/lib/python3.8/dist-packages/keras/applications/inception_v3.py:138: UserWarning: This model usually expects 1 or 3 input channels. However, it was passed an input_shape with 7 input channels. input_shape = imagenet_utils.obtain_input_shape(. I0828 10:40:47.952382 140318776715072 keras_modeling.py:325] Number of l2 regularizers: 95. I0828 10:40:48.007193 140318776715072 keras_modeling.py:362] inceptionv3: load_weights from checkpoint: /home/training_outs/epoch1//checkpoints/ckpt-5997. I0828 10:40:49.193293 140318776715072 train.py:191] Exponential Decay: initial_learning_rate=0.0001. decay_steps=45448. learning_rate_decay_rate=0.947. I0828 10:40:49.193522 140318776715072 train.py:203] Use LinearWarmup:. warmup_steps=10000. warmup_learning_rate=1e-05. I0828 10:40:49.401860 140318776715072 keras_modeling.py:472] Restored checkpoint ckpt-5997 at step=0. tune/f1_weighted=tf.Tensor(0.0, shape=(), dtype=float32). WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23. Instructions for updating:. Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089. W0828 10:40:49.488072 140318776715072 deprecation.py:350] From /usr/local/lib/pytho",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:4971,reliability,Restor,Restored,4971,"ce:CPU:0',). I0828 10:40:42.658734 140318776715072 mirrored_strategy.py:374] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',). /usr/local/lib/python3.8/dist-packages/keras/applications/inception_v3.py:138: UserWarning: This model usually expects 1 or 3 input channels. However, it was passed an input_shape with 7 input channels. input_shape = imagenet_utils.obtain_input_shape(. I0828 10:40:47.952382 140318776715072 keras_modeling.py:325] Number of l2 regularizers: 95. I0828 10:40:48.007193 140318776715072 keras_modeling.py:362] inceptionv3: load_weights from checkpoint: /home/training_outs/epoch1//checkpoints/ckpt-5997. I0828 10:40:49.193293 140318776715072 train.py:191] Exponential Decay: initial_learning_rate=0.0001. decay_steps=45448. learning_rate_decay_rate=0.947. I0828 10:40:49.193522 140318776715072 train.py:203] Use LinearWarmup:. warmup_steps=10000. warmup_learning_rate=1e-05. I0828 10:40:49.401860 140318776715072 keras_modeling.py:472] Restored checkpoint ckpt-5997 at step=0. tune/f1_weighted=tf.Tensor(0.0, shape=(), dtype=float32). WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23. Instructions for updating:. Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089. W0828 10:40:49.488072 140318776715072 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be rem>. Instructions for updating:. Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. htt",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:4980,reliability,checkpoint,checkpoint,4980,"). I0828 10:40:42.658734 140318776715072 mirrored_strategy.py:374] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',). /usr/local/lib/python3.8/dist-packages/keras/applications/inception_v3.py:138: UserWarning: This model usually expects 1 or 3 input channels. However, it was passed an input_shape with 7 input channels. input_shape = imagenet_utils.obtain_input_shape(. I0828 10:40:47.952382 140318776715072 keras_modeling.py:325] Number of l2 regularizers: 95. I0828 10:40:48.007193 140318776715072 keras_modeling.py:362] inceptionv3: load_weights from checkpoint: /home/training_outs/epoch1//checkpoints/ckpt-5997. I0828 10:40:49.193293 140318776715072 train.py:191] Exponential Decay: initial_learning_rate=0.0001. decay_steps=45448. learning_rate_decay_rate=0.947. I0828 10:40:49.193522 140318776715072 train.py:203] Use LinearWarmup:. warmup_steps=10000. warmup_learning_rate=1e-05. I0828 10:40:49.401860 140318776715072 keras_modeling.py:472] Restored checkpoint ckpt-5997 at step=0. tune/f1_weighted=tf.Tensor(0.0, shape=(), dtype=float32). WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23. Instructions for updating:. Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089. W0828 10:40:49.488072 140318776715072 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be rem>. Instructions for updating:. Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://githu",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:6178,reliability,doe,does,6178,"s/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23. Instructions for updating:. Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089. W0828 10:40:49.488072 140318776715072 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be rem>. Instructions for updating:. Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089. 2024-08-28 10:40:49.893797: W tensorflow/core/framework/dataset.cc:769] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations. I0828 10:40:49.947995 140318776715072 train.py:316]. ```. And here is an excerpt of from a later portion of the log file including some training and tuning steps, where you can see the 0.0 for het and homalt eval stats. . ```. I0829 07:13:59.098341 140305134778112 logging_writer.py:48] [13700] epoch=0, train/categorical_accuracy=1.0, train/categorical_crossentropy=0.552009105682373, train/f1_het=0.0, train/f1_homalt=0.0, train/f1_homref=1.0, train/f1_macro=0.3333333432674408, train/f1_micro=1.0, train/f1_. weighted=1.0, train/false_negatives=0.0, train/false_positives=0.0, train/learning_rate=9.999999747378752e-05, train/loss=0.5520098805427551, train/precision=1.0, train/precision_het=0.0, train/precision_homalt=0.0, train/precision_homref=1.0, train/recall=1.0, train/recall_het=0.0,. train/recall_homalt=0.0, train/recall_homref=1.0, train/true_negatives=12800.0, train/true_positives=6400.0. I0829 07:18:37",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:7448,reliability,uptim,uptime,7448,"r het and homalt eval stats. . ```. I0829 07:13:59.098341 140305134778112 logging_writer.py:48] [13700] epoch=0, train/categorical_accuracy=1.0, train/categorical_crossentropy=0.552009105682373, train/f1_het=0.0, train/f1_homalt=0.0, train/f1_homref=1.0, train/f1_macro=0.3333333432674408, train/f1_micro=1.0, train/f1_. weighted=1.0, train/false_negatives=0.0, train/false_positives=0.0, train/learning_rate=9.999999747378752e-05, train/loss=0.5520098805427551, train/precision=1.0, train/precision_het=0.0, train/precision_homalt=0.0, train/precision_homref=1.0, train/recall=1.0, train/recall_het=0.0,. train/recall_homalt=0.0, train/recall_homref=1.0, train/true_negatives=12800.0, train/true_positives=6400.0. I0829 07:18:37.609363 140318776715072 local.py:41] Setting work unit notes: 0.3 steps/s, 60.6% (13778/22724), ETA: 8h52m. I0829 07:18:37.611700 140305134778112 logging_writer.py:48] [13778] steps_per_sec=0.280118. I0829 07:18:37.611787 140305134778112 logging_writer.py:48] [13778] uptime=74267.6. I0829 07:19:56.116713 140305134778112 logging_writer.py:48] [13800] epoch=0, train/categorical_accuracy=1.0, train/categorical_crossentropy=0.5520044565200806, train/f1_het=0.0, train/f1_homalt=0.0, train/f1_homref=1.0, train/f1_macro=0.3333333432674408, train/f1_micro=1.0, train/f1_weighted=1.0, train/false_negatives=0.0, train/false_positives=0.0, train/learning_rate=9.999999747378752e-05, train/loss=0.5520052909851074, train/precision=1.0, train/precision_het=0.0, train/precision_homalt=0.0, train/precision_homref=1.0, train/recall=1.0, train/recall_het=0.0, train/recall_homalt=0.0, train/recall_homref=1.0, train/true_negatives=12800.0, train/true_positives=6400.0. I0829 07:23:41.076397 140318776715072 local.py:41] Setting work unit notes: 0.3 steps/s, 61.0% (13863/22724), ETA: 8h47m. I0829 07:23:41.078737 140305134778112 logging_writer.py:48] [13863] steps_per_sec=0.280096. I0829 07:23:41.078827 140305134778112 logging_writer.py:48] [13863] uptime=74571.1. I0829 07:25:",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:8423,reliability,uptim,uptime,8423,"writer.py:48] [13778] uptime=74267.6. I0829 07:19:56.116713 140305134778112 logging_writer.py:48] [13800] epoch=0, train/categorical_accuracy=1.0, train/categorical_crossentropy=0.5520044565200806, train/f1_het=0.0, train/f1_homalt=0.0, train/f1_homref=1.0, train/f1_macro=0.3333333432674408, train/f1_micro=1.0, train/f1_weighted=1.0, train/false_negatives=0.0, train/false_positives=0.0, train/learning_rate=9.999999747378752e-05, train/loss=0.5520052909851074, train/precision=1.0, train/precision_het=0.0, train/precision_homalt=0.0, train/precision_homref=1.0, train/recall=1.0, train/recall_het=0.0, train/recall_homalt=0.0, train/recall_homref=1.0, train/true_negatives=12800.0, train/true_positives=6400.0. I0829 07:23:41.076397 140318776715072 local.py:41] Setting work unit notes: 0.3 steps/s, 61.0% (13863/22724), ETA: 8h47m. I0829 07:23:41.078737 140305134778112 logging_writer.py:48] [13863] steps_per_sec=0.280096. I0829 07:23:41.078827 140305134778112 logging_writer.py:48] [13863] uptime=74571.1. I0829 07:25:53.180995 140305134778112 logging_writer.py:48] [13900] epoch=0, train/categorical_accuracy=1.0, train/categorical_crossentropy=0.5519936680793762, train/f1_het=0.0, train/f1_homalt=0.0, train/f1_homref=1.0, train/f1_macro=0.3333333432674408, train/f1_micro=1.0, train/f1_weighted=1.0, train/false_negatives=0.0, train/false_positives=0.0, train/learning_rate=9.999999747378752e-05, train/loss=0.5519945025444031, train/precision=1.0, train/precision_het=0.0, train/precision_homalt=0.0, train/precision_homref=1.0, train/recall=1.0, train/recall_het=0.0, train/recall_homalt=0.0, train/recall_homref=1.0, train/true_negatives=12800.0, train/true_positives=6400.0. I0829 07:28:44.566404 140318776715072 local.py:41] Setting work unit notes: 0.3 steps/s, 61.4% (13948/22724), ETA: 8h42m. I0829 07:28:44.568708 140305134778112 logging_writer.py:48] [13948] steps_per_sec=0.280075. I0829 07:28:44.568793 140305134778112 logging_writer.py:48] [13948] uptime=74874.6. I0829 07:31:",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:9398,reliability,uptim,uptime,9398,"writer.py:48] [13863] uptime=74571.1. I0829 07:25:53.180995 140305134778112 logging_writer.py:48] [13900] epoch=0, train/categorical_accuracy=1.0, train/categorical_crossentropy=0.5519936680793762, train/f1_het=0.0, train/f1_homalt=0.0, train/f1_homref=1.0, train/f1_macro=0.3333333432674408, train/f1_micro=1.0, train/f1_weighted=1.0, train/false_negatives=0.0, train/false_positives=0.0, train/learning_rate=9.999999747378752e-05, train/loss=0.5519945025444031, train/precision=1.0, train/precision_het=0.0, train/precision_homalt=0.0, train/precision_homref=1.0, train/recall=1.0, train/recall_het=0.0, train/recall_homalt=0.0, train/recall_homref=1.0, train/true_negatives=12800.0, train/true_positives=6400.0. I0829 07:28:44.566404 140318776715072 local.py:41] Setting work unit notes: 0.3 steps/s, 61.4% (13948/22724), ETA: 8h42m. I0829 07:28:44.568708 140305134778112 logging_writer.py:48] [13948] steps_per_sec=0.280075. I0829 07:28:44.568793 140305134778112 logging_writer.py:48] [13948] uptime=74874.6. I0829 07:31:25.151819 140318776715072 train.py:361] Running tune at step=13993 epoch=0. I0829 07:31:25.152109 140318776715072 train.py:366] Tune step 0 / 3162 (0.0%). I0829 07:33:17.573163 140318776715072 train.py:366] Tune step 100 / 3162 (0.0%). I0829 07:35:10.013494 140318776715072 train.py:366] Tune step 200 / 3162 (10.0%). I0829 07:37:02.497336 140318776715072 train.py:366] Tune step 300 / 3162 (10.0%). I0829 07:38:54.834164 140318776715072 train.py:366] Tune step 400 / 3162 (10.0%). I0829 07:40:47.319165 140318776715072 train.py:366] Tune step 500 / 3162 (20.0%). I0829 07:42:39.802007 140318776715072 train.py:366] Tune step 600 / 3162 (20.0%). I0829 07:44:32.297624 140318776715072 train.py:366] Tune step 700 / 3162 (20.0%). I0829 07:46:24.658610 140318776715072 train.py:366] Tune step 800 / 3162 (30.0%). I0829 07:48:17.176530 140318776715072 train.py:366] Tune step 900 / 3162 (30.0%). I0829 07:50:09.700463 140318776715072 train.py:366] Tune step 1000 / 3162 (30.0%). ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:12936,reliability,checkpoint,checkpoint,12936,":366] Tune step 2900 / 3162 (90.0%). I0829 08:27:39.775715 140318776715072 train.py:366] Tune step 3000 / 3162 (90.0%). I0829 08:29:29.592094 140318776715072 train.py:366] Tune step 3100 / 3162 (100.0%). I0829 08:30:42.583051 140305134778112 logging_writer.py:48] [13993] tune/categorical_accuracy=0.9916982650756836, tune/categorical_crossentropy=0.560210645198822, tune/f1_het=0.0, tune/f1_homalt=0.0, tune/f1_homref=0.9958318471908569, tune/f1_macro=0.33194395899772644, tune/f1_micro=0.9916982650756836, tune/f1_weighted=0.9958318471908569, tune/false_negatives_1=1777.0, tune/false_positives_1=1544.0, tune/loss=0.5603554248809814, tune/precision_1=0.9923615455627441, tune/precision_het=0.0, tune/precision_homalt=0.0, tune/precision_homref=1.0, tune/recall_1=0.9912189841270447, tune/recall_het=0.0, tune/recall_homalt=0.0, tune/recall_homref=0.9912189841270447, tune/true_negatives_1=403192.0, tune/true_positives_1=200591.0. I0829 08:30:42.590469 140318776715072 train.py:471] Skipping checkpoint with tune/f1_weighted=0.99583185 < previous best tune/f1_weighted=0.99845344. I0829 08:30:42.595992 140305134778112 logging_writer.py:48] [13993] tune/early_stopping=7. I0829 08:30:46.123329 140318776715072 local.py:41] Setting work unit notes: 0.0 steps/s, 61.6% (13994/22724), ETA: 8d4h11m. I0829 08:30:46.125013 140305134778112 logging_writer.py:48] [13994] steps_per_sec=0.0123604. I0829 08:30:46.125087 140305134778112 logging_writer.py:48] [13994] uptime=78596.1. I0829 08:31:07.673585 140305134778112 logging_writer.py:48] [14000] epoch=0, train/categorical_accuracy=1.0, train/categorical_crossentropy=0.5519920587539673, train/f1_het=0.0, train/f1_homalt=0.0, train/f1_homref=1.0, train/f1_macro=0.3333333432674408, train/f1_micro=1.0, train/f1_weighted=1.0, train/false_negatives=0.0, train/false_positives=0.0, train/learning_rate=9.999999747378752e-05, train/loss=0.551992654800415, train/precision=1.0, train/precision_het=0.0, train/precision_homalt=0.0, train/precision_homref=1.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:13401,reliability,uptim,uptime,13401,"899772644, tune/f1_micro=0.9916982650756836, tune/f1_weighted=0.9958318471908569, tune/false_negatives_1=1777.0, tune/false_positives_1=1544.0, tune/loss=0.5603554248809814, tune/precision_1=0.9923615455627441, tune/precision_het=0.0, tune/precision_homalt=0.0, tune/precision_homref=1.0, tune/recall_1=0.9912189841270447, tune/recall_het=0.0, tune/recall_homalt=0.0, tune/recall_homref=0.9912189841270447, tune/true_negatives_1=403192.0, tune/true_positives_1=200591.0. I0829 08:30:42.590469 140318776715072 train.py:471] Skipping checkpoint with tune/f1_weighted=0.99583185 < previous best tune/f1_weighted=0.99845344. I0829 08:30:42.595992 140305134778112 logging_writer.py:48] [13993] tune/early_stopping=7. I0829 08:30:46.123329 140318776715072 local.py:41] Setting work unit notes: 0.0 steps/s, 61.6% (13994/22724), ETA: 8d4h11m. I0829 08:30:46.125013 140305134778112 logging_writer.py:48] [13994] steps_per_sec=0.0123604. I0829 08:30:46.125087 140305134778112 logging_writer.py:48] [13994] uptime=78596.1. I0829 08:31:07.673585 140305134778112 logging_writer.py:48] [14000] epoch=0, train/categorical_accuracy=1.0, train/categorical_crossentropy=0.5519920587539673, train/f1_het=0.0, train/f1_homalt=0.0, train/f1_homref=1.0, train/f1_macro=0.3333333432674408, train/f1_micro=1.0, train/f1_weighted=1.0, train/false_negatives=0.0, train/false_positives=0.0, train/learning_rate=9.999999747378752e-05, train/loss=0.551992654800415, train/precision=1.0, train/precision_het=0.0, train/precision_homalt=0.0, train/precision_homref=1.0, train/recall=1.0, train/recall_het=0.0, train/recall_homalt=0.0, train/recall_homref=1.0, train/true_negatives=12800.0, train/true_positives=6400.0. ```. I am new to Deep Learning and am struggling to decide whether something is wrong with my training approach/scripts or whether the model just needs more time / different hyperparams. Given the number of examples, I can only run 1 epoch at a time before I hit the 24hr cluster wall-time limit. So I have only",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:14489,reliability,checkpoint,checkpoint,14489,"ne/loss=0.5603554248809814, tune/precision_1=0.9923615455627441, tune/precision_het=0.0, tune/precision_homalt=0.0, tune/precision_homref=1.0, tune/recall_1=0.9912189841270447, tune/recall_het=0.0, tune/recall_homalt=0.0, tune/recall_homref=0.9912189841270447, tune/true_negatives_1=403192.0, tune/true_positives_1=200591.0. I0829 08:30:42.590469 140318776715072 train.py:471] Skipping checkpoint with tune/f1_weighted=0.99583185 < previous best tune/f1_weighted=0.99845344. I0829 08:30:42.595992 140305134778112 logging_writer.py:48] [13993] tune/early_stopping=7. I0829 08:30:46.123329 140318776715072 local.py:41] Setting work unit notes: 0.0 steps/s, 61.6% (13994/22724), ETA: 8d4h11m. I0829 08:30:46.125013 140305134778112 logging_writer.py:48] [13994] steps_per_sec=0.0123604. I0829 08:30:46.125087 140305134778112 logging_writer.py:48] [13994] uptime=78596.1. I0829 08:31:07.673585 140305134778112 logging_writer.py:48] [14000] epoch=0, train/categorical_accuracy=1.0, train/categorical_crossentropy=0.5519920587539673, train/f1_het=0.0, train/f1_homalt=0.0, train/f1_homref=1.0, train/f1_macro=0.3333333432674408, train/f1_micro=1.0, train/f1_weighted=1.0, train/false_negatives=0.0, train/false_positives=0.0, train/learning_rate=9.999999747378752e-05, train/loss=0.551992654800415, train/precision=1.0, train/precision_het=0.0, train/precision_homalt=0.0, train/precision_homref=1.0, train/recall=1.0, train/recall_het=0.0, train/recall_homalt=0.0, train/recall_homref=1.0, train/true_negatives=12800.0, train/true_positives=6400.0. ```. I am new to Deep Learning and am struggling to decide whether something is wrong with my training approach/scripts or whether the model just needs more time / different hyperparams. Given the number of examples, I can only run 1 epoch at a time before I hit the 24hr cluster wall-time limit. So I have only trained for around 30,000 steps in total across 2 epochs so far (starting from last checkpoint after 1st epoch). . All advice much appreciated! .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:1311,safety,test,testing,1311,"r more specifically they are all 0.0. Eval stats are reported for homref though. I have now tried running the training several times with different hyperparameters but so far still no change at the het or homalt eval stats. . My first, very simple question is thus, are these eval stats truly 0 (i.e. the model is very bad) or is 0.0 some starting value and there are not enough data to calculate them initially? I am warmstarting from the 1.6.1 wgs model so I cant imagine the model is really that bad at calling variants initially, even if in a fish. . **Setup**. Running on a university computing cluster (https://hpc-unibe-ch.github.io/) . OS: Rocky 9.3 Blue Onyx. GPU: rtx4090 . Installation: Running from Docker image via singularity. DV version: 1.6.1. **Data**. I am training on examples from 5 individuals, data from Illumina NovaSeq ~20x coverage. . 17/21 chromosomes used for training (~1.45M examples). 2/21 chromosomes used for tuning (~200k examples). 2/21 chromosomes reserved for testing. . (Different chromosomes used for train/tune/test across samples - see below). <img width=""1437"" alt=""Screenshot 2024-08-07 at 09 30 23"" src=""https://github.com/user-attachments/assets/3178e87a-8cf7-47cb-84a2-0a84d15c958f"">. **Shuffling**. Performed downsampling=0.5. Shuffled globally across samples, chromosomes and downsampling. . **Command**. My latest training run was like so:. ```. apptainer run . --nv . -B $WD:/home . $DV_PATH . /opt/deepvariant/bin/train . --config=/home/dv_config.py:base . --config.train_dataset_pbtxt=""/home/examples_shuffled/train/All_samples_training_examples.dataset_config.pbtxt"" . --config.tune_dataset_pbtxt=""/home/examples_shuffled/tune/All_samples_tune_examples.dataset_config.pbtxt"". . --config.num_epochs=1 . --config.learning_rate=0.0001 . --config.num_validation_examples=0 . --config.tune_every_steps=2000 . --experiment_dir=/home/${OUTDIR} . --strategy=mirrored . --config.batch_size=64 . --config.init_checkpoint=""/home/model_wgs_v1.6.1/deepvariant.w",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:1365,safety,test,test,1365," reported for homref though. I have now tried running the training several times with different hyperparameters but so far still no change at the het or homalt eval stats. . My first, very simple question is thus, are these eval stats truly 0 (i.e. the model is very bad) or is 0.0 some starting value and there are not enough data to calculate them initially? I am warmstarting from the 1.6.1 wgs model so I cant imagine the model is really that bad at calling variants initially, even if in a fish. . **Setup**. Running on a university computing cluster (https://hpc-unibe-ch.github.io/) . OS: Rocky 9.3 Blue Onyx. GPU: rtx4090 . Installation: Running from Docker image via singularity. DV version: 1.6.1. **Data**. I am training on examples from 5 individuals, data from Illumina NovaSeq ~20x coverage. . 17/21 chromosomes used for training (~1.45M examples). 2/21 chromosomes used for tuning (~200k examples). 2/21 chromosomes reserved for testing. . (Different chromosomes used for train/tune/test across samples - see below). <img width=""1437"" alt=""Screenshot 2024-08-07 at 09 30 23"" src=""https://github.com/user-attachments/assets/3178e87a-8cf7-47cb-84a2-0a84d15c958f"">. **Shuffling**. Performed downsampling=0.5. Shuffled globally across samples, chromosomes and downsampling. . **Command**. My latest training run was like so:. ```. apptainer run . --nv . -B $WD:/home . $DV_PATH . /opt/deepvariant/bin/train . --config=/home/dv_config.py:base . --config.train_dataset_pbtxt=""/home/examples_shuffled/train/All_samples_training_examples.dataset_config.pbtxt"" . --config.tune_dataset_pbtxt=""/home/examples_shuffled/tune/All_samples_tune_examples.dataset_config.pbtxt"". . --config.num_epochs=1 . --config.learning_rate=0.0001 . --config.num_validation_examples=0 . --config.tune_every_steps=2000 . --experiment_dir=/home/${OUTDIR} . --strategy=mirrored . --config.batch_size=64 . --config.init_checkpoint=""/home/model_wgs_v1.6.1/deepvariant.wgs.ckpt"". ```. Though previous runs had higher learn",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:2565,safety,Log,Log,2565,"ed downsampling=0.5. Shuffled globally across samples, chromosomes and downsampling. . **Command**. My latest training run was like so:. ```. apptainer run . --nv . -B $WD:/home . $DV_PATH . /opt/deepvariant/bin/train . --config=/home/dv_config.py:base . --config.train_dataset_pbtxt=""/home/examples_shuffled/train/All_samples_training_examples.dataset_config.pbtxt"" . --config.tune_dataset_pbtxt=""/home/examples_shuffled/tune/All_samples_tune_examples.dataset_config.pbtxt"". . --config.num_epochs=1 . --config.learning_rate=0.0001 . --config.num_validation_examples=0 . --config.tune_every_steps=2000 . --experiment_dir=/home/${OUTDIR} . --strategy=mirrored . --config.batch_size=64 . --config.init_checkpoint=""/home/model_wgs_v1.6.1/deepvariant.wgs.ckpt"". ```. Though previous runs had higher learning rates (0.01) and batch sizes (128). Training proceeds as follows:. Training Examples: 1454377. Batch Size: 64. Epochs: 1. Steps per epoch: 22724. Steps per tune: 3162. Num train steps: 22724. **Log file**. Here is the top of the log file, including some warnings in case they are relevant:. ```. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(. 2024-08-28 10:40:42.588215: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_SYSTEM_DRIVER_MISMATCH: system has unsupported display driver / cuda driver combination. I0828 10:40:42.589054 140318776715072 train.py:92] Running with debug=False. I0828 10:40:42.589343 140318776715072 train.py:100] Use TPU at local. I0828 10:40:42.589422 14",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:2600,safety,log,log,2600,"lly across samples, chromosomes and downsampling. . **Command**. My latest training run was like so:. ```. apptainer run . --nv . -B $WD:/home . $DV_PATH . /opt/deepvariant/bin/train . --config=/home/dv_config.py:base . --config.train_dataset_pbtxt=""/home/examples_shuffled/train/All_samples_training_examples.dataset_config.pbtxt"" . --config.tune_dataset_pbtxt=""/home/examples_shuffled/tune/All_samples_tune_examples.dataset_config.pbtxt"". . --config.num_epochs=1 . --config.learning_rate=0.0001 . --config.num_validation_examples=0 . --config.tune_every_steps=2000 . --experiment_dir=/home/${OUTDIR} . --strategy=mirrored . --config.batch_size=64 . --config.init_checkpoint=""/home/model_wgs_v1.6.1/deepvariant.wgs.ckpt"". ```. Though previous runs had higher learning rates (0.01) and batch sizes (128). Training proceeds as follows:. Training Examples: 1454377. Batch Size: 64. Epochs: 1. Steps per epoch: 22724. Steps per tune: 3162. Num train steps: 22724. **Log file**. Here is the top of the log file, including some warnings in case they are relevant:. ```. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(. 2024-08-28 10:40:42.588215: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_SYSTEM_DRIVER_MISMATCH: system has unsupported display driver / cuda driver combination. I0828 10:40:42.589054 140318776715072 train.py:92] Running with debug=False. I0828 10:40:42.589343 140318776715072 train.py:100] Use TPU at local. I0828 10:40:42.589422 140318776715072 train.py:103] experim",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:2982,safety,depend,dependencies,2982,"/tune/All_samples_tune_examples.dataset_config.pbtxt"". . --config.num_epochs=1 . --config.learning_rate=0.0001 . --config.num_validation_examples=0 . --config.tune_every_steps=2000 . --experiment_dir=/home/${OUTDIR} . --strategy=mirrored . --config.batch_size=64 . --config.init_checkpoint=""/home/model_wgs_v1.6.1/deepvariant.wgs.ckpt"". ```. Though previous runs had higher learning rates (0.01) and batch sizes (128). Training proceeds as follows:. Training Examples: 1454377. Batch Size: 64. Epochs: 1. Steps per epoch: 22724. Steps per tune: 3162. Num train steps: 22724. **Log file**. Here is the top of the log file, including some warnings in case they are relevant:. ```. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(. 2024-08-28 10:40:42.588215: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_SYSTEM_DRIVER_MISMATCH: system has unsupported display driver / cuda driver combination. I0828 10:40:42.589054 140318776715072 train.py:92] Running with debug=False. I0828 10:40:42.589343 140318776715072 train.py:100] Use TPU at local. I0828 10:40:42.589422 140318776715072 train.py:103] experiment_dir: /home/training_outs/epoch1/. WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce. W0828 10:40:42.596594 140318776715072 cross_device_ops.py:1387] There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce. INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',). ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:4265,safety,input,input,4265,"267] failed call to cuInit: CUDA_ERROR_SYSTEM_DRIVER_MISMATCH: system has unsupported display driver / cuda driver combination. I0828 10:40:42.589054 140318776715072 train.py:92] Running with debug=False. I0828 10:40:42.589343 140318776715072 train.py:100] Use TPU at local. I0828 10:40:42.589422 140318776715072 train.py:103] experiment_dir: /home/training_outs/epoch1/. WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce. W0828 10:40:42.596594 140318776715072 cross_device_ops.py:1387] There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce. INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',). I0828 10:40:42.658734 140318776715072 mirrored_strategy.py:374] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',). /usr/local/lib/python3.8/dist-packages/keras/applications/inception_v3.py:138: UserWarning: This model usually expects 1 or 3 input channels. However, it was passed an input_shape with 7 input channels. input_shape = imagenet_utils.obtain_input_shape(. I0828 10:40:47.952382 140318776715072 keras_modeling.py:325] Number of l2 regularizers: 95. I0828 10:40:48.007193 140318776715072 keras_modeling.py:362] inceptionv3: load_weights from checkpoint: /home/training_outs/epoch1//checkpoints/ckpt-5997. I0828 10:40:49.193293 140318776715072 train.py:191] Exponential Decay: initial_learning_rate=0.0001. decay_steps=45448. learning_rate_decay_rate=0.947. I0828 10:40:49.193522 140318776715072 train.py:203] Use LinearWarmup:. warmup_steps=10000. warmup_learning_rate=1e-05. I0828 10:40:49.401860 140318776715072 keras_modeling.py:472] Restored checkpoint ckpt-5997 at step=0. tune/f1_weighted=tf.Tensor(0.0, shape=(), dtype=float32). WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_ana",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:4326,safety,input,input,4326,": system has unsupported display driver / cuda driver combination. I0828 10:40:42.589054 140318776715072 train.py:92] Running with debug=False. I0828 10:40:42.589343 140318776715072 train.py:100] Use TPU at local. I0828 10:40:42.589422 140318776715072 train.py:103] experiment_dir: /home/training_outs/epoch1/. WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce. W0828 10:40:42.596594 140318776715072 cross_device_ops.py:1387] There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce. INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',). I0828 10:40:42.658734 140318776715072 mirrored_strategy.py:374] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',). /usr/local/lib/python3.8/dist-packages/keras/applications/inception_v3.py:138: UserWarning: This model usually expects 1 or 3 input channels. However, it was passed an input_shape with 7 input channels. input_shape = imagenet_utils.obtain_input_shape(. I0828 10:40:47.952382 140318776715072 keras_modeling.py:325] Number of l2 regularizers: 95. I0828 10:40:48.007193 140318776715072 keras_modeling.py:362] inceptionv3: load_weights from checkpoint: /home/training_outs/epoch1//checkpoints/ckpt-5997. I0828 10:40:49.193293 140318776715072 train.py:191] Exponential Decay: initial_learning_rate=0.0001. decay_steps=45448. learning_rate_decay_rate=0.947. I0828 10:40:49.193522 140318776715072 train.py:203] Use LinearWarmup:. warmup_steps=10000. warmup_learning_rate=1e-05. I0828 10:40:49.401860 140318776715072 keras_modeling.py:472] Restored checkpoint ckpt-5997 at step=0. tune/f1_weighted=tf.Tensor(0.0, shape=(), dtype=float32). WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:5353,safety,updat,updating,5353,"magenet_utils.obtain_input_shape(. I0828 10:40:47.952382 140318776715072 keras_modeling.py:325] Number of l2 regularizers: 95. I0828 10:40:48.007193 140318776715072 keras_modeling.py:362] inceptionv3: load_weights from checkpoint: /home/training_outs/epoch1//checkpoints/ckpt-5997. I0828 10:40:49.193293 140318776715072 train.py:191] Exponential Decay: initial_learning_rate=0.0001. decay_steps=45448. learning_rate_decay_rate=0.947. I0828 10:40:49.193522 140318776715072 train.py:203] Use LinearWarmup:. warmup_steps=10000. warmup_learning_rate=1e-05. I0828 10:40:49.401860 140318776715072 keras_modeling.py:472] Restored checkpoint ckpt-5997 at step=0. tune/f1_weighted=tf.Tensor(0.0, shape=(), dtype=float32). WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23. Instructions for updating:. Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089. W0828 10:40:49.488072 140318776715072 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be rem>. Instructions for updating:. Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089. 2024-08-28 10:40:49.893797: W tensorflow/core/framework/dataset.cc:769] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations. I0828 10:40:49.947995 140318776715072 train.py:316]. ```. And here is an excerpt of from a later ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:5841,safety,updat,updating,5841,"e LinearWarmup:. warmup_steps=10000. warmup_learning_rate=1e-05. I0828 10:40:49.401860 140318776715072 keras_modeling.py:472] Restored checkpoint ckpt-5997 at step=0. tune/f1_weighted=tf.Tensor(0.0, shape=(), dtype=float32). WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23. Instructions for updating:. Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089. W0828 10:40:49.488072 140318776715072 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be rem>. Instructions for updating:. Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089. 2024-08-28 10:40:49.893797: W tensorflow/core/framework/dataset.cc:769] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations. I0828 10:40:49.947995 140318776715072 train.py:316]. ```. And here is an excerpt of from a later portion of the log file including some training and tuning steps, where you can see the 0.0 for het and homalt eval stats. . ```. I0829 07:13:59.098341 140305134778112 logging_writer.py:48] [13700] epoch=0, train/categorical_accuracy=1.0, train/categorical_crossentropy=0.552009105682373, train/f1_het=0.0, train/f1_homalt=0.0, train/f1_homref=1.0, train/f1_macro=0.3333333432674408, train/f1_micro=1.0, train/f1_. weighted=1.0, train/false_negatives=0.0, train/false_positives=0.0, train",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:6099,safety,Input,Input,6099,"al/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23. Instructions for updating:. Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089. W0828 10:40:49.488072 140318776715072 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be rem>. Instructions for updating:. Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089. 2024-08-28 10:40:49.893797: W tensorflow/core/framework/dataset.cc:769] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations. I0828 10:40:49.947995 140318776715072 train.py:316]. ```. And here is an excerpt of from a later portion of the log file including some training and tuning steps, where you can see the 0.0 for het and homalt eval stats. . ```. I0829 07:13:59.098341 140305134778112 logging_writer.py:48] [13700] epoch=0, train/categorical_accuracy=1.0, train/categorical_crossentropy=0.552009105682373, train/f1_het=0.0, train/f1_homalt=0.0, train/f1_homref=1.0, train/f1_macro=0.3333333432674408, train/f1_micro=1.0, train/f1_. weighted=1.0, train/false_negatives=0.0, train/false_positives=0.0, train/learning_rate=9.999999747378752e-05, train/loss=0.5520098805427551, train/precision=1.0, train/precision_het=0.0, train/precision_homalt=0.0, train/precision_homref=1.0, train/recall=1.0, train/recall_het=0.0,. train/recall_homalt=0.0, train/recall_homref=",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:6372,safety,log,log,6372,"tions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089. W0828 10:40:49.488072 140318776715072 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be rem>. Instructions for updating:. Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089. 2024-08-28 10:40:49.893797: W tensorflow/core/framework/dataset.cc:769] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations. I0828 10:40:49.947995 140318776715072 train.py:316]. ```. And here is an excerpt of from a later portion of the log file including some training and tuning steps, where you can see the 0.0 for het and homalt eval stats. . ```. I0829 07:13:59.098341 140305134778112 logging_writer.py:48] [13700] epoch=0, train/categorical_accuracy=1.0, train/categorical_crossentropy=0.552009105682373, train/f1_het=0.0, train/f1_homalt=0.0, train/f1_homref=1.0, train/f1_macro=0.3333333432674408, train/f1_micro=1.0, train/f1_. weighted=1.0, train/false_negatives=0.0, train/false_positives=0.0, train/learning_rate=9.999999747378752e-05, train/loss=0.5520098805427551, train/precision=1.0, train/precision_het=0.0, train/precision_homalt=0.0, train/precision_homref=1.0, train/recall=1.0, train/recall_het=0.0,. train/recall_homalt=0.0, train/recall_homref=1.0, train/true_negatives=12800.0, train/true_positives=6400.0. I0829 07:18:37.609363 140318776715072 local.py:41] Setting work unit notes: 0.3 steps/s, 60.6% (13778/22724), ETA: 8h52m. I0829 07:18:37.611700 140305134778112 logging_writer.py:48] [13778] steps_per_sec=0.28",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:57,security,model,model,57,"No evaluation statistics for het and homalt calls during model training; Hello DV team, and thanks for creating such a great tool! . I am currently trying to retrain the wgs model for a new species (a fish) however, during training, I see no evaluation statistics (precision, recall, f1) for either het or homalt. Or more specifically they are all 0.0. Eval stats are reported for homref though. I have now tried running the training several times with different hyperparameters but so far still no change at the het or homalt eval stats. . My first, very simple question is thus, are these eval stats truly 0 (i.e. the model is very bad) or is 0.0 some starting value and there are not enough data to calculate them initially? I am warmstarting from the 1.6.1 wgs model so I cant imagine the model is really that bad at calling variants initially, even if in a fish. . **Setup**. Running on a university computing cluster (https://hpc-unibe-ch.github.io/) . OS: Rocky 9.3 Blue Onyx. GPU: rtx4090 . Installation: Running from Docker image via singularity. DV version: 1.6.1. **Data**. I am training on examples from 5 individuals, data from Illumina NovaSeq ~20x coverage. . 17/21 chromosomes used for training (~1.45M examples). 2/21 chromosomes used for tuning (~200k examples). 2/21 chromosomes reserved for testing. . (Different chromosomes used for train/tune/test across samples - see below). <img width=""1437"" alt=""Screenshot 2024-08-07 at 09 30 23"" src=""https://github.com/user-attachments/assets/3178e87a-8cf7-47cb-84a2-0a84d15c958f"">. **Shuffling**. Performed downsampling=0.5. Shuffled globally across samples, chromosomes and downsampling. . **Command**. My latest training run was like so:. ```. apptainer run . --nv . -B $WD:/home . $DV_PATH . /opt/deepvariant/bin/train . --config=/home/dv_config.py:base . --config.train_dataset_pbtxt=""/home/examples_shuffled/train/All_samples_training_examples.dataset_config.pbtxt"" . --config.tune_dataset_pbtxt=""/home/examples_shuffled/tune/All_sa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:82,security,team,team,82,"No evaluation statistics for het and homalt calls during model training; Hello DV team, and thanks for creating such a great tool! . I am currently trying to retrain the wgs model for a new species (a fish) however, during training, I see no evaluation statistics (precision, recall, f1) for either het or homalt. Or more specifically they are all 0.0. Eval stats are reported for homref though. I have now tried running the training several times with different hyperparameters but so far still no change at the het or homalt eval stats. . My first, very simple question is thus, are these eval stats truly 0 (i.e. the model is very bad) or is 0.0 some starting value and there are not enough data to calculate them initially? I am warmstarting from the 1.6.1 wgs model so I cant imagine the model is really that bad at calling variants initially, even if in a fish. . **Setup**. Running on a university computing cluster (https://hpc-unibe-ch.github.io/) . OS: Rocky 9.3 Blue Onyx. GPU: rtx4090 . Installation: Running from Docker image via singularity. DV version: 1.6.1. **Data**. I am training on examples from 5 individuals, data from Illumina NovaSeq ~20x coverage. . 17/21 chromosomes used for training (~1.45M examples). 2/21 chromosomes used for tuning (~200k examples). 2/21 chromosomes reserved for testing. . (Different chromosomes used for train/tune/test across samples - see below). <img width=""1437"" alt=""Screenshot 2024-08-07 at 09 30 23"" src=""https://github.com/user-attachments/assets/3178e87a-8cf7-47cb-84a2-0a84d15c958f"">. **Shuffling**. Performed downsampling=0.5. Shuffled globally across samples, chromosomes and downsampling. . **Command**. My latest training run was like so:. ```. apptainer run . --nv . -B $WD:/home . $DV_PATH . /opt/deepvariant/bin/train . --config=/home/dv_config.py:base . --config.train_dataset_pbtxt=""/home/examples_shuffled/train/All_samples_training_examples.dataset_config.pbtxt"" . --config.tune_dataset_pbtxt=""/home/examples_shuffled/tune/All_sa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:174,security,model,model,174,"No evaluation statistics for het and homalt calls during model training; Hello DV team, and thanks for creating such a great tool! . I am currently trying to retrain the wgs model for a new species (a fish) however, during training, I see no evaluation statistics (precision, recall, f1) for either het or homalt. Or more specifically they are all 0.0. Eval stats are reported for homref though. I have now tried running the training several times with different hyperparameters but so far still no change at the het or homalt eval stats. . My first, very simple question is thus, are these eval stats truly 0 (i.e. the model is very bad) or is 0.0 some starting value and there are not enough data to calculate them initially? I am warmstarting from the 1.6.1 wgs model so I cant imagine the model is really that bad at calling variants initially, even if in a fish. . **Setup**. Running on a university computing cluster (https://hpc-unibe-ch.github.io/) . OS: Rocky 9.3 Blue Onyx. GPU: rtx4090 . Installation: Running from Docker image via singularity. DV version: 1.6.1. **Data**. I am training on examples from 5 individuals, data from Illumina NovaSeq ~20x coverage. . 17/21 chromosomes used for training (~1.45M examples). 2/21 chromosomes used for tuning (~200k examples). 2/21 chromosomes reserved for testing. . (Different chromosomes used for train/tune/test across samples - see below). <img width=""1437"" alt=""Screenshot 2024-08-07 at 09 30 23"" src=""https://github.com/user-attachments/assets/3178e87a-8cf7-47cb-84a2-0a84d15c958f"">. **Shuffling**. Performed downsampling=0.5. Shuffled globally across samples, chromosomes and downsampling. . **Command**. My latest training run was like so:. ```. apptainer run . --nv . -B $WD:/home . $DV_PATH . /opt/deepvariant/bin/train . --config=/home/dv_config.py:base . --config.train_dataset_pbtxt=""/home/examples_shuffled/train/All_samples_training_examples.dataset_config.pbtxt"" . --config.tune_dataset_pbtxt=""/home/examples_shuffled/tune/All_sa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:620,security,model,model,620,"No evaluation statistics for het and homalt calls during model training; Hello DV team, and thanks for creating such a great tool! . I am currently trying to retrain the wgs model for a new species (a fish) however, during training, I see no evaluation statistics (precision, recall, f1) for either het or homalt. Or more specifically they are all 0.0. Eval stats are reported for homref though. I have now tried running the training several times with different hyperparameters but so far still no change at the het or homalt eval stats. . My first, very simple question is thus, are these eval stats truly 0 (i.e. the model is very bad) or is 0.0 some starting value and there are not enough data to calculate them initially? I am warmstarting from the 1.6.1 wgs model so I cant imagine the model is really that bad at calling variants initially, even if in a fish. . **Setup**. Running on a university computing cluster (https://hpc-unibe-ch.github.io/) . OS: Rocky 9.3 Blue Onyx. GPU: rtx4090 . Installation: Running from Docker image via singularity. DV version: 1.6.1. **Data**. I am training on examples from 5 individuals, data from Illumina NovaSeq ~20x coverage. . 17/21 chromosomes used for training (~1.45M examples). 2/21 chromosomes used for tuning (~200k examples). 2/21 chromosomes reserved for testing. . (Different chromosomes used for train/tune/test across samples - see below). <img width=""1437"" alt=""Screenshot 2024-08-07 at 09 30 23"" src=""https://github.com/user-attachments/assets/3178e87a-8cf7-47cb-84a2-0a84d15c958f"">. **Shuffling**. Performed downsampling=0.5. Shuffled globally across samples, chromosomes and downsampling. . **Command**. My latest training run was like so:. ```. apptainer run . --nv . -B $WD:/home . $DV_PATH . /opt/deepvariant/bin/train . --config=/home/dv_config.py:base . --config.train_dataset_pbtxt=""/home/examples_shuffled/train/All_samples_training_examples.dataset_config.pbtxt"" . --config.tune_dataset_pbtxt=""/home/examples_shuffled/tune/All_sa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:765,security,model,model,765,"No evaluation statistics for het and homalt calls during model training; Hello DV team, and thanks for creating such a great tool! . I am currently trying to retrain the wgs model for a new species (a fish) however, during training, I see no evaluation statistics (precision, recall, f1) for either het or homalt. Or more specifically they are all 0.0. Eval stats are reported for homref though. I have now tried running the training several times with different hyperparameters but so far still no change at the het or homalt eval stats. . My first, very simple question is thus, are these eval stats truly 0 (i.e. the model is very bad) or is 0.0 some starting value and there are not enough data to calculate them initially? I am warmstarting from the 1.6.1 wgs model so I cant imagine the model is really that bad at calling variants initially, even if in a fish. . **Setup**. Running on a university computing cluster (https://hpc-unibe-ch.github.io/) . OS: Rocky 9.3 Blue Onyx. GPU: rtx4090 . Installation: Running from Docker image via singularity. DV version: 1.6.1. **Data**. I am training on examples from 5 individuals, data from Illumina NovaSeq ~20x coverage. . 17/21 chromosomes used for training (~1.45M examples). 2/21 chromosomes used for tuning (~200k examples). 2/21 chromosomes reserved for testing. . (Different chromosomes used for train/tune/test across samples - see below). <img width=""1437"" alt=""Screenshot 2024-08-07 at 09 30 23"" src=""https://github.com/user-attachments/assets/3178e87a-8cf7-47cb-84a2-0a84d15c958f"">. **Shuffling**. Performed downsampling=0.5. Shuffled globally across samples, chromosomes and downsampling. . **Command**. My latest training run was like so:. ```. apptainer run . --nv . -B $WD:/home . $DV_PATH . /opt/deepvariant/bin/train . --config=/home/dv_config.py:base . --config.train_dataset_pbtxt=""/home/examples_shuffled/train/All_samples_training_examples.dataset_config.pbtxt"" . --config.tune_dataset_pbtxt=""/home/examples_shuffled/tune/All_sa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:793,security,model,model,793,"No evaluation statistics for het and homalt calls during model training; Hello DV team, and thanks for creating such a great tool! . I am currently trying to retrain the wgs model for a new species (a fish) however, during training, I see no evaluation statistics (precision, recall, f1) for either het or homalt. Or more specifically they are all 0.0. Eval stats are reported for homref though. I have now tried running the training several times with different hyperparameters but so far still no change at the het or homalt eval stats. . My first, very simple question is thus, are these eval stats truly 0 (i.e. the model is very bad) or is 0.0 some starting value and there are not enough data to calculate them initially? I am warmstarting from the 1.6.1 wgs model so I cant imagine the model is really that bad at calling variants initially, even if in a fish. . **Setup**. Running on a university computing cluster (https://hpc-unibe-ch.github.io/) . OS: Rocky 9.3 Blue Onyx. GPU: rtx4090 . Installation: Running from Docker image via singularity. DV version: 1.6.1. **Data**. I am training on examples from 5 individuals, data from Illumina NovaSeq ~20x coverage. . 17/21 chromosomes used for training (~1.45M examples). 2/21 chromosomes used for tuning (~200k examples). 2/21 chromosomes reserved for testing. . (Different chromosomes used for train/tune/test across samples - see below). <img width=""1437"" alt=""Screenshot 2024-08-07 at 09 30 23"" src=""https://github.com/user-attachments/assets/3178e87a-8cf7-47cb-84a2-0a84d15c958f"">. **Shuffling**. Performed downsampling=0.5. Shuffled globally across samples, chromosomes and downsampling. . **Command**. My latest training run was like so:. ```. apptainer run . --nv . -B $WD:/home . $DV_PATH . /opt/deepvariant/bin/train . --config=/home/dv_config.py:base . --config.train_dataset_pbtxt=""/home/examples_shuffled/train/All_samples_training_examples.dataset_config.pbtxt"" . --config.tune_dataset_pbtxt=""/home/examples_shuffled/tune/All_sa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:2565,security,Log,Log,2565,"ed downsampling=0.5. Shuffled globally across samples, chromosomes and downsampling. . **Command**. My latest training run was like so:. ```. apptainer run . --nv . -B $WD:/home . $DV_PATH . /opt/deepvariant/bin/train . --config=/home/dv_config.py:base . --config.train_dataset_pbtxt=""/home/examples_shuffled/train/All_samples_training_examples.dataset_config.pbtxt"" . --config.tune_dataset_pbtxt=""/home/examples_shuffled/tune/All_samples_tune_examples.dataset_config.pbtxt"". . --config.num_epochs=1 . --config.learning_rate=0.0001 . --config.num_validation_examples=0 . --config.tune_every_steps=2000 . --experiment_dir=/home/${OUTDIR} . --strategy=mirrored . --config.batch_size=64 . --config.init_checkpoint=""/home/model_wgs_v1.6.1/deepvariant.wgs.ckpt"". ```. Though previous runs had higher learning rates (0.01) and batch sizes (128). Training proceeds as follows:. Training Examples: 1454377. Batch Size: 64. Epochs: 1. Steps per epoch: 22724. Steps per tune: 3162. Num train steps: 22724. **Log file**. Here is the top of the log file, including some warnings in case they are relevant:. ```. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(. 2024-08-28 10:40:42.588215: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_SYSTEM_DRIVER_MISMATCH: system has unsupported display driver / cuda driver combination. I0828 10:40:42.589054 140318776715072 train.py:92] Running with debug=False. I0828 10:40:42.589343 140318776715072 train.py:100] Use TPU at local. I0828 10:40:42.589422 14",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:2600,security,log,log,2600,"lly across samples, chromosomes and downsampling. . **Command**. My latest training run was like so:. ```. apptainer run . --nv . -B $WD:/home . $DV_PATH . /opt/deepvariant/bin/train . --config=/home/dv_config.py:base . --config.train_dataset_pbtxt=""/home/examples_shuffled/train/All_samples_training_examples.dataset_config.pbtxt"" . --config.tune_dataset_pbtxt=""/home/examples_shuffled/tune/All_samples_tune_examples.dataset_config.pbtxt"". . --config.num_epochs=1 . --config.learning_rate=0.0001 . --config.num_validation_examples=0 . --config.tune_every_steps=2000 . --experiment_dir=/home/${OUTDIR} . --strategy=mirrored . --config.batch_size=64 . --config.init_checkpoint=""/home/model_wgs_v1.6.1/deepvariant.wgs.ckpt"". ```. Though previous runs had higher learning rates (0.01) and batch sizes (128). Training proceeds as follows:. Training Examples: 1454377. Batch Size: 64. Epochs: 1. Steps per epoch: 22724. Steps per tune: 3162. Num train steps: 22724. **Log file**. Here is the top of the log file, including some warnings in case they are relevant:. ```. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(. 2024-08-28 10:40:42.588215: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_SYSTEM_DRIVER_MISMATCH: system has unsupported display driver / cuda driver combination. I0828 10:40:42.589054 140318776715072 train.py:92] Running with debug=False. I0828 10:40:42.589343 140318776715072 train.py:100] Use TPU at local. I0828 10:40:42.589422 140318776715072 train.py:103] experim",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:2946,security,modif,modify,2946,"_dataset_pbtxt=""/home/examples_shuffled/tune/All_samples_tune_examples.dataset_config.pbtxt"". . --config.num_epochs=1 . --config.learning_rate=0.0001 . --config.num_validation_examples=0 . --config.tune_every_steps=2000 . --experiment_dir=/home/${OUTDIR} . --strategy=mirrored . --config.batch_size=64 . --config.init_checkpoint=""/home/model_wgs_v1.6.1/deepvariant.wgs.ckpt"". ```. Though previous runs had higher learning rates (0.01) and batch sizes (128). Training proceeds as follows:. Training Examples: 1454377. Batch Size: 64. Epochs: 1. Steps per epoch: 22724. Steps per tune: 3162. Num train steps: 22724. **Log file**. Here is the top of the log file, including some warnings in case they are relevant:. ```. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(. 2024-08-28 10:40:42.588215: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_SYSTEM_DRIVER_MISMATCH: system has unsupported display driver / cuda driver combination. I0828 10:40:42.589054 140318776715072 train.py:92] Running with debug=False. I0828 10:40:42.589343 140318776715072 train.py:100] Use TPU at local. I0828 10:40:42.589422 140318776715072 train.py:103] experiment_dir: /home/training_outs/epoch1/. WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce. W0828 10:40:42.596594 140318776715072 cross_device_ops.py:1387] There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce. INFO:tensorflow:Using MirroredStrategy with devices ('/job:local",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:4236,security,model,model,4236,"executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_SYSTEM_DRIVER_MISMATCH: system has unsupported display driver / cuda driver combination. I0828 10:40:42.589054 140318776715072 train.py:92] Running with debug=False. I0828 10:40:42.589343 140318776715072 train.py:100] Use TPU at local. I0828 10:40:42.589422 140318776715072 train.py:103] experiment_dir: /home/training_outs/epoch1/. WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce. W0828 10:40:42.596594 140318776715072 cross_device_ops.py:1387] There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce. INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',). I0828 10:40:42.658734 140318776715072 mirrored_strategy.py:374] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',). /usr/local/lib/python3.8/dist-packages/keras/applications/inception_v3.py:138: UserWarning: This model usually expects 1 or 3 input channels. However, it was passed an input_shape with 7 input channels. input_shape = imagenet_utils.obtain_input_shape(. I0828 10:40:47.952382 140318776715072 keras_modeling.py:325] Number of l2 regularizers: 95. I0828 10:40:48.007193 140318776715072 keras_modeling.py:362] inceptionv3: load_weights from checkpoint: /home/training_outs/epoch1//checkpoints/ckpt-5997. I0828 10:40:49.193293 140318776715072 train.py:191] Exponential Decay: initial_learning_rate=0.0001. decay_steps=45448. learning_rate_decay_rate=0.947. I0828 10:40:49.193522 140318776715072 train.py:203] Use LinearWarmup:. warmup_steps=10000. warmup_learning_rate=1e-05. I0828 10:40:49.401860 140318776715072 keras_modeling.py:472] Restored checkpoint ckpt-5997 at step=0. tune/f1_weighted=tf.Tensor(0.0, shape=(), dtype=float32). WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.pyt",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:5353,security,updat,updating,5353,"magenet_utils.obtain_input_shape(. I0828 10:40:47.952382 140318776715072 keras_modeling.py:325] Number of l2 regularizers: 95. I0828 10:40:48.007193 140318776715072 keras_modeling.py:362] inceptionv3: load_weights from checkpoint: /home/training_outs/epoch1//checkpoints/ckpt-5997. I0828 10:40:49.193293 140318776715072 train.py:191] Exponential Decay: initial_learning_rate=0.0001. decay_steps=45448. learning_rate_decay_rate=0.947. I0828 10:40:49.193522 140318776715072 train.py:203] Use LinearWarmup:. warmup_steps=10000. warmup_learning_rate=1e-05. I0828 10:40:49.401860 140318776715072 keras_modeling.py:472] Restored checkpoint ckpt-5997 at step=0. tune/f1_weighted=tf.Tensor(0.0, shape=(), dtype=float32). WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23. Instructions for updating:. Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089. W0828 10:40:49.488072 140318776715072 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be rem>. Instructions for updating:. Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089. 2024-08-28 10:40:49.893797: W tensorflow/core/framework/dataset.cc:769] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations. I0828 10:40:49.947995 140318776715072 train.py:316]. ```. And here is an excerpt of from a later ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:5841,security,updat,updating,5841,"e LinearWarmup:. warmup_steps=10000. warmup_learning_rate=1e-05. I0828 10:40:49.401860 140318776715072 keras_modeling.py:472] Restored checkpoint ckpt-5997 at step=0. tune/f1_weighted=tf.Tensor(0.0, shape=(), dtype=float32). WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23. Instructions for updating:. Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089. W0828 10:40:49.488072 140318776715072 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be rem>. Instructions for updating:. Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089. 2024-08-28 10:40:49.893797: W tensorflow/core/framework/dataset.cc:769] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations. I0828 10:40:49.947995 140318776715072 train.py:316]. ```. And here is an excerpt of from a later portion of the log file including some training and tuning steps, where you can see the 0.0 for het and homalt eval stats. . ```. I0829 07:13:59.098341 140305134778112 logging_writer.py:48] [13700] epoch=0, train/categorical_accuracy=1.0, train/categorical_crossentropy=0.552009105682373, train/f1_het=0.0, train/f1_homalt=0.0, train/f1_homref=1.0, train/f1_macro=0.3333333432674408, train/f1_micro=1.0, train/f1_. weighted=1.0, train/false_negatives=0.0, train/false_positives=0.0, train",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:6372,security,log,log,6372,"tions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089. W0828 10:40:49.488072 140318776715072 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be rem>. Instructions for updating:. Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089. 2024-08-28 10:40:49.893797: W tensorflow/core/framework/dataset.cc:769] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations. I0828 10:40:49.947995 140318776715072 train.py:316]. ```. And here is an excerpt of from a later portion of the log file including some training and tuning steps, where you can see the 0.0 for het and homalt eval stats. . ```. I0829 07:13:59.098341 140305134778112 logging_writer.py:48] [13700] epoch=0, train/categorical_accuracy=1.0, train/categorical_crossentropy=0.552009105682373, train/f1_het=0.0, train/f1_homalt=0.0, train/f1_homref=1.0, train/f1_macro=0.3333333432674408, train/f1_micro=1.0, train/f1_. weighted=1.0, train/false_negatives=0.0, train/false_positives=0.0, train/learning_rate=9.999999747378752e-05, train/loss=0.5520098805427551, train/precision=1.0, train/precision_het=0.0, train/precision_homalt=0.0, train/precision_homref=1.0, train/recall=1.0, train/recall_het=0.0,. train/recall_homalt=0.0, train/recall_homref=1.0, train/true_negatives=12800.0, train/true_positives=6400.0. I0829 07:18:37.609363 140318776715072 local.py:41] Setting work unit notes: 0.3 steps/s, 60.6% (13778/22724), ETA: 8h52m. I0829 07:18:37.611700 140305134778112 logging_writer.py:48] [13778] steps_per_sec=0.28",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:6889,security,loss,loss,6889," to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089. 2024-08-28 10:40:49.893797: W tensorflow/core/framework/dataset.cc:769] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations. I0828 10:40:49.947995 140318776715072 train.py:316]. ```. And here is an excerpt of from a later portion of the log file including some training and tuning steps, where you can see the 0.0 for het and homalt eval stats. . ```. I0829 07:13:59.098341 140305134778112 logging_writer.py:48] [13700] epoch=0, train/categorical_accuracy=1.0, train/categorical_crossentropy=0.552009105682373, train/f1_het=0.0, train/f1_homalt=0.0, train/f1_homref=1.0, train/f1_macro=0.3333333432674408, train/f1_micro=1.0, train/f1_. weighted=1.0, train/false_negatives=0.0, train/false_positives=0.0, train/learning_rate=9.999999747378752e-05, train/loss=0.5520098805427551, train/precision=1.0, train/precision_het=0.0, train/precision_homalt=0.0, train/precision_homref=1.0, train/recall=1.0, train/recall_het=0.0,. train/recall_homalt=0.0, train/recall_homref=1.0, train/true_negatives=12800.0, train/true_positives=6400.0. I0829 07:18:37.609363 140318776715072 local.py:41] Setting work unit notes: 0.3 steps/s, 60.6% (13778/22724), ETA: 8h52m. I0829 07:18:37.611700 140305134778112 logging_writer.py:48] [13778] steps_per_sec=0.280118. I0829 07:18:37.611787 140305134778112 logging_writer.py:48] [13778] uptime=74267.6. I0829 07:19:56.116713 140305134778112 logging_writer.py:48] [13800] epoch=0, train/categorical_accuracy=1.0, train/categorical_crossentropy=0.5520044565200806, train/f1_het=0.0, train/f1_homalt=0.0, train/f1_homref=1.0, train/f1_macro=0.3333333432674408, train/f1_micro=1.0, train/f1_weighted=1.0, train/false_negatives=0.0, train/false_positives=0.0, train/learning_rate=9.999999747378752e-05, train/loss=0.5520052909851074, t",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:7865,security,loss,loss,7865,"9747378752e-05, train/loss=0.5520098805427551, train/precision=1.0, train/precision_het=0.0, train/precision_homalt=0.0, train/precision_homref=1.0, train/recall=1.0, train/recall_het=0.0,. train/recall_homalt=0.0, train/recall_homref=1.0, train/true_negatives=12800.0, train/true_positives=6400.0. I0829 07:18:37.609363 140318776715072 local.py:41] Setting work unit notes: 0.3 steps/s, 60.6% (13778/22724), ETA: 8h52m. I0829 07:18:37.611700 140305134778112 logging_writer.py:48] [13778] steps_per_sec=0.280118. I0829 07:18:37.611787 140305134778112 logging_writer.py:48] [13778] uptime=74267.6. I0829 07:19:56.116713 140305134778112 logging_writer.py:48] [13800] epoch=0, train/categorical_accuracy=1.0, train/categorical_crossentropy=0.5520044565200806, train/f1_het=0.0, train/f1_homalt=0.0, train/f1_homref=1.0, train/f1_macro=0.3333333432674408, train/f1_micro=1.0, train/f1_weighted=1.0, train/false_negatives=0.0, train/false_positives=0.0, train/learning_rate=9.999999747378752e-05, train/loss=0.5520052909851074, train/precision=1.0, train/precision_het=0.0, train/precision_homalt=0.0, train/precision_homref=1.0, train/recall=1.0, train/recall_het=0.0, train/recall_homalt=0.0, train/recall_homref=1.0, train/true_negatives=12800.0, train/true_positives=6400.0. I0829 07:23:41.076397 140318776715072 local.py:41] Setting work unit notes: 0.3 steps/s, 61.0% (13863/22724), ETA: 8h47m. I0829 07:23:41.078737 140305134778112 logging_writer.py:48] [13863] steps_per_sec=0.280096. I0829 07:23:41.078827 140305134778112 logging_writer.py:48] [13863] uptime=74571.1. I0829 07:25:53.180995 140305134778112 logging_writer.py:48] [13900] epoch=0, train/categorical_accuracy=1.0, train/categorical_crossentropy=0.5519936680793762, train/f1_het=0.0, train/f1_homalt=0.0, train/f1_homref=1.0, train/f1_macro=0.3333333432674408, train/f1_micro=1.0, train/f1_weighted=1.0, train/false_negatives=0.0, train/false_positives=0.0, train/learning_rate=9.999999747378752e-05, train/loss=0.5519945025444031, tr",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:8840,security,loss,loss,8840,"99747378752e-05, train/loss=0.5520052909851074, train/precision=1.0, train/precision_het=0.0, train/precision_homalt=0.0, train/precision_homref=1.0, train/recall=1.0, train/recall_het=0.0, train/recall_homalt=0.0, train/recall_homref=1.0, train/true_negatives=12800.0, train/true_positives=6400.0. I0829 07:23:41.076397 140318776715072 local.py:41] Setting work unit notes: 0.3 steps/s, 61.0% (13863/22724), ETA: 8h47m. I0829 07:23:41.078737 140305134778112 logging_writer.py:48] [13863] steps_per_sec=0.280096. I0829 07:23:41.078827 140305134778112 logging_writer.py:48] [13863] uptime=74571.1. I0829 07:25:53.180995 140305134778112 logging_writer.py:48] [13900] epoch=0, train/categorical_accuracy=1.0, train/categorical_crossentropy=0.5519936680793762, train/f1_het=0.0, train/f1_homalt=0.0, train/f1_homref=1.0, train/f1_macro=0.3333333432674408, train/f1_micro=1.0, train/f1_weighted=1.0, train/false_negatives=0.0, train/false_positives=0.0, train/learning_rate=9.999999747378752e-05, train/loss=0.5519945025444031, train/precision=1.0, train/precision_het=0.0, train/precision_homalt=0.0, train/precision_homref=1.0, train/recall=1.0, train/recall_het=0.0, train/recall_homalt=0.0, train/recall_homref=1.0, train/true_negatives=12800.0, train/true_positives=6400.0. I0829 07:28:44.566404 140318776715072 local.py:41] Setting work unit notes: 0.3 steps/s, 61.4% (13948/22724), ETA: 8h42m. I0829 07:28:44.568708 140305134778112 logging_writer.py:48] [13948] steps_per_sec=0.280075. I0829 07:28:44.568793 140305134778112 logging_writer.py:48] [13948] uptime=74874.6. I0829 07:31:25.151819 140318776715072 train.py:361] Running tune at step=13993 epoch=0. I0829 07:31:25.152109 140318776715072 train.py:366] Tune step 0 / 3162 (0.0%). I0829 07:33:17.573163 140318776715072 train.py:366] Tune step 100 / 3162 (0.0%). I0829 07:35:10.013494 140318776715072 train.py:366] Tune step 200 / 3162 (10.0%). I0829 07:37:02.497336 140318776715072 train.py:366] Tune step 300 / 3162 (10.0%). I0829 07:38:54.8",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:12553,security,loss,loss,12553,"80.0%). I0829 08:18:17.252759 140318776715072 train.py:366] Tune step 2500 / 3162 (80.0%). I0829 08:20:09.823046 140318776715072 train.py:366] Tune step 2600 / 3162 (80.0%). I0829 08:22:02.367495 140318776715072 train.py:366] Tune step 2700 / 3162 (90.0%). I0829 08:23:54.783612 140318776715072 train.py:366] Tune step 2800 / 3162 (90.0%). I0829 08:25:47.336242 140318776715072 train.py:366] Tune step 2900 / 3162 (90.0%). I0829 08:27:39.775715 140318776715072 train.py:366] Tune step 3000 / 3162 (90.0%). I0829 08:29:29.592094 140318776715072 train.py:366] Tune step 3100 / 3162 (100.0%). I0829 08:30:42.583051 140305134778112 logging_writer.py:48] [13993] tune/categorical_accuracy=0.9916982650756836, tune/categorical_crossentropy=0.560210645198822, tune/f1_het=0.0, tune/f1_homalt=0.0, tune/f1_homref=0.9958318471908569, tune/f1_macro=0.33194395899772644, tune/f1_micro=0.9916982650756836, tune/f1_weighted=0.9958318471908569, tune/false_negatives_1=1777.0, tune/false_positives_1=1544.0, tune/loss=0.5603554248809814, tune/precision_1=0.9923615455627441, tune/precision_het=0.0, tune/precision_homalt=0.0, tune/precision_homref=1.0, tune/recall_1=0.9912189841270447, tune/recall_het=0.0, tune/recall_homalt=0.0, tune/recall_homref=0.9912189841270447, tune/true_negatives_1=403192.0, tune/true_positives_1=200591.0. I0829 08:30:42.590469 140318776715072 train.py:471] Skipping checkpoint with tune/f1_weighted=0.99583185 < previous best tune/f1_weighted=0.99845344. I0829 08:30:42.595992 140305134778112 logging_writer.py:48] [13993] tune/early_stopping=7. I0829 08:30:46.123329 140318776715072 local.py:41] Setting work unit notes: 0.0 steps/s, 61.6% (13994/22724), ETA: 8d4h11m. I0829 08:30:46.125013 140305134778112 logging_writer.py:48] [13994] steps_per_sec=0.0123604. I0829 08:30:46.125087 140305134778112 logging_writer.py:48] [13994] uptime=78596.1. I0829 08:31:07.673585 140305134778112 logging_writer.py:48] [14000] epoch=0, train/categorical_accuracy=1.0, train/categorical_crossentrop",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:13818,security,loss,loss,13818,"ne/loss=0.5603554248809814, tune/precision_1=0.9923615455627441, tune/precision_het=0.0, tune/precision_homalt=0.0, tune/precision_homref=1.0, tune/recall_1=0.9912189841270447, tune/recall_het=0.0, tune/recall_homalt=0.0, tune/recall_homref=0.9912189841270447, tune/true_negatives_1=403192.0, tune/true_positives_1=200591.0. I0829 08:30:42.590469 140318776715072 train.py:471] Skipping checkpoint with tune/f1_weighted=0.99583185 < previous best tune/f1_weighted=0.99845344. I0829 08:30:42.595992 140305134778112 logging_writer.py:48] [13993] tune/early_stopping=7. I0829 08:30:46.123329 140318776715072 local.py:41] Setting work unit notes: 0.0 steps/s, 61.6% (13994/22724), ETA: 8d4h11m. I0829 08:30:46.125013 140305134778112 logging_writer.py:48] [13994] steps_per_sec=0.0123604. I0829 08:30:46.125087 140305134778112 logging_writer.py:48] [13994] uptime=78596.1. I0829 08:31:07.673585 140305134778112 logging_writer.py:48] [14000] epoch=0, train/categorical_accuracy=1.0, train/categorical_crossentropy=0.5519920587539673, train/f1_het=0.0, train/f1_homalt=0.0, train/f1_homref=1.0, train/f1_macro=0.3333333432674408, train/f1_micro=1.0, train/f1_weighted=1.0, train/false_negatives=0.0, train/false_positives=0.0, train/learning_rate=9.999999747378752e-05, train/loss=0.551992654800415, train/precision=1.0, train/precision_het=0.0, train/precision_homalt=0.0, train/precision_homref=1.0, train/recall=1.0, train/recall_het=0.0, train/recall_homalt=0.0, train/recall_homref=1.0, train/true_negatives=12800.0, train/true_positives=6400.0. ```. I am new to Deep Learning and am struggling to decide whether something is wrong with my training approach/scripts or whether the model just needs more time / different hyperparams. Given the number of examples, I can only run 1 epoch at a time before I hit the 24hr cluster wall-time limit. So I have only trained for around 30,000 steps in total across 2 epochs so far (starting from last checkpoint after 1st epoch). . All advice much appreciated! .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:14228,security,model,model,14228,"ne/loss=0.5603554248809814, tune/precision_1=0.9923615455627441, tune/precision_het=0.0, tune/precision_homalt=0.0, tune/precision_homref=1.0, tune/recall_1=0.9912189841270447, tune/recall_het=0.0, tune/recall_homalt=0.0, tune/recall_homref=0.9912189841270447, tune/true_negatives_1=403192.0, tune/true_positives_1=200591.0. I0829 08:30:42.590469 140318776715072 train.py:471] Skipping checkpoint with tune/f1_weighted=0.99583185 < previous best tune/f1_weighted=0.99845344. I0829 08:30:42.595992 140305134778112 logging_writer.py:48] [13993] tune/early_stopping=7. I0829 08:30:46.123329 140318776715072 local.py:41] Setting work unit notes: 0.0 steps/s, 61.6% (13994/22724), ETA: 8d4h11m. I0829 08:30:46.125013 140305134778112 logging_writer.py:48] [13994] steps_per_sec=0.0123604. I0829 08:30:46.125087 140305134778112 logging_writer.py:48] [13994] uptime=78596.1. I0829 08:31:07.673585 140305134778112 logging_writer.py:48] [14000] epoch=0, train/categorical_accuracy=1.0, train/categorical_crossentropy=0.5519920587539673, train/f1_het=0.0, train/f1_homalt=0.0, train/f1_homref=1.0, train/f1_macro=0.3333333432674408, train/f1_micro=1.0, train/f1_weighted=1.0, train/false_negatives=0.0, train/false_positives=0.0, train/learning_rate=9.999999747378752e-05, train/loss=0.551992654800415, train/precision=1.0, train/precision_het=0.0, train/precision_homalt=0.0, train/precision_homref=1.0, train/recall=1.0, train/recall_het=0.0, train/recall_homalt=0.0, train/recall_homref=1.0, train/true_negatives=12800.0, train/true_positives=6400.0. ```. I am new to Deep Learning and am struggling to decide whether something is wrong with my training approach/scripts or whether the model just needs more time / different hyperparams. Given the number of examples, I can only run 1 epoch at a time before I hit the 24hr cluster wall-time limit. So I have only trained for around 30,000 steps in total across 2 epochs so far (starting from last checkpoint after 1st epoch). . All advice much appreciated! .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:556,testability,simpl,simple,556,"No evaluation statistics for het and homalt calls during model training; Hello DV team, and thanks for creating such a great tool! . I am currently trying to retrain the wgs model for a new species (a fish) however, during training, I see no evaluation statistics (precision, recall, f1) for either het or homalt. Or more specifically they are all 0.0. Eval stats are reported for homref though. I have now tried running the training several times with different hyperparameters but so far still no change at the het or homalt eval stats. . My first, very simple question is thus, are these eval stats truly 0 (i.e. the model is very bad) or is 0.0 some starting value and there are not enough data to calculate them initially? I am warmstarting from the 1.6.1 wgs model so I cant imagine the model is really that bad at calling variants initially, even if in a fish. . **Setup**. Running on a university computing cluster (https://hpc-unibe-ch.github.io/) . OS: Rocky 9.3 Blue Onyx. GPU: rtx4090 . Installation: Running from Docker image via singularity. DV version: 1.6.1. **Data**. I am training on examples from 5 individuals, data from Illumina NovaSeq ~20x coverage. . 17/21 chromosomes used for training (~1.45M examples). 2/21 chromosomes used for tuning (~200k examples). 2/21 chromosomes reserved for testing. . (Different chromosomes used for train/tune/test across samples - see below). <img width=""1437"" alt=""Screenshot 2024-08-07 at 09 30 23"" src=""https://github.com/user-attachments/assets/3178e87a-8cf7-47cb-84a2-0a84d15c958f"">. **Shuffling**. Performed downsampling=0.5. Shuffled globally across samples, chromosomes and downsampling. . **Command**. My latest training run was like so:. ```. apptainer run . --nv . -B $WD:/home . $DV_PATH . /opt/deepvariant/bin/train . --config=/home/dv_config.py:base . --config.train_dataset_pbtxt=""/home/examples_shuffled/train/All_samples_training_examples.dataset_config.pbtxt"" . --config.tune_dataset_pbtxt=""/home/examples_shuffled/tune/All_sa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:1163,testability,coverag,coverage,1163,"he wgs model for a new species (a fish) however, during training, I see no evaluation statistics (precision, recall, f1) for either het or homalt. Or more specifically they are all 0.0. Eval stats are reported for homref though. I have now tried running the training several times with different hyperparameters but so far still no change at the het or homalt eval stats. . My first, very simple question is thus, are these eval stats truly 0 (i.e. the model is very bad) or is 0.0 some starting value and there are not enough data to calculate them initially? I am warmstarting from the 1.6.1 wgs model so I cant imagine the model is really that bad at calling variants initially, even if in a fish. . **Setup**. Running on a university computing cluster (https://hpc-unibe-ch.github.io/) . OS: Rocky 9.3 Blue Onyx. GPU: rtx4090 . Installation: Running from Docker image via singularity. DV version: 1.6.1. **Data**. I am training on examples from 5 individuals, data from Illumina NovaSeq ~20x coverage. . 17/21 chromosomes used for training (~1.45M examples). 2/21 chromosomes used for tuning (~200k examples). 2/21 chromosomes reserved for testing. . (Different chromosomes used for train/tune/test across samples - see below). <img width=""1437"" alt=""Screenshot 2024-08-07 at 09 30 23"" src=""https://github.com/user-attachments/assets/3178e87a-8cf7-47cb-84a2-0a84d15c958f"">. **Shuffling**. Performed downsampling=0.5. Shuffled globally across samples, chromosomes and downsampling. . **Command**. My latest training run was like so:. ```. apptainer run . --nv . -B $WD:/home . $DV_PATH . /opt/deepvariant/bin/train . --config=/home/dv_config.py:base . --config.train_dataset_pbtxt=""/home/examples_shuffled/train/All_samples_training_examples.dataset_config.pbtxt"" . --config.tune_dataset_pbtxt=""/home/examples_shuffled/tune/All_samples_tune_examples.dataset_config.pbtxt"". . --config.num_epochs=1 . --config.learning_rate=0.0001 . --config.num_validation_examples=0 . --config.tune_every_steps=200",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:1311,testability,test,testing,1311,"r more specifically they are all 0.0. Eval stats are reported for homref though. I have now tried running the training several times with different hyperparameters but so far still no change at the het or homalt eval stats. . My first, very simple question is thus, are these eval stats truly 0 (i.e. the model is very bad) or is 0.0 some starting value and there are not enough data to calculate them initially? I am warmstarting from the 1.6.1 wgs model so I cant imagine the model is really that bad at calling variants initially, even if in a fish. . **Setup**. Running on a university computing cluster (https://hpc-unibe-ch.github.io/) . OS: Rocky 9.3 Blue Onyx. GPU: rtx4090 . Installation: Running from Docker image via singularity. DV version: 1.6.1. **Data**. I am training on examples from 5 individuals, data from Illumina NovaSeq ~20x coverage. . 17/21 chromosomes used for training (~1.45M examples). 2/21 chromosomes used for tuning (~200k examples). 2/21 chromosomes reserved for testing. . (Different chromosomes used for train/tune/test across samples - see below). <img width=""1437"" alt=""Screenshot 2024-08-07 at 09 30 23"" src=""https://github.com/user-attachments/assets/3178e87a-8cf7-47cb-84a2-0a84d15c958f"">. **Shuffling**. Performed downsampling=0.5. Shuffled globally across samples, chromosomes and downsampling. . **Command**. My latest training run was like so:. ```. apptainer run . --nv . -B $WD:/home . $DV_PATH . /opt/deepvariant/bin/train . --config=/home/dv_config.py:base . --config.train_dataset_pbtxt=""/home/examples_shuffled/train/All_samples_training_examples.dataset_config.pbtxt"" . --config.tune_dataset_pbtxt=""/home/examples_shuffled/tune/All_samples_tune_examples.dataset_config.pbtxt"". . --config.num_epochs=1 . --config.learning_rate=0.0001 . --config.num_validation_examples=0 . --config.tune_every_steps=2000 . --experiment_dir=/home/${OUTDIR} . --strategy=mirrored . --config.batch_size=64 . --config.init_checkpoint=""/home/model_wgs_v1.6.1/deepvariant.w",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:1365,testability,test,test,1365," reported for homref though. I have now tried running the training several times with different hyperparameters but so far still no change at the het or homalt eval stats. . My first, very simple question is thus, are these eval stats truly 0 (i.e. the model is very bad) or is 0.0 some starting value and there are not enough data to calculate them initially? I am warmstarting from the 1.6.1 wgs model so I cant imagine the model is really that bad at calling variants initially, even if in a fish. . **Setup**. Running on a university computing cluster (https://hpc-unibe-ch.github.io/) . OS: Rocky 9.3 Blue Onyx. GPU: rtx4090 . Installation: Running from Docker image via singularity. DV version: 1.6.1. **Data**. I am training on examples from 5 individuals, data from Illumina NovaSeq ~20x coverage. . 17/21 chromosomes used for training (~1.45M examples). 2/21 chromosomes used for tuning (~200k examples). 2/21 chromosomes reserved for testing. . (Different chromosomes used for train/tune/test across samples - see below). <img width=""1437"" alt=""Screenshot 2024-08-07 at 09 30 23"" src=""https://github.com/user-attachments/assets/3178e87a-8cf7-47cb-84a2-0a84d15c958f"">. **Shuffling**. Performed downsampling=0.5. Shuffled globally across samples, chromosomes and downsampling. . **Command**. My latest training run was like so:. ```. apptainer run . --nv . -B $WD:/home . $DV_PATH . /opt/deepvariant/bin/train . --config=/home/dv_config.py:base . --config.train_dataset_pbtxt=""/home/examples_shuffled/train/All_samples_training_examples.dataset_config.pbtxt"" . --config.tune_dataset_pbtxt=""/home/examples_shuffled/tune/All_samples_tune_examples.dataset_config.pbtxt"". . --config.num_epochs=1 . --config.learning_rate=0.0001 . --config.num_validation_examples=0 . --config.tune_every_steps=2000 . --experiment_dir=/home/${OUTDIR} . --strategy=mirrored . --config.batch_size=64 . --config.init_checkpoint=""/home/model_wgs_v1.6.1/deepvariant.wgs.ckpt"". ```. Though previous runs had higher learn",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:2565,testability,Log,Log,2565,"ed downsampling=0.5. Shuffled globally across samples, chromosomes and downsampling. . **Command**. My latest training run was like so:. ```. apptainer run . --nv . -B $WD:/home . $DV_PATH . /opt/deepvariant/bin/train . --config=/home/dv_config.py:base . --config.train_dataset_pbtxt=""/home/examples_shuffled/train/All_samples_training_examples.dataset_config.pbtxt"" . --config.tune_dataset_pbtxt=""/home/examples_shuffled/tune/All_samples_tune_examples.dataset_config.pbtxt"". . --config.num_epochs=1 . --config.learning_rate=0.0001 . --config.num_validation_examples=0 . --config.tune_every_steps=2000 . --experiment_dir=/home/${OUTDIR} . --strategy=mirrored . --config.batch_size=64 . --config.init_checkpoint=""/home/model_wgs_v1.6.1/deepvariant.wgs.ckpt"". ```. Though previous runs had higher learning rates (0.01) and batch sizes (128). Training proceeds as follows:. Training Examples: 1454377. Batch Size: 64. Epochs: 1. Steps per epoch: 22724. Steps per tune: 3162. Num train steps: 22724. **Log file**. Here is the top of the log file, including some warnings in case they are relevant:. ```. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(. 2024-08-28 10:40:42.588215: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_SYSTEM_DRIVER_MISMATCH: system has unsupported display driver / cuda driver combination. I0828 10:40:42.589054 140318776715072 train.py:92] Running with debug=False. I0828 10:40:42.589343 140318776715072 train.py:100] Use TPU at local. I0828 10:40:42.589422 14",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:2600,testability,log,log,2600,"lly across samples, chromosomes and downsampling. . **Command**. My latest training run was like so:. ```. apptainer run . --nv . -B $WD:/home . $DV_PATH . /opt/deepvariant/bin/train . --config=/home/dv_config.py:base . --config.train_dataset_pbtxt=""/home/examples_shuffled/train/All_samples_training_examples.dataset_config.pbtxt"" . --config.tune_dataset_pbtxt=""/home/examples_shuffled/tune/All_samples_tune_examples.dataset_config.pbtxt"". . --config.num_epochs=1 . --config.learning_rate=0.0001 . --config.num_validation_examples=0 . --config.tune_every_steps=2000 . --experiment_dir=/home/${OUTDIR} . --strategy=mirrored . --config.batch_size=64 . --config.init_checkpoint=""/home/model_wgs_v1.6.1/deepvariant.wgs.ckpt"". ```. Though previous runs had higher learning rates (0.01) and batch sizes (128). Training proceeds as follows:. Training Examples: 1454377. Batch Size: 64. Epochs: 1. Steps per epoch: 22724. Steps per tune: 3162. Num train steps: 22724. **Log file**. Here is the top of the log file, including some warnings in case they are relevant:. ```. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(. 2024-08-28 10:40:42.588215: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_SYSTEM_DRIVER_MISMATCH: system has unsupported display driver / cuda driver combination. I0828 10:40:42.589054 140318776715072 train.py:92] Running with debug=False. I0828 10:40:42.589343 140318776715072 train.py:100] Use TPU at local. I0828 10:40:42.589422 140318776715072 train.py:103] experim",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:2906,testability,plan,planned,2906,"s.dataset_config.pbtxt"" . --config.tune_dataset_pbtxt=""/home/examples_shuffled/tune/All_samples_tune_examples.dataset_config.pbtxt"". . --config.num_epochs=1 . --config.learning_rate=0.0001 . --config.num_validation_examples=0 . --config.tune_every_steps=2000 . --experiment_dir=/home/${OUTDIR} . --strategy=mirrored . --config.batch_size=64 . --config.init_checkpoint=""/home/model_wgs_v1.6.1/deepvariant.wgs.ckpt"". ```. Though previous runs had higher learning rates (0.01) and batch sizes (128). Training proceeds as follows:. Training Examples: 1454377. Batch Size: 64. Epochs: 1. Steps per epoch: 22724. Steps per tune: 3162. Num train steps: 22724. **Log file**. Here is the top of the log file, including some warnings in case they are relevant:. ```. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(. 2024-08-28 10:40:42.588215: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_SYSTEM_DRIVER_MISMATCH: system has unsupported display driver / cuda driver combination. I0828 10:40:42.589054 140318776715072 train.py:92] Running with debug=False. I0828 10:40:42.589343 140318776715072 train.py:100] Use TPU at local. I0828 10:40:42.589422 140318776715072 train.py:103] experiment_dir: /home/training_outs/epoch1/. WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce. W0828 10:40:42.596594 140318776715072 cross_device_ops.py:1387] There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce. INFO:tensorflow:Using Mir",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:2982,testability,depend,dependencies,2982,"/tune/All_samples_tune_examples.dataset_config.pbtxt"". . --config.num_epochs=1 . --config.learning_rate=0.0001 . --config.num_validation_examples=0 . --config.tune_every_steps=2000 . --experiment_dir=/home/${OUTDIR} . --strategy=mirrored . --config.batch_size=64 . --config.init_checkpoint=""/home/model_wgs_v1.6.1/deepvariant.wgs.ckpt"". ```. Though previous runs had higher learning rates (0.01) and batch sizes (128). Training proceeds as follows:. Training Examples: 1454377. Batch Size: 64. Epochs: 1. Steps per epoch: 22724. Steps per tune: 3162. Num train steps: 22724. **Log file**. Here is the top of the log file, including some warnings in case they are relevant:. ```. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(. 2024-08-28 10:40:42.588215: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_SYSTEM_DRIVER_MISMATCH: system has unsupported display driver / cuda driver combination. I0828 10:40:42.589054 140318776715072 train.py:92] Running with debug=False. I0828 10:40:42.589343 140318776715072 train.py:100] Use TPU at local. I0828 10:40:42.589422 140318776715072 train.py:103] experiment_dir: /home/training_outs/epoch1/. WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce. W0828 10:40:42.596594 140318776715072 cross_device_ops.py:1387] There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce. INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',). ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:6372,testability,log,log,6372,"tions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089. W0828 10:40:49.488072 140318776715072 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be rem>. Instructions for updating:. Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089. 2024-08-28 10:40:49.893797: W tensorflow/core/framework/dataset.cc:769] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations. I0828 10:40:49.947995 140318776715072 train.py:316]. ```. And here is an excerpt of from a later portion of the log file including some training and tuning steps, where you can see the 0.0 for het and homalt eval stats. . ```. I0829 07:13:59.098341 140305134778112 logging_writer.py:48] [13700] epoch=0, train/categorical_accuracy=1.0, train/categorical_crossentropy=0.552009105682373, train/f1_het=0.0, train/f1_homalt=0.0, train/f1_homref=1.0, train/f1_macro=0.3333333432674408, train/f1_micro=1.0, train/f1_. weighted=1.0, train/false_negatives=0.0, train/false_positives=0.0, train/learning_rate=9.999999747378752e-05, train/loss=0.5520098805427551, train/precision=1.0, train/precision_het=0.0, train/precision_homalt=0.0, train/precision_homref=1.0, train/recall=1.0, train/recall_het=0.0,. train/recall_homalt=0.0, train/recall_homref=1.0, train/true_negatives=12800.0, train/true_positives=6400.0. I0829 07:18:37.609363 140318776715072 local.py:41] Setting work unit notes: 0.3 steps/s, 60.6% (13778/22724), ETA: 8h52m. I0829 07:18:37.611700 140305134778112 logging_writer.py:48] [13778] steps_per_sec=0.28",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:7230,testability,unit,unit,7230,"ded to apply optimizations. I0828 10:40:49.947995 140318776715072 train.py:316]. ```. And here is an excerpt of from a later portion of the log file including some training and tuning steps, where you can see the 0.0 for het and homalt eval stats. . ```. I0829 07:13:59.098341 140305134778112 logging_writer.py:48] [13700] epoch=0, train/categorical_accuracy=1.0, train/categorical_crossentropy=0.552009105682373, train/f1_het=0.0, train/f1_homalt=0.0, train/f1_homref=1.0, train/f1_macro=0.3333333432674408, train/f1_micro=1.0, train/f1_. weighted=1.0, train/false_negatives=0.0, train/false_positives=0.0, train/learning_rate=9.999999747378752e-05, train/loss=0.5520098805427551, train/precision=1.0, train/precision_het=0.0, train/precision_homalt=0.0, train/precision_homref=1.0, train/recall=1.0, train/recall_het=0.0,. train/recall_homalt=0.0, train/recall_homref=1.0, train/true_negatives=12800.0, train/true_positives=6400.0. I0829 07:18:37.609363 140318776715072 local.py:41] Setting work unit notes: 0.3 steps/s, 60.6% (13778/22724), ETA: 8h52m. I0829 07:18:37.611700 140305134778112 logging_writer.py:48] [13778] steps_per_sec=0.280118. I0829 07:18:37.611787 140305134778112 logging_writer.py:48] [13778] uptime=74267.6. I0829 07:19:56.116713 140305134778112 logging_writer.py:48] [13800] epoch=0, train/categorical_accuracy=1.0, train/categorical_crossentropy=0.5520044565200806, train/f1_het=0.0, train/f1_homalt=0.0, train/f1_homref=1.0, train/f1_macro=0.3333333432674408, train/f1_micro=1.0, train/f1_weighted=1.0, train/false_negatives=0.0, train/false_positives=0.0, train/learning_rate=9.999999747378752e-05, train/loss=0.5520052909851074, train/precision=1.0, train/precision_het=0.0, train/precision_homalt=0.0, train/precision_homref=1.0, train/recall=1.0, train/recall_het=0.0, train/recall_homalt=0.0, train/recall_homref=1.0, train/true_negatives=12800.0, train/true_positives=6400.0. I0829 07:23:41.076397 140318776715072 local.py:41] Setting work unit notes: 0.3 steps/s, 61",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:8205,testability,unit,unit,8205,"al.py:41] Setting work unit notes: 0.3 steps/s, 60.6% (13778/22724), ETA: 8h52m. I0829 07:18:37.611700 140305134778112 logging_writer.py:48] [13778] steps_per_sec=0.280118. I0829 07:18:37.611787 140305134778112 logging_writer.py:48] [13778] uptime=74267.6. I0829 07:19:56.116713 140305134778112 logging_writer.py:48] [13800] epoch=0, train/categorical_accuracy=1.0, train/categorical_crossentropy=0.5520044565200806, train/f1_het=0.0, train/f1_homalt=0.0, train/f1_homref=1.0, train/f1_macro=0.3333333432674408, train/f1_micro=1.0, train/f1_weighted=1.0, train/false_negatives=0.0, train/false_positives=0.0, train/learning_rate=9.999999747378752e-05, train/loss=0.5520052909851074, train/precision=1.0, train/precision_het=0.0, train/precision_homalt=0.0, train/precision_homref=1.0, train/recall=1.0, train/recall_het=0.0, train/recall_homalt=0.0, train/recall_homref=1.0, train/true_negatives=12800.0, train/true_positives=6400.0. I0829 07:23:41.076397 140318776715072 local.py:41] Setting work unit notes: 0.3 steps/s, 61.0% (13863/22724), ETA: 8h47m. I0829 07:23:41.078737 140305134778112 logging_writer.py:48] [13863] steps_per_sec=0.280096. I0829 07:23:41.078827 140305134778112 logging_writer.py:48] [13863] uptime=74571.1. I0829 07:25:53.180995 140305134778112 logging_writer.py:48] [13900] epoch=0, train/categorical_accuracy=1.0, train/categorical_crossentropy=0.5519936680793762, train/f1_het=0.0, train/f1_homalt=0.0, train/f1_homref=1.0, train/f1_macro=0.3333333432674408, train/f1_micro=1.0, train/f1_weighted=1.0, train/false_negatives=0.0, train/false_positives=0.0, train/learning_rate=9.999999747378752e-05, train/loss=0.5519945025444031, train/precision=1.0, train/precision_het=0.0, train/precision_homalt=0.0, train/precision_homref=1.0, train/recall=1.0, train/recall_het=0.0, train/recall_homalt=0.0, train/recall_homref=1.0, train/true_negatives=12800.0, train/true_positives=6400.0. I0829 07:28:44.566404 140318776715072 local.py:41] Setting work unit notes: 0.3 steps/s, 61",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:9180,testability,unit,unit,9180,"al.py:41] Setting work unit notes: 0.3 steps/s, 61.0% (13863/22724), ETA: 8h47m. I0829 07:23:41.078737 140305134778112 logging_writer.py:48] [13863] steps_per_sec=0.280096. I0829 07:23:41.078827 140305134778112 logging_writer.py:48] [13863] uptime=74571.1. I0829 07:25:53.180995 140305134778112 logging_writer.py:48] [13900] epoch=0, train/categorical_accuracy=1.0, train/categorical_crossentropy=0.5519936680793762, train/f1_het=0.0, train/f1_homalt=0.0, train/f1_homref=1.0, train/f1_macro=0.3333333432674408, train/f1_micro=1.0, train/f1_weighted=1.0, train/false_negatives=0.0, train/false_positives=0.0, train/learning_rate=9.999999747378752e-05, train/loss=0.5519945025444031, train/precision=1.0, train/precision_het=0.0, train/precision_homalt=0.0, train/precision_homref=1.0, train/recall=1.0, train/recall_het=0.0, train/recall_homalt=0.0, train/recall_homref=1.0, train/true_negatives=12800.0, train/true_positives=6400.0. I0829 07:28:44.566404 140318776715072 local.py:41] Setting work unit notes: 0.3 steps/s, 61.4% (13948/22724), ETA: 8h42m. I0829 07:28:44.568708 140305134778112 logging_writer.py:48] [13948] steps_per_sec=0.280075. I0829 07:28:44.568793 140305134778112 logging_writer.py:48] [13948] uptime=74874.6. I0829 07:31:25.151819 140318776715072 train.py:361] Running tune at step=13993 epoch=0. I0829 07:31:25.152109 140318776715072 train.py:366] Tune step 0 / 3162 (0.0%). I0829 07:33:17.573163 140318776715072 train.py:366] Tune step 100 / 3162 (0.0%). I0829 07:35:10.013494 140318776715072 train.py:366] Tune step 200 / 3162 (10.0%). I0829 07:37:02.497336 140318776715072 train.py:366] Tune step 300 / 3162 (10.0%). I0829 07:38:54.834164 140318776715072 train.py:366] Tune step 400 / 3162 (10.0%). I0829 07:40:47.319165 140318776715072 train.py:366] Tune step 500 / 3162 (20.0%). I0829 07:42:39.802007 140318776715072 train.py:366] Tune step 600 / 3162 (20.0%). I0829 07:44:32.297624 140318776715072 train.py:366] Tune step 700 / 3162 (20.0%). I0829 07:46:24.658610 140318",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:13180,testability,unit,unit,13180," logging_writer.py:48] [13993] tune/categorical_accuracy=0.9916982650756836, tune/categorical_crossentropy=0.560210645198822, tune/f1_het=0.0, tune/f1_homalt=0.0, tune/f1_homref=0.9958318471908569, tune/f1_macro=0.33194395899772644, tune/f1_micro=0.9916982650756836, tune/f1_weighted=0.9958318471908569, tune/false_negatives_1=1777.0, tune/false_positives_1=1544.0, tune/loss=0.5603554248809814, tune/precision_1=0.9923615455627441, tune/precision_het=0.0, tune/precision_homalt=0.0, tune/precision_homref=1.0, tune/recall_1=0.9912189841270447, tune/recall_het=0.0, tune/recall_homalt=0.0, tune/recall_homref=0.9912189841270447, tune/true_negatives_1=403192.0, tune/true_positives_1=200591.0. I0829 08:30:42.590469 140318776715072 train.py:471] Skipping checkpoint with tune/f1_weighted=0.99583185 < previous best tune/f1_weighted=0.99845344. I0829 08:30:42.595992 140305134778112 logging_writer.py:48] [13993] tune/early_stopping=7. I0829 08:30:46.123329 140318776715072 local.py:41] Setting work unit notes: 0.0 steps/s, 61.6% (13994/22724), ETA: 8d4h11m. I0829 08:30:46.125013 140305134778112 logging_writer.py:48] [13994] steps_per_sec=0.0123604. I0829 08:30:46.125087 140305134778112 logging_writer.py:48] [13994] uptime=78596.1. I0829 08:31:07.673585 140305134778112 logging_writer.py:48] [14000] epoch=0, train/categorical_accuracy=1.0, train/categorical_crossentropy=0.5519920587539673, train/f1_het=0.0, train/f1_homalt=0.0, train/f1_homref=1.0, train/f1_macro=0.3333333432674408, train/f1_micro=1.0, train/f1_weighted=1.0, train/false_negatives=0.0, train/false_positives=0.0, train/learning_rate=9.999999747378752e-05, train/loss=0.551992654800415, train/precision=1.0, train/precision_het=0.0, train/precision_homalt=0.0, train/precision_homref=1.0, train/recall=1.0, train/recall_het=0.0, train/recall_homalt=0.0, train/recall_homref=1.0, train/true_negatives=12800.0, train/true_positives=6400.0. ```. I am new to Deep Learning and am struggling to decide whether something is wrong wit",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:125,usability,tool,tool,125,"No evaluation statistics for het and homalt calls during model training; Hello DV team, and thanks for creating such a great tool! . I am currently trying to retrain the wgs model for a new species (a fish) however, during training, I see no evaluation statistics (precision, recall, f1) for either het or homalt. Or more specifically they are all 0.0. Eval stats are reported for homref though. I have now tried running the training several times with different hyperparameters but so far still no change at the het or homalt eval stats. . My first, very simple question is thus, are these eval stats truly 0 (i.e. the model is very bad) or is 0.0 some starting value and there are not enough data to calculate them initially? I am warmstarting from the 1.6.1 wgs model so I cant imagine the model is really that bad at calling variants initially, even if in a fish. . **Setup**. Running on a university computing cluster (https://hpc-unibe-ch.github.io/) . OS: Rocky 9.3 Blue Onyx. GPU: rtx4090 . Installation: Running from Docker image via singularity. DV version: 1.6.1. **Data**. I am training on examples from 5 individuals, data from Illumina NovaSeq ~20x coverage. . 17/21 chromosomes used for training (~1.45M examples). 2/21 chromosomes used for tuning (~200k examples). 2/21 chromosomes reserved for testing. . (Different chromosomes used for train/tune/test across samples - see below). <img width=""1437"" alt=""Screenshot 2024-08-07 at 09 30 23"" src=""https://github.com/user-attachments/assets/3178e87a-8cf7-47cb-84a2-0a84d15c958f"">. **Shuffling**. Performed downsampling=0.5. Shuffled globally across samples, chromosomes and downsampling. . **Command**. My latest training run was like so:. ```. apptainer run . --nv . -B $WD:/home . $DV_PATH . /opt/deepvariant/bin/train . --config=/home/dv_config.py:base . --config.train_dataset_pbtxt=""/home/examples_shuffled/train/All_samples_training_examples.dataset_config.pbtxt"" . --config.tune_dataset_pbtxt=""/home/examples_shuffled/tune/All_sa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:556,usability,simpl,simple,556,"No evaluation statistics for het and homalt calls during model training; Hello DV team, and thanks for creating such a great tool! . I am currently trying to retrain the wgs model for a new species (a fish) however, during training, I see no evaluation statistics (precision, recall, f1) for either het or homalt. Or more specifically they are all 0.0. Eval stats are reported for homref though. I have now tried running the training several times with different hyperparameters but so far still no change at the het or homalt eval stats. . My first, very simple question is thus, are these eval stats truly 0 (i.e. the model is very bad) or is 0.0 some starting value and there are not enough data to calculate them initially? I am warmstarting from the 1.6.1 wgs model so I cant imagine the model is really that bad at calling variants initially, even if in a fish. . **Setup**. Running on a university computing cluster (https://hpc-unibe-ch.github.io/) . OS: Rocky 9.3 Blue Onyx. GPU: rtx4090 . Installation: Running from Docker image via singularity. DV version: 1.6.1. **Data**. I am training on examples from 5 individuals, data from Illumina NovaSeq ~20x coverage. . 17/21 chromosomes used for training (~1.45M examples). 2/21 chromosomes used for tuning (~200k examples). 2/21 chromosomes reserved for testing. . (Different chromosomes used for train/tune/test across samples - see below). <img width=""1437"" alt=""Screenshot 2024-08-07 at 09 30 23"" src=""https://github.com/user-attachments/assets/3178e87a-8cf7-47cb-84a2-0a84d15c958f"">. **Shuffling**. Performed downsampling=0.5. Shuffled globally across samples, chromosomes and downsampling. . **Command**. My latest training run was like so:. ```. apptainer run . --nv . -B $WD:/home . $DV_PATH . /opt/deepvariant/bin/train . --config=/home/dv_config.py:base . --config.train_dataset_pbtxt=""/home/examples_shuffled/train/All_samples_training_examples.dataset_config.pbtxt"" . --config.tune_dataset_pbtxt=""/home/examples_shuffled/tune/All_sa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:1481,usability,user,user-attachments,1481," still no change at the het or homalt eval stats. . My first, very simple question is thus, are these eval stats truly 0 (i.e. the model is very bad) or is 0.0 some starting value and there are not enough data to calculate them initially? I am warmstarting from the 1.6.1 wgs model so I cant imagine the model is really that bad at calling variants initially, even if in a fish. . **Setup**. Running on a university computing cluster (https://hpc-unibe-ch.github.io/) . OS: Rocky 9.3 Blue Onyx. GPU: rtx4090 . Installation: Running from Docker image via singularity. DV version: 1.6.1. **Data**. I am training on examples from 5 individuals, data from Illumina NovaSeq ~20x coverage. . 17/21 chromosomes used for training (~1.45M examples). 2/21 chromosomes used for tuning (~200k examples). 2/21 chromosomes reserved for testing. . (Different chromosomes used for train/tune/test across samples - see below). <img width=""1437"" alt=""Screenshot 2024-08-07 at 09 30 23"" src=""https://github.com/user-attachments/assets/3178e87a-8cf7-47cb-84a2-0a84d15c958f"">. **Shuffling**. Performed downsampling=0.5. Shuffled globally across samples, chromosomes and downsampling. . **Command**. My latest training run was like so:. ```. apptainer run . --nv . -B $WD:/home . $DV_PATH . /opt/deepvariant/bin/train . --config=/home/dv_config.py:base . --config.train_dataset_pbtxt=""/home/examples_shuffled/train/All_samples_training_examples.dataset_config.pbtxt"" . --config.tune_dataset_pbtxt=""/home/examples_shuffled/tune/All_samples_tune_examples.dataset_config.pbtxt"". . --config.num_epochs=1 . --config.learning_rate=0.0001 . --config.num_validation_examples=0 . --config.tune_every_steps=2000 . --experiment_dir=/home/${OUTDIR} . --strategy=mirrored . --config.batch_size=64 . --config.init_checkpoint=""/home/model_wgs_v1.6.1/deepvariant.wgs.ckpt"". ```. Though previous runs had higher learning rates (0.01) and batch sizes (128). Training proceeds as follows:. Training Examples: 1454377. Batch Size: 64. Epochs:",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:1560,usability,Perform,Performed,1560,"estion is thus, are these eval stats truly 0 (i.e. the model is very bad) or is 0.0 some starting value and there are not enough data to calculate them initially? I am warmstarting from the 1.6.1 wgs model so I cant imagine the model is really that bad at calling variants initially, even if in a fish. . **Setup**. Running on a university computing cluster (https://hpc-unibe-ch.github.io/) . OS: Rocky 9.3 Blue Onyx. GPU: rtx4090 . Installation: Running from Docker image via singularity. DV version: 1.6.1. **Data**. I am training on examples from 5 individuals, data from Illumina NovaSeq ~20x coverage. . 17/21 chromosomes used for training (~1.45M examples). 2/21 chromosomes used for tuning (~200k examples). 2/21 chromosomes reserved for testing. . (Different chromosomes used for train/tune/test across samples - see below). <img width=""1437"" alt=""Screenshot 2024-08-07 at 09 30 23"" src=""https://github.com/user-attachments/assets/3178e87a-8cf7-47cb-84a2-0a84d15c958f"">. **Shuffling**. Performed downsampling=0.5. Shuffled globally across samples, chromosomes and downsampling. . **Command**. My latest training run was like so:. ```. apptainer run . --nv . -B $WD:/home . $DV_PATH . /opt/deepvariant/bin/train . --config=/home/dv_config.py:base . --config.train_dataset_pbtxt=""/home/examples_shuffled/train/All_samples_training_examples.dataset_config.pbtxt"" . --config.tune_dataset_pbtxt=""/home/examples_shuffled/tune/All_samples_tune_examples.dataset_config.pbtxt"". . --config.num_epochs=1 . --config.learning_rate=0.0001 . --config.num_validation_examples=0 . --config.tune_every_steps=2000 . --experiment_dir=/home/${OUTDIR} . --strategy=mirrored . --config.batch_size=64 . --config.init_checkpoint=""/home/model_wgs_v1.6.1/deepvariant.wgs.ckpt"". ```. Though previous runs had higher learning rates (0.01) and batch sizes (128). Training proceeds as follows:. Training Examples: 1454377. Batch Size: 64. Epochs: 1. Steps per epoch: 22724. Steps per tune: 3162. Num train steps: 22724. **",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:1656,usability,Command,Command,1656,"ng value and there are not enough data to calculate them initially? I am warmstarting from the 1.6.1 wgs model so I cant imagine the model is really that bad at calling variants initially, even if in a fish. . **Setup**. Running on a university computing cluster (https://hpc-unibe-ch.github.io/) . OS: Rocky 9.3 Blue Onyx. GPU: rtx4090 . Installation: Running from Docker image via singularity. DV version: 1.6.1. **Data**. I am training on examples from 5 individuals, data from Illumina NovaSeq ~20x coverage. . 17/21 chromosomes used for training (~1.45M examples). 2/21 chromosomes used for tuning (~200k examples). 2/21 chromosomes reserved for testing. . (Different chromosomes used for train/tune/test across samples - see below). <img width=""1437"" alt=""Screenshot 2024-08-07 at 09 30 23"" src=""https://github.com/user-attachments/assets/3178e87a-8cf7-47cb-84a2-0a84d15c958f"">. **Shuffling**. Performed downsampling=0.5. Shuffled globally across samples, chromosomes and downsampling. . **Command**. My latest training run was like so:. ```. apptainer run . --nv . -B $WD:/home . $DV_PATH . /opt/deepvariant/bin/train . --config=/home/dv_config.py:base . --config.train_dataset_pbtxt=""/home/examples_shuffled/train/All_samples_training_examples.dataset_config.pbtxt"" . --config.tune_dataset_pbtxt=""/home/examples_shuffled/tune/All_samples_tune_examples.dataset_config.pbtxt"". . --config.num_epochs=1 . --config.learning_rate=0.0001 . --config.num_validation_examples=0 . --config.tune_every_steps=2000 . --experiment_dir=/home/${OUTDIR} . --strategy=mirrored . --config.batch_size=64 . --config.init_checkpoint=""/home/model_wgs_v1.6.1/deepvariant.wgs.ckpt"". ```. Though previous runs had higher learning rates (0.01) and batch sizes (128). Training proceeds as follows:. Training Examples: 1454377. Batch Size: 64. Epochs: 1. Steps per epoch: 22724. Steps per tune: 3162. Num train steps: 22724. **Log file**. Here is the top of the log file, including some warnings in case they are relevant:",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:2362,usability,learn,learning,2362,"est across samples - see below). <img width=""1437"" alt=""Screenshot 2024-08-07 at 09 30 23"" src=""https://github.com/user-attachments/assets/3178e87a-8cf7-47cb-84a2-0a84d15c958f"">. **Shuffling**. Performed downsampling=0.5. Shuffled globally across samples, chromosomes and downsampling. . **Command**. My latest training run was like so:. ```. apptainer run . --nv . -B $WD:/home . $DV_PATH . /opt/deepvariant/bin/train . --config=/home/dv_config.py:base . --config.train_dataset_pbtxt=""/home/examples_shuffled/train/All_samples_training_examples.dataset_config.pbtxt"" . --config.tune_dataset_pbtxt=""/home/examples_shuffled/tune/All_samples_tune_examples.dataset_config.pbtxt"". . --config.num_epochs=1 . --config.learning_rate=0.0001 . --config.num_validation_examples=0 . --config.tune_every_steps=2000 . --experiment_dir=/home/${OUTDIR} . --strategy=mirrored . --config.batch_size=64 . --config.init_checkpoint=""/home/model_wgs_v1.6.1/deepvariant.wgs.ckpt"". ```. Though previous runs had higher learning rates (0.01) and batch sizes (128). Training proceeds as follows:. Training Examples: 1454377. Batch Size: 64. Epochs: 1. Steps per epoch: 22724. Steps per tune: 3162. Num train steps: 22724. **Log file**. Here is the top of the log file, including some warnings in case they are relevant:. ```. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(. 2024-08-28 10:40:42.588215: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_SYSTEM_DRIVER_MISMATCH: system has unsupported display driv",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:2749,usability,User,UserWarning,2749," . /opt/deepvariant/bin/train . --config=/home/dv_config.py:base . --config.train_dataset_pbtxt=""/home/examples_shuffled/train/All_samples_training_examples.dataset_config.pbtxt"" . --config.tune_dataset_pbtxt=""/home/examples_shuffled/tune/All_samples_tune_examples.dataset_config.pbtxt"". . --config.num_epochs=1 . --config.learning_rate=0.0001 . --config.num_validation_examples=0 . --config.tune_every_steps=2000 . --experiment_dir=/home/${OUTDIR} . --strategy=mirrored . --config.batch_size=64 . --config.init_checkpoint=""/home/model_wgs_v1.6.1/deepvariant.wgs.ckpt"". ```. Though previous runs had higher learning rates (0.01) and batch sizes (128). Training proceeds as follows:. Training Examples: 1454377. Batch Size: 64. Epochs: 1. Steps per epoch: 22724. Steps per tune: 3162. Num train steps: 22724. **Log file**. Here is the top of the log file, including some warnings in case they are relevant:. ```. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(. 2024-08-28 10:40:42.588215: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_SYSTEM_DRIVER_MISMATCH: system has unsupported display driver / cuda driver combination. I0828 10:40:42.589054 140318776715072 train.py:92] Running with debug=False. I0828 10:40:42.589343 140318776715072 train.py:100] Use TPU at local. I0828 10:40:42.589422 140318776715072 train.py:103] experiment_dir: /home/training_outs/epoch1/. WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce. W0828 10:40:42.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:2861,usability,minim,minimal,2861,"s_shuffled/train/All_samples_training_examples.dataset_config.pbtxt"" . --config.tune_dataset_pbtxt=""/home/examples_shuffled/tune/All_samples_tune_examples.dataset_config.pbtxt"". . --config.num_epochs=1 . --config.learning_rate=0.0001 . --config.num_validation_examples=0 . --config.tune_every_steps=2000 . --experiment_dir=/home/${OUTDIR} . --strategy=mirrored . --config.batch_size=64 . --config.init_checkpoint=""/home/model_wgs_v1.6.1/deepvariant.wgs.ckpt"". ```. Though previous runs had higher learning rates (0.01) and batch sizes (128). Training proceeds as follows:. Training Examples: 1454377. Batch Size: 64. Epochs: 1. Steps per epoch: 22724. Steps per tune: 3162. Num train steps: 22724. **Log file**. Here is the top of the log file, including some warnings in case they are relevant:. ```. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(. 2024-08-28 10:40:42.588215: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_SYSTEM_DRIVER_MISMATCH: system has unsupported display driver / cuda driver combination. I0828 10:40:42.589054 140318776715072 train.py:92] Running with debug=False. I0828 10:40:42.589343 140318776715072 train.py:100] Use TPU at local. I0828 10:40:42.589422 140318776715072 train.py:103] experiment_dir: /home/training_outs/epoch1/. WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce. W0828 10:40:42.596594 140318776715072 cross_device_ops.py:1387] There are non-GPU devices in `tf.distribute.Strategy`, not us",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:4218,usability,User,UserWarning,4218,"ler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_SYSTEM_DRIVER_MISMATCH: system has unsupported display driver / cuda driver combination. I0828 10:40:42.589054 140318776715072 train.py:92] Running with debug=False. I0828 10:40:42.589343 140318776715072 train.py:100] Use TPU at local. I0828 10:40:42.589422 140318776715072 train.py:103] experiment_dir: /home/training_outs/epoch1/. WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce. W0828 10:40:42.596594 140318776715072 cross_device_ops.py:1387] There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce. INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',). I0828 10:40:42.658734 140318776715072 mirrored_strategy.py:374] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',). /usr/local/lib/python3.8/dist-packages/keras/applications/inception_v3.py:138: UserWarning: This model usually expects 1 or 3 input channels. However, it was passed an input_shape with 7 input channels. input_shape = imagenet_utils.obtain_input_shape(. I0828 10:40:47.952382 140318776715072 keras_modeling.py:325] Number of l2 regularizers: 95. I0828 10:40:48.007193 140318776715072 keras_modeling.py:362] inceptionv3: load_weights from checkpoint: /home/training_outs/epoch1//checkpoints/ckpt-5997. I0828 10:40:49.193293 140318776715072 train.py:191] Exponential Decay: initial_learning_rate=0.0001. decay_steps=45448. learning_rate_decay_rate=0.947. I0828 10:40:49.193522 140318776715072 train.py:203] Use LinearWarmup:. warmup_steps=10000. warmup_learning_rate=1e-05. I0828 10:40:49.401860 140318776715072 keras_modeling.py:472] Restored checkpoint ckpt-5997 at step=0. tune/f1_weighted=tf.Tensor(0.0, shape=(), dtype=float32). WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:4265,usability,input,input,4265,"267] failed call to cuInit: CUDA_ERROR_SYSTEM_DRIVER_MISMATCH: system has unsupported display driver / cuda driver combination. I0828 10:40:42.589054 140318776715072 train.py:92] Running with debug=False. I0828 10:40:42.589343 140318776715072 train.py:100] Use TPU at local. I0828 10:40:42.589422 140318776715072 train.py:103] experiment_dir: /home/training_outs/epoch1/. WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce. W0828 10:40:42.596594 140318776715072 cross_device_ops.py:1387] There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce. INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',). I0828 10:40:42.658734 140318776715072 mirrored_strategy.py:374] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',). /usr/local/lib/python3.8/dist-packages/keras/applications/inception_v3.py:138: UserWarning: This model usually expects 1 or 3 input channels. However, it was passed an input_shape with 7 input channels. input_shape = imagenet_utils.obtain_input_shape(. I0828 10:40:47.952382 140318776715072 keras_modeling.py:325] Number of l2 regularizers: 95. I0828 10:40:48.007193 140318776715072 keras_modeling.py:362] inceptionv3: load_weights from checkpoint: /home/training_outs/epoch1//checkpoints/ckpt-5997. I0828 10:40:49.193293 140318776715072 train.py:191] Exponential Decay: initial_learning_rate=0.0001. decay_steps=45448. learning_rate_decay_rate=0.947. I0828 10:40:49.193522 140318776715072 train.py:203] Use LinearWarmup:. warmup_steps=10000. warmup_learning_rate=1e-05. I0828 10:40:49.401860 140318776715072 keras_modeling.py:472] Restored checkpoint ckpt-5997 at step=0. tune/f1_weighted=tf.Tensor(0.0, shape=(), dtype=float32). WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_ana",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:4326,usability,input,input,4326,": system has unsupported display driver / cuda driver combination. I0828 10:40:42.589054 140318776715072 train.py:92] Running with debug=False. I0828 10:40:42.589343 140318776715072 train.py:100] Use TPU at local. I0828 10:40:42.589422 140318776715072 train.py:103] experiment_dir: /home/training_outs/epoch1/. WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce. W0828 10:40:42.596594 140318776715072 cross_device_ops.py:1387] There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce. INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',). I0828 10:40:42.658734 140318776715072 mirrored_strategy.py:374] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',). /usr/local/lib/python3.8/dist-packages/keras/applications/inception_v3.py:138: UserWarning: This model usually expects 1 or 3 input channels. However, it was passed an input_shape with 7 input channels. input_shape = imagenet_utils.obtain_input_shape(. I0828 10:40:47.952382 140318776715072 keras_modeling.py:325] Number of l2 regularizers: 95. I0828 10:40:48.007193 140318776715072 keras_modeling.py:362] inceptionv3: load_weights from checkpoint: /home/training_outs/epoch1//checkpoints/ckpt-5997. I0828 10:40:49.193293 140318776715072 train.py:191] Exponential Decay: initial_learning_rate=0.0001. decay_steps=45448. learning_rate_decay_rate=0.947. I0828 10:40:49.193522 140318776715072 train.py:203] Use LinearWarmup:. warmup_steps=10000. warmup_learning_rate=1e-05. I0828 10:40:49.401860 140318776715072 keras_modeling.py:472] Restored checkpoint ckpt-5997 at step=0. tune/f1_weighted=tf.Tensor(0.0, shape=(), dtype=float32). WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:6099,usability,Input,Input,6099,"al/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23. Instructions for updating:. Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089. W0828 10:40:49.488072 140318776715072 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be rem>. Instructions for updating:. Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089. 2024-08-28 10:40:49.893797: W tensorflow/core/framework/dataset.cc:769] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations. I0828 10:40:49.947995 140318776715072 train.py:316]. ```. And here is an excerpt of from a later portion of the log file including some training and tuning steps, where you can see the 0.0 for het and homalt eval stats. . ```. I0829 07:13:59.098341 140305134778112 logging_writer.py:48] [13700] epoch=0, train/categorical_accuracy=1.0, train/categorical_crossentropy=0.552009105682373, train/f1_het=0.0, train/f1_homalt=0.0, train/f1_homref=1.0, train/f1_macro=0.3333333432674408, train/f1_micro=1.0, train/f1_. weighted=1.0, train/false_negatives=0.0, train/false_positives=0.0, train/learning_rate=9.999999747378752e-05, train/loss=0.5520098805427551, train/precision=1.0, train/precision_het=0.0, train/precision_homalt=0.0, train/precision_homref=1.0, train/recall=1.0, train/recall_het=0.0,. train/recall_homalt=0.0, train/recall_homref=",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:14115,usability,Learn,Learning,14115,"ne/loss=0.5603554248809814, tune/precision_1=0.9923615455627441, tune/precision_het=0.0, tune/precision_homalt=0.0, tune/precision_homref=1.0, tune/recall_1=0.9912189841270447, tune/recall_het=0.0, tune/recall_homalt=0.0, tune/recall_homref=0.9912189841270447, tune/true_negatives_1=403192.0, tune/true_positives_1=200591.0. I0829 08:30:42.590469 140318776715072 train.py:471] Skipping checkpoint with tune/f1_weighted=0.99583185 < previous best tune/f1_weighted=0.99845344. I0829 08:30:42.595992 140305134778112 logging_writer.py:48] [13993] tune/early_stopping=7. I0829 08:30:46.123329 140318776715072 local.py:41] Setting work unit notes: 0.0 steps/s, 61.6% (13994/22724), ETA: 8d4h11m. I0829 08:30:46.125013 140305134778112 logging_writer.py:48] [13994] steps_per_sec=0.0123604. I0829 08:30:46.125087 140305134778112 logging_writer.py:48] [13994] uptime=78596.1. I0829 08:31:07.673585 140305134778112 logging_writer.py:48] [14000] epoch=0, train/categorical_accuracy=1.0, train/categorical_crossentropy=0.5519920587539673, train/f1_het=0.0, train/f1_homalt=0.0, train/f1_homref=1.0, train/f1_macro=0.3333333432674408, train/f1_micro=1.0, train/f1_weighted=1.0, train/false_negatives=0.0, train/false_positives=0.0, train/learning_rate=9.999999747378752e-05, train/loss=0.551992654800415, train/precision=1.0, train/precision_het=0.0, train/precision_homalt=0.0, train/precision_homref=1.0, train/recall=1.0, train/recall_het=0.0, train/recall_homalt=0.0, train/recall_homref=1.0, train/true_negatives=12800.0, train/true_positives=6400.0. ```. I am new to Deep Learning and am struggling to decide whether something is wrong with my training approach/scripts or whether the model just needs more time / different hyperparams. Given the number of examples, I can only run 1 epoch at a time before I hit the 24hr cluster wall-time limit. So I have only trained for around 30,000 steps in total across 2 epochs so far (starting from last checkpoint after 1st epoch). . All advice much appreciated! .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/877:13,availability,error,error,13,"Fatal Python error: Aborted; **Hello, I ran deep variant for mutation calling of single cell iso seq bam file (Pacbio long read rna-seq), and I got this error messages:**. `9-03 12:26:09.055921: W third_party/nucleus/io/sam_reader.cc:612] Could not read base quality scores molecule/44871400: NOT_FOUND: Could not read base quality scores. 2024-09-03 12:26:09.055938: W third_party/nucleus/io/sam_reader.cc:612] Could not read base quality scores molecule/22677071: NOT_FOUND: Could not read base quality scores. 2024-09-03 12:26:09.055954: W third_party/nucleus/io/sam_reader.cc:612] Could not read base quality scores molecule/31298741: NOT_FOUND: Could not read base quality scores. 2024-09-03 12:26:09.055967: W third_party/nucleus/io/sam_reader.cc:612] Could not read base quality scores molecule/31321506: NOT_FOUND: Could not read base quality scores. 2024-09-03 12:26:09.055980: W third_party/nucleus/io/sam_reader.cc:612] Could not read base quality scores molecule/31927218: NOT_FOUND: Could not read base quality scores. 2024-09-03 12:26:09.055993: W third_party/nucleus/io/sam_reader.cc:612] Could not read base quality scores molecule/25969828: NOT_FOUND: Could not read base quality scores. 2024-09-03 12:26:09.056006: W third_party/nucleus/io/sam_reader.cc:612] Could not read base quality scores molecule/6236354: NOT_FOUND: Could not read base quality scores. 2024-09-03 12:26:09.056021: W third_party/nucleus/io/sam_reader.cc:612] Could not read base quality scores molecule/32560810: NOT_FOUND: Could not read base quality scores. 2024-09-03 12:26:09.056034: W third_party/nucleus/io/sam_reader.cc:612] Could not read base quality scores molecule/12686626: NOT_FOUND: Could not read base quality scores. 2024-09-03 12:26:09.056046: W third_party/nucleus/io/sam_reader.cc:612] Could not read base quality scores molecule/12686630: NOT_FOUND: Could not read base quality scores. 2024-09-03 12:26:09.056060: W third_party/nucleus/io/sam_reader.cc:612] Could not read base quality scor",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/877
https://github.com/google/deepvariant/issues/877:153,availability,error,error,153,"Fatal Python error: Aborted; **Hello, I ran deep variant for mutation calling of single cell iso seq bam file (Pacbio long read rna-seq), and I got this error messages:**. `9-03 12:26:09.055921: W third_party/nucleus/io/sam_reader.cc:612] Could not read base quality scores molecule/44871400: NOT_FOUND: Could not read base quality scores. 2024-09-03 12:26:09.055938: W third_party/nucleus/io/sam_reader.cc:612] Could not read base quality scores molecule/22677071: NOT_FOUND: Could not read base quality scores. 2024-09-03 12:26:09.055954: W third_party/nucleus/io/sam_reader.cc:612] Could not read base quality scores molecule/31298741: NOT_FOUND: Could not read base quality scores. 2024-09-03 12:26:09.055967: W third_party/nucleus/io/sam_reader.cc:612] Could not read base quality scores molecule/31321506: NOT_FOUND: Could not read base quality scores. 2024-09-03 12:26:09.055980: W third_party/nucleus/io/sam_reader.cc:612] Could not read base quality scores molecule/31927218: NOT_FOUND: Could not read base quality scores. 2024-09-03 12:26:09.055993: W third_party/nucleus/io/sam_reader.cc:612] Could not read base quality scores molecule/25969828: NOT_FOUND: Could not read base quality scores. 2024-09-03 12:26:09.056006: W third_party/nucleus/io/sam_reader.cc:612] Could not read base quality scores molecule/6236354: NOT_FOUND: Could not read base quality scores. 2024-09-03 12:26:09.056021: W third_party/nucleus/io/sam_reader.cc:612] Could not read base quality scores molecule/32560810: NOT_FOUND: Could not read base quality scores. 2024-09-03 12:26:09.056034: W third_party/nucleus/io/sam_reader.cc:612] Could not read base quality scores molecule/12686626: NOT_FOUND: Could not read base quality scores. 2024-09-03 12:26:09.056046: W third_party/nucleus/io/sam_reader.cc:612] Could not read base quality scores molecule/12686630: NOT_FOUND: Could not read base quality scores. 2024-09-03 12:26:09.056060: W third_party/nucleus/io/sam_reader.cc:612] Could not read base quality scor",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/877
https://github.com/google/deepvariant/issues/877:5155,availability,error,error,5155,"26:09.056452: W third_party/nucleus/io/sam_reader.cc:612] Could not read base quality scores molecule/25963197: NOT_FOUND: Could not read base quality scores. 2024-09-03 12:26:09.056463: W third_party/nucleus/io/sam_reader.cc:612] Could not read base quality scores molecule/25963211: NOT_FOUND: Could not read base quality scores. 2024-09-03 12:26:09.056474: W third_party/nucleus/io/sam_reader.cc:612] Could not read base quality scores molecule/25963212: NOT_FOUND: Could not read base quality scores. 2024-09-03 12:26:09.056489: W third_party/nucleus/io/sam_reader.cc:612] Could not read base quality scores molecule/9461690: NOT_FOUND: Could not read base quality scores. 2024-09-03 12:26:09.056506: W third_party/nucleus/io/sam_reader.cc:612] Could not read base quality scores molecule/8764719: NOT_FOUND: Could not read base quality scores. 2024-09-03 12:26:09.086379: F deepvariant/allelecounter.cc:204] Check failed: offset + len <= read.aligned_quality_size() (496 vs. 0). Fatal Python error: Aborted. Current thread 0x00007b82cc097740 (most recent call first):. File ""/tmp/Bazel.runfiles_vzux0__g/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 2040 in candidates_in_region. File ""/tmp/Bazel.runfiles_vzux0__g/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1734 in process. File ""/tmp/Bazel.runfiles_vzux0__g/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 2838 in make_examples_runner. File ""/tmp/Bazel.runfiles_vzux0__g/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 224 in main. File ""/tmp/Bazel.runfiles_vzux0__g/runfiles/absl_py/absl/app.py"", line 258 in _run_main. File ""/tmp/Bazel.runfiles_vzux0__g/runfiles/absl_py/absl/app.py"", line 312 in run. File ""/tmp/Bazel.runfiles_vzux0__g/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 234 in <module>. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/GRCh38.p13.genome.fa --rea",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/877
https://github.com/google/deepvariant/issues/877:8433,availability,error,errors,8433,"199 --norealign_reads --regions chr17 --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels 0.12 --task 2. real 0m4.188s. user 0m3.295s. sys 0m0.885s`. **this is the form of bam files I have used:**. `molecule/22487242 0 chr1 11823 22 1S22=165N39=1X71=1X27=1X9=1X9=1X16=1D3=1X10=1X12=1X13=385N109=761N9=1I16=1X104=1X70=1X91=1I37=1X24=1X54=1D18=1X67=1X1=1X132=1X132=1X49=1X55=1X58= * 0 2590 GTAAACGAGATTGCCAGCACCGGGTGTCTGACTTCCAGCAACTGCTGGCCTGTGCCAGGGTGGAAGCTGAGCACTGGAGTGGAGTTTTCCTGTGGAGAGGAGCCATGCCTAGAGTGGGATGGGCCATTGTTCATATTCTGGCCCCTGTTGTCTGCATGTAACCTAATACCACGACCAGGCATGGGGGAAAGATTGGAGGAAGTTGAGTGAGAGGATCAACTTCTCTGACAACCTAGGCCAGTGTGTGGTGATGCCAGGCATGCCCTTCCCCAGCATCAGGTCTCCAGAGCTGCAGAAGACGACGGCCGACTTGGATCACACTCTTGTGAGTGTCCCCAGTGTTGCAGAGGCAGCTGCACCCACTGCCTGGCGCTGCGCCCTTCCTTTGCTCTGCCCGCTGGAGACGGTGTTTGTCATGGGCCTGGTCTGCAGGGATCCTGCTACAAAGGTGAAACCCAGGAGAGTGTGGAGTCCAGAGTGATGCCAGGACCCAGGCACAGGCATTAGTGCCCGTTGGAGAAAACAGGGGAATCCCGAAGAAATGGTGGGTCTTGGCCATCCGTGAGATCTTCCCAGGGCAGCTCCCCTCTGTGGAATCCAATCTGTCTTCCATCCTGCGTGGCCGAGGGCCAGGCTTCTCACTGGGGCCTCTGCAGGAGGCTGCCATTTGTCCTGCCCACCGTCTTAGAAGCGAGACGGAGCAGACTCATCTGCTACTGCCCTTTCTATAATAACTAAAGTTAGCTGCCCTGGACTATTCACCCCTAGTCTCAATTTAAAAAGATCCCCATGGCCACAGGGCCCCTGCCTGGGGGCTTGTCACCTCCCCCACCTTCTTCCTGAGTCACTTCTGCAGCCTTGCTCCCTAACCTGCCCCACAGCCTTGCCTGGATTTCTATCTCCCTGGCTTGGTGCCAGTTCCTCCAAGTCGATGGCACCTCCCTCCCTCTCAACCACTTGAGCAAACTCCAAGACATCTTCTTCCCCAACACCAGCAATTGTGCCAAGGGCCATTAGGCTCTCAGCATGACTATTTTTAGAGACCCCGTGTCTGTCACTGAAACCTTTTTTGTGGGAGACTATTCCTCCCATCTGCAACAGCTGCCCCTGCTGACGGCCCTTCTCTCCTCCCTCTCATCCCAGAGAAACAGGTCAGCTGGGAGCTCCTGCCCCCACTGCCTAGGGACCAACAGGGGCAGGAGGCAGTCACTGACCCCGAGAAGTTTGCATCCTGCACAGCTAGAGATCCTTTATTAAAAGCACACTGTTGGTTTCTGCTC * CB:Z:CCAACTCACATTGAAG XA:Z:XM-CB XM:Z:AGACAATCCGTA ic:i:1 im:Z:m84210_240422_080753_s1/229444864/ccs/5985_7265 is:i:1 it:Z:AGACAATCCGTACCAACTCACATTGAAG rc:i:1 RG:Z:e4927d21 zm:i:22487242 mg:f:98.1265 NM:i:24`. **Also, when I used test files, I got the final results without any errors**. All advice much appreciated!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/877
https://github.com/google/deepvariant/issues/877:5077,deployability,fail,failed,5077,"lecule/43885191: NOT_FOUND: Could not read base quality scores. 2024-09-03 12:26:09.056452: W third_party/nucleus/io/sam_reader.cc:612] Could not read base quality scores molecule/25963197: NOT_FOUND: Could not read base quality scores. 2024-09-03 12:26:09.056463: W third_party/nucleus/io/sam_reader.cc:612] Could not read base quality scores molecule/25963211: NOT_FOUND: Could not read base quality scores. 2024-09-03 12:26:09.056474: W third_party/nucleus/io/sam_reader.cc:612] Could not read base quality scores molecule/25963212: NOT_FOUND: Could not read base quality scores. 2024-09-03 12:26:09.056489: W third_party/nucleus/io/sam_reader.cc:612] Could not read base quality scores molecule/9461690: NOT_FOUND: Could not read base quality scores. 2024-09-03 12:26:09.056506: W third_party/nucleus/io/sam_reader.cc:612] Could not read base quality scores molecule/8764719: NOT_FOUND: Could not read base quality scores. 2024-09-03 12:26:09.086379: F deepvariant/allelecounter.cc:204] Check failed: offset + len <= read.aligned_quality_size() (496 vs. 0). Fatal Python error: Aborted. Current thread 0x00007b82cc097740 (most recent call first):. File ""/tmp/Bazel.runfiles_vzux0__g/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 2040 in candidates_in_region. File ""/tmp/Bazel.runfiles_vzux0__g/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1734 in process. File ""/tmp/Bazel.runfiles_vzux0__g/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 2838 in make_examples_runner. File ""/tmp/Bazel.runfiles_vzux0__g/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 224 in main. File ""/tmp/Bazel.runfiles_vzux0__g/runfiles/absl_py/absl/app.py"", line 258 in _run_main. File ""/tmp/Bazel.runfiles_vzux0__g/runfiles/absl_py/absl/app.py"", line 312 in run. File ""/tmp/Bazel.runfiles_vzux0__g/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 234 in <module>. parallel: This job failed:. /opt/deepva",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/877
https://github.com/google/deepvariant/issues/877:6032,deployability,modul,module,6032,"F deepvariant/allelecounter.cc:204] Check failed: offset + len <= read.aligned_quality_size() (496 vs. 0). Fatal Python error: Aborted. Current thread 0x00007b82cc097740 (most recent call first):. File ""/tmp/Bazel.runfiles_vzux0__g/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 2040 in candidates_in_region. File ""/tmp/Bazel.runfiles_vzux0__g/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1734 in process. File ""/tmp/Bazel.runfiles_vzux0__g/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 2838 in make_examples_runner. File ""/tmp/Bazel.runfiles_vzux0__g/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 224 in main. File ""/tmp/Bazel.runfiles_vzux0__g/runfiles/absl_py/absl/app.py"", line 258 in _run_main. File ""/tmp/Bazel.runfiles_vzux0__g/runfiles/absl_py/absl/app.py"", line 312 in run. File ""/tmp/Bazel.runfiles_vzux0__g/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 234 in <module>. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/GRCh38.p13.genome.fa --reads /input/9091.aligned.bam --examples /tmp/tmp6ub5qq7n/make_examples.tfrecord@4.gz --add_hp_channel --alt_aligned_pileup diff_channels --gvcf /tmp/tmp6ub5qq7n/gvcf.tfrecord@4.gz --max_reads_per_partition 600 --min_mapping_quality 1 --parse_sam_aux_fields --partition_size 25000 --phase_reads --pileup_image_width 199 --norealign_reads --regions chr17 --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels 0.12 --task 2. real 0m4.188s. user 0m3.295s. sys 0m0.885s`. **this is the form of bam files I have used:**. `molecule/22487242 0 chr1 11823 22 1S22=165N39=1X71=1X27=1X9=1X9=1X16=1D3=1X10=1X12=1X13=385N109=761N9=1I16=1X104=1X70=1X91=1I37=1X24=1X54=1D18=1X67=1X1=1X132=1X132=1X49=1X55=1X58= * 0 2590 GTAAACGAGATTGCCAGCACCGGGTGTCTGACTTCCAGCAACTGCTGGCCTGTGCCAGGGTGGAAGCTGAGCACTGGAGTGGAGTTTTCCTGTGGAGAGGAGCCATGCCTAGAGTGGGATGGGCCATTGTTCATATTCTGGCCCCTGTTGTCTGCATGTAACC",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/877
https://github.com/google/deepvariant/issues/877:6060,deployability,fail,failed,6060,"cc:204] Check failed: offset + len <= read.aligned_quality_size() (496 vs. 0). Fatal Python error: Aborted. Current thread 0x00007b82cc097740 (most recent call first):. File ""/tmp/Bazel.runfiles_vzux0__g/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 2040 in candidates_in_region. File ""/tmp/Bazel.runfiles_vzux0__g/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1734 in process. File ""/tmp/Bazel.runfiles_vzux0__g/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 2838 in make_examples_runner. File ""/tmp/Bazel.runfiles_vzux0__g/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 224 in main. File ""/tmp/Bazel.runfiles_vzux0__g/runfiles/absl_py/absl/app.py"", line 258 in _run_main. File ""/tmp/Bazel.runfiles_vzux0__g/runfiles/absl_py/absl/app.py"", line 312 in run. File ""/tmp/Bazel.runfiles_vzux0__g/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 234 in <module>. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/GRCh38.p13.genome.fa --reads /input/9091.aligned.bam --examples /tmp/tmp6ub5qq7n/make_examples.tfrecord@4.gz --add_hp_channel --alt_aligned_pileup diff_channels --gvcf /tmp/tmp6ub5qq7n/gvcf.tfrecord@4.gz --max_reads_per_partition 600 --min_mapping_quality 1 --parse_sam_aux_fields --partition_size 25000 --phase_reads --pileup_image_width 199 --norealign_reads --regions chr17 --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels 0.12 --task 2. real 0m4.188s. user 0m3.295s. sys 0m0.885s`. **this is the form of bam files I have used:**. `molecule/22487242 0 chr1 11823 22 1S22=165N39=1X71=1X27=1X9=1X9=1X16=1D3=1X10=1X12=1X13=385N109=761N9=1I16=1X104=1X70=1X91=1I37=1X24=1X54=1D18=1X67=1X1=1X132=1X132=1X49=1X55=1X58= * 0 2590 GTAAACGAGATTGCCAGCACCGGGTGTCTGACTTCCAGCAACTGCTGGCCTGTGCCAGGGTGGAAGCTGAGCACTGGAGTGGAGTTTTCCTGTGGAGAGGAGCCATGCCTAGAGTGGGATGGGCCATTGTTCATATTCTGGCCCCTGTTGTCTGCATGTAACCTAATACCACGACCAGGCATGGGGGAAAG",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/877
https://github.com/google/deepvariant/issues/877:5171,energy efficiency,Current,Current,5171,"hird_party/nucleus/io/sam_reader.cc:612] Could not read base quality scores molecule/25963197: NOT_FOUND: Could not read base quality scores. 2024-09-03 12:26:09.056463: W third_party/nucleus/io/sam_reader.cc:612] Could not read base quality scores molecule/25963211: NOT_FOUND: Could not read base quality scores. 2024-09-03 12:26:09.056474: W third_party/nucleus/io/sam_reader.cc:612] Could not read base quality scores molecule/25963212: NOT_FOUND: Could not read base quality scores. 2024-09-03 12:26:09.056489: W third_party/nucleus/io/sam_reader.cc:612] Could not read base quality scores molecule/9461690: NOT_FOUND: Could not read base quality scores. 2024-09-03 12:26:09.056506: W third_party/nucleus/io/sam_reader.cc:612] Could not read base quality scores molecule/8764719: NOT_FOUND: Could not read base quality scores. 2024-09-03 12:26:09.086379: F deepvariant/allelecounter.cc:204] Check failed: offset + len <= read.aligned_quality_size() (496 vs. 0). Fatal Python error: Aborted. Current thread 0x00007b82cc097740 (most recent call first):. File ""/tmp/Bazel.runfiles_vzux0__g/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 2040 in candidates_in_region. File ""/tmp/Bazel.runfiles_vzux0__g/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1734 in process. File ""/tmp/Bazel.runfiles_vzux0__g/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 2838 in make_examples_runner. File ""/tmp/Bazel.runfiles_vzux0__g/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 224 in main. File ""/tmp/Bazel.runfiles_vzux0__g/runfiles/absl_py/absl/app.py"", line 258 in _run_main. File ""/tmp/Bazel.runfiles_vzux0__g/runfiles/absl_py/absl/app.py"", line 312 in run. File ""/tmp/Bazel.runfiles_vzux0__g/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 234 in <module>. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/GRCh38.p13.genome.fa --reads /input/9091.al",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/877
https://github.com/google/deepvariant/issues/877:159,integrability,messag,messages,159,"Fatal Python error: Aborted; **Hello, I ran deep variant for mutation calling of single cell iso seq bam file (Pacbio long read rna-seq), and I got this error messages:**. `9-03 12:26:09.055921: W third_party/nucleus/io/sam_reader.cc:612] Could not read base quality scores molecule/44871400: NOT_FOUND: Could not read base quality scores. 2024-09-03 12:26:09.055938: W third_party/nucleus/io/sam_reader.cc:612] Could not read base quality scores molecule/22677071: NOT_FOUND: Could not read base quality scores. 2024-09-03 12:26:09.055954: W third_party/nucleus/io/sam_reader.cc:612] Could not read base quality scores molecule/31298741: NOT_FOUND: Could not read base quality scores. 2024-09-03 12:26:09.055967: W third_party/nucleus/io/sam_reader.cc:612] Could not read base quality scores molecule/31321506: NOT_FOUND: Could not read base quality scores. 2024-09-03 12:26:09.055980: W third_party/nucleus/io/sam_reader.cc:612] Could not read base quality scores molecule/31927218: NOT_FOUND: Could not read base quality scores. 2024-09-03 12:26:09.055993: W third_party/nucleus/io/sam_reader.cc:612] Could not read base quality scores molecule/25969828: NOT_FOUND: Could not read base quality scores. 2024-09-03 12:26:09.056006: W third_party/nucleus/io/sam_reader.cc:612] Could not read base quality scores molecule/6236354: NOT_FOUND: Could not read base quality scores. 2024-09-03 12:26:09.056021: W third_party/nucleus/io/sam_reader.cc:612] Could not read base quality scores molecule/32560810: NOT_FOUND: Could not read base quality scores. 2024-09-03 12:26:09.056034: W third_party/nucleus/io/sam_reader.cc:612] Could not read base quality scores molecule/12686626: NOT_FOUND: Could not read base quality scores. 2024-09-03 12:26:09.056046: W third_party/nucleus/io/sam_reader.cc:612] Could not read base quality scores molecule/12686630: NOT_FOUND: Could not read base quality scores. 2024-09-03 12:26:09.056060: W third_party/nucleus/io/sam_reader.cc:612] Could not read base quality scor",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/877
https://github.com/google/deepvariant/issues/877:159,interoperability,messag,messages,159,"Fatal Python error: Aborted; **Hello, I ran deep variant for mutation calling of single cell iso seq bam file (Pacbio long read rna-seq), and I got this error messages:**. `9-03 12:26:09.055921: W third_party/nucleus/io/sam_reader.cc:612] Could not read base quality scores molecule/44871400: NOT_FOUND: Could not read base quality scores. 2024-09-03 12:26:09.055938: W third_party/nucleus/io/sam_reader.cc:612] Could not read base quality scores molecule/22677071: NOT_FOUND: Could not read base quality scores. 2024-09-03 12:26:09.055954: W third_party/nucleus/io/sam_reader.cc:612] Could not read base quality scores molecule/31298741: NOT_FOUND: Could not read base quality scores. 2024-09-03 12:26:09.055967: W third_party/nucleus/io/sam_reader.cc:612] Could not read base quality scores molecule/31321506: NOT_FOUND: Could not read base quality scores. 2024-09-03 12:26:09.055980: W third_party/nucleus/io/sam_reader.cc:612] Could not read base quality scores molecule/31927218: NOT_FOUND: Could not read base quality scores. 2024-09-03 12:26:09.055993: W third_party/nucleus/io/sam_reader.cc:612] Could not read base quality scores molecule/25969828: NOT_FOUND: Could not read base quality scores. 2024-09-03 12:26:09.056006: W third_party/nucleus/io/sam_reader.cc:612] Could not read base quality scores molecule/6236354: NOT_FOUND: Could not read base quality scores. 2024-09-03 12:26:09.056021: W third_party/nucleus/io/sam_reader.cc:612] Could not read base quality scores molecule/32560810: NOT_FOUND: Could not read base quality scores. 2024-09-03 12:26:09.056034: W third_party/nucleus/io/sam_reader.cc:612] Could not read base quality scores molecule/12686626: NOT_FOUND: Could not read base quality scores. 2024-09-03 12:26:09.056046: W third_party/nucleus/io/sam_reader.cc:612] Could not read base quality scores molecule/12686630: NOT_FOUND: Could not read base quality scores. 2024-09-03 12:26:09.056060: W third_party/nucleus/io/sam_reader.cc:612] Could not read base quality scor",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/877
https://github.com/google/deepvariant/issues/877:111,modifiability,Pac,Pacbio,111,"Fatal Python error: Aborted; **Hello, I ran deep variant for mutation calling of single cell iso seq bam file (Pacbio long read rna-seq), and I got this error messages:**. `9-03 12:26:09.055921: W third_party/nucleus/io/sam_reader.cc:612] Could not read base quality scores molecule/44871400: NOT_FOUND: Could not read base quality scores. 2024-09-03 12:26:09.055938: W third_party/nucleus/io/sam_reader.cc:612] Could not read base quality scores molecule/22677071: NOT_FOUND: Could not read base quality scores. 2024-09-03 12:26:09.055954: W third_party/nucleus/io/sam_reader.cc:612] Could not read base quality scores molecule/31298741: NOT_FOUND: Could not read base quality scores. 2024-09-03 12:26:09.055967: W third_party/nucleus/io/sam_reader.cc:612] Could not read base quality scores molecule/31321506: NOT_FOUND: Could not read base quality scores. 2024-09-03 12:26:09.055980: W third_party/nucleus/io/sam_reader.cc:612] Could not read base quality scores molecule/31927218: NOT_FOUND: Could not read base quality scores. 2024-09-03 12:26:09.055993: W third_party/nucleus/io/sam_reader.cc:612] Could not read base quality scores molecule/25969828: NOT_FOUND: Could not read base quality scores. 2024-09-03 12:26:09.056006: W third_party/nucleus/io/sam_reader.cc:612] Could not read base quality scores molecule/6236354: NOT_FOUND: Could not read base quality scores. 2024-09-03 12:26:09.056021: W third_party/nucleus/io/sam_reader.cc:612] Could not read base quality scores molecule/32560810: NOT_FOUND: Could not read base quality scores. 2024-09-03 12:26:09.056034: W third_party/nucleus/io/sam_reader.cc:612] Could not read base quality scores molecule/12686626: NOT_FOUND: Could not read base quality scores. 2024-09-03 12:26:09.056046: W third_party/nucleus/io/sam_reader.cc:612] Could not read base quality scores molecule/12686630: NOT_FOUND: Could not read base quality scores. 2024-09-03 12:26:09.056060: W third_party/nucleus/io/sam_reader.cc:612] Could not read base quality scor",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/877
https://github.com/google/deepvariant/issues/877:6032,modifiability,modul,module,6032,"F deepvariant/allelecounter.cc:204] Check failed: offset + len <= read.aligned_quality_size() (496 vs. 0). Fatal Python error: Aborted. Current thread 0x00007b82cc097740 (most recent call first):. File ""/tmp/Bazel.runfiles_vzux0__g/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 2040 in candidates_in_region. File ""/tmp/Bazel.runfiles_vzux0__g/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1734 in process. File ""/tmp/Bazel.runfiles_vzux0__g/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 2838 in make_examples_runner. File ""/tmp/Bazel.runfiles_vzux0__g/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 224 in main. File ""/tmp/Bazel.runfiles_vzux0__g/runfiles/absl_py/absl/app.py"", line 258 in _run_main. File ""/tmp/Bazel.runfiles_vzux0__g/runfiles/absl_py/absl/app.py"", line 312 in run. File ""/tmp/Bazel.runfiles_vzux0__g/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 234 in <module>. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/GRCh38.p13.genome.fa --reads /input/9091.aligned.bam --examples /tmp/tmp6ub5qq7n/make_examples.tfrecord@4.gz --add_hp_channel --alt_aligned_pileup diff_channels --gvcf /tmp/tmp6ub5qq7n/gvcf.tfrecord@4.gz --max_reads_per_partition 600 --min_mapping_quality 1 --parse_sam_aux_fields --partition_size 25000 --phase_reads --pileup_image_width 199 --norealign_reads --regions chr17 --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels 0.12 --task 2. real 0m4.188s. user 0m3.295s. sys 0m0.885s`. **this is the form of bam files I have used:**. `molecule/22487242 0 chr1 11823 22 1S22=165N39=1X71=1X27=1X9=1X9=1X16=1D3=1X10=1X12=1X13=385N109=761N9=1I16=1X104=1X70=1X91=1I37=1X24=1X54=1D18=1X67=1X1=1X132=1X132=1X49=1X55=1X58= * 0 2590 GTAAACGAGATTGCCAGCACCGGGTGTCTGACTTCCAGCAACTGCTGGCCTGTGCCAGGGTGGAAGCTGAGCACTGGAGTGGAGTTTTCCTGTGGAGAGGAGCCATGCCTAGAGTGGGATGGGCCATTGTTCATATTCTGGCCCCTGTTGTCTGCATGTAACC",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/877
https://github.com/google/deepvariant/issues/877:13,performance,error,error,13,"Fatal Python error: Aborted; **Hello, I ran deep variant for mutation calling of single cell iso seq bam file (Pacbio long read rna-seq), and I got this error messages:**. `9-03 12:26:09.055921: W third_party/nucleus/io/sam_reader.cc:612] Could not read base quality scores molecule/44871400: NOT_FOUND: Could not read base quality scores. 2024-09-03 12:26:09.055938: W third_party/nucleus/io/sam_reader.cc:612] Could not read base quality scores molecule/22677071: NOT_FOUND: Could not read base quality scores. 2024-09-03 12:26:09.055954: W third_party/nucleus/io/sam_reader.cc:612] Could not read base quality scores molecule/31298741: NOT_FOUND: Could not read base quality scores. 2024-09-03 12:26:09.055967: W third_party/nucleus/io/sam_reader.cc:612] Could not read base quality scores molecule/31321506: NOT_FOUND: Could not read base quality scores. 2024-09-03 12:26:09.055980: W third_party/nucleus/io/sam_reader.cc:612] Could not read base quality scores molecule/31927218: NOT_FOUND: Could not read base quality scores. 2024-09-03 12:26:09.055993: W third_party/nucleus/io/sam_reader.cc:612] Could not read base quality scores molecule/25969828: NOT_FOUND: Could not read base quality scores. 2024-09-03 12:26:09.056006: W third_party/nucleus/io/sam_reader.cc:612] Could not read base quality scores molecule/6236354: NOT_FOUND: Could not read base quality scores. 2024-09-03 12:26:09.056021: W third_party/nucleus/io/sam_reader.cc:612] Could not read base quality scores molecule/32560810: NOT_FOUND: Could not read base quality scores. 2024-09-03 12:26:09.056034: W third_party/nucleus/io/sam_reader.cc:612] Could not read base quality scores molecule/12686626: NOT_FOUND: Could not read base quality scores. 2024-09-03 12:26:09.056046: W third_party/nucleus/io/sam_reader.cc:612] Could not read base quality scores molecule/12686630: NOT_FOUND: Could not read base quality scores. 2024-09-03 12:26:09.056060: W third_party/nucleus/io/sam_reader.cc:612] Could not read base quality scor",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/877
https://github.com/google/deepvariant/issues/877:153,performance,error,error,153,"Fatal Python error: Aborted; **Hello, I ran deep variant for mutation calling of single cell iso seq bam file (Pacbio long read rna-seq), and I got this error messages:**. `9-03 12:26:09.055921: W third_party/nucleus/io/sam_reader.cc:612] Could not read base quality scores molecule/44871400: NOT_FOUND: Could not read base quality scores. 2024-09-03 12:26:09.055938: W third_party/nucleus/io/sam_reader.cc:612] Could not read base quality scores molecule/22677071: NOT_FOUND: Could not read base quality scores. 2024-09-03 12:26:09.055954: W third_party/nucleus/io/sam_reader.cc:612] Could not read base quality scores molecule/31298741: NOT_FOUND: Could not read base quality scores. 2024-09-03 12:26:09.055967: W third_party/nucleus/io/sam_reader.cc:612] Could not read base quality scores molecule/31321506: NOT_FOUND: Could not read base quality scores. 2024-09-03 12:26:09.055980: W third_party/nucleus/io/sam_reader.cc:612] Could not read base quality scores molecule/31927218: NOT_FOUND: Could not read base quality scores. 2024-09-03 12:26:09.055993: W third_party/nucleus/io/sam_reader.cc:612] Could not read base quality scores molecule/25969828: NOT_FOUND: Could not read base quality scores. 2024-09-03 12:26:09.056006: W third_party/nucleus/io/sam_reader.cc:612] Could not read base quality scores molecule/6236354: NOT_FOUND: Could not read base quality scores. 2024-09-03 12:26:09.056021: W third_party/nucleus/io/sam_reader.cc:612] Could not read base quality scores molecule/32560810: NOT_FOUND: Could not read base quality scores. 2024-09-03 12:26:09.056034: W third_party/nucleus/io/sam_reader.cc:612] Could not read base quality scores molecule/12686626: NOT_FOUND: Could not read base quality scores. 2024-09-03 12:26:09.056046: W third_party/nucleus/io/sam_reader.cc:612] Could not read base quality scores molecule/12686630: NOT_FOUND: Could not read base quality scores. 2024-09-03 12:26:09.056060: W third_party/nucleus/io/sam_reader.cc:612] Could not read base quality scor",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/877
https://github.com/google/deepvariant/issues/877:5155,performance,error,error,5155,"26:09.056452: W third_party/nucleus/io/sam_reader.cc:612] Could not read base quality scores molecule/25963197: NOT_FOUND: Could not read base quality scores. 2024-09-03 12:26:09.056463: W third_party/nucleus/io/sam_reader.cc:612] Could not read base quality scores molecule/25963211: NOT_FOUND: Could not read base quality scores. 2024-09-03 12:26:09.056474: W third_party/nucleus/io/sam_reader.cc:612] Could not read base quality scores molecule/25963212: NOT_FOUND: Could not read base quality scores. 2024-09-03 12:26:09.056489: W third_party/nucleus/io/sam_reader.cc:612] Could not read base quality scores molecule/9461690: NOT_FOUND: Could not read base quality scores. 2024-09-03 12:26:09.056506: W third_party/nucleus/io/sam_reader.cc:612] Could not read base quality scores molecule/8764719: NOT_FOUND: Could not read base quality scores. 2024-09-03 12:26:09.086379: F deepvariant/allelecounter.cc:204] Check failed: offset + len <= read.aligned_quality_size() (496 vs. 0). Fatal Python error: Aborted. Current thread 0x00007b82cc097740 (most recent call first):. File ""/tmp/Bazel.runfiles_vzux0__g/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 2040 in candidates_in_region. File ""/tmp/Bazel.runfiles_vzux0__g/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1734 in process. File ""/tmp/Bazel.runfiles_vzux0__g/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 2838 in make_examples_runner. File ""/tmp/Bazel.runfiles_vzux0__g/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 224 in main. File ""/tmp/Bazel.runfiles_vzux0__g/runfiles/absl_py/absl/app.py"", line 258 in _run_main. File ""/tmp/Bazel.runfiles_vzux0__g/runfiles/absl_py/absl/app.py"", line 312 in run. File ""/tmp/Bazel.runfiles_vzux0__g/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 234 in <module>. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/GRCh38.p13.genome.fa --rea",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/877
https://github.com/google/deepvariant/issues/877:6041,performance,parallel,parallel,6041,"ant/allelecounter.cc:204] Check failed: offset + len <= read.aligned_quality_size() (496 vs. 0). Fatal Python error: Aborted. Current thread 0x00007b82cc097740 (most recent call first):. File ""/tmp/Bazel.runfiles_vzux0__g/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 2040 in candidates_in_region. File ""/tmp/Bazel.runfiles_vzux0__g/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1734 in process. File ""/tmp/Bazel.runfiles_vzux0__g/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 2838 in make_examples_runner. File ""/tmp/Bazel.runfiles_vzux0__g/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 224 in main. File ""/tmp/Bazel.runfiles_vzux0__g/runfiles/absl_py/absl/app.py"", line 258 in _run_main. File ""/tmp/Bazel.runfiles_vzux0__g/runfiles/absl_py/absl/app.py"", line 312 in run. File ""/tmp/Bazel.runfiles_vzux0__g/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 234 in <module>. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/GRCh38.p13.genome.fa --reads /input/9091.aligned.bam --examples /tmp/tmp6ub5qq7n/make_examples.tfrecord@4.gz --add_hp_channel --alt_aligned_pileup diff_channels --gvcf /tmp/tmp6ub5qq7n/gvcf.tfrecord@4.gz --max_reads_per_partition 600 --min_mapping_quality 1 --parse_sam_aux_fields --partition_size 25000 --phase_reads --pileup_image_width 199 --norealign_reads --regions chr17 --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels 0.12 --task 2. real 0m4.188s. user 0m3.295s. sys 0m0.885s`. **this is the form of bam files I have used:**. `molecule/22487242 0 chr1 11823 22 1S22=165N39=1X71=1X27=1X9=1X9=1X16=1D3=1X10=1X12=1X13=385N109=761N9=1I16=1X104=1X70=1X91=1I37=1X24=1X54=1D18=1X67=1X1=1X132=1X132=1X49=1X55=1X58= * 0 2590 GTAAACGAGATTGCCAGCACCGGGTGTCTGACTTCCAGCAACTGCTGGCCTGTGCCAGGGTGGAAGCTGAGCACTGGAGTGGAGTTTTCCTGTGGAGAGGAGCCATGCCTAGAGTGGGATGGGCCATTGTTCATATTCTGGCCCCTGTTGTCTGCATGTAACCTAATACCACG",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/877
https://github.com/google/deepvariant/issues/877:8433,performance,error,errors,8433,"199 --norealign_reads --regions chr17 --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels 0.12 --task 2. real 0m4.188s. user 0m3.295s. sys 0m0.885s`. **this is the form of bam files I have used:**. `molecule/22487242 0 chr1 11823 22 1S22=165N39=1X71=1X27=1X9=1X9=1X16=1D3=1X10=1X12=1X13=385N109=761N9=1I16=1X104=1X70=1X91=1I37=1X24=1X54=1D18=1X67=1X1=1X132=1X132=1X49=1X55=1X58= * 0 2590 GTAAACGAGATTGCCAGCACCGGGTGTCTGACTTCCAGCAACTGCTGGCCTGTGCCAGGGTGGAAGCTGAGCACTGGAGTGGAGTTTTCCTGTGGAGAGGAGCCATGCCTAGAGTGGGATGGGCCATTGTTCATATTCTGGCCCCTGTTGTCTGCATGTAACCTAATACCACGACCAGGCATGGGGGAAAGATTGGAGGAAGTTGAGTGAGAGGATCAACTTCTCTGACAACCTAGGCCAGTGTGTGGTGATGCCAGGCATGCCCTTCCCCAGCATCAGGTCTCCAGAGCTGCAGAAGACGACGGCCGACTTGGATCACACTCTTGTGAGTGTCCCCAGTGTTGCAGAGGCAGCTGCACCCACTGCCTGGCGCTGCGCCCTTCCTTTGCTCTGCCCGCTGGAGACGGTGTTTGTCATGGGCCTGGTCTGCAGGGATCCTGCTACAAAGGTGAAACCCAGGAGAGTGTGGAGTCCAGAGTGATGCCAGGACCCAGGCACAGGCATTAGTGCCCGTTGGAGAAAACAGGGGAATCCCGAAGAAATGGTGGGTCTTGGCCATCCGTGAGATCTTCCCAGGGCAGCTCCCCTCTGTGGAATCCAATCTGTCTTCCATCCTGCGTGGCCGAGGGCCAGGCTTCTCACTGGGGCCTCTGCAGGAGGCTGCCATTTGTCCTGCCCACCGTCTTAGAAGCGAGACGGAGCAGACTCATCTGCTACTGCCCTTTCTATAATAACTAAAGTTAGCTGCCCTGGACTATTCACCCCTAGTCTCAATTTAAAAAGATCCCCATGGCCACAGGGCCCCTGCCTGGGGGCTTGTCACCTCCCCCACCTTCTTCCTGAGTCACTTCTGCAGCCTTGCTCCCTAACCTGCCCCACAGCCTTGCCTGGATTTCTATCTCCCTGGCTTGGTGCCAGTTCCTCCAAGTCGATGGCACCTCCCTCCCTCTCAACCACTTGAGCAAACTCCAAGACATCTTCTTCCCCAACACCAGCAATTGTGCCAAGGGCCATTAGGCTCTCAGCATGACTATTTTTAGAGACCCCGTGTCTGTCACTGAAACCTTTTTTGTGGGAGACTATTCCTCCCATCTGCAACAGCTGCCCCTGCTGACGGCCCTTCTCTCCTCCCTCTCATCCCAGAGAAACAGGTCAGCTGGGAGCTCCTGCCCCCACTGCCTAGGGACCAACAGGGGCAGGAGGCAGTCACTGACCCCGAGAAGTTTGCATCCTGCACAGCTAGAGATCCTTTATTAAAAGCACACTGTTGGTTTCTGCTC * CB:Z:CCAACTCACATTGAAG XA:Z:XM-CB XM:Z:AGACAATCCGTA ic:i:1 im:Z:m84210_240422_080753_s1/229444864/ccs/5985_7265 is:i:1 it:Z:AGACAATCCGTACCAACTCACATTGAAG rc:i:1 RG:Z:e4927d21 zm:i:22487242 mg:f:98.1265 NM:i:24`. **Also, when I used test files, I got the final results without any errors**. All advice much appreciated!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/877
https://github.com/google/deepvariant/issues/877:5077,reliability,fail,failed,5077,"lecule/43885191: NOT_FOUND: Could not read base quality scores. 2024-09-03 12:26:09.056452: W third_party/nucleus/io/sam_reader.cc:612] Could not read base quality scores molecule/25963197: NOT_FOUND: Could not read base quality scores. 2024-09-03 12:26:09.056463: W third_party/nucleus/io/sam_reader.cc:612] Could not read base quality scores molecule/25963211: NOT_FOUND: Could not read base quality scores. 2024-09-03 12:26:09.056474: W third_party/nucleus/io/sam_reader.cc:612] Could not read base quality scores molecule/25963212: NOT_FOUND: Could not read base quality scores. 2024-09-03 12:26:09.056489: W third_party/nucleus/io/sam_reader.cc:612] Could not read base quality scores molecule/9461690: NOT_FOUND: Could not read base quality scores. 2024-09-03 12:26:09.056506: W third_party/nucleus/io/sam_reader.cc:612] Could not read base quality scores molecule/8764719: NOT_FOUND: Could not read base quality scores. 2024-09-03 12:26:09.086379: F deepvariant/allelecounter.cc:204] Check failed: offset + len <= read.aligned_quality_size() (496 vs. 0). Fatal Python error: Aborted. Current thread 0x00007b82cc097740 (most recent call first):. File ""/tmp/Bazel.runfiles_vzux0__g/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 2040 in candidates_in_region. File ""/tmp/Bazel.runfiles_vzux0__g/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1734 in process. File ""/tmp/Bazel.runfiles_vzux0__g/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 2838 in make_examples_runner. File ""/tmp/Bazel.runfiles_vzux0__g/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 224 in main. File ""/tmp/Bazel.runfiles_vzux0__g/runfiles/absl_py/absl/app.py"", line 258 in _run_main. File ""/tmp/Bazel.runfiles_vzux0__g/runfiles/absl_py/absl/app.py"", line 312 in run. File ""/tmp/Bazel.runfiles_vzux0__g/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 234 in <module>. parallel: This job failed:. /opt/deepva",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/877
https://github.com/google/deepvariant/issues/877:6060,reliability,fail,failed,6060,"cc:204] Check failed: offset + len <= read.aligned_quality_size() (496 vs. 0). Fatal Python error: Aborted. Current thread 0x00007b82cc097740 (most recent call first):. File ""/tmp/Bazel.runfiles_vzux0__g/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 2040 in candidates_in_region. File ""/tmp/Bazel.runfiles_vzux0__g/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1734 in process. File ""/tmp/Bazel.runfiles_vzux0__g/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 2838 in make_examples_runner. File ""/tmp/Bazel.runfiles_vzux0__g/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 224 in main. File ""/tmp/Bazel.runfiles_vzux0__g/runfiles/absl_py/absl/app.py"", line 258 in _run_main. File ""/tmp/Bazel.runfiles_vzux0__g/runfiles/absl_py/absl/app.py"", line 312 in run. File ""/tmp/Bazel.runfiles_vzux0__g/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 234 in <module>. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/GRCh38.p13.genome.fa --reads /input/9091.aligned.bam --examples /tmp/tmp6ub5qq7n/make_examples.tfrecord@4.gz --add_hp_channel --alt_aligned_pileup diff_channels --gvcf /tmp/tmp6ub5qq7n/gvcf.tfrecord@4.gz --max_reads_per_partition 600 --min_mapping_quality 1 --parse_sam_aux_fields --partition_size 25000 --phase_reads --pileup_image_width 199 --norealign_reads --regions chr17 --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels 0.12 --task 2. real 0m4.188s. user 0m3.295s. sys 0m0.885s`. **this is the form of bam files I have used:**. `molecule/22487242 0 chr1 11823 22 1S22=165N39=1X71=1X27=1X9=1X9=1X16=1D3=1X10=1X12=1X13=385N109=761N9=1I16=1X104=1X70=1X91=1I37=1X24=1X54=1D18=1X67=1X1=1X132=1X132=1X49=1X55=1X58= * 0 2590 GTAAACGAGATTGCCAGCACCGGGTGTCTGACTTCCAGCAACTGCTGGCCTGTGCCAGGGTGGAAGCTGAGCACTGGAGTGGAGTTTTCCTGTGGAGAGGAGCCATGCCTAGAGTGGGATGGGCCATTGTTCATATTCTGGCCCCTGTTGTCTGCATGTAACCTAATACCACGACCAGGCATGGGGGAAAG",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/877
https://github.com/google/deepvariant/issues/877:13,safety,error,error,13,"Fatal Python error: Aborted; **Hello, I ran deep variant for mutation calling of single cell iso seq bam file (Pacbio long read rna-seq), and I got this error messages:**. `9-03 12:26:09.055921: W third_party/nucleus/io/sam_reader.cc:612] Could not read base quality scores molecule/44871400: NOT_FOUND: Could not read base quality scores. 2024-09-03 12:26:09.055938: W third_party/nucleus/io/sam_reader.cc:612] Could not read base quality scores molecule/22677071: NOT_FOUND: Could not read base quality scores. 2024-09-03 12:26:09.055954: W third_party/nucleus/io/sam_reader.cc:612] Could not read base quality scores molecule/31298741: NOT_FOUND: Could not read base quality scores. 2024-09-03 12:26:09.055967: W third_party/nucleus/io/sam_reader.cc:612] Could not read base quality scores molecule/31321506: NOT_FOUND: Could not read base quality scores. 2024-09-03 12:26:09.055980: W third_party/nucleus/io/sam_reader.cc:612] Could not read base quality scores molecule/31927218: NOT_FOUND: Could not read base quality scores. 2024-09-03 12:26:09.055993: W third_party/nucleus/io/sam_reader.cc:612] Could not read base quality scores molecule/25969828: NOT_FOUND: Could not read base quality scores. 2024-09-03 12:26:09.056006: W third_party/nucleus/io/sam_reader.cc:612] Could not read base quality scores molecule/6236354: NOT_FOUND: Could not read base quality scores. 2024-09-03 12:26:09.056021: W third_party/nucleus/io/sam_reader.cc:612] Could not read base quality scores molecule/32560810: NOT_FOUND: Could not read base quality scores. 2024-09-03 12:26:09.056034: W third_party/nucleus/io/sam_reader.cc:612] Could not read base quality scores molecule/12686626: NOT_FOUND: Could not read base quality scores. 2024-09-03 12:26:09.056046: W third_party/nucleus/io/sam_reader.cc:612] Could not read base quality scores molecule/12686630: NOT_FOUND: Could not read base quality scores. 2024-09-03 12:26:09.056060: W third_party/nucleus/io/sam_reader.cc:612] Could not read base quality scor",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/877
https://github.com/google/deepvariant/issues/877:153,safety,error,error,153,"Fatal Python error: Aborted; **Hello, I ran deep variant for mutation calling of single cell iso seq bam file (Pacbio long read rna-seq), and I got this error messages:**. `9-03 12:26:09.055921: W third_party/nucleus/io/sam_reader.cc:612] Could not read base quality scores molecule/44871400: NOT_FOUND: Could not read base quality scores. 2024-09-03 12:26:09.055938: W third_party/nucleus/io/sam_reader.cc:612] Could not read base quality scores molecule/22677071: NOT_FOUND: Could not read base quality scores. 2024-09-03 12:26:09.055954: W third_party/nucleus/io/sam_reader.cc:612] Could not read base quality scores molecule/31298741: NOT_FOUND: Could not read base quality scores. 2024-09-03 12:26:09.055967: W third_party/nucleus/io/sam_reader.cc:612] Could not read base quality scores molecule/31321506: NOT_FOUND: Could not read base quality scores. 2024-09-03 12:26:09.055980: W third_party/nucleus/io/sam_reader.cc:612] Could not read base quality scores molecule/31927218: NOT_FOUND: Could not read base quality scores. 2024-09-03 12:26:09.055993: W third_party/nucleus/io/sam_reader.cc:612] Could not read base quality scores molecule/25969828: NOT_FOUND: Could not read base quality scores. 2024-09-03 12:26:09.056006: W third_party/nucleus/io/sam_reader.cc:612] Could not read base quality scores molecule/6236354: NOT_FOUND: Could not read base quality scores. 2024-09-03 12:26:09.056021: W third_party/nucleus/io/sam_reader.cc:612] Could not read base quality scores molecule/32560810: NOT_FOUND: Could not read base quality scores. 2024-09-03 12:26:09.056034: W third_party/nucleus/io/sam_reader.cc:612] Could not read base quality scores molecule/12686626: NOT_FOUND: Could not read base quality scores. 2024-09-03 12:26:09.056046: W third_party/nucleus/io/sam_reader.cc:612] Could not read base quality scores molecule/12686630: NOT_FOUND: Could not read base quality scores. 2024-09-03 12:26:09.056060: W third_party/nucleus/io/sam_reader.cc:612] Could not read base quality scor",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/877
https://github.com/google/deepvariant/issues/877:5155,safety,error,error,5155,"26:09.056452: W third_party/nucleus/io/sam_reader.cc:612] Could not read base quality scores molecule/25963197: NOT_FOUND: Could not read base quality scores. 2024-09-03 12:26:09.056463: W third_party/nucleus/io/sam_reader.cc:612] Could not read base quality scores molecule/25963211: NOT_FOUND: Could not read base quality scores. 2024-09-03 12:26:09.056474: W third_party/nucleus/io/sam_reader.cc:612] Could not read base quality scores molecule/25963212: NOT_FOUND: Could not read base quality scores. 2024-09-03 12:26:09.056489: W third_party/nucleus/io/sam_reader.cc:612] Could not read base quality scores molecule/9461690: NOT_FOUND: Could not read base quality scores. 2024-09-03 12:26:09.056506: W third_party/nucleus/io/sam_reader.cc:612] Could not read base quality scores molecule/8764719: NOT_FOUND: Could not read base quality scores. 2024-09-03 12:26:09.086379: F deepvariant/allelecounter.cc:204] Check failed: offset + len <= read.aligned_quality_size() (496 vs. 0). Fatal Python error: Aborted. Current thread 0x00007b82cc097740 (most recent call first):. File ""/tmp/Bazel.runfiles_vzux0__g/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 2040 in candidates_in_region. File ""/tmp/Bazel.runfiles_vzux0__g/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1734 in process. File ""/tmp/Bazel.runfiles_vzux0__g/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 2838 in make_examples_runner. File ""/tmp/Bazel.runfiles_vzux0__g/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 224 in main. File ""/tmp/Bazel.runfiles_vzux0__g/runfiles/absl_py/absl/app.py"", line 258 in _run_main. File ""/tmp/Bazel.runfiles_vzux0__g/runfiles/absl_py/absl/app.py"", line 312 in run. File ""/tmp/Bazel.runfiles_vzux0__g/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 234 in <module>. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/GRCh38.p13.genome.fa --rea",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/877
https://github.com/google/deepvariant/issues/877:6032,safety,modul,module,6032,"F deepvariant/allelecounter.cc:204] Check failed: offset + len <= read.aligned_quality_size() (496 vs. 0). Fatal Python error: Aborted. Current thread 0x00007b82cc097740 (most recent call first):. File ""/tmp/Bazel.runfiles_vzux0__g/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 2040 in candidates_in_region. File ""/tmp/Bazel.runfiles_vzux0__g/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1734 in process. File ""/tmp/Bazel.runfiles_vzux0__g/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 2838 in make_examples_runner. File ""/tmp/Bazel.runfiles_vzux0__g/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 224 in main. File ""/tmp/Bazel.runfiles_vzux0__g/runfiles/absl_py/absl/app.py"", line 258 in _run_main. File ""/tmp/Bazel.runfiles_vzux0__g/runfiles/absl_py/absl/app.py"", line 312 in run. File ""/tmp/Bazel.runfiles_vzux0__g/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 234 in <module>. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/GRCh38.p13.genome.fa --reads /input/9091.aligned.bam --examples /tmp/tmp6ub5qq7n/make_examples.tfrecord@4.gz --add_hp_channel --alt_aligned_pileup diff_channels --gvcf /tmp/tmp6ub5qq7n/gvcf.tfrecord@4.gz --max_reads_per_partition 600 --min_mapping_quality 1 --parse_sam_aux_fields --partition_size 25000 --phase_reads --pileup_image_width 199 --norealign_reads --regions chr17 --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels 0.12 --task 2. real 0m4.188s. user 0m3.295s. sys 0m0.885s`. **this is the form of bam files I have used:**. `molecule/22487242 0 chr1 11823 22 1S22=165N39=1X71=1X27=1X9=1X9=1X16=1D3=1X10=1X12=1X13=385N109=761N9=1I16=1X104=1X70=1X91=1I37=1X24=1X54=1D18=1X67=1X1=1X132=1X132=1X49=1X55=1X58= * 0 2590 GTAAACGAGATTGCCAGCACCGGGTGTCTGACTTCCAGCAACTGCTGGCCTGTGCCAGGGTGGAAGCTGAGCACTGGAGTGGAGTTTTCCTGTGGAGAGGAGCCATGCCTAGAGTGGGATGGGCCATTGTTCATATTCTGGCCCCTGTTGTCTGCATGTAACC",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/877
https://github.com/google/deepvariant/issues/877:6126,safety,input,input,6126,"(496 vs. 0). Fatal Python error: Aborted. Current thread 0x00007b82cc097740 (most recent call first):. File ""/tmp/Bazel.runfiles_vzux0__g/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 2040 in candidates_in_region. File ""/tmp/Bazel.runfiles_vzux0__g/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1734 in process. File ""/tmp/Bazel.runfiles_vzux0__g/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 2838 in make_examples_runner. File ""/tmp/Bazel.runfiles_vzux0__g/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 224 in main. File ""/tmp/Bazel.runfiles_vzux0__g/runfiles/absl_py/absl/app.py"", line 258 in _run_main. File ""/tmp/Bazel.runfiles_vzux0__g/runfiles/absl_py/absl/app.py"", line 312 in run. File ""/tmp/Bazel.runfiles_vzux0__g/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 234 in <module>. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/GRCh38.p13.genome.fa --reads /input/9091.aligned.bam --examples /tmp/tmp6ub5qq7n/make_examples.tfrecord@4.gz --add_hp_channel --alt_aligned_pileup diff_channels --gvcf /tmp/tmp6ub5qq7n/gvcf.tfrecord@4.gz --max_reads_per_partition 600 --min_mapping_quality 1 --parse_sam_aux_fields --partition_size 25000 --phase_reads --pileup_image_width 199 --norealign_reads --regions chr17 --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels 0.12 --task 2. real 0m4.188s. user 0m3.295s. sys 0m0.885s`. **this is the form of bam files I have used:**. `molecule/22487242 0 chr1 11823 22 1S22=165N39=1X71=1X27=1X9=1X9=1X16=1D3=1X10=1X12=1X13=385N109=761N9=1I16=1X104=1X70=1X91=1I37=1X24=1X54=1D18=1X67=1X1=1X132=1X132=1X49=1X55=1X58= * 0 2590 GTAAACGAGATTGCCAGCACCGGGTGTCTGACTTCCAGCAACTGCTGGCCTGTGCCAGGGTGGAAGCTGAGCACTGGAGTGGAGTTTTCCTGTGGAGAGGAGCCATGCCTAGAGTGGGATGGGCCATTGTTCATATTCTGGCCCCTGTTGTCTGCATGTAACCTAATACCACGACCAGGCATGGGGGAAAGATTGGAGGAAGTTGAGTGAGAGGATCAACTTCTCTGACAACCTAGGCCAGTGTGTGGTGATGCCAG",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/877
https://github.com/google/deepvariant/issues/877:6162,safety,input,input,6162,"rted. Current thread 0x00007b82cc097740 (most recent call first):. File ""/tmp/Bazel.runfiles_vzux0__g/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 2040 in candidates_in_region. File ""/tmp/Bazel.runfiles_vzux0__g/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1734 in process. File ""/tmp/Bazel.runfiles_vzux0__g/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 2838 in make_examples_runner. File ""/tmp/Bazel.runfiles_vzux0__g/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 224 in main. File ""/tmp/Bazel.runfiles_vzux0__g/runfiles/absl_py/absl/app.py"", line 258 in _run_main. File ""/tmp/Bazel.runfiles_vzux0__g/runfiles/absl_py/absl/app.py"", line 312 in run. File ""/tmp/Bazel.runfiles_vzux0__g/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 234 in <module>. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/GRCh38.p13.genome.fa --reads /input/9091.aligned.bam --examples /tmp/tmp6ub5qq7n/make_examples.tfrecord@4.gz --add_hp_channel --alt_aligned_pileup diff_channels --gvcf /tmp/tmp6ub5qq7n/gvcf.tfrecord@4.gz --max_reads_per_partition 600 --min_mapping_quality 1 --parse_sam_aux_fields --partition_size 25000 --phase_reads --pileup_image_width 199 --norealign_reads --regions chr17 --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels 0.12 --task 2. real 0m4.188s. user 0m3.295s. sys 0m0.885s`. **this is the form of bam files I have used:**. `molecule/22487242 0 chr1 11823 22 1S22=165N39=1X71=1X27=1X9=1X9=1X16=1D3=1X10=1X12=1X13=385N109=761N9=1I16=1X104=1X70=1X91=1I37=1X24=1X54=1D18=1X67=1X1=1X132=1X132=1X49=1X55=1X58= * 0 2590 GTAAACGAGATTGCCAGCACCGGGTGTCTGACTTCCAGCAACTGCTGGCCTGTGCCAGGGTGGAAGCTGAGCACTGGAGTGGAGTTTTCCTGTGGAGAGGAGCCATGCCTAGAGTGGGATGGGCCATTGTTCATATTCTGGCCCCTGTTGTCTGCATGTAACCTAATACCACGACCAGGCATGGGGGAAAGATTGGAGGAAGTTGAGTGAGAGGATCAACTTCTCTGACAACCTAGGCCAGTGTGTGGTGATGCCAGGCATGCCCTTCCCCAGCATCAGGTCTCCAGAGCTGC",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/877
https://github.com/google/deepvariant/issues/877:8385,safety,test,test,8385,"199 --norealign_reads --regions chr17 --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels 0.12 --task 2. real 0m4.188s. user 0m3.295s. sys 0m0.885s`. **this is the form of bam files I have used:**. `molecule/22487242 0 chr1 11823 22 1S22=165N39=1X71=1X27=1X9=1X9=1X16=1D3=1X10=1X12=1X13=385N109=761N9=1I16=1X104=1X70=1X91=1I37=1X24=1X54=1D18=1X67=1X1=1X132=1X132=1X49=1X55=1X58= * 0 2590 GTAAACGAGATTGCCAGCACCGGGTGTCTGACTTCCAGCAACTGCTGGCCTGTGCCAGGGTGGAAGCTGAGCACTGGAGTGGAGTTTTCCTGTGGAGAGGAGCCATGCCTAGAGTGGGATGGGCCATTGTTCATATTCTGGCCCCTGTTGTCTGCATGTAACCTAATACCACGACCAGGCATGGGGGAAAGATTGGAGGAAGTTGAGTGAGAGGATCAACTTCTCTGACAACCTAGGCCAGTGTGTGGTGATGCCAGGCATGCCCTTCCCCAGCATCAGGTCTCCAGAGCTGCAGAAGACGACGGCCGACTTGGATCACACTCTTGTGAGTGTCCCCAGTGTTGCAGAGGCAGCTGCACCCACTGCCTGGCGCTGCGCCCTTCCTTTGCTCTGCCCGCTGGAGACGGTGTTTGTCATGGGCCTGGTCTGCAGGGATCCTGCTACAAAGGTGAAACCCAGGAGAGTGTGGAGTCCAGAGTGATGCCAGGACCCAGGCACAGGCATTAGTGCCCGTTGGAGAAAACAGGGGAATCCCGAAGAAATGGTGGGTCTTGGCCATCCGTGAGATCTTCCCAGGGCAGCTCCCCTCTGTGGAATCCAATCTGTCTTCCATCCTGCGTGGCCGAGGGCCAGGCTTCTCACTGGGGCCTCTGCAGGAGGCTGCCATTTGTCCTGCCCACCGTCTTAGAAGCGAGACGGAGCAGACTCATCTGCTACTGCCCTTTCTATAATAACTAAAGTTAGCTGCCCTGGACTATTCACCCCTAGTCTCAATTTAAAAAGATCCCCATGGCCACAGGGCCCCTGCCTGGGGGCTTGTCACCTCCCCCACCTTCTTCCTGAGTCACTTCTGCAGCCTTGCTCCCTAACCTGCCCCACAGCCTTGCCTGGATTTCTATCTCCCTGGCTTGGTGCCAGTTCCTCCAAGTCGATGGCACCTCCCTCCCTCTCAACCACTTGAGCAAACTCCAAGACATCTTCTTCCCCAACACCAGCAATTGTGCCAAGGGCCATTAGGCTCTCAGCATGACTATTTTTAGAGACCCCGTGTCTGTCACTGAAACCTTTTTTGTGGGAGACTATTCCTCCCATCTGCAACAGCTGCCCCTGCTGACGGCCCTTCTCTCCTCCCTCTCATCCCAGAGAAACAGGTCAGCTGGGAGCTCCTGCCCCCACTGCCTAGGGACCAACAGGGGCAGGAGGCAGTCACTGACCCCGAGAAGTTTGCATCCTGCACAGCTAGAGATCCTTTATTAAAAGCACACTGTTGGTTTCTGCTC * CB:Z:CCAACTCACATTGAAG XA:Z:XM-CB XM:Z:AGACAATCCGTA ic:i:1 im:Z:m84210_240422_080753_s1/229444864/ccs/5985_7265 is:i:1 it:Z:AGACAATCCGTACCAACTCACATTGAAG rc:i:1 RG:Z:e4927d21 zm:i:22487242 mg:f:98.1265 NM:i:24`. **Also, when I used test files, I got the final results without any errors**. All advice much appreciated!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/877
https://github.com/google/deepvariant/issues/877:8433,safety,error,errors,8433,"199 --norealign_reads --regions chr17 --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels 0.12 --task 2. real 0m4.188s. user 0m3.295s. sys 0m0.885s`. **this is the form of bam files I have used:**. `molecule/22487242 0 chr1 11823 22 1S22=165N39=1X71=1X27=1X9=1X9=1X16=1D3=1X10=1X12=1X13=385N109=761N9=1I16=1X104=1X70=1X91=1I37=1X24=1X54=1D18=1X67=1X1=1X132=1X132=1X49=1X55=1X58= * 0 2590 GTAAACGAGATTGCCAGCACCGGGTGTCTGACTTCCAGCAACTGCTGGCCTGTGCCAGGGTGGAAGCTGAGCACTGGAGTGGAGTTTTCCTGTGGAGAGGAGCCATGCCTAGAGTGGGATGGGCCATTGTTCATATTCTGGCCCCTGTTGTCTGCATGTAACCTAATACCACGACCAGGCATGGGGGAAAGATTGGAGGAAGTTGAGTGAGAGGATCAACTTCTCTGACAACCTAGGCCAGTGTGTGGTGATGCCAGGCATGCCCTTCCCCAGCATCAGGTCTCCAGAGCTGCAGAAGACGACGGCCGACTTGGATCACACTCTTGTGAGTGTCCCCAGTGTTGCAGAGGCAGCTGCACCCACTGCCTGGCGCTGCGCCCTTCCTTTGCTCTGCCCGCTGGAGACGGTGTTTGTCATGGGCCTGGTCTGCAGGGATCCTGCTACAAAGGTGAAACCCAGGAGAGTGTGGAGTCCAGAGTGATGCCAGGACCCAGGCACAGGCATTAGTGCCCGTTGGAGAAAACAGGGGAATCCCGAAGAAATGGTGGGTCTTGGCCATCCGTGAGATCTTCCCAGGGCAGCTCCCCTCTGTGGAATCCAATCTGTCTTCCATCCTGCGTGGCCGAGGGCCAGGCTTCTCACTGGGGCCTCTGCAGGAGGCTGCCATTTGTCCTGCCCACCGTCTTAGAAGCGAGACGGAGCAGACTCATCTGCTACTGCCCTTTCTATAATAACTAAAGTTAGCTGCCCTGGACTATTCACCCCTAGTCTCAATTTAAAAAGATCCCCATGGCCACAGGGCCCCTGCCTGGGGGCTTGTCACCTCCCCCACCTTCTTCCTGAGTCACTTCTGCAGCCTTGCTCCCTAACCTGCCCCACAGCCTTGCCTGGATTTCTATCTCCCTGGCTTGGTGCCAGTTCCTCCAAGTCGATGGCACCTCCCTCCCTCTCAACCACTTGAGCAAACTCCAAGACATCTTCTTCCCCAACACCAGCAATTGTGCCAAGGGCCATTAGGCTCTCAGCATGACTATTTTTAGAGACCCCGTGTCTGTCACTGAAACCTTTTTTGTGGGAGACTATTCCTCCCATCTGCAACAGCTGCCCCTGCTGACGGCCCTTCTCTCCTCCCTCTCATCCCAGAGAAACAGGTCAGCTGGGAGCTCCTGCCCCCACTGCCTAGGGACCAACAGGGGCAGGAGGCAGTCACTGACCCCGAGAAGTTTGCATCCTGCACAGCTAGAGATCCTTTATTAAAAGCACACTGTTGGTTTCTGCTC * CB:Z:CCAACTCACATTGAAG XA:Z:XM-CB XM:Z:AGACAATCCGTA ic:i:1 im:Z:m84210_240422_080753_s1/229444864/ccs/5985_7265 is:i:1 it:Z:AGACAATCCGTACCAACTCACATTGAAG rc:i:1 RG:Z:e4927d21 zm:i:22487242 mg:f:98.1265 NM:i:24`. **Also, when I used test files, I got the final results without any errors**. All advice much appreciated!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/877
https://github.com/google/deepvariant/issues/877:93,security,iso,iso,93,"Fatal Python error: Aborted; **Hello, I ran deep variant for mutation calling of single cell iso seq bam file (Pacbio long read rna-seq), and I got this error messages:**. `9-03 12:26:09.055921: W third_party/nucleus/io/sam_reader.cc:612] Could not read base quality scores molecule/44871400: NOT_FOUND: Could not read base quality scores. 2024-09-03 12:26:09.055938: W third_party/nucleus/io/sam_reader.cc:612] Could not read base quality scores molecule/22677071: NOT_FOUND: Could not read base quality scores. 2024-09-03 12:26:09.055954: W third_party/nucleus/io/sam_reader.cc:612] Could not read base quality scores molecule/31298741: NOT_FOUND: Could not read base quality scores. 2024-09-03 12:26:09.055967: W third_party/nucleus/io/sam_reader.cc:612] Could not read base quality scores molecule/31321506: NOT_FOUND: Could not read base quality scores. 2024-09-03 12:26:09.055980: W third_party/nucleus/io/sam_reader.cc:612] Could not read base quality scores molecule/31927218: NOT_FOUND: Could not read base quality scores. 2024-09-03 12:26:09.055993: W third_party/nucleus/io/sam_reader.cc:612] Could not read base quality scores molecule/25969828: NOT_FOUND: Could not read base quality scores. 2024-09-03 12:26:09.056006: W third_party/nucleus/io/sam_reader.cc:612] Could not read base quality scores molecule/6236354: NOT_FOUND: Could not read base quality scores. 2024-09-03 12:26:09.056021: W third_party/nucleus/io/sam_reader.cc:612] Could not read base quality scores molecule/32560810: NOT_FOUND: Could not read base quality scores. 2024-09-03 12:26:09.056034: W third_party/nucleus/io/sam_reader.cc:612] Could not read base quality scores molecule/12686626: NOT_FOUND: Could not read base quality scores. 2024-09-03 12:26:09.056046: W third_party/nucleus/io/sam_reader.cc:612] Could not read base quality scores molecule/12686630: NOT_FOUND: Could not read base quality scores. 2024-09-03 12:26:09.056060: W third_party/nucleus/io/sam_reader.cc:612] Could not read base quality scor",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/877
https://github.com/google/deepvariant/issues/877:8385,testability,test,test,8385,"199 --norealign_reads --regions chr17 --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels 0.12 --task 2. real 0m4.188s. user 0m3.295s. sys 0m0.885s`. **this is the form of bam files I have used:**. `molecule/22487242 0 chr1 11823 22 1S22=165N39=1X71=1X27=1X9=1X9=1X16=1D3=1X10=1X12=1X13=385N109=761N9=1I16=1X104=1X70=1X91=1I37=1X24=1X54=1D18=1X67=1X1=1X132=1X132=1X49=1X55=1X58= * 0 2590 GTAAACGAGATTGCCAGCACCGGGTGTCTGACTTCCAGCAACTGCTGGCCTGTGCCAGGGTGGAAGCTGAGCACTGGAGTGGAGTTTTCCTGTGGAGAGGAGCCATGCCTAGAGTGGGATGGGCCATTGTTCATATTCTGGCCCCTGTTGTCTGCATGTAACCTAATACCACGACCAGGCATGGGGGAAAGATTGGAGGAAGTTGAGTGAGAGGATCAACTTCTCTGACAACCTAGGCCAGTGTGTGGTGATGCCAGGCATGCCCTTCCCCAGCATCAGGTCTCCAGAGCTGCAGAAGACGACGGCCGACTTGGATCACACTCTTGTGAGTGTCCCCAGTGTTGCAGAGGCAGCTGCACCCACTGCCTGGCGCTGCGCCCTTCCTTTGCTCTGCCCGCTGGAGACGGTGTTTGTCATGGGCCTGGTCTGCAGGGATCCTGCTACAAAGGTGAAACCCAGGAGAGTGTGGAGTCCAGAGTGATGCCAGGACCCAGGCACAGGCATTAGTGCCCGTTGGAGAAAACAGGGGAATCCCGAAGAAATGGTGGGTCTTGGCCATCCGTGAGATCTTCCCAGGGCAGCTCCCCTCTGTGGAATCCAATCTGTCTTCCATCCTGCGTGGCCGAGGGCCAGGCTTCTCACTGGGGCCTCTGCAGGAGGCTGCCATTTGTCCTGCCCACCGTCTTAGAAGCGAGACGGAGCAGACTCATCTGCTACTGCCCTTTCTATAATAACTAAAGTTAGCTGCCCTGGACTATTCACCCCTAGTCTCAATTTAAAAAGATCCCCATGGCCACAGGGCCCCTGCCTGGGGGCTTGTCACCTCCCCCACCTTCTTCCTGAGTCACTTCTGCAGCCTTGCTCCCTAACCTGCCCCACAGCCTTGCCTGGATTTCTATCTCCCTGGCTTGGTGCCAGTTCCTCCAAGTCGATGGCACCTCCCTCCCTCTCAACCACTTGAGCAAACTCCAAGACATCTTCTTCCCCAACACCAGCAATTGTGCCAAGGGCCATTAGGCTCTCAGCATGACTATTTTTAGAGACCCCGTGTCTGTCACTGAAACCTTTTTTGTGGGAGACTATTCCTCCCATCTGCAACAGCTGCCCCTGCTGACGGCCCTTCTCTCCTCCCTCTCATCCCAGAGAAACAGGTCAGCTGGGAGCTCCTGCCCCCACTGCCTAGGGACCAACAGGGGCAGGAGGCAGTCACTGACCCCGAGAAGTTTGCATCCTGCACAGCTAGAGATCCTTTATTAAAAGCACACTGTTGGTTTCTGCTC * CB:Z:CCAACTCACATTGAAG XA:Z:XM-CB XM:Z:AGACAATCCGTA ic:i:1 im:Z:m84210_240422_080753_s1/229444864/ccs/5985_7265 is:i:1 it:Z:AGACAATCCGTACCAACTCACATTGAAG rc:i:1 RG:Z:e4927d21 zm:i:22487242 mg:f:98.1265 NM:i:24`. **Also, when I used test files, I got the final results without any errors**. All advice much appreciated!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/877
https://github.com/google/deepvariant/issues/877:13,usability,error,error,13,"Fatal Python error: Aborted; **Hello, I ran deep variant for mutation calling of single cell iso seq bam file (Pacbio long read rna-seq), and I got this error messages:**. `9-03 12:26:09.055921: W third_party/nucleus/io/sam_reader.cc:612] Could not read base quality scores molecule/44871400: NOT_FOUND: Could not read base quality scores. 2024-09-03 12:26:09.055938: W third_party/nucleus/io/sam_reader.cc:612] Could not read base quality scores molecule/22677071: NOT_FOUND: Could not read base quality scores. 2024-09-03 12:26:09.055954: W third_party/nucleus/io/sam_reader.cc:612] Could not read base quality scores molecule/31298741: NOT_FOUND: Could not read base quality scores. 2024-09-03 12:26:09.055967: W third_party/nucleus/io/sam_reader.cc:612] Could not read base quality scores molecule/31321506: NOT_FOUND: Could not read base quality scores. 2024-09-03 12:26:09.055980: W third_party/nucleus/io/sam_reader.cc:612] Could not read base quality scores molecule/31927218: NOT_FOUND: Could not read base quality scores. 2024-09-03 12:26:09.055993: W third_party/nucleus/io/sam_reader.cc:612] Could not read base quality scores molecule/25969828: NOT_FOUND: Could not read base quality scores. 2024-09-03 12:26:09.056006: W third_party/nucleus/io/sam_reader.cc:612] Could not read base quality scores molecule/6236354: NOT_FOUND: Could not read base quality scores. 2024-09-03 12:26:09.056021: W third_party/nucleus/io/sam_reader.cc:612] Could not read base quality scores molecule/32560810: NOT_FOUND: Could not read base quality scores. 2024-09-03 12:26:09.056034: W third_party/nucleus/io/sam_reader.cc:612] Could not read base quality scores molecule/12686626: NOT_FOUND: Could not read base quality scores. 2024-09-03 12:26:09.056046: W third_party/nucleus/io/sam_reader.cc:612] Could not read base quality scores molecule/12686630: NOT_FOUND: Could not read base quality scores. 2024-09-03 12:26:09.056060: W third_party/nucleus/io/sam_reader.cc:612] Could not read base quality scor",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/877
https://github.com/google/deepvariant/issues/877:153,usability,error,error,153,"Fatal Python error: Aborted; **Hello, I ran deep variant for mutation calling of single cell iso seq bam file (Pacbio long read rna-seq), and I got this error messages:**. `9-03 12:26:09.055921: W third_party/nucleus/io/sam_reader.cc:612] Could not read base quality scores molecule/44871400: NOT_FOUND: Could not read base quality scores. 2024-09-03 12:26:09.055938: W third_party/nucleus/io/sam_reader.cc:612] Could not read base quality scores molecule/22677071: NOT_FOUND: Could not read base quality scores. 2024-09-03 12:26:09.055954: W third_party/nucleus/io/sam_reader.cc:612] Could not read base quality scores molecule/31298741: NOT_FOUND: Could not read base quality scores. 2024-09-03 12:26:09.055967: W third_party/nucleus/io/sam_reader.cc:612] Could not read base quality scores molecule/31321506: NOT_FOUND: Could not read base quality scores. 2024-09-03 12:26:09.055980: W third_party/nucleus/io/sam_reader.cc:612] Could not read base quality scores molecule/31927218: NOT_FOUND: Could not read base quality scores. 2024-09-03 12:26:09.055993: W third_party/nucleus/io/sam_reader.cc:612] Could not read base quality scores molecule/25969828: NOT_FOUND: Could not read base quality scores. 2024-09-03 12:26:09.056006: W third_party/nucleus/io/sam_reader.cc:612] Could not read base quality scores molecule/6236354: NOT_FOUND: Could not read base quality scores. 2024-09-03 12:26:09.056021: W third_party/nucleus/io/sam_reader.cc:612] Could not read base quality scores molecule/32560810: NOT_FOUND: Could not read base quality scores. 2024-09-03 12:26:09.056034: W third_party/nucleus/io/sam_reader.cc:612] Could not read base quality scores molecule/12686626: NOT_FOUND: Could not read base quality scores. 2024-09-03 12:26:09.056046: W third_party/nucleus/io/sam_reader.cc:612] Could not read base quality scores molecule/12686630: NOT_FOUND: Could not read base quality scores. 2024-09-03 12:26:09.056060: W third_party/nucleus/io/sam_reader.cc:612] Could not read base quality scor",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/877
https://github.com/google/deepvariant/issues/877:5155,usability,error,error,5155,"26:09.056452: W third_party/nucleus/io/sam_reader.cc:612] Could not read base quality scores molecule/25963197: NOT_FOUND: Could not read base quality scores. 2024-09-03 12:26:09.056463: W third_party/nucleus/io/sam_reader.cc:612] Could not read base quality scores molecule/25963211: NOT_FOUND: Could not read base quality scores. 2024-09-03 12:26:09.056474: W third_party/nucleus/io/sam_reader.cc:612] Could not read base quality scores molecule/25963212: NOT_FOUND: Could not read base quality scores. 2024-09-03 12:26:09.056489: W third_party/nucleus/io/sam_reader.cc:612] Could not read base quality scores molecule/9461690: NOT_FOUND: Could not read base quality scores. 2024-09-03 12:26:09.056506: W third_party/nucleus/io/sam_reader.cc:612] Could not read base quality scores molecule/8764719: NOT_FOUND: Could not read base quality scores. 2024-09-03 12:26:09.086379: F deepvariant/allelecounter.cc:204] Check failed: offset + len <= read.aligned_quality_size() (496 vs. 0). Fatal Python error: Aborted. Current thread 0x00007b82cc097740 (most recent call first):. File ""/tmp/Bazel.runfiles_vzux0__g/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 2040 in candidates_in_region. File ""/tmp/Bazel.runfiles_vzux0__g/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1734 in process. File ""/tmp/Bazel.runfiles_vzux0__g/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 2838 in make_examples_runner. File ""/tmp/Bazel.runfiles_vzux0__g/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 224 in main. File ""/tmp/Bazel.runfiles_vzux0__g/runfiles/absl_py/absl/app.py"", line 258 in _run_main. File ""/tmp/Bazel.runfiles_vzux0__g/runfiles/absl_py/absl/app.py"", line 312 in run. File ""/tmp/Bazel.runfiles_vzux0__g/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 234 in <module>. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/GRCh38.p13.genome.fa --rea",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/877
https://github.com/google/deepvariant/issues/877:6126,usability,input,input,6126,"(496 vs. 0). Fatal Python error: Aborted. Current thread 0x00007b82cc097740 (most recent call first):. File ""/tmp/Bazel.runfiles_vzux0__g/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 2040 in candidates_in_region. File ""/tmp/Bazel.runfiles_vzux0__g/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1734 in process. File ""/tmp/Bazel.runfiles_vzux0__g/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 2838 in make_examples_runner. File ""/tmp/Bazel.runfiles_vzux0__g/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 224 in main. File ""/tmp/Bazel.runfiles_vzux0__g/runfiles/absl_py/absl/app.py"", line 258 in _run_main. File ""/tmp/Bazel.runfiles_vzux0__g/runfiles/absl_py/absl/app.py"", line 312 in run. File ""/tmp/Bazel.runfiles_vzux0__g/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 234 in <module>. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/GRCh38.p13.genome.fa --reads /input/9091.aligned.bam --examples /tmp/tmp6ub5qq7n/make_examples.tfrecord@4.gz --add_hp_channel --alt_aligned_pileup diff_channels --gvcf /tmp/tmp6ub5qq7n/gvcf.tfrecord@4.gz --max_reads_per_partition 600 --min_mapping_quality 1 --parse_sam_aux_fields --partition_size 25000 --phase_reads --pileup_image_width 199 --norealign_reads --regions chr17 --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels 0.12 --task 2. real 0m4.188s. user 0m3.295s. sys 0m0.885s`. **this is the form of bam files I have used:**. `molecule/22487242 0 chr1 11823 22 1S22=165N39=1X71=1X27=1X9=1X9=1X16=1D3=1X10=1X12=1X13=385N109=761N9=1I16=1X104=1X70=1X91=1I37=1X24=1X54=1D18=1X67=1X1=1X132=1X132=1X49=1X55=1X58= * 0 2590 GTAAACGAGATTGCCAGCACCGGGTGTCTGACTTCCAGCAACTGCTGGCCTGTGCCAGGGTGGAAGCTGAGCACTGGAGTGGAGTTTTCCTGTGGAGAGGAGCCATGCCTAGAGTGGGATGGGCCATTGTTCATATTCTGGCCCCTGTTGTCTGCATGTAACCTAATACCACGACCAGGCATGGGGGAAAGATTGGAGGAAGTTGAGTGAGAGGATCAACTTCTCTGACAACCTAGGCCAGTGTGTGGTGATGCCAG",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/877
https://github.com/google/deepvariant/issues/877:6162,usability,input,input,6162,"rted. Current thread 0x00007b82cc097740 (most recent call first):. File ""/tmp/Bazel.runfiles_vzux0__g/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 2040 in candidates_in_region. File ""/tmp/Bazel.runfiles_vzux0__g/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1734 in process. File ""/tmp/Bazel.runfiles_vzux0__g/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 2838 in make_examples_runner. File ""/tmp/Bazel.runfiles_vzux0__g/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 224 in main. File ""/tmp/Bazel.runfiles_vzux0__g/runfiles/absl_py/absl/app.py"", line 258 in _run_main. File ""/tmp/Bazel.runfiles_vzux0__g/runfiles/absl_py/absl/app.py"", line 312 in run. File ""/tmp/Bazel.runfiles_vzux0__g/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 234 in <module>. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/GRCh38.p13.genome.fa --reads /input/9091.aligned.bam --examples /tmp/tmp6ub5qq7n/make_examples.tfrecord@4.gz --add_hp_channel --alt_aligned_pileup diff_channels --gvcf /tmp/tmp6ub5qq7n/gvcf.tfrecord@4.gz --max_reads_per_partition 600 --min_mapping_quality 1 --parse_sam_aux_fields --partition_size 25000 --phase_reads --pileup_image_width 199 --norealign_reads --regions chr17 --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels 0.12 --task 2. real 0m4.188s. user 0m3.295s. sys 0m0.885s`. **this is the form of bam files I have used:**. `molecule/22487242 0 chr1 11823 22 1S22=165N39=1X71=1X27=1X9=1X9=1X16=1D3=1X10=1X12=1X13=385N109=761N9=1I16=1X104=1X70=1X91=1I37=1X24=1X54=1D18=1X67=1X1=1X132=1X132=1X49=1X55=1X58= * 0 2590 GTAAACGAGATTGCCAGCACCGGGTGTCTGACTTCCAGCAACTGCTGGCCTGTGCCAGGGTGGAAGCTGAGCACTGGAGTGGAGTTTTCCTGTGGAGAGGAGCCATGCCTAGAGTGGGATGGGCCATTGTTCATATTCTGGCCCCTGTTGTCTGCATGTAACCTAATACCACGACCAGGCATGGGGGAAAGATTGGAGGAAGTTGAGTGAGAGGATCAACTTCTCTGACAACCTAGGCCAGTGTGTGGTGATGCCAGGCATGCCCTTCCCCAGCATCAGGTCTCCAGAGCTGC",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/877
https://github.com/google/deepvariant/issues/877:6604,usability,user,user,6604,"8 in make_examples_runner. File ""/tmp/Bazel.runfiles_vzux0__g/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 224 in main. File ""/tmp/Bazel.runfiles_vzux0__g/runfiles/absl_py/absl/app.py"", line 258 in _run_main. File ""/tmp/Bazel.runfiles_vzux0__g/runfiles/absl_py/absl/app.py"", line 312 in run. File ""/tmp/Bazel.runfiles_vzux0__g/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 234 in <module>. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/GRCh38.p13.genome.fa --reads /input/9091.aligned.bam --examples /tmp/tmp6ub5qq7n/make_examples.tfrecord@4.gz --add_hp_channel --alt_aligned_pileup diff_channels --gvcf /tmp/tmp6ub5qq7n/gvcf.tfrecord@4.gz --max_reads_per_partition 600 --min_mapping_quality 1 --parse_sam_aux_fields --partition_size 25000 --phase_reads --pileup_image_width 199 --norealign_reads --regions chr17 --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels 0.12 --task 2. real 0m4.188s. user 0m3.295s. sys 0m0.885s`. **this is the form of bam files I have used:**. `molecule/22487242 0 chr1 11823 22 1S22=165N39=1X71=1X27=1X9=1X9=1X16=1D3=1X10=1X12=1X13=385N109=761N9=1I16=1X104=1X70=1X91=1I37=1X24=1X54=1D18=1X67=1X1=1X132=1X132=1X49=1X55=1X58= * 0 2590 GTAAACGAGATTGCCAGCACCGGGTGTCTGACTTCCAGCAACTGCTGGCCTGTGCCAGGGTGGAAGCTGAGCACTGGAGTGGAGTTTTCCTGTGGAGAGGAGCCATGCCTAGAGTGGGATGGGCCATTGTTCATATTCTGGCCCCTGTTGTCTGCATGTAACCTAATACCACGACCAGGCATGGGGGAAAGATTGGAGGAAGTTGAGTGAGAGGATCAACTTCTCTGACAACCTAGGCCAGTGTGTGGTGATGCCAGGCATGCCCTTCCCCAGCATCAGGTCTCCAGAGCTGCAGAAGACGACGGCCGACTTGGATCACACTCTTGTGAGTGTCCCCAGTGTTGCAGAGGCAGCTGCACCCACTGCCTGGCGCTGCGCCCTTCCTTTGCTCTGCCCGCTGGAGACGGTGTTTGTCATGGGCCTGGTCTGCAGGGATCCTGCTACAAAGGTGAAACCCAGGAGAGTGTGGAGTCCAGAGTGATGCCAGGACCCAGGCACAGGCATTAGTGCCCGTTGGAGAAAACAGGGGAATCCCGAAGAAATGGTGGGTCTTGGCCATCCGTGAGATCTTCCCAGGGCAGCTCCCCTCTGTGGAATCCAATCTGTCTTCCATCCTGCGTGGCCGAGGGCCAGGCTTCTCACTGGGGCCTCTGCAGGAGGCTGCCATTTGTCCTGCCCACCGTCTTAGAAGCGAGACGGAGCAGACTCATCTGCTACTGCCCTTTCTATAATAA",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/877
https://github.com/google/deepvariant/issues/877:8433,usability,error,errors,8433,"199 --norealign_reads --regions chr17 --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels 0.12 --task 2. real 0m4.188s. user 0m3.295s. sys 0m0.885s`. **this is the form of bam files I have used:**. `molecule/22487242 0 chr1 11823 22 1S22=165N39=1X71=1X27=1X9=1X9=1X16=1D3=1X10=1X12=1X13=385N109=761N9=1I16=1X104=1X70=1X91=1I37=1X24=1X54=1D18=1X67=1X1=1X132=1X132=1X49=1X55=1X58= * 0 2590 GTAAACGAGATTGCCAGCACCGGGTGTCTGACTTCCAGCAACTGCTGGCCTGTGCCAGGGTGGAAGCTGAGCACTGGAGTGGAGTTTTCCTGTGGAGAGGAGCCATGCCTAGAGTGGGATGGGCCATTGTTCATATTCTGGCCCCTGTTGTCTGCATGTAACCTAATACCACGACCAGGCATGGGGGAAAGATTGGAGGAAGTTGAGTGAGAGGATCAACTTCTCTGACAACCTAGGCCAGTGTGTGGTGATGCCAGGCATGCCCTTCCCCAGCATCAGGTCTCCAGAGCTGCAGAAGACGACGGCCGACTTGGATCACACTCTTGTGAGTGTCCCCAGTGTTGCAGAGGCAGCTGCACCCACTGCCTGGCGCTGCGCCCTTCCTTTGCTCTGCCCGCTGGAGACGGTGTTTGTCATGGGCCTGGTCTGCAGGGATCCTGCTACAAAGGTGAAACCCAGGAGAGTGTGGAGTCCAGAGTGATGCCAGGACCCAGGCACAGGCATTAGTGCCCGTTGGAGAAAACAGGGGAATCCCGAAGAAATGGTGGGTCTTGGCCATCCGTGAGATCTTCCCAGGGCAGCTCCCCTCTGTGGAATCCAATCTGTCTTCCATCCTGCGTGGCCGAGGGCCAGGCTTCTCACTGGGGCCTCTGCAGGAGGCTGCCATTTGTCCTGCCCACCGTCTTAGAAGCGAGACGGAGCAGACTCATCTGCTACTGCCCTTTCTATAATAACTAAAGTTAGCTGCCCTGGACTATTCACCCCTAGTCTCAATTTAAAAAGATCCCCATGGCCACAGGGCCCCTGCCTGGGGGCTTGTCACCTCCCCCACCTTCTTCCTGAGTCACTTCTGCAGCCTTGCTCCCTAACCTGCCCCACAGCCTTGCCTGGATTTCTATCTCCCTGGCTTGGTGCCAGTTCCTCCAAGTCGATGGCACCTCCCTCCCTCTCAACCACTTGAGCAAACTCCAAGACATCTTCTTCCCCAACACCAGCAATTGTGCCAAGGGCCATTAGGCTCTCAGCATGACTATTTTTAGAGACCCCGTGTCTGTCACTGAAACCTTTTTTGTGGGAGACTATTCCTCCCATCTGCAACAGCTGCCCCTGCTGACGGCCCTTCTCTCCTCCCTCTCATCCCAGAGAAACAGGTCAGCTGGGAGCTCCTGCCCCCACTGCCTAGGGACCAACAGGGGCAGGAGGCAGTCACTGACCCCGAGAAGTTTGCATCCTGCACAGCTAGAGATCCTTTATTAAAAGCACACTGTTGGTTTCTGCTC * CB:Z:CCAACTCACATTGAAG XA:Z:XM-CB XM:Z:AGACAATCCGTA ic:i:1 im:Z:m84210_240422_080753_s1/229444864/ccs/5985_7265 is:i:1 it:Z:AGACAATCCGTACCAACTCACATTGAAG rc:i:1 RG:Z:e4927d21 zm:i:22487242 mg:f:98.1265 NM:i:24`. **Also, when I used test files, I got the final results without any errors**. All advice much appreciated!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/877
https://github.com/google/deepvariant/issues/878:308,availability,reliab,reliability,308,"Retraining DeepVariant without trios data?; Hi,. I am doing a genomic analysis of bats, and I have WGS for about 13 individuals but with unknown ancestry or relatedness, many from different populations. I read that DeepVariant is one of the best genotype-callers, but I would like to consult first about the reliability and confidence on calling variants on a non-human system (yet mammalian..??). I read the blog about doing the mosquito-specific model, but the problem, as stated, is that I don't have trios data to train a model, nor I think that I can get it (nor samples or money), which is a very hard request. I would appreciate a lot your comments and suggestions on what can I do, or if DeepVariant can confidently call variants. Thanks;",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/878
https://github.com/google/deepvariant/issues/878:475,availability,state,stated,475,"Retraining DeepVariant without trios data?; Hi,. I am doing a genomic analysis of bats, and I have WGS for about 13 individuals but with unknown ancestry or relatedness, many from different populations. I read that DeepVariant is one of the best genotype-callers, but I would like to consult first about the reliability and confidence on calling variants on a non-human system (yet mammalian..??). I read the blog about doing the mosquito-specific model, but the problem, as stated, is that I don't have trios data to train a model, nor I think that I can get it (nor samples or money), which is a very hard request. I would appreciate a lot your comments and suggestions on what can I do, or if DeepVariant can confidently call variants. Thanks;",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/878
https://github.com/google/deepvariant/issues/878:448,energy efficiency,model,model,448,"Retraining DeepVariant without trios data?; Hi,. I am doing a genomic analysis of bats, and I have WGS for about 13 individuals but with unknown ancestry or relatedness, many from different populations. I read that DeepVariant is one of the best genotype-callers, but I would like to consult first about the reliability and confidence on calling variants on a non-human system (yet mammalian..??). I read the blog about doing the mosquito-specific model, but the problem, as stated, is that I don't have trios data to train a model, nor I think that I can get it (nor samples or money), which is a very hard request. I would appreciate a lot your comments and suggestions on what can I do, or if DeepVariant can confidently call variants. Thanks;",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/878
https://github.com/google/deepvariant/issues/878:526,energy efficiency,model,model,526,"Retraining DeepVariant without trios data?; Hi,. I am doing a genomic analysis of bats, and I have WGS for about 13 individuals but with unknown ancestry or relatedness, many from different populations. I read that DeepVariant is one of the best genotype-callers, but I would like to consult first about the reliability and confidence on calling variants on a non-human system (yet mammalian..??). I read the blog about doing the mosquito-specific model, but the problem, as stated, is that I don't have trios data to train a model, nor I think that I can get it (nor samples or money), which is a very hard request. I would appreciate a lot your comments and suggestions on what can I do, or if DeepVariant can confidently call variants. Thanks;",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/878
https://github.com/google/deepvariant/issues/878:475,integrability,state,stated,475,"Retraining DeepVariant without trios data?; Hi,. I am doing a genomic analysis of bats, and I have WGS for about 13 individuals but with unknown ancestry or relatedness, many from different populations. I read that DeepVariant is one of the best genotype-callers, but I would like to consult first about the reliability and confidence on calling variants on a non-human system (yet mammalian..??). I read the blog about doing the mosquito-specific model, but the problem, as stated, is that I don't have trios data to train a model, nor I think that I can get it (nor samples or money), which is a very hard request. I would appreciate a lot your comments and suggestions on what can I do, or if DeepVariant can confidently call variants. Thanks;",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/878
https://github.com/google/deepvariant/issues/878:439,interoperability,specif,specific,439,"Retraining DeepVariant without trios data?; Hi,. I am doing a genomic analysis of bats, and I have WGS for about 13 individuals but with unknown ancestry or relatedness, many from different populations. I read that DeepVariant is one of the best genotype-callers, but I would like to consult first about the reliability and confidence on calling variants on a non-human system (yet mammalian..??). I read the blog about doing the mosquito-specific model, but the problem, as stated, is that I don't have trios data to train a model, nor I think that I can get it (nor samples or money), which is a very hard request. I would appreciate a lot your comments and suggestions on what can I do, or if DeepVariant can confidently call variants. Thanks;",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/878
https://github.com/google/deepvariant/issues/878:308,reliability,reliab,reliability,308,"Retraining DeepVariant without trios data?; Hi,. I am doing a genomic analysis of bats, and I have WGS for about 13 individuals but with unknown ancestry or relatedness, many from different populations. I read that DeepVariant is one of the best genotype-callers, but I would like to consult first about the reliability and confidence on calling variants on a non-human system (yet mammalian..??). I read the blog about doing the mosquito-specific model, but the problem, as stated, is that I don't have trios data to train a model, nor I think that I can get it (nor samples or money), which is a very hard request. I would appreciate a lot your comments and suggestions on what can I do, or if DeepVariant can confidently call variants. Thanks;",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/878
https://github.com/google/deepvariant/issues/878:308,safety,reliabil,reliability,308,"Retraining DeepVariant without trios data?; Hi,. I am doing a genomic analysis of bats, and I have WGS for about 13 individuals but with unknown ancestry or relatedness, many from different populations. I read that DeepVariant is one of the best genotype-callers, but I would like to consult first about the reliability and confidence on calling variants on a non-human system (yet mammalian..??). I read the blog about doing the mosquito-specific model, but the problem, as stated, is that I don't have trios data to train a model, nor I think that I can get it (nor samples or money), which is a very hard request. I would appreciate a lot your comments and suggestions on what can I do, or if DeepVariant can confidently call variants. Thanks;",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/878
https://github.com/google/deepvariant/issues/878:448,security,model,model,448,"Retraining DeepVariant without trios data?; Hi,. I am doing a genomic analysis of bats, and I have WGS for about 13 individuals but with unknown ancestry or relatedness, many from different populations. I read that DeepVariant is one of the best genotype-callers, but I would like to consult first about the reliability and confidence on calling variants on a non-human system (yet mammalian..??). I read the blog about doing the mosquito-specific model, but the problem, as stated, is that I don't have trios data to train a model, nor I think that I can get it (nor samples or money), which is a very hard request. I would appreciate a lot your comments and suggestions on what can I do, or if DeepVariant can confidently call variants. Thanks;",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/878
https://github.com/google/deepvariant/issues/878:526,security,model,model,526,"Retraining DeepVariant without trios data?; Hi,. I am doing a genomic analysis of bats, and I have WGS for about 13 individuals but with unknown ancestry or relatedness, many from different populations. I read that DeepVariant is one of the best genotype-callers, but I would like to consult first about the reliability and confidence on calling variants on a non-human system (yet mammalian..??). I read the blog about doing the mosquito-specific model, but the problem, as stated, is that I don't have trios data to train a model, nor I think that I can get it (nor samples or money), which is a very hard request. I would appreciate a lot your comments and suggestions on what can I do, or if DeepVariant can confidently call variants. Thanks;",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/878
https://github.com/google/deepvariant/issues/879:13,availability,error,error,13,"Fatal Python error: Segmentation fault; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. I tried to test run deepvariant following the quick-start guide at https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-quick-start.md and I got `Fatal Python error: Segmentation fault`. **Setup**. - Operating system: Ubuntu 20.04.6 LTS. - DeepVariant version: r1.6.1. - Installation method (Docker, built from source, etc.): Docker. - Type of data: exact same data in the quick start guide. **Steps to reproduce:**. - Command:. ``` . sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. deepvbuild:latest \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=1. ```. - Error trace:. ```. I0906 02:45:46.585311 275767425675280 run_deepvariant.py:519] Re-using the directory for intermediate results in /output/intermediate_results_dir. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I0906 02:45:51.909050 257960059396112 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0906 02:45:51.913105 257960059396112 make_examples_core.py:301] Preparing inputs. I0906 02:45:5",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:33,availability,fault,fault,33,"Fatal Python error: Segmentation fault; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. I tried to test run deepvariant following the quick-start guide at https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-quick-start.md and I got `Fatal Python error: Segmentation fault`. **Setup**. - Operating system: Ubuntu 20.04.6 LTS. - DeepVariant version: r1.6.1. - Installation method (Docker, built from source, etc.): Docker. - Type of data: exact same data in the quick start guide. **Steps to reproduce:**. - Command:. ``` . sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. deepvbuild:latest \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=1. ```. - Error trace:. ```. I0906 02:45:46.585311 275767425675280 run_deepvariant.py:519] Re-using the directory for intermediate results in /output/intermediate_results_dir. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I0906 02:45:51.909050 257960059396112 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0906 02:45:51.913105 257960059396112 make_examples_core.py:301] Preparing inputs. I0906 02:45:5",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:332,availability,error,error,332,"Fatal Python error: Segmentation fault; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. I tried to test run deepvariant following the quick-start guide at https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-quick-start.md and I got `Fatal Python error: Segmentation fault`. **Setup**. - Operating system: Ubuntu 20.04.6 LTS. - DeepVariant version: r1.6.1. - Installation method (Docker, built from source, etc.): Docker. - Type of data: exact same data in the quick start guide. **Steps to reproduce:**. - Command:. ``` . sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. deepvbuild:latest \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=1. ```. - Error trace:. ```. I0906 02:45:46.585311 275767425675280 run_deepvariant.py:519] Re-using the directory for intermediate results in /output/intermediate_results_dir. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I0906 02:45:51.909050 257960059396112 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0906 02:45:51.913105 257960059396112 make_examples_core.py:301] Preparing inputs. I0906 02:45:5",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:352,availability,fault,fault,352,"Fatal Python error: Segmentation fault; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. I tried to test run deepvariant following the quick-start guide at https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-quick-start.md and I got `Fatal Python error: Segmentation fault`. **Setup**. - Operating system: Ubuntu 20.04.6 LTS. - DeepVariant version: r1.6.1. - Installation method (Docker, built from source, etc.): Docker. - Type of data: exact same data in the quick start guide. **Steps to reproduce:**. - Command:. ``` . sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. deepvbuild:latest \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=1. ```. - Error trace:. ```. I0906 02:45:46.585311 275767425675280 run_deepvariant.py:519] Re-using the directory for intermediate results in /output/intermediate_results_dir. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I0906 02:45:51.909050 257960059396112 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0906 02:45:51.913105 257960059396112 make_examples_core.py:301] Preparing inputs. I0906 02:45:5",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:373,availability,Operat,Operating,373,"Fatal Python error: Segmentation fault; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. I tried to test run deepvariant following the quick-start guide at https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-quick-start.md and I got `Fatal Python error: Segmentation fault`. **Setup**. - Operating system: Ubuntu 20.04.6 LTS. - DeepVariant version: r1.6.1. - Installation method (Docker, built from source, etc.): Docker. - Type of data: exact same data in the quick start guide. **Steps to reproduce:**. - Command:. ``` . sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. deepvbuild:latest \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=1. ```. - Error trace:. ```. I0906 02:45:46.585311 275767425675280 run_deepvariant.py:519] Re-using the directory for intermediate results in /output/intermediate_results_dir. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I0906 02:45:51.909050 257960059396112 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0906 02:45:51.913105 257960059396112 make_examples_core.py:301] Preparing inputs. I0906 02:45:5",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:1074,availability,Error,Error,1074,"ithub.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. I tried to test run deepvariant following the quick-start guide at https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-quick-start.md and I got `Fatal Python error: Segmentation fault`. **Setup**. - Operating system: Ubuntu 20.04.6 LTS. - DeepVariant version: r1.6.1. - Installation method (Docker, built from source, etc.): Docker. - Type of data: exact same data in the quick start guide. **Steps to reproduce:**. - Command:. ``` . sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. deepvbuild:latest \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=1. ```. - Error trace:. ```. I0906 02:45:46.585311 275767425675280 run_deepvariant.py:519] Re-using the directory for intermediate results in /output/intermediate_results_dir. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I0906 02:45:51.909050 257960059396112 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0906 02:45:51.913105 257960059396112 make_examples_core.py:301] Preparing inputs. I0906 02:45:51.913431 257960059396112 genomics_reader.py:222] Reading /input/NA12878_S1.ch",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:3138,availability,error,error,3138,"7960059396112 make_examples_core.py:301] Common contigs are ['chr20']. I0906 02:45:51.914803 257960059396112 make_examples_core.py:301] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. I0906 02:45:51.916343 257960059396112 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0906 02:45:51.961755 257960059396112 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0906 02:45:51.961891 257960059396112 make_examples_core.py:301] Writing gvcf records to /output/intermediate_results_dir/gvcf.tfrecord-00000-of-00001.gz. I0906 02:45:51.962091 257960059396112 make_examples_core.py:301] Writing examples to /output/intermediate_results_dir/make_examples.tfrecord-00000-of-00001.gz. I0906 02:45:51.962123 257960059396112 make_examples_core.py:301] Overhead for preparing inputs: 0 seconds. Fatal Python error: Segmentation fault. Current thread 0x0000ea9d01b4e010 (most recent call first):. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/realigner/window_selector.py"", line 116 in _variant_reads_threshold_selector. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/realigner/window_selector.py"", line 76 in _candidates_from_reads. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/realigner/realigner.py"", line 806 in realign_reads. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 1881 in realign_reads. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 1908 in <listcomp>. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 1907 in realign_reads_per_sample_multisample. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:3158,availability,fault,fault,3158,"xamples_core.py:301] Common contigs are ['chr20']. I0906 02:45:51.914803 257960059396112 make_examples_core.py:301] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. I0906 02:45:51.916343 257960059396112 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0906 02:45:51.961755 257960059396112 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0906 02:45:51.961891 257960059396112 make_examples_core.py:301] Writing gvcf records to /output/intermediate_results_dir/gvcf.tfrecord-00000-of-00001.gz. I0906 02:45:51.962091 257960059396112 make_examples_core.py:301] Writing examples to /output/intermediate_results_dir/make_examples.tfrecord-00000-of-00001.gz. I0906 02:45:51.962123 257960059396112 make_examples_core.py:301] Overhead for preparing inputs: 0 seconds. Fatal Python error: Segmentation fault. Current thread 0x0000ea9d01b4e010 (most recent call first):. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/realigner/window_selector.py"", line 116 in _variant_reads_threshold_selector. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/realigner/window_selector.py"", line 76 in _candidates_from_reads. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/realigner/realigner.py"", line 806 in realign_reads. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 1881 in realign_reads. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 1908 in <listcomp>. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 1907 in realign_reads_per_sample_multisample. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_exa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:5526,availability,error,errors,5526,"realigner/realigner.py"", line 806 in realign_reads. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 1881 in realign_reads. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 1908 in <listcomp>. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 1907 in realign_reads_per_sample_multisample. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 1709 in process. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 2838 in make_examples_runner. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples.py"", line 224 in main. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/absl_py/absl/app.py"", line 258 in _run_main. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/absl_py/absl/app.py"", line 312 in run. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples.py"", line 234 in <module>. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /output/intermediate_results_dir/make_examples.tfrecord@1.gz --channels insert_size --gvcf /output/intermediate_results_dir/gvcf.tfrecord@1.gz --regions chr20:10,000,000-10,010,000 --task 0. real 0m5.584s. user 0m13.426s. sys 0m0.563s. ```. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. I am running this on an AWS graviton4 machine (aarch64 architecture). The Dockerfile does not work for me directly. I had to run `build-prereq.sh` and resolve all the errors manually within a docker container. But I did run build_and_test.sh to make sure all tests passed and the binaries were also built successfully.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:425,deployability,version,version,425,"Fatal Python error: Segmentation fault; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. I tried to test run deepvariant following the quick-start guide at https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-quick-start.md and I got `Fatal Python error: Segmentation fault`. **Setup**. - Operating system: Ubuntu 20.04.6 LTS. - DeepVariant version: r1.6.1. - Installation method (Docker, built from source, etc.): Docker. - Type of data: exact same data in the quick start guide. **Steps to reproduce:**. - Command:. ``` . sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. deepvbuild:latest \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=1. ```. - Error trace:. ```. I0906 02:45:46.585311 275767425675280 run_deepvariant.py:519] Re-using the directory for intermediate results in /output/intermediate_results_dir. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I0906 02:45:51.909050 257960059396112 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0906 02:45:51.913105 257960059396112 make_examples_core.py:301] Preparing inputs. I0906 02:45:5",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:444,deployability,Instal,Installation,444,"Fatal Python error: Segmentation fault; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. I tried to test run deepvariant following the quick-start guide at https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-quick-start.md and I got `Fatal Python error: Segmentation fault`. **Setup**. - Operating system: Ubuntu 20.04.6 LTS. - DeepVariant version: r1.6.1. - Installation method (Docker, built from source, etc.): Docker. - Type of data: exact same data in the quick start guide. **Steps to reproduce:**. - Command:. ``` . sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. deepvbuild:latest \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=1. ```. - Error trace:. ```. I0906 02:45:46.585311 275767425675280 run_deepvariant.py:519] Re-using the directory for intermediate results in /output/intermediate_results_dir. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I0906 02:45:51.909050 257960059396112 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0906 02:45:51.913105 257960059396112 make_examples_core.py:301] Preparing inputs. I0906 02:45:5",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:4685,deployability,modul,module,4685,"realigner/realigner.py"", line 806 in realign_reads. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 1881 in realign_reads. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 1908 in <listcomp>. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 1907 in realign_reads_per_sample_multisample. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 1709 in process. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 2838 in make_examples_runner. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples.py"", line 224 in main. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/absl_py/absl/app.py"", line 258 in _run_main. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/absl_py/absl/app.py"", line 312 in run. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples.py"", line 234 in <module>. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /output/intermediate_results_dir/make_examples.tfrecord@1.gz --channels insert_size --gvcf /output/intermediate_results_dir/gvcf.tfrecord@1.gz --regions chr20:10,000,000-10,010,000 --task 0. real 0m5.584s. user 0m13.426s. sys 0m0.563s. ```. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. I am running this on an AWS graviton4 machine (aarch64 architecture). The Dockerfile does not work for me directly. I had to run `build-prereq.sh` and resolve all the errors manually within a docker container. But I did run build_and_test.sh to make sure all tests passed and the binaries were also built successfully.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:4713,deployability,fail,failed,4713,"realigner/realigner.py"", line 806 in realign_reads. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 1881 in realign_reads. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 1908 in <listcomp>. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 1907 in realign_reads_per_sample_multisample. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 1709 in process. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 2838 in make_examples_runner. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples.py"", line 224 in main. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/absl_py/absl/app.py"", line 258 in _run_main. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/absl_py/absl/app.py"", line 312 in run. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples.py"", line 234 in <module>. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /output/intermediate_results_dir/make_examples.tfrecord@1.gz --channels insert_size --gvcf /output/intermediate_results_dir/gvcf.tfrecord@1.gz --regions chr20:10,000,000-10,010,000 --task 0. real 0m5.584s. user 0m13.426s. sys 0m0.563s. ```. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. I am running this on an AWS graviton4 machine (aarch64 architecture). The Dockerfile does not work for me directly. I had to run `build-prereq.sh` and resolve all the errors manually within a docker container. But I did run build_and_test.sh to make sure all tests passed and the binaries were also built successfully.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:5489,deployability,build,build-prereq,5489,"realigner/realigner.py"", line 806 in realign_reads. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 1881 in realign_reads. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 1908 in <listcomp>. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 1907 in realign_reads_per_sample_multisample. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 1709 in process. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 2838 in make_examples_runner. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples.py"", line 224 in main. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/absl_py/absl/app.py"", line 258 in _run_main. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/absl_py/absl/app.py"", line 312 in run. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples.py"", line 234 in <module>. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /output/intermediate_results_dir/make_examples.tfrecord@1.gz --channels insert_size --gvcf /output/intermediate_results_dir/gvcf.tfrecord@1.gz --regions chr20:10,000,000-10,010,000 --task 0. real 0m5.584s. user 0m13.426s. sys 0m0.563s. ```. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. I am running this on an AWS graviton4 machine (aarch64 architecture). The Dockerfile does not work for me directly. I had to run `build-prereq.sh` and resolve all the errors manually within a docker container. But I did run build_and_test.sh to make sure all tests passed and the binaries were also built successfully.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:5558,deployability,contain,container,5558,"realigner/realigner.py"", line 806 in realign_reads. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 1881 in realign_reads. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 1908 in <listcomp>. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 1907 in realign_reads_per_sample_multisample. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 1709 in process. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 2838 in make_examples_runner. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples.py"", line 224 in main. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/absl_py/absl/app.py"", line 258 in _run_main. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/absl_py/absl/app.py"", line 312 in run. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples.py"", line 234 in <module>. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /output/intermediate_results_dir/make_examples.tfrecord@1.gz --channels insert_size --gvcf /output/intermediate_results_dir/gvcf.tfrecord@1.gz --regions chr20:10,000,000-10,010,000 --task 0. real 0m5.584s. user 0m13.426s. sys 0m0.563s. ```. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. I am running this on an AWS graviton4 machine (aarch64 architecture). The Dockerfile does not work for me directly. I had to run `build-prereq.sh` and resolve all the errors manually within a docker container. But I did run build_and_test.sh to make sure all tests passed and the binaries were also built successfully.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:33,energy efficiency,fault,fault,33,"Fatal Python error: Segmentation fault; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. I tried to test run deepvariant following the quick-start guide at https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-quick-start.md and I got `Fatal Python error: Segmentation fault`. **Setup**. - Operating system: Ubuntu 20.04.6 LTS. - DeepVariant version: r1.6.1. - Installation method (Docker, built from source, etc.): Docker. - Type of data: exact same data in the quick start guide. **Steps to reproduce:**. - Command:. ``` . sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. deepvbuild:latest \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=1. ```. - Error trace:. ```. I0906 02:45:46.585311 275767425675280 run_deepvariant.py:519] Re-using the directory for intermediate results in /output/intermediate_results_dir. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I0906 02:45:51.909050 257960059396112 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0906 02:45:51.913105 257960059396112 make_examples_core.py:301] Preparing inputs. I0906 02:45:5",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:352,energy efficiency,fault,fault,352,"Fatal Python error: Segmentation fault; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. I tried to test run deepvariant following the quick-start guide at https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-quick-start.md and I got `Fatal Python error: Segmentation fault`. **Setup**. - Operating system: Ubuntu 20.04.6 LTS. - DeepVariant version: r1.6.1. - Installation method (Docker, built from source, etc.): Docker. - Type of data: exact same data in the quick start guide. **Steps to reproduce:**. - Command:. ``` . sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. deepvbuild:latest \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=1. ```. - Error trace:. ```. I0906 02:45:46.585311 275767425675280 run_deepvariant.py:519] Re-using the directory for intermediate results in /output/intermediate_results_dir. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I0906 02:45:51.909050 257960059396112 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0906 02:45:51.913105 257960059396112 make_examples_core.py:301] Preparing inputs. I0906 02:45:5",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:3158,energy efficiency,fault,fault,3158,"xamples_core.py:301] Common contigs are ['chr20']. I0906 02:45:51.914803 257960059396112 make_examples_core.py:301] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. I0906 02:45:51.916343 257960059396112 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0906 02:45:51.961755 257960059396112 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0906 02:45:51.961891 257960059396112 make_examples_core.py:301] Writing gvcf records to /output/intermediate_results_dir/gvcf.tfrecord-00000-of-00001.gz. I0906 02:45:51.962091 257960059396112 make_examples_core.py:301] Writing examples to /output/intermediate_results_dir/make_examples.tfrecord-00000-of-00001.gz. I0906 02:45:51.962123 257960059396112 make_examples_core.py:301] Overhead for preparing inputs: 0 seconds. Fatal Python error: Segmentation fault. Current thread 0x0000ea9d01b4e010 (most recent call first):. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/realigner/window_selector.py"", line 116 in _variant_reads_threshold_selector. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/realigner/window_selector.py"", line 76 in _candidates_from_reads. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/realigner/realigner.py"", line 806 in realign_reads. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 1881 in realign_reads. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 1908 in <listcomp>. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 1907 in realign_reads_per_sample_multisample. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_exa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:3165,energy efficiency,Current,Current,3165,"core.py:301] Common contigs are ['chr20']. I0906 02:45:51.914803 257960059396112 make_examples_core.py:301] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. I0906 02:45:51.916343 257960059396112 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0906 02:45:51.961755 257960059396112 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0906 02:45:51.961891 257960059396112 make_examples_core.py:301] Writing gvcf records to /output/intermediate_results_dir/gvcf.tfrecord-00000-of-00001.gz. I0906 02:45:51.962091 257960059396112 make_examples_core.py:301] Writing examples to /output/intermediate_results_dir/make_examples.tfrecord-00000-of-00001.gz. I0906 02:45:51.962123 257960059396112 make_examples_core.py:301] Overhead for preparing inputs: 0 seconds. Fatal Python error: Segmentation fault. Current thread 0x0000ea9d01b4e010 (most recent call first):. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/realigner/window_selector.py"", line 116 in _variant_reads_threshold_selector. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/realigner/window_selector.py"", line 76 in _candidates_from_reads. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/realigner/realigner.py"", line 806 in realign_reads. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 1881 in realign_reads. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 1908 in <listcomp>. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 1907 in realign_reads_per_sample_multisample. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_co",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:425,integrability,version,version,425,"Fatal Python error: Segmentation fault; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. I tried to test run deepvariant following the quick-start guide at https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-quick-start.md and I got `Fatal Python error: Segmentation fault`. **Setup**. - Operating system: Ubuntu 20.04.6 LTS. - DeepVariant version: r1.6.1. - Installation method (Docker, built from source, etc.): Docker. - Type of data: exact same data in the quick start guide. **Steps to reproduce:**. - Command:. ``` . sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. deepvbuild:latest \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=1. ```. - Error trace:. ```. I0906 02:45:46.585311 275767425675280 run_deepvariant.py:519] Re-using the directory for intermediate results in /output/intermediate_results_dir. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I0906 02:45:51.909050 257960059396112 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0906 02:45:51.913105 257960059396112 make_examples_core.py:301] Preparing inputs. I0906 02:45:5",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:1412,integrability,buffer,buffer,1412,"epVariant version: r1.6.1. - Installation method (Docker, built from source, etc.): Docker. - Type of data: exact same data in the quick start guide. **Steps to reproduce:**. - Command:. ``` . sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. deepvbuild:latest \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=1. ```. - Error trace:. ```. I0906 02:45:46.585311 275767425675280 run_deepvariant.py:519] Re-using the directory for intermediate results in /output/intermediate_results_dir. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I0906 02:45:51.909050 257960059396112 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0906 02:45:51.913105 257960059396112 make_examples_core.py:301] Preparing inputs. I0906 02:45:51.913431 257960059396112 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0906 02:45:51.913708 257960059396112 make_examples_core.py:301] Common contigs are ['chr20']. I0906 02:45:51.914803 257960059396112 make_examples_core.py:301] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the referenc",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:5414,interoperability,architectur,architecture,5414,"realigner/realigner.py"", line 806 in realign_reads. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 1881 in realign_reads. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 1908 in <listcomp>. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 1907 in realign_reads_per_sample_multisample. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 1709 in process. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 2838 in make_examples_runner. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples.py"", line 224 in main. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/absl_py/absl/app.py"", line 258 in _run_main. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/absl_py/absl/app.py"", line 312 in run. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples.py"", line 234 in <module>. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /output/intermediate_results_dir/make_examples.tfrecord@1.gz --channels insert_size --gvcf /output/intermediate_results_dir/gvcf.tfrecord@1.gz --regions chr20:10,000,000-10,010,000 --task 0. real 0m5.584s. user 0m13.426s. sys 0m0.563s. ```. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. I am running this on an AWS graviton4 machine (aarch64 architecture). The Dockerfile does not work for me directly. I had to run `build-prereq.sh` and resolve all the errors manually within a docker container. But I did run build_and_test.sh to make sure all tests passed and the binaries were also built successfully.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:425,modifiability,version,version,425,"Fatal Python error: Segmentation fault; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. I tried to test run deepvariant following the quick-start guide at https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-quick-start.md and I got `Fatal Python error: Segmentation fault`. **Setup**. - Operating system: Ubuntu 20.04.6 LTS. - DeepVariant version: r1.6.1. - Installation method (Docker, built from source, etc.): Docker. - Type of data: exact same data in the quick start guide. **Steps to reproduce:**. - Command:. ``` . sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. deepvbuild:latest \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=1. ```. - Error trace:. ```. I0906 02:45:46.585311 275767425675280 run_deepvariant.py:519] Re-using the directory for intermediate results in /output/intermediate_results_dir. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I0906 02:45:51.909050 257960059396112 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0906 02:45:51.913105 257960059396112 make_examples_core.py:301] Preparing inputs. I0906 02:45:5",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:1182,modifiability,interm,intermediate,1182,"nt following the quick-start guide at https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-quick-start.md and I got `Fatal Python error: Segmentation fault`. **Setup**. - Operating system: Ubuntu 20.04.6 LTS. - DeepVariant version: r1.6.1. - Installation method (Docker, built from source, etc.): Docker. - Type of data: exact same data in the quick start guide. **Steps to reproduce:**. - Command:. ``` . sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. deepvbuild:latest \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=1. ```. - Error trace:. ```. I0906 02:45:46.585311 275767425675280 run_deepvariant.py:519] Re-using the directory for intermediate results in /output/intermediate_results_dir. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I0906 02:45:51.909050 257960059396112 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0906 02:45:51.913105 257960059396112 make_examples_core.py:301] Preparing inputs. I0906 02:45:51.913431 257960059396112 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0906 02:45:51.913708 257960059396112 make_examples_core.py:301] Common",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:1246,modifiability,Interm,Intermediate,1246,"deepvariant/blob/r1.6.1/docs/deepvariant-quick-start.md and I got `Fatal Python error: Segmentation fault`. **Setup**. - Operating system: Ubuntu 20.04.6 LTS. - DeepVariant version: r1.6.1. - Installation method (Docker, built from source, etc.): Docker. - Type of data: exact same data in the quick start guide. **Steps to reproduce:**. - Command:. ``` . sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. deepvbuild:latest \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=1. ```. - Error trace:. ```. I0906 02:45:46.585311 275767425675280 run_deepvariant.py:519] Re-using the directory for intermediate results in /output/intermediate_results_dir. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I0906 02:45:51.909050 257960059396112 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0906 02:45:51.913105 257960059396112 make_examples_core.py:301] Preparing inputs. I0906 02:45:51.913431 257960059396112 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0906 02:45:51.913708 257960059396112 make_examples_core.py:301] Common contigs are ['chr20']. I0906 02:45:51.914803 257960059396112 ma",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:2385,modifiability,deco,decode,2385,"llel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I0906 02:45:51.909050 257960059396112 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0906 02:45:51.913105 257960059396112 make_examples_core.py:301] Preparing inputs. I0906 02:45:51.913431 257960059396112 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0906 02:45:51.913708 257960059396112 make_examples_core.py:301] Common contigs are ['chr20']. I0906 02:45:51.914803 257960059396112 make_examples_core.py:301] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. I0906 02:45:51.916343 257960059396112 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0906 02:45:51.961755 257960059396112 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0906 02:45:51.961891 257960059396112 make_examples_core.py:301] Writing gvcf records to /output/intermediate_results_dir/gvcf.tfrecord-00000-of-00001.gz. I0906 02:45:51.962091 257960059396112 make_examples_core.py:301] Writing examples to /output/intermediate_results_dir/make_examples.tfrecord-00000-of-00001.gz. I0906 02:45:51.962123 257960059396112 make_examples_core.py:301] Overhead for preparing inputs: 0 seconds. Fatal Python error: Segmentation fault. Current thread 0x0000ea9d01b4e010 (most recent call first):. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/realigner/window_selector.py"", line 116 in _variant_reads_threshold_selector. File ""/tmp/Bazel.runfi",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:4685,modifiability,modul,module,4685,"realigner/realigner.py"", line 806 in realign_reads. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 1881 in realign_reads. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 1908 in <listcomp>. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 1907 in realign_reads_per_sample_multisample. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 1709 in process. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 2838 in make_examples_runner. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples.py"", line 224 in main. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/absl_py/absl/app.py"", line 258 in _run_main. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/absl_py/absl/app.py"", line 312 in run. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples.py"", line 234 in <module>. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /output/intermediate_results_dir/make_examples.tfrecord@1.gz --channels insert_size --gvcf /output/intermediate_results_dir/gvcf.tfrecord@1.gz --regions chr20:10,000,000-10,010,000 --task 0. real 0m5.584s. user 0m13.426s. sys 0m0.563s. ```. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. I am running this on an AWS graviton4 machine (aarch64 architecture). The Dockerfile does not work for me directly. I had to run `build-prereq.sh` and resolve all the errors manually within a docker container. But I did run build_and_test.sh to make sure all tests passed and the binaries were also built successfully.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:13,performance,error,error,13,"Fatal Python error: Segmentation fault; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. I tried to test run deepvariant following the quick-start guide at https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-quick-start.md and I got `Fatal Python error: Segmentation fault`. **Setup**. - Operating system: Ubuntu 20.04.6 LTS. - DeepVariant version: r1.6.1. - Installation method (Docker, built from source, etc.): Docker. - Type of data: exact same data in the quick start guide. **Steps to reproduce:**. - Command:. ``` . sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. deepvbuild:latest \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=1. ```. - Error trace:. ```. I0906 02:45:46.585311 275767425675280 run_deepvariant.py:519] Re-using the directory for intermediate results in /output/intermediate_results_dir. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I0906 02:45:51.909050 257960059396112 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0906 02:45:51.913105 257960059396112 make_examples_core.py:301] Preparing inputs. I0906 02:45:5",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:33,performance,fault,fault,33,"Fatal Python error: Segmentation fault; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. I tried to test run deepvariant following the quick-start guide at https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-quick-start.md and I got `Fatal Python error: Segmentation fault`. **Setup**. - Operating system: Ubuntu 20.04.6 LTS. - DeepVariant version: r1.6.1. - Installation method (Docker, built from source, etc.): Docker. - Type of data: exact same data in the quick start guide. **Steps to reproduce:**. - Command:. ``` . sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. deepvbuild:latest \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=1. ```. - Error trace:. ```. I0906 02:45:46.585311 275767425675280 run_deepvariant.py:519] Re-using the directory for intermediate results in /output/intermediate_results_dir. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I0906 02:45:51.909050 257960059396112 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0906 02:45:51.913105 257960059396112 make_examples_core.py:301] Preparing inputs. I0906 02:45:5",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:332,performance,error,error,332,"Fatal Python error: Segmentation fault; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. I tried to test run deepvariant following the quick-start guide at https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-quick-start.md and I got `Fatal Python error: Segmentation fault`. **Setup**. - Operating system: Ubuntu 20.04.6 LTS. - DeepVariant version: r1.6.1. - Installation method (Docker, built from source, etc.): Docker. - Type of data: exact same data in the quick start guide. **Steps to reproduce:**. - Command:. ``` . sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. deepvbuild:latest \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=1. ```. - Error trace:. ```. I0906 02:45:46.585311 275767425675280 run_deepvariant.py:519] Re-using the directory for intermediate results in /output/intermediate_results_dir. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I0906 02:45:51.909050 257960059396112 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0906 02:45:51.913105 257960059396112 make_examples_core.py:301] Preparing inputs. I0906 02:45:5",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:352,performance,fault,fault,352,"Fatal Python error: Segmentation fault; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. I tried to test run deepvariant following the quick-start guide at https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-quick-start.md and I got `Fatal Python error: Segmentation fault`. **Setup**. - Operating system: Ubuntu 20.04.6 LTS. - DeepVariant version: r1.6.1. - Installation method (Docker, built from source, etc.): Docker. - Type of data: exact same data in the quick start guide. **Steps to reproduce:**. - Command:. ``` . sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. deepvbuild:latest \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=1. ```. - Error trace:. ```. I0906 02:45:46.585311 275767425675280 run_deepvariant.py:519] Re-using the directory for intermediate results in /output/intermediate_results_dir. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I0906 02:45:51.909050 257960059396112 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0906 02:45:51.913105 257960059396112 make_examples_core.py:301] Preparing inputs. I0906 02:45:5",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:1074,performance,Error,Error,1074,"ithub.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. I tried to test run deepvariant following the quick-start guide at https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-quick-start.md and I got `Fatal Python error: Segmentation fault`. **Setup**. - Operating system: Ubuntu 20.04.6 LTS. - DeepVariant version: r1.6.1. - Installation method (Docker, built from source, etc.): Docker. - Type of data: exact same data in the quick start guide. **Steps to reproduce:**. - Command:. ``` . sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. deepvbuild:latest \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=1. ```. - Error trace:. ```. I0906 02:45:46.585311 275767425675280 run_deepvariant.py:519] Re-using the directory for intermediate results in /output/intermediate_results_dir. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I0906 02:45:51.909050 257960059396112 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0906 02:45:51.913105 257960059396112 make_examples_core.py:301] Preparing inputs. I0906 02:45:51.913431 257960059396112 genomics_reader.py:222] Reading /input/NA12878_S1.ch",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:1369,performance,time,time,1369,"- Operating system: Ubuntu 20.04.6 LTS. - DeepVariant version: r1.6.1. - Installation method (Docker, built from source, etc.): Docker. - Type of data: exact same data in the quick start guide. **Steps to reproduce:**. - Command:. ``` . sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. deepvbuild:latest \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=1. ```. - Error trace:. ```. I0906 02:45:46.585311 275767425675280 run_deepvariant.py:519] Re-using the directory for intermediate results in /output/intermediate_results_dir. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I0906 02:45:51.909050 257960059396112 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0906 02:45:51.913105 257960059396112 make_examples_core.py:301] Preparing inputs. I0906 02:45:51.913431 257960059396112 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0906 02:45:51.913708 257960059396112 make_examples_core.py:301] Common contigs are ['chr20']. I0906 02:45:51.914803 257960059396112 make_examples_core.py:301] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:1384,performance,parallel,parallel,1384,"m: Ubuntu 20.04.6 LTS. - DeepVariant version: r1.6.1. - Installation method (Docker, built from source, etc.): Docker. - Type of data: exact same data in the quick start guide. **Steps to reproduce:**. - Command:. ``` . sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. deepvbuild:latest \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=1. ```. - Error trace:. ```. I0906 02:45:46.585311 275767425675280 run_deepvariant.py:519] Re-using the directory for intermediate results in /output/intermediate_results_dir. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I0906 02:45:51.909050 257960059396112 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0906 02:45:51.913105 257960059396112 make_examples_core.py:301] Preparing inputs. I0906 02:45:51.913431 257960059396112 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0906 02:45:51.913708 257960059396112 make_examples_core.py:301] Common contigs are ['chr20']. I0906 02:45:51.914803 257960059396112 make_examples_core.py:301] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will dec",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:3083,performance,Overhead,Overhead,3083,"1mb.bam with NativeSamReader. I0906 02:45:51.913708 257960059396112 make_examples_core.py:301] Common contigs are ['chr20']. I0906 02:45:51.914803 257960059396112 make_examples_core.py:301] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. I0906 02:45:51.916343 257960059396112 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0906 02:45:51.961755 257960059396112 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0906 02:45:51.961891 257960059396112 make_examples_core.py:301] Writing gvcf records to /output/intermediate_results_dir/gvcf.tfrecord-00000-of-00001.gz. I0906 02:45:51.962091 257960059396112 make_examples_core.py:301] Writing examples to /output/intermediate_results_dir/make_examples.tfrecord-00000-of-00001.gz. I0906 02:45:51.962123 257960059396112 make_examples_core.py:301] Overhead for preparing inputs: 0 seconds. Fatal Python error: Segmentation fault. Current thread 0x0000ea9d01b4e010 (most recent call first):. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/realigner/window_selector.py"", line 116 in _variant_reads_threshold_selector. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/realigner/window_selector.py"", line 76 in _candidates_from_reads. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/realigner/realigner.py"", line 806 in realign_reads. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 1881 in realign_reads. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 1908 in <listcomp>. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 1907 in realign_reads_per_sample_multisamp",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:3138,performance,error,error,3138,"7960059396112 make_examples_core.py:301] Common contigs are ['chr20']. I0906 02:45:51.914803 257960059396112 make_examples_core.py:301] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. I0906 02:45:51.916343 257960059396112 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0906 02:45:51.961755 257960059396112 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0906 02:45:51.961891 257960059396112 make_examples_core.py:301] Writing gvcf records to /output/intermediate_results_dir/gvcf.tfrecord-00000-of-00001.gz. I0906 02:45:51.962091 257960059396112 make_examples_core.py:301] Writing examples to /output/intermediate_results_dir/make_examples.tfrecord-00000-of-00001.gz. I0906 02:45:51.962123 257960059396112 make_examples_core.py:301] Overhead for preparing inputs: 0 seconds. Fatal Python error: Segmentation fault. Current thread 0x0000ea9d01b4e010 (most recent call first):. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/realigner/window_selector.py"", line 116 in _variant_reads_threshold_selector. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/realigner/window_selector.py"", line 76 in _candidates_from_reads. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/realigner/realigner.py"", line 806 in realign_reads. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 1881 in realign_reads. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 1908 in <listcomp>. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 1907 in realign_reads_per_sample_multisample. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:3158,performance,fault,fault,3158,"xamples_core.py:301] Common contigs are ['chr20']. I0906 02:45:51.914803 257960059396112 make_examples_core.py:301] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. I0906 02:45:51.916343 257960059396112 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0906 02:45:51.961755 257960059396112 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0906 02:45:51.961891 257960059396112 make_examples_core.py:301] Writing gvcf records to /output/intermediate_results_dir/gvcf.tfrecord-00000-of-00001.gz. I0906 02:45:51.962091 257960059396112 make_examples_core.py:301] Writing examples to /output/intermediate_results_dir/make_examples.tfrecord-00000-of-00001.gz. I0906 02:45:51.962123 257960059396112 make_examples_core.py:301] Overhead for preparing inputs: 0 seconds. Fatal Python error: Segmentation fault. Current thread 0x0000ea9d01b4e010 (most recent call first):. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/realigner/window_selector.py"", line 116 in _variant_reads_threshold_selector. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/realigner/window_selector.py"", line 76 in _candidates_from_reads. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/realigner/realigner.py"", line 806 in realign_reads. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 1881 in realign_reads. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 1908 in <listcomp>. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 1907 in realign_reads_per_sample_multisample. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_exa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:4694,performance,parallel,parallel,4694,"realigner/realigner.py"", line 806 in realign_reads. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 1881 in realign_reads. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 1908 in <listcomp>. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 1907 in realign_reads_per_sample_multisample. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 1709 in process. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 2838 in make_examples_runner. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples.py"", line 224 in main. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/absl_py/absl/app.py"", line 258 in _run_main. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/absl_py/absl/app.py"", line 312 in run. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples.py"", line 234 in <module>. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /output/intermediate_results_dir/make_examples.tfrecord@1.gz --channels insert_size --gvcf /output/intermediate_results_dir/gvcf.tfrecord@1.gz --regions chr20:10,000,000-10,010,000 --task 0. real 0m5.584s. user 0m13.426s. sys 0m0.563s. ```. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. I am running this on an AWS graviton4 machine (aarch64 architecture). The Dockerfile does not work for me directly. I had to run `build-prereq.sh` and resolve all the errors manually within a docker container. But I did run build_and_test.sh to make sure all tests passed and the binaries were also built successfully.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:5526,performance,error,errors,5526,"realigner/realigner.py"", line 806 in realign_reads. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 1881 in realign_reads. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 1908 in <listcomp>. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 1907 in realign_reads_per_sample_multisample. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 1709 in process. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 2838 in make_examples_runner. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples.py"", line 224 in main. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/absl_py/absl/app.py"", line 258 in _run_main. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/absl_py/absl/app.py"", line 312 in run. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples.py"", line 234 in <module>. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /output/intermediate_results_dir/make_examples.tfrecord@1.gz --channels insert_size --gvcf /output/intermediate_results_dir/gvcf.tfrecord@1.gz --regions chr20:10,000,000-10,010,000 --task 0. real 0m5.584s. user 0m13.426s. sys 0m0.563s. ```. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. I am running this on an AWS graviton4 machine (aarch64 architecture). The Dockerfile does not work for me directly. I had to run `build-prereq.sh` and resolve all the errors manually within a docker container. But I did run build_and_test.sh to make sure all tests passed and the binaries were also built successfully.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:33,reliability,fault,fault,33,"Fatal Python error: Segmentation fault; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. I tried to test run deepvariant following the quick-start guide at https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-quick-start.md and I got `Fatal Python error: Segmentation fault`. **Setup**. - Operating system: Ubuntu 20.04.6 LTS. - DeepVariant version: r1.6.1. - Installation method (Docker, built from source, etc.): Docker. - Type of data: exact same data in the quick start guide. **Steps to reproduce:**. - Command:. ``` . sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. deepvbuild:latest \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=1. ```. - Error trace:. ```. I0906 02:45:46.585311 275767425675280 run_deepvariant.py:519] Re-using the directory for intermediate results in /output/intermediate_results_dir. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I0906 02:45:51.909050 257960059396112 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0906 02:45:51.913105 257960059396112 make_examples_core.py:301] Preparing inputs. I0906 02:45:5",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:352,reliability,fault,fault,352,"Fatal Python error: Segmentation fault; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. I tried to test run deepvariant following the quick-start guide at https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-quick-start.md and I got `Fatal Python error: Segmentation fault`. **Setup**. - Operating system: Ubuntu 20.04.6 LTS. - DeepVariant version: r1.6.1. - Installation method (Docker, built from source, etc.): Docker. - Type of data: exact same data in the quick start guide. **Steps to reproduce:**. - Command:. ``` . sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. deepvbuild:latest \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=1. ```. - Error trace:. ```. I0906 02:45:46.585311 275767425675280 run_deepvariant.py:519] Re-using the directory for intermediate results in /output/intermediate_results_dir. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I0906 02:45:51.909050 257960059396112 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0906 02:45:51.913105 257960059396112 make_examples_core.py:301] Preparing inputs. I0906 02:45:5",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:3158,reliability,fault,fault,3158,"xamples_core.py:301] Common contigs are ['chr20']. I0906 02:45:51.914803 257960059396112 make_examples_core.py:301] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. I0906 02:45:51.916343 257960059396112 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0906 02:45:51.961755 257960059396112 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0906 02:45:51.961891 257960059396112 make_examples_core.py:301] Writing gvcf records to /output/intermediate_results_dir/gvcf.tfrecord-00000-of-00001.gz. I0906 02:45:51.962091 257960059396112 make_examples_core.py:301] Writing examples to /output/intermediate_results_dir/make_examples.tfrecord-00000-of-00001.gz. I0906 02:45:51.962123 257960059396112 make_examples_core.py:301] Overhead for preparing inputs: 0 seconds. Fatal Python error: Segmentation fault. Current thread 0x0000ea9d01b4e010 (most recent call first):. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/realigner/window_selector.py"", line 116 in _variant_reads_threshold_selector. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/realigner/window_selector.py"", line 76 in _candidates_from_reads. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/realigner/realigner.py"", line 806 in realign_reads. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 1881 in realign_reads. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 1908 in <listcomp>. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 1907 in realign_reads_per_sample_multisample. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_exa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:4713,reliability,fail,failed,4713,"realigner/realigner.py"", line 806 in realign_reads. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 1881 in realign_reads. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 1908 in <listcomp>. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 1907 in realign_reads_per_sample_multisample. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 1709 in process. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 2838 in make_examples_runner. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples.py"", line 224 in main. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/absl_py/absl/app.py"", line 258 in _run_main. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/absl_py/absl/app.py"", line 312 in run. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples.py"", line 234 in <module>. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /output/intermediate_results_dir/make_examples.tfrecord@1.gz --channels insert_size --gvcf /output/intermediate_results_dir/gvcf.tfrecord@1.gz --regions chr20:10,000,000-10,010,000 --task 0. real 0m5.584s. user 0m13.426s. sys 0m0.563s. ```. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. I am running this on an AWS graviton4 machine (aarch64 architecture). The Dockerfile does not work for me directly. I had to run `build-prereq.sh` and resolve all the errors manually within a docker container. But I did run build_and_test.sh to make sure all tests passed and the binaries were also built successfully.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:5116,reliability,Doe,Does,5116,"realigner/realigner.py"", line 806 in realign_reads. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 1881 in realign_reads. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 1908 in <listcomp>. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 1907 in realign_reads_per_sample_multisample. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 1709 in process. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 2838 in make_examples_runner. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples.py"", line 224 in main. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/absl_py/absl/app.py"", line 258 in _run_main. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/absl_py/absl/app.py"", line 312 in run. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples.py"", line 234 in <module>. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /output/intermediate_results_dir/make_examples.tfrecord@1.gz --channels insert_size --gvcf /output/intermediate_results_dir/gvcf.tfrecord@1.gz --regions chr20:10,000,000-10,010,000 --task 0. real 0m5.584s. user 0m13.426s. sys 0m0.563s. ```. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. I am running this on an AWS graviton4 machine (aarch64 architecture). The Dockerfile does not work for me directly. I had to run `build-prereq.sh` and resolve all the errors manually within a docker container. But I did run build_and_test.sh to make sure all tests passed and the binaries were also built successfully.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:5444,reliability,doe,does,5444,"realigner/realigner.py"", line 806 in realign_reads. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 1881 in realign_reads. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 1908 in <listcomp>. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 1907 in realign_reads_per_sample_multisample. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 1709 in process. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 2838 in make_examples_runner. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples.py"", line 224 in main. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/absl_py/absl/app.py"", line 258 in _run_main. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/absl_py/absl/app.py"", line 312 in run. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples.py"", line 234 in <module>. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /output/intermediate_results_dir/make_examples.tfrecord@1.gz --channels insert_size --gvcf /output/intermediate_results_dir/gvcf.tfrecord@1.gz --regions chr20:10,000,000-10,010,000 --task 0. real 0m5.584s. user 0m13.426s. sys 0m0.563s. ```. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. I am running this on an AWS graviton4 machine (aarch64 architecture). The Dockerfile does not work for me directly. I had to run `build-prereq.sh` and resolve all the errors manually within a docker container. But I did run build_and_test.sh to make sure all tests passed and the binaries were also built successfully.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:13,safety,error,error,13,"Fatal Python error: Segmentation fault; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. I tried to test run deepvariant following the quick-start guide at https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-quick-start.md and I got `Fatal Python error: Segmentation fault`. **Setup**. - Operating system: Ubuntu 20.04.6 LTS. - DeepVariant version: r1.6.1. - Installation method (Docker, built from source, etc.): Docker. - Type of data: exact same data in the quick start guide. **Steps to reproduce:**. - Command:. ``` . sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. deepvbuild:latest \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=1. ```. - Error trace:. ```. I0906 02:45:46.585311 275767425675280 run_deepvariant.py:519] Re-using the directory for intermediate results in /output/intermediate_results_dir. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I0906 02:45:51.909050 257960059396112 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0906 02:45:51.913105 257960059396112 make_examples_core.py:301] Preparing inputs. I0906 02:45:5",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:33,safety,fault,fault,33,"Fatal Python error: Segmentation fault; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. I tried to test run deepvariant following the quick-start guide at https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-quick-start.md and I got `Fatal Python error: Segmentation fault`. **Setup**. - Operating system: Ubuntu 20.04.6 LTS. - DeepVariant version: r1.6.1. - Installation method (Docker, built from source, etc.): Docker. - Type of data: exact same data in the quick start guide. **Steps to reproduce:**. - Command:. ``` . sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. deepvbuild:latest \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=1. ```. - Error trace:. ```. I0906 02:45:46.585311 275767425675280 run_deepvariant.py:519] Re-using the directory for intermediate results in /output/intermediate_results_dir. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I0906 02:45:51.909050 257960059396112 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0906 02:45:51.913105 257960059396112 make_examples_core.py:301] Preparing inputs. I0906 02:45:5",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:170,safety,test,test,170,"Fatal Python error: Segmentation fault; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. I tried to test run deepvariant following the quick-start guide at https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-quick-start.md and I got `Fatal Python error: Segmentation fault`. **Setup**. - Operating system: Ubuntu 20.04.6 LTS. - DeepVariant version: r1.6.1. - Installation method (Docker, built from source, etc.): Docker. - Type of data: exact same data in the quick start guide. **Steps to reproduce:**. - Command:. ``` . sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. deepvbuild:latest \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=1. ```. - Error trace:. ```. I0906 02:45:46.585311 275767425675280 run_deepvariant.py:519] Re-using the directory for intermediate results in /output/intermediate_results_dir. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I0906 02:45:51.909050 257960059396112 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0906 02:45:51.913105 257960059396112 make_examples_core.py:301] Preparing inputs. I0906 02:45:5",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:332,safety,error,error,332,"Fatal Python error: Segmentation fault; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. I tried to test run deepvariant following the quick-start guide at https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-quick-start.md and I got `Fatal Python error: Segmentation fault`. **Setup**. - Operating system: Ubuntu 20.04.6 LTS. - DeepVariant version: r1.6.1. - Installation method (Docker, built from source, etc.): Docker. - Type of data: exact same data in the quick start guide. **Steps to reproduce:**. - Command:. ``` . sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. deepvbuild:latest \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=1. ```. - Error trace:. ```. I0906 02:45:46.585311 275767425675280 run_deepvariant.py:519] Re-using the directory for intermediate results in /output/intermediate_results_dir. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I0906 02:45:51.909050 257960059396112 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0906 02:45:51.913105 257960059396112 make_examples_core.py:301] Preparing inputs. I0906 02:45:5",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:352,safety,fault,fault,352,"Fatal Python error: Segmentation fault; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. I tried to test run deepvariant following the quick-start guide at https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-quick-start.md and I got `Fatal Python error: Segmentation fault`. **Setup**. - Operating system: Ubuntu 20.04.6 LTS. - DeepVariant version: r1.6.1. - Installation method (Docker, built from source, etc.): Docker. - Type of data: exact same data in the quick start guide. **Steps to reproduce:**. - Command:. ``` . sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. deepvbuild:latest \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=1. ```. - Error trace:. ```. I0906 02:45:46.585311 275767425675280 run_deepvariant.py:519] Re-using the directory for intermediate results in /output/intermediate_results_dir. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I0906 02:45:51.909050 257960059396112 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0906 02:45:51.913105 257960059396112 make_examples_core.py:301] Preparing inputs. I0906 02:45:5",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:647,safety,input,input,647,"Fatal Python error: Segmentation fault; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. I tried to test run deepvariant following the quick-start guide at https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-quick-start.md and I got `Fatal Python error: Segmentation fault`. **Setup**. - Operating system: Ubuntu 20.04.6 LTS. - DeepVariant version: r1.6.1. - Installation method (Docker, built from source, etc.): Docker. - Type of data: exact same data in the quick start guide. **Steps to reproduce:**. - Command:. ``` . sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. deepvbuild:latest \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=1. ```. - Error trace:. ```. I0906 02:45:46.585311 275767425675280 run_deepvariant.py:519] Re-using the directory for intermediate results in /output/intermediate_results_dir. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I0906 02:45:51.909050 257960059396112 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0906 02:45:51.913105 257960059396112 make_examples_core.py:301] Preparing inputs. I0906 02:45:5",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:777,safety,input,input,777,"Fatal Python error: Segmentation fault; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. I tried to test run deepvariant following the quick-start guide at https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-quick-start.md and I got `Fatal Python error: Segmentation fault`. **Setup**. - Operating system: Ubuntu 20.04.6 LTS. - DeepVariant version: r1.6.1. - Installation method (Docker, built from source, etc.): Docker. - Type of data: exact same data in the quick start guide. **Steps to reproduce:**. - Command:. ``` . sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. deepvbuild:latest \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=1. ```. - Error trace:. ```. I0906 02:45:46.585311 275767425675280 run_deepvariant.py:519] Re-using the directory for intermediate results in /output/intermediate_results_dir. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I0906 02:45:51.909050 257960059396112 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0906 02:45:51.913105 257960059396112 make_examples_core.py:301] Preparing inputs. I0906 02:45:5",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:826,safety,input,input,826,"Fatal Python error: Segmentation fault; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. I tried to test run deepvariant following the quick-start guide at https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-quick-start.md and I got `Fatal Python error: Segmentation fault`. **Setup**. - Operating system: Ubuntu 20.04.6 LTS. - DeepVariant version: r1.6.1. - Installation method (Docker, built from source, etc.): Docker. - Type of data: exact same data in the quick start guide. **Steps to reproduce:**. - Command:. ``` . sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. deepvbuild:latest \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=1. ```. - Error trace:. ```. I0906 02:45:46.585311 275767425675280 run_deepvariant.py:519] Re-using the directory for intermediate results in /output/intermediate_results_dir. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I0906 02:45:51.909050 257960059396112 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0906 02:45:51.913105 257960059396112 make_examples_core.py:301] Preparing inputs. I0906 02:45:5",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:1074,safety,Error,Error,1074,"ithub.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. I tried to test run deepvariant following the quick-start guide at https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-quick-start.md and I got `Fatal Python error: Segmentation fault`. **Setup**. - Operating system: Ubuntu 20.04.6 LTS. - DeepVariant version: r1.6.1. - Installation method (Docker, built from source, etc.): Docker. - Type of data: exact same data in the quick start guide. **Steps to reproduce:**. - Command:. ``` . sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. deepvbuild:latest \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=1. ```. - Error trace:. ```. I0906 02:45:46.585311 275767425675280 run_deepvariant.py:519] Re-using the directory for intermediate results in /output/intermediate_results_dir. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I0906 02:45:51.909050 257960059396112 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0906 02:45:51.913105 257960059396112 make_examples_core.py:301] Preparing inputs. I0906 02:45:51.913431 257960059396112 genomics_reader.py:222] Reading /input/NA12878_S1.ch",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:1477,safety,input,input,1477,"rom source, etc.): Docker. - Type of data: exact same data in the quick start guide. **Steps to reproduce:**. - Command:. ``` . sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. deepvbuild:latest \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=1. ```. - Error trace:. ```. I0906 02:45:46.585311 275767425675280 run_deepvariant.py:519] Re-using the directory for intermediate results in /output/intermediate_results_dir. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I0906 02:45:51.909050 257960059396112 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0906 02:45:51.913105 257960059396112 make_examples_core.py:301] Preparing inputs. I0906 02:45:51.913431 257960059396112 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0906 02:45:51.913708 257960059396112 make_examples_core.py:301] Common contigs are ['chr20']. I0906 02:45:51.914803 257960059396112 make_examples_core.py:301] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. I0906 02:45:51.916343 257960059396112",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:1525,safety,input,input,1525," same data in the quick start guide. **Steps to reproduce:**. - Command:. ``` . sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. deepvbuild:latest \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=1. ```. - Error trace:. ```. I0906 02:45:46.585311 275767425675280 run_deepvariant.py:519] Re-using the directory for intermediate results in /output/intermediate_results_dir. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I0906 02:45:51.909050 257960059396112 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0906 02:45:51.913105 257960059396112 make_examples_core.py:301] Preparing inputs. I0906 02:45:51.913431 257960059396112 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0906 02:45:51.913708 257960059396112 make_examples_core.py:301] Common contigs are ['chr20']. I0906 02:45:51.914803 257960059396112 make_examples_core.py:301] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. I0906 02:45:51.916343 257960059396112 genomics_reader.py:222] Reading /input/NA12878_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:1845,safety,input,input,1845,".10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=1. ```. - Error trace:. ```. I0906 02:45:46.585311 275767425675280 run_deepvariant.py:519] Re-using the directory for intermediate results in /output/intermediate_results_dir. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I0906 02:45:51.909050 257960059396112 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0906 02:45:51.913105 257960059396112 make_examples_core.py:301] Preparing inputs. I0906 02:45:51.913431 257960059396112 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0906 02:45:51.913708 257960059396112 make_examples_core.py:301] Common contigs are ['chr20']. I0906 02:45:51.914803 257960059396112 make_examples_core.py:301] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. I0906 02:45:51.916343 257960059396112 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0906 02:45:51.961755 257960059396112 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0906 02:45:51.961891 257960059396112 make_examples_core.py:301] Writing gvcf records to /output/intermediate_results_dir/gvcf.tfrecord-00000-of-",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:1979,safety,input,inputs,1979,"gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=1. ```. - Error trace:. ```. I0906 02:45:46.585311 275767425675280 run_deepvariant.py:519] Re-using the directory for intermediate results in /output/intermediate_results_dir. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I0906 02:45:51.909050 257960059396112 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0906 02:45:51.913105 257960059396112 make_examples_core.py:301] Preparing inputs. I0906 02:45:51.913431 257960059396112 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0906 02:45:51.913708 257960059396112 make_examples_core.py:301] Common contigs are ['chr20']. I0906 02:45:51.914803 257960059396112 make_examples_core.py:301] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. I0906 02:45:51.916343 257960059396112 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0906 02:45:51.961755 257960059396112 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0906 02:45:51.961891 257960059396112 make_examples_core.py:301] Writing gvcf records to /output/intermediate_results_dir/gvcf.tfrecord-00000-of-00001.gz. I0906 02:45:51.962091 257960059396112 make_examples_core.py:301] Writing examples to /output/intermediate_results_dir/make_e",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:2058,safety,input,input,2058,"ds=1. ```. - Error trace:. ```. I0906 02:45:46.585311 275767425675280 run_deepvariant.py:519] Re-using the directory for intermediate results in /output/intermediate_results_dir. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I0906 02:45:51.909050 257960059396112 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0906 02:45:51.913105 257960059396112 make_examples_core.py:301] Preparing inputs. I0906 02:45:51.913431 257960059396112 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0906 02:45:51.913708 257960059396112 make_examples_core.py:301] Common contigs are ['chr20']. I0906 02:45:51.914803 257960059396112 make_examples_core.py:301] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. I0906 02:45:51.916343 257960059396112 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0906 02:45:51.961755 257960059396112 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0906 02:45:51.961891 257960059396112 make_examples_core.py:301] Writing gvcf records to /output/intermediate_results_dir/gvcf.tfrecord-00000-of-00001.gz. I0906 02:45:51.962091 257960059396112 make_examples_core.py:301] Writing examples to /output/intermediate_results_dir/make_examples.tfrecord-00000-of-00001.gz. I0906 02:45:51.962123 257960059396112 make_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:2360,safety,input,input,2360,"****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I0906 02:45:51.909050 257960059396112 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0906 02:45:51.913105 257960059396112 make_examples_core.py:301] Preparing inputs. I0906 02:45:51.913431 257960059396112 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0906 02:45:51.913708 257960059396112 make_examples_core.py:301] Common contigs are ['chr20']. I0906 02:45:51.914803 257960059396112 make_examples_core.py:301] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. I0906 02:45:51.916343 257960059396112 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0906 02:45:51.961755 257960059396112 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0906 02:45:51.961891 257960059396112 make_examples_core.py:301] Writing gvcf records to /output/intermediate_results_dir/gvcf.tfrecord-00000-of-00001.gz. I0906 02:45:51.962091 257960059396112 make_examples_core.py:301] Writing examples to /output/intermediate_results_dir/make_examples.tfrecord-00000-of-00001.gz. I0906 02:45:51.962123 257960059396112 make_examples_core.py:301] Overhead for preparing inputs: 0 seconds. Fatal Python error: Segmentation fault. Current thread 0x0000ea9d01b4e010 (most recent call first):. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/realigner/window_selector.py"", line 116 in _variant_reads_threshold_selecto",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:2514,safety,input,input,2514,"reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I0906 02:45:51.909050 257960059396112 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0906 02:45:51.913105 257960059396112 make_examples_core.py:301] Preparing inputs. I0906 02:45:51.913431 257960059396112 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0906 02:45:51.913708 257960059396112 make_examples_core.py:301] Common contigs are ['chr20']. I0906 02:45:51.914803 257960059396112 make_examples_core.py:301] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. I0906 02:45:51.916343 257960059396112 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0906 02:45:51.961755 257960059396112 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0906 02:45:51.961891 257960059396112 make_examples_core.py:301] Writing gvcf records to /output/intermediate_results_dir/gvcf.tfrecord-00000-of-00001.gz. I0906 02:45:51.962091 257960059396112 make_examples_core.py:301] Writing examples to /output/intermediate_results_dir/make_examples.tfrecord-00000-of-00001.gz. I0906 02:45:51.962123 257960059396112 make_examples_core.py:301] Overhead for preparing inputs: 0 seconds. Fatal Python error: Segmentation fault. Current thread 0x0000ea9d01b4e010 (most recent call first):. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/realigner/window_selector.py"", line 116 in _variant_reads_threshold_selector. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/realigner/window_selector.py"", line 76 in _candidates_from_reads. File ""/tmp/Bazel.runfil",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:2644,safety,input,input,2644," ""insert_size"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I0906 02:45:51.909050 257960059396112 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0906 02:45:51.913105 257960059396112 make_examples_core.py:301] Preparing inputs. I0906 02:45:51.913431 257960059396112 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0906 02:45:51.913708 257960059396112 make_examples_core.py:301] Common contigs are ['chr20']. I0906 02:45:51.914803 257960059396112 make_examples_core.py:301] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. I0906 02:45:51.916343 257960059396112 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0906 02:45:51.961755 257960059396112 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0906 02:45:51.961891 257960059396112 make_examples_core.py:301] Writing gvcf records to /output/intermediate_results_dir/gvcf.tfrecord-00000-of-00001.gz. I0906 02:45:51.962091 257960059396112 make_examples_core.py:301] Writing examples to /output/intermediate_results_dir/make_examples.tfrecord-00000-of-00001.gz. I0906 02:45:51.962123 257960059396112 make_examples_core.py:301] Overhead for preparing inputs: 0 seconds. Fatal Python error: Segmentation fault. Current thread 0x0000ea9d01b4e010 (most recent call first):. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/realigner/window_selector.py"", line 116 in _variant_reads_threshold_selector. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/realigner/window_selector.py"", line 76 in _candidates_from_reads. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_v_91gi",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:3106,safety,input,inputs,3106,"Reader. I0906 02:45:51.913708 257960059396112 make_examples_core.py:301] Common contigs are ['chr20']. I0906 02:45:51.914803 257960059396112 make_examples_core.py:301] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. I0906 02:45:51.916343 257960059396112 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0906 02:45:51.961755 257960059396112 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0906 02:45:51.961891 257960059396112 make_examples_core.py:301] Writing gvcf records to /output/intermediate_results_dir/gvcf.tfrecord-00000-of-00001.gz. I0906 02:45:51.962091 257960059396112 make_examples_core.py:301] Writing examples to /output/intermediate_results_dir/make_examples.tfrecord-00000-of-00001.gz. I0906 02:45:51.962123 257960059396112 make_examples_core.py:301] Overhead for preparing inputs: 0 seconds. Fatal Python error: Segmentation fault. Current thread 0x0000ea9d01b4e010 (most recent call first):. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/realigner/window_selector.py"", line 116 in _variant_reads_threshold_selector. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/realigner/window_selector.py"", line 76 in _candidates_from_reads. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/realigner/realigner.py"", line 806 in realign_reads. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 1881 in realign_reads. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 1908 in <listcomp>. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 1907 in realign_reads_per_sample_multisample. File ""/tmp/Bazel.r",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:3138,safety,error,error,3138,"7960059396112 make_examples_core.py:301] Common contigs are ['chr20']. I0906 02:45:51.914803 257960059396112 make_examples_core.py:301] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. I0906 02:45:51.916343 257960059396112 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0906 02:45:51.961755 257960059396112 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0906 02:45:51.961891 257960059396112 make_examples_core.py:301] Writing gvcf records to /output/intermediate_results_dir/gvcf.tfrecord-00000-of-00001.gz. I0906 02:45:51.962091 257960059396112 make_examples_core.py:301] Writing examples to /output/intermediate_results_dir/make_examples.tfrecord-00000-of-00001.gz. I0906 02:45:51.962123 257960059396112 make_examples_core.py:301] Overhead for preparing inputs: 0 seconds. Fatal Python error: Segmentation fault. Current thread 0x0000ea9d01b4e010 (most recent call first):. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/realigner/window_selector.py"", line 116 in _variant_reads_threshold_selector. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/realigner/window_selector.py"", line 76 in _candidates_from_reads. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/realigner/realigner.py"", line 806 in realign_reads. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 1881 in realign_reads. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 1908 in <listcomp>. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 1907 in realign_reads_per_sample_multisample. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:3158,safety,fault,fault,3158,"xamples_core.py:301] Common contigs are ['chr20']. I0906 02:45:51.914803 257960059396112 make_examples_core.py:301] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. I0906 02:45:51.916343 257960059396112 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0906 02:45:51.961755 257960059396112 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0906 02:45:51.961891 257960059396112 make_examples_core.py:301] Writing gvcf records to /output/intermediate_results_dir/gvcf.tfrecord-00000-of-00001.gz. I0906 02:45:51.962091 257960059396112 make_examples_core.py:301] Writing examples to /output/intermediate_results_dir/make_examples.tfrecord-00000-of-00001.gz. I0906 02:45:51.962123 257960059396112 make_examples_core.py:301] Overhead for preparing inputs: 0 seconds. Fatal Python error: Segmentation fault. Current thread 0x0000ea9d01b4e010 (most recent call first):. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/realigner/window_selector.py"", line 116 in _variant_reads_threshold_selector. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/realigner/window_selector.py"", line 76 in _candidates_from_reads. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/realigner/realigner.py"", line 806 in realign_reads. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 1881 in realign_reads. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 1908 in <listcomp>. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 1907 in realign_reads_per_sample_multisample. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_exa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:4685,safety,modul,module,4685,"realigner/realigner.py"", line 806 in realign_reads. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 1881 in realign_reads. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 1908 in <listcomp>. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 1907 in realign_reads_per_sample_multisample. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 1709 in process. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 2838 in make_examples_runner. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples.py"", line 224 in main. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/absl_py/absl/app.py"", line 258 in _run_main. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/absl_py/absl/app.py"", line 312 in run. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples.py"", line 234 in <module>. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /output/intermediate_results_dir/make_examples.tfrecord@1.gz --channels insert_size --gvcf /output/intermediate_results_dir/gvcf.tfrecord@1.gz --regions chr20:10,000,000-10,010,000 --task 0. real 0m5.584s. user 0m13.426s. sys 0m0.563s. ```. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. I am running this on an AWS graviton4 machine (aarch64 architecture). The Dockerfile does not work for me directly. I had to run `build-prereq.sh` and resolve all the errors manually within a docker container. But I did run build_and_test.sh to make sure all tests passed and the binaries were also built successfully.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:4779,safety,input,input,4779,"realigner/realigner.py"", line 806 in realign_reads. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 1881 in realign_reads. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 1908 in <listcomp>. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 1907 in realign_reads_per_sample_multisample. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 1709 in process. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 2838 in make_examples_runner. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples.py"", line 224 in main. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/absl_py/absl/app.py"", line 258 in _run_main. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/absl_py/absl/app.py"", line 312 in run. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples.py"", line 234 in <module>. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /output/intermediate_results_dir/make_examples.tfrecord@1.gz --channels insert_size --gvcf /output/intermediate_results_dir/gvcf.tfrecord@1.gz --regions chr20:10,000,000-10,010,000 --task 0. real 0m5.584s. user 0m13.426s. sys 0m0.563s. ```. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. I am running this on an AWS graviton4 machine (aarch64 architecture). The Dockerfile does not work for me directly. I had to run `build-prereq.sh` and resolve all the errors manually within a docker container. But I did run build_and_test.sh to make sure all tests passed and the binaries were also built successfully.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:4825,safety,input,input,4825,"realigner/realigner.py"", line 806 in realign_reads. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 1881 in realign_reads. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 1908 in <listcomp>. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 1907 in realign_reads_per_sample_multisample. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 1709 in process. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 2838 in make_examples_runner. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples.py"", line 224 in main. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/absl_py/absl/app.py"", line 258 in _run_main. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/absl_py/absl/app.py"", line 312 in run. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples.py"", line 234 in <module>. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /output/intermediate_results_dir/make_examples.tfrecord@1.gz --channels insert_size --gvcf /output/intermediate_results_dir/gvcf.tfrecord@1.gz --regions chr20:10,000,000-10,010,000 --task 0. real 0m5.584s. user 0m13.426s. sys 0m0.563s. ```. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. I am running this on an AWS graviton4 machine (aarch64 architecture). The Dockerfile does not work for me directly. I had to run `build-prereq.sh` and resolve all the errors manually within a docker container. But I did run build_and_test.sh to make sure all tests passed and the binaries were also built successfully.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:5137,safety,test,test,5137,"realigner/realigner.py"", line 806 in realign_reads. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 1881 in realign_reads. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 1908 in <listcomp>. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 1907 in realign_reads_per_sample_multisample. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 1709 in process. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 2838 in make_examples_runner. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples.py"", line 224 in main. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/absl_py/absl/app.py"", line 258 in _run_main. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/absl_py/absl/app.py"", line 312 in run. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples.py"", line 234 in <module>. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /output/intermediate_results_dir/make_examples.tfrecord@1.gz --channels insert_size --gvcf /output/intermediate_results_dir/gvcf.tfrecord@1.gz --regions chr20:10,000,000-10,010,000 --task 0. real 0m5.584s. user 0m13.426s. sys 0m0.563s. ```. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. I am running this on an AWS graviton4 machine (aarch64 architecture). The Dockerfile does not work for me directly. I had to run `build-prereq.sh` and resolve all the errors manually within a docker container. But I did run build_and_test.sh to make sure all tests passed and the binaries were also built successfully.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:5173,safety,test,test,5173,"realigner/realigner.py"", line 806 in realign_reads. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 1881 in realign_reads. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 1908 in <listcomp>. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 1907 in realign_reads_per_sample_multisample. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 1709 in process. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 2838 in make_examples_runner. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples.py"", line 224 in main. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/absl_py/absl/app.py"", line 258 in _run_main. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/absl_py/absl/app.py"", line 312 in run. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples.py"", line 234 in <module>. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /output/intermediate_results_dir/make_examples.tfrecord@1.gz --channels insert_size --gvcf /output/intermediate_results_dir/gvcf.tfrecord@1.gz --regions chr20:10,000,000-10,010,000 --task 0. real 0m5.584s. user 0m13.426s. sys 0m0.563s. ```. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. I am running this on an AWS graviton4 machine (aarch64 architecture). The Dockerfile does not work for me directly. I had to run `build-prereq.sh` and resolve all the errors manually within a docker container. But I did run build_and_test.sh to make sure all tests passed and the binaries were also built successfully.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:5526,safety,error,errors,5526,"realigner/realigner.py"", line 806 in realign_reads. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 1881 in realign_reads. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 1908 in <listcomp>. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 1907 in realign_reads_per_sample_multisample. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 1709 in process. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 2838 in make_examples_runner. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples.py"", line 224 in main. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/absl_py/absl/app.py"", line 258 in _run_main. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/absl_py/absl/app.py"", line 312 in run. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples.py"", line 234 in <module>. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /output/intermediate_results_dir/make_examples.tfrecord@1.gz --channels insert_size --gvcf /output/intermediate_results_dir/gvcf.tfrecord@1.gz --regions chr20:10,000,000-10,010,000 --task 0. real 0m5.584s. user 0m13.426s. sys 0m0.563s. ```. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. I am running this on an AWS graviton4 machine (aarch64 architecture). The Dockerfile does not work for me directly. I had to run `build-prereq.sh` and resolve all the errors manually within a docker container. But I did run build_and_test.sh to make sure all tests passed and the binaries were also built successfully.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:5618,safety,test,tests,5618,"realigner/realigner.py"", line 806 in realign_reads. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 1881 in realign_reads. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 1908 in <listcomp>. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 1907 in realign_reads_per_sample_multisample. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 1709 in process. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 2838 in make_examples_runner. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples.py"", line 224 in main. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/absl_py/absl/app.py"", line 258 in _run_main. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/absl_py/absl/app.py"", line 312 in run. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples.py"", line 234 in <module>. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /output/intermediate_results_dir/make_examples.tfrecord@1.gz --channels insert_size --gvcf /output/intermediate_results_dir/gvcf.tfrecord@1.gz --regions chr20:10,000,000-10,010,000 --task 0. real 0m5.584s. user 0m13.426s. sys 0m0.563s. ```. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. I am running this on an AWS graviton4 machine (aarch64 architecture). The Dockerfile does not work for me directly. I had to run `build-prereq.sh` and resolve all the errors manually within a docker container. But I did run build_and_test.sh to make sure all tests passed and the binaries were also built successfully.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:170,testability,test,test,170,"Fatal Python error: Segmentation fault; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. I tried to test run deepvariant following the quick-start guide at https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-quick-start.md and I got `Fatal Python error: Segmentation fault`. **Setup**. - Operating system: Ubuntu 20.04.6 LTS. - DeepVariant version: r1.6.1. - Installation method (Docker, built from source, etc.): Docker. - Type of data: exact same data in the quick start guide. **Steps to reproduce:**. - Command:. ``` . sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. deepvbuild:latest \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=1. ```. - Error trace:. ```. I0906 02:45:46.585311 275767425675280 run_deepvariant.py:519] Re-using the directory for intermediate results in /output/intermediate_results_dir. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I0906 02:45:51.909050 257960059396112 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0906 02:45:51.913105 257960059396112 make_examples_core.py:301] Preparing inputs. I0906 02:45:5",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:799,testability,unit,unittest,799,"Fatal Python error: Segmentation fault; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. I tried to test run deepvariant following the quick-start guide at https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-quick-start.md and I got `Fatal Python error: Segmentation fault`. **Setup**. - Operating system: Ubuntu 20.04.6 LTS. - DeepVariant version: r1.6.1. - Installation method (Docker, built from source, etc.): Docker. - Type of data: exact same data in the quick start guide. **Steps to reproduce:**. - Command:. ``` . sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. deepvbuild:latest \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=1. ```. - Error trace:. ```. I0906 02:45:46.585311 275767425675280 run_deepvariant.py:519] Re-using the directory for intermediate results in /output/intermediate_results_dir. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I0906 02:45:51.909050 257960059396112 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0906 02:45:51.913105 257960059396112 make_examples_core.py:301] Preparing inputs. I0906 02:45:5",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:1080,testability,trace,trace,1080,"com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. I tried to test run deepvariant following the quick-start guide at https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-quick-start.md and I got `Fatal Python error: Segmentation fault`. **Setup**. - Operating system: Ubuntu 20.04.6 LTS. - DeepVariant version: r1.6.1. - Installation method (Docker, built from source, etc.): Docker. - Type of data: exact same data in the quick start guide. **Steps to reproduce:**. - Command:. ``` . sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. deepvbuild:latest \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=1. ```. - Error trace:. ```. I0906 02:45:46.585311 275767425675280 run_deepvariant.py:519] Re-using the directory for intermediate results in /output/intermediate_results_dir. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I0906 02:45:51.909050 257960059396112 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0906 02:45:51.913105 257960059396112 make_examples_core.py:301] Preparing inputs. I0906 02:45:51.913431 257960059396112 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:1499,testability,unit,unittest,1499,"er. - Type of data: exact same data in the quick start guide. **Steps to reproduce:**. - Command:. ``` . sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. deepvbuild:latest \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=1. ```. - Error trace:. ```. I0906 02:45:46.585311 275767425675280 run_deepvariant.py:519] Re-using the directory for intermediate results in /output/intermediate_results_dir. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I0906 02:45:51.909050 257960059396112 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0906 02:45:51.913105 257960059396112 make_examples_core.py:301] Preparing inputs. I0906 02:45:51.913431 257960059396112 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0906 02:45:51.913708 257960059396112 make_examples_core.py:301] Common contigs are ['chr20']. I0906 02:45:51.914803 257960059396112 make_examples_core.py:301] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. I0906 02:45:51.916343 257960059396112 genomics_reader.py:222",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:4801,testability,unit,unittest,4801,"realigner/realigner.py"", line 806 in realign_reads. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 1881 in realign_reads. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 1908 in <listcomp>. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 1907 in realign_reads_per_sample_multisample. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 1709 in process. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 2838 in make_examples_runner. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples.py"", line 224 in main. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/absl_py/absl/app.py"", line 258 in _run_main. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/absl_py/absl/app.py"", line 312 in run. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples.py"", line 234 in <module>. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /output/intermediate_results_dir/make_examples.tfrecord@1.gz --channels insert_size --gvcf /output/intermediate_results_dir/gvcf.tfrecord@1.gz --regions chr20:10,000,000-10,010,000 --task 0. real 0m5.584s. user 0m13.426s. sys 0m0.563s. ```. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. I am running this on an AWS graviton4 machine (aarch64 architecture). The Dockerfile does not work for me directly. I had to run `build-prereq.sh` and resolve all the errors manually within a docker container. But I did run build_and_test.sh to make sure all tests passed and the binaries were also built successfully.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:5137,testability,test,test,5137,"realigner/realigner.py"", line 806 in realign_reads. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 1881 in realign_reads. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 1908 in <listcomp>. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 1907 in realign_reads_per_sample_multisample. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 1709 in process. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 2838 in make_examples_runner. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples.py"", line 224 in main. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/absl_py/absl/app.py"", line 258 in _run_main. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/absl_py/absl/app.py"", line 312 in run. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples.py"", line 234 in <module>. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /output/intermediate_results_dir/make_examples.tfrecord@1.gz --channels insert_size --gvcf /output/intermediate_results_dir/gvcf.tfrecord@1.gz --regions chr20:10,000,000-10,010,000 --task 0. real 0m5.584s. user 0m13.426s. sys 0m0.563s. ```. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. I am running this on an AWS graviton4 machine (aarch64 architecture). The Dockerfile does not work for me directly. I had to run `build-prereq.sh` and resolve all the errors manually within a docker container. But I did run build_and_test.sh to make sure all tests passed and the binaries were also built successfully.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:5173,testability,test,test,5173,"realigner/realigner.py"", line 806 in realign_reads. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 1881 in realign_reads. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 1908 in <listcomp>. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 1907 in realign_reads_per_sample_multisample. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 1709 in process. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 2838 in make_examples_runner. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples.py"", line 224 in main. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/absl_py/absl/app.py"", line 258 in _run_main. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/absl_py/absl/app.py"", line 312 in run. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples.py"", line 234 in <module>. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /output/intermediate_results_dir/make_examples.tfrecord@1.gz --channels insert_size --gvcf /output/intermediate_results_dir/gvcf.tfrecord@1.gz --regions chr20:10,000,000-10,010,000 --task 0. real 0m5.584s. user 0m13.426s. sys 0m0.563s. ```. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. I am running this on an AWS graviton4 machine (aarch64 architecture). The Dockerfile does not work for me directly. I had to run `build-prereq.sh` and resolve all the errors manually within a docker container. But I did run build_and_test.sh to make sure all tests passed and the binaries were also built successfully.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:5347,testability,context,context,5347,"realigner/realigner.py"", line 806 in realign_reads. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 1881 in realign_reads. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 1908 in <listcomp>. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 1907 in realign_reads_per_sample_multisample. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 1709 in process. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 2838 in make_examples_runner. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples.py"", line 224 in main. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/absl_py/absl/app.py"", line 258 in _run_main. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/absl_py/absl/app.py"", line 312 in run. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples.py"", line 234 in <module>. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /output/intermediate_results_dir/make_examples.tfrecord@1.gz --channels insert_size --gvcf /output/intermediate_results_dir/gvcf.tfrecord@1.gz --regions chr20:10,000,000-10,010,000 --task 0. real 0m5.584s. user 0m13.426s. sys 0m0.563s. ```. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. I am running this on an AWS graviton4 machine (aarch64 architecture). The Dockerfile does not work for me directly. I had to run `build-prereq.sh` and resolve all the errors manually within a docker container. But I did run build_and_test.sh to make sure all tests passed and the binaries were also built successfully.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:5618,testability,test,tests,5618,"realigner/realigner.py"", line 806 in realign_reads. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 1881 in realign_reads. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 1908 in <listcomp>. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 1907 in realign_reads_per_sample_multisample. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 1709 in process. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 2838 in make_examples_runner. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples.py"", line 224 in main. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/absl_py/absl/app.py"", line 258 in _run_main. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/absl_py/absl/app.py"", line 312 in run. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples.py"", line 234 in <module>. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /output/intermediate_results_dir/make_examples.tfrecord@1.gz --channels insert_size --gvcf /output/intermediate_results_dir/gvcf.tfrecord@1.gz --regions chr20:10,000,000-10,010,000 --task 0. real 0m5.584s. user 0m13.426s. sys 0m0.563s. ```. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. I am running this on an AWS graviton4 machine (aarch64 architecture). The Dockerfile does not work for me directly. I had to run `build-prereq.sh` and resolve all the errors manually within a docker container. But I did run build_and_test.sh to make sure all tests passed and the binaries were also built successfully.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:13,usability,error,error,13,"Fatal Python error: Segmentation fault; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. I tried to test run deepvariant following the quick-start guide at https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-quick-start.md and I got `Fatal Python error: Segmentation fault`. **Setup**. - Operating system: Ubuntu 20.04.6 LTS. - DeepVariant version: r1.6.1. - Installation method (Docker, built from source, etc.): Docker. - Type of data: exact same data in the quick start guide. **Steps to reproduce:**. - Command:. ``` . sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. deepvbuild:latest \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=1. ```. - Error trace:. ```. I0906 02:45:46.585311 275767425675280 run_deepvariant.py:519] Re-using the directory for intermediate results in /output/intermediate_results_dir. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I0906 02:45:51.909050 257960059396112 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0906 02:45:51.913105 257960059396112 make_examples_core.py:301] Preparing inputs. I0906 02:45:5",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:217,usability,guid,guide,217,"Fatal Python error: Segmentation fault; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. I tried to test run deepvariant following the quick-start guide at https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-quick-start.md and I got `Fatal Python error: Segmentation fault`. **Setup**. - Operating system: Ubuntu 20.04.6 LTS. - DeepVariant version: r1.6.1. - Installation method (Docker, built from source, etc.): Docker. - Type of data: exact same data in the quick start guide. **Steps to reproduce:**. - Command:. ``` . sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. deepvbuild:latest \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=1. ```. - Error trace:. ```. I0906 02:45:46.585311 275767425675280 run_deepvariant.py:519] Re-using the directory for intermediate results in /output/intermediate_results_dir. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I0906 02:45:51.909050 257960059396112 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0906 02:45:51.913105 257960059396112 make_examples_core.py:301] Preparing inputs. I0906 02:45:5",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:332,usability,error,error,332,"Fatal Python error: Segmentation fault; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. I tried to test run deepvariant following the quick-start guide at https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-quick-start.md and I got `Fatal Python error: Segmentation fault`. **Setup**. - Operating system: Ubuntu 20.04.6 LTS. - DeepVariant version: r1.6.1. - Installation method (Docker, built from source, etc.): Docker. - Type of data: exact same data in the quick start guide. **Steps to reproduce:**. - Command:. ``` . sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. deepvbuild:latest \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=1. ```. - Error trace:. ```. I0906 02:45:46.585311 275767425675280 run_deepvariant.py:519] Re-using the directory for intermediate results in /output/intermediate_results_dir. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I0906 02:45:51.909050 257960059396112 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0906 02:45:51.913105 257960059396112 make_examples_core.py:301] Preparing inputs. I0906 02:45:5",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:558,usability,guid,guide,558,"Fatal Python error: Segmentation fault; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. I tried to test run deepvariant following the quick-start guide at https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-quick-start.md and I got `Fatal Python error: Segmentation fault`. **Setup**. - Operating system: Ubuntu 20.04.6 LTS. - DeepVariant version: r1.6.1. - Installation method (Docker, built from source, etc.): Docker. - Type of data: exact same data in the quick start guide. **Steps to reproduce:**. - Command:. ``` . sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. deepvbuild:latest \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=1. ```. - Error trace:. ```. I0906 02:45:46.585311 275767425675280 run_deepvariant.py:519] Re-using the directory for intermediate results in /output/intermediate_results_dir. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I0906 02:45:51.909050 257960059396112 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0906 02:45:51.913105 257960059396112 make_examples_core.py:301] Preparing inputs. I0906 02:45:5",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:592,usability,Command,Command,592,"Fatal Python error: Segmentation fault; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. I tried to test run deepvariant following the quick-start guide at https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-quick-start.md and I got `Fatal Python error: Segmentation fault`. **Setup**. - Operating system: Ubuntu 20.04.6 LTS. - DeepVariant version: r1.6.1. - Installation method (Docker, built from source, etc.): Docker. - Type of data: exact same data in the quick start guide. **Steps to reproduce:**. - Command:. ``` . sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. deepvbuild:latest \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=1. ```. - Error trace:. ```. I0906 02:45:46.585311 275767425675280 run_deepvariant.py:519] Re-using the directory for intermediate results in /output/intermediate_results_dir. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I0906 02:45:51.909050 257960059396112 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0906 02:45:51.913105 257960059396112 make_examples_core.py:301] Preparing inputs. I0906 02:45:5",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:647,usability,input,input,647,"Fatal Python error: Segmentation fault; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. I tried to test run deepvariant following the quick-start guide at https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-quick-start.md and I got `Fatal Python error: Segmentation fault`. **Setup**. - Operating system: Ubuntu 20.04.6 LTS. - DeepVariant version: r1.6.1. - Installation method (Docker, built from source, etc.): Docker. - Type of data: exact same data in the quick start guide. **Steps to reproduce:**. - Command:. ``` . sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. deepvbuild:latest \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=1. ```. - Error trace:. ```. I0906 02:45:46.585311 275767425675280 run_deepvariant.py:519] Re-using the directory for intermediate results in /output/intermediate_results_dir. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I0906 02:45:51.909050 257960059396112 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0906 02:45:51.913105 257960059396112 make_examples_core.py:301] Preparing inputs. I0906 02:45:5",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:777,usability,input,input,777,"Fatal Python error: Segmentation fault; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. I tried to test run deepvariant following the quick-start guide at https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-quick-start.md and I got `Fatal Python error: Segmentation fault`. **Setup**. - Operating system: Ubuntu 20.04.6 LTS. - DeepVariant version: r1.6.1. - Installation method (Docker, built from source, etc.): Docker. - Type of data: exact same data in the quick start guide. **Steps to reproduce:**. - Command:. ``` . sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. deepvbuild:latest \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=1. ```. - Error trace:. ```. I0906 02:45:46.585311 275767425675280 run_deepvariant.py:519] Re-using the directory for intermediate results in /output/intermediate_results_dir. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I0906 02:45:51.909050 257960059396112 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0906 02:45:51.913105 257960059396112 make_examples_core.py:301] Preparing inputs. I0906 02:45:5",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:826,usability,input,input,826,"Fatal Python error: Segmentation fault; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. I tried to test run deepvariant following the quick-start guide at https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-quick-start.md and I got `Fatal Python error: Segmentation fault`. **Setup**. - Operating system: Ubuntu 20.04.6 LTS. - DeepVariant version: r1.6.1. - Installation method (Docker, built from source, etc.): Docker. - Type of data: exact same data in the quick start guide. **Steps to reproduce:**. - Command:. ``` . sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. deepvbuild:latest \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=1. ```. - Error trace:. ```. I0906 02:45:46.585311 275767425675280 run_deepvariant.py:519] Re-using the directory for intermediate results in /output/intermediate_results_dir. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I0906 02:45:51.909050 257960059396112 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0906 02:45:51.913105 257960059396112 make_examples_core.py:301] Preparing inputs. I0906 02:45:5",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:1074,usability,Error,Error,1074,"ithub.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. I tried to test run deepvariant following the quick-start guide at https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-quick-start.md and I got `Fatal Python error: Segmentation fault`. **Setup**. - Operating system: Ubuntu 20.04.6 LTS. - DeepVariant version: r1.6.1. - Installation method (Docker, built from source, etc.): Docker. - Type of data: exact same data in the quick start guide. **Steps to reproduce:**. - Command:. ``` . sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. deepvbuild:latest \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=1. ```. - Error trace:. ```. I0906 02:45:46.585311 275767425675280 run_deepvariant.py:519] Re-using the directory for intermediate results in /output/intermediate_results_dir. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I0906 02:45:51.909050 257960059396112 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0906 02:45:51.913105 257960059396112 make_examples_core.py:301] Preparing inputs. I0906 02:45:51.913431 257960059396112 genomics_reader.py:222] Reading /input/NA12878_S1.ch",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:1354,usability,command,command,1354,". **Setup**. - Operating system: Ubuntu 20.04.6 LTS. - DeepVariant version: r1.6.1. - Installation method (Docker, built from source, etc.): Docker. - Type of data: exact same data in the quick start guide. **Steps to reproduce:**. - Command:. ``` . sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. deepvbuild:latest \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=1. ```. - Error trace:. ```. I0906 02:45:46.585311 275767425675280 run_deepvariant.py:519] Re-using the directory for intermediate results in /output/intermediate_results_dir. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I0906 02:45:51.909050 257960059396112 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0906 02:45:51.913105 257960059396112 make_examples_core.py:301] Preparing inputs. I0906 02:45:51.913431 257960059396112 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0906 02:45:51.913708 257960059396112 make_examples_core.py:301] Common contigs are ['chr20']. I0906 02:45:51.914803 257960059396112 make_examples_core.py:301] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRA",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:1477,usability,input,input,1477,"rom source, etc.): Docker. - Type of data: exact same data in the quick start guide. **Steps to reproduce:**. - Command:. ``` . sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. deepvbuild:latest \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=1. ```. - Error trace:. ```. I0906 02:45:46.585311 275767425675280 run_deepvariant.py:519] Re-using the directory for intermediate results in /output/intermediate_results_dir. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I0906 02:45:51.909050 257960059396112 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0906 02:45:51.913105 257960059396112 make_examples_core.py:301] Preparing inputs. I0906 02:45:51.913431 257960059396112 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0906 02:45:51.913708 257960059396112 make_examples_core.py:301] Common contigs are ['chr20']. I0906 02:45:51.914803 257960059396112 make_examples_core.py:301] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. I0906 02:45:51.916343 257960059396112",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:1525,usability,input,input,1525," same data in the quick start guide. **Steps to reproduce:**. - Command:. ``` . sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. deepvbuild:latest \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=1. ```. - Error trace:. ```. I0906 02:45:46.585311 275767425675280 run_deepvariant.py:519] Re-using the directory for intermediate results in /output/intermediate_results_dir. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I0906 02:45:51.909050 257960059396112 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0906 02:45:51.913105 257960059396112 make_examples_core.py:301] Preparing inputs. I0906 02:45:51.913431 257960059396112 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0906 02:45:51.913708 257960059396112 make_examples_core.py:301] Common contigs are ['chr20']. I0906 02:45:51.914803 257960059396112 make_examples_core.py:301] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. I0906 02:45:51.916343 257960059396112 genomics_reader.py:222] Reading /input/NA12878_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:1845,usability,input,input,1845,".10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=1. ```. - Error trace:. ```. I0906 02:45:46.585311 275767425675280 run_deepvariant.py:519] Re-using the directory for intermediate results in /output/intermediate_results_dir. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I0906 02:45:51.909050 257960059396112 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0906 02:45:51.913105 257960059396112 make_examples_core.py:301] Preparing inputs. I0906 02:45:51.913431 257960059396112 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0906 02:45:51.913708 257960059396112 make_examples_core.py:301] Common contigs are ['chr20']. I0906 02:45:51.914803 257960059396112 make_examples_core.py:301] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. I0906 02:45:51.916343 257960059396112 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0906 02:45:51.961755 257960059396112 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0906 02:45:51.961891 257960059396112 make_examples_core.py:301] Writing gvcf records to /output/intermediate_results_dir/gvcf.tfrecord-00000-of-",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:1979,usability,input,inputs,1979,"gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=1. ```. - Error trace:. ```. I0906 02:45:46.585311 275767425675280 run_deepvariant.py:519] Re-using the directory for intermediate results in /output/intermediate_results_dir. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I0906 02:45:51.909050 257960059396112 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0906 02:45:51.913105 257960059396112 make_examples_core.py:301] Preparing inputs. I0906 02:45:51.913431 257960059396112 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0906 02:45:51.913708 257960059396112 make_examples_core.py:301] Common contigs are ['chr20']. I0906 02:45:51.914803 257960059396112 make_examples_core.py:301] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. I0906 02:45:51.916343 257960059396112 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0906 02:45:51.961755 257960059396112 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0906 02:45:51.961891 257960059396112 make_examples_core.py:301] Writing gvcf records to /output/intermediate_results_dir/gvcf.tfrecord-00000-of-00001.gz. I0906 02:45:51.962091 257960059396112 make_examples_core.py:301] Writing examples to /output/intermediate_results_dir/make_e",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:2058,usability,input,input,2058,"ds=1. ```. - Error trace:. ```. I0906 02:45:46.585311 275767425675280 run_deepvariant.py:519] Re-using the directory for intermediate results in /output/intermediate_results_dir. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I0906 02:45:51.909050 257960059396112 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0906 02:45:51.913105 257960059396112 make_examples_core.py:301] Preparing inputs. I0906 02:45:51.913431 257960059396112 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0906 02:45:51.913708 257960059396112 make_examples_core.py:301] Common contigs are ['chr20']. I0906 02:45:51.914803 257960059396112 make_examples_core.py:301] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. I0906 02:45:51.916343 257960059396112 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0906 02:45:51.961755 257960059396112 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0906 02:45:51.961891 257960059396112 make_examples_core.py:301] Writing gvcf records to /output/intermediate_results_dir/gvcf.tfrecord-00000-of-00001.gz. I0906 02:45:51.962091 257960059396112 make_examples_core.py:301] Writing examples to /output/intermediate_results_dir/make_examples.tfrecord-00000-of-00001.gz. I0906 02:45:51.962123 257960059396112 make_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:2360,usability,input,input,2360,"****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I0906 02:45:51.909050 257960059396112 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0906 02:45:51.913105 257960059396112 make_examples_core.py:301] Preparing inputs. I0906 02:45:51.913431 257960059396112 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0906 02:45:51.913708 257960059396112 make_examples_core.py:301] Common contigs are ['chr20']. I0906 02:45:51.914803 257960059396112 make_examples_core.py:301] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. I0906 02:45:51.916343 257960059396112 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0906 02:45:51.961755 257960059396112 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0906 02:45:51.961891 257960059396112 make_examples_core.py:301] Writing gvcf records to /output/intermediate_results_dir/gvcf.tfrecord-00000-of-00001.gz. I0906 02:45:51.962091 257960059396112 make_examples_core.py:301] Writing examples to /output/intermediate_results_dir/make_examples.tfrecord-00000-of-00001.gz. I0906 02:45:51.962123 257960059396112 make_examples_core.py:301] Overhead for preparing inputs: 0 seconds. Fatal Python error: Segmentation fault. Current thread 0x0000ea9d01b4e010 (most recent call first):. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/realigner/window_selector.py"", line 116 in _variant_reads_threshold_selecto",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:2514,usability,input,input,2514,"reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --channels ""insert_size"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I0906 02:45:51.909050 257960059396112 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0906 02:45:51.913105 257960059396112 make_examples_core.py:301] Preparing inputs. I0906 02:45:51.913431 257960059396112 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0906 02:45:51.913708 257960059396112 make_examples_core.py:301] Common contigs are ['chr20']. I0906 02:45:51.914803 257960059396112 make_examples_core.py:301] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. I0906 02:45:51.916343 257960059396112 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0906 02:45:51.961755 257960059396112 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0906 02:45:51.961891 257960059396112 make_examples_core.py:301] Writing gvcf records to /output/intermediate_results_dir/gvcf.tfrecord-00000-of-00001.gz. I0906 02:45:51.962091 257960059396112 make_examples_core.py:301] Writing examples to /output/intermediate_results_dir/make_examples.tfrecord-00000-of-00001.gz. I0906 02:45:51.962123 257960059396112 make_examples_core.py:301] Overhead for preparing inputs: 0 seconds. Fatal Python error: Segmentation fault. Current thread 0x0000ea9d01b4e010 (most recent call first):. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/realigner/window_selector.py"", line 116 in _variant_reads_threshold_selector. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/realigner/window_selector.py"", line 76 in _candidates_from_reads. File ""/tmp/Bazel.runfil",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:2644,usability,input,input,2644," ""insert_size"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I0906 02:45:51.909050 257960059396112 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0906 02:45:51.913105 257960059396112 make_examples_core.py:301] Preparing inputs. I0906 02:45:51.913431 257960059396112 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0906 02:45:51.913708 257960059396112 make_examples_core.py:301] Common contigs are ['chr20']. I0906 02:45:51.914803 257960059396112 make_examples_core.py:301] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. I0906 02:45:51.916343 257960059396112 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0906 02:45:51.961755 257960059396112 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0906 02:45:51.961891 257960059396112 make_examples_core.py:301] Writing gvcf records to /output/intermediate_results_dir/gvcf.tfrecord-00000-of-00001.gz. I0906 02:45:51.962091 257960059396112 make_examples_core.py:301] Writing examples to /output/intermediate_results_dir/make_examples.tfrecord-00000-of-00001.gz. I0906 02:45:51.962123 257960059396112 make_examples_core.py:301] Overhead for preparing inputs: 0 seconds. Fatal Python error: Segmentation fault. Current thread 0x0000ea9d01b4e010 (most recent call first):. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/realigner/window_selector.py"", line 116 in _variant_reads_threshold_selector. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/realigner/window_selector.py"", line 76 in _candidates_from_reads. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_v_91gi",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:3106,usability,input,inputs,3106,"Reader. I0906 02:45:51.913708 257960059396112 make_examples_core.py:301] Common contigs are ['chr20']. I0906 02:45:51.914803 257960059396112 make_examples_core.py:301] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. I0906 02:45:51.916343 257960059396112 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0906 02:45:51.961755 257960059396112 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0906 02:45:51.961891 257960059396112 make_examples_core.py:301] Writing gvcf records to /output/intermediate_results_dir/gvcf.tfrecord-00000-of-00001.gz. I0906 02:45:51.962091 257960059396112 make_examples_core.py:301] Writing examples to /output/intermediate_results_dir/make_examples.tfrecord-00000-of-00001.gz. I0906 02:45:51.962123 257960059396112 make_examples_core.py:301] Overhead for preparing inputs: 0 seconds. Fatal Python error: Segmentation fault. Current thread 0x0000ea9d01b4e010 (most recent call first):. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/realigner/window_selector.py"", line 116 in _variant_reads_threshold_selector. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/realigner/window_selector.py"", line 76 in _candidates_from_reads. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/realigner/realigner.py"", line 806 in realign_reads. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 1881 in realign_reads. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 1908 in <listcomp>. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 1907 in realign_reads_per_sample_multisample. File ""/tmp/Bazel.r",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:3138,usability,error,error,3138,"7960059396112 make_examples_core.py:301] Common contigs are ['chr20']. I0906 02:45:51.914803 257960059396112 make_examples_core.py:301] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. I0906 02:45:51.916343 257960059396112 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0906 02:45:51.961755 257960059396112 genomics_reader.py:222] Reading /input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I0906 02:45:51.961891 257960059396112 make_examples_core.py:301] Writing gvcf records to /output/intermediate_results_dir/gvcf.tfrecord-00000-of-00001.gz. I0906 02:45:51.962091 257960059396112 make_examples_core.py:301] Writing examples to /output/intermediate_results_dir/make_examples.tfrecord-00000-of-00001.gz. I0906 02:45:51.962123 257960059396112 make_examples_core.py:301] Overhead for preparing inputs: 0 seconds. Fatal Python error: Segmentation fault. Current thread 0x0000ea9d01b4e010 (most recent call first):. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/realigner/window_selector.py"", line 116 in _variant_reads_threshold_selector. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/realigner/window_selector.py"", line 76 in _candidates_from_reads. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/realigner/window_selector.py"", line 233 in select_windows. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/realigner/realigner.py"", line 806 in realign_reads. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 1881 in realign_reads. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 1908 in <listcomp>. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 1907 in realign_reads_per_sample_multisample. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:4779,usability,input,input,4779,"realigner/realigner.py"", line 806 in realign_reads. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 1881 in realign_reads. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 1908 in <listcomp>. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 1907 in realign_reads_per_sample_multisample. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 1709 in process. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 2838 in make_examples_runner. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples.py"", line 224 in main. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/absl_py/absl/app.py"", line 258 in _run_main. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/absl_py/absl/app.py"", line 312 in run. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples.py"", line 234 in <module>. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /output/intermediate_results_dir/make_examples.tfrecord@1.gz --channels insert_size --gvcf /output/intermediate_results_dir/gvcf.tfrecord@1.gz --regions chr20:10,000,000-10,010,000 --task 0. real 0m5.584s. user 0m13.426s. sys 0m0.563s. ```. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. I am running this on an AWS graviton4 machine (aarch64 architecture). The Dockerfile does not work for me directly. I had to run `build-prereq.sh` and resolve all the errors manually within a docker container. But I did run build_and_test.sh to make sure all tests passed and the binaries were also built successfully.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:4825,usability,input,input,4825,"realigner/realigner.py"", line 806 in realign_reads. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 1881 in realign_reads. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 1908 in <listcomp>. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 1907 in realign_reads_per_sample_multisample. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 1709 in process. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 2838 in make_examples_runner. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples.py"", line 224 in main. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/absl_py/absl/app.py"", line 258 in _run_main. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/absl_py/absl/app.py"", line 312 in run. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples.py"", line 234 in <module>. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /output/intermediate_results_dir/make_examples.tfrecord@1.gz --channels insert_size --gvcf /output/intermediate_results_dir/gvcf.tfrecord@1.gz --regions chr20:10,000,000-10,010,000 --task 0. real 0m5.584s. user 0m13.426s. sys 0m0.563s. ```. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. I am running this on an AWS graviton4 machine (aarch64 architecture). The Dockerfile does not work for me directly. I had to run `build-prereq.sh` and resolve all the errors manually within a docker container. But I did run build_and_test.sh to make sure all tests passed and the binaries were also built successfully.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:5079,usability,user,user,5079,"realigner/realigner.py"", line 806 in realign_reads. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 1881 in realign_reads. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 1908 in <listcomp>. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 1907 in realign_reads_per_sample_multisample. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 1709 in process. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 2838 in make_examples_runner. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples.py"", line 224 in main. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/absl_py/absl/app.py"", line 258 in _run_main. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/absl_py/absl/app.py"", line 312 in run. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples.py"", line 234 in <module>. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /output/intermediate_results_dir/make_examples.tfrecord@1.gz --channels insert_size --gvcf /output/intermediate_results_dir/gvcf.tfrecord@1.gz --regions chr20:10,000,000-10,010,000 --task 0. real 0m5.584s. user 0m13.426s. sys 0m0.563s. ```. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. I am running this on an AWS graviton4 machine (aarch64 architecture). The Dockerfile does not work for me directly. I had to run `build-prereq.sh` and resolve all the errors manually within a docker container. But I did run build_and_test.sh to make sure all tests passed and the binaries were also built successfully.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:5526,usability,error,errors,5526,"realigner/realigner.py"", line 806 in realign_reads. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 1881 in realign_reads. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 1908 in <listcomp>. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 1907 in realign_reads_per_sample_multisample. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 1709 in process. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples_core.py"", line 2838 in make_examples_runner. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples.py"", line 224 in main. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/absl_py/absl/app.py"", line 258 in _run_main. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/absl_py/absl/app.py"", line 312 in run. File ""/tmp/Bazel.runfiles_v_91gifn/runfiles/_main/deepvariant/make_examples.py"", line 234 in <module>. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /output/intermediate_results_dir/make_examples.tfrecord@1.gz --channels insert_size --gvcf /output/intermediate_results_dir/gvcf.tfrecord@1.gz --regions chr20:10,000,000-10,010,000 --task 0. real 0m5.584s. user 0m13.426s. sys 0m0.563s. ```. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. I am running this on an AWS graviton4 machine (aarch64 architecture). The Dockerfile does not work for me directly. I had to run `build-prereq.sh` and resolve all the errors manually within a docker container. But I did run build_and_test.sh to make sure all tests passed and the binaries were also built successfully.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/880:556,interoperability,FORMAT,FORMAT,556,"VAF != AD[1]/(AD[0]+AD[1]); Hello, . Thank you for developing the tool. . I expected the VAF field to be roughly equal to the fraction of alternative alleles in reads, but that wasn't the case. Would you know why? . In the example below, the first variant has a VAF of 25%, but the read depth of REF allele is 6 and the alternative allele is also 6. I had expected the VAF to be about 50%. The second variant has a VAF of 52.1739%, but the read depth of REF alelle is 6 and the alternative allele is 12. I had expected the VAF to be about 66.67%. . ```. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. chr13	32323151	.	A	AT	45.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:21:24:6,6:0.25:45,24,44. chr13	32349216	.	CA	C	8.3	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:8:23:6,12:0.521739:7,0,22. ```. Could you help me interpret the discrepancy in the `VAF` field and the `AD` field, please? . Many thanks,. Min",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/880
https://github.com/google/deepvariant/issues/880:637,interoperability,FORMAT,FORMAT,637,"VAF != AD[1]/(AD[0]+AD[1]); Hello, . Thank you for developing the tool. . I expected the VAF field to be roughly equal to the fraction of alternative alleles in reads, but that wasn't the case. Would you know why? . In the example below, the first variant has a VAF of 25%, but the read depth of REF allele is 6 and the alternative allele is also 6. I had expected the VAF to be about 50%. The second variant has a VAF of 52.1739%, but the read depth of REF alelle is 6 and the alternative allele is 12. I had expected the VAF to be about 66.67%. . ```. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. chr13	32323151	.	A	AT	45.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:21:24:6,6:0.25:45,24,44. chr13	32349216	.	CA	C	8.3	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:8:23:6,12:0.521739:7,0,22. ```. Could you help me interpret the discrepancy in the `VAF` field and the `AD` field, please? . Many thanks,. Min",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/880
https://github.com/google/deepvariant/issues/880:66,usability,tool,tool,66,"VAF != AD[1]/(AD[0]+AD[1]); Hello, . Thank you for developing the tool. . I expected the VAF field to be roughly equal to the fraction of alternative alleles in reads, but that wasn't the case. Would you know why? . In the example below, the first variant has a VAF of 25%, but the read depth of REF allele is 6 and the alternative allele is also 6. I had expected the VAF to be about 50%. The second variant has a VAF of 52.1739%, but the read depth of REF alelle is 6 and the alternative allele is 12. I had expected the VAF to be about 66.67%. . ```. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. chr13	32323151	.	A	AT	45.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:21:24:6,6:0.25:45,24,44. chr13	32349216	.	CA	C	8.3	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:8:23:6,12:0.521739:7,0,22. ```. Could you help me interpret the discrepancy in the `VAF` field and the `AD` field, please? . Many thanks,. Min",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/880
https://github.com/google/deepvariant/issues/880:894,usability,help,help,894,"VAF != AD[1]/(AD[0]+AD[1]); Hello, . Thank you for developing the tool. . I expected the VAF field to be roughly equal to the fraction of alternative alleles in reads, but that wasn't the case. Would you know why? . In the example below, the first variant has a VAF of 25%, but the read depth of REF allele is 6 and the alternative allele is also 6. I had expected the VAF to be about 50%. The second variant has a VAF of 52.1739%, but the read depth of REF alelle is 6 and the alternative allele is 12. I had expected the VAF to be about 66.67%. . ```. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. chr13	32323151	.	A	AT	45.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:21:24:6,6:0.25:45,24,44. chr13	32349216	.	CA	C	8.3	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:8:23:6,12:0.521739:7,0,22. ```. Could you help me interpret the discrepancy in the `VAF` field and the `AD` field, please? . Many thanks,. Min",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/880
https://github.com/google/deepvariant/issues/883:1511,availability,Error,Error,1511,"ample_id, file]. }. .set { read_pairs }. // Process steps. /// Germline variant calling. deepvar(read_pairs, params.reference, params.bed_file). }. process deepvar {. tag ""Germline Variant on ${sample_id}"". publishDir ""${params.outdir}/6.variantM"", mode: 'copy'. cpus 16. input:. tuple val(sample_id), path(read_files). val(params.reference). val(params.bed_file). . output:. tuple val(sample_id), path(""${sample_id}_raw.vcf.gz""), path(""${sample_id}_raw.gvcf.gz""), emit: raw_vcfs. script:. """""". sudo docker run \. -v ""${PWD}"":""${PWD}"" \. google/deepvariant:1.6.1 \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref ${PWD}/${params.reference} \. --reads ${PWD}/output/4.markDuplicate/${sample_id}_sorted_md.bam \. --regions ${PWD}/${params.bed_file} \. --output_vcf ${PWD}/${params.outdir}/${sample_id}_raw.vcf.gz \. --output_gvcf ${PWD}/${sample_id}_raw.gvcf.gz \. --num_shards ${task.cpus}. --intermediate_results_dir ${PWD}/tmp > deepvariant_log.txt 2>&1. """""". }. ############# Error ###################. N E X T F L O W ~ version 24.04.4. Launching `dip.nf` [deadly_pike] DSL2 - revision: e075b1fba0. executor > local (2). [a6/9c6b79] process > deepvar (Germline Variant on SRR26512959) [ 0%] 0 of 2. ERROR ~ Error executing process > 'deepvar (Germline Variant on SRR26512958)'. executor > local (2). [a6/9c6b79] process > deepvar (Germline Variant on SRR26512959) [100%] 1 of 1, failed: 1. ERROR ~ Error executing process > 'deepvar (Germline Variant on SRR26512958)'. Caused by:. Process `deepvar (Germline Variant on SRR26512958)` terminated with an error exit status (127). Command executed:. sudo docker run -v ""/home/ubuntu/dd/nextflow2"":""/home/ubuntu/dd/nextflow2"" google/deepvariant:1.6.1 /opt/deepvariant/bin/run_deepvariant --model_type WES --ref /home/ubuntu/dd/nextflow2/reference/Homo_sapiens_assembly38.fasta --reads /home/ubuntu/dd/nextflow2/output/4.markDuplicate/SRR26512958_sorted_md.bam --regions /home/ubuntu/dd/nextflow2/reference/hg38_exome.bed --output_vcf",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/883:1735,availability,ERROR,ERROR,1735,"ams.outdir}/6.variantM"", mode: 'copy'. cpus 16. input:. tuple val(sample_id), path(read_files). val(params.reference). val(params.bed_file). . output:. tuple val(sample_id), path(""${sample_id}_raw.vcf.gz""), path(""${sample_id}_raw.gvcf.gz""), emit: raw_vcfs. script:. """""". sudo docker run \. -v ""${PWD}"":""${PWD}"" \. google/deepvariant:1.6.1 \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref ${PWD}/${params.reference} \. --reads ${PWD}/output/4.markDuplicate/${sample_id}_sorted_md.bam \. --regions ${PWD}/${params.bed_file} \. --output_vcf ${PWD}/${params.outdir}/${sample_id}_raw.vcf.gz \. --output_gvcf ${PWD}/${sample_id}_raw.gvcf.gz \. --num_shards ${task.cpus}. --intermediate_results_dir ${PWD}/tmp > deepvariant_log.txt 2>&1. """""". }. ############# Error ###################. N E X T F L O W ~ version 24.04.4. Launching `dip.nf` [deadly_pike] DSL2 - revision: e075b1fba0. executor > local (2). [a6/9c6b79] process > deepvar (Germline Variant on SRR26512959) [ 0%] 0 of 2. ERROR ~ Error executing process > 'deepvar (Germline Variant on SRR26512958)'. executor > local (2). [a6/9c6b79] process > deepvar (Germline Variant on SRR26512959) [100%] 1 of 1, failed: 1. ERROR ~ Error executing process > 'deepvar (Germline Variant on SRR26512958)'. Caused by:. Process `deepvar (Germline Variant on SRR26512958)` terminated with an error exit status (127). Command executed:. sudo docker run -v ""/home/ubuntu/dd/nextflow2"":""/home/ubuntu/dd/nextflow2"" google/deepvariant:1.6.1 /opt/deepvariant/bin/run_deepvariant --model_type WES --ref /home/ubuntu/dd/nextflow2/reference/Homo_sapiens_assembly38.fasta --reads /home/ubuntu/dd/nextflow2/output/4.markDuplicate/SRR26512958_sorted_md.bam --regions /home/ubuntu/dd/nextflow2/reference/hg38_exome.bed --output_vcf /home/ubuntu/dd/nextflow2/output/5.snvS/SRR26512958_raw.vcf.gz --output_gvcf /home/ubuntu/dd/nextflow2/SRR26512958_raw.gvcf.gz --num_shards 16. --intermediate_results_dir /home/ubuntu/dd/nextflow2/tmp > deepvariant_log.txt ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/883:1743,availability,Error,Error,1743,"ir}/6.variantM"", mode: 'copy'. cpus 16. input:. tuple val(sample_id), path(read_files). val(params.reference). val(params.bed_file). . output:. tuple val(sample_id), path(""${sample_id}_raw.vcf.gz""), path(""${sample_id}_raw.gvcf.gz""), emit: raw_vcfs. script:. """""". sudo docker run \. -v ""${PWD}"":""${PWD}"" \. google/deepvariant:1.6.1 \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref ${PWD}/${params.reference} \. --reads ${PWD}/output/4.markDuplicate/${sample_id}_sorted_md.bam \. --regions ${PWD}/${params.bed_file} \. --output_vcf ${PWD}/${params.outdir}/${sample_id}_raw.vcf.gz \. --output_gvcf ${PWD}/${sample_id}_raw.gvcf.gz \. --num_shards ${task.cpus}. --intermediate_results_dir ${PWD}/tmp > deepvariant_log.txt 2>&1. """""". }. ############# Error ###################. N E X T F L O W ~ version 24.04.4. Launching `dip.nf` [deadly_pike] DSL2 - revision: e075b1fba0. executor > local (2). [a6/9c6b79] process > deepvar (Germline Variant on SRR26512959) [ 0%] 0 of 2. ERROR ~ Error executing process > 'deepvar (Germline Variant on SRR26512958)'. executor > local (2). [a6/9c6b79] process > deepvar (Germline Variant on SRR26512959) [100%] 1 of 1, failed: 1. ERROR ~ Error executing process > 'deepvar (Germline Variant on SRR26512958)'. Caused by:. Process `deepvar (Germline Variant on SRR26512958)` terminated with an error exit status (127). Command executed:. sudo docker run -v ""/home/ubuntu/dd/nextflow2"":""/home/ubuntu/dd/nextflow2"" google/deepvariant:1.6.1 /opt/deepvariant/bin/run_deepvariant --model_type WES --ref /home/ubuntu/dd/nextflow2/reference/Homo_sapiens_assembly38.fasta --reads /home/ubuntu/dd/nextflow2/output/4.markDuplicate/SRR26512958_sorted_md.bam --regions /home/ubuntu/dd/nextflow2/reference/hg38_exome.bed --output_vcf /home/ubuntu/dd/nextflow2/output/5.snvS/SRR26512958_raw.vcf.gz --output_gvcf /home/ubuntu/dd/nextflow2/SRR26512958_raw.gvcf.gz --num_shards 16. --intermediate_results_dir /home/ubuntu/dd/nextflow2/tmp > deepvariant_log.txt 2>&1. Co",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/883:1926,availability,ERROR,ERROR,1926,"}_raw.vcf.gz""), path(""${sample_id}_raw.gvcf.gz""), emit: raw_vcfs. script:. """""". sudo docker run \. -v ""${PWD}"":""${PWD}"" \. google/deepvariant:1.6.1 \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref ${PWD}/${params.reference} \. --reads ${PWD}/output/4.markDuplicate/${sample_id}_sorted_md.bam \. --regions ${PWD}/${params.bed_file} \. --output_vcf ${PWD}/${params.outdir}/${sample_id}_raw.vcf.gz \. --output_gvcf ${PWD}/${sample_id}_raw.gvcf.gz \. --num_shards ${task.cpus}. --intermediate_results_dir ${PWD}/tmp > deepvariant_log.txt 2>&1. """""". }. ############# Error ###################. N E X T F L O W ~ version 24.04.4. Launching `dip.nf` [deadly_pike] DSL2 - revision: e075b1fba0. executor > local (2). [a6/9c6b79] process > deepvar (Germline Variant on SRR26512959) [ 0%] 0 of 2. ERROR ~ Error executing process > 'deepvar (Germline Variant on SRR26512958)'. executor > local (2). [a6/9c6b79] process > deepvar (Germline Variant on SRR26512959) [100%] 1 of 1, failed: 1. ERROR ~ Error executing process > 'deepvar (Germline Variant on SRR26512958)'. Caused by:. Process `deepvar (Germline Variant on SRR26512958)` terminated with an error exit status (127). Command executed:. sudo docker run -v ""/home/ubuntu/dd/nextflow2"":""/home/ubuntu/dd/nextflow2"" google/deepvariant:1.6.1 /opt/deepvariant/bin/run_deepvariant --model_type WES --ref /home/ubuntu/dd/nextflow2/reference/Homo_sapiens_assembly38.fasta --reads /home/ubuntu/dd/nextflow2/output/4.markDuplicate/SRR26512958_sorted_md.bam --regions /home/ubuntu/dd/nextflow2/reference/hg38_exome.bed --output_vcf /home/ubuntu/dd/nextflow2/output/5.snvS/SRR26512958_raw.vcf.gz --output_gvcf /home/ubuntu/dd/nextflow2/SRR26512958_raw.gvcf.gz --num_shards 16. --intermediate_results_dir /home/ubuntu/dd/nextflow2/tmp > deepvariant_log.txt 2>&1. Command exit status:. 127. Command output:. (empty). Command error:. docker: Error response from daemon: open /var/lib/docker/overlay2/fe3663cd03e849890d83be14603f217249f3f43f9585b554df",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/883:1934,availability,Error,Error,1934,"f.gz""), path(""${sample_id}_raw.gvcf.gz""), emit: raw_vcfs. script:. """""". sudo docker run \. -v ""${PWD}"":""${PWD}"" \. google/deepvariant:1.6.1 \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref ${PWD}/${params.reference} \. --reads ${PWD}/output/4.markDuplicate/${sample_id}_sorted_md.bam \. --regions ${PWD}/${params.bed_file} \. --output_vcf ${PWD}/${params.outdir}/${sample_id}_raw.vcf.gz \. --output_gvcf ${PWD}/${sample_id}_raw.gvcf.gz \. --num_shards ${task.cpus}. --intermediate_results_dir ${PWD}/tmp > deepvariant_log.txt 2>&1. """""". }. ############# Error ###################. N E X T F L O W ~ version 24.04.4. Launching `dip.nf` [deadly_pike] DSL2 - revision: e075b1fba0. executor > local (2). [a6/9c6b79] process > deepvar (Germline Variant on SRR26512959) [ 0%] 0 of 2. ERROR ~ Error executing process > 'deepvar (Germline Variant on SRR26512958)'. executor > local (2). [a6/9c6b79] process > deepvar (Germline Variant on SRR26512959) [100%] 1 of 1, failed: 1. ERROR ~ Error executing process > 'deepvar (Germline Variant on SRR26512958)'. Caused by:. Process `deepvar (Germline Variant on SRR26512958)` terminated with an error exit status (127). Command executed:. sudo docker run -v ""/home/ubuntu/dd/nextflow2"":""/home/ubuntu/dd/nextflow2"" google/deepvariant:1.6.1 /opt/deepvariant/bin/run_deepvariant --model_type WES --ref /home/ubuntu/dd/nextflow2/reference/Homo_sapiens_assembly38.fasta --reads /home/ubuntu/dd/nextflow2/output/4.markDuplicate/SRR26512958_sorted_md.bam --regions /home/ubuntu/dd/nextflow2/reference/hg38_exome.bed --output_vcf /home/ubuntu/dd/nextflow2/output/5.snvS/SRR26512958_raw.vcf.gz --output_gvcf /home/ubuntu/dd/nextflow2/SRR26512958_raw.gvcf.gz --num_shards 16. --intermediate_results_dir /home/ubuntu/dd/nextflow2/tmp > deepvariant_log.txt 2>&1. Command exit status:. 127. Command output:. (empty). Command error:. docker: Error response from daemon: open /var/lib/docker/overlay2/fe3663cd03e849890d83be14603f217249f3f43f9585b554df599d0318",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/883:2088,availability,error,error,2088,"riant/bin/run_deepvariant \. --model_type WES \. --ref ${PWD}/${params.reference} \. --reads ${PWD}/output/4.markDuplicate/${sample_id}_sorted_md.bam \. --regions ${PWD}/${params.bed_file} \. --output_vcf ${PWD}/${params.outdir}/${sample_id}_raw.vcf.gz \. --output_gvcf ${PWD}/${sample_id}_raw.gvcf.gz \. --num_shards ${task.cpus}. --intermediate_results_dir ${PWD}/tmp > deepvariant_log.txt 2>&1. """""". }. ############# Error ###################. N E X T F L O W ~ version 24.04.4. Launching `dip.nf` [deadly_pike] DSL2 - revision: e075b1fba0. executor > local (2). [a6/9c6b79] process > deepvar (Germline Variant on SRR26512959) [ 0%] 0 of 2. ERROR ~ Error executing process > 'deepvar (Germline Variant on SRR26512958)'. executor > local (2). [a6/9c6b79] process > deepvar (Germline Variant on SRR26512959) [100%] 1 of 1, failed: 1. ERROR ~ Error executing process > 'deepvar (Germline Variant on SRR26512958)'. Caused by:. Process `deepvar (Germline Variant on SRR26512958)` terminated with an error exit status (127). Command executed:. sudo docker run -v ""/home/ubuntu/dd/nextflow2"":""/home/ubuntu/dd/nextflow2"" google/deepvariant:1.6.1 /opt/deepvariant/bin/run_deepvariant --model_type WES --ref /home/ubuntu/dd/nextflow2/reference/Homo_sapiens_assembly38.fasta --reads /home/ubuntu/dd/nextflow2/output/4.markDuplicate/SRR26512958_sorted_md.bam --regions /home/ubuntu/dd/nextflow2/reference/hg38_exome.bed --output_vcf /home/ubuntu/dd/nextflow2/output/5.snvS/SRR26512958_raw.vcf.gz --output_gvcf /home/ubuntu/dd/nextflow2/SRR26512958_raw.gvcf.gz --num_shards 16. --intermediate_results_dir /home/ubuntu/dd/nextflow2/tmp > deepvariant_log.txt 2>&1. Command exit status:. 127. Command output:. (empty). Command error:. docker: Error response from daemon: open /var/lib/docker/overlay2/fe3663cd03e849890d83be14603f217249f3f43f9585b554df599d0318909f21/.tmp-committed2046174062: no such file or directory. See 'docker run --help'. Work dir:. /home/ubuntu/dd/nextflow2/work/ea/9ecd306270fe3f00d9b73f82",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/883:2805,availability,error,error,2805,"bed_file} \. --output_vcf ${PWD}/${params.outdir}/${sample_id}_raw.vcf.gz \. --output_gvcf ${PWD}/${sample_id}_raw.gvcf.gz \. --num_shards ${task.cpus}. --intermediate_results_dir ${PWD}/tmp > deepvariant_log.txt 2>&1. """""". }. ############# Error ###################. N E X T F L O W ~ version 24.04.4. Launching `dip.nf` [deadly_pike] DSL2 - revision: e075b1fba0. executor > local (2). [a6/9c6b79] process > deepvar (Germline Variant on SRR26512959) [ 0%] 0 of 2. ERROR ~ Error executing process > 'deepvar (Germline Variant on SRR26512958)'. executor > local (2). [a6/9c6b79] process > deepvar (Germline Variant on SRR26512959) [100%] 1 of 1, failed: 1. ERROR ~ Error executing process > 'deepvar (Germline Variant on SRR26512958)'. Caused by:. Process `deepvar (Germline Variant on SRR26512958)` terminated with an error exit status (127). Command executed:. sudo docker run -v ""/home/ubuntu/dd/nextflow2"":""/home/ubuntu/dd/nextflow2"" google/deepvariant:1.6.1 /opt/deepvariant/bin/run_deepvariant --model_type WES --ref /home/ubuntu/dd/nextflow2/reference/Homo_sapiens_assembly38.fasta --reads /home/ubuntu/dd/nextflow2/output/4.markDuplicate/SRR26512958_sorted_md.bam --regions /home/ubuntu/dd/nextflow2/reference/hg38_exome.bed --output_vcf /home/ubuntu/dd/nextflow2/output/5.snvS/SRR26512958_raw.vcf.gz --output_gvcf /home/ubuntu/dd/nextflow2/SRR26512958_raw.gvcf.gz --num_shards 16. --intermediate_results_dir /home/ubuntu/dd/nextflow2/tmp > deepvariant_log.txt 2>&1. Command exit status:. 127. Command output:. (empty). Command error:. docker: Error response from daemon: open /var/lib/docker/overlay2/fe3663cd03e849890d83be14603f217249f3f43f9585b554df599d0318909f21/.tmp-committed2046174062: no such file or directory. See 'docker run --help'. Work dir:. /home/ubuntu/dd/nextflow2/work/ea/9ecd306270fe3f00d9b73f8261fe89. Tip: you can try to figure out what's wrong by changing to the process work dir and showing the script file named `.command.sh`. -- Check '.nextflow.log' file for details.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/883:2821,availability,Error,Error,2821,"bed_file} \. --output_vcf ${PWD}/${params.outdir}/${sample_id}_raw.vcf.gz \. --output_gvcf ${PWD}/${sample_id}_raw.gvcf.gz \. --num_shards ${task.cpus}. --intermediate_results_dir ${PWD}/tmp > deepvariant_log.txt 2>&1. """""". }. ############# Error ###################. N E X T F L O W ~ version 24.04.4. Launching `dip.nf` [deadly_pike] DSL2 - revision: e075b1fba0. executor > local (2). [a6/9c6b79] process > deepvar (Germline Variant on SRR26512959) [ 0%] 0 of 2. ERROR ~ Error executing process > 'deepvar (Germline Variant on SRR26512958)'. executor > local (2). [a6/9c6b79] process > deepvar (Germline Variant on SRR26512959) [100%] 1 of 1, failed: 1. ERROR ~ Error executing process > 'deepvar (Germline Variant on SRR26512958)'. Caused by:. Process `deepvar (Germline Variant on SRR26512958)` terminated with an error exit status (127). Command executed:. sudo docker run -v ""/home/ubuntu/dd/nextflow2"":""/home/ubuntu/dd/nextflow2"" google/deepvariant:1.6.1 /opt/deepvariant/bin/run_deepvariant --model_type WES --ref /home/ubuntu/dd/nextflow2/reference/Homo_sapiens_assembly38.fasta --reads /home/ubuntu/dd/nextflow2/output/4.markDuplicate/SRR26512958_sorted_md.bam --regions /home/ubuntu/dd/nextflow2/reference/hg38_exome.bed --output_vcf /home/ubuntu/dd/nextflow2/output/5.snvS/SRR26512958_raw.vcf.gz --output_gvcf /home/ubuntu/dd/nextflow2/SRR26512958_raw.gvcf.gz --num_shards 16. --intermediate_results_dir /home/ubuntu/dd/nextflow2/tmp > deepvariant_log.txt 2>&1. Command exit status:. 127. Command output:. (empty). Command error:. docker: Error response from daemon: open /var/lib/docker/overlay2/fe3663cd03e849890d83be14603f217249f3f43f9585b554df599d0318909f21/.tmp-committed2046174062: no such file or directory. See 'docker run --help'. Work dir:. /home/ubuntu/dd/nextflow2/work/ea/9ecd306270fe3f00d9b73f8261fe89. Tip: you can try to figure out what's wrong by changing to the process work dir and showing the script file named `.command.sh`. -- Check '.nextflow.log' file for details.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/883:1556,deployability,version,version,1556,"ocess steps. /// Germline variant calling. deepvar(read_pairs, params.reference, params.bed_file). }. process deepvar {. tag ""Germline Variant on ${sample_id}"". publishDir ""${params.outdir}/6.variantM"", mode: 'copy'. cpus 16. input:. tuple val(sample_id), path(read_files). val(params.reference). val(params.bed_file). . output:. tuple val(sample_id), path(""${sample_id}_raw.vcf.gz""), path(""${sample_id}_raw.gvcf.gz""), emit: raw_vcfs. script:. """""". sudo docker run \. -v ""${PWD}"":""${PWD}"" \. google/deepvariant:1.6.1 \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref ${PWD}/${params.reference} \. --reads ${PWD}/output/4.markDuplicate/${sample_id}_sorted_md.bam \. --regions ${PWD}/${params.bed_file} \. --output_vcf ${PWD}/${params.outdir}/${sample_id}_raw.vcf.gz \. --output_gvcf ${PWD}/${sample_id}_raw.gvcf.gz \. --num_shards ${task.cpus}. --intermediate_results_dir ${PWD}/tmp > deepvariant_log.txt 2>&1. """""". }. ############# Error ###################. N E X T F L O W ~ version 24.04.4. Launching `dip.nf` [deadly_pike] DSL2 - revision: e075b1fba0. executor > local (2). [a6/9c6b79] process > deepvar (Germline Variant on SRR26512959) [ 0%] 0 of 2. ERROR ~ Error executing process > 'deepvar (Germline Variant on SRR26512958)'. executor > local (2). [a6/9c6b79] process > deepvar (Germline Variant on SRR26512959) [100%] 1 of 1, failed: 1. ERROR ~ Error executing process > 'deepvar (Germline Variant on SRR26512958)'. Caused by:. Process `deepvar (Germline Variant on SRR26512958)` terminated with an error exit status (127). Command executed:. sudo docker run -v ""/home/ubuntu/dd/nextflow2"":""/home/ubuntu/dd/nextflow2"" google/deepvariant:1.6.1 /opt/deepvariant/bin/run_deepvariant --model_type WES --ref /home/ubuntu/dd/nextflow2/reference/Homo_sapiens_assembly38.fasta --reads /home/ubuntu/dd/nextflow2/output/4.markDuplicate/SRR26512958_sorted_md.bam --regions /home/ubuntu/dd/nextflow2/reference/hg38_exome.bed --output_vcf /home/ubuntu/dd/nextflow2/output/5.snvS/SRR26",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/883:1915,deployability,fail,failed,1915,"${sample_id}_raw.vcf.gz""), path(""${sample_id}_raw.gvcf.gz""), emit: raw_vcfs. script:. """""". sudo docker run \. -v ""${PWD}"":""${PWD}"" \. google/deepvariant:1.6.1 \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref ${PWD}/${params.reference} \. --reads ${PWD}/output/4.markDuplicate/${sample_id}_sorted_md.bam \. --regions ${PWD}/${params.bed_file} \. --output_vcf ${PWD}/${params.outdir}/${sample_id}_raw.vcf.gz \. --output_gvcf ${PWD}/${sample_id}_raw.gvcf.gz \. --num_shards ${task.cpus}. --intermediate_results_dir ${PWD}/tmp > deepvariant_log.txt 2>&1. """""". }. ############# Error ###################. N E X T F L O W ~ version 24.04.4. Launching `dip.nf` [deadly_pike] DSL2 - revision: e075b1fba0. executor > local (2). [a6/9c6b79] process > deepvar (Germline Variant on SRR26512959) [ 0%] 0 of 2. ERROR ~ Error executing process > 'deepvar (Germline Variant on SRR26512958)'. executor > local (2). [a6/9c6b79] process > deepvar (Germline Variant on SRR26512959) [100%] 1 of 1, failed: 1. ERROR ~ Error executing process > 'deepvar (Germline Variant on SRR26512958)'. Caused by:. Process `deepvar (Germline Variant on SRR26512958)` terminated with an error exit status (127). Command executed:. sudo docker run -v ""/home/ubuntu/dd/nextflow2"":""/home/ubuntu/dd/nextflow2"" google/deepvariant:1.6.1 /opt/deepvariant/bin/run_deepvariant --model_type WES --ref /home/ubuntu/dd/nextflow2/reference/Homo_sapiens_assembly38.fasta --reads /home/ubuntu/dd/nextflow2/output/4.markDuplicate/SRR26512958_sorted_md.bam --regions /home/ubuntu/dd/nextflow2/reference/hg38_exome.bed --output_vcf /home/ubuntu/dd/nextflow2/output/5.snvS/SRR26512958_raw.vcf.gz --output_gvcf /home/ubuntu/dd/nextflow2/SRR26512958_raw.gvcf.gz --num_shards 16. --intermediate_results_dir /home/ubuntu/dd/nextflow2/tmp > deepvariant_log.txt 2>&1. Command exit status:. 127. Command output:. (empty). Command error:. docker: Error response from daemon: open /var/lib/docker/overlay2/fe3663cd03e849890d83be14603f217249f3f43",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/883:3248,deployability,log,log,3248,"bed_file} \. --output_vcf ${PWD}/${params.outdir}/${sample_id}_raw.vcf.gz \. --output_gvcf ${PWD}/${sample_id}_raw.gvcf.gz \. --num_shards ${task.cpus}. --intermediate_results_dir ${PWD}/tmp > deepvariant_log.txt 2>&1. """""". }. ############# Error ###################. N E X T F L O W ~ version 24.04.4. Launching `dip.nf` [deadly_pike] DSL2 - revision: e075b1fba0. executor > local (2). [a6/9c6b79] process > deepvar (Germline Variant on SRR26512959) [ 0%] 0 of 2. ERROR ~ Error executing process > 'deepvar (Germline Variant on SRR26512958)'. executor > local (2). [a6/9c6b79] process > deepvar (Germline Variant on SRR26512959) [100%] 1 of 1, failed: 1. ERROR ~ Error executing process > 'deepvar (Germline Variant on SRR26512958)'. Caused by:. Process `deepvar (Germline Variant on SRR26512958)` terminated with an error exit status (127). Command executed:. sudo docker run -v ""/home/ubuntu/dd/nextflow2"":""/home/ubuntu/dd/nextflow2"" google/deepvariant:1.6.1 /opt/deepvariant/bin/run_deepvariant --model_type WES --ref /home/ubuntu/dd/nextflow2/reference/Homo_sapiens_assembly38.fasta --reads /home/ubuntu/dd/nextflow2/output/4.markDuplicate/SRR26512958_sorted_md.bam --regions /home/ubuntu/dd/nextflow2/reference/hg38_exome.bed --output_vcf /home/ubuntu/dd/nextflow2/output/5.snvS/SRR26512958_raw.vcf.gz --output_gvcf /home/ubuntu/dd/nextflow2/SRR26512958_raw.gvcf.gz --num_shards 16. --intermediate_results_dir /home/ubuntu/dd/nextflow2/tmp > deepvariant_log.txt 2>&1. Command exit status:. 127. Command output:. (empty). Command error:. docker: Error response from daemon: open /var/lib/docker/overlay2/fe3663cd03e849890d83be14603f217249f3f43f9585b554df599d0318909f21/.tmp-committed2046174062: no such file or directory. See 'docker run --help'. Work dir:. /home/ubuntu/dd/nextflow2/work/ea/9ecd306270fe3f00d9b73f8261fe89. Tip: you can try to figure out what's wrong by changing to the process work dir and showing the script file named `.command.sh`. -- Check '.nextflow.log' file for details.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/883:285,energy efficiency,cpu,cpus,285,"Running deepvariant within Nextflow DSL2; . #!/usr/bin/env nextflow . nextflow.enable.dsl=2. params.data_dir = 'output/4.markDuplicate'. params.reference = 'reference/Homo_sapiens_assembly38.fasta'. params.bed_file = 'reference/hg38_exome.bed'. params.outdir = 'output/5.snvS'. params.cpus = 16 // Number of CPUs to use. workflow {. // Define channels for input data. Channel. .fromPath(""${PWD}${params.data_dir}/*_sorted_md.bam""). .map { file ->. def sample_id = file.baseName.replace('_sorted_md', ''). return [sample_id, file]. }. .set { read_pairs }. // Process steps. /// Germline variant calling. deepvar(read_pairs, params.reference, params.bed_file). }. process deepvar {. tag ""Germline Variant on ${sample_id}"". publishDir ""${params.outdir}/6.variantM"", mode: 'copy'. cpus 16. input:. tuple val(sample_id), path(read_files). val(params.reference). val(params.bed_file). . output:. tuple val(sample_id), path(""${sample_id}_raw.vcf.gz""), path(""${sample_id}_raw.gvcf.gz""), emit: raw_vcfs. script:. """""". sudo docker run \. -v ""${PWD}"":""${PWD}"" \. google/deepvariant:1.6.1 \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref ${PWD}/${params.reference} \. --reads ${PWD}/output/4.markDuplicate/${sample_id}_sorted_md.bam \. --regions ${PWD}/${params.bed_file} \. --output_vcf ${PWD}/${params.outdir}/${sample_id}_raw.vcf.gz \. --output_gvcf ${PWD}/${sample_id}_raw.gvcf.gz \. --num_shards ${task.cpus}. --intermediate_results_dir ${PWD}/tmp > deepvariant_log.txt 2>&1. """""". }. ############# Error ###################. N E X T F L O W ~ version 24.04.4. Launching `dip.nf` [deadly_pike] DSL2 - revision: e075b1fba0. executor > local (2). [a6/9c6b79] process > deepvar (Germline Variant on SRR26512959) [ 0%] 0 of 2. ERROR ~ Error executing process > 'deepvar (Germline Variant on SRR26512958)'. executor > local (2). [a6/9c6b79] process > deepvar (Germline Variant on SRR26512959) [100%] 1 of 1, failed: 1. ERROR ~ Error executing process > 'deepvar (Germline Variant on SRR2651295",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/883:308,energy efficiency,CPU,CPUs,308,"Running deepvariant within Nextflow DSL2; . #!/usr/bin/env nextflow . nextflow.enable.dsl=2. params.data_dir = 'output/4.markDuplicate'. params.reference = 'reference/Homo_sapiens_assembly38.fasta'. params.bed_file = 'reference/hg38_exome.bed'. params.outdir = 'output/5.snvS'. params.cpus = 16 // Number of CPUs to use. workflow {. // Define channels for input data. Channel. .fromPath(""${PWD}${params.data_dir}/*_sorted_md.bam""). .map { file ->. def sample_id = file.baseName.replace('_sorted_md', ''). return [sample_id, file]. }. .set { read_pairs }. // Process steps. /// Germline variant calling. deepvar(read_pairs, params.reference, params.bed_file). }. process deepvar {. tag ""Germline Variant on ${sample_id}"". publishDir ""${params.outdir}/6.variantM"", mode: 'copy'. cpus 16. input:. tuple val(sample_id), path(read_files). val(params.reference). val(params.bed_file). . output:. tuple val(sample_id), path(""${sample_id}_raw.vcf.gz""), path(""${sample_id}_raw.gvcf.gz""), emit: raw_vcfs. script:. """""". sudo docker run \. -v ""${PWD}"":""${PWD}"" \. google/deepvariant:1.6.1 \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref ${PWD}/${params.reference} \. --reads ${PWD}/output/4.markDuplicate/${sample_id}_sorted_md.bam \. --regions ${PWD}/${params.bed_file} \. --output_vcf ${PWD}/${params.outdir}/${sample_id}_raw.vcf.gz \. --output_gvcf ${PWD}/${sample_id}_raw.gvcf.gz \. --num_shards ${task.cpus}. --intermediate_results_dir ${PWD}/tmp > deepvariant_log.txt 2>&1. """""". }. ############# Error ###################. N E X T F L O W ~ version 24.04.4. Launching `dip.nf` [deadly_pike] DSL2 - revision: e075b1fba0. executor > local (2). [a6/9c6b79] process > deepvar (Germline Variant on SRR26512959) [ 0%] 0 of 2. ERROR ~ Error executing process > 'deepvar (Germline Variant on SRR26512958)'. executor > local (2). [a6/9c6b79] process > deepvar (Germline Variant on SRR26512959) [100%] 1 of 1, failed: 1. ERROR ~ Error executing process > 'deepvar (Germline Variant on SRR2651295",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/883:777,energy efficiency,cpu,cpus,777,"Running deepvariant within Nextflow DSL2; . #!/usr/bin/env nextflow . nextflow.enable.dsl=2. params.data_dir = 'output/4.markDuplicate'. params.reference = 'reference/Homo_sapiens_assembly38.fasta'. params.bed_file = 'reference/hg38_exome.bed'. params.outdir = 'output/5.snvS'. params.cpus = 16 // Number of CPUs to use. workflow {. // Define channels for input data. Channel. .fromPath(""${PWD}${params.data_dir}/*_sorted_md.bam""). .map { file ->. def sample_id = file.baseName.replace('_sorted_md', ''). return [sample_id, file]. }. .set { read_pairs }. // Process steps. /// Germline variant calling. deepvar(read_pairs, params.reference, params.bed_file). }. process deepvar {. tag ""Germline Variant on ${sample_id}"". publishDir ""${params.outdir}/6.variantM"", mode: 'copy'. cpus 16. input:. tuple val(sample_id), path(read_files). val(params.reference). val(params.bed_file). . output:. tuple val(sample_id), path(""${sample_id}_raw.vcf.gz""), path(""${sample_id}_raw.gvcf.gz""), emit: raw_vcfs. script:. """""". sudo docker run \. -v ""${PWD}"":""${PWD}"" \. google/deepvariant:1.6.1 \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref ${PWD}/${params.reference} \. --reads ${PWD}/output/4.markDuplicate/${sample_id}_sorted_md.bam \. --regions ${PWD}/${params.bed_file} \. --output_vcf ${PWD}/${params.outdir}/${sample_id}_raw.vcf.gz \. --output_gvcf ${PWD}/${sample_id}_raw.gvcf.gz \. --num_shards ${task.cpus}. --intermediate_results_dir ${PWD}/tmp > deepvariant_log.txt 2>&1. """""". }. ############# Error ###################. N E X T F L O W ~ version 24.04.4. Launching `dip.nf` [deadly_pike] DSL2 - revision: e075b1fba0. executor > local (2). [a6/9c6b79] process > deepvar (Germline Variant on SRR26512959) [ 0%] 0 of 2. ERROR ~ Error executing process > 'deepvar (Germline Variant on SRR26512958)'. executor > local (2). [a6/9c6b79] process > deepvar (Germline Variant on SRR26512959) [100%] 1 of 1, failed: 1. ERROR ~ Error executing process > 'deepvar (Germline Variant on SRR2651295",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/883:1416,energy efficiency,cpu,cpus,1416,"ted_md.bam""). .map { file ->. def sample_id = file.baseName.replace('_sorted_md', ''). return [sample_id, file]. }. .set { read_pairs }. // Process steps. /// Germline variant calling. deepvar(read_pairs, params.reference, params.bed_file). }. process deepvar {. tag ""Germline Variant on ${sample_id}"". publishDir ""${params.outdir}/6.variantM"", mode: 'copy'. cpus 16. input:. tuple val(sample_id), path(read_files). val(params.reference). val(params.bed_file). . output:. tuple val(sample_id), path(""${sample_id}_raw.vcf.gz""), path(""${sample_id}_raw.gvcf.gz""), emit: raw_vcfs. script:. """""". sudo docker run \. -v ""${PWD}"":""${PWD}"" \. google/deepvariant:1.6.1 \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref ${PWD}/${params.reference} \. --reads ${PWD}/output/4.markDuplicate/${sample_id}_sorted_md.bam \. --regions ${PWD}/${params.bed_file} \. --output_vcf ${PWD}/${params.outdir}/${sample_id}_raw.vcf.gz \. --output_gvcf ${PWD}/${sample_id}_raw.gvcf.gz \. --num_shards ${task.cpus}. --intermediate_results_dir ${PWD}/tmp > deepvariant_log.txt 2>&1. """""". }. ############# Error ###################. N E X T F L O W ~ version 24.04.4. Launching `dip.nf` [deadly_pike] DSL2 - revision: e075b1fba0. executor > local (2). [a6/9c6b79] process > deepvar (Germline Variant on SRR26512959) [ 0%] 0 of 2. ERROR ~ Error executing process > 'deepvar (Germline Variant on SRR26512958)'. executor > local (2). [a6/9c6b79] process > deepvar (Germline Variant on SRR26512959) [100%] 1 of 1, failed: 1. ERROR ~ Error executing process > 'deepvar (Germline Variant on SRR26512958)'. Caused by:. Process `deepvar (Germline Variant on SRR26512958)` terminated with an error exit status (127). Command executed:. sudo docker run -v ""/home/ubuntu/dd/nextflow2"":""/home/ubuntu/dd/nextflow2"" google/deepvariant:1.6.1 /opt/deepvariant/bin/run_deepvariant --model_type WES --ref /home/ubuntu/dd/nextflow2/reference/Homo_sapiens_assembly38.fasta --reads /home/ubuntu/dd/nextflow2/output/4.markDuplicate/SRR",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/883:721,integrability,pub,publishDir,721,"Running deepvariant within Nextflow DSL2; . #!/usr/bin/env nextflow . nextflow.enable.dsl=2. params.data_dir = 'output/4.markDuplicate'. params.reference = 'reference/Homo_sapiens_assembly38.fasta'. params.bed_file = 'reference/hg38_exome.bed'. params.outdir = 'output/5.snvS'. params.cpus = 16 // Number of CPUs to use. workflow {. // Define channels for input data. Channel. .fromPath(""${PWD}${params.data_dir}/*_sorted_md.bam""). .map { file ->. def sample_id = file.baseName.replace('_sorted_md', ''). return [sample_id, file]. }. .set { read_pairs }. // Process steps. /// Germline variant calling. deepvar(read_pairs, params.reference, params.bed_file). }. process deepvar {. tag ""Germline Variant on ${sample_id}"". publishDir ""${params.outdir}/6.variantM"", mode: 'copy'. cpus 16. input:. tuple val(sample_id), path(read_files). val(params.reference). val(params.bed_file). . output:. tuple val(sample_id), path(""${sample_id}_raw.vcf.gz""), path(""${sample_id}_raw.gvcf.gz""), emit: raw_vcfs. script:. """""". sudo docker run \. -v ""${PWD}"":""${PWD}"" \. google/deepvariant:1.6.1 \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref ${PWD}/${params.reference} \. --reads ${PWD}/output/4.markDuplicate/${sample_id}_sorted_md.bam \. --regions ${PWD}/${params.bed_file} \. --output_vcf ${PWD}/${params.outdir}/${sample_id}_raw.vcf.gz \. --output_gvcf ${PWD}/${sample_id}_raw.gvcf.gz \. --num_shards ${task.cpus}. --intermediate_results_dir ${PWD}/tmp > deepvariant_log.txt 2>&1. """""". }. ############# Error ###################. N E X T F L O W ~ version 24.04.4. Launching `dip.nf` [deadly_pike] DSL2 - revision: e075b1fba0. executor > local (2). [a6/9c6b79] process > deepvar (Germline Variant on SRR26512959) [ 0%] 0 of 2. ERROR ~ Error executing process > 'deepvar (Germline Variant on SRR26512958)'. executor > local (2). [a6/9c6b79] process > deepvar (Germline Variant on SRR26512959) [100%] 1 of 1, failed: 1. ERROR ~ Error executing process > 'deepvar (Germline Variant on SRR2651295",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/883:1556,integrability,version,version,1556,"ocess steps. /// Germline variant calling. deepvar(read_pairs, params.reference, params.bed_file). }. process deepvar {. tag ""Germline Variant on ${sample_id}"". publishDir ""${params.outdir}/6.variantM"", mode: 'copy'. cpus 16. input:. tuple val(sample_id), path(read_files). val(params.reference). val(params.bed_file). . output:. tuple val(sample_id), path(""${sample_id}_raw.vcf.gz""), path(""${sample_id}_raw.gvcf.gz""), emit: raw_vcfs. script:. """""". sudo docker run \. -v ""${PWD}"":""${PWD}"" \. google/deepvariant:1.6.1 \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref ${PWD}/${params.reference} \. --reads ${PWD}/output/4.markDuplicate/${sample_id}_sorted_md.bam \. --regions ${PWD}/${params.bed_file} \. --output_vcf ${PWD}/${params.outdir}/${sample_id}_raw.vcf.gz \. --output_gvcf ${PWD}/${sample_id}_raw.gvcf.gz \. --num_shards ${task.cpus}. --intermediate_results_dir ${PWD}/tmp > deepvariant_log.txt 2>&1. """""". }. ############# Error ###################. N E X T F L O W ~ version 24.04.4. Launching `dip.nf` [deadly_pike] DSL2 - revision: e075b1fba0. executor > local (2). [a6/9c6b79] process > deepvar (Germline Variant on SRR26512959) [ 0%] 0 of 2. ERROR ~ Error executing process > 'deepvar (Germline Variant on SRR26512958)'. executor > local (2). [a6/9c6b79] process > deepvar (Germline Variant on SRR26512959) [100%] 1 of 1, failed: 1. ERROR ~ Error executing process > 'deepvar (Germline Variant on SRR26512958)'. Caused by:. Process `deepvar (Germline Variant on SRR26512958)` terminated with an error exit status (127). Command executed:. sudo docker run -v ""/home/ubuntu/dd/nextflow2"":""/home/ubuntu/dd/nextflow2"" google/deepvariant:1.6.1 /opt/deepvariant/bin/run_deepvariant --model_type WES --ref /home/ubuntu/dd/nextflow2/reference/Homo_sapiens_assembly38.fasta --reads /home/ubuntu/dd/nextflow2/output/4.markDuplicate/SRR26512958_sorted_md.bam --regions /home/ubuntu/dd/nextflow2/reference/hg38_exome.bed --output_vcf /home/ubuntu/dd/nextflow2/output/5.snvS/SRR26",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/883:1556,modifiability,version,version,1556,"ocess steps. /// Germline variant calling. deepvar(read_pairs, params.reference, params.bed_file). }. process deepvar {. tag ""Germline Variant on ${sample_id}"". publishDir ""${params.outdir}/6.variantM"", mode: 'copy'. cpus 16. input:. tuple val(sample_id), path(read_files). val(params.reference). val(params.bed_file). . output:. tuple val(sample_id), path(""${sample_id}_raw.vcf.gz""), path(""${sample_id}_raw.gvcf.gz""), emit: raw_vcfs. script:. """""". sudo docker run \. -v ""${PWD}"":""${PWD}"" \. google/deepvariant:1.6.1 \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref ${PWD}/${params.reference} \. --reads ${PWD}/output/4.markDuplicate/${sample_id}_sorted_md.bam \. --regions ${PWD}/${params.bed_file} \. --output_vcf ${PWD}/${params.outdir}/${sample_id}_raw.vcf.gz \. --output_gvcf ${PWD}/${sample_id}_raw.gvcf.gz \. --num_shards ${task.cpus}. --intermediate_results_dir ${PWD}/tmp > deepvariant_log.txt 2>&1. """""". }. ############# Error ###################. N E X T F L O W ~ version 24.04.4. Launching `dip.nf` [deadly_pike] DSL2 - revision: e075b1fba0. executor > local (2). [a6/9c6b79] process > deepvar (Germline Variant on SRR26512959) [ 0%] 0 of 2. ERROR ~ Error executing process > 'deepvar (Germline Variant on SRR26512958)'. executor > local (2). [a6/9c6b79] process > deepvar (Germline Variant on SRR26512959) [100%] 1 of 1, failed: 1. ERROR ~ Error executing process > 'deepvar (Germline Variant on SRR26512958)'. Caused by:. Process `deepvar (Germline Variant on SRR26512958)` terminated with an error exit status (127). Command executed:. sudo docker run -v ""/home/ubuntu/dd/nextflow2"":""/home/ubuntu/dd/nextflow2"" google/deepvariant:1.6.1 /opt/deepvariant/bin/run_deepvariant --model_type WES --ref /home/ubuntu/dd/nextflow2/reference/Homo_sapiens_assembly38.fasta --reads /home/ubuntu/dd/nextflow2/output/4.markDuplicate/SRR26512958_sorted_md.bam --regions /home/ubuntu/dd/nextflow2/reference/hg38_exome.bed --output_vcf /home/ubuntu/dd/nextflow2/output/5.snvS/SRR26",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/883:285,performance,cpu,cpus,285,"Running deepvariant within Nextflow DSL2; . #!/usr/bin/env nextflow . nextflow.enable.dsl=2. params.data_dir = 'output/4.markDuplicate'. params.reference = 'reference/Homo_sapiens_assembly38.fasta'. params.bed_file = 'reference/hg38_exome.bed'. params.outdir = 'output/5.snvS'. params.cpus = 16 // Number of CPUs to use. workflow {. // Define channels for input data. Channel. .fromPath(""${PWD}${params.data_dir}/*_sorted_md.bam""). .map { file ->. def sample_id = file.baseName.replace('_sorted_md', ''). return [sample_id, file]. }. .set { read_pairs }. // Process steps. /// Germline variant calling. deepvar(read_pairs, params.reference, params.bed_file). }. process deepvar {. tag ""Germline Variant on ${sample_id}"". publishDir ""${params.outdir}/6.variantM"", mode: 'copy'. cpus 16. input:. tuple val(sample_id), path(read_files). val(params.reference). val(params.bed_file). . output:. tuple val(sample_id), path(""${sample_id}_raw.vcf.gz""), path(""${sample_id}_raw.gvcf.gz""), emit: raw_vcfs. script:. """""". sudo docker run \. -v ""${PWD}"":""${PWD}"" \. google/deepvariant:1.6.1 \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref ${PWD}/${params.reference} \. --reads ${PWD}/output/4.markDuplicate/${sample_id}_sorted_md.bam \. --regions ${PWD}/${params.bed_file} \. --output_vcf ${PWD}/${params.outdir}/${sample_id}_raw.vcf.gz \. --output_gvcf ${PWD}/${sample_id}_raw.gvcf.gz \. --num_shards ${task.cpus}. --intermediate_results_dir ${PWD}/tmp > deepvariant_log.txt 2>&1. """""". }. ############# Error ###################. N E X T F L O W ~ version 24.04.4. Launching `dip.nf` [deadly_pike] DSL2 - revision: e075b1fba0. executor > local (2). [a6/9c6b79] process > deepvar (Germline Variant on SRR26512959) [ 0%] 0 of 2. ERROR ~ Error executing process > 'deepvar (Germline Variant on SRR26512958)'. executor > local (2). [a6/9c6b79] process > deepvar (Germline Variant on SRR26512959) [100%] 1 of 1, failed: 1. ERROR ~ Error executing process > 'deepvar (Germline Variant on SRR2651295",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/883:308,performance,CPU,CPUs,308,"Running deepvariant within Nextflow DSL2; . #!/usr/bin/env nextflow . nextflow.enable.dsl=2. params.data_dir = 'output/4.markDuplicate'. params.reference = 'reference/Homo_sapiens_assembly38.fasta'. params.bed_file = 'reference/hg38_exome.bed'. params.outdir = 'output/5.snvS'. params.cpus = 16 // Number of CPUs to use. workflow {. // Define channels for input data. Channel. .fromPath(""${PWD}${params.data_dir}/*_sorted_md.bam""). .map { file ->. def sample_id = file.baseName.replace('_sorted_md', ''). return [sample_id, file]. }. .set { read_pairs }. // Process steps. /// Germline variant calling. deepvar(read_pairs, params.reference, params.bed_file). }. process deepvar {. tag ""Germline Variant on ${sample_id}"". publishDir ""${params.outdir}/6.variantM"", mode: 'copy'. cpus 16. input:. tuple val(sample_id), path(read_files). val(params.reference). val(params.bed_file). . output:. tuple val(sample_id), path(""${sample_id}_raw.vcf.gz""), path(""${sample_id}_raw.gvcf.gz""), emit: raw_vcfs. script:. """""". sudo docker run \. -v ""${PWD}"":""${PWD}"" \. google/deepvariant:1.6.1 \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref ${PWD}/${params.reference} \. --reads ${PWD}/output/4.markDuplicate/${sample_id}_sorted_md.bam \. --regions ${PWD}/${params.bed_file} \. --output_vcf ${PWD}/${params.outdir}/${sample_id}_raw.vcf.gz \. --output_gvcf ${PWD}/${sample_id}_raw.gvcf.gz \. --num_shards ${task.cpus}. --intermediate_results_dir ${PWD}/tmp > deepvariant_log.txt 2>&1. """""". }. ############# Error ###################. N E X T F L O W ~ version 24.04.4. Launching `dip.nf` [deadly_pike] DSL2 - revision: e075b1fba0. executor > local (2). [a6/9c6b79] process > deepvar (Germline Variant on SRR26512959) [ 0%] 0 of 2. ERROR ~ Error executing process > 'deepvar (Germline Variant on SRR26512958)'. executor > local (2). [a6/9c6b79] process > deepvar (Germline Variant on SRR26512959) [100%] 1 of 1, failed: 1. ERROR ~ Error executing process > 'deepvar (Germline Variant on SRR2651295",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/883:777,performance,cpu,cpus,777,"Running deepvariant within Nextflow DSL2; . #!/usr/bin/env nextflow . nextflow.enable.dsl=2. params.data_dir = 'output/4.markDuplicate'. params.reference = 'reference/Homo_sapiens_assembly38.fasta'. params.bed_file = 'reference/hg38_exome.bed'. params.outdir = 'output/5.snvS'. params.cpus = 16 // Number of CPUs to use. workflow {. // Define channels for input data. Channel. .fromPath(""${PWD}${params.data_dir}/*_sorted_md.bam""). .map { file ->. def sample_id = file.baseName.replace('_sorted_md', ''). return [sample_id, file]. }. .set { read_pairs }. // Process steps. /// Germline variant calling. deepvar(read_pairs, params.reference, params.bed_file). }. process deepvar {. tag ""Germline Variant on ${sample_id}"". publishDir ""${params.outdir}/6.variantM"", mode: 'copy'. cpus 16. input:. tuple val(sample_id), path(read_files). val(params.reference). val(params.bed_file). . output:. tuple val(sample_id), path(""${sample_id}_raw.vcf.gz""), path(""${sample_id}_raw.gvcf.gz""), emit: raw_vcfs. script:. """""". sudo docker run \. -v ""${PWD}"":""${PWD}"" \. google/deepvariant:1.6.1 \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref ${PWD}/${params.reference} \. --reads ${PWD}/output/4.markDuplicate/${sample_id}_sorted_md.bam \. --regions ${PWD}/${params.bed_file} \. --output_vcf ${PWD}/${params.outdir}/${sample_id}_raw.vcf.gz \. --output_gvcf ${PWD}/${sample_id}_raw.gvcf.gz \. --num_shards ${task.cpus}. --intermediate_results_dir ${PWD}/tmp > deepvariant_log.txt 2>&1. """""". }. ############# Error ###################. N E X T F L O W ~ version 24.04.4. Launching `dip.nf` [deadly_pike] DSL2 - revision: e075b1fba0. executor > local (2). [a6/9c6b79] process > deepvar (Germline Variant on SRR26512959) [ 0%] 0 of 2. ERROR ~ Error executing process > 'deepvar (Germline Variant on SRR26512958)'. executor > local (2). [a6/9c6b79] process > deepvar (Germline Variant on SRR26512959) [100%] 1 of 1, failed: 1. ERROR ~ Error executing process > 'deepvar (Germline Variant on SRR2651295",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/883:1416,performance,cpu,cpus,1416,"ted_md.bam""). .map { file ->. def sample_id = file.baseName.replace('_sorted_md', ''). return [sample_id, file]. }. .set { read_pairs }. // Process steps. /// Germline variant calling. deepvar(read_pairs, params.reference, params.bed_file). }. process deepvar {. tag ""Germline Variant on ${sample_id}"". publishDir ""${params.outdir}/6.variantM"", mode: 'copy'. cpus 16. input:. tuple val(sample_id), path(read_files). val(params.reference). val(params.bed_file). . output:. tuple val(sample_id), path(""${sample_id}_raw.vcf.gz""), path(""${sample_id}_raw.gvcf.gz""), emit: raw_vcfs. script:. """""". sudo docker run \. -v ""${PWD}"":""${PWD}"" \. google/deepvariant:1.6.1 \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref ${PWD}/${params.reference} \. --reads ${PWD}/output/4.markDuplicate/${sample_id}_sorted_md.bam \. --regions ${PWD}/${params.bed_file} \. --output_vcf ${PWD}/${params.outdir}/${sample_id}_raw.vcf.gz \. --output_gvcf ${PWD}/${sample_id}_raw.gvcf.gz \. --num_shards ${task.cpus}. --intermediate_results_dir ${PWD}/tmp > deepvariant_log.txt 2>&1. """""". }. ############# Error ###################. N E X T F L O W ~ version 24.04.4. Launching `dip.nf` [deadly_pike] DSL2 - revision: e075b1fba0. executor > local (2). [a6/9c6b79] process > deepvar (Germline Variant on SRR26512959) [ 0%] 0 of 2. ERROR ~ Error executing process > 'deepvar (Germline Variant on SRR26512958)'. executor > local (2). [a6/9c6b79] process > deepvar (Germline Variant on SRR26512959) [100%] 1 of 1, failed: 1. ERROR ~ Error executing process > 'deepvar (Germline Variant on SRR26512958)'. Caused by:. Process `deepvar (Germline Variant on SRR26512958)` terminated with an error exit status (127). Command executed:. sudo docker run -v ""/home/ubuntu/dd/nextflow2"":""/home/ubuntu/dd/nextflow2"" google/deepvariant:1.6.1 /opt/deepvariant/bin/run_deepvariant --model_type WES --ref /home/ubuntu/dd/nextflow2/reference/Homo_sapiens_assembly38.fasta --reads /home/ubuntu/dd/nextflow2/output/4.markDuplicate/SRR",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/883:1511,performance,Error,Error,1511,"ample_id, file]. }. .set { read_pairs }. // Process steps. /// Germline variant calling. deepvar(read_pairs, params.reference, params.bed_file). }. process deepvar {. tag ""Germline Variant on ${sample_id}"". publishDir ""${params.outdir}/6.variantM"", mode: 'copy'. cpus 16. input:. tuple val(sample_id), path(read_files). val(params.reference). val(params.bed_file). . output:. tuple val(sample_id), path(""${sample_id}_raw.vcf.gz""), path(""${sample_id}_raw.gvcf.gz""), emit: raw_vcfs. script:. """""". sudo docker run \. -v ""${PWD}"":""${PWD}"" \. google/deepvariant:1.6.1 \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref ${PWD}/${params.reference} \. --reads ${PWD}/output/4.markDuplicate/${sample_id}_sorted_md.bam \. --regions ${PWD}/${params.bed_file} \. --output_vcf ${PWD}/${params.outdir}/${sample_id}_raw.vcf.gz \. --output_gvcf ${PWD}/${sample_id}_raw.gvcf.gz \. --num_shards ${task.cpus}. --intermediate_results_dir ${PWD}/tmp > deepvariant_log.txt 2>&1. """""". }. ############# Error ###################. N E X T F L O W ~ version 24.04.4. Launching `dip.nf` [deadly_pike] DSL2 - revision: e075b1fba0. executor > local (2). [a6/9c6b79] process > deepvar (Germline Variant on SRR26512959) [ 0%] 0 of 2. ERROR ~ Error executing process > 'deepvar (Germline Variant on SRR26512958)'. executor > local (2). [a6/9c6b79] process > deepvar (Germline Variant on SRR26512959) [100%] 1 of 1, failed: 1. ERROR ~ Error executing process > 'deepvar (Germline Variant on SRR26512958)'. Caused by:. Process `deepvar (Germline Variant on SRR26512958)` terminated with an error exit status (127). Command executed:. sudo docker run -v ""/home/ubuntu/dd/nextflow2"":""/home/ubuntu/dd/nextflow2"" google/deepvariant:1.6.1 /opt/deepvariant/bin/run_deepvariant --model_type WES --ref /home/ubuntu/dd/nextflow2/reference/Homo_sapiens_assembly38.fasta --reads /home/ubuntu/dd/nextflow2/output/4.markDuplicate/SRR26512958_sorted_md.bam --regions /home/ubuntu/dd/nextflow2/reference/hg38_exome.bed --output_vcf",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/883:1735,performance,ERROR,ERROR,1735,"ams.outdir}/6.variantM"", mode: 'copy'. cpus 16. input:. tuple val(sample_id), path(read_files). val(params.reference). val(params.bed_file). . output:. tuple val(sample_id), path(""${sample_id}_raw.vcf.gz""), path(""${sample_id}_raw.gvcf.gz""), emit: raw_vcfs. script:. """""". sudo docker run \. -v ""${PWD}"":""${PWD}"" \. google/deepvariant:1.6.1 \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref ${PWD}/${params.reference} \. --reads ${PWD}/output/4.markDuplicate/${sample_id}_sorted_md.bam \. --regions ${PWD}/${params.bed_file} \. --output_vcf ${PWD}/${params.outdir}/${sample_id}_raw.vcf.gz \. --output_gvcf ${PWD}/${sample_id}_raw.gvcf.gz \. --num_shards ${task.cpus}. --intermediate_results_dir ${PWD}/tmp > deepvariant_log.txt 2>&1. """""". }. ############# Error ###################. N E X T F L O W ~ version 24.04.4. Launching `dip.nf` [deadly_pike] DSL2 - revision: e075b1fba0. executor > local (2). [a6/9c6b79] process > deepvar (Germline Variant on SRR26512959) [ 0%] 0 of 2. ERROR ~ Error executing process > 'deepvar (Germline Variant on SRR26512958)'. executor > local (2). [a6/9c6b79] process > deepvar (Germline Variant on SRR26512959) [100%] 1 of 1, failed: 1. ERROR ~ Error executing process > 'deepvar (Germline Variant on SRR26512958)'. Caused by:. Process `deepvar (Germline Variant on SRR26512958)` terminated with an error exit status (127). Command executed:. sudo docker run -v ""/home/ubuntu/dd/nextflow2"":""/home/ubuntu/dd/nextflow2"" google/deepvariant:1.6.1 /opt/deepvariant/bin/run_deepvariant --model_type WES --ref /home/ubuntu/dd/nextflow2/reference/Homo_sapiens_assembly38.fasta --reads /home/ubuntu/dd/nextflow2/output/4.markDuplicate/SRR26512958_sorted_md.bam --regions /home/ubuntu/dd/nextflow2/reference/hg38_exome.bed --output_vcf /home/ubuntu/dd/nextflow2/output/5.snvS/SRR26512958_raw.vcf.gz --output_gvcf /home/ubuntu/dd/nextflow2/SRR26512958_raw.gvcf.gz --num_shards 16. --intermediate_results_dir /home/ubuntu/dd/nextflow2/tmp > deepvariant_log.txt ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/883:1743,performance,Error,Error,1743,"ir}/6.variantM"", mode: 'copy'. cpus 16. input:. tuple val(sample_id), path(read_files). val(params.reference). val(params.bed_file). . output:. tuple val(sample_id), path(""${sample_id}_raw.vcf.gz""), path(""${sample_id}_raw.gvcf.gz""), emit: raw_vcfs. script:. """""". sudo docker run \. -v ""${PWD}"":""${PWD}"" \. google/deepvariant:1.6.1 \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref ${PWD}/${params.reference} \. --reads ${PWD}/output/4.markDuplicate/${sample_id}_sorted_md.bam \. --regions ${PWD}/${params.bed_file} \. --output_vcf ${PWD}/${params.outdir}/${sample_id}_raw.vcf.gz \. --output_gvcf ${PWD}/${sample_id}_raw.gvcf.gz \. --num_shards ${task.cpus}. --intermediate_results_dir ${PWD}/tmp > deepvariant_log.txt 2>&1. """""". }. ############# Error ###################. N E X T F L O W ~ version 24.04.4. Launching `dip.nf` [deadly_pike] DSL2 - revision: e075b1fba0. executor > local (2). [a6/9c6b79] process > deepvar (Germline Variant on SRR26512959) [ 0%] 0 of 2. ERROR ~ Error executing process > 'deepvar (Germline Variant on SRR26512958)'. executor > local (2). [a6/9c6b79] process > deepvar (Germline Variant on SRR26512959) [100%] 1 of 1, failed: 1. ERROR ~ Error executing process > 'deepvar (Germline Variant on SRR26512958)'. Caused by:. Process `deepvar (Germline Variant on SRR26512958)` terminated with an error exit status (127). Command executed:. sudo docker run -v ""/home/ubuntu/dd/nextflow2"":""/home/ubuntu/dd/nextflow2"" google/deepvariant:1.6.1 /opt/deepvariant/bin/run_deepvariant --model_type WES --ref /home/ubuntu/dd/nextflow2/reference/Homo_sapiens_assembly38.fasta --reads /home/ubuntu/dd/nextflow2/output/4.markDuplicate/SRR26512958_sorted_md.bam --regions /home/ubuntu/dd/nextflow2/reference/hg38_exome.bed --output_vcf /home/ubuntu/dd/nextflow2/output/5.snvS/SRR26512958_raw.vcf.gz --output_gvcf /home/ubuntu/dd/nextflow2/SRR26512958_raw.gvcf.gz --num_shards 16. --intermediate_results_dir /home/ubuntu/dd/nextflow2/tmp > deepvariant_log.txt 2>&1. Co",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/883:1926,performance,ERROR,ERROR,1926,"}_raw.vcf.gz""), path(""${sample_id}_raw.gvcf.gz""), emit: raw_vcfs. script:. """""". sudo docker run \. -v ""${PWD}"":""${PWD}"" \. google/deepvariant:1.6.1 \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref ${PWD}/${params.reference} \. --reads ${PWD}/output/4.markDuplicate/${sample_id}_sorted_md.bam \. --regions ${PWD}/${params.bed_file} \. --output_vcf ${PWD}/${params.outdir}/${sample_id}_raw.vcf.gz \. --output_gvcf ${PWD}/${sample_id}_raw.gvcf.gz \. --num_shards ${task.cpus}. --intermediate_results_dir ${PWD}/tmp > deepvariant_log.txt 2>&1. """""". }. ############# Error ###################. N E X T F L O W ~ version 24.04.4. Launching `dip.nf` [deadly_pike] DSL2 - revision: e075b1fba0. executor > local (2). [a6/9c6b79] process > deepvar (Germline Variant on SRR26512959) [ 0%] 0 of 2. ERROR ~ Error executing process > 'deepvar (Germline Variant on SRR26512958)'. executor > local (2). [a6/9c6b79] process > deepvar (Germline Variant on SRR26512959) [100%] 1 of 1, failed: 1. ERROR ~ Error executing process > 'deepvar (Germline Variant on SRR26512958)'. Caused by:. Process `deepvar (Germline Variant on SRR26512958)` terminated with an error exit status (127). Command executed:. sudo docker run -v ""/home/ubuntu/dd/nextflow2"":""/home/ubuntu/dd/nextflow2"" google/deepvariant:1.6.1 /opt/deepvariant/bin/run_deepvariant --model_type WES --ref /home/ubuntu/dd/nextflow2/reference/Homo_sapiens_assembly38.fasta --reads /home/ubuntu/dd/nextflow2/output/4.markDuplicate/SRR26512958_sorted_md.bam --regions /home/ubuntu/dd/nextflow2/reference/hg38_exome.bed --output_vcf /home/ubuntu/dd/nextflow2/output/5.snvS/SRR26512958_raw.vcf.gz --output_gvcf /home/ubuntu/dd/nextflow2/SRR26512958_raw.gvcf.gz --num_shards 16. --intermediate_results_dir /home/ubuntu/dd/nextflow2/tmp > deepvariant_log.txt 2>&1. Command exit status:. 127. Command output:. (empty). Command error:. docker: Error response from daemon: open /var/lib/docker/overlay2/fe3663cd03e849890d83be14603f217249f3f43f9585b554df",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/883:1934,performance,Error,Error,1934,"f.gz""), path(""${sample_id}_raw.gvcf.gz""), emit: raw_vcfs. script:. """""". sudo docker run \. -v ""${PWD}"":""${PWD}"" \. google/deepvariant:1.6.1 \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref ${PWD}/${params.reference} \. --reads ${PWD}/output/4.markDuplicate/${sample_id}_sorted_md.bam \. --regions ${PWD}/${params.bed_file} \. --output_vcf ${PWD}/${params.outdir}/${sample_id}_raw.vcf.gz \. --output_gvcf ${PWD}/${sample_id}_raw.gvcf.gz \. --num_shards ${task.cpus}. --intermediate_results_dir ${PWD}/tmp > deepvariant_log.txt 2>&1. """""". }. ############# Error ###################. N E X T F L O W ~ version 24.04.4. Launching `dip.nf` [deadly_pike] DSL2 - revision: e075b1fba0. executor > local (2). [a6/9c6b79] process > deepvar (Germline Variant on SRR26512959) [ 0%] 0 of 2. ERROR ~ Error executing process > 'deepvar (Germline Variant on SRR26512958)'. executor > local (2). [a6/9c6b79] process > deepvar (Germline Variant on SRR26512959) [100%] 1 of 1, failed: 1. ERROR ~ Error executing process > 'deepvar (Germline Variant on SRR26512958)'. Caused by:. Process `deepvar (Germline Variant on SRR26512958)` terminated with an error exit status (127). Command executed:. sudo docker run -v ""/home/ubuntu/dd/nextflow2"":""/home/ubuntu/dd/nextflow2"" google/deepvariant:1.6.1 /opt/deepvariant/bin/run_deepvariant --model_type WES --ref /home/ubuntu/dd/nextflow2/reference/Homo_sapiens_assembly38.fasta --reads /home/ubuntu/dd/nextflow2/output/4.markDuplicate/SRR26512958_sorted_md.bam --regions /home/ubuntu/dd/nextflow2/reference/hg38_exome.bed --output_vcf /home/ubuntu/dd/nextflow2/output/5.snvS/SRR26512958_raw.vcf.gz --output_gvcf /home/ubuntu/dd/nextflow2/SRR26512958_raw.gvcf.gz --num_shards 16. --intermediate_results_dir /home/ubuntu/dd/nextflow2/tmp > deepvariant_log.txt 2>&1. Command exit status:. 127. Command output:. (empty). Command error:. docker: Error response from daemon: open /var/lib/docker/overlay2/fe3663cd03e849890d83be14603f217249f3f43f9585b554df599d0318",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/883:2088,performance,error,error,2088,"riant/bin/run_deepvariant \. --model_type WES \. --ref ${PWD}/${params.reference} \. --reads ${PWD}/output/4.markDuplicate/${sample_id}_sorted_md.bam \. --regions ${PWD}/${params.bed_file} \. --output_vcf ${PWD}/${params.outdir}/${sample_id}_raw.vcf.gz \. --output_gvcf ${PWD}/${sample_id}_raw.gvcf.gz \. --num_shards ${task.cpus}. --intermediate_results_dir ${PWD}/tmp > deepvariant_log.txt 2>&1. """""". }. ############# Error ###################. N E X T F L O W ~ version 24.04.4. Launching `dip.nf` [deadly_pike] DSL2 - revision: e075b1fba0. executor > local (2). [a6/9c6b79] process > deepvar (Germline Variant on SRR26512959) [ 0%] 0 of 2. ERROR ~ Error executing process > 'deepvar (Germline Variant on SRR26512958)'. executor > local (2). [a6/9c6b79] process > deepvar (Germline Variant on SRR26512959) [100%] 1 of 1, failed: 1. ERROR ~ Error executing process > 'deepvar (Germline Variant on SRR26512958)'. Caused by:. Process `deepvar (Germline Variant on SRR26512958)` terminated with an error exit status (127). Command executed:. sudo docker run -v ""/home/ubuntu/dd/nextflow2"":""/home/ubuntu/dd/nextflow2"" google/deepvariant:1.6.1 /opt/deepvariant/bin/run_deepvariant --model_type WES --ref /home/ubuntu/dd/nextflow2/reference/Homo_sapiens_assembly38.fasta --reads /home/ubuntu/dd/nextflow2/output/4.markDuplicate/SRR26512958_sorted_md.bam --regions /home/ubuntu/dd/nextflow2/reference/hg38_exome.bed --output_vcf /home/ubuntu/dd/nextflow2/output/5.snvS/SRR26512958_raw.vcf.gz --output_gvcf /home/ubuntu/dd/nextflow2/SRR26512958_raw.gvcf.gz --num_shards 16. --intermediate_results_dir /home/ubuntu/dd/nextflow2/tmp > deepvariant_log.txt 2>&1. Command exit status:. 127. Command output:. (empty). Command error:. docker: Error response from daemon: open /var/lib/docker/overlay2/fe3663cd03e849890d83be14603f217249f3f43f9585b554df599d0318909f21/.tmp-committed2046174062: no such file or directory. See 'docker run --help'. Work dir:. /home/ubuntu/dd/nextflow2/work/ea/9ecd306270fe3f00d9b73f82",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/883:2805,performance,error,error,2805,"bed_file} \. --output_vcf ${PWD}/${params.outdir}/${sample_id}_raw.vcf.gz \. --output_gvcf ${PWD}/${sample_id}_raw.gvcf.gz \. --num_shards ${task.cpus}. --intermediate_results_dir ${PWD}/tmp > deepvariant_log.txt 2>&1. """""". }. ############# Error ###################. N E X T F L O W ~ version 24.04.4. Launching `dip.nf` [deadly_pike] DSL2 - revision: e075b1fba0. executor > local (2). [a6/9c6b79] process > deepvar (Germline Variant on SRR26512959) [ 0%] 0 of 2. ERROR ~ Error executing process > 'deepvar (Germline Variant on SRR26512958)'. executor > local (2). [a6/9c6b79] process > deepvar (Germline Variant on SRR26512959) [100%] 1 of 1, failed: 1. ERROR ~ Error executing process > 'deepvar (Germline Variant on SRR26512958)'. Caused by:. Process `deepvar (Germline Variant on SRR26512958)` terminated with an error exit status (127). Command executed:. sudo docker run -v ""/home/ubuntu/dd/nextflow2"":""/home/ubuntu/dd/nextflow2"" google/deepvariant:1.6.1 /opt/deepvariant/bin/run_deepvariant --model_type WES --ref /home/ubuntu/dd/nextflow2/reference/Homo_sapiens_assembly38.fasta --reads /home/ubuntu/dd/nextflow2/output/4.markDuplicate/SRR26512958_sorted_md.bam --regions /home/ubuntu/dd/nextflow2/reference/hg38_exome.bed --output_vcf /home/ubuntu/dd/nextflow2/output/5.snvS/SRR26512958_raw.vcf.gz --output_gvcf /home/ubuntu/dd/nextflow2/SRR26512958_raw.gvcf.gz --num_shards 16. --intermediate_results_dir /home/ubuntu/dd/nextflow2/tmp > deepvariant_log.txt 2>&1. Command exit status:. 127. Command output:. (empty). Command error:. docker: Error response from daemon: open /var/lib/docker/overlay2/fe3663cd03e849890d83be14603f217249f3f43f9585b554df599d0318909f21/.tmp-committed2046174062: no such file or directory. See 'docker run --help'. Work dir:. /home/ubuntu/dd/nextflow2/work/ea/9ecd306270fe3f00d9b73f8261fe89. Tip: you can try to figure out what's wrong by changing to the process work dir and showing the script file named `.command.sh`. -- Check '.nextflow.log' file for details.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/883:2821,performance,Error,Error,2821,"bed_file} \. --output_vcf ${PWD}/${params.outdir}/${sample_id}_raw.vcf.gz \. --output_gvcf ${PWD}/${sample_id}_raw.gvcf.gz \. --num_shards ${task.cpus}. --intermediate_results_dir ${PWD}/tmp > deepvariant_log.txt 2>&1. """""". }. ############# Error ###################. N E X T F L O W ~ version 24.04.4. Launching `dip.nf` [deadly_pike] DSL2 - revision: e075b1fba0. executor > local (2). [a6/9c6b79] process > deepvar (Germline Variant on SRR26512959) [ 0%] 0 of 2. ERROR ~ Error executing process > 'deepvar (Germline Variant on SRR26512958)'. executor > local (2). [a6/9c6b79] process > deepvar (Germline Variant on SRR26512959) [100%] 1 of 1, failed: 1. ERROR ~ Error executing process > 'deepvar (Germline Variant on SRR26512958)'. Caused by:. Process `deepvar (Germline Variant on SRR26512958)` terminated with an error exit status (127). Command executed:. sudo docker run -v ""/home/ubuntu/dd/nextflow2"":""/home/ubuntu/dd/nextflow2"" google/deepvariant:1.6.1 /opt/deepvariant/bin/run_deepvariant --model_type WES --ref /home/ubuntu/dd/nextflow2/reference/Homo_sapiens_assembly38.fasta --reads /home/ubuntu/dd/nextflow2/output/4.markDuplicate/SRR26512958_sorted_md.bam --regions /home/ubuntu/dd/nextflow2/reference/hg38_exome.bed --output_vcf /home/ubuntu/dd/nextflow2/output/5.snvS/SRR26512958_raw.vcf.gz --output_gvcf /home/ubuntu/dd/nextflow2/SRR26512958_raw.gvcf.gz --num_shards 16. --intermediate_results_dir /home/ubuntu/dd/nextflow2/tmp > deepvariant_log.txt 2>&1. Command exit status:. 127. Command output:. (empty). Command error:. docker: Error response from daemon: open /var/lib/docker/overlay2/fe3663cd03e849890d83be14603f217249f3f43f9585b554df599d0318909f21/.tmp-committed2046174062: no such file or directory. See 'docker run --help'. Work dir:. /home/ubuntu/dd/nextflow2/work/ea/9ecd306270fe3f00d9b73f8261fe89. Tip: you can try to figure out what's wrong by changing to the process work dir and showing the script file named `.command.sh`. -- Check '.nextflow.log' file for details.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/883:1915,reliability,fail,failed,1915,"${sample_id}_raw.vcf.gz""), path(""${sample_id}_raw.gvcf.gz""), emit: raw_vcfs. script:. """""". sudo docker run \. -v ""${PWD}"":""${PWD}"" \. google/deepvariant:1.6.1 \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref ${PWD}/${params.reference} \. --reads ${PWD}/output/4.markDuplicate/${sample_id}_sorted_md.bam \. --regions ${PWD}/${params.bed_file} \. --output_vcf ${PWD}/${params.outdir}/${sample_id}_raw.vcf.gz \. --output_gvcf ${PWD}/${sample_id}_raw.gvcf.gz \. --num_shards ${task.cpus}. --intermediate_results_dir ${PWD}/tmp > deepvariant_log.txt 2>&1. """""". }. ############# Error ###################. N E X T F L O W ~ version 24.04.4. Launching `dip.nf` [deadly_pike] DSL2 - revision: e075b1fba0. executor > local (2). [a6/9c6b79] process > deepvar (Germline Variant on SRR26512959) [ 0%] 0 of 2. ERROR ~ Error executing process > 'deepvar (Germline Variant on SRR26512958)'. executor > local (2). [a6/9c6b79] process > deepvar (Germline Variant on SRR26512959) [100%] 1 of 1, failed: 1. ERROR ~ Error executing process > 'deepvar (Germline Variant on SRR26512958)'. Caused by:. Process `deepvar (Germline Variant on SRR26512958)` terminated with an error exit status (127). Command executed:. sudo docker run -v ""/home/ubuntu/dd/nextflow2"":""/home/ubuntu/dd/nextflow2"" google/deepvariant:1.6.1 /opt/deepvariant/bin/run_deepvariant --model_type WES --ref /home/ubuntu/dd/nextflow2/reference/Homo_sapiens_assembly38.fasta --reads /home/ubuntu/dd/nextflow2/output/4.markDuplicate/SRR26512958_sorted_md.bam --regions /home/ubuntu/dd/nextflow2/reference/hg38_exome.bed --output_vcf /home/ubuntu/dd/nextflow2/output/5.snvS/SRR26512958_raw.vcf.gz --output_gvcf /home/ubuntu/dd/nextflow2/SRR26512958_raw.gvcf.gz --num_shards 16. --intermediate_results_dir /home/ubuntu/dd/nextflow2/tmp > deepvariant_log.txt 2>&1. Command exit status:. 127. Command output:. (empty). Command error:. docker: Error response from daemon: open /var/lib/docker/overlay2/fe3663cd03e849890d83be14603f217249f3f43",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/883:356,safety,input,input,356,"Running deepvariant within Nextflow DSL2; . #!/usr/bin/env nextflow . nextflow.enable.dsl=2. params.data_dir = 'output/4.markDuplicate'. params.reference = 'reference/Homo_sapiens_assembly38.fasta'. params.bed_file = 'reference/hg38_exome.bed'. params.outdir = 'output/5.snvS'. params.cpus = 16 // Number of CPUs to use. workflow {. // Define channels for input data. Channel. .fromPath(""${PWD}${params.data_dir}/*_sorted_md.bam""). .map { file ->. def sample_id = file.baseName.replace('_sorted_md', ''). return [sample_id, file]. }. .set { read_pairs }. // Process steps. /// Germline variant calling. deepvar(read_pairs, params.reference, params.bed_file). }. process deepvar {. tag ""Germline Variant on ${sample_id}"". publishDir ""${params.outdir}/6.variantM"", mode: 'copy'. cpus 16. input:. tuple val(sample_id), path(read_files). val(params.reference). val(params.bed_file). . output:. tuple val(sample_id), path(""${sample_id}_raw.vcf.gz""), path(""${sample_id}_raw.gvcf.gz""), emit: raw_vcfs. script:. """""". sudo docker run \. -v ""${PWD}"":""${PWD}"" \. google/deepvariant:1.6.1 \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref ${PWD}/${params.reference} \. --reads ${PWD}/output/4.markDuplicate/${sample_id}_sorted_md.bam \. --regions ${PWD}/${params.bed_file} \. --output_vcf ${PWD}/${params.outdir}/${sample_id}_raw.vcf.gz \. --output_gvcf ${PWD}/${sample_id}_raw.gvcf.gz \. --num_shards ${task.cpus}. --intermediate_results_dir ${PWD}/tmp > deepvariant_log.txt 2>&1. """""". }. ############# Error ###################. N E X T F L O W ~ version 24.04.4. Launching `dip.nf` [deadly_pike] DSL2 - revision: e075b1fba0. executor > local (2). [a6/9c6b79] process > deepvar (Germline Variant on SRR26512959) [ 0%] 0 of 2. ERROR ~ Error executing process > 'deepvar (Germline Variant on SRR26512958)'. executor > local (2). [a6/9c6b79] process > deepvar (Germline Variant on SRR26512959) [100%] 1 of 1, failed: 1. ERROR ~ Error executing process > 'deepvar (Germline Variant on SRR2651295",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/883:786,safety,input,input,786,"Running deepvariant within Nextflow DSL2; . #!/usr/bin/env nextflow . nextflow.enable.dsl=2. params.data_dir = 'output/4.markDuplicate'. params.reference = 'reference/Homo_sapiens_assembly38.fasta'. params.bed_file = 'reference/hg38_exome.bed'. params.outdir = 'output/5.snvS'. params.cpus = 16 // Number of CPUs to use. workflow {. // Define channels for input data. Channel. .fromPath(""${PWD}${params.data_dir}/*_sorted_md.bam""). .map { file ->. def sample_id = file.baseName.replace('_sorted_md', ''). return [sample_id, file]. }. .set { read_pairs }. // Process steps. /// Germline variant calling. deepvar(read_pairs, params.reference, params.bed_file). }. process deepvar {. tag ""Germline Variant on ${sample_id}"". publishDir ""${params.outdir}/6.variantM"", mode: 'copy'. cpus 16. input:. tuple val(sample_id), path(read_files). val(params.reference). val(params.bed_file). . output:. tuple val(sample_id), path(""${sample_id}_raw.vcf.gz""), path(""${sample_id}_raw.gvcf.gz""), emit: raw_vcfs. script:. """""". sudo docker run \. -v ""${PWD}"":""${PWD}"" \. google/deepvariant:1.6.1 \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref ${PWD}/${params.reference} \. --reads ${PWD}/output/4.markDuplicate/${sample_id}_sorted_md.bam \. --regions ${PWD}/${params.bed_file} \. --output_vcf ${PWD}/${params.outdir}/${sample_id}_raw.vcf.gz \. --output_gvcf ${PWD}/${sample_id}_raw.gvcf.gz \. --num_shards ${task.cpus}. --intermediate_results_dir ${PWD}/tmp > deepvariant_log.txt 2>&1. """""". }. ############# Error ###################. N E X T F L O W ~ version 24.04.4. Launching `dip.nf` [deadly_pike] DSL2 - revision: e075b1fba0. executor > local (2). [a6/9c6b79] process > deepvar (Germline Variant on SRR26512959) [ 0%] 0 of 2. ERROR ~ Error executing process > 'deepvar (Germline Variant on SRR26512958)'. executor > local (2). [a6/9c6b79] process > deepvar (Germline Variant on SRR26512959) [100%] 1 of 1, failed: 1. ERROR ~ Error executing process > 'deepvar (Germline Variant on SRR2651295",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/883:1511,safety,Error,Error,1511,"ample_id, file]. }. .set { read_pairs }. // Process steps. /// Germline variant calling. deepvar(read_pairs, params.reference, params.bed_file). }. process deepvar {. tag ""Germline Variant on ${sample_id}"". publishDir ""${params.outdir}/6.variantM"", mode: 'copy'. cpus 16. input:. tuple val(sample_id), path(read_files). val(params.reference). val(params.bed_file). . output:. tuple val(sample_id), path(""${sample_id}_raw.vcf.gz""), path(""${sample_id}_raw.gvcf.gz""), emit: raw_vcfs. script:. """""". sudo docker run \. -v ""${PWD}"":""${PWD}"" \. google/deepvariant:1.6.1 \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref ${PWD}/${params.reference} \. --reads ${PWD}/output/4.markDuplicate/${sample_id}_sorted_md.bam \. --regions ${PWD}/${params.bed_file} \. --output_vcf ${PWD}/${params.outdir}/${sample_id}_raw.vcf.gz \. --output_gvcf ${PWD}/${sample_id}_raw.gvcf.gz \. --num_shards ${task.cpus}. --intermediate_results_dir ${PWD}/tmp > deepvariant_log.txt 2>&1. """""". }. ############# Error ###################. N E X T F L O W ~ version 24.04.4. Launching `dip.nf` [deadly_pike] DSL2 - revision: e075b1fba0. executor > local (2). [a6/9c6b79] process > deepvar (Germline Variant on SRR26512959) [ 0%] 0 of 2. ERROR ~ Error executing process > 'deepvar (Germline Variant on SRR26512958)'. executor > local (2). [a6/9c6b79] process > deepvar (Germline Variant on SRR26512959) [100%] 1 of 1, failed: 1. ERROR ~ Error executing process > 'deepvar (Germline Variant on SRR26512958)'. Caused by:. Process `deepvar (Germline Variant on SRR26512958)` terminated with an error exit status (127). Command executed:. sudo docker run -v ""/home/ubuntu/dd/nextflow2"":""/home/ubuntu/dd/nextflow2"" google/deepvariant:1.6.1 /opt/deepvariant/bin/run_deepvariant --model_type WES --ref /home/ubuntu/dd/nextflow2/reference/Homo_sapiens_assembly38.fasta --reads /home/ubuntu/dd/nextflow2/output/4.markDuplicate/SRR26512958_sorted_md.bam --regions /home/ubuntu/dd/nextflow2/reference/hg38_exome.bed --output_vcf",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/883:1735,safety,ERROR,ERROR,1735,"ams.outdir}/6.variantM"", mode: 'copy'. cpus 16. input:. tuple val(sample_id), path(read_files). val(params.reference). val(params.bed_file). . output:. tuple val(sample_id), path(""${sample_id}_raw.vcf.gz""), path(""${sample_id}_raw.gvcf.gz""), emit: raw_vcfs. script:. """""". sudo docker run \. -v ""${PWD}"":""${PWD}"" \. google/deepvariant:1.6.1 \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref ${PWD}/${params.reference} \. --reads ${PWD}/output/4.markDuplicate/${sample_id}_sorted_md.bam \. --regions ${PWD}/${params.bed_file} \. --output_vcf ${PWD}/${params.outdir}/${sample_id}_raw.vcf.gz \. --output_gvcf ${PWD}/${sample_id}_raw.gvcf.gz \. --num_shards ${task.cpus}. --intermediate_results_dir ${PWD}/tmp > deepvariant_log.txt 2>&1. """""". }. ############# Error ###################. N E X T F L O W ~ version 24.04.4. Launching `dip.nf` [deadly_pike] DSL2 - revision: e075b1fba0. executor > local (2). [a6/9c6b79] process > deepvar (Germline Variant on SRR26512959) [ 0%] 0 of 2. ERROR ~ Error executing process > 'deepvar (Germline Variant on SRR26512958)'. executor > local (2). [a6/9c6b79] process > deepvar (Germline Variant on SRR26512959) [100%] 1 of 1, failed: 1. ERROR ~ Error executing process > 'deepvar (Germline Variant on SRR26512958)'. Caused by:. Process `deepvar (Germline Variant on SRR26512958)` terminated with an error exit status (127). Command executed:. sudo docker run -v ""/home/ubuntu/dd/nextflow2"":""/home/ubuntu/dd/nextflow2"" google/deepvariant:1.6.1 /opt/deepvariant/bin/run_deepvariant --model_type WES --ref /home/ubuntu/dd/nextflow2/reference/Homo_sapiens_assembly38.fasta --reads /home/ubuntu/dd/nextflow2/output/4.markDuplicate/SRR26512958_sorted_md.bam --regions /home/ubuntu/dd/nextflow2/reference/hg38_exome.bed --output_vcf /home/ubuntu/dd/nextflow2/output/5.snvS/SRR26512958_raw.vcf.gz --output_gvcf /home/ubuntu/dd/nextflow2/SRR26512958_raw.gvcf.gz --num_shards 16. --intermediate_results_dir /home/ubuntu/dd/nextflow2/tmp > deepvariant_log.txt ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/883:1743,safety,Error,Error,1743,"ir}/6.variantM"", mode: 'copy'. cpus 16. input:. tuple val(sample_id), path(read_files). val(params.reference). val(params.bed_file). . output:. tuple val(sample_id), path(""${sample_id}_raw.vcf.gz""), path(""${sample_id}_raw.gvcf.gz""), emit: raw_vcfs. script:. """""". sudo docker run \. -v ""${PWD}"":""${PWD}"" \. google/deepvariant:1.6.1 \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref ${PWD}/${params.reference} \. --reads ${PWD}/output/4.markDuplicate/${sample_id}_sorted_md.bam \. --regions ${PWD}/${params.bed_file} \. --output_vcf ${PWD}/${params.outdir}/${sample_id}_raw.vcf.gz \. --output_gvcf ${PWD}/${sample_id}_raw.gvcf.gz \. --num_shards ${task.cpus}. --intermediate_results_dir ${PWD}/tmp > deepvariant_log.txt 2>&1. """""". }. ############# Error ###################. N E X T F L O W ~ version 24.04.4. Launching `dip.nf` [deadly_pike] DSL2 - revision: e075b1fba0. executor > local (2). [a6/9c6b79] process > deepvar (Germline Variant on SRR26512959) [ 0%] 0 of 2. ERROR ~ Error executing process > 'deepvar (Germline Variant on SRR26512958)'. executor > local (2). [a6/9c6b79] process > deepvar (Germline Variant on SRR26512959) [100%] 1 of 1, failed: 1. ERROR ~ Error executing process > 'deepvar (Germline Variant on SRR26512958)'. Caused by:. Process `deepvar (Germline Variant on SRR26512958)` terminated with an error exit status (127). Command executed:. sudo docker run -v ""/home/ubuntu/dd/nextflow2"":""/home/ubuntu/dd/nextflow2"" google/deepvariant:1.6.1 /opt/deepvariant/bin/run_deepvariant --model_type WES --ref /home/ubuntu/dd/nextflow2/reference/Homo_sapiens_assembly38.fasta --reads /home/ubuntu/dd/nextflow2/output/4.markDuplicate/SRR26512958_sorted_md.bam --regions /home/ubuntu/dd/nextflow2/reference/hg38_exome.bed --output_vcf /home/ubuntu/dd/nextflow2/output/5.snvS/SRR26512958_raw.vcf.gz --output_gvcf /home/ubuntu/dd/nextflow2/SRR26512958_raw.gvcf.gz --num_shards 16. --intermediate_results_dir /home/ubuntu/dd/nextflow2/tmp > deepvariant_log.txt 2>&1. Co",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/883:1926,safety,ERROR,ERROR,1926,"}_raw.vcf.gz""), path(""${sample_id}_raw.gvcf.gz""), emit: raw_vcfs. script:. """""". sudo docker run \. -v ""${PWD}"":""${PWD}"" \. google/deepvariant:1.6.1 \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref ${PWD}/${params.reference} \. --reads ${PWD}/output/4.markDuplicate/${sample_id}_sorted_md.bam \. --regions ${PWD}/${params.bed_file} \. --output_vcf ${PWD}/${params.outdir}/${sample_id}_raw.vcf.gz \. --output_gvcf ${PWD}/${sample_id}_raw.gvcf.gz \. --num_shards ${task.cpus}. --intermediate_results_dir ${PWD}/tmp > deepvariant_log.txt 2>&1. """""". }. ############# Error ###################. N E X T F L O W ~ version 24.04.4. Launching `dip.nf` [deadly_pike] DSL2 - revision: e075b1fba0. executor > local (2). [a6/9c6b79] process > deepvar (Germline Variant on SRR26512959) [ 0%] 0 of 2. ERROR ~ Error executing process > 'deepvar (Germline Variant on SRR26512958)'. executor > local (2). [a6/9c6b79] process > deepvar (Germline Variant on SRR26512959) [100%] 1 of 1, failed: 1. ERROR ~ Error executing process > 'deepvar (Germline Variant on SRR26512958)'. Caused by:. Process `deepvar (Germline Variant on SRR26512958)` terminated with an error exit status (127). Command executed:. sudo docker run -v ""/home/ubuntu/dd/nextflow2"":""/home/ubuntu/dd/nextflow2"" google/deepvariant:1.6.1 /opt/deepvariant/bin/run_deepvariant --model_type WES --ref /home/ubuntu/dd/nextflow2/reference/Homo_sapiens_assembly38.fasta --reads /home/ubuntu/dd/nextflow2/output/4.markDuplicate/SRR26512958_sorted_md.bam --regions /home/ubuntu/dd/nextflow2/reference/hg38_exome.bed --output_vcf /home/ubuntu/dd/nextflow2/output/5.snvS/SRR26512958_raw.vcf.gz --output_gvcf /home/ubuntu/dd/nextflow2/SRR26512958_raw.gvcf.gz --num_shards 16. --intermediate_results_dir /home/ubuntu/dd/nextflow2/tmp > deepvariant_log.txt 2>&1. Command exit status:. 127. Command output:. (empty). Command error:. docker: Error response from daemon: open /var/lib/docker/overlay2/fe3663cd03e849890d83be14603f217249f3f43f9585b554df",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/883:1934,safety,Error,Error,1934,"f.gz""), path(""${sample_id}_raw.gvcf.gz""), emit: raw_vcfs. script:. """""". sudo docker run \. -v ""${PWD}"":""${PWD}"" \. google/deepvariant:1.6.1 \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref ${PWD}/${params.reference} \. --reads ${PWD}/output/4.markDuplicate/${sample_id}_sorted_md.bam \. --regions ${PWD}/${params.bed_file} \. --output_vcf ${PWD}/${params.outdir}/${sample_id}_raw.vcf.gz \. --output_gvcf ${PWD}/${sample_id}_raw.gvcf.gz \. --num_shards ${task.cpus}. --intermediate_results_dir ${PWD}/tmp > deepvariant_log.txt 2>&1. """""". }. ############# Error ###################. N E X T F L O W ~ version 24.04.4. Launching `dip.nf` [deadly_pike] DSL2 - revision: e075b1fba0. executor > local (2). [a6/9c6b79] process > deepvar (Germline Variant on SRR26512959) [ 0%] 0 of 2. ERROR ~ Error executing process > 'deepvar (Germline Variant on SRR26512958)'. executor > local (2). [a6/9c6b79] process > deepvar (Germline Variant on SRR26512959) [100%] 1 of 1, failed: 1. ERROR ~ Error executing process > 'deepvar (Germline Variant on SRR26512958)'. Caused by:. Process `deepvar (Germline Variant on SRR26512958)` terminated with an error exit status (127). Command executed:. sudo docker run -v ""/home/ubuntu/dd/nextflow2"":""/home/ubuntu/dd/nextflow2"" google/deepvariant:1.6.1 /opt/deepvariant/bin/run_deepvariant --model_type WES --ref /home/ubuntu/dd/nextflow2/reference/Homo_sapiens_assembly38.fasta --reads /home/ubuntu/dd/nextflow2/output/4.markDuplicate/SRR26512958_sorted_md.bam --regions /home/ubuntu/dd/nextflow2/reference/hg38_exome.bed --output_vcf /home/ubuntu/dd/nextflow2/output/5.snvS/SRR26512958_raw.vcf.gz --output_gvcf /home/ubuntu/dd/nextflow2/SRR26512958_raw.gvcf.gz --num_shards 16. --intermediate_results_dir /home/ubuntu/dd/nextflow2/tmp > deepvariant_log.txt 2>&1. Command exit status:. 127. Command output:. (empty). Command error:. docker: Error response from daemon: open /var/lib/docker/overlay2/fe3663cd03e849890d83be14603f217249f3f43f9585b554df599d0318",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/883:2088,safety,error,error,2088,"riant/bin/run_deepvariant \. --model_type WES \. --ref ${PWD}/${params.reference} \. --reads ${PWD}/output/4.markDuplicate/${sample_id}_sorted_md.bam \. --regions ${PWD}/${params.bed_file} \. --output_vcf ${PWD}/${params.outdir}/${sample_id}_raw.vcf.gz \. --output_gvcf ${PWD}/${sample_id}_raw.gvcf.gz \. --num_shards ${task.cpus}. --intermediate_results_dir ${PWD}/tmp > deepvariant_log.txt 2>&1. """""". }. ############# Error ###################. N E X T F L O W ~ version 24.04.4. Launching `dip.nf` [deadly_pike] DSL2 - revision: e075b1fba0. executor > local (2). [a6/9c6b79] process > deepvar (Germline Variant on SRR26512959) [ 0%] 0 of 2. ERROR ~ Error executing process > 'deepvar (Germline Variant on SRR26512958)'. executor > local (2). [a6/9c6b79] process > deepvar (Germline Variant on SRR26512959) [100%] 1 of 1, failed: 1. ERROR ~ Error executing process > 'deepvar (Germline Variant on SRR26512958)'. Caused by:. Process `deepvar (Germline Variant on SRR26512958)` terminated with an error exit status (127). Command executed:. sudo docker run -v ""/home/ubuntu/dd/nextflow2"":""/home/ubuntu/dd/nextflow2"" google/deepvariant:1.6.1 /opt/deepvariant/bin/run_deepvariant --model_type WES --ref /home/ubuntu/dd/nextflow2/reference/Homo_sapiens_assembly38.fasta --reads /home/ubuntu/dd/nextflow2/output/4.markDuplicate/SRR26512958_sorted_md.bam --regions /home/ubuntu/dd/nextflow2/reference/hg38_exome.bed --output_vcf /home/ubuntu/dd/nextflow2/output/5.snvS/SRR26512958_raw.vcf.gz --output_gvcf /home/ubuntu/dd/nextflow2/SRR26512958_raw.gvcf.gz --num_shards 16. --intermediate_results_dir /home/ubuntu/dd/nextflow2/tmp > deepvariant_log.txt 2>&1. Command exit status:. 127. Command output:. (empty). Command error:. docker: Error response from daemon: open /var/lib/docker/overlay2/fe3663cd03e849890d83be14603f217249f3f43f9585b554df599d0318909f21/.tmp-committed2046174062: no such file or directory. See 'docker run --help'. Work dir:. /home/ubuntu/dd/nextflow2/work/ea/9ecd306270fe3f00d9b73f82",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/883:2805,safety,error,error,2805,"bed_file} \. --output_vcf ${PWD}/${params.outdir}/${sample_id}_raw.vcf.gz \. --output_gvcf ${PWD}/${sample_id}_raw.gvcf.gz \. --num_shards ${task.cpus}. --intermediate_results_dir ${PWD}/tmp > deepvariant_log.txt 2>&1. """""". }. ############# Error ###################. N E X T F L O W ~ version 24.04.4. Launching `dip.nf` [deadly_pike] DSL2 - revision: e075b1fba0. executor > local (2). [a6/9c6b79] process > deepvar (Germline Variant on SRR26512959) [ 0%] 0 of 2. ERROR ~ Error executing process > 'deepvar (Germline Variant on SRR26512958)'. executor > local (2). [a6/9c6b79] process > deepvar (Germline Variant on SRR26512959) [100%] 1 of 1, failed: 1. ERROR ~ Error executing process > 'deepvar (Germline Variant on SRR26512958)'. Caused by:. Process `deepvar (Germline Variant on SRR26512958)` terminated with an error exit status (127). Command executed:. sudo docker run -v ""/home/ubuntu/dd/nextflow2"":""/home/ubuntu/dd/nextflow2"" google/deepvariant:1.6.1 /opt/deepvariant/bin/run_deepvariant --model_type WES --ref /home/ubuntu/dd/nextflow2/reference/Homo_sapiens_assembly38.fasta --reads /home/ubuntu/dd/nextflow2/output/4.markDuplicate/SRR26512958_sorted_md.bam --regions /home/ubuntu/dd/nextflow2/reference/hg38_exome.bed --output_vcf /home/ubuntu/dd/nextflow2/output/5.snvS/SRR26512958_raw.vcf.gz --output_gvcf /home/ubuntu/dd/nextflow2/SRR26512958_raw.gvcf.gz --num_shards 16. --intermediate_results_dir /home/ubuntu/dd/nextflow2/tmp > deepvariant_log.txt 2>&1. Command exit status:. 127. Command output:. (empty). Command error:. docker: Error response from daemon: open /var/lib/docker/overlay2/fe3663cd03e849890d83be14603f217249f3f43f9585b554df599d0318909f21/.tmp-committed2046174062: no such file or directory. See 'docker run --help'. Work dir:. /home/ubuntu/dd/nextflow2/work/ea/9ecd306270fe3f00d9b73f8261fe89. Tip: you can try to figure out what's wrong by changing to the process work dir and showing the script file named `.command.sh`. -- Check '.nextflow.log' file for details.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/883:2821,safety,Error,Error,2821,"bed_file} \. --output_vcf ${PWD}/${params.outdir}/${sample_id}_raw.vcf.gz \. --output_gvcf ${PWD}/${sample_id}_raw.gvcf.gz \. --num_shards ${task.cpus}. --intermediate_results_dir ${PWD}/tmp > deepvariant_log.txt 2>&1. """""". }. ############# Error ###################. N E X T F L O W ~ version 24.04.4. Launching `dip.nf` [deadly_pike] DSL2 - revision: e075b1fba0. executor > local (2). [a6/9c6b79] process > deepvar (Germline Variant on SRR26512959) [ 0%] 0 of 2. ERROR ~ Error executing process > 'deepvar (Germline Variant on SRR26512958)'. executor > local (2). [a6/9c6b79] process > deepvar (Germline Variant on SRR26512959) [100%] 1 of 1, failed: 1. ERROR ~ Error executing process > 'deepvar (Germline Variant on SRR26512958)'. Caused by:. Process `deepvar (Germline Variant on SRR26512958)` terminated with an error exit status (127). Command executed:. sudo docker run -v ""/home/ubuntu/dd/nextflow2"":""/home/ubuntu/dd/nextflow2"" google/deepvariant:1.6.1 /opt/deepvariant/bin/run_deepvariant --model_type WES --ref /home/ubuntu/dd/nextflow2/reference/Homo_sapiens_assembly38.fasta --reads /home/ubuntu/dd/nextflow2/output/4.markDuplicate/SRR26512958_sorted_md.bam --regions /home/ubuntu/dd/nextflow2/reference/hg38_exome.bed --output_vcf /home/ubuntu/dd/nextflow2/output/5.snvS/SRR26512958_raw.vcf.gz --output_gvcf /home/ubuntu/dd/nextflow2/SRR26512958_raw.gvcf.gz --num_shards 16. --intermediate_results_dir /home/ubuntu/dd/nextflow2/tmp > deepvariant_log.txt 2>&1. Command exit status:. 127. Command output:. (empty). Command error:. docker: Error response from daemon: open /var/lib/docker/overlay2/fe3663cd03e849890d83be14603f217249f3f43f9585b554df599d0318909f21/.tmp-committed2046174062: no such file or directory. See 'docker run --help'. Work dir:. /home/ubuntu/dd/nextflow2/work/ea/9ecd306270fe3f00d9b73f8261fe89. Tip: you can try to figure out what's wrong by changing to the process work dir and showing the script file named `.command.sh`. -- Check '.nextflow.log' file for details.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/883:3248,safety,log,log,3248,"bed_file} \. --output_vcf ${PWD}/${params.outdir}/${sample_id}_raw.vcf.gz \. --output_gvcf ${PWD}/${sample_id}_raw.gvcf.gz \. --num_shards ${task.cpus}. --intermediate_results_dir ${PWD}/tmp > deepvariant_log.txt 2>&1. """""". }. ############# Error ###################. N E X T F L O W ~ version 24.04.4. Launching `dip.nf` [deadly_pike] DSL2 - revision: e075b1fba0. executor > local (2). [a6/9c6b79] process > deepvar (Germline Variant on SRR26512959) [ 0%] 0 of 2. ERROR ~ Error executing process > 'deepvar (Germline Variant on SRR26512958)'. executor > local (2). [a6/9c6b79] process > deepvar (Germline Variant on SRR26512959) [100%] 1 of 1, failed: 1. ERROR ~ Error executing process > 'deepvar (Germline Variant on SRR26512958)'. Caused by:. Process `deepvar (Germline Variant on SRR26512958)` terminated with an error exit status (127). Command executed:. sudo docker run -v ""/home/ubuntu/dd/nextflow2"":""/home/ubuntu/dd/nextflow2"" google/deepvariant:1.6.1 /opt/deepvariant/bin/run_deepvariant --model_type WES --ref /home/ubuntu/dd/nextflow2/reference/Homo_sapiens_assembly38.fasta --reads /home/ubuntu/dd/nextflow2/output/4.markDuplicate/SRR26512958_sorted_md.bam --regions /home/ubuntu/dd/nextflow2/reference/hg38_exome.bed --output_vcf /home/ubuntu/dd/nextflow2/output/5.snvS/SRR26512958_raw.vcf.gz --output_gvcf /home/ubuntu/dd/nextflow2/SRR26512958_raw.gvcf.gz --num_shards 16. --intermediate_results_dir /home/ubuntu/dd/nextflow2/tmp > deepvariant_log.txt 2>&1. Command exit status:. 127. Command output:. (empty). Command error:. docker: Error response from daemon: open /var/lib/docker/overlay2/fe3663cd03e849890d83be14603f217249f3f43f9585b554df599d0318909f21/.tmp-committed2046174062: no such file or directory. See 'docker run --help'. Work dir:. /home/ubuntu/dd/nextflow2/work/ea/9ecd306270fe3f00d9b73f8261fe89. Tip: you can try to figure out what's wrong by changing to the process work dir and showing the script file named `.command.sh`. -- Check '.nextflow.log' file for details.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/883:3248,security,log,log,3248,"bed_file} \. --output_vcf ${PWD}/${params.outdir}/${sample_id}_raw.vcf.gz \. --output_gvcf ${PWD}/${sample_id}_raw.gvcf.gz \. --num_shards ${task.cpus}. --intermediate_results_dir ${PWD}/tmp > deepvariant_log.txt 2>&1. """""". }. ############# Error ###################. N E X T F L O W ~ version 24.04.4. Launching `dip.nf` [deadly_pike] DSL2 - revision: e075b1fba0. executor > local (2). [a6/9c6b79] process > deepvar (Germline Variant on SRR26512959) [ 0%] 0 of 2. ERROR ~ Error executing process > 'deepvar (Germline Variant on SRR26512958)'. executor > local (2). [a6/9c6b79] process > deepvar (Germline Variant on SRR26512959) [100%] 1 of 1, failed: 1. ERROR ~ Error executing process > 'deepvar (Germline Variant on SRR26512958)'. Caused by:. Process `deepvar (Germline Variant on SRR26512958)` terminated with an error exit status (127). Command executed:. sudo docker run -v ""/home/ubuntu/dd/nextflow2"":""/home/ubuntu/dd/nextflow2"" google/deepvariant:1.6.1 /opt/deepvariant/bin/run_deepvariant --model_type WES --ref /home/ubuntu/dd/nextflow2/reference/Homo_sapiens_assembly38.fasta --reads /home/ubuntu/dd/nextflow2/output/4.markDuplicate/SRR26512958_sorted_md.bam --regions /home/ubuntu/dd/nextflow2/reference/hg38_exome.bed --output_vcf /home/ubuntu/dd/nextflow2/output/5.snvS/SRR26512958_raw.vcf.gz --output_gvcf /home/ubuntu/dd/nextflow2/SRR26512958_raw.gvcf.gz --num_shards 16. --intermediate_results_dir /home/ubuntu/dd/nextflow2/tmp > deepvariant_log.txt 2>&1. Command exit status:. 127. Command output:. (empty). Command error:. docker: Error response from daemon: open /var/lib/docker/overlay2/fe3663cd03e849890d83be14603f217249f3f43f9585b554df599d0318909f21/.tmp-committed2046174062: no such file or directory. See 'docker run --help'. Work dir:. /home/ubuntu/dd/nextflow2/work/ea/9ecd306270fe3f00d9b73f8261fe89. Tip: you can try to figure out what's wrong by changing to the process work dir and showing the script file named `.command.sh`. -- Check '.nextflow.log' file for details.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/883:3248,testability,log,log,3248,"bed_file} \. --output_vcf ${PWD}/${params.outdir}/${sample_id}_raw.vcf.gz \. --output_gvcf ${PWD}/${sample_id}_raw.gvcf.gz \. --num_shards ${task.cpus}. --intermediate_results_dir ${PWD}/tmp > deepvariant_log.txt 2>&1. """""". }. ############# Error ###################. N E X T F L O W ~ version 24.04.4. Launching `dip.nf` [deadly_pike] DSL2 - revision: e075b1fba0. executor > local (2). [a6/9c6b79] process > deepvar (Germline Variant on SRR26512959) [ 0%] 0 of 2. ERROR ~ Error executing process > 'deepvar (Germline Variant on SRR26512958)'. executor > local (2). [a6/9c6b79] process > deepvar (Germline Variant on SRR26512959) [100%] 1 of 1, failed: 1. ERROR ~ Error executing process > 'deepvar (Germline Variant on SRR26512958)'. Caused by:. Process `deepvar (Germline Variant on SRR26512958)` terminated with an error exit status (127). Command executed:. sudo docker run -v ""/home/ubuntu/dd/nextflow2"":""/home/ubuntu/dd/nextflow2"" google/deepvariant:1.6.1 /opt/deepvariant/bin/run_deepvariant --model_type WES --ref /home/ubuntu/dd/nextflow2/reference/Homo_sapiens_assembly38.fasta --reads /home/ubuntu/dd/nextflow2/output/4.markDuplicate/SRR26512958_sorted_md.bam --regions /home/ubuntu/dd/nextflow2/reference/hg38_exome.bed --output_vcf /home/ubuntu/dd/nextflow2/output/5.snvS/SRR26512958_raw.vcf.gz --output_gvcf /home/ubuntu/dd/nextflow2/SRR26512958_raw.gvcf.gz --num_shards 16. --intermediate_results_dir /home/ubuntu/dd/nextflow2/tmp > deepvariant_log.txt 2>&1. Command exit status:. 127. Command output:. (empty). Command error:. docker: Error response from daemon: open /var/lib/docker/overlay2/fe3663cd03e849890d83be14603f217249f3f43f9585b554df599d0318909f21/.tmp-committed2046174062: no such file or directory. See 'docker run --help'. Work dir:. /home/ubuntu/dd/nextflow2/work/ea/9ecd306270fe3f00d9b73f8261fe89. Tip: you can try to figure out what's wrong by changing to the process work dir and showing the script file named `.command.sh`. -- Check '.nextflow.log' file for details.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/883:321,usability,workflow,workflow,321,"Running deepvariant within Nextflow DSL2; . #!/usr/bin/env nextflow . nextflow.enable.dsl=2. params.data_dir = 'output/4.markDuplicate'. params.reference = 'reference/Homo_sapiens_assembly38.fasta'. params.bed_file = 'reference/hg38_exome.bed'. params.outdir = 'output/5.snvS'. params.cpus = 16 // Number of CPUs to use. workflow {. // Define channels for input data. Channel. .fromPath(""${PWD}${params.data_dir}/*_sorted_md.bam""). .map { file ->. def sample_id = file.baseName.replace('_sorted_md', ''). return [sample_id, file]. }. .set { read_pairs }. // Process steps. /// Germline variant calling. deepvar(read_pairs, params.reference, params.bed_file). }. process deepvar {. tag ""Germline Variant on ${sample_id}"". publishDir ""${params.outdir}/6.variantM"", mode: 'copy'. cpus 16. input:. tuple val(sample_id), path(read_files). val(params.reference). val(params.bed_file). . output:. tuple val(sample_id), path(""${sample_id}_raw.vcf.gz""), path(""${sample_id}_raw.gvcf.gz""), emit: raw_vcfs. script:. """""". sudo docker run \. -v ""${PWD}"":""${PWD}"" \. google/deepvariant:1.6.1 \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref ${PWD}/${params.reference} \. --reads ${PWD}/output/4.markDuplicate/${sample_id}_sorted_md.bam \. --regions ${PWD}/${params.bed_file} \. --output_vcf ${PWD}/${params.outdir}/${sample_id}_raw.vcf.gz \. --output_gvcf ${PWD}/${sample_id}_raw.gvcf.gz \. --num_shards ${task.cpus}. --intermediate_results_dir ${PWD}/tmp > deepvariant_log.txt 2>&1. """""". }. ############# Error ###################. N E X T F L O W ~ version 24.04.4. Launching `dip.nf` [deadly_pike] DSL2 - revision: e075b1fba0. executor > local (2). [a6/9c6b79] process > deepvar (Germline Variant on SRR26512959) [ 0%] 0 of 2. ERROR ~ Error executing process > 'deepvar (Germline Variant on SRR26512958)'. executor > local (2). [a6/9c6b79] process > deepvar (Germline Variant on SRR26512959) [100%] 1 of 1, failed: 1. ERROR ~ Error executing process > 'deepvar (Germline Variant on SRR2651295",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/883:356,usability,input,input,356,"Running deepvariant within Nextflow DSL2; . #!/usr/bin/env nextflow . nextflow.enable.dsl=2. params.data_dir = 'output/4.markDuplicate'. params.reference = 'reference/Homo_sapiens_assembly38.fasta'. params.bed_file = 'reference/hg38_exome.bed'. params.outdir = 'output/5.snvS'. params.cpus = 16 // Number of CPUs to use. workflow {. // Define channels for input data. Channel. .fromPath(""${PWD}${params.data_dir}/*_sorted_md.bam""). .map { file ->. def sample_id = file.baseName.replace('_sorted_md', ''). return [sample_id, file]. }. .set { read_pairs }. // Process steps. /// Germline variant calling. deepvar(read_pairs, params.reference, params.bed_file). }. process deepvar {. tag ""Germline Variant on ${sample_id}"". publishDir ""${params.outdir}/6.variantM"", mode: 'copy'. cpus 16. input:. tuple val(sample_id), path(read_files). val(params.reference). val(params.bed_file). . output:. tuple val(sample_id), path(""${sample_id}_raw.vcf.gz""), path(""${sample_id}_raw.gvcf.gz""), emit: raw_vcfs. script:. """""". sudo docker run \. -v ""${PWD}"":""${PWD}"" \. google/deepvariant:1.6.1 \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref ${PWD}/${params.reference} \. --reads ${PWD}/output/4.markDuplicate/${sample_id}_sorted_md.bam \. --regions ${PWD}/${params.bed_file} \. --output_vcf ${PWD}/${params.outdir}/${sample_id}_raw.vcf.gz \. --output_gvcf ${PWD}/${sample_id}_raw.gvcf.gz \. --num_shards ${task.cpus}. --intermediate_results_dir ${PWD}/tmp > deepvariant_log.txt 2>&1. """""". }. ############# Error ###################. N E X T F L O W ~ version 24.04.4. Launching `dip.nf` [deadly_pike] DSL2 - revision: e075b1fba0. executor > local (2). [a6/9c6b79] process > deepvar (Germline Variant on SRR26512959) [ 0%] 0 of 2. ERROR ~ Error executing process > 'deepvar (Germline Variant on SRR26512958)'. executor > local (2). [a6/9c6b79] process > deepvar (Germline Variant on SRR26512959) [100%] 1 of 1, failed: 1. ERROR ~ Error executing process > 'deepvar (Germline Variant on SRR2651295",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/883:786,usability,input,input,786,"Running deepvariant within Nextflow DSL2; . #!/usr/bin/env nextflow . nextflow.enable.dsl=2. params.data_dir = 'output/4.markDuplicate'. params.reference = 'reference/Homo_sapiens_assembly38.fasta'. params.bed_file = 'reference/hg38_exome.bed'. params.outdir = 'output/5.snvS'. params.cpus = 16 // Number of CPUs to use. workflow {. // Define channels for input data. Channel. .fromPath(""${PWD}${params.data_dir}/*_sorted_md.bam""). .map { file ->. def sample_id = file.baseName.replace('_sorted_md', ''). return [sample_id, file]. }. .set { read_pairs }. // Process steps. /// Germline variant calling. deepvar(read_pairs, params.reference, params.bed_file). }. process deepvar {. tag ""Germline Variant on ${sample_id}"". publishDir ""${params.outdir}/6.variantM"", mode: 'copy'. cpus 16. input:. tuple val(sample_id), path(read_files). val(params.reference). val(params.bed_file). . output:. tuple val(sample_id), path(""${sample_id}_raw.vcf.gz""), path(""${sample_id}_raw.gvcf.gz""), emit: raw_vcfs. script:. """""". sudo docker run \. -v ""${PWD}"":""${PWD}"" \. google/deepvariant:1.6.1 \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref ${PWD}/${params.reference} \. --reads ${PWD}/output/4.markDuplicate/${sample_id}_sorted_md.bam \. --regions ${PWD}/${params.bed_file} \. --output_vcf ${PWD}/${params.outdir}/${sample_id}_raw.vcf.gz \. --output_gvcf ${PWD}/${sample_id}_raw.gvcf.gz \. --num_shards ${task.cpus}. --intermediate_results_dir ${PWD}/tmp > deepvariant_log.txt 2>&1. """""". }. ############# Error ###################. N E X T F L O W ~ version 24.04.4. Launching `dip.nf` [deadly_pike] DSL2 - revision: e075b1fba0. executor > local (2). [a6/9c6b79] process > deepvar (Germline Variant on SRR26512959) [ 0%] 0 of 2. ERROR ~ Error executing process > 'deepvar (Germline Variant on SRR26512958)'. executor > local (2). [a6/9c6b79] process > deepvar (Germline Variant on SRR26512959) [100%] 1 of 1, failed: 1. ERROR ~ Error executing process > 'deepvar (Germline Variant on SRR2651295",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/883:1511,usability,Error,Error,1511,"ample_id, file]. }. .set { read_pairs }. // Process steps. /// Germline variant calling. deepvar(read_pairs, params.reference, params.bed_file). }. process deepvar {. tag ""Germline Variant on ${sample_id}"". publishDir ""${params.outdir}/6.variantM"", mode: 'copy'. cpus 16. input:. tuple val(sample_id), path(read_files). val(params.reference). val(params.bed_file). . output:. tuple val(sample_id), path(""${sample_id}_raw.vcf.gz""), path(""${sample_id}_raw.gvcf.gz""), emit: raw_vcfs. script:. """""". sudo docker run \. -v ""${PWD}"":""${PWD}"" \. google/deepvariant:1.6.1 \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref ${PWD}/${params.reference} \. --reads ${PWD}/output/4.markDuplicate/${sample_id}_sorted_md.bam \. --regions ${PWD}/${params.bed_file} \. --output_vcf ${PWD}/${params.outdir}/${sample_id}_raw.vcf.gz \. --output_gvcf ${PWD}/${sample_id}_raw.gvcf.gz \. --num_shards ${task.cpus}. --intermediate_results_dir ${PWD}/tmp > deepvariant_log.txt 2>&1. """""". }. ############# Error ###################. N E X T F L O W ~ version 24.04.4. Launching `dip.nf` [deadly_pike] DSL2 - revision: e075b1fba0. executor > local (2). [a6/9c6b79] process > deepvar (Germline Variant on SRR26512959) [ 0%] 0 of 2. ERROR ~ Error executing process > 'deepvar (Germline Variant on SRR26512958)'. executor > local (2). [a6/9c6b79] process > deepvar (Germline Variant on SRR26512959) [100%] 1 of 1, failed: 1. ERROR ~ Error executing process > 'deepvar (Germline Variant on SRR26512958)'. Caused by:. Process `deepvar (Germline Variant on SRR26512958)` terminated with an error exit status (127). Command executed:. sudo docker run -v ""/home/ubuntu/dd/nextflow2"":""/home/ubuntu/dd/nextflow2"" google/deepvariant:1.6.1 /opt/deepvariant/bin/run_deepvariant --model_type WES --ref /home/ubuntu/dd/nextflow2/reference/Homo_sapiens_assembly38.fasta --reads /home/ubuntu/dd/nextflow2/output/4.markDuplicate/SRR26512958_sorted_md.bam --regions /home/ubuntu/dd/nextflow2/reference/hg38_exome.bed --output_vcf",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/883:1735,usability,ERROR,ERROR,1735,"ams.outdir}/6.variantM"", mode: 'copy'. cpus 16. input:. tuple val(sample_id), path(read_files). val(params.reference). val(params.bed_file). . output:. tuple val(sample_id), path(""${sample_id}_raw.vcf.gz""), path(""${sample_id}_raw.gvcf.gz""), emit: raw_vcfs. script:. """""". sudo docker run \. -v ""${PWD}"":""${PWD}"" \. google/deepvariant:1.6.1 \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref ${PWD}/${params.reference} \. --reads ${PWD}/output/4.markDuplicate/${sample_id}_sorted_md.bam \. --regions ${PWD}/${params.bed_file} \. --output_vcf ${PWD}/${params.outdir}/${sample_id}_raw.vcf.gz \. --output_gvcf ${PWD}/${sample_id}_raw.gvcf.gz \. --num_shards ${task.cpus}. --intermediate_results_dir ${PWD}/tmp > deepvariant_log.txt 2>&1. """""". }. ############# Error ###################. N E X T F L O W ~ version 24.04.4. Launching `dip.nf` [deadly_pike] DSL2 - revision: e075b1fba0. executor > local (2). [a6/9c6b79] process > deepvar (Germline Variant on SRR26512959) [ 0%] 0 of 2. ERROR ~ Error executing process > 'deepvar (Germline Variant on SRR26512958)'. executor > local (2). [a6/9c6b79] process > deepvar (Germline Variant on SRR26512959) [100%] 1 of 1, failed: 1. ERROR ~ Error executing process > 'deepvar (Germline Variant on SRR26512958)'. Caused by:. Process `deepvar (Germline Variant on SRR26512958)` terminated with an error exit status (127). Command executed:. sudo docker run -v ""/home/ubuntu/dd/nextflow2"":""/home/ubuntu/dd/nextflow2"" google/deepvariant:1.6.1 /opt/deepvariant/bin/run_deepvariant --model_type WES --ref /home/ubuntu/dd/nextflow2/reference/Homo_sapiens_assembly38.fasta --reads /home/ubuntu/dd/nextflow2/output/4.markDuplicate/SRR26512958_sorted_md.bam --regions /home/ubuntu/dd/nextflow2/reference/hg38_exome.bed --output_vcf /home/ubuntu/dd/nextflow2/output/5.snvS/SRR26512958_raw.vcf.gz --output_gvcf /home/ubuntu/dd/nextflow2/SRR26512958_raw.gvcf.gz --num_shards 16. --intermediate_results_dir /home/ubuntu/dd/nextflow2/tmp > deepvariant_log.txt ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/883:1743,usability,Error,Error,1743,"ir}/6.variantM"", mode: 'copy'. cpus 16. input:. tuple val(sample_id), path(read_files). val(params.reference). val(params.bed_file). . output:. tuple val(sample_id), path(""${sample_id}_raw.vcf.gz""), path(""${sample_id}_raw.gvcf.gz""), emit: raw_vcfs. script:. """""". sudo docker run \. -v ""${PWD}"":""${PWD}"" \. google/deepvariant:1.6.1 \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref ${PWD}/${params.reference} \. --reads ${PWD}/output/4.markDuplicate/${sample_id}_sorted_md.bam \. --regions ${PWD}/${params.bed_file} \. --output_vcf ${PWD}/${params.outdir}/${sample_id}_raw.vcf.gz \. --output_gvcf ${PWD}/${sample_id}_raw.gvcf.gz \. --num_shards ${task.cpus}. --intermediate_results_dir ${PWD}/tmp > deepvariant_log.txt 2>&1. """""". }. ############# Error ###################. N E X T F L O W ~ version 24.04.4. Launching `dip.nf` [deadly_pike] DSL2 - revision: e075b1fba0. executor > local (2). [a6/9c6b79] process > deepvar (Germline Variant on SRR26512959) [ 0%] 0 of 2. ERROR ~ Error executing process > 'deepvar (Germline Variant on SRR26512958)'. executor > local (2). [a6/9c6b79] process > deepvar (Germline Variant on SRR26512959) [100%] 1 of 1, failed: 1. ERROR ~ Error executing process > 'deepvar (Germline Variant on SRR26512958)'. Caused by:. Process `deepvar (Germline Variant on SRR26512958)` terminated with an error exit status (127). Command executed:. sudo docker run -v ""/home/ubuntu/dd/nextflow2"":""/home/ubuntu/dd/nextflow2"" google/deepvariant:1.6.1 /opt/deepvariant/bin/run_deepvariant --model_type WES --ref /home/ubuntu/dd/nextflow2/reference/Homo_sapiens_assembly38.fasta --reads /home/ubuntu/dd/nextflow2/output/4.markDuplicate/SRR26512958_sorted_md.bam --regions /home/ubuntu/dd/nextflow2/reference/hg38_exome.bed --output_vcf /home/ubuntu/dd/nextflow2/output/5.snvS/SRR26512958_raw.vcf.gz --output_gvcf /home/ubuntu/dd/nextflow2/SRR26512958_raw.gvcf.gz --num_shards 16. --intermediate_results_dir /home/ubuntu/dd/nextflow2/tmp > deepvariant_log.txt 2>&1. Co",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/883:1926,usability,ERROR,ERROR,1926,"}_raw.vcf.gz""), path(""${sample_id}_raw.gvcf.gz""), emit: raw_vcfs. script:. """""". sudo docker run \. -v ""${PWD}"":""${PWD}"" \. google/deepvariant:1.6.1 \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref ${PWD}/${params.reference} \. --reads ${PWD}/output/4.markDuplicate/${sample_id}_sorted_md.bam \. --regions ${PWD}/${params.bed_file} \. --output_vcf ${PWD}/${params.outdir}/${sample_id}_raw.vcf.gz \. --output_gvcf ${PWD}/${sample_id}_raw.gvcf.gz \. --num_shards ${task.cpus}. --intermediate_results_dir ${PWD}/tmp > deepvariant_log.txt 2>&1. """""". }. ############# Error ###################. N E X T F L O W ~ version 24.04.4. Launching `dip.nf` [deadly_pike] DSL2 - revision: e075b1fba0. executor > local (2). [a6/9c6b79] process > deepvar (Germline Variant on SRR26512959) [ 0%] 0 of 2. ERROR ~ Error executing process > 'deepvar (Germline Variant on SRR26512958)'. executor > local (2). [a6/9c6b79] process > deepvar (Germline Variant on SRR26512959) [100%] 1 of 1, failed: 1. ERROR ~ Error executing process > 'deepvar (Germline Variant on SRR26512958)'. Caused by:. Process `deepvar (Germline Variant on SRR26512958)` terminated with an error exit status (127). Command executed:. sudo docker run -v ""/home/ubuntu/dd/nextflow2"":""/home/ubuntu/dd/nextflow2"" google/deepvariant:1.6.1 /opt/deepvariant/bin/run_deepvariant --model_type WES --ref /home/ubuntu/dd/nextflow2/reference/Homo_sapiens_assembly38.fasta --reads /home/ubuntu/dd/nextflow2/output/4.markDuplicate/SRR26512958_sorted_md.bam --regions /home/ubuntu/dd/nextflow2/reference/hg38_exome.bed --output_vcf /home/ubuntu/dd/nextflow2/output/5.snvS/SRR26512958_raw.vcf.gz --output_gvcf /home/ubuntu/dd/nextflow2/SRR26512958_raw.gvcf.gz --num_shards 16. --intermediate_results_dir /home/ubuntu/dd/nextflow2/tmp > deepvariant_log.txt 2>&1. Command exit status:. 127. Command output:. (empty). Command error:. docker: Error response from daemon: open /var/lib/docker/overlay2/fe3663cd03e849890d83be14603f217249f3f43f9585b554df",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/883:1934,usability,Error,Error,1934,"f.gz""), path(""${sample_id}_raw.gvcf.gz""), emit: raw_vcfs. script:. """""". sudo docker run \. -v ""${PWD}"":""${PWD}"" \. google/deepvariant:1.6.1 \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref ${PWD}/${params.reference} \. --reads ${PWD}/output/4.markDuplicate/${sample_id}_sorted_md.bam \. --regions ${PWD}/${params.bed_file} \. --output_vcf ${PWD}/${params.outdir}/${sample_id}_raw.vcf.gz \. --output_gvcf ${PWD}/${sample_id}_raw.gvcf.gz \. --num_shards ${task.cpus}. --intermediate_results_dir ${PWD}/tmp > deepvariant_log.txt 2>&1. """""". }. ############# Error ###################. N E X T F L O W ~ version 24.04.4. Launching `dip.nf` [deadly_pike] DSL2 - revision: e075b1fba0. executor > local (2). [a6/9c6b79] process > deepvar (Germline Variant on SRR26512959) [ 0%] 0 of 2. ERROR ~ Error executing process > 'deepvar (Germline Variant on SRR26512958)'. executor > local (2). [a6/9c6b79] process > deepvar (Germline Variant on SRR26512959) [100%] 1 of 1, failed: 1. ERROR ~ Error executing process > 'deepvar (Germline Variant on SRR26512958)'. Caused by:. Process `deepvar (Germline Variant on SRR26512958)` terminated with an error exit status (127). Command executed:. sudo docker run -v ""/home/ubuntu/dd/nextflow2"":""/home/ubuntu/dd/nextflow2"" google/deepvariant:1.6.1 /opt/deepvariant/bin/run_deepvariant --model_type WES --ref /home/ubuntu/dd/nextflow2/reference/Homo_sapiens_assembly38.fasta --reads /home/ubuntu/dd/nextflow2/output/4.markDuplicate/SRR26512958_sorted_md.bam --regions /home/ubuntu/dd/nextflow2/reference/hg38_exome.bed --output_vcf /home/ubuntu/dd/nextflow2/output/5.snvS/SRR26512958_raw.vcf.gz --output_gvcf /home/ubuntu/dd/nextflow2/SRR26512958_raw.gvcf.gz --num_shards 16. --intermediate_results_dir /home/ubuntu/dd/nextflow2/tmp > deepvariant_log.txt 2>&1. Command exit status:. 127. Command output:. (empty). Command error:. docker: Error response from daemon: open /var/lib/docker/overlay2/fe3663cd03e849890d83be14603f217249f3f43f9585b554df599d0318",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/883:2088,usability,error,error,2088,"riant/bin/run_deepvariant \. --model_type WES \. --ref ${PWD}/${params.reference} \. --reads ${PWD}/output/4.markDuplicate/${sample_id}_sorted_md.bam \. --regions ${PWD}/${params.bed_file} \. --output_vcf ${PWD}/${params.outdir}/${sample_id}_raw.vcf.gz \. --output_gvcf ${PWD}/${sample_id}_raw.gvcf.gz \. --num_shards ${task.cpus}. --intermediate_results_dir ${PWD}/tmp > deepvariant_log.txt 2>&1. """""". }. ############# Error ###################. N E X T F L O W ~ version 24.04.4. Launching `dip.nf` [deadly_pike] DSL2 - revision: e075b1fba0. executor > local (2). [a6/9c6b79] process > deepvar (Germline Variant on SRR26512959) [ 0%] 0 of 2. ERROR ~ Error executing process > 'deepvar (Germline Variant on SRR26512958)'. executor > local (2). [a6/9c6b79] process > deepvar (Germline Variant on SRR26512959) [100%] 1 of 1, failed: 1. ERROR ~ Error executing process > 'deepvar (Germline Variant on SRR26512958)'. Caused by:. Process `deepvar (Germline Variant on SRR26512958)` terminated with an error exit status (127). Command executed:. sudo docker run -v ""/home/ubuntu/dd/nextflow2"":""/home/ubuntu/dd/nextflow2"" google/deepvariant:1.6.1 /opt/deepvariant/bin/run_deepvariant --model_type WES --ref /home/ubuntu/dd/nextflow2/reference/Homo_sapiens_assembly38.fasta --reads /home/ubuntu/dd/nextflow2/output/4.markDuplicate/SRR26512958_sorted_md.bam --regions /home/ubuntu/dd/nextflow2/reference/hg38_exome.bed --output_vcf /home/ubuntu/dd/nextflow2/output/5.snvS/SRR26512958_raw.vcf.gz --output_gvcf /home/ubuntu/dd/nextflow2/SRR26512958_raw.gvcf.gz --num_shards 16. --intermediate_results_dir /home/ubuntu/dd/nextflow2/tmp > deepvariant_log.txt 2>&1. Command exit status:. 127. Command output:. (empty). Command error:. docker: Error response from daemon: open /var/lib/docker/overlay2/fe3663cd03e849890d83be14603f217249f3f43f9585b554df599d0318909f21/.tmp-committed2046174062: no such file or directory. See 'docker run --help'. Work dir:. /home/ubuntu/dd/nextflow2/work/ea/9ecd306270fe3f00d9b73f82",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/883:2099,usability,statu,status,2099,"un_deepvariant \. --model_type WES \. --ref ${PWD}/${params.reference} \. --reads ${PWD}/output/4.markDuplicate/${sample_id}_sorted_md.bam \. --regions ${PWD}/${params.bed_file} \. --output_vcf ${PWD}/${params.outdir}/${sample_id}_raw.vcf.gz \. --output_gvcf ${PWD}/${sample_id}_raw.gvcf.gz \. --num_shards ${task.cpus}. --intermediate_results_dir ${PWD}/tmp > deepvariant_log.txt 2>&1. """""". }. ############# Error ###################. N E X T F L O W ~ version 24.04.4. Launching `dip.nf` [deadly_pike] DSL2 - revision: e075b1fba0. executor > local (2). [a6/9c6b79] process > deepvar (Germline Variant on SRR26512959) [ 0%] 0 of 2. ERROR ~ Error executing process > 'deepvar (Germline Variant on SRR26512958)'. executor > local (2). [a6/9c6b79] process > deepvar (Germline Variant on SRR26512959) [100%] 1 of 1, failed: 1. ERROR ~ Error executing process > 'deepvar (Germline Variant on SRR26512958)'. Caused by:. Process `deepvar (Germline Variant on SRR26512958)` terminated with an error exit status (127). Command executed:. sudo docker run -v ""/home/ubuntu/dd/nextflow2"":""/home/ubuntu/dd/nextflow2"" google/deepvariant:1.6.1 /opt/deepvariant/bin/run_deepvariant --model_type WES --ref /home/ubuntu/dd/nextflow2/reference/Homo_sapiens_assembly38.fasta --reads /home/ubuntu/dd/nextflow2/output/4.markDuplicate/SRR26512958_sorted_md.bam --regions /home/ubuntu/dd/nextflow2/reference/hg38_exome.bed --output_vcf /home/ubuntu/dd/nextflow2/output/5.snvS/SRR26512958_raw.vcf.gz --output_gvcf /home/ubuntu/dd/nextflow2/SRR26512958_raw.gvcf.gz --num_shards 16. --intermediate_results_dir /home/ubuntu/dd/nextflow2/tmp > deepvariant_log.txt 2>&1. Command exit status:. 127. Command output:. (empty). Command error:. docker: Error response from daemon: open /var/lib/docker/overlay2/fe3663cd03e849890d83be14603f217249f3f43f9585b554df599d0318909f21/.tmp-committed2046174062: no such file or directory. See 'docker run --help'. Work dir:. /home/ubuntu/dd/nextflow2/work/ea/9ecd306270fe3f00d9b73f8261fe89. Tip",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/883:2113,usability,Command,Command,2113,"\. --model_type WES \. --ref ${PWD}/${params.reference} \. --reads ${PWD}/output/4.markDuplicate/${sample_id}_sorted_md.bam \. --regions ${PWD}/${params.bed_file} \. --output_vcf ${PWD}/${params.outdir}/${sample_id}_raw.vcf.gz \. --output_gvcf ${PWD}/${sample_id}_raw.gvcf.gz \. --num_shards ${task.cpus}. --intermediate_results_dir ${PWD}/tmp > deepvariant_log.txt 2>&1. """""". }. ############# Error ###################. N E X T F L O W ~ version 24.04.4. Launching `dip.nf` [deadly_pike] DSL2 - revision: e075b1fba0. executor > local (2). [a6/9c6b79] process > deepvar (Germline Variant on SRR26512959) [ 0%] 0 of 2. ERROR ~ Error executing process > 'deepvar (Germline Variant on SRR26512958)'. executor > local (2). [a6/9c6b79] process > deepvar (Germline Variant on SRR26512959) [100%] 1 of 1, failed: 1. ERROR ~ Error executing process > 'deepvar (Germline Variant on SRR26512958)'. Caused by:. Process `deepvar (Germline Variant on SRR26512958)` terminated with an error exit status (127). Command executed:. sudo docker run -v ""/home/ubuntu/dd/nextflow2"":""/home/ubuntu/dd/nextflow2"" google/deepvariant:1.6.1 /opt/deepvariant/bin/run_deepvariant --model_type WES --ref /home/ubuntu/dd/nextflow2/reference/Homo_sapiens_assembly38.fasta --reads /home/ubuntu/dd/nextflow2/output/4.markDuplicate/SRR26512958_sorted_md.bam --regions /home/ubuntu/dd/nextflow2/reference/hg38_exome.bed --output_vcf /home/ubuntu/dd/nextflow2/output/5.snvS/SRR26512958_raw.vcf.gz --output_gvcf /home/ubuntu/dd/nextflow2/SRR26512958_raw.gvcf.gz --num_shards 16. --intermediate_results_dir /home/ubuntu/dd/nextflow2/tmp > deepvariant_log.txt 2>&1. Command exit status:. 127. Command output:. (empty). Command error:. docker: Error response from daemon: open /var/lib/docker/overlay2/fe3663cd03e849890d83be14603f217249f3f43f9585b554df599d0318909f21/.tmp-committed2046174062: no such file or directory. See 'docker run --help'. Work dir:. /home/ubuntu/dd/nextflow2/work/ea/9ecd306270fe3f00d9b73f8261fe89. Tip: you can try t",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/883:2744,usability,Command,Command,2744,"bed_file} \. --output_vcf ${PWD}/${params.outdir}/${sample_id}_raw.vcf.gz \. --output_gvcf ${PWD}/${sample_id}_raw.gvcf.gz \. --num_shards ${task.cpus}. --intermediate_results_dir ${PWD}/tmp > deepvariant_log.txt 2>&1. """""". }. ############# Error ###################. N E X T F L O W ~ version 24.04.4. Launching `dip.nf` [deadly_pike] DSL2 - revision: e075b1fba0. executor > local (2). [a6/9c6b79] process > deepvar (Germline Variant on SRR26512959) [ 0%] 0 of 2. ERROR ~ Error executing process > 'deepvar (Germline Variant on SRR26512958)'. executor > local (2). [a6/9c6b79] process > deepvar (Germline Variant on SRR26512959) [100%] 1 of 1, failed: 1. ERROR ~ Error executing process > 'deepvar (Germline Variant on SRR26512958)'. Caused by:. Process `deepvar (Germline Variant on SRR26512958)` terminated with an error exit status (127). Command executed:. sudo docker run -v ""/home/ubuntu/dd/nextflow2"":""/home/ubuntu/dd/nextflow2"" google/deepvariant:1.6.1 /opt/deepvariant/bin/run_deepvariant --model_type WES --ref /home/ubuntu/dd/nextflow2/reference/Homo_sapiens_assembly38.fasta --reads /home/ubuntu/dd/nextflow2/output/4.markDuplicate/SRR26512958_sorted_md.bam --regions /home/ubuntu/dd/nextflow2/reference/hg38_exome.bed --output_vcf /home/ubuntu/dd/nextflow2/output/5.snvS/SRR26512958_raw.vcf.gz --output_gvcf /home/ubuntu/dd/nextflow2/SRR26512958_raw.gvcf.gz --num_shards 16. --intermediate_results_dir /home/ubuntu/dd/nextflow2/tmp > deepvariant_log.txt 2>&1. Command exit status:. 127. Command output:. (empty). Command error:. docker: Error response from daemon: open /var/lib/docker/overlay2/fe3663cd03e849890d83be14603f217249f3f43f9585b554df599d0318909f21/.tmp-committed2046174062: no such file or directory. See 'docker run --help'. Work dir:. /home/ubuntu/dd/nextflow2/work/ea/9ecd306270fe3f00d9b73f8261fe89. Tip: you can try to figure out what's wrong by changing to the process work dir and showing the script file named `.command.sh`. -- Check '.nextflow.log' file for details.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/883:2757,usability,statu,status,2757,"bed_file} \. --output_vcf ${PWD}/${params.outdir}/${sample_id}_raw.vcf.gz \. --output_gvcf ${PWD}/${sample_id}_raw.gvcf.gz \. --num_shards ${task.cpus}. --intermediate_results_dir ${PWD}/tmp > deepvariant_log.txt 2>&1. """""". }. ############# Error ###################. N E X T F L O W ~ version 24.04.4. Launching `dip.nf` [deadly_pike] DSL2 - revision: e075b1fba0. executor > local (2). [a6/9c6b79] process > deepvar (Germline Variant on SRR26512959) [ 0%] 0 of 2. ERROR ~ Error executing process > 'deepvar (Germline Variant on SRR26512958)'. executor > local (2). [a6/9c6b79] process > deepvar (Germline Variant on SRR26512959) [100%] 1 of 1, failed: 1. ERROR ~ Error executing process > 'deepvar (Germline Variant on SRR26512958)'. Caused by:. Process `deepvar (Germline Variant on SRR26512958)` terminated with an error exit status (127). Command executed:. sudo docker run -v ""/home/ubuntu/dd/nextflow2"":""/home/ubuntu/dd/nextflow2"" google/deepvariant:1.6.1 /opt/deepvariant/bin/run_deepvariant --model_type WES --ref /home/ubuntu/dd/nextflow2/reference/Homo_sapiens_assembly38.fasta --reads /home/ubuntu/dd/nextflow2/output/4.markDuplicate/SRR26512958_sorted_md.bam --regions /home/ubuntu/dd/nextflow2/reference/hg38_exome.bed --output_vcf /home/ubuntu/dd/nextflow2/output/5.snvS/SRR26512958_raw.vcf.gz --output_gvcf /home/ubuntu/dd/nextflow2/SRR26512958_raw.gvcf.gz --num_shards 16. --intermediate_results_dir /home/ubuntu/dd/nextflow2/tmp > deepvariant_log.txt 2>&1. Command exit status:. 127. Command output:. (empty). Command error:. docker: Error response from daemon: open /var/lib/docker/overlay2/fe3663cd03e849890d83be14603f217249f3f43f9585b554df599d0318909f21/.tmp-committed2046174062: no such file or directory. See 'docker run --help'. Work dir:. /home/ubuntu/dd/nextflow2/work/ea/9ecd306270fe3f00d9b73f8261fe89. Tip: you can try to figure out what's wrong by changing to the process work dir and showing the script file named `.command.sh`. -- Check '.nextflow.log' file for details.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/883:2771,usability,Command,Command,2771,"bed_file} \. --output_vcf ${PWD}/${params.outdir}/${sample_id}_raw.vcf.gz \. --output_gvcf ${PWD}/${sample_id}_raw.gvcf.gz \. --num_shards ${task.cpus}. --intermediate_results_dir ${PWD}/tmp > deepvariant_log.txt 2>&1. """""". }. ############# Error ###################. N E X T F L O W ~ version 24.04.4. Launching `dip.nf` [deadly_pike] DSL2 - revision: e075b1fba0. executor > local (2). [a6/9c6b79] process > deepvar (Germline Variant on SRR26512959) [ 0%] 0 of 2. ERROR ~ Error executing process > 'deepvar (Germline Variant on SRR26512958)'. executor > local (2). [a6/9c6b79] process > deepvar (Germline Variant on SRR26512959) [100%] 1 of 1, failed: 1. ERROR ~ Error executing process > 'deepvar (Germline Variant on SRR26512958)'. Caused by:. Process `deepvar (Germline Variant on SRR26512958)` terminated with an error exit status (127). Command executed:. sudo docker run -v ""/home/ubuntu/dd/nextflow2"":""/home/ubuntu/dd/nextflow2"" google/deepvariant:1.6.1 /opt/deepvariant/bin/run_deepvariant --model_type WES --ref /home/ubuntu/dd/nextflow2/reference/Homo_sapiens_assembly38.fasta --reads /home/ubuntu/dd/nextflow2/output/4.markDuplicate/SRR26512958_sorted_md.bam --regions /home/ubuntu/dd/nextflow2/reference/hg38_exome.bed --output_vcf /home/ubuntu/dd/nextflow2/output/5.snvS/SRR26512958_raw.vcf.gz --output_gvcf /home/ubuntu/dd/nextflow2/SRR26512958_raw.gvcf.gz --num_shards 16. --intermediate_results_dir /home/ubuntu/dd/nextflow2/tmp > deepvariant_log.txt 2>&1. Command exit status:. 127. Command output:. (empty). Command error:. docker: Error response from daemon: open /var/lib/docker/overlay2/fe3663cd03e849890d83be14603f217249f3f43f9585b554df599d0318909f21/.tmp-committed2046174062: no such file or directory. See 'docker run --help'. Work dir:. /home/ubuntu/dd/nextflow2/work/ea/9ecd306270fe3f00d9b73f8261fe89. Tip: you can try to figure out what's wrong by changing to the process work dir and showing the script file named `.command.sh`. -- Check '.nextflow.log' file for details.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/883:2797,usability,Command,Command,2797,"bed_file} \. --output_vcf ${PWD}/${params.outdir}/${sample_id}_raw.vcf.gz \. --output_gvcf ${PWD}/${sample_id}_raw.gvcf.gz \. --num_shards ${task.cpus}. --intermediate_results_dir ${PWD}/tmp > deepvariant_log.txt 2>&1. """""". }. ############# Error ###################. N E X T F L O W ~ version 24.04.4. Launching `dip.nf` [deadly_pike] DSL2 - revision: e075b1fba0. executor > local (2). [a6/9c6b79] process > deepvar (Germline Variant on SRR26512959) [ 0%] 0 of 2. ERROR ~ Error executing process > 'deepvar (Germline Variant on SRR26512958)'. executor > local (2). [a6/9c6b79] process > deepvar (Germline Variant on SRR26512959) [100%] 1 of 1, failed: 1. ERROR ~ Error executing process > 'deepvar (Germline Variant on SRR26512958)'. Caused by:. Process `deepvar (Germline Variant on SRR26512958)` terminated with an error exit status (127). Command executed:. sudo docker run -v ""/home/ubuntu/dd/nextflow2"":""/home/ubuntu/dd/nextflow2"" google/deepvariant:1.6.1 /opt/deepvariant/bin/run_deepvariant --model_type WES --ref /home/ubuntu/dd/nextflow2/reference/Homo_sapiens_assembly38.fasta --reads /home/ubuntu/dd/nextflow2/output/4.markDuplicate/SRR26512958_sorted_md.bam --regions /home/ubuntu/dd/nextflow2/reference/hg38_exome.bed --output_vcf /home/ubuntu/dd/nextflow2/output/5.snvS/SRR26512958_raw.vcf.gz --output_gvcf /home/ubuntu/dd/nextflow2/SRR26512958_raw.gvcf.gz --num_shards 16. --intermediate_results_dir /home/ubuntu/dd/nextflow2/tmp > deepvariant_log.txt 2>&1. Command exit status:. 127. Command output:. (empty). Command error:. docker: Error response from daemon: open /var/lib/docker/overlay2/fe3663cd03e849890d83be14603f217249f3f43f9585b554df599d0318909f21/.tmp-committed2046174062: no such file or directory. See 'docker run --help'. Work dir:. /home/ubuntu/dd/nextflow2/work/ea/9ecd306270fe3f00d9b73f8261fe89. Tip: you can try to figure out what's wrong by changing to the process work dir and showing the script file named `.command.sh`. -- Check '.nextflow.log' file for details.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/883:2805,usability,error,error,2805,"bed_file} \. --output_vcf ${PWD}/${params.outdir}/${sample_id}_raw.vcf.gz \. --output_gvcf ${PWD}/${sample_id}_raw.gvcf.gz \. --num_shards ${task.cpus}. --intermediate_results_dir ${PWD}/tmp > deepvariant_log.txt 2>&1. """""". }. ############# Error ###################. N E X T F L O W ~ version 24.04.4. Launching `dip.nf` [deadly_pike] DSL2 - revision: e075b1fba0. executor > local (2). [a6/9c6b79] process > deepvar (Germline Variant on SRR26512959) [ 0%] 0 of 2. ERROR ~ Error executing process > 'deepvar (Germline Variant on SRR26512958)'. executor > local (2). [a6/9c6b79] process > deepvar (Germline Variant on SRR26512959) [100%] 1 of 1, failed: 1. ERROR ~ Error executing process > 'deepvar (Germline Variant on SRR26512958)'. Caused by:. Process `deepvar (Germline Variant on SRR26512958)` terminated with an error exit status (127). Command executed:. sudo docker run -v ""/home/ubuntu/dd/nextflow2"":""/home/ubuntu/dd/nextflow2"" google/deepvariant:1.6.1 /opt/deepvariant/bin/run_deepvariant --model_type WES --ref /home/ubuntu/dd/nextflow2/reference/Homo_sapiens_assembly38.fasta --reads /home/ubuntu/dd/nextflow2/output/4.markDuplicate/SRR26512958_sorted_md.bam --regions /home/ubuntu/dd/nextflow2/reference/hg38_exome.bed --output_vcf /home/ubuntu/dd/nextflow2/output/5.snvS/SRR26512958_raw.vcf.gz --output_gvcf /home/ubuntu/dd/nextflow2/SRR26512958_raw.gvcf.gz --num_shards 16. --intermediate_results_dir /home/ubuntu/dd/nextflow2/tmp > deepvariant_log.txt 2>&1. Command exit status:. 127. Command output:. (empty). Command error:. docker: Error response from daemon: open /var/lib/docker/overlay2/fe3663cd03e849890d83be14603f217249f3f43f9585b554df599d0318909f21/.tmp-committed2046174062: no such file or directory. See 'docker run --help'. Work dir:. /home/ubuntu/dd/nextflow2/work/ea/9ecd306270fe3f00d9b73f8261fe89. Tip: you can try to figure out what's wrong by changing to the process work dir and showing the script file named `.command.sh`. -- Check '.nextflow.log' file for details.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/883:2821,usability,Error,Error,2821,"bed_file} \. --output_vcf ${PWD}/${params.outdir}/${sample_id}_raw.vcf.gz \. --output_gvcf ${PWD}/${sample_id}_raw.gvcf.gz \. --num_shards ${task.cpus}. --intermediate_results_dir ${PWD}/tmp > deepvariant_log.txt 2>&1. """""". }. ############# Error ###################. N E X T F L O W ~ version 24.04.4. Launching `dip.nf` [deadly_pike] DSL2 - revision: e075b1fba0. executor > local (2). [a6/9c6b79] process > deepvar (Germline Variant on SRR26512959) [ 0%] 0 of 2. ERROR ~ Error executing process > 'deepvar (Germline Variant on SRR26512958)'. executor > local (2). [a6/9c6b79] process > deepvar (Germline Variant on SRR26512959) [100%] 1 of 1, failed: 1. ERROR ~ Error executing process > 'deepvar (Germline Variant on SRR26512958)'. Caused by:. Process `deepvar (Germline Variant on SRR26512958)` terminated with an error exit status (127). Command executed:. sudo docker run -v ""/home/ubuntu/dd/nextflow2"":""/home/ubuntu/dd/nextflow2"" google/deepvariant:1.6.1 /opt/deepvariant/bin/run_deepvariant --model_type WES --ref /home/ubuntu/dd/nextflow2/reference/Homo_sapiens_assembly38.fasta --reads /home/ubuntu/dd/nextflow2/output/4.markDuplicate/SRR26512958_sorted_md.bam --regions /home/ubuntu/dd/nextflow2/reference/hg38_exome.bed --output_vcf /home/ubuntu/dd/nextflow2/output/5.snvS/SRR26512958_raw.vcf.gz --output_gvcf /home/ubuntu/dd/nextflow2/SRR26512958_raw.gvcf.gz --num_shards 16. --intermediate_results_dir /home/ubuntu/dd/nextflow2/tmp > deepvariant_log.txt 2>&1. Command exit status:. 127. Command output:. (empty). Command error:. docker: Error response from daemon: open /var/lib/docker/overlay2/fe3663cd03e849890d83be14603f217249f3f43f9585b554df599d0318909f21/.tmp-committed2046174062: no such file or directory. See 'docker run --help'. Work dir:. /home/ubuntu/dd/nextflow2/work/ea/9ecd306270fe3f00d9b73f8261fe89. Tip: you can try to figure out what's wrong by changing to the process work dir and showing the script file named `.command.sh`. -- Check '.nextflow.log' file for details.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/883:3015,usability,help,help,3015,"bed_file} \. --output_vcf ${PWD}/${params.outdir}/${sample_id}_raw.vcf.gz \. --output_gvcf ${PWD}/${sample_id}_raw.gvcf.gz \. --num_shards ${task.cpus}. --intermediate_results_dir ${PWD}/tmp > deepvariant_log.txt 2>&1. """""". }. ############# Error ###################. N E X T F L O W ~ version 24.04.4. Launching `dip.nf` [deadly_pike] DSL2 - revision: e075b1fba0. executor > local (2). [a6/9c6b79] process > deepvar (Germline Variant on SRR26512959) [ 0%] 0 of 2. ERROR ~ Error executing process > 'deepvar (Germline Variant on SRR26512958)'. executor > local (2). [a6/9c6b79] process > deepvar (Germline Variant on SRR26512959) [100%] 1 of 1, failed: 1. ERROR ~ Error executing process > 'deepvar (Germline Variant on SRR26512958)'. Caused by:. Process `deepvar (Germline Variant on SRR26512958)` terminated with an error exit status (127). Command executed:. sudo docker run -v ""/home/ubuntu/dd/nextflow2"":""/home/ubuntu/dd/nextflow2"" google/deepvariant:1.6.1 /opt/deepvariant/bin/run_deepvariant --model_type WES --ref /home/ubuntu/dd/nextflow2/reference/Homo_sapiens_assembly38.fasta --reads /home/ubuntu/dd/nextflow2/output/4.markDuplicate/SRR26512958_sorted_md.bam --regions /home/ubuntu/dd/nextflow2/reference/hg38_exome.bed --output_vcf /home/ubuntu/dd/nextflow2/output/5.snvS/SRR26512958_raw.vcf.gz --output_gvcf /home/ubuntu/dd/nextflow2/SRR26512958_raw.gvcf.gz --num_shards 16. --intermediate_results_dir /home/ubuntu/dd/nextflow2/tmp > deepvariant_log.txt 2>&1. Command exit status:. 127. Command output:. (empty). Command error:. docker: Error response from daemon: open /var/lib/docker/overlay2/fe3663cd03e849890d83be14603f217249f3f43f9585b554df599d0318909f21/.tmp-committed2046174062: no such file or directory. See 'docker run --help'. Work dir:. /home/ubuntu/dd/nextflow2/work/ea/9ecd306270fe3f00d9b73f8261fe89. Tip: you can try to figure out what's wrong by changing to the process work dir and showing the script file named `.command.sh`. -- Check '.nextflow.log' file for details.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/883:3099,usability,Tip,Tip,3099,"bed_file} \. --output_vcf ${PWD}/${params.outdir}/${sample_id}_raw.vcf.gz \. --output_gvcf ${PWD}/${sample_id}_raw.gvcf.gz \. --num_shards ${task.cpus}. --intermediate_results_dir ${PWD}/tmp > deepvariant_log.txt 2>&1. """""". }. ############# Error ###################. N E X T F L O W ~ version 24.04.4. Launching `dip.nf` [deadly_pike] DSL2 - revision: e075b1fba0. executor > local (2). [a6/9c6b79] process > deepvar (Germline Variant on SRR26512959) [ 0%] 0 of 2. ERROR ~ Error executing process > 'deepvar (Germline Variant on SRR26512958)'. executor > local (2). [a6/9c6b79] process > deepvar (Germline Variant on SRR26512959) [100%] 1 of 1, failed: 1. ERROR ~ Error executing process > 'deepvar (Germline Variant on SRR26512958)'. Caused by:. Process `deepvar (Germline Variant on SRR26512958)` terminated with an error exit status (127). Command executed:. sudo docker run -v ""/home/ubuntu/dd/nextflow2"":""/home/ubuntu/dd/nextflow2"" google/deepvariant:1.6.1 /opt/deepvariant/bin/run_deepvariant --model_type WES --ref /home/ubuntu/dd/nextflow2/reference/Homo_sapiens_assembly38.fasta --reads /home/ubuntu/dd/nextflow2/output/4.markDuplicate/SRR26512958_sorted_md.bam --regions /home/ubuntu/dd/nextflow2/reference/hg38_exome.bed --output_vcf /home/ubuntu/dd/nextflow2/output/5.snvS/SRR26512958_raw.vcf.gz --output_gvcf /home/ubuntu/dd/nextflow2/SRR26512958_raw.gvcf.gz --num_shards 16. --intermediate_results_dir /home/ubuntu/dd/nextflow2/tmp > deepvariant_log.txt 2>&1. Command exit status:. 127. Command output:. (empty). Command error:. docker: Error response from daemon: open /var/lib/docker/overlay2/fe3663cd03e849890d83be14603f217249f3f43f9585b554df599d0318909f21/.tmp-committed2046174062: no such file or directory. See 'docker run --help'. Work dir:. /home/ubuntu/dd/nextflow2/work/ea/9ecd306270fe3f00d9b73f8261fe89. Tip: you can try to figure out what's wrong by changing to the process work dir and showing the script file named `.command.sh`. -- Check '.nextflow.log' file for details.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/883:3215,usability,command,command,3215,"bed_file} \. --output_vcf ${PWD}/${params.outdir}/${sample_id}_raw.vcf.gz \. --output_gvcf ${PWD}/${sample_id}_raw.gvcf.gz \. --num_shards ${task.cpus}. --intermediate_results_dir ${PWD}/tmp > deepvariant_log.txt 2>&1. """""". }. ############# Error ###################. N E X T F L O W ~ version 24.04.4. Launching `dip.nf` [deadly_pike] DSL2 - revision: e075b1fba0. executor > local (2). [a6/9c6b79] process > deepvar (Germline Variant on SRR26512959) [ 0%] 0 of 2. ERROR ~ Error executing process > 'deepvar (Germline Variant on SRR26512958)'. executor > local (2). [a6/9c6b79] process > deepvar (Germline Variant on SRR26512959) [100%] 1 of 1, failed: 1. ERROR ~ Error executing process > 'deepvar (Germline Variant on SRR26512958)'. Caused by:. Process `deepvar (Germline Variant on SRR26512958)` terminated with an error exit status (127). Command executed:. sudo docker run -v ""/home/ubuntu/dd/nextflow2"":""/home/ubuntu/dd/nextflow2"" google/deepvariant:1.6.1 /opt/deepvariant/bin/run_deepvariant --model_type WES --ref /home/ubuntu/dd/nextflow2/reference/Homo_sapiens_assembly38.fasta --reads /home/ubuntu/dd/nextflow2/output/4.markDuplicate/SRR26512958_sorted_md.bam --regions /home/ubuntu/dd/nextflow2/reference/hg38_exome.bed --output_vcf /home/ubuntu/dd/nextflow2/output/5.snvS/SRR26512958_raw.vcf.gz --output_gvcf /home/ubuntu/dd/nextflow2/SRR26512958_raw.gvcf.gz --num_shards 16. --intermediate_results_dir /home/ubuntu/dd/nextflow2/tmp > deepvariant_log.txt 2>&1. Command exit status:. 127. Command output:. (empty). Command error:. docker: Error response from daemon: open /var/lib/docker/overlay2/fe3663cd03e849890d83be14603f217249f3f43f9585b554df599d0318909f21/.tmp-committed2046174062: no such file or directory. See 'docker run --help'. Work dir:. /home/ubuntu/dd/nextflow2/work/ea/9ecd306270fe3f00d9b73f8261fe89. Tip: you can try to figure out what's wrong by changing to the process work dir and showing the script file named `.command.sh`. -- Check '.nextflow.log' file for details.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/884:0,interoperability,Compatib,Compatibility,0,"Compatibility of DeepSomatic Tumor-Only Mode for Short-Read RNA-Seq without Control Sample; Hello,. Thank you for developing those fancy variant callers. We conducted short-read RNA sequencing, and since we do not have a control sample, we are planning to call variants using the DeepSomatic tumor-only mode. However, the tumor-only mode is only supported for Illumina WGS, PacBio, and ONT, and not for WES. Would it be acceptable to apply the WGS mode to our sample? Additionally, are there any significant differences in the algorithms or methods between WGS and WES for variant calling, and would this lead to meaningful differences in the results? Also, does setting variant call region (chr2:????-???) makes change in mutation call result? Many thanks,. Song",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/884
https://github.com/google/deepvariant/issues/884:374,modifiability,Pac,PacBio,374,"Compatibility of DeepSomatic Tumor-Only Mode for Short-Read RNA-Seq without Control Sample; Hello,. Thank you for developing those fancy variant callers. We conducted short-read RNA sequencing, and since we do not have a control sample, we are planning to call variants using the DeepSomatic tumor-only mode. However, the tumor-only mode is only supported for Illumina WGS, PacBio, and ONT, and not for WES. Would it be acceptable to apply the WGS mode to our sample? Additionally, are there any significant differences in the algorithms or methods between WGS and WES for variant calling, and would this lead to meaningful differences in the results? Also, does setting variant call region (chr2:????-???) makes change in mutation call result? Many thanks,. Song",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/884
https://github.com/google/deepvariant/issues/884:658,reliability,doe,does,658,"Compatibility of DeepSomatic Tumor-Only Mode for Short-Read RNA-Seq without Control Sample; Hello,. Thank you for developing those fancy variant callers. We conducted short-read RNA sequencing, and since we do not have a control sample, we are planning to call variants using the DeepSomatic tumor-only mode. However, the tumor-only mode is only supported for Illumina WGS, PacBio, and ONT, and not for WES. Would it be acceptable to apply the WGS mode to our sample? Additionally, are there any significant differences in the algorithms or methods between WGS and WES for variant calling, and would this lead to meaningful differences in the results? Also, does setting variant call region (chr2:????-???) makes change in mutation call result? Many thanks,. Song",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/884
https://github.com/google/deepvariant/issues/884:76,security,Control,Control,76,"Compatibility of DeepSomatic Tumor-Only Mode for Short-Read RNA-Seq without Control Sample; Hello,. Thank you for developing those fancy variant callers. We conducted short-read RNA sequencing, and since we do not have a control sample, we are planning to call variants using the DeepSomatic tumor-only mode. However, the tumor-only mode is only supported for Illumina WGS, PacBio, and ONT, and not for WES. Would it be acceptable to apply the WGS mode to our sample? Additionally, are there any significant differences in the algorithms or methods between WGS and WES for variant calling, and would this lead to meaningful differences in the results? Also, does setting variant call region (chr2:????-???) makes change in mutation call result? Many thanks,. Song",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/884
https://github.com/google/deepvariant/issues/884:221,security,control,control,221,"Compatibility of DeepSomatic Tumor-Only Mode for Short-Read RNA-Seq without Control Sample; Hello,. Thank you for developing those fancy variant callers. We conducted short-read RNA sequencing, and since we do not have a control sample, we are planning to call variants using the DeepSomatic tumor-only mode. However, the tumor-only mode is only supported for Illumina WGS, PacBio, and ONT, and not for WES. Would it be acceptable to apply the WGS mode to our sample? Additionally, are there any significant differences in the algorithms or methods between WGS and WES for variant calling, and would this lead to meaningful differences in the results? Also, does setting variant call region (chr2:????-???) makes change in mutation call result? Many thanks,. Song",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/884
https://github.com/google/deepvariant/issues/884:496,security,sign,significant,496,"Compatibility of DeepSomatic Tumor-Only Mode for Short-Read RNA-Seq without Control Sample; Hello,. Thank you for developing those fancy variant callers. We conducted short-read RNA sequencing, and since we do not have a control sample, we are planning to call variants using the DeepSomatic tumor-only mode. However, the tumor-only mode is only supported for Illumina WGS, PacBio, and ONT, and not for WES. Would it be acceptable to apply the WGS mode to our sample? Additionally, are there any significant differences in the algorithms or methods between WGS and WES for variant calling, and would this lead to meaningful differences in the results? Also, does setting variant call region (chr2:????-???) makes change in mutation call result? Many thanks,. Song",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/884
https://github.com/google/deepvariant/issues/884:76,testability,Control,Control,76,"Compatibility of DeepSomatic Tumor-Only Mode for Short-Read RNA-Seq without Control Sample; Hello,. Thank you for developing those fancy variant callers. We conducted short-read RNA sequencing, and since we do not have a control sample, we are planning to call variants using the DeepSomatic tumor-only mode. However, the tumor-only mode is only supported for Illumina WGS, PacBio, and ONT, and not for WES. Would it be acceptable to apply the WGS mode to our sample? Additionally, are there any significant differences in the algorithms or methods between WGS and WES for variant calling, and would this lead to meaningful differences in the results? Also, does setting variant call region (chr2:????-???) makes change in mutation call result? Many thanks,. Song",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/884
https://github.com/google/deepvariant/issues/884:221,testability,control,control,221,"Compatibility of DeepSomatic Tumor-Only Mode for Short-Read RNA-Seq without Control Sample; Hello,. Thank you for developing those fancy variant callers. We conducted short-read RNA sequencing, and since we do not have a control sample, we are planning to call variants using the DeepSomatic tumor-only mode. However, the tumor-only mode is only supported for Illumina WGS, PacBio, and ONT, and not for WES. Would it be acceptable to apply the WGS mode to our sample? Additionally, are there any significant differences in the algorithms or methods between WGS and WES for variant calling, and would this lead to meaningful differences in the results? Also, does setting variant call region (chr2:????-???) makes change in mutation call result? Many thanks,. Song",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/884
https://github.com/google/deepvariant/issues/884:244,testability,plan,planning,244,"Compatibility of DeepSomatic Tumor-Only Mode for Short-Read RNA-Seq without Control Sample; Hello,. Thank you for developing those fancy variant callers. We conducted short-read RNA sequencing, and since we do not have a control sample, we are planning to call variants using the DeepSomatic tumor-only mode. However, the tumor-only mode is only supported for Illumina WGS, PacBio, and ONT, and not for WES. Would it be acceptable to apply the WGS mode to our sample? Additionally, are there any significant differences in the algorithms or methods between WGS and WES for variant calling, and would this lead to meaningful differences in the results? Also, does setting variant call region (chr2:????-???) makes change in mutation call result? Many thanks,. Song",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/884
https://github.com/google/deepvariant/issues/884:346,usability,support,supported,346,"Compatibility of DeepSomatic Tumor-Only Mode for Short-Read RNA-Seq without Control Sample; Hello,. Thank you for developing those fancy variant callers. We conducted short-read RNA sequencing, and since we do not have a control sample, we are planning to call variants using the DeepSomatic tumor-only mode. However, the tumor-only mode is only supported for Illumina WGS, PacBio, and ONT, and not for WES. Would it be acceptable to apply the WGS mode to our sample? Additionally, are there any significant differences in the algorithms or methods between WGS and WES for variant calling, and would this lead to meaningful differences in the results? Also, does setting variant call region (chr2:????-???) makes change in mutation call result? Many thanks,. Song",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/884
https://github.com/google/deepvariant/issues/885:315,deployability,observ,observed,315,"Discussion on Multi-GPU Training; Hi,. Since DeepVariant does not support multi-GPU training ([Can model_train be run on multiple GPUs?](https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md#can-model_train-be-run-on-multiple-gpus)), I am pretty curious about ""We have tested training with 1 and 2 GPUs and observed the following runtimes:"" mentioned in the [training case](https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-training-case-study.md#start-train). Specifically, how is the training with 2 GPUs tested? Thank you! Regards : ).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/885
https://github.com/google/deepvariant/issues/885:20,energy efficiency,GPU,GPU,20,"Discussion on Multi-GPU Training; Hi,. Since DeepVariant does not support multi-GPU training ([Can model_train be run on multiple GPUs?](https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md#can-model_train-be-run-on-multiple-gpus)), I am pretty curious about ""We have tested training with 1 and 2 GPUs and observed the following runtimes:"" mentioned in the [training case](https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-training-case-study.md#start-train). Specifically, how is the training with 2 GPUs tested? Thank you! Regards : ).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/885
https://github.com/google/deepvariant/issues/885:80,energy efficiency,GPU,GPU,80,"Discussion on Multi-GPU Training; Hi,. Since DeepVariant does not support multi-GPU training ([Can model_train be run on multiple GPUs?](https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md#can-model_train-be-run-on-multiple-gpus)), I am pretty curious about ""We have tested training with 1 and 2 GPUs and observed the following runtimes:"" mentioned in the [training case](https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-training-case-study.md#start-train). Specifically, how is the training with 2 GPUs tested? Thank you! Regards : ).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/885
https://github.com/google/deepvariant/issues/885:130,energy efficiency,GPU,GPUs,130,"Discussion on Multi-GPU Training; Hi,. Since DeepVariant does not support multi-GPU training ([Can model_train be run on multiple GPUs?](https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md#can-model_train-be-run-on-multiple-gpus)), I am pretty curious about ""We have tested training with 1 and 2 GPUs and observed the following runtimes:"" mentioned in the [training case](https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-training-case-study.md#start-train). Specifically, how is the training with 2 GPUs tested? Thank you! Regards : ).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/885
https://github.com/google/deepvariant/issues/885:234,energy efficiency,gpu,gpus,234,"Discussion on Multi-GPU Training; Hi,. Since DeepVariant does not support multi-GPU training ([Can model_train be run on multiple GPUs?](https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md#can-model_train-be-run-on-multiple-gpus)), I am pretty curious about ""We have tested training with 1 and 2 GPUs and observed the following runtimes:"" mentioned in the [training case](https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-training-case-study.md#start-train). Specifically, how is the training with 2 GPUs tested? Thank you! Regards : ).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/885
https://github.com/google/deepvariant/issues/885:306,energy efficiency,GPU,GPUs,306,"Discussion on Multi-GPU Training; Hi,. Since DeepVariant does not support multi-GPU training ([Can model_train be run on multiple GPUs?](https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md#can-model_train-be-run-on-multiple-gpus)), I am pretty curious about ""We have tested training with 1 and 2 GPUs and observed the following runtimes:"" mentioned in the [training case](https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-training-case-study.md#start-train). Specifically, how is the training with 2 GPUs tested? Thank you! Regards : ).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/885
https://github.com/google/deepvariant/issues/885:527,energy efficiency,GPU,GPUs,527,"Discussion on Multi-GPU Training; Hi,. Since DeepVariant does not support multi-GPU training ([Can model_train be run on multiple GPUs?](https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md#can-model_train-be-run-on-multiple-gpus)), I am pretty curious about ""We have tested training with 1 and 2 GPUs and observed the following runtimes:"" mentioned in the [training case](https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-training-case-study.md#start-train). Specifically, how is the training with 2 GPUs tested? Thank you! Regards : ).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/885
https://github.com/google/deepvariant/issues/885:486,interoperability,Specif,Specifically,486,"Discussion on Multi-GPU Training; Hi,. Since DeepVariant does not support multi-GPU training ([Can model_train be run on multiple GPUs?](https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md#can-model_train-be-run-on-multiple-gpus)), I am pretty curious about ""We have tested training with 1 and 2 GPUs and observed the following runtimes:"" mentioned in the [training case](https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-training-case-study.md#start-train). Specifically, how is the training with 2 GPUs tested? Thank you! Regards : ).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/885
https://github.com/google/deepvariant/issues/885:20,performance,GPU,GPU,20,"Discussion on Multi-GPU Training; Hi,. Since DeepVariant does not support multi-GPU training ([Can model_train be run on multiple GPUs?](https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md#can-model_train-be-run-on-multiple-gpus)), I am pretty curious about ""We have tested training with 1 and 2 GPUs and observed the following runtimes:"" mentioned in the [training case](https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-training-case-study.md#start-train). Specifically, how is the training with 2 GPUs tested? Thank you! Regards : ).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/885
https://github.com/google/deepvariant/issues/885:80,performance,GPU,GPU,80,"Discussion on Multi-GPU Training; Hi,. Since DeepVariant does not support multi-GPU training ([Can model_train be run on multiple GPUs?](https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md#can-model_train-be-run-on-multiple-gpus)), I am pretty curious about ""We have tested training with 1 and 2 GPUs and observed the following runtimes:"" mentioned in the [training case](https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-training-case-study.md#start-train). Specifically, how is the training with 2 GPUs tested? Thank you! Regards : ).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/885
https://github.com/google/deepvariant/issues/885:130,performance,GPU,GPUs,130,"Discussion on Multi-GPU Training; Hi,. Since DeepVariant does not support multi-GPU training ([Can model_train be run on multiple GPUs?](https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md#can-model_train-be-run-on-multiple-gpus)), I am pretty curious about ""We have tested training with 1 and 2 GPUs and observed the following runtimes:"" mentioned in the [training case](https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-training-case-study.md#start-train). Specifically, how is the training with 2 GPUs tested? Thank you! Regards : ).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/885
https://github.com/google/deepvariant/issues/885:234,performance,gpu,gpus,234,"Discussion on Multi-GPU Training; Hi,. Since DeepVariant does not support multi-GPU training ([Can model_train be run on multiple GPUs?](https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md#can-model_train-be-run-on-multiple-gpus)), I am pretty curious about ""We have tested training with 1 and 2 GPUs and observed the following runtimes:"" mentioned in the [training case](https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-training-case-study.md#start-train). Specifically, how is the training with 2 GPUs tested? Thank you! Regards : ).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/885
https://github.com/google/deepvariant/issues/885:306,performance,GPU,GPUs,306,"Discussion on Multi-GPU Training; Hi,. Since DeepVariant does not support multi-GPU training ([Can model_train be run on multiple GPUs?](https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md#can-model_train-be-run-on-multiple-gpus)), I am pretty curious about ""We have tested training with 1 and 2 GPUs and observed the following runtimes:"" mentioned in the [training case](https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-training-case-study.md#start-train). Specifically, how is the training with 2 GPUs tested? Thank you! Regards : ).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/885
https://github.com/google/deepvariant/issues/885:527,performance,GPU,GPUs,527,"Discussion on Multi-GPU Training; Hi,. Since DeepVariant does not support multi-GPU training ([Can model_train be run on multiple GPUs?](https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md#can-model_train-be-run-on-multiple-gpus)), I am pretty curious about ""We have tested training with 1 and 2 GPUs and observed the following runtimes:"" mentioned in the [training case](https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-training-case-study.md#start-train). Specifically, how is the training with 2 GPUs tested? Thank you! Regards : ).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/885
https://github.com/google/deepvariant/issues/885:57,reliability,doe,does,57,"Discussion on Multi-GPU Training; Hi,. Since DeepVariant does not support multi-GPU training ([Can model_train be run on multiple GPUs?](https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md#can-model_train-be-run-on-multiple-gpus)), I am pretty curious about ""We have tested training with 1 and 2 GPUs and observed the following runtimes:"" mentioned in the [training case](https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-training-case-study.md#start-train). Specifically, how is the training with 2 GPUs tested? Thank you! Regards : ).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/885
https://github.com/google/deepvariant/issues/885:277,safety,test,tested,277,"Discussion on Multi-GPU Training; Hi,. Since DeepVariant does not support multi-GPU training ([Can model_train be run on multiple GPUs?](https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md#can-model_train-be-run-on-multiple-gpus)), I am pretty curious about ""We have tested training with 1 and 2 GPUs and observed the following runtimes:"" mentioned in the [training case](https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-training-case-study.md#start-train). Specifically, how is the training with 2 GPUs tested? Thank you! Regards : ).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/885
https://github.com/google/deepvariant/issues/885:532,safety,test,tested,532,"Discussion on Multi-GPU Training; Hi,. Since DeepVariant does not support multi-GPU training ([Can model_train be run on multiple GPUs?](https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md#can-model_train-be-run-on-multiple-gpus)), I am pretty curious about ""We have tested training with 1 and 2 GPUs and observed the following runtimes:"" mentioned in the [training case](https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-training-case-study.md#start-train). Specifically, how is the training with 2 GPUs tested? Thank you! Regards : ).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/885
https://github.com/google/deepvariant/issues/885:277,testability,test,tested,277,"Discussion on Multi-GPU Training; Hi,. Since DeepVariant does not support multi-GPU training ([Can model_train be run on multiple GPUs?](https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md#can-model_train-be-run-on-multiple-gpus)), I am pretty curious about ""We have tested training with 1 and 2 GPUs and observed the following runtimes:"" mentioned in the [training case](https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-training-case-study.md#start-train). Specifically, how is the training with 2 GPUs tested? Thank you! Regards : ).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/885
https://github.com/google/deepvariant/issues/885:315,testability,observ,observed,315,"Discussion on Multi-GPU Training; Hi,. Since DeepVariant does not support multi-GPU training ([Can model_train be run on multiple GPUs?](https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md#can-model_train-be-run-on-multiple-gpus)), I am pretty curious about ""We have tested training with 1 and 2 GPUs and observed the following runtimes:"" mentioned in the [training case](https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-training-case-study.md#start-train). Specifically, how is the training with 2 GPUs tested? Thank you! Regards : ).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/885
https://github.com/google/deepvariant/issues/885:532,testability,test,tested,532,"Discussion on Multi-GPU Training; Hi,. Since DeepVariant does not support multi-GPU training ([Can model_train be run on multiple GPUs?](https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md#can-model_train-be-run-on-multiple-gpus)), I am pretty curious about ""We have tested training with 1 and 2 GPUs and observed the following runtimes:"" mentioned in the [training case](https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-training-case-study.md#start-train). Specifically, how is the training with 2 GPUs tested? Thank you! Regards : ).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/885
https://github.com/google/deepvariant/issues/885:66,usability,support,support,66,"Discussion on Multi-GPU Training; Hi,. Since DeepVariant does not support multi-GPU training ([Can model_train be run on multiple GPUs?](https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md#can-model_train-be-run-on-multiple-gpus)), I am pretty curious about ""We have tested training with 1 and 2 GPUs and observed the following runtimes:"" mentioned in the [training case](https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-training-case-study.md#start-train). Specifically, how is the training with 2 GPUs tested? Thank you! Regards : ).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/885
https://github.com/google/deepvariant/issues/886:186,availability,Operat,Operating,186,"D; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. I can't pull the container using singularity. **Setup**. - Operating system: Ubuntu. - Installation method (Docker, built from source, etc.): tried with singularity. My system has singularity installed, I tried getting the container but it failed:. I used this code. ```. BIN_VERSION=""1.6.1"". singularity pull docker://google/deepvariant:""${BIN_VERSION}"". ```. and It got several warning messages:. WARNING: pull for Docker Hub is not guaranteed to produce the. WARNING: same image on repeated pull. Use Singularity Registry. WARNING: (shub://) to pull exactly equivalent images. /usr/bin/env: python: No such file or directory. Cleaning up... ERROR: pulling container failed! I was thinking of installing DeepVariant with conda, but the version in conda is 1.5.0, and I was told to always run the most up-to-date one.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/886
https://github.com/google/deepvariant/issues/886:773,availability,ERROR,ERROR,773,"D; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. I can't pull the container using singularity. **Setup**. - Operating system: Ubuntu. - Installation method (Docker, built from source, etc.): tried with singularity. My system has singularity installed, I tried getting the container but it failed:. I used this code. ```. BIN_VERSION=""1.6.1"". singularity pull docker://google/deepvariant:""${BIN_VERSION}"". ```. and It got several warning messages:. WARNING: pull for Docker Hub is not guaranteed to produce the. WARNING: same image on repeated pull. Use Singularity Registry. WARNING: (shub://) to pull exactly equivalent images. /usr/bin/env: python: No such file or directory. Cleaning up... ERROR: pulling container failed! I was thinking of installing DeepVariant with conda, but the version in conda is 1.5.0, and I was told to always run the most up-to-date one.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/886
https://github.com/google/deepvariant/issues/886:144,deployability,contain,container,144,"D; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. I can't pull the container using singularity. **Setup**. - Operating system: Ubuntu. - Installation method (Docker, built from source, etc.): tried with singularity. My system has singularity installed, I tried getting the container but it failed:. I used this code. ```. BIN_VERSION=""1.6.1"". singularity pull docker://google/deepvariant:""${BIN_VERSION}"". ```. and It got several warning messages:. WARNING: pull for Docker Hub is not guaranteed to produce the. WARNING: same image on repeated pull. Use Singularity Registry. WARNING: (shub://) to pull exactly equivalent images. /usr/bin/env: python: No such file or directory. Cleaning up... ERROR: pulling container failed! I was thinking of installing DeepVariant with conda, but the version in conda is 1.5.0, and I was told to always run the most up-to-date one.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/886
https://github.com/google/deepvariant/issues/886:214,deployability,Instal,Installation,214,"D; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. I can't pull the container using singularity. **Setup**. - Operating system: Ubuntu. - Installation method (Docker, built from source, etc.): tried with singularity. My system has singularity installed, I tried getting the container but it failed:. I used this code. ```. BIN_VERSION=""1.6.1"". singularity pull docker://google/deepvariant:""${BIN_VERSION}"". ```. and It got several warning messages:. WARNING: pull for Docker Hub is not guaranteed to produce the. WARNING: same image on repeated pull. Use Singularity Registry. WARNING: (shub://) to pull exactly equivalent images. /usr/bin/env: python: No such file or directory. Cleaning up... ERROR: pulling container failed! I was thinking of installing DeepVariant with conda, but the version in conda is 1.5.0, and I was told to always run the most up-to-date one.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/886
https://github.com/google/deepvariant/issues/886:319,deployability,instal,installed,319,"D; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. I can't pull the container using singularity. **Setup**. - Operating system: Ubuntu. - Installation method (Docker, built from source, etc.): tried with singularity. My system has singularity installed, I tried getting the container but it failed:. I used this code. ```. BIN_VERSION=""1.6.1"". singularity pull docker://google/deepvariant:""${BIN_VERSION}"". ```. and It got several warning messages:. WARNING: pull for Docker Hub is not guaranteed to produce the. WARNING: same image on repeated pull. Use Singularity Registry. WARNING: (shub://) to pull exactly equivalent images. /usr/bin/env: python: No such file or directory. Cleaning up... ERROR: pulling container failed! I was thinking of installing DeepVariant with conda, but the version in conda is 1.5.0, and I was told to always run the most up-to-date one.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/886
https://github.com/google/deepvariant/issues/886:350,deployability,contain,container,350,"D; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. I can't pull the container using singularity. **Setup**. - Operating system: Ubuntu. - Installation method (Docker, built from source, etc.): tried with singularity. My system has singularity installed, I tried getting the container but it failed:. I used this code. ```. BIN_VERSION=""1.6.1"". singularity pull docker://google/deepvariant:""${BIN_VERSION}"". ```. and It got several warning messages:. WARNING: pull for Docker Hub is not guaranteed to produce the. WARNING: same image on repeated pull. Use Singularity Registry. WARNING: (shub://) to pull exactly equivalent images. /usr/bin/env: python: No such file or directory. Cleaning up... ERROR: pulling container failed! I was thinking of installing DeepVariant with conda, but the version in conda is 1.5.0, and I was told to always run the most up-to-date one.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/886
https://github.com/google/deepvariant/issues/886:367,deployability,fail,failed,367,"D; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. I can't pull the container using singularity. **Setup**. - Operating system: Ubuntu. - Installation method (Docker, built from source, etc.): tried with singularity. My system has singularity installed, I tried getting the container but it failed:. I used this code. ```. BIN_VERSION=""1.6.1"". singularity pull docker://google/deepvariant:""${BIN_VERSION}"". ```. and It got several warning messages:. WARNING: pull for Docker Hub is not guaranteed to produce the. WARNING: same image on repeated pull. Use Singularity Registry. WARNING: (shub://) to pull exactly equivalent images. /usr/bin/env: python: No such file or directory. Cleaning up... ERROR: pulling container failed! I was thinking of installing DeepVariant with conda, but the version in conda is 1.5.0, and I was told to always run the most up-to-date one.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/886
https://github.com/google/deepvariant/issues/886:788,deployability,contain,container,788,"D; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. I can't pull the container using singularity. **Setup**. - Operating system: Ubuntu. - Installation method (Docker, built from source, etc.): tried with singularity. My system has singularity installed, I tried getting the container but it failed:. I used this code. ```. BIN_VERSION=""1.6.1"". singularity pull docker://google/deepvariant:""${BIN_VERSION}"". ```. and It got several warning messages:. WARNING: pull for Docker Hub is not guaranteed to produce the. WARNING: same image on repeated pull. Use Singularity Registry. WARNING: (shub://) to pull exactly equivalent images. /usr/bin/env: python: No such file or directory. Cleaning up... ERROR: pulling container failed! I was thinking of installing DeepVariant with conda, but the version in conda is 1.5.0, and I was told to always run the most up-to-date one.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/886
https://github.com/google/deepvariant/issues/886:798,deployability,fail,failed,798,"D; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. I can't pull the container using singularity. **Setup**. - Operating system: Ubuntu. - Installation method (Docker, built from source, etc.): tried with singularity. My system has singularity installed, I tried getting the container but it failed:. I used this code. ```. BIN_VERSION=""1.6.1"". singularity pull docker://google/deepvariant:""${BIN_VERSION}"". ```. and It got several warning messages:. WARNING: pull for Docker Hub is not guaranteed to produce the. WARNING: same image on repeated pull. Use Singularity Registry. WARNING: (shub://) to pull exactly equivalent images. /usr/bin/env: python: No such file or directory. Cleaning up... ERROR: pulling container failed! I was thinking of installing DeepVariant with conda, but the version in conda is 1.5.0, and I was told to always run the most up-to-date one.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/886
https://github.com/google/deepvariant/issues/886:824,deployability,instal,installing,824,"D; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. I can't pull the container using singularity. **Setup**. - Operating system: Ubuntu. - Installation method (Docker, built from source, etc.): tried with singularity. My system has singularity installed, I tried getting the container but it failed:. I used this code. ```. BIN_VERSION=""1.6.1"". singularity pull docker://google/deepvariant:""${BIN_VERSION}"". ```. and It got several warning messages:. WARNING: pull for Docker Hub is not guaranteed to produce the. WARNING: same image on repeated pull. Use Singularity Registry. WARNING: (shub://) to pull exactly equivalent images. /usr/bin/env: python: No such file or directory. Cleaning up... ERROR: pulling container failed! I was thinking of installing DeepVariant with conda, but the version in conda is 1.5.0, and I was told to always run the most up-to-date one.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/886
https://github.com/google/deepvariant/issues/886:867,deployability,version,version,867,"D; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. I can't pull the container using singularity. **Setup**. - Operating system: Ubuntu. - Installation method (Docker, built from source, etc.): tried with singularity. My system has singularity installed, I tried getting the container but it failed:. I used this code. ```. BIN_VERSION=""1.6.1"". singularity pull docker://google/deepvariant:""${BIN_VERSION}"". ```. and It got several warning messages:. WARNING: pull for Docker Hub is not guaranteed to produce the. WARNING: same image on repeated pull. Use Singularity Registry. WARNING: (shub://) to pull exactly equivalent images. /usr/bin/env: python: No such file or directory. Cleaning up... ERROR: pulling container failed! I was thinking of installing DeepVariant with conda, but the version in conda is 1.5.0, and I was told to always run the most up-to-date one.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/886
https://github.com/google/deepvariant/issues/886:515,integrability,messag,messages,515,"D; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. I can't pull the container using singularity. **Setup**. - Operating system: Ubuntu. - Installation method (Docker, built from source, etc.): tried with singularity. My system has singularity installed, I tried getting the container but it failed:. I used this code. ```. BIN_VERSION=""1.6.1"". singularity pull docker://google/deepvariant:""${BIN_VERSION}"". ```. and It got several warning messages:. WARNING: pull for Docker Hub is not guaranteed to produce the. WARNING: same image on repeated pull. Use Singularity Registry. WARNING: (shub://) to pull exactly equivalent images. /usr/bin/env: python: No such file or directory. Cleaning up... ERROR: pulling container failed! I was thinking of installing DeepVariant with conda, but the version in conda is 1.5.0, and I was told to always run the most up-to-date one.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/886
https://github.com/google/deepvariant/issues/886:867,integrability,version,version,867,"D; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. I can't pull the container using singularity. **Setup**. - Operating system: Ubuntu. - Installation method (Docker, built from source, etc.): tried with singularity. My system has singularity installed, I tried getting the container but it failed:. I used this code. ```. BIN_VERSION=""1.6.1"". singularity pull docker://google/deepvariant:""${BIN_VERSION}"". ```. and It got several warning messages:. WARNING: pull for Docker Hub is not guaranteed to produce the. WARNING: same image on repeated pull. Use Singularity Registry. WARNING: (shub://) to pull exactly equivalent images. /usr/bin/env: python: No such file or directory. Cleaning up... ERROR: pulling container failed! I was thinking of installing DeepVariant with conda, but the version in conda is 1.5.0, and I was told to always run the most up-to-date one.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/886
https://github.com/google/deepvariant/issues/886:515,interoperability,messag,messages,515,"D; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. I can't pull the container using singularity. **Setup**. - Operating system: Ubuntu. - Installation method (Docker, built from source, etc.): tried with singularity. My system has singularity installed, I tried getting the container but it failed:. I used this code. ```. BIN_VERSION=""1.6.1"". singularity pull docker://google/deepvariant:""${BIN_VERSION}"". ```. and It got several warning messages:. WARNING: pull for Docker Hub is not guaranteed to produce the. WARNING: same image on repeated pull. Use Singularity Registry. WARNING: (shub://) to pull exactly equivalent images. /usr/bin/env: python: No such file or directory. Cleaning up... ERROR: pulling container failed! I was thinking of installing DeepVariant with conda, but the version in conda is 1.5.0, and I was told to always run the most up-to-date one.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/886
https://github.com/google/deepvariant/issues/886:643,interoperability,Registr,Registry,643,"D; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. I can't pull the container using singularity. **Setup**. - Operating system: Ubuntu. - Installation method (Docker, built from source, etc.): tried with singularity. My system has singularity installed, I tried getting the container but it failed:. I used this code. ```. BIN_VERSION=""1.6.1"". singularity pull docker://google/deepvariant:""${BIN_VERSION}"". ```. and It got several warning messages:. WARNING: pull for Docker Hub is not guaranteed to produce the. WARNING: same image on repeated pull. Use Singularity Registry. WARNING: (shub://) to pull exactly equivalent images. /usr/bin/env: python: No such file or directory. Cleaning up... ERROR: pulling container failed! I was thinking of installing DeepVariant with conda, but the version in conda is 1.5.0, and I was told to always run the most up-to-date one.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/886
https://github.com/google/deepvariant/issues/886:867,modifiability,version,version,867,"D; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. I can't pull the container using singularity. **Setup**. - Operating system: Ubuntu. - Installation method (Docker, built from source, etc.): tried with singularity. My system has singularity installed, I tried getting the container but it failed:. I used this code. ```. BIN_VERSION=""1.6.1"". singularity pull docker://google/deepvariant:""${BIN_VERSION}"". ```. and It got several warning messages:. WARNING: pull for Docker Hub is not guaranteed to produce the. WARNING: same image on repeated pull. Use Singularity Registry. WARNING: (shub://) to pull exactly equivalent images. /usr/bin/env: python: No such file or directory. Cleaning up... ERROR: pulling container failed! I was thinking of installing DeepVariant with conda, but the version in conda is 1.5.0, and I was told to always run the most up-to-date one.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/886
https://github.com/google/deepvariant/issues/886:773,performance,ERROR,ERROR,773,"D; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. I can't pull the container using singularity. **Setup**. - Operating system: Ubuntu. - Installation method (Docker, built from source, etc.): tried with singularity. My system has singularity installed, I tried getting the container but it failed:. I used this code. ```. BIN_VERSION=""1.6.1"". singularity pull docker://google/deepvariant:""${BIN_VERSION}"". ```. and It got several warning messages:. WARNING: pull for Docker Hub is not guaranteed to produce the. WARNING: same image on repeated pull. Use Singularity Registry. WARNING: (shub://) to pull exactly equivalent images. /usr/bin/env: python: No such file or directory. Cleaning up... ERROR: pulling container failed! I was thinking of installing DeepVariant with conda, but the version in conda is 1.5.0, and I was told to always run the most up-to-date one.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/886
https://github.com/google/deepvariant/issues/886:367,reliability,fail,failed,367,"D; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. I can't pull the container using singularity. **Setup**. - Operating system: Ubuntu. - Installation method (Docker, built from source, etc.): tried with singularity. My system has singularity installed, I tried getting the container but it failed:. I used this code. ```. BIN_VERSION=""1.6.1"". singularity pull docker://google/deepvariant:""${BIN_VERSION}"". ```. and It got several warning messages:. WARNING: pull for Docker Hub is not guaranteed to produce the. WARNING: same image on repeated pull. Use Singularity Registry. WARNING: (shub://) to pull exactly equivalent images. /usr/bin/env: python: No such file or directory. Cleaning up... ERROR: pulling container failed! I was thinking of installing DeepVariant with conda, but the version in conda is 1.5.0, and I was told to always run the most up-to-date one.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/886
https://github.com/google/deepvariant/issues/886:798,reliability,fail,failed,798,"D; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. I can't pull the container using singularity. **Setup**. - Operating system: Ubuntu. - Installation method (Docker, built from source, etc.): tried with singularity. My system has singularity installed, I tried getting the container but it failed:. I used this code. ```. BIN_VERSION=""1.6.1"". singularity pull docker://google/deepvariant:""${BIN_VERSION}"". ```. and It got several warning messages:. WARNING: pull for Docker Hub is not guaranteed to produce the. WARNING: same image on repeated pull. Use Singularity Registry. WARNING: (shub://) to pull exactly equivalent images. /usr/bin/env: python: No such file or directory. Cleaning up... ERROR: pulling container failed! I was thinking of installing DeepVariant with conda, but the version in conda is 1.5.0, and I was told to always run the most up-to-date one.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/886
https://github.com/google/deepvariant/issues/886:773,safety,ERROR,ERROR,773,"D; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. I can't pull the container using singularity. **Setup**. - Operating system: Ubuntu. - Installation method (Docker, built from source, etc.): tried with singularity. My system has singularity installed, I tried getting the container but it failed:. I used this code. ```. BIN_VERSION=""1.6.1"". singularity pull docker://google/deepvariant:""${BIN_VERSION}"". ```. and It got several warning messages:. WARNING: pull for Docker Hub is not guaranteed to produce the. WARNING: same image on repeated pull. Use Singularity Registry. WARNING: (shub://) to pull exactly equivalent images. /usr/bin/env: python: No such file or directory. Cleaning up... ERROR: pulling container failed! I was thinking of installing DeepVariant with conda, but the version in conda is 1.5.0, and I was told to always run the most up-to-date one.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/886
https://github.com/google/deepvariant/issues/886:773,usability,ERROR,ERROR,773,"D; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. I can't pull the container using singularity. **Setup**. - Operating system: Ubuntu. - Installation method (Docker, built from source, etc.): tried with singularity. My system has singularity installed, I tried getting the container but it failed:. I used this code. ```. BIN_VERSION=""1.6.1"". singularity pull docker://google/deepvariant:""${BIN_VERSION}"". ```. and It got several warning messages:. WARNING: pull for Docker Hub is not guaranteed to produce the. WARNING: same image on repeated pull. Use Singularity Registry. WARNING: (shub://) to pull exactly equivalent images. /usr/bin/env: python: No such file or directory. Cleaning up... ERROR: pulling container failed! I was thinking of installing DeepVariant with conda, but the version in conda is 1.5.0, and I was told to always run the most up-to-date one.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/886
https://github.com/google/deepvariant/issues/887:114,testability,understand,understand,114,"Question about intermediate_results; Hello,. I have learned that DeepVariant is three steps at runtime. To better understand DeepVariant, I want to know if there is a way to parse the output file of call_variants like the output file of make_examples ([Visualizing DeepVariant examples](https://github.com/google/deepvariant/blob/r1.6.1/docs/visualizing_examples.ipynb)), so that it becomes human readable instead of a binary string like below. ```. tf.Tensor(b'\nc2\x01T:\x01AZQ\x12\n\n\x02DP\x12\x04\n\x028\x1c\x12\x0e\n\x02AD\x12\x08\n\x028\x15\n\x028\x04\x12\x12\n\x03VAF\x12\x0b\n\t\x11\x92$I\x92$I\xc2?:\x14\xff\xff\xff\xff\xff\xff\xff\xff\xff\x01\xff\xff\xff\xff\xff\xff\xff\xff\xff\x01J\tHG001_10Xh\xf7Nr\x011\x80\x01\xf6N\x12\x03\n\x01\x00\x1a\x18\x00\x00\x00\x00\xb6\xf8\xef?\x00\x00\x00@\x9e\x0fH?]F\xb5\xb9\x86a$?', shape=(), dtype=string). ```. Sorry for the interruption!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/887
https://github.com/google/deepvariant/issues/887:52,usability,learn,learned,52,"Question about intermediate_results; Hello,. I have learned that DeepVariant is three steps at runtime. To better understand DeepVariant, I want to know if there is a way to parse the output file of call_variants like the output file of make_examples ([Visualizing DeepVariant examples](https://github.com/google/deepvariant/blob/r1.6.1/docs/visualizing_examples.ipynb)), so that it becomes human readable instead of a binary string like below. ```. tf.Tensor(b'\nc2\x01T:\x01AZQ\x12\n\n\x02DP\x12\x04\n\x028\x1c\x12\x0e\n\x02AD\x12\x08\n\x028\x15\n\x028\x04\x12\x12\n\x03VAF\x12\x0b\n\t\x11\x92$I\x92$I\xc2?:\x14\xff\xff\xff\xff\xff\xff\xff\xff\xff\x01\xff\xff\xff\xff\xff\xff\xff\xff\xff\x01J\tHG001_10Xh\xf7Nr\x011\x80\x01\xf6N\x12\x03\n\x01\x00\x1a\x18\x00\x00\x00\x00\xb6\xf8\xef?\x00\x00\x00@\x9e\x0fH?]F\xb5\xb9\x86a$?', shape=(), dtype=string). ```. Sorry for the interruption!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/887
https://github.com/google/deepvariant/issues/887:253,usability,Visual,Visualizing,253,"Question about intermediate_results; Hello,. I have learned that DeepVariant is three steps at runtime. To better understand DeepVariant, I want to know if there is a way to parse the output file of call_variants like the output file of make_examples ([Visualizing DeepVariant examples](https://github.com/google/deepvariant/blob/r1.6.1/docs/visualizing_examples.ipynb)), so that it becomes human readable instead of a binary string like below. ```. tf.Tensor(b'\nc2\x01T:\x01AZQ\x12\n\n\x02DP\x12\x04\n\x028\x1c\x12\x0e\n\x02AD\x12\x08\n\x028\x15\n\x028\x04\x12\x12\n\x03VAF\x12\x0b\n\t\x11\x92$I\x92$I\xc2?:\x14\xff\xff\xff\xff\xff\xff\xff\xff\xff\x01\xff\xff\xff\xff\xff\xff\xff\xff\xff\x01J\tHG001_10Xh\xf7Nr\x011\x80\x01\xf6N\x12\x03\n\x01\x00\x1a\x18\x00\x00\x00\x00\xb6\xf8\xef?\x00\x00\x00@\x9e\x0fH?]F\xb5\xb9\x86a$?', shape=(), dtype=string). ```. Sorry for the interruption!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/887
https://github.com/google/deepvariant/issues/888:1387,deployability,resourc,resources,1387,"Call variant from bam file which includes methylation tags (MM/ML); Dear developers; . Thanks for the great tool for variant calling. I use deepvariant 1.6.1 for small variant calling from picbio HIFI data (Revio system). For HIFI data, there are two ways to get the input bam for deepvariant. The first, like we do in NGS data analysis, extracting fastq reads from raw HIFI bam and mapping the fastq reads to reference genome, eg. T2TCHM13v2, then get the input bam ( fastq-mapping bam ) ```sample.pbmm2.bam```. ```bash. bam2fastq -o sample.fastq raw.bam. pbmm2 align CHM13.fa sample.fastq sample.pbmm2.bam --preset HIFI. ##. run deepvarint with sample.pbmm2.bam . ```. The second, mapping from bam data with methylation signal to reference genome directly (bam-to-bam mapping) , ```sample.pbmm2.jasmine.bam```. ```bash. jasmine raw.bam raw.jasmine.bam # get 5mC methylation informations. pbmm2 align CHM13.fa raw.jasmine.bam sample.pbmm2.jasmine.bam --preset HIFI # bam-to-bam mapping, keep methylation tags in bam file. ##. run deepvarint with sample.pbmm2.jasmine.bam. ```. The first way bam for small variant calling makes no mistakes. But considering the following methylation analysis also needs to map reads to reference genome, so if it is suitable for using mapped bam with methylation tags to call small variant, we only need to map once, this can save time and computational resources. So my question is, is that OK for us to use bam with methylation tags as the input of deepvariant? Is the performance difference between using ```fastq-mapping bam``` and ```bam-to-bam mapping bam```? best, . Wilson.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/888
https://github.com/google/deepvariant/issues/888:1387,energy efficiency,resourc,resources,1387,"Call variant from bam file which includes methylation tags (MM/ML); Dear developers; . Thanks for the great tool for variant calling. I use deepvariant 1.6.1 for small variant calling from picbio HIFI data (Revio system). For HIFI data, there are two ways to get the input bam for deepvariant. The first, like we do in NGS data analysis, extracting fastq reads from raw HIFI bam and mapping the fastq reads to reference genome, eg. T2TCHM13v2, then get the input bam ( fastq-mapping bam ) ```sample.pbmm2.bam```. ```bash. bam2fastq -o sample.fastq raw.bam. pbmm2 align CHM13.fa sample.fastq sample.pbmm2.bam --preset HIFI. ##. run deepvarint with sample.pbmm2.bam . ```. The second, mapping from bam data with methylation signal to reference genome directly (bam-to-bam mapping) , ```sample.pbmm2.jasmine.bam```. ```bash. jasmine raw.bam raw.jasmine.bam # get 5mC methylation informations. pbmm2 align CHM13.fa raw.jasmine.bam sample.pbmm2.jasmine.bam --preset HIFI # bam-to-bam mapping, keep methylation tags in bam file. ##. run deepvarint with sample.pbmm2.jasmine.bam. ```. The first way bam for small variant calling makes no mistakes. But considering the following methylation analysis also needs to map reads to reference genome, so if it is suitable for using mapped bam with methylation tags to call small variant, we only need to map once, this can save time and computational resources. So my question is, is that OK for us to use bam with methylation tags as the input of deepvariant? Is the performance difference between using ```fastq-mapping bam``` and ```bam-to-bam mapping bam```? best, . Wilson.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/888
https://github.com/google/deepvariant/issues/888:1364,performance,time,time,1364,"Call variant from bam file which includes methylation tags (MM/ML); Dear developers; . Thanks for the great tool for variant calling. I use deepvariant 1.6.1 for small variant calling from picbio HIFI data (Revio system). For HIFI data, there are two ways to get the input bam for deepvariant. The first, like we do in NGS data analysis, extracting fastq reads from raw HIFI bam and mapping the fastq reads to reference genome, eg. T2TCHM13v2, then get the input bam ( fastq-mapping bam ) ```sample.pbmm2.bam```. ```bash. bam2fastq -o sample.fastq raw.bam. pbmm2 align CHM13.fa sample.fastq sample.pbmm2.bam --preset HIFI. ##. run deepvarint with sample.pbmm2.bam . ```. The second, mapping from bam data with methylation signal to reference genome directly (bam-to-bam mapping) , ```sample.pbmm2.jasmine.bam```. ```bash. jasmine raw.bam raw.jasmine.bam # get 5mC methylation informations. pbmm2 align CHM13.fa raw.jasmine.bam sample.pbmm2.jasmine.bam --preset HIFI # bam-to-bam mapping, keep methylation tags in bam file. ##. run deepvarint with sample.pbmm2.jasmine.bam. ```. The first way bam for small variant calling makes no mistakes. But considering the following methylation analysis also needs to map reads to reference genome, so if it is suitable for using mapped bam with methylation tags to call small variant, we only need to map once, this can save time and computational resources. So my question is, is that OK for us to use bam with methylation tags as the input of deepvariant? Is the performance difference between using ```fastq-mapping bam``` and ```bam-to-bam mapping bam```? best, . Wilson.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/888
https://github.com/google/deepvariant/issues/888:1373,performance,computational resourc,computational resources,1373,"Call variant from bam file which includes methylation tags (MM/ML); Dear developers; . Thanks for the great tool for variant calling. I use deepvariant 1.6.1 for small variant calling from picbio HIFI data (Revio system). For HIFI data, there are two ways to get the input bam for deepvariant. The first, like we do in NGS data analysis, extracting fastq reads from raw HIFI bam and mapping the fastq reads to reference genome, eg. T2TCHM13v2, then get the input bam ( fastq-mapping bam ) ```sample.pbmm2.bam```. ```bash. bam2fastq -o sample.fastq raw.bam. pbmm2 align CHM13.fa sample.fastq sample.pbmm2.bam --preset HIFI. ##. run deepvarint with sample.pbmm2.bam . ```. The second, mapping from bam data with methylation signal to reference genome directly (bam-to-bam mapping) , ```sample.pbmm2.jasmine.bam```. ```bash. jasmine raw.bam raw.jasmine.bam # get 5mC methylation informations. pbmm2 align CHM13.fa raw.jasmine.bam sample.pbmm2.jasmine.bam --preset HIFI # bam-to-bam mapping, keep methylation tags in bam file. ##. run deepvarint with sample.pbmm2.jasmine.bam. ```. The first way bam for small variant calling makes no mistakes. But considering the following methylation analysis also needs to map reads to reference genome, so if it is suitable for using mapped bam with methylation tags to call small variant, we only need to map once, this can save time and computational resources. So my question is, is that OK for us to use bam with methylation tags as the input of deepvariant? Is the performance difference between using ```fastq-mapping bam``` and ```bam-to-bam mapping bam```? best, . Wilson.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/888
https://github.com/google/deepvariant/issues/888:1504,performance,perform,performance,1504,"Call variant from bam file which includes methylation tags (MM/ML); Dear developers; . Thanks for the great tool for variant calling. I use deepvariant 1.6.1 for small variant calling from picbio HIFI data (Revio system). For HIFI data, there are two ways to get the input bam for deepvariant. The first, like we do in NGS data analysis, extracting fastq reads from raw HIFI bam and mapping the fastq reads to reference genome, eg. T2TCHM13v2, then get the input bam ( fastq-mapping bam ) ```sample.pbmm2.bam```. ```bash. bam2fastq -o sample.fastq raw.bam. pbmm2 align CHM13.fa sample.fastq sample.pbmm2.bam --preset HIFI. ##. run deepvarint with sample.pbmm2.bam . ```. The second, mapping from bam data with methylation signal to reference genome directly (bam-to-bam mapping) , ```sample.pbmm2.jasmine.bam```. ```bash. jasmine raw.bam raw.jasmine.bam # get 5mC methylation informations. pbmm2 align CHM13.fa raw.jasmine.bam sample.pbmm2.jasmine.bam --preset HIFI # bam-to-bam mapping, keep methylation tags in bam file. ##. run deepvarint with sample.pbmm2.jasmine.bam. ```. The first way bam for small variant calling makes no mistakes. But considering the following methylation analysis also needs to map reads to reference genome, so if it is suitable for using mapped bam with methylation tags to call small variant, we only need to map once, this can save time and computational resources. So my question is, is that OK for us to use bam with methylation tags as the input of deepvariant? Is the performance difference between using ```fastq-mapping bam``` and ```bam-to-bam mapping bam```? best, . Wilson.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/888
https://github.com/google/deepvariant/issues/888:267,safety,input,input,267,"Call variant from bam file which includes methylation tags (MM/ML); Dear developers; . Thanks for the great tool for variant calling. I use deepvariant 1.6.1 for small variant calling from picbio HIFI data (Revio system). For HIFI data, there are two ways to get the input bam for deepvariant. The first, like we do in NGS data analysis, extracting fastq reads from raw HIFI bam and mapping the fastq reads to reference genome, eg. T2TCHM13v2, then get the input bam ( fastq-mapping bam ) ```sample.pbmm2.bam```. ```bash. bam2fastq -o sample.fastq raw.bam. pbmm2 align CHM13.fa sample.fastq sample.pbmm2.bam --preset HIFI. ##. run deepvarint with sample.pbmm2.bam . ```. The second, mapping from bam data with methylation signal to reference genome directly (bam-to-bam mapping) , ```sample.pbmm2.jasmine.bam```. ```bash. jasmine raw.bam raw.jasmine.bam # get 5mC methylation informations. pbmm2 align CHM13.fa raw.jasmine.bam sample.pbmm2.jasmine.bam --preset HIFI # bam-to-bam mapping, keep methylation tags in bam file. ##. run deepvarint with sample.pbmm2.jasmine.bam. ```. The first way bam for small variant calling makes no mistakes. But considering the following methylation analysis also needs to map reads to reference genome, so if it is suitable for using mapped bam with methylation tags to call small variant, we only need to map once, this can save time and computational resources. So my question is, is that OK for us to use bam with methylation tags as the input of deepvariant? Is the performance difference between using ```fastq-mapping bam``` and ```bam-to-bam mapping bam```? best, . Wilson.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/888
https://github.com/google/deepvariant/issues/888:457,safety,input,input,457,"Call variant from bam file which includes methylation tags (MM/ML); Dear developers; . Thanks for the great tool for variant calling. I use deepvariant 1.6.1 for small variant calling from picbio HIFI data (Revio system). For HIFI data, there are two ways to get the input bam for deepvariant. The first, like we do in NGS data analysis, extracting fastq reads from raw HIFI bam and mapping the fastq reads to reference genome, eg. T2TCHM13v2, then get the input bam ( fastq-mapping bam ) ```sample.pbmm2.bam```. ```bash. bam2fastq -o sample.fastq raw.bam. pbmm2 align CHM13.fa sample.fastq sample.pbmm2.bam --preset HIFI. ##. run deepvarint with sample.pbmm2.bam . ```. The second, mapping from bam data with methylation signal to reference genome directly (bam-to-bam mapping) , ```sample.pbmm2.jasmine.bam```. ```bash. jasmine raw.bam raw.jasmine.bam # get 5mC methylation informations. pbmm2 align CHM13.fa raw.jasmine.bam sample.pbmm2.jasmine.bam --preset HIFI # bam-to-bam mapping, keep methylation tags in bam file. ##. run deepvarint with sample.pbmm2.jasmine.bam. ```. The first way bam for small variant calling makes no mistakes. But considering the following methylation analysis also needs to map reads to reference genome, so if it is suitable for using mapped bam with methylation tags to call small variant, we only need to map once, this can save time and computational resources. So my question is, is that OK for us to use bam with methylation tags as the input of deepvariant? Is the performance difference between using ```fastq-mapping bam``` and ```bam-to-bam mapping bam```? best, . Wilson.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/888
https://github.com/google/deepvariant/issues/888:1387,safety,resourc,resources,1387,"Call variant from bam file which includes methylation tags (MM/ML); Dear developers; . Thanks for the great tool for variant calling. I use deepvariant 1.6.1 for small variant calling from picbio HIFI data (Revio system). For HIFI data, there are two ways to get the input bam for deepvariant. The first, like we do in NGS data analysis, extracting fastq reads from raw HIFI bam and mapping the fastq reads to reference genome, eg. T2TCHM13v2, then get the input bam ( fastq-mapping bam ) ```sample.pbmm2.bam```. ```bash. bam2fastq -o sample.fastq raw.bam. pbmm2 align CHM13.fa sample.fastq sample.pbmm2.bam --preset HIFI. ##. run deepvarint with sample.pbmm2.bam . ```. The second, mapping from bam data with methylation signal to reference genome directly (bam-to-bam mapping) , ```sample.pbmm2.jasmine.bam```. ```bash. jasmine raw.bam raw.jasmine.bam # get 5mC methylation informations. pbmm2 align CHM13.fa raw.jasmine.bam sample.pbmm2.jasmine.bam --preset HIFI # bam-to-bam mapping, keep methylation tags in bam file. ##. run deepvarint with sample.pbmm2.jasmine.bam. ```. The first way bam for small variant calling makes no mistakes. But considering the following methylation analysis also needs to map reads to reference genome, so if it is suitable for using mapped bam with methylation tags to call small variant, we only need to map once, this can save time and computational resources. So my question is, is that OK for us to use bam with methylation tags as the input of deepvariant? Is the performance difference between using ```fastq-mapping bam``` and ```bam-to-bam mapping bam```? best, . Wilson.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/888
https://github.com/google/deepvariant/issues/888:1475,safety,input,input,1475,"Call variant from bam file which includes methylation tags (MM/ML); Dear developers; . Thanks for the great tool for variant calling. I use deepvariant 1.6.1 for small variant calling from picbio HIFI data (Revio system). For HIFI data, there are two ways to get the input bam for deepvariant. The first, like we do in NGS data analysis, extracting fastq reads from raw HIFI bam and mapping the fastq reads to reference genome, eg. T2TCHM13v2, then get the input bam ( fastq-mapping bam ) ```sample.pbmm2.bam```. ```bash. bam2fastq -o sample.fastq raw.bam. pbmm2 align CHM13.fa sample.fastq sample.pbmm2.bam --preset HIFI. ##. run deepvarint with sample.pbmm2.bam . ```. The second, mapping from bam data with methylation signal to reference genome directly (bam-to-bam mapping) , ```sample.pbmm2.jasmine.bam```. ```bash. jasmine raw.bam raw.jasmine.bam # get 5mC methylation informations. pbmm2 align CHM13.fa raw.jasmine.bam sample.pbmm2.jasmine.bam --preset HIFI # bam-to-bam mapping, keep methylation tags in bam file. ##. run deepvarint with sample.pbmm2.jasmine.bam. ```. The first way bam for small variant calling makes no mistakes. But considering the following methylation analysis also needs to map reads to reference genome, so if it is suitable for using mapped bam with methylation tags to call small variant, we only need to map once, this can save time and computational resources. So my question is, is that OK for us to use bam with methylation tags as the input of deepvariant? Is the performance difference between using ```fastq-mapping bam``` and ```bam-to-bam mapping bam```? best, . Wilson.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/888
https://github.com/google/deepvariant/issues/888:722,security,sign,signal,722,"Call variant from bam file which includes methylation tags (MM/ML); Dear developers; . Thanks for the great tool for variant calling. I use deepvariant 1.6.1 for small variant calling from picbio HIFI data (Revio system). For HIFI data, there are two ways to get the input bam for deepvariant. The first, like we do in NGS data analysis, extracting fastq reads from raw HIFI bam and mapping the fastq reads to reference genome, eg. T2TCHM13v2, then get the input bam ( fastq-mapping bam ) ```sample.pbmm2.bam```. ```bash. bam2fastq -o sample.fastq raw.bam. pbmm2 align CHM13.fa sample.fastq sample.pbmm2.bam --preset HIFI. ##. run deepvarint with sample.pbmm2.bam . ```. The second, mapping from bam data with methylation signal to reference genome directly (bam-to-bam mapping) , ```sample.pbmm2.jasmine.bam```. ```bash. jasmine raw.bam raw.jasmine.bam # get 5mC methylation informations. pbmm2 align CHM13.fa raw.jasmine.bam sample.pbmm2.jasmine.bam --preset HIFI # bam-to-bam mapping, keep methylation tags in bam file. ##. run deepvarint with sample.pbmm2.jasmine.bam. ```. The first way bam for small variant calling makes no mistakes. But considering the following methylation analysis also needs to map reads to reference genome, so if it is suitable for using mapped bam with methylation tags to call small variant, we only need to map once, this can save time and computational resources. So my question is, is that OK for us to use bam with methylation tags as the input of deepvariant? Is the performance difference between using ```fastq-mapping bam``` and ```bam-to-bam mapping bam```? best, . Wilson.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/888
https://github.com/google/deepvariant/issues/888:1387,testability,resourc,resources,1387,"Call variant from bam file which includes methylation tags (MM/ML); Dear developers; . Thanks for the great tool for variant calling. I use deepvariant 1.6.1 for small variant calling from picbio HIFI data (Revio system). For HIFI data, there are two ways to get the input bam for deepvariant. The first, like we do in NGS data analysis, extracting fastq reads from raw HIFI bam and mapping the fastq reads to reference genome, eg. T2TCHM13v2, then get the input bam ( fastq-mapping bam ) ```sample.pbmm2.bam```. ```bash. bam2fastq -o sample.fastq raw.bam. pbmm2 align CHM13.fa sample.fastq sample.pbmm2.bam --preset HIFI. ##. run deepvarint with sample.pbmm2.bam . ```. The second, mapping from bam data with methylation signal to reference genome directly (bam-to-bam mapping) , ```sample.pbmm2.jasmine.bam```. ```bash. jasmine raw.bam raw.jasmine.bam # get 5mC methylation informations. pbmm2 align CHM13.fa raw.jasmine.bam sample.pbmm2.jasmine.bam --preset HIFI # bam-to-bam mapping, keep methylation tags in bam file. ##. run deepvarint with sample.pbmm2.jasmine.bam. ```. The first way bam for small variant calling makes no mistakes. But considering the following methylation analysis also needs to map reads to reference genome, so if it is suitable for using mapped bam with methylation tags to call small variant, we only need to map once, this can save time and computational resources. So my question is, is that OK for us to use bam with methylation tags as the input of deepvariant? Is the performance difference between using ```fastq-mapping bam``` and ```bam-to-bam mapping bam```? best, . Wilson.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/888
https://github.com/google/deepvariant/issues/888:108,usability,tool,tool,108,"Call variant from bam file which includes methylation tags (MM/ML); Dear developers; . Thanks for the great tool for variant calling. I use deepvariant 1.6.1 for small variant calling from picbio HIFI data (Revio system). For HIFI data, there are two ways to get the input bam for deepvariant. The first, like we do in NGS data analysis, extracting fastq reads from raw HIFI bam and mapping the fastq reads to reference genome, eg. T2TCHM13v2, then get the input bam ( fastq-mapping bam ) ```sample.pbmm2.bam```. ```bash. bam2fastq -o sample.fastq raw.bam. pbmm2 align CHM13.fa sample.fastq sample.pbmm2.bam --preset HIFI. ##. run deepvarint with sample.pbmm2.bam . ```. The second, mapping from bam data with methylation signal to reference genome directly (bam-to-bam mapping) , ```sample.pbmm2.jasmine.bam```. ```bash. jasmine raw.bam raw.jasmine.bam # get 5mC methylation informations. pbmm2 align CHM13.fa raw.jasmine.bam sample.pbmm2.jasmine.bam --preset HIFI # bam-to-bam mapping, keep methylation tags in bam file. ##. run deepvarint with sample.pbmm2.jasmine.bam. ```. The first way bam for small variant calling makes no mistakes. But considering the following methylation analysis also needs to map reads to reference genome, so if it is suitable for using mapped bam with methylation tags to call small variant, we only need to map once, this can save time and computational resources. So my question is, is that OK for us to use bam with methylation tags as the input of deepvariant? Is the performance difference between using ```fastq-mapping bam``` and ```bam-to-bam mapping bam```? best, . Wilson.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/888
https://github.com/google/deepvariant/issues/888:267,usability,input,input,267,"Call variant from bam file which includes methylation tags (MM/ML); Dear developers; . Thanks for the great tool for variant calling. I use deepvariant 1.6.1 for small variant calling from picbio HIFI data (Revio system). For HIFI data, there are two ways to get the input bam for deepvariant. The first, like we do in NGS data analysis, extracting fastq reads from raw HIFI bam and mapping the fastq reads to reference genome, eg. T2TCHM13v2, then get the input bam ( fastq-mapping bam ) ```sample.pbmm2.bam```. ```bash. bam2fastq -o sample.fastq raw.bam. pbmm2 align CHM13.fa sample.fastq sample.pbmm2.bam --preset HIFI. ##. run deepvarint with sample.pbmm2.bam . ```. The second, mapping from bam data with methylation signal to reference genome directly (bam-to-bam mapping) , ```sample.pbmm2.jasmine.bam```. ```bash. jasmine raw.bam raw.jasmine.bam # get 5mC methylation informations. pbmm2 align CHM13.fa raw.jasmine.bam sample.pbmm2.jasmine.bam --preset HIFI # bam-to-bam mapping, keep methylation tags in bam file. ##. run deepvarint with sample.pbmm2.jasmine.bam. ```. The first way bam for small variant calling makes no mistakes. But considering the following methylation analysis also needs to map reads to reference genome, so if it is suitable for using mapped bam with methylation tags to call small variant, we only need to map once, this can save time and computational resources. So my question is, is that OK for us to use bam with methylation tags as the input of deepvariant? Is the performance difference between using ```fastq-mapping bam``` and ```bam-to-bam mapping bam```? best, . Wilson.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/888
https://github.com/google/deepvariant/issues/888:457,usability,input,input,457,"Call variant from bam file which includes methylation tags (MM/ML); Dear developers; . Thanks for the great tool for variant calling. I use deepvariant 1.6.1 for small variant calling from picbio HIFI data (Revio system). For HIFI data, there are two ways to get the input bam for deepvariant. The first, like we do in NGS data analysis, extracting fastq reads from raw HIFI bam and mapping the fastq reads to reference genome, eg. T2TCHM13v2, then get the input bam ( fastq-mapping bam ) ```sample.pbmm2.bam```. ```bash. bam2fastq -o sample.fastq raw.bam. pbmm2 align CHM13.fa sample.fastq sample.pbmm2.bam --preset HIFI. ##. run deepvarint with sample.pbmm2.bam . ```. The second, mapping from bam data with methylation signal to reference genome directly (bam-to-bam mapping) , ```sample.pbmm2.jasmine.bam```. ```bash. jasmine raw.bam raw.jasmine.bam # get 5mC methylation informations. pbmm2 align CHM13.fa raw.jasmine.bam sample.pbmm2.jasmine.bam --preset HIFI # bam-to-bam mapping, keep methylation tags in bam file. ##. run deepvarint with sample.pbmm2.jasmine.bam. ```. The first way bam for small variant calling makes no mistakes. But considering the following methylation analysis also needs to map reads to reference genome, so if it is suitable for using mapped bam with methylation tags to call small variant, we only need to map once, this can save time and computational resources. So my question is, is that OK for us to use bam with methylation tags as the input of deepvariant? Is the performance difference between using ```fastq-mapping bam``` and ```bam-to-bam mapping bam```? best, . Wilson.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/888
https://github.com/google/deepvariant/issues/888:1475,usability,input,input,1475,"Call variant from bam file which includes methylation tags (MM/ML); Dear developers; . Thanks for the great tool for variant calling. I use deepvariant 1.6.1 for small variant calling from picbio HIFI data (Revio system). For HIFI data, there are two ways to get the input bam for deepvariant. The first, like we do in NGS data analysis, extracting fastq reads from raw HIFI bam and mapping the fastq reads to reference genome, eg. T2TCHM13v2, then get the input bam ( fastq-mapping bam ) ```sample.pbmm2.bam```. ```bash. bam2fastq -o sample.fastq raw.bam. pbmm2 align CHM13.fa sample.fastq sample.pbmm2.bam --preset HIFI. ##. run deepvarint with sample.pbmm2.bam . ```. The second, mapping from bam data with methylation signal to reference genome directly (bam-to-bam mapping) , ```sample.pbmm2.jasmine.bam```. ```bash. jasmine raw.bam raw.jasmine.bam # get 5mC methylation informations. pbmm2 align CHM13.fa raw.jasmine.bam sample.pbmm2.jasmine.bam --preset HIFI # bam-to-bam mapping, keep methylation tags in bam file. ##. run deepvarint with sample.pbmm2.jasmine.bam. ```. The first way bam for small variant calling makes no mistakes. But considering the following methylation analysis also needs to map reads to reference genome, so if it is suitable for using mapped bam with methylation tags to call small variant, we only need to map once, this can save time and computational resources. So my question is, is that OK for us to use bam with methylation tags as the input of deepvariant? Is the performance difference between using ```fastq-mapping bam``` and ```bam-to-bam mapping bam```? best, . Wilson.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/888
https://github.com/google/deepvariant/issues/888:1504,usability,perform,performance,1504,"Call variant from bam file which includes methylation tags (MM/ML); Dear developers; . Thanks for the great tool for variant calling. I use deepvariant 1.6.1 for small variant calling from picbio HIFI data (Revio system). For HIFI data, there are two ways to get the input bam for deepvariant. The first, like we do in NGS data analysis, extracting fastq reads from raw HIFI bam and mapping the fastq reads to reference genome, eg. T2TCHM13v2, then get the input bam ( fastq-mapping bam ) ```sample.pbmm2.bam```. ```bash. bam2fastq -o sample.fastq raw.bam. pbmm2 align CHM13.fa sample.fastq sample.pbmm2.bam --preset HIFI. ##. run deepvarint with sample.pbmm2.bam . ```. The second, mapping from bam data with methylation signal to reference genome directly (bam-to-bam mapping) , ```sample.pbmm2.jasmine.bam```. ```bash. jasmine raw.bam raw.jasmine.bam # get 5mC methylation informations. pbmm2 align CHM13.fa raw.jasmine.bam sample.pbmm2.jasmine.bam --preset HIFI # bam-to-bam mapping, keep methylation tags in bam file. ##. run deepvarint with sample.pbmm2.jasmine.bam. ```. The first way bam for small variant calling makes no mistakes. But considering the following methylation analysis also needs to map reads to reference genome, so if it is suitable for using mapped bam with methylation tags to call small variant, we only need to map once, this can save time and computational resources. So my question is, is that OK for us to use bam with methylation tags as the input of deepvariant? Is the performance difference between using ```fastq-mapping bam``` and ```bam-to-bam mapping bam```? best, . Wilson.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/888
https://github.com/google/deepvariant/issues/889:47,energy efficiency,current,currently,47,"Is deepvariant appropriate for my data. ; I am currently looking to call very small minor variants (e.g. less than 1%) using super deep HiFi data with ~8000 coverage for pseudomonas aeruginosa, is deep variant appropriate to use in this case? If so are there any options/flags/parameters that should be set a particular way?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/889
https://github.com/google/deepvariant/issues/889:277,modifiability,paramet,parameters,277,"Is deepvariant appropriate for my data. ; I am currently looking to call very small minor variants (e.g. less than 1%) using super deep HiFi data with ~8000 coverage for pseudomonas aeruginosa, is deep variant appropriate to use in this case? If so are there any options/flags/parameters that should be set a particular way?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/889
https://github.com/google/deepvariant/issues/889:157,testability,coverag,coverage,157,"Is deepvariant appropriate for my data. ; I am currently looking to call very small minor variants (e.g. less than 1%) using super deep HiFi data with ~8000 coverage for pseudomonas aeruginosa, is deep variant appropriate to use in this case? If so are there any options/flags/parameters that should be set a particular way?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/889
https://github.com/google/deepvariant/issues/890:828,availability,Operat,Operating,828,"Recommendations for variant call from long-read RNA-seq; **Describe the issue:**. Thank you so much for the great tool. . I'm working on a heterozygous mouse long-read RNA-seq dataset from PacBio and would like to perform variant call + phasing at read-level. I'm wondering whether you have some recommendations regarding the points below:. - I'm currently using `--model_type=PACBIO` with the bam files processed with `gatk SplitNCigarReads`. Does this model consider RNA editing? Or should I use `--model_type=WES`? I saw some discussions mentioning WES model considers RNA-editing in https://github.com/google/deepvariant/issues/775. - Is there anyway that I could integrate the known variants from genomic data into the variant calling? Or should it be integrated after `DeepVariant` variant call at vcf-level? **Setup**. - Operating system: Ubuntu 2.20. - DeepVariant version: v1.6.1. - Installation method (Docker, built from source, etc.): singularity. - Type of data: PacBio HiFi, mm10, long-read RNA-seq data. **Steps to reproduce:**. - Command:. ```. singularity run -B /usr/lib/locale/:/usr/lib/locale/ docker://google/deepvariant:1.6.1 \. /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO \. --ref=GRCm38.primary_assembly.genome.fa \. --reads=SNCR.bam \. --output_vcf=output.vcf.gz \. --num_shards 16. ```. Thank you so much for your kind help!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/890
https://github.com/google/deepvariant/issues/890:668,deployability,integr,integrate,668,"Recommendations for variant call from long-read RNA-seq; **Describe the issue:**. Thank you so much for the great tool. . I'm working on a heterozygous mouse long-read RNA-seq dataset from PacBio and would like to perform variant call + phasing at read-level. I'm wondering whether you have some recommendations regarding the points below:. - I'm currently using `--model_type=PACBIO` with the bam files processed with `gatk SplitNCigarReads`. Does this model consider RNA editing? Or should I use `--model_type=WES`? I saw some discussions mentioning WES model considers RNA-editing in https://github.com/google/deepvariant/issues/775. - Is there anyway that I could integrate the known variants from genomic data into the variant calling? Or should it be integrated after `DeepVariant` variant call at vcf-level? **Setup**. - Operating system: Ubuntu 2.20. - DeepVariant version: v1.6.1. - Installation method (Docker, built from source, etc.): singularity. - Type of data: PacBio HiFi, mm10, long-read RNA-seq data. **Steps to reproduce:**. - Command:. ```. singularity run -B /usr/lib/locale/:/usr/lib/locale/ docker://google/deepvariant:1.6.1 \. /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO \. --ref=GRCm38.primary_assembly.genome.fa \. --reads=SNCR.bam \. --output_vcf=output.vcf.gz \. --num_shards 16. ```. Thank you so much for your kind help!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/890
https://github.com/google/deepvariant/issues/890:757,deployability,integr,integrated,757,"Recommendations for variant call from long-read RNA-seq; **Describe the issue:**. Thank you so much for the great tool. . I'm working on a heterozygous mouse long-read RNA-seq dataset from PacBio and would like to perform variant call + phasing at read-level. I'm wondering whether you have some recommendations regarding the points below:. - I'm currently using `--model_type=PACBIO` with the bam files processed with `gatk SplitNCigarReads`. Does this model consider RNA editing? Or should I use `--model_type=WES`? I saw some discussions mentioning WES model considers RNA-editing in https://github.com/google/deepvariant/issues/775. - Is there anyway that I could integrate the known variants from genomic data into the variant calling? Or should it be integrated after `DeepVariant` variant call at vcf-level? **Setup**. - Operating system: Ubuntu 2.20. - DeepVariant version: v1.6.1. - Installation method (Docker, built from source, etc.): singularity. - Type of data: PacBio HiFi, mm10, long-read RNA-seq data. **Steps to reproduce:**. - Command:. ```. singularity run -B /usr/lib/locale/:/usr/lib/locale/ docker://google/deepvariant:1.6.1 \. /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO \. --ref=GRCm38.primary_assembly.genome.fa \. --reads=SNCR.bam \. --output_vcf=output.vcf.gz \. --num_shards 16. ```. Thank you so much for your kind help!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/890
https://github.com/google/deepvariant/issues/890:873,deployability,version,version,873,"Recommendations for variant call from long-read RNA-seq; **Describe the issue:**. Thank you so much for the great tool. . I'm working on a heterozygous mouse long-read RNA-seq dataset from PacBio and would like to perform variant call + phasing at read-level. I'm wondering whether you have some recommendations regarding the points below:. - I'm currently using `--model_type=PACBIO` with the bam files processed with `gatk SplitNCigarReads`. Does this model consider RNA editing? Or should I use `--model_type=WES`? I saw some discussions mentioning WES model considers RNA-editing in https://github.com/google/deepvariant/issues/775. - Is there anyway that I could integrate the known variants from genomic data into the variant calling? Or should it be integrated after `DeepVariant` variant call at vcf-level? **Setup**. - Operating system: Ubuntu 2.20. - DeepVariant version: v1.6.1. - Installation method (Docker, built from source, etc.): singularity. - Type of data: PacBio HiFi, mm10, long-read RNA-seq data. **Steps to reproduce:**. - Command:. ```. singularity run -B /usr/lib/locale/:/usr/lib/locale/ docker://google/deepvariant:1.6.1 \. /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO \. --ref=GRCm38.primary_assembly.genome.fa \. --reads=SNCR.bam \. --output_vcf=output.vcf.gz \. --num_shards 16. ```. Thank you so much for your kind help!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/890
https://github.com/google/deepvariant/issues/890:892,deployability,Instal,Installation,892,"Recommendations for variant call from long-read RNA-seq; **Describe the issue:**. Thank you so much for the great tool. . I'm working on a heterozygous mouse long-read RNA-seq dataset from PacBio and would like to perform variant call + phasing at read-level. I'm wondering whether you have some recommendations regarding the points below:. - I'm currently using `--model_type=PACBIO` with the bam files processed with `gatk SplitNCigarReads`. Does this model consider RNA editing? Or should I use `--model_type=WES`? I saw some discussions mentioning WES model considers RNA-editing in https://github.com/google/deepvariant/issues/775. - Is there anyway that I could integrate the known variants from genomic data into the variant calling? Or should it be integrated after `DeepVariant` variant call at vcf-level? **Setup**. - Operating system: Ubuntu 2.20. - DeepVariant version: v1.6.1. - Installation method (Docker, built from source, etc.): singularity. - Type of data: PacBio HiFi, mm10, long-read RNA-seq data. **Steps to reproduce:**. - Command:. ```. singularity run -B /usr/lib/locale/:/usr/lib/locale/ docker://google/deepvariant:1.6.1 \. /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO \. --ref=GRCm38.primary_assembly.genome.fa \. --reads=SNCR.bam \. --output_vcf=output.vcf.gz \. --num_shards 16. ```. Thank you so much for your kind help!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/890
https://github.com/google/deepvariant/issues/890:347,energy efficiency,current,currently,347,"Recommendations for variant call from long-read RNA-seq; **Describe the issue:**. Thank you so much for the great tool. . I'm working on a heterozygous mouse long-read RNA-seq dataset from PacBio and would like to perform variant call + phasing at read-level. I'm wondering whether you have some recommendations regarding the points below:. - I'm currently using `--model_type=PACBIO` with the bam files processed with `gatk SplitNCigarReads`. Does this model consider RNA editing? Or should I use `--model_type=WES`? I saw some discussions mentioning WES model considers RNA-editing in https://github.com/google/deepvariant/issues/775. - Is there anyway that I could integrate the known variants from genomic data into the variant calling? Or should it be integrated after `DeepVariant` variant call at vcf-level? **Setup**. - Operating system: Ubuntu 2.20. - DeepVariant version: v1.6.1. - Installation method (Docker, built from source, etc.): singularity. - Type of data: PacBio HiFi, mm10, long-read RNA-seq data. **Steps to reproduce:**. - Command:. ```. singularity run -B /usr/lib/locale/:/usr/lib/locale/ docker://google/deepvariant:1.6.1 \. /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO \. --ref=GRCm38.primary_assembly.genome.fa \. --reads=SNCR.bam \. --output_vcf=output.vcf.gz \. --num_shards 16. ```. Thank you so much for your kind help!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/890
https://github.com/google/deepvariant/issues/890:454,energy efficiency,model,model,454,"Recommendations for variant call from long-read RNA-seq; **Describe the issue:**. Thank you so much for the great tool. . I'm working on a heterozygous mouse long-read RNA-seq dataset from PacBio and would like to perform variant call + phasing at read-level. I'm wondering whether you have some recommendations regarding the points below:. - I'm currently using `--model_type=PACBIO` with the bam files processed with `gatk SplitNCigarReads`. Does this model consider RNA editing? Or should I use `--model_type=WES`? I saw some discussions mentioning WES model considers RNA-editing in https://github.com/google/deepvariant/issues/775. - Is there anyway that I could integrate the known variants from genomic data into the variant calling? Or should it be integrated after `DeepVariant` variant call at vcf-level? **Setup**. - Operating system: Ubuntu 2.20. - DeepVariant version: v1.6.1. - Installation method (Docker, built from source, etc.): singularity. - Type of data: PacBio HiFi, mm10, long-read RNA-seq data. **Steps to reproduce:**. - Command:. ```. singularity run -B /usr/lib/locale/:/usr/lib/locale/ docker://google/deepvariant:1.6.1 \. /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO \. --ref=GRCm38.primary_assembly.genome.fa \. --reads=SNCR.bam \. --output_vcf=output.vcf.gz \. --num_shards 16. ```. Thank you so much for your kind help!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/890
https://github.com/google/deepvariant/issues/890:556,energy efficiency,model,model,556,"Recommendations for variant call from long-read RNA-seq; **Describe the issue:**. Thank you so much for the great tool. . I'm working on a heterozygous mouse long-read RNA-seq dataset from PacBio and would like to perform variant call + phasing at read-level. I'm wondering whether you have some recommendations regarding the points below:. - I'm currently using `--model_type=PACBIO` with the bam files processed with `gatk SplitNCigarReads`. Does this model consider RNA editing? Or should I use `--model_type=WES`? I saw some discussions mentioning WES model considers RNA-editing in https://github.com/google/deepvariant/issues/775. - Is there anyway that I could integrate the known variants from genomic data into the variant calling? Or should it be integrated after `DeepVariant` variant call at vcf-level? **Setup**. - Operating system: Ubuntu 2.20. - DeepVariant version: v1.6.1. - Installation method (Docker, built from source, etc.): singularity. - Type of data: PacBio HiFi, mm10, long-read RNA-seq data. **Steps to reproduce:**. - Command:. ```. singularity run -B /usr/lib/locale/:/usr/lib/locale/ docker://google/deepvariant:1.6.1 \. /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO \. --ref=GRCm38.primary_assembly.genome.fa \. --reads=SNCR.bam \. --output_vcf=output.vcf.gz \. --num_shards 16. ```. Thank you so much for your kind help!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/890
https://github.com/google/deepvariant/issues/890:668,integrability,integr,integrate,668,"Recommendations for variant call from long-read RNA-seq; **Describe the issue:**. Thank you so much for the great tool. . I'm working on a heterozygous mouse long-read RNA-seq dataset from PacBio and would like to perform variant call + phasing at read-level. I'm wondering whether you have some recommendations regarding the points below:. - I'm currently using `--model_type=PACBIO` with the bam files processed with `gatk SplitNCigarReads`. Does this model consider RNA editing? Or should I use `--model_type=WES`? I saw some discussions mentioning WES model considers RNA-editing in https://github.com/google/deepvariant/issues/775. - Is there anyway that I could integrate the known variants from genomic data into the variant calling? Or should it be integrated after `DeepVariant` variant call at vcf-level? **Setup**. - Operating system: Ubuntu 2.20. - DeepVariant version: v1.6.1. - Installation method (Docker, built from source, etc.): singularity. - Type of data: PacBio HiFi, mm10, long-read RNA-seq data. **Steps to reproduce:**. - Command:. ```. singularity run -B /usr/lib/locale/:/usr/lib/locale/ docker://google/deepvariant:1.6.1 \. /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO \. --ref=GRCm38.primary_assembly.genome.fa \. --reads=SNCR.bam \. --output_vcf=output.vcf.gz \. --num_shards 16. ```. Thank you so much for your kind help!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/890
https://github.com/google/deepvariant/issues/890:757,integrability,integr,integrated,757,"Recommendations for variant call from long-read RNA-seq; **Describe the issue:**. Thank you so much for the great tool. . I'm working on a heterozygous mouse long-read RNA-seq dataset from PacBio and would like to perform variant call + phasing at read-level. I'm wondering whether you have some recommendations regarding the points below:. - I'm currently using `--model_type=PACBIO` with the bam files processed with `gatk SplitNCigarReads`. Does this model consider RNA editing? Or should I use `--model_type=WES`? I saw some discussions mentioning WES model considers RNA-editing in https://github.com/google/deepvariant/issues/775. - Is there anyway that I could integrate the known variants from genomic data into the variant calling? Or should it be integrated after `DeepVariant` variant call at vcf-level? **Setup**. - Operating system: Ubuntu 2.20. - DeepVariant version: v1.6.1. - Installation method (Docker, built from source, etc.): singularity. - Type of data: PacBio HiFi, mm10, long-read RNA-seq data. **Steps to reproduce:**. - Command:. ```. singularity run -B /usr/lib/locale/:/usr/lib/locale/ docker://google/deepvariant:1.6.1 \. /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO \. --ref=GRCm38.primary_assembly.genome.fa \. --reads=SNCR.bam \. --output_vcf=output.vcf.gz \. --num_shards 16. ```. Thank you so much for your kind help!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/890
https://github.com/google/deepvariant/issues/890:873,integrability,version,version,873,"Recommendations for variant call from long-read RNA-seq; **Describe the issue:**. Thank you so much for the great tool. . I'm working on a heterozygous mouse long-read RNA-seq dataset from PacBio and would like to perform variant call + phasing at read-level. I'm wondering whether you have some recommendations regarding the points below:. - I'm currently using `--model_type=PACBIO` with the bam files processed with `gatk SplitNCigarReads`. Does this model consider RNA editing? Or should I use `--model_type=WES`? I saw some discussions mentioning WES model considers RNA-editing in https://github.com/google/deepvariant/issues/775. - Is there anyway that I could integrate the known variants from genomic data into the variant calling? Or should it be integrated after `DeepVariant` variant call at vcf-level? **Setup**. - Operating system: Ubuntu 2.20. - DeepVariant version: v1.6.1. - Installation method (Docker, built from source, etc.): singularity. - Type of data: PacBio HiFi, mm10, long-read RNA-seq data. **Steps to reproduce:**. - Command:. ```. singularity run -B /usr/lib/locale/:/usr/lib/locale/ docker://google/deepvariant:1.6.1 \. /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO \. --ref=GRCm38.primary_assembly.genome.fa \. --reads=SNCR.bam \. --output_vcf=output.vcf.gz \. --num_shards 16. ```. Thank you so much for your kind help!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/890
https://github.com/google/deepvariant/issues/890:668,interoperability,integr,integrate,668,"Recommendations for variant call from long-read RNA-seq; **Describe the issue:**. Thank you so much for the great tool. . I'm working on a heterozygous mouse long-read RNA-seq dataset from PacBio and would like to perform variant call + phasing at read-level. I'm wondering whether you have some recommendations regarding the points below:. - I'm currently using `--model_type=PACBIO` with the bam files processed with `gatk SplitNCigarReads`. Does this model consider RNA editing? Or should I use `--model_type=WES`? I saw some discussions mentioning WES model considers RNA-editing in https://github.com/google/deepvariant/issues/775. - Is there anyway that I could integrate the known variants from genomic data into the variant calling? Or should it be integrated after `DeepVariant` variant call at vcf-level? **Setup**. - Operating system: Ubuntu 2.20. - DeepVariant version: v1.6.1. - Installation method (Docker, built from source, etc.): singularity. - Type of data: PacBio HiFi, mm10, long-read RNA-seq data. **Steps to reproduce:**. - Command:. ```. singularity run -B /usr/lib/locale/:/usr/lib/locale/ docker://google/deepvariant:1.6.1 \. /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO \. --ref=GRCm38.primary_assembly.genome.fa \. --reads=SNCR.bam \. --output_vcf=output.vcf.gz \. --num_shards 16. ```. Thank you so much for your kind help!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/890
https://github.com/google/deepvariant/issues/890:757,interoperability,integr,integrated,757,"Recommendations for variant call from long-read RNA-seq; **Describe the issue:**. Thank you so much for the great tool. . I'm working on a heterozygous mouse long-read RNA-seq dataset from PacBio and would like to perform variant call + phasing at read-level. I'm wondering whether you have some recommendations regarding the points below:. - I'm currently using `--model_type=PACBIO` with the bam files processed with `gatk SplitNCigarReads`. Does this model consider RNA editing? Or should I use `--model_type=WES`? I saw some discussions mentioning WES model considers RNA-editing in https://github.com/google/deepvariant/issues/775. - Is there anyway that I could integrate the known variants from genomic data into the variant calling? Or should it be integrated after `DeepVariant` variant call at vcf-level? **Setup**. - Operating system: Ubuntu 2.20. - DeepVariant version: v1.6.1. - Installation method (Docker, built from source, etc.): singularity. - Type of data: PacBio HiFi, mm10, long-read RNA-seq data. **Steps to reproduce:**. - Command:. ```. singularity run -B /usr/lib/locale/:/usr/lib/locale/ docker://google/deepvariant:1.6.1 \. /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO \. --ref=GRCm38.primary_assembly.genome.fa \. --reads=SNCR.bam \. --output_vcf=output.vcf.gz \. --num_shards 16. ```. Thank you so much for your kind help!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/890
https://github.com/google/deepvariant/issues/890:189,modifiability,Pac,PacBio,189,"Recommendations for variant call from long-read RNA-seq; **Describe the issue:**. Thank you so much for the great tool. . I'm working on a heterozygous mouse long-read RNA-seq dataset from PacBio and would like to perform variant call + phasing at read-level. I'm wondering whether you have some recommendations regarding the points below:. - I'm currently using `--model_type=PACBIO` with the bam files processed with `gatk SplitNCigarReads`. Does this model consider RNA editing? Or should I use `--model_type=WES`? I saw some discussions mentioning WES model considers RNA-editing in https://github.com/google/deepvariant/issues/775. - Is there anyway that I could integrate the known variants from genomic data into the variant calling? Or should it be integrated after `DeepVariant` variant call at vcf-level? **Setup**. - Operating system: Ubuntu 2.20. - DeepVariant version: v1.6.1. - Installation method (Docker, built from source, etc.): singularity. - Type of data: PacBio HiFi, mm10, long-read RNA-seq data. **Steps to reproduce:**. - Command:. ```. singularity run -B /usr/lib/locale/:/usr/lib/locale/ docker://google/deepvariant:1.6.1 \. /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO \. --ref=GRCm38.primary_assembly.genome.fa \. --reads=SNCR.bam \. --output_vcf=output.vcf.gz \. --num_shards 16. ```. Thank you so much for your kind help!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/890
https://github.com/google/deepvariant/issues/890:377,modifiability,PAC,PACBIO,377,"Recommendations for variant call from long-read RNA-seq; **Describe the issue:**. Thank you so much for the great tool. . I'm working on a heterozygous mouse long-read RNA-seq dataset from PacBio and would like to perform variant call + phasing at read-level. I'm wondering whether you have some recommendations regarding the points below:. - I'm currently using `--model_type=PACBIO` with the bam files processed with `gatk SplitNCigarReads`. Does this model consider RNA editing? Or should I use `--model_type=WES`? I saw some discussions mentioning WES model considers RNA-editing in https://github.com/google/deepvariant/issues/775. - Is there anyway that I could integrate the known variants from genomic data into the variant calling? Or should it be integrated after `DeepVariant` variant call at vcf-level? **Setup**. - Operating system: Ubuntu 2.20. - DeepVariant version: v1.6.1. - Installation method (Docker, built from source, etc.): singularity. - Type of data: PacBio HiFi, mm10, long-read RNA-seq data. **Steps to reproduce:**. - Command:. ```. singularity run -B /usr/lib/locale/:/usr/lib/locale/ docker://google/deepvariant:1.6.1 \. /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO \. --ref=GRCm38.primary_assembly.genome.fa \. --reads=SNCR.bam \. --output_vcf=output.vcf.gz \. --num_shards 16. ```. Thank you so much for your kind help!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/890
https://github.com/google/deepvariant/issues/890:668,modifiability,integr,integrate,668,"Recommendations for variant call from long-read RNA-seq; **Describe the issue:**. Thank you so much for the great tool. . I'm working on a heterozygous mouse long-read RNA-seq dataset from PacBio and would like to perform variant call + phasing at read-level. I'm wondering whether you have some recommendations regarding the points below:. - I'm currently using `--model_type=PACBIO` with the bam files processed with `gatk SplitNCigarReads`. Does this model consider RNA editing? Or should I use `--model_type=WES`? I saw some discussions mentioning WES model considers RNA-editing in https://github.com/google/deepvariant/issues/775. - Is there anyway that I could integrate the known variants from genomic data into the variant calling? Or should it be integrated after `DeepVariant` variant call at vcf-level? **Setup**. - Operating system: Ubuntu 2.20. - DeepVariant version: v1.6.1. - Installation method (Docker, built from source, etc.): singularity. - Type of data: PacBio HiFi, mm10, long-read RNA-seq data. **Steps to reproduce:**. - Command:. ```. singularity run -B /usr/lib/locale/:/usr/lib/locale/ docker://google/deepvariant:1.6.1 \. /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO \. --ref=GRCm38.primary_assembly.genome.fa \. --reads=SNCR.bam \. --output_vcf=output.vcf.gz \. --num_shards 16. ```. Thank you so much for your kind help!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/890
https://github.com/google/deepvariant/issues/890:757,modifiability,integr,integrated,757,"Recommendations for variant call from long-read RNA-seq; **Describe the issue:**. Thank you so much for the great tool. . I'm working on a heterozygous mouse long-read RNA-seq dataset from PacBio and would like to perform variant call + phasing at read-level. I'm wondering whether you have some recommendations regarding the points below:. - I'm currently using `--model_type=PACBIO` with the bam files processed with `gatk SplitNCigarReads`. Does this model consider RNA editing? Or should I use `--model_type=WES`? I saw some discussions mentioning WES model considers RNA-editing in https://github.com/google/deepvariant/issues/775. - Is there anyway that I could integrate the known variants from genomic data into the variant calling? Or should it be integrated after `DeepVariant` variant call at vcf-level? **Setup**. - Operating system: Ubuntu 2.20. - DeepVariant version: v1.6.1. - Installation method (Docker, built from source, etc.): singularity. - Type of data: PacBio HiFi, mm10, long-read RNA-seq data. **Steps to reproduce:**. - Command:. ```. singularity run -B /usr/lib/locale/:/usr/lib/locale/ docker://google/deepvariant:1.6.1 \. /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO \. --ref=GRCm38.primary_assembly.genome.fa \. --reads=SNCR.bam \. --output_vcf=output.vcf.gz \. --num_shards 16. ```. Thank you so much for your kind help!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/890
https://github.com/google/deepvariant/issues/890:873,modifiability,version,version,873,"Recommendations for variant call from long-read RNA-seq; **Describe the issue:**. Thank you so much for the great tool. . I'm working on a heterozygous mouse long-read RNA-seq dataset from PacBio and would like to perform variant call + phasing at read-level. I'm wondering whether you have some recommendations regarding the points below:. - I'm currently using `--model_type=PACBIO` with the bam files processed with `gatk SplitNCigarReads`. Does this model consider RNA editing? Or should I use `--model_type=WES`? I saw some discussions mentioning WES model considers RNA-editing in https://github.com/google/deepvariant/issues/775. - Is there anyway that I could integrate the known variants from genomic data into the variant calling? Or should it be integrated after `DeepVariant` variant call at vcf-level? **Setup**. - Operating system: Ubuntu 2.20. - DeepVariant version: v1.6.1. - Installation method (Docker, built from source, etc.): singularity. - Type of data: PacBio HiFi, mm10, long-read RNA-seq data. **Steps to reproduce:**. - Command:. ```. singularity run -B /usr/lib/locale/:/usr/lib/locale/ docker://google/deepvariant:1.6.1 \. /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO \. --ref=GRCm38.primary_assembly.genome.fa \. --reads=SNCR.bam \. --output_vcf=output.vcf.gz \. --num_shards 16. ```. Thank you so much for your kind help!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/890
https://github.com/google/deepvariant/issues/890:976,modifiability,Pac,PacBio,976,"Recommendations for variant call from long-read RNA-seq; **Describe the issue:**. Thank you so much for the great tool. . I'm working on a heterozygous mouse long-read RNA-seq dataset from PacBio and would like to perform variant call + phasing at read-level. I'm wondering whether you have some recommendations regarding the points below:. - I'm currently using `--model_type=PACBIO` with the bam files processed with `gatk SplitNCigarReads`. Does this model consider RNA editing? Or should I use `--model_type=WES`? I saw some discussions mentioning WES model considers RNA-editing in https://github.com/google/deepvariant/issues/775. - Is there anyway that I could integrate the known variants from genomic data into the variant calling? Or should it be integrated after `DeepVariant` variant call at vcf-level? **Setup**. - Operating system: Ubuntu 2.20. - DeepVariant version: v1.6.1. - Installation method (Docker, built from source, etc.): singularity. - Type of data: PacBio HiFi, mm10, long-read RNA-seq data. **Steps to reproduce:**. - Command:. ```. singularity run -B /usr/lib/locale/:/usr/lib/locale/ docker://google/deepvariant:1.6.1 \. /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO \. --ref=GRCm38.primary_assembly.genome.fa \. --reads=SNCR.bam \. --output_vcf=output.vcf.gz \. --num_shards 16. ```. Thank you so much for your kind help!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/890
https://github.com/google/deepvariant/issues/890:1204,modifiability,PAC,PACBIO,1204,"Recommendations for variant call from long-read RNA-seq; **Describe the issue:**. Thank you so much for the great tool. . I'm working on a heterozygous mouse long-read RNA-seq dataset from PacBio and would like to perform variant call + phasing at read-level. I'm wondering whether you have some recommendations regarding the points below:. - I'm currently using `--model_type=PACBIO` with the bam files processed with `gatk SplitNCigarReads`. Does this model consider RNA editing? Or should I use `--model_type=WES`? I saw some discussions mentioning WES model considers RNA-editing in https://github.com/google/deepvariant/issues/775. - Is there anyway that I could integrate the known variants from genomic data into the variant calling? Or should it be integrated after `DeepVariant` variant call at vcf-level? **Setup**. - Operating system: Ubuntu 2.20. - DeepVariant version: v1.6.1. - Installation method (Docker, built from source, etc.): singularity. - Type of data: PacBio HiFi, mm10, long-read RNA-seq data. **Steps to reproduce:**. - Command:. ```. singularity run -B /usr/lib/locale/:/usr/lib/locale/ docker://google/deepvariant:1.6.1 \. /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO \. --ref=GRCm38.primary_assembly.genome.fa \. --reads=SNCR.bam \. --output_vcf=output.vcf.gz \. --num_shards 16. ```. Thank you so much for your kind help!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/890
https://github.com/google/deepvariant/issues/890:214,performance,perform,perform,214,"Recommendations for variant call from long-read RNA-seq; **Describe the issue:**. Thank you so much for the great tool. . I'm working on a heterozygous mouse long-read RNA-seq dataset from PacBio and would like to perform variant call + phasing at read-level. I'm wondering whether you have some recommendations regarding the points below:. - I'm currently using `--model_type=PACBIO` with the bam files processed with `gatk SplitNCigarReads`. Does this model consider RNA editing? Or should I use `--model_type=WES`? I saw some discussions mentioning WES model considers RNA-editing in https://github.com/google/deepvariant/issues/775. - Is there anyway that I could integrate the known variants from genomic data into the variant calling? Or should it be integrated after `DeepVariant` variant call at vcf-level? **Setup**. - Operating system: Ubuntu 2.20. - DeepVariant version: v1.6.1. - Installation method (Docker, built from source, etc.): singularity. - Type of data: PacBio HiFi, mm10, long-read RNA-seq data. **Steps to reproduce:**. - Command:. ```. singularity run -B /usr/lib/locale/:/usr/lib/locale/ docker://google/deepvariant:1.6.1 \. /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO \. --ref=GRCm38.primary_assembly.genome.fa \. --reads=SNCR.bam \. --output_vcf=output.vcf.gz \. --num_shards 16. ```. Thank you so much for your kind help!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/890
https://github.com/google/deepvariant/issues/890:444,reliability,Doe,Does,444,"Recommendations for variant call from long-read RNA-seq; **Describe the issue:**. Thank you so much for the great tool. . I'm working on a heterozygous mouse long-read RNA-seq dataset from PacBio and would like to perform variant call + phasing at read-level. I'm wondering whether you have some recommendations regarding the points below:. - I'm currently using `--model_type=PACBIO` with the bam files processed with `gatk SplitNCigarReads`. Does this model consider RNA editing? Or should I use `--model_type=WES`? I saw some discussions mentioning WES model considers RNA-editing in https://github.com/google/deepvariant/issues/775. - Is there anyway that I could integrate the known variants from genomic data into the variant calling? Or should it be integrated after `DeepVariant` variant call at vcf-level? **Setup**. - Operating system: Ubuntu 2.20. - DeepVariant version: v1.6.1. - Installation method (Docker, built from source, etc.): singularity. - Type of data: PacBio HiFi, mm10, long-read RNA-seq data. **Steps to reproduce:**. - Command:. ```. singularity run -B /usr/lib/locale/:/usr/lib/locale/ docker://google/deepvariant:1.6.1 \. /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO \. --ref=GRCm38.primary_assembly.genome.fa \. --reads=SNCR.bam \. --output_vcf=output.vcf.gz \. --num_shards 16. ```. Thank you so much for your kind help!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/890
https://github.com/google/deepvariant/issues/890:668,reliability,integr,integrate,668,"Recommendations for variant call from long-read RNA-seq; **Describe the issue:**. Thank you so much for the great tool. . I'm working on a heterozygous mouse long-read RNA-seq dataset from PacBio and would like to perform variant call + phasing at read-level. I'm wondering whether you have some recommendations regarding the points below:. - I'm currently using `--model_type=PACBIO` with the bam files processed with `gatk SplitNCigarReads`. Does this model consider RNA editing? Or should I use `--model_type=WES`? I saw some discussions mentioning WES model considers RNA-editing in https://github.com/google/deepvariant/issues/775. - Is there anyway that I could integrate the known variants from genomic data into the variant calling? Or should it be integrated after `DeepVariant` variant call at vcf-level? **Setup**. - Operating system: Ubuntu 2.20. - DeepVariant version: v1.6.1. - Installation method (Docker, built from source, etc.): singularity. - Type of data: PacBio HiFi, mm10, long-read RNA-seq data. **Steps to reproduce:**. - Command:. ```. singularity run -B /usr/lib/locale/:/usr/lib/locale/ docker://google/deepvariant:1.6.1 \. /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO \. --ref=GRCm38.primary_assembly.genome.fa \. --reads=SNCR.bam \. --output_vcf=output.vcf.gz \. --num_shards 16. ```. Thank you so much for your kind help!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/890
https://github.com/google/deepvariant/issues/890:757,reliability,integr,integrated,757,"Recommendations for variant call from long-read RNA-seq; **Describe the issue:**. Thank you so much for the great tool. . I'm working on a heterozygous mouse long-read RNA-seq dataset from PacBio and would like to perform variant call + phasing at read-level. I'm wondering whether you have some recommendations regarding the points below:. - I'm currently using `--model_type=PACBIO` with the bam files processed with `gatk SplitNCigarReads`. Does this model consider RNA editing? Or should I use `--model_type=WES`? I saw some discussions mentioning WES model considers RNA-editing in https://github.com/google/deepvariant/issues/775. - Is there anyway that I could integrate the known variants from genomic data into the variant calling? Or should it be integrated after `DeepVariant` variant call at vcf-level? **Setup**. - Operating system: Ubuntu 2.20. - DeepVariant version: v1.6.1. - Installation method (Docker, built from source, etc.): singularity. - Type of data: PacBio HiFi, mm10, long-read RNA-seq data. **Steps to reproduce:**. - Command:. ```. singularity run -B /usr/lib/locale/:/usr/lib/locale/ docker://google/deepvariant:1.6.1 \. /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO \. --ref=GRCm38.primary_assembly.genome.fa \. --reads=SNCR.bam \. --output_vcf=output.vcf.gz \. --num_shards 16. ```. Thank you so much for your kind help!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/890
https://github.com/google/deepvariant/issues/890:454,security,model,model,454,"Recommendations for variant call from long-read RNA-seq; **Describe the issue:**. Thank you so much for the great tool. . I'm working on a heterozygous mouse long-read RNA-seq dataset from PacBio and would like to perform variant call + phasing at read-level. I'm wondering whether you have some recommendations regarding the points below:. - I'm currently using `--model_type=PACBIO` with the bam files processed with `gatk SplitNCigarReads`. Does this model consider RNA editing? Or should I use `--model_type=WES`? I saw some discussions mentioning WES model considers RNA-editing in https://github.com/google/deepvariant/issues/775. - Is there anyway that I could integrate the known variants from genomic data into the variant calling? Or should it be integrated after `DeepVariant` variant call at vcf-level? **Setup**. - Operating system: Ubuntu 2.20. - DeepVariant version: v1.6.1. - Installation method (Docker, built from source, etc.): singularity. - Type of data: PacBio HiFi, mm10, long-read RNA-seq data. **Steps to reproduce:**. - Command:. ```. singularity run -B /usr/lib/locale/:/usr/lib/locale/ docker://google/deepvariant:1.6.1 \. /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO \. --ref=GRCm38.primary_assembly.genome.fa \. --reads=SNCR.bam \. --output_vcf=output.vcf.gz \. --num_shards 16. ```. Thank you so much for your kind help!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/890
https://github.com/google/deepvariant/issues/890:556,security,model,model,556,"Recommendations for variant call from long-read RNA-seq; **Describe the issue:**. Thank you so much for the great tool. . I'm working on a heterozygous mouse long-read RNA-seq dataset from PacBio and would like to perform variant call + phasing at read-level. I'm wondering whether you have some recommendations regarding the points below:. - I'm currently using `--model_type=PACBIO` with the bam files processed with `gatk SplitNCigarReads`. Does this model consider RNA editing? Or should I use `--model_type=WES`? I saw some discussions mentioning WES model considers RNA-editing in https://github.com/google/deepvariant/issues/775. - Is there anyway that I could integrate the known variants from genomic data into the variant calling? Or should it be integrated after `DeepVariant` variant call at vcf-level? **Setup**. - Operating system: Ubuntu 2.20. - DeepVariant version: v1.6.1. - Installation method (Docker, built from source, etc.): singularity. - Type of data: PacBio HiFi, mm10, long-read RNA-seq data. **Steps to reproduce:**. - Command:. ```. singularity run -B /usr/lib/locale/:/usr/lib/locale/ docker://google/deepvariant:1.6.1 \. /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO \. --ref=GRCm38.primary_assembly.genome.fa \. --reads=SNCR.bam \. --output_vcf=output.vcf.gz \. --num_shards 16. ```. Thank you so much for your kind help!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/890
https://github.com/google/deepvariant/issues/890:668,security,integr,integrate,668,"Recommendations for variant call from long-read RNA-seq; **Describe the issue:**. Thank you so much for the great tool. . I'm working on a heterozygous mouse long-read RNA-seq dataset from PacBio and would like to perform variant call + phasing at read-level. I'm wondering whether you have some recommendations regarding the points below:. - I'm currently using `--model_type=PACBIO` with the bam files processed with `gatk SplitNCigarReads`. Does this model consider RNA editing? Or should I use `--model_type=WES`? I saw some discussions mentioning WES model considers RNA-editing in https://github.com/google/deepvariant/issues/775. - Is there anyway that I could integrate the known variants from genomic data into the variant calling? Or should it be integrated after `DeepVariant` variant call at vcf-level? **Setup**. - Operating system: Ubuntu 2.20. - DeepVariant version: v1.6.1. - Installation method (Docker, built from source, etc.): singularity. - Type of data: PacBio HiFi, mm10, long-read RNA-seq data. **Steps to reproduce:**. - Command:. ```. singularity run -B /usr/lib/locale/:/usr/lib/locale/ docker://google/deepvariant:1.6.1 \. /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO \. --ref=GRCm38.primary_assembly.genome.fa \. --reads=SNCR.bam \. --output_vcf=output.vcf.gz \. --num_shards 16. ```. Thank you so much for your kind help!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/890
https://github.com/google/deepvariant/issues/890:757,security,integr,integrated,757,"Recommendations for variant call from long-read RNA-seq; **Describe the issue:**. Thank you so much for the great tool. . I'm working on a heterozygous mouse long-read RNA-seq dataset from PacBio and would like to perform variant call + phasing at read-level. I'm wondering whether you have some recommendations regarding the points below:. - I'm currently using `--model_type=PACBIO` with the bam files processed with `gatk SplitNCigarReads`. Does this model consider RNA editing? Or should I use `--model_type=WES`? I saw some discussions mentioning WES model considers RNA-editing in https://github.com/google/deepvariant/issues/775. - Is there anyway that I could integrate the known variants from genomic data into the variant calling? Or should it be integrated after `DeepVariant` variant call at vcf-level? **Setup**. - Operating system: Ubuntu 2.20. - DeepVariant version: v1.6.1. - Installation method (Docker, built from source, etc.): singularity. - Type of data: PacBio HiFi, mm10, long-read RNA-seq data. **Steps to reproduce:**. - Command:. ```. singularity run -B /usr/lib/locale/:/usr/lib/locale/ docker://google/deepvariant:1.6.1 \. /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO \. --ref=GRCm38.primary_assembly.genome.fa \. --reads=SNCR.bam \. --output_vcf=output.vcf.gz \. --num_shards 16. ```. Thank you so much for your kind help!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/890
https://github.com/google/deepvariant/issues/890:668,testability,integr,integrate,668,"Recommendations for variant call from long-read RNA-seq; **Describe the issue:**. Thank you so much for the great tool. . I'm working on a heterozygous mouse long-read RNA-seq dataset from PacBio and would like to perform variant call + phasing at read-level. I'm wondering whether you have some recommendations regarding the points below:. - I'm currently using `--model_type=PACBIO` with the bam files processed with `gatk SplitNCigarReads`. Does this model consider RNA editing? Or should I use `--model_type=WES`? I saw some discussions mentioning WES model considers RNA-editing in https://github.com/google/deepvariant/issues/775. - Is there anyway that I could integrate the known variants from genomic data into the variant calling? Or should it be integrated after `DeepVariant` variant call at vcf-level? **Setup**. - Operating system: Ubuntu 2.20. - DeepVariant version: v1.6.1. - Installation method (Docker, built from source, etc.): singularity. - Type of data: PacBio HiFi, mm10, long-read RNA-seq data. **Steps to reproduce:**. - Command:. ```. singularity run -B /usr/lib/locale/:/usr/lib/locale/ docker://google/deepvariant:1.6.1 \. /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO \. --ref=GRCm38.primary_assembly.genome.fa \. --reads=SNCR.bam \. --output_vcf=output.vcf.gz \. --num_shards 16. ```. Thank you so much for your kind help!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/890
https://github.com/google/deepvariant/issues/890:757,testability,integr,integrated,757,"Recommendations for variant call from long-read RNA-seq; **Describe the issue:**. Thank you so much for the great tool. . I'm working on a heterozygous mouse long-read RNA-seq dataset from PacBio and would like to perform variant call + phasing at read-level. I'm wondering whether you have some recommendations regarding the points below:. - I'm currently using `--model_type=PACBIO` with the bam files processed with `gatk SplitNCigarReads`. Does this model consider RNA editing? Or should I use `--model_type=WES`? I saw some discussions mentioning WES model considers RNA-editing in https://github.com/google/deepvariant/issues/775. - Is there anyway that I could integrate the known variants from genomic data into the variant calling? Or should it be integrated after `DeepVariant` variant call at vcf-level? **Setup**. - Operating system: Ubuntu 2.20. - DeepVariant version: v1.6.1. - Installation method (Docker, built from source, etc.): singularity. - Type of data: PacBio HiFi, mm10, long-read RNA-seq data. **Steps to reproduce:**. - Command:. ```. singularity run -B /usr/lib/locale/:/usr/lib/locale/ docker://google/deepvariant:1.6.1 \. /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO \. --ref=GRCm38.primary_assembly.genome.fa \. --reads=SNCR.bam \. --output_vcf=output.vcf.gz \. --num_shards 16. ```. Thank you so much for your kind help!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/890
https://github.com/google/deepvariant/issues/890:114,usability,tool,tool,114,"Recommendations for variant call from long-read RNA-seq; **Describe the issue:**. Thank you so much for the great tool. . I'm working on a heterozygous mouse long-read RNA-seq dataset from PacBio and would like to perform variant call + phasing at read-level. I'm wondering whether you have some recommendations regarding the points below:. - I'm currently using `--model_type=PACBIO` with the bam files processed with `gatk SplitNCigarReads`. Does this model consider RNA editing? Or should I use `--model_type=WES`? I saw some discussions mentioning WES model considers RNA-editing in https://github.com/google/deepvariant/issues/775. - Is there anyway that I could integrate the known variants from genomic data into the variant calling? Or should it be integrated after `DeepVariant` variant call at vcf-level? **Setup**. - Operating system: Ubuntu 2.20. - DeepVariant version: v1.6.1. - Installation method (Docker, built from source, etc.): singularity. - Type of data: PacBio HiFi, mm10, long-read RNA-seq data. **Steps to reproduce:**. - Command:. ```. singularity run -B /usr/lib/locale/:/usr/lib/locale/ docker://google/deepvariant:1.6.1 \. /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO \. --ref=GRCm38.primary_assembly.genome.fa \. --reads=SNCR.bam \. --output_vcf=output.vcf.gz \. --num_shards 16. ```. Thank you so much for your kind help!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/890
https://github.com/google/deepvariant/issues/890:152,usability,mous,mouse,152,"Recommendations for variant call from long-read RNA-seq; **Describe the issue:**. Thank you so much for the great tool. . I'm working on a heterozygous mouse long-read RNA-seq dataset from PacBio and would like to perform variant call + phasing at read-level. I'm wondering whether you have some recommendations regarding the points below:. - I'm currently using `--model_type=PACBIO` with the bam files processed with `gatk SplitNCigarReads`. Does this model consider RNA editing? Or should I use `--model_type=WES`? I saw some discussions mentioning WES model considers RNA-editing in https://github.com/google/deepvariant/issues/775. - Is there anyway that I could integrate the known variants from genomic data into the variant calling? Or should it be integrated after `DeepVariant` variant call at vcf-level? **Setup**. - Operating system: Ubuntu 2.20. - DeepVariant version: v1.6.1. - Installation method (Docker, built from source, etc.): singularity. - Type of data: PacBio HiFi, mm10, long-read RNA-seq data. **Steps to reproduce:**. - Command:. ```. singularity run -B /usr/lib/locale/:/usr/lib/locale/ docker://google/deepvariant:1.6.1 \. /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO \. --ref=GRCm38.primary_assembly.genome.fa \. --reads=SNCR.bam \. --output_vcf=output.vcf.gz \. --num_shards 16. ```. Thank you so much for your kind help!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/890
https://github.com/google/deepvariant/issues/890:214,usability,perform,perform,214,"Recommendations for variant call from long-read RNA-seq; **Describe the issue:**. Thank you so much for the great tool. . I'm working on a heterozygous mouse long-read RNA-seq dataset from PacBio and would like to perform variant call + phasing at read-level. I'm wondering whether you have some recommendations regarding the points below:. - I'm currently using `--model_type=PACBIO` with the bam files processed with `gatk SplitNCigarReads`. Does this model consider RNA editing? Or should I use `--model_type=WES`? I saw some discussions mentioning WES model considers RNA-editing in https://github.com/google/deepvariant/issues/775. - Is there anyway that I could integrate the known variants from genomic data into the variant calling? Or should it be integrated after `DeepVariant` variant call at vcf-level? **Setup**. - Operating system: Ubuntu 2.20. - DeepVariant version: v1.6.1. - Installation method (Docker, built from source, etc.): singularity. - Type of data: PacBio HiFi, mm10, long-read RNA-seq data. **Steps to reproduce:**. - Command:. ```. singularity run -B /usr/lib/locale/:/usr/lib/locale/ docker://google/deepvariant:1.6.1 \. /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO \. --ref=GRCm38.primary_assembly.genome.fa \. --reads=SNCR.bam \. --output_vcf=output.vcf.gz \. --num_shards 16. ```. Thank you so much for your kind help!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/890
https://github.com/google/deepvariant/issues/890:1046,usability,Command,Command,1046,"Recommendations for variant call from long-read RNA-seq; **Describe the issue:**. Thank you so much for the great tool. . I'm working on a heterozygous mouse long-read RNA-seq dataset from PacBio and would like to perform variant call + phasing at read-level. I'm wondering whether you have some recommendations regarding the points below:. - I'm currently using `--model_type=PACBIO` with the bam files processed with `gatk SplitNCigarReads`. Does this model consider RNA editing? Or should I use `--model_type=WES`? I saw some discussions mentioning WES model considers RNA-editing in https://github.com/google/deepvariant/issues/775. - Is there anyway that I could integrate the known variants from genomic data into the variant calling? Or should it be integrated after `DeepVariant` variant call at vcf-level? **Setup**. - Operating system: Ubuntu 2.20. - DeepVariant version: v1.6.1. - Installation method (Docker, built from source, etc.): singularity. - Type of data: PacBio HiFi, mm10, long-read RNA-seq data. **Steps to reproduce:**. - Command:. ```. singularity run -B /usr/lib/locale/:/usr/lib/locale/ docker://google/deepvariant:1.6.1 \. /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO \. --ref=GRCm38.primary_assembly.genome.fa \. --reads=SNCR.bam \. --output_vcf=output.vcf.gz \. --num_shards 16. ```. Thank you so much for your kind help!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/890
https://github.com/google/deepvariant/issues/890:1361,usability,help,help,1361,"Recommendations for variant call from long-read RNA-seq; **Describe the issue:**. Thank you so much for the great tool. . I'm working on a heterozygous mouse long-read RNA-seq dataset from PacBio and would like to perform variant call + phasing at read-level. I'm wondering whether you have some recommendations regarding the points below:. - I'm currently using `--model_type=PACBIO` with the bam files processed with `gatk SplitNCigarReads`. Does this model consider RNA editing? Or should I use `--model_type=WES`? I saw some discussions mentioning WES model considers RNA-editing in https://github.com/google/deepvariant/issues/775. - Is there anyway that I could integrate the known variants from genomic data into the variant calling? Or should it be integrated after `DeepVariant` variant call at vcf-level? **Setup**. - Operating system: Ubuntu 2.20. - DeepVariant version: v1.6.1. - Installation method (Docker, built from source, etc.): singularity. - Type of data: PacBio HiFi, mm10, long-read RNA-seq data. **Steps to reproduce:**. - Command:. ```. singularity run -B /usr/lib/locale/:/usr/lib/locale/ docker://google/deepvariant:1.6.1 \. /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO \. --ref=GRCm38.primary_assembly.genome.fa \. --reads=SNCR.bam \. --output_vcf=output.vcf.gz \. --num_shards 16. ```. Thank you so much for your kind help!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/890
https://github.com/google/deepvariant/issues/891:27,energy efficiency,model,model,27,"License of the DeepVariant model; Hi,. Thank you for this great work! I just wanted to learn about the license under which the Deepvariant model is shared?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/891
https://github.com/google/deepvariant/issues/891:139,energy efficiency,model,model,139,"License of the DeepVariant model; Hi,. Thank you for this great work! I just wanted to learn about the license under which the Deepvariant model is shared?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/891
https://github.com/google/deepvariant/issues/891:148,interoperability,share,shared,148,"License of the DeepVariant model; Hi,. Thank you for this great work! I just wanted to learn about the license under which the Deepvariant model is shared?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/891
https://github.com/google/deepvariant/issues/891:27,security,model,model,27,"License of the DeepVariant model; Hi,. Thank you for this great work! I just wanted to learn about the license under which the Deepvariant model is shared?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/891
https://github.com/google/deepvariant/issues/891:139,security,model,model,139,"License of the DeepVariant model; Hi,. Thank you for this great work! I just wanted to learn about the license under which the Deepvariant model is shared?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/891
https://github.com/google/deepvariant/issues/891:87,usability,learn,learn,87,"License of the DeepVariant model; Hi,. Thank you for this great work! I just wanted to learn about the license under which the Deepvariant model is shared?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/891
https://github.com/google/deepvariant/issues/892:505,deployability,version,version,505,"Variant not called although obvious in IGV; Hello,. I have the issue that two obvious variations are not called. This is WGS nanopore sequencing of a transgenic mouse. The region in question is alien sequence (human for the most part) that was introduced in the genome, so these reads connect to a certain region in the genome. There are three variations in the region and only one is called:. ![image](https://github.com/user-attachments/assets/857acbd1-991d-423a-a7f2-ccbaa5268ac3). This is my command (version 1.6.1 or 1.5.0 give the same result) :. ```. docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=ONT_R104 \. --ref=/input/$FASTA_FILE \. --reads=/input/$BAM_FILE \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --regions ""my_region"" \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=$(nproc) \. --postprocess_variants_extra_args=""debug_output_all_candidates=ALT"" \. --make_examples_extra_args=""vsc_min_count_snps=2,vsc_min_fraction_snps=0.06,vsc_min_count_indels=2,vsc_min_fraction_indels=0.06"". ```. I initially thought it might be this issue [https://github.com/google/deepvariant/issues/366](url) but the borders are more than 110 bp away. So is there any way to tackle this issue?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/892
https://github.com/google/deepvariant/issues/892:505,integrability,version,version,505,"Variant not called although obvious in IGV; Hello,. I have the issue that two obvious variations are not called. This is WGS nanopore sequencing of a transgenic mouse. The region in question is alien sequence (human for the most part) that was introduced in the genome, so these reads connect to a certain region in the genome. There are three variations in the region and only one is called:. ![image](https://github.com/user-attachments/assets/857acbd1-991d-423a-a7f2-ccbaa5268ac3). This is my command (version 1.6.1 or 1.5.0 give the same result) :. ```. docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=ONT_R104 \. --ref=/input/$FASTA_FILE \. --reads=/input/$BAM_FILE \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --regions ""my_region"" \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=$(nproc) \. --postprocess_variants_extra_args=""debug_output_all_candidates=ALT"" \. --make_examples_extra_args=""vsc_min_count_snps=2,vsc_min_fraction_snps=0.06,vsc_min_count_indels=2,vsc_min_fraction_indels=0.06"". ```. I initially thought it might be this issue [https://github.com/google/deepvariant/issues/366](url) but the borders are more than 110 bp away. So is there any way to tackle this issue?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/892
https://github.com/google/deepvariant/issues/892:505,modifiability,version,version,505,"Variant not called although obvious in IGV; Hello,. I have the issue that two obvious variations are not called. This is WGS nanopore sequencing of a transgenic mouse. The region in question is alien sequence (human for the most part) that was introduced in the genome, so these reads connect to a certain region in the genome. There are three variations in the region and only one is called:. ![image](https://github.com/user-attachments/assets/857acbd1-991d-423a-a7f2-ccbaa5268ac3). This is my command (version 1.6.1 or 1.5.0 give the same result) :. ```. docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=ONT_R104 \. --ref=/input/$FASTA_FILE \. --reads=/input/$BAM_FILE \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --regions ""my_region"" \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=$(nproc) \. --postprocess_variants_extra_args=""debug_output_all_candidates=ALT"" \. --make_examples_extra_args=""vsc_min_count_snps=2,vsc_min_fraction_snps=0.06,vsc_min_count_indels=2,vsc_min_fraction_indels=0.06"". ```. I initially thought it might be this issue [https://github.com/google/deepvariant/issues/366](url) but the borders are more than 110 bp away. So is there any way to tackle this issue?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/892
https://github.com/google/deepvariant/issues/892:592,safety,input,input,592,"Variant not called although obvious in IGV; Hello,. I have the issue that two obvious variations are not called. This is WGS nanopore sequencing of a transgenic mouse. The region in question is alien sequence (human for the most part) that was introduced in the genome, so these reads connect to a certain region in the genome. There are three variations in the region and only one is called:. ![image](https://github.com/user-attachments/assets/857acbd1-991d-423a-a7f2-ccbaa5268ac3). This is my command (version 1.6.1 or 1.5.0 give the same result) :. ```. docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=ONT_R104 \. --ref=/input/$FASTA_FILE \. --reads=/input/$BAM_FILE \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --regions ""my_region"" \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=$(nproc) \. --postprocess_variants_extra_args=""debug_output_all_candidates=ALT"" \. --make_examples_extra_args=""vsc_min_count_snps=2,vsc_min_fraction_snps=0.06,vsc_min_count_indels=2,vsc_min_fraction_indels=0.06"". ```. I initially thought it might be this issue [https://github.com/google/deepvariant/issues/366](url) but the borders are more than 110 bp away. So is there any way to tackle this issue?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/892
https://github.com/google/deepvariant/issues/892:745,safety,input,input,745,"Variant not called although obvious in IGV; Hello,. I have the issue that two obvious variations are not called. This is WGS nanopore sequencing of a transgenic mouse. The region in question is alien sequence (human for the most part) that was introduced in the genome, so these reads connect to a certain region in the genome. There are three variations in the region and only one is called:. ![image](https://github.com/user-attachments/assets/857acbd1-991d-423a-a7f2-ccbaa5268ac3). This is my command (version 1.6.1 or 1.5.0 give the same result) :. ```. docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=ONT_R104 \. --ref=/input/$FASTA_FILE \. --reads=/input/$BAM_FILE \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --regions ""my_region"" \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=$(nproc) \. --postprocess_variants_extra_args=""debug_output_all_candidates=ALT"" \. --make_examples_extra_args=""vsc_min_count_snps=2,vsc_min_fraction_snps=0.06,vsc_min_count_indels=2,vsc_min_fraction_indels=0.06"". ```. I initially thought it might be this issue [https://github.com/google/deepvariant/issues/366](url) but the borders are more than 110 bp away. So is there any way to tackle this issue?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/892
https://github.com/google/deepvariant/issues/892:775,safety,input,input,775,"Variant not called although obvious in IGV; Hello,. I have the issue that two obvious variations are not called. This is WGS nanopore sequencing of a transgenic mouse. The region in question is alien sequence (human for the most part) that was introduced in the genome, so these reads connect to a certain region in the genome. There are three variations in the region and only one is called:. ![image](https://github.com/user-attachments/assets/857acbd1-991d-423a-a7f2-ccbaa5268ac3). This is my command (version 1.6.1 or 1.5.0 give the same result) :. ```. docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=ONT_R104 \. --ref=/input/$FASTA_FILE \. --reads=/input/$BAM_FILE \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --regions ""my_region"" \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=$(nproc) \. --postprocess_variants_extra_args=""debug_output_all_candidates=ALT"" \. --make_examples_extra_args=""vsc_min_count_snps=2,vsc_min_fraction_snps=0.06,vsc_min_count_indels=2,vsc_min_fraction_indels=0.06"". ```. I initially thought it might be this issue [https://github.com/google/deepvariant/issues/366](url) but the borders are more than 110 bp away. So is there any way to tackle this issue?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/892
https://github.com/google/deepvariant/issues/892:161,usability,mous,mouse,161,"Variant not called although obvious in IGV; Hello,. I have the issue that two obvious variations are not called. This is WGS nanopore sequencing of a transgenic mouse. The region in question is alien sequence (human for the most part) that was introduced in the genome, so these reads connect to a certain region in the genome. There are three variations in the region and only one is called:. ![image](https://github.com/user-attachments/assets/857acbd1-991d-423a-a7f2-ccbaa5268ac3). This is my command (version 1.6.1 or 1.5.0 give the same result) :. ```. docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=ONT_R104 \. --ref=/input/$FASTA_FILE \. --reads=/input/$BAM_FILE \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --regions ""my_region"" \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=$(nproc) \. --postprocess_variants_extra_args=""debug_output_all_candidates=ALT"" \. --make_examples_extra_args=""vsc_min_count_snps=2,vsc_min_fraction_snps=0.06,vsc_min_count_indels=2,vsc_min_fraction_indels=0.06"". ```. I initially thought it might be this issue [https://github.com/google/deepvariant/issues/366](url) but the borders are more than 110 bp away. So is there any way to tackle this issue?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/892
https://github.com/google/deepvariant/issues/892:422,usability,user,user-attachments,422,"Variant not called although obvious in IGV; Hello,. I have the issue that two obvious variations are not called. This is WGS nanopore sequencing of a transgenic mouse. The region in question is alien sequence (human for the most part) that was introduced in the genome, so these reads connect to a certain region in the genome. There are three variations in the region and only one is called:. ![image](https://github.com/user-attachments/assets/857acbd1-991d-423a-a7f2-ccbaa5268ac3). This is my command (version 1.6.1 or 1.5.0 give the same result) :. ```. docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=ONT_R104 \. --ref=/input/$FASTA_FILE \. --reads=/input/$BAM_FILE \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --regions ""my_region"" \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=$(nproc) \. --postprocess_variants_extra_args=""debug_output_all_candidates=ALT"" \. --make_examples_extra_args=""vsc_min_count_snps=2,vsc_min_fraction_snps=0.06,vsc_min_count_indels=2,vsc_min_fraction_indels=0.06"". ```. I initially thought it might be this issue [https://github.com/google/deepvariant/issues/366](url) but the borders are more than 110 bp away. So is there any way to tackle this issue?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/892
https://github.com/google/deepvariant/issues/892:496,usability,command,command,496,"Variant not called although obvious in IGV; Hello,. I have the issue that two obvious variations are not called. This is WGS nanopore sequencing of a transgenic mouse. The region in question is alien sequence (human for the most part) that was introduced in the genome, so these reads connect to a certain region in the genome. There are three variations in the region and only one is called:. ![image](https://github.com/user-attachments/assets/857acbd1-991d-423a-a7f2-ccbaa5268ac3). This is my command (version 1.6.1 or 1.5.0 give the same result) :. ```. docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=ONT_R104 \. --ref=/input/$FASTA_FILE \. --reads=/input/$BAM_FILE \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --regions ""my_region"" \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=$(nproc) \. --postprocess_variants_extra_args=""debug_output_all_candidates=ALT"" \. --make_examples_extra_args=""vsc_min_count_snps=2,vsc_min_fraction_snps=0.06,vsc_min_count_indels=2,vsc_min_fraction_indels=0.06"". ```. I initially thought it might be this issue [https://github.com/google/deepvariant/issues/366](url) but the borders are more than 110 bp away. So is there any way to tackle this issue?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/892
https://github.com/google/deepvariant/issues/892:592,usability,input,input,592,"Variant not called although obvious in IGV; Hello,. I have the issue that two obvious variations are not called. This is WGS nanopore sequencing of a transgenic mouse. The region in question is alien sequence (human for the most part) that was introduced in the genome, so these reads connect to a certain region in the genome. There are three variations in the region and only one is called:. ![image](https://github.com/user-attachments/assets/857acbd1-991d-423a-a7f2-ccbaa5268ac3). This is my command (version 1.6.1 or 1.5.0 give the same result) :. ```. docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=ONT_R104 \. --ref=/input/$FASTA_FILE \. --reads=/input/$BAM_FILE \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --regions ""my_region"" \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=$(nproc) \. --postprocess_variants_extra_args=""debug_output_all_candidates=ALT"" \. --make_examples_extra_args=""vsc_min_count_snps=2,vsc_min_fraction_snps=0.06,vsc_min_count_indels=2,vsc_min_fraction_indels=0.06"". ```. I initially thought it might be this issue [https://github.com/google/deepvariant/issues/366](url) but the borders are more than 110 bp away. So is there any way to tackle this issue?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/892
https://github.com/google/deepvariant/issues/892:745,usability,input,input,745,"Variant not called although obvious in IGV; Hello,. I have the issue that two obvious variations are not called. This is WGS nanopore sequencing of a transgenic mouse. The region in question is alien sequence (human for the most part) that was introduced in the genome, so these reads connect to a certain region in the genome. There are three variations in the region and only one is called:. ![image](https://github.com/user-attachments/assets/857acbd1-991d-423a-a7f2-ccbaa5268ac3). This is my command (version 1.6.1 or 1.5.0 give the same result) :. ```. docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=ONT_R104 \. --ref=/input/$FASTA_FILE \. --reads=/input/$BAM_FILE \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --regions ""my_region"" \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=$(nproc) \. --postprocess_variants_extra_args=""debug_output_all_candidates=ALT"" \. --make_examples_extra_args=""vsc_min_count_snps=2,vsc_min_fraction_snps=0.06,vsc_min_count_indels=2,vsc_min_fraction_indels=0.06"". ```. I initially thought it might be this issue [https://github.com/google/deepvariant/issues/366](url) but the borders are more than 110 bp away. So is there any way to tackle this issue?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/892
https://github.com/google/deepvariant/issues/892:775,usability,input,input,775,"Variant not called although obvious in IGV; Hello,. I have the issue that two obvious variations are not called. This is WGS nanopore sequencing of a transgenic mouse. The region in question is alien sequence (human for the most part) that was introduced in the genome, so these reads connect to a certain region in the genome. There are three variations in the region and only one is called:. ![image](https://github.com/user-attachments/assets/857acbd1-991d-423a-a7f2-ccbaa5268ac3). This is my command (version 1.6.1 or 1.5.0 give the same result) :. ```. docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=ONT_R104 \. --ref=/input/$FASTA_FILE \. --reads=/input/$BAM_FILE \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --regions ""my_region"" \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=$(nproc) \. --postprocess_variants_extra_args=""debug_output_all_candidates=ALT"" \. --make_examples_extra_args=""vsc_min_count_snps=2,vsc_min_fraction_snps=0.06,vsc_min_count_indels=2,vsc_min_fraction_indels=0.06"". ```. I initially thought it might be this issue [https://github.com/google/deepvariant/issues/366](url) but the borders are more than 110 bp away. So is there any way to tackle this issue?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/892
https://github.com/google/deepvariant/issues/893:499,deployability,log,log,499,"question about pileup image height; Hello,. When I trained DeepVariant, I set pileup_image_height=75. My question is, when I run DeepVariant to evaluate with a trained model, do I have to add this parameter --make_examples_extra_args=""pileup_image_height=75"" . I tested running with and without parameter and I noticed I have better precision and accuracy not using this parameter. However, I have 'call_variants.py:623] Input shape [100, 221, 7] and model shape [75, 221, 7] does not match.' in my log file when I do not add this parameter --make_examples_extra_args=""pileup_image_height=75"". . Which way is the correct way to do? Thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/893
https://github.com/google/deepvariant/issues/893:168,energy efficiency,model,model,168,"question about pileup image height; Hello,. When I trained DeepVariant, I set pileup_image_height=75. My question is, when I run DeepVariant to evaluate with a trained model, do I have to add this parameter --make_examples_extra_args=""pileup_image_height=75"" . I tested running with and without parameter and I noticed I have better precision and accuracy not using this parameter. However, I have 'call_variants.py:623] Input shape [100, 221, 7] and model shape [75, 221, 7] does not match.' in my log file when I do not add this parameter --make_examples_extra_args=""pileup_image_height=75"". . Which way is the correct way to do? Thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/893
https://github.com/google/deepvariant/issues/893:451,energy efficiency,model,model,451,"question about pileup image height; Hello,. When I trained DeepVariant, I set pileup_image_height=75. My question is, when I run DeepVariant to evaluate with a trained model, do I have to add this parameter --make_examples_extra_args=""pileup_image_height=75"" . I tested running with and without parameter and I noticed I have better precision and accuracy not using this parameter. However, I have 'call_variants.py:623] Input shape [100, 221, 7] and model shape [75, 221, 7] does not match.' in my log file when I do not add this parameter --make_examples_extra_args=""pileup_image_height=75"". . Which way is the correct way to do? Thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/893
https://github.com/google/deepvariant/issues/893:197,modifiability,paramet,parameter,197,"question about pileup image height; Hello,. When I trained DeepVariant, I set pileup_image_height=75. My question is, when I run DeepVariant to evaluate with a trained model, do I have to add this parameter --make_examples_extra_args=""pileup_image_height=75"" . I tested running with and without parameter and I noticed I have better precision and accuracy not using this parameter. However, I have 'call_variants.py:623] Input shape [100, 221, 7] and model shape [75, 221, 7] does not match.' in my log file when I do not add this parameter --make_examples_extra_args=""pileup_image_height=75"". . Which way is the correct way to do? Thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/893
https://github.com/google/deepvariant/issues/893:295,modifiability,paramet,parameter,295,"question about pileup image height; Hello,. When I trained DeepVariant, I set pileup_image_height=75. My question is, when I run DeepVariant to evaluate with a trained model, do I have to add this parameter --make_examples_extra_args=""pileup_image_height=75"" . I tested running with and without parameter and I noticed I have better precision and accuracy not using this parameter. However, I have 'call_variants.py:623] Input shape [100, 221, 7] and model shape [75, 221, 7] does not match.' in my log file when I do not add this parameter --make_examples_extra_args=""pileup_image_height=75"". . Which way is the correct way to do? Thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/893
https://github.com/google/deepvariant/issues/893:371,modifiability,paramet,parameter,371,"question about pileup image height; Hello,. When I trained DeepVariant, I set pileup_image_height=75. My question is, when I run DeepVariant to evaluate with a trained model, do I have to add this parameter --make_examples_extra_args=""pileup_image_height=75"" . I tested running with and without parameter and I noticed I have better precision and accuracy not using this parameter. However, I have 'call_variants.py:623] Input shape [100, 221, 7] and model shape [75, 221, 7] does not match.' in my log file when I do not add this parameter --make_examples_extra_args=""pileup_image_height=75"". . Which way is the correct way to do? Thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/893
https://github.com/google/deepvariant/issues/893:531,modifiability,paramet,parameter,531,"question about pileup image height; Hello,. When I trained DeepVariant, I set pileup_image_height=75. My question is, when I run DeepVariant to evaluate with a trained model, do I have to add this parameter --make_examples_extra_args=""pileup_image_height=75"" . I tested running with and without parameter and I noticed I have better precision and accuracy not using this parameter. However, I have 'call_variants.py:623] Input shape [100, 221, 7] and model shape [75, 221, 7] does not match.' in my log file when I do not add this parameter --make_examples_extra_args=""pileup_image_height=75"". . Which way is the correct way to do? Thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/893
https://github.com/google/deepvariant/issues/893:476,reliability,doe,does,476,"question about pileup image height; Hello,. When I trained DeepVariant, I set pileup_image_height=75. My question is, when I run DeepVariant to evaluate with a trained model, do I have to add this parameter --make_examples_extra_args=""pileup_image_height=75"" . I tested running with and without parameter and I noticed I have better precision and accuracy not using this parameter. However, I have 'call_variants.py:623] Input shape [100, 221, 7] and model shape [75, 221, 7] does not match.' in my log file when I do not add this parameter --make_examples_extra_args=""pileup_image_height=75"". . Which way is the correct way to do? Thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/893
https://github.com/google/deepvariant/issues/893:263,safety,test,tested,263,"question about pileup image height; Hello,. When I trained DeepVariant, I set pileup_image_height=75. My question is, when I run DeepVariant to evaluate with a trained model, do I have to add this parameter --make_examples_extra_args=""pileup_image_height=75"" . I tested running with and without parameter and I noticed I have better precision and accuracy not using this parameter. However, I have 'call_variants.py:623] Input shape [100, 221, 7] and model shape [75, 221, 7] does not match.' in my log file when I do not add this parameter --make_examples_extra_args=""pileup_image_height=75"". . Which way is the correct way to do? Thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/893
https://github.com/google/deepvariant/issues/893:421,safety,Input,Input,421,"question about pileup image height; Hello,. When I trained DeepVariant, I set pileup_image_height=75. My question is, when I run DeepVariant to evaluate with a trained model, do I have to add this parameter --make_examples_extra_args=""pileup_image_height=75"" . I tested running with and without parameter and I noticed I have better precision and accuracy not using this parameter. However, I have 'call_variants.py:623] Input shape [100, 221, 7] and model shape [75, 221, 7] does not match.' in my log file when I do not add this parameter --make_examples_extra_args=""pileup_image_height=75"". . Which way is the correct way to do? Thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/893
https://github.com/google/deepvariant/issues/893:499,safety,log,log,499,"question about pileup image height; Hello,. When I trained DeepVariant, I set pileup_image_height=75. My question is, when I run DeepVariant to evaluate with a trained model, do I have to add this parameter --make_examples_extra_args=""pileup_image_height=75"" . I tested running with and without parameter and I noticed I have better precision and accuracy not using this parameter. However, I have 'call_variants.py:623] Input shape [100, 221, 7] and model shape [75, 221, 7] does not match.' in my log file when I do not add this parameter --make_examples_extra_args=""pileup_image_height=75"". . Which way is the correct way to do? Thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/893
https://github.com/google/deepvariant/issues/893:168,security,model,model,168,"question about pileup image height; Hello,. When I trained DeepVariant, I set pileup_image_height=75. My question is, when I run DeepVariant to evaluate with a trained model, do I have to add this parameter --make_examples_extra_args=""pileup_image_height=75"" . I tested running with and without parameter and I noticed I have better precision and accuracy not using this parameter. However, I have 'call_variants.py:623] Input shape [100, 221, 7] and model shape [75, 221, 7] does not match.' in my log file when I do not add this parameter --make_examples_extra_args=""pileup_image_height=75"". . Which way is the correct way to do? Thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/893
https://github.com/google/deepvariant/issues/893:451,security,model,model,451,"question about pileup image height; Hello,. When I trained DeepVariant, I set pileup_image_height=75. My question is, when I run DeepVariant to evaluate with a trained model, do I have to add this parameter --make_examples_extra_args=""pileup_image_height=75"" . I tested running with and without parameter and I noticed I have better precision and accuracy not using this parameter. However, I have 'call_variants.py:623] Input shape [100, 221, 7] and model shape [75, 221, 7] does not match.' in my log file when I do not add this parameter --make_examples_extra_args=""pileup_image_height=75"". . Which way is the correct way to do? Thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/893
https://github.com/google/deepvariant/issues/893:499,security,log,log,499,"question about pileup image height; Hello,. When I trained DeepVariant, I set pileup_image_height=75. My question is, when I run DeepVariant to evaluate with a trained model, do I have to add this parameter --make_examples_extra_args=""pileup_image_height=75"" . I tested running with and without parameter and I noticed I have better precision and accuracy not using this parameter. However, I have 'call_variants.py:623] Input shape [100, 221, 7] and model shape [75, 221, 7] does not match.' in my log file when I do not add this parameter --make_examples_extra_args=""pileup_image_height=75"". . Which way is the correct way to do? Thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/893
https://github.com/google/deepvariant/issues/893:263,testability,test,tested,263,"question about pileup image height; Hello,. When I trained DeepVariant, I set pileup_image_height=75. My question is, when I run DeepVariant to evaluate with a trained model, do I have to add this parameter --make_examples_extra_args=""pileup_image_height=75"" . I tested running with and without parameter and I noticed I have better precision and accuracy not using this parameter. However, I have 'call_variants.py:623] Input shape [100, 221, 7] and model shape [75, 221, 7] does not match.' in my log file when I do not add this parameter --make_examples_extra_args=""pileup_image_height=75"". . Which way is the correct way to do? Thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/893
https://github.com/google/deepvariant/issues/893:499,testability,log,log,499,"question about pileup image height; Hello,. When I trained DeepVariant, I set pileup_image_height=75. My question is, when I run DeepVariant to evaluate with a trained model, do I have to add this parameter --make_examples_extra_args=""pileup_image_height=75"" . I tested running with and without parameter and I noticed I have better precision and accuracy not using this parameter. However, I have 'call_variants.py:623] Input shape [100, 221, 7] and model shape [75, 221, 7] does not match.' in my log file when I do not add this parameter --make_examples_extra_args=""pileup_image_height=75"". . Which way is the correct way to do? Thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/893
https://github.com/google/deepvariant/issues/893:421,usability,Input,Input,421,"question about pileup image height; Hello,. When I trained DeepVariant, I set pileup_image_height=75. My question is, when I run DeepVariant to evaluate with a trained model, do I have to add this parameter --make_examples_extra_args=""pileup_image_height=75"" . I tested running with and without parameter and I noticed I have better precision and accuracy not using this parameter. However, I have 'call_variants.py:623] Input shape [100, 221, 7] and model shape [75, 221, 7] does not match.' in my log file when I do not add this parameter --make_examples_extra_args=""pileup_image_height=75"". . Which way is the correct way to do? Thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/893
https://github.com/google/deepvariant/issues/894:21,energy efficiency,model,model,21,"issue with retrained model; Hi,. Here is a set of additional parameter I used in 'make_examples' step to create examples for retraining DeepVariant:. --min_base_quality 5 \. --min_mapping_quality 1 \. --vsc_min_fraction_snps 0.02 \. --p_error 0.1 \. After retraining DeepVariant and get the model with best score, I compared the vcf outputs using default DeepVariant and retrained DeepVariant model on HG003 sample at chromosome20. I notice that there are many variants that two models classify differently. Here is an example of the difference:. default model:. chr20 61083 . C T 33.3 PASS . GT:GQ:DP:AD:VAF:PL 0/1:33:40:19,21:0.525:33,0,42. chr20 11479054 . A G 56.6 PASS . GT:GQ:DP:AD:VAF:PL 1/1:53:29:0,29:1:56,55,0. chr20 29356747 . A G 43.4 PASS . GT:GQ:DP:AD:VAF:PL 1/1:29:26:0,26:1:43,29,0. chr20	54889360	.	G	A	56.8	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:54:39:0,39:1:56,57,0. trained model:. chr20 61083 . C T 24.9 PASS . GT:GQ:DP:AD:VAF:PL 0/1:18:41:19,21:0.512195:24,0,18. chr20 11479054 . A G 0 RefCall . GT:GQ:DP:AD:VAF:PL 0/0:36:29:0,29:1:0,47,36. chr20 29356747 . A G 0 RefCall . GT:GQ:DP:AD:VAF:PL 0/0:33:28:0,28:1:0,47,33. chr20	54889360	.	G	A	0.5	RefCall	.	GT:GQ:DP:AD:VAF:PL	./.:10:39:0,39:1:0,29,9. Is there an output from DeepVariant (e.g intermediate files) that help me to understand how DV make decision on classifying the variant? My goal is to train DeepVariant so that it can keep those 'PASS' variants as in the default model and detect more variants in the dataset. Please advise how I can do that. Thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/894
https://github.com/google/deepvariant/issues/894:291,energy efficiency,model,model,291,"issue with retrained model; Hi,. Here is a set of additional parameter I used in 'make_examples' step to create examples for retraining DeepVariant:. --min_base_quality 5 \. --min_mapping_quality 1 \. --vsc_min_fraction_snps 0.02 \. --p_error 0.1 \. After retraining DeepVariant and get the model with best score, I compared the vcf outputs using default DeepVariant and retrained DeepVariant model on HG003 sample at chromosome20. I notice that there are many variants that two models classify differently. Here is an example of the difference:. default model:. chr20 61083 . C T 33.3 PASS . GT:GQ:DP:AD:VAF:PL 0/1:33:40:19,21:0.525:33,0,42. chr20 11479054 . A G 56.6 PASS . GT:GQ:DP:AD:VAF:PL 1/1:53:29:0,29:1:56,55,0. chr20 29356747 . A G 43.4 PASS . GT:GQ:DP:AD:VAF:PL 1/1:29:26:0,26:1:43,29,0. chr20	54889360	.	G	A	56.8	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:54:39:0,39:1:56,57,0. trained model:. chr20 61083 . C T 24.9 PASS . GT:GQ:DP:AD:VAF:PL 0/1:18:41:19,21:0.512195:24,0,18. chr20 11479054 . A G 0 RefCall . GT:GQ:DP:AD:VAF:PL 0/0:36:29:0,29:1:0,47,36. chr20 29356747 . A G 0 RefCall . GT:GQ:DP:AD:VAF:PL 0/0:33:28:0,28:1:0,47,33. chr20	54889360	.	G	A	0.5	RefCall	.	GT:GQ:DP:AD:VAF:PL	./.:10:39:0,39:1:0,29,9. Is there an output from DeepVariant (e.g intermediate files) that help me to understand how DV make decision on classifying the variant? My goal is to train DeepVariant so that it can keep those 'PASS' variants as in the default model and detect more variants in the dataset. Please advise how I can do that. Thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/894
https://github.com/google/deepvariant/issues/894:393,energy efficiency,model,model,393,"issue with retrained model; Hi,. Here is a set of additional parameter I used in 'make_examples' step to create examples for retraining DeepVariant:. --min_base_quality 5 \. --min_mapping_quality 1 \. --vsc_min_fraction_snps 0.02 \. --p_error 0.1 \. After retraining DeepVariant and get the model with best score, I compared the vcf outputs using default DeepVariant and retrained DeepVariant model on HG003 sample at chromosome20. I notice that there are many variants that two models classify differently. Here is an example of the difference:. default model:. chr20 61083 . C T 33.3 PASS . GT:GQ:DP:AD:VAF:PL 0/1:33:40:19,21:0.525:33,0,42. chr20 11479054 . A G 56.6 PASS . GT:GQ:DP:AD:VAF:PL 1/1:53:29:0,29:1:56,55,0. chr20 29356747 . A G 43.4 PASS . GT:GQ:DP:AD:VAF:PL 1/1:29:26:0,26:1:43,29,0. chr20	54889360	.	G	A	56.8	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:54:39:0,39:1:56,57,0. trained model:. chr20 61083 . C T 24.9 PASS . GT:GQ:DP:AD:VAF:PL 0/1:18:41:19,21:0.512195:24,0,18. chr20 11479054 . A G 0 RefCall . GT:GQ:DP:AD:VAF:PL 0/0:36:29:0,29:1:0,47,36. chr20 29356747 . A G 0 RefCall . GT:GQ:DP:AD:VAF:PL 0/0:33:28:0,28:1:0,47,33. chr20	54889360	.	G	A	0.5	RefCall	.	GT:GQ:DP:AD:VAF:PL	./.:10:39:0,39:1:0,29,9. Is there an output from DeepVariant (e.g intermediate files) that help me to understand how DV make decision on classifying the variant? My goal is to train DeepVariant so that it can keep those 'PASS' variants as in the default model and detect more variants in the dataset. Please advise how I can do that. Thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/894
https://github.com/google/deepvariant/issues/894:479,energy efficiency,model,models,479,"issue with retrained model; Hi,. Here is a set of additional parameter I used in 'make_examples' step to create examples for retraining DeepVariant:. --min_base_quality 5 \. --min_mapping_quality 1 \. --vsc_min_fraction_snps 0.02 \. --p_error 0.1 \. After retraining DeepVariant and get the model with best score, I compared the vcf outputs using default DeepVariant and retrained DeepVariant model on HG003 sample at chromosome20. I notice that there are many variants that two models classify differently. Here is an example of the difference:. default model:. chr20 61083 . C T 33.3 PASS . GT:GQ:DP:AD:VAF:PL 0/1:33:40:19,21:0.525:33,0,42. chr20 11479054 . A G 56.6 PASS . GT:GQ:DP:AD:VAF:PL 1/1:53:29:0,29:1:56,55,0. chr20 29356747 . A G 43.4 PASS . GT:GQ:DP:AD:VAF:PL 1/1:29:26:0,26:1:43,29,0. chr20	54889360	.	G	A	56.8	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:54:39:0,39:1:56,57,0. trained model:. chr20 61083 . C T 24.9 PASS . GT:GQ:DP:AD:VAF:PL 0/1:18:41:19,21:0.512195:24,0,18. chr20 11479054 . A G 0 RefCall . GT:GQ:DP:AD:VAF:PL 0/0:36:29:0,29:1:0,47,36. chr20 29356747 . A G 0 RefCall . GT:GQ:DP:AD:VAF:PL 0/0:33:28:0,28:1:0,47,33. chr20	54889360	.	G	A	0.5	RefCall	.	GT:GQ:DP:AD:VAF:PL	./.:10:39:0,39:1:0,29,9. Is there an output from DeepVariant (e.g intermediate files) that help me to understand how DV make decision on classifying the variant? My goal is to train DeepVariant so that it can keep those 'PASS' variants as in the default model and detect more variants in the dataset. Please advise how I can do that. Thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/894
https://github.com/google/deepvariant/issues/894:555,energy efficiency,model,model,555,"issue with retrained model; Hi,. Here is a set of additional parameter I used in 'make_examples' step to create examples for retraining DeepVariant:. --min_base_quality 5 \. --min_mapping_quality 1 \. --vsc_min_fraction_snps 0.02 \. --p_error 0.1 \. After retraining DeepVariant and get the model with best score, I compared the vcf outputs using default DeepVariant and retrained DeepVariant model on HG003 sample at chromosome20. I notice that there are many variants that two models classify differently. Here is an example of the difference:. default model:. chr20 61083 . C T 33.3 PASS . GT:GQ:DP:AD:VAF:PL 0/1:33:40:19,21:0.525:33,0,42. chr20 11479054 . A G 56.6 PASS . GT:GQ:DP:AD:VAF:PL 1/1:53:29:0,29:1:56,55,0. chr20 29356747 . A G 43.4 PASS . GT:GQ:DP:AD:VAF:PL 1/1:29:26:0,26:1:43,29,0. chr20	54889360	.	G	A	56.8	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:54:39:0,39:1:56,57,0. trained model:. chr20 61083 . C T 24.9 PASS . GT:GQ:DP:AD:VAF:PL 0/1:18:41:19,21:0.512195:24,0,18. chr20 11479054 . A G 0 RefCall . GT:GQ:DP:AD:VAF:PL 0/0:36:29:0,29:1:0,47,36. chr20 29356747 . A G 0 RefCall . GT:GQ:DP:AD:VAF:PL 0/0:33:28:0,28:1:0,47,33. chr20	54889360	.	G	A	0.5	RefCall	.	GT:GQ:DP:AD:VAF:PL	./.:10:39:0,39:1:0,29,9. Is there an output from DeepVariant (e.g intermediate files) that help me to understand how DV make decision on classifying the variant? My goal is to train DeepVariant so that it can keep those 'PASS' variants as in the default model and detect more variants in the dataset. Please advise how I can do that. Thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/894
https://github.com/google/deepvariant/issues/894:885,energy efficiency,model,model,885,"issue with retrained model; Hi,. Here is a set of additional parameter I used in 'make_examples' step to create examples for retraining DeepVariant:. --min_base_quality 5 \. --min_mapping_quality 1 \. --vsc_min_fraction_snps 0.02 \. --p_error 0.1 \. After retraining DeepVariant and get the model with best score, I compared the vcf outputs using default DeepVariant and retrained DeepVariant model on HG003 sample at chromosome20. I notice that there are many variants that two models classify differently. Here is an example of the difference:. default model:. chr20 61083 . C T 33.3 PASS . GT:GQ:DP:AD:VAF:PL 0/1:33:40:19,21:0.525:33,0,42. chr20 11479054 . A G 56.6 PASS . GT:GQ:DP:AD:VAF:PL 1/1:53:29:0,29:1:56,55,0. chr20 29356747 . A G 43.4 PASS . GT:GQ:DP:AD:VAF:PL 1/1:29:26:0,26:1:43,29,0. chr20	54889360	.	G	A	56.8	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:54:39:0,39:1:56,57,0. trained model:. chr20 61083 . C T 24.9 PASS . GT:GQ:DP:AD:VAF:PL 0/1:18:41:19,21:0.512195:24,0,18. chr20 11479054 . A G 0 RefCall . GT:GQ:DP:AD:VAF:PL 0/0:36:29:0,29:1:0,47,36. chr20 29356747 . A G 0 RefCall . GT:GQ:DP:AD:VAF:PL 0/0:33:28:0,28:1:0,47,33. chr20	54889360	.	G	A	0.5	RefCall	.	GT:GQ:DP:AD:VAF:PL	./.:10:39:0,39:1:0,29,9. Is there an output from DeepVariant (e.g intermediate files) that help me to understand how DV make decision on classifying the variant? My goal is to train DeepVariant so that it can keep those 'PASS' variants as in the default model and detect more variants in the dataset. Please advise how I can do that. Thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/894
https://github.com/google/deepvariant/issues/894:1440,energy efficiency,model,model,1440,"issue with retrained model; Hi,. Here is a set of additional parameter I used in 'make_examples' step to create examples for retraining DeepVariant:. --min_base_quality 5 \. --min_mapping_quality 1 \. --vsc_min_fraction_snps 0.02 \. --p_error 0.1 \. After retraining DeepVariant and get the model with best score, I compared the vcf outputs using default DeepVariant and retrained DeepVariant model on HG003 sample at chromosome20. I notice that there are many variants that two models classify differently. Here is an example of the difference:. default model:. chr20 61083 . C T 33.3 PASS . GT:GQ:DP:AD:VAF:PL 0/1:33:40:19,21:0.525:33,0,42. chr20 11479054 . A G 56.6 PASS . GT:GQ:DP:AD:VAF:PL 1/1:53:29:0,29:1:56,55,0. chr20 29356747 . A G 43.4 PASS . GT:GQ:DP:AD:VAF:PL 1/1:29:26:0,26:1:43,29,0. chr20	54889360	.	G	A	56.8	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:54:39:0,39:1:56,57,0. trained model:. chr20 61083 . C T 24.9 PASS . GT:GQ:DP:AD:VAF:PL 0/1:18:41:19,21:0.512195:24,0,18. chr20 11479054 . A G 0 RefCall . GT:GQ:DP:AD:VAF:PL 0/0:36:29:0,29:1:0,47,36. chr20 29356747 . A G 0 RefCall . GT:GQ:DP:AD:VAF:PL 0/0:33:28:0,28:1:0,47,33. chr20	54889360	.	G	A	0.5	RefCall	.	GT:GQ:DP:AD:VAF:PL	./.:10:39:0,39:1:0,29,9. Is there an output from DeepVariant (e.g intermediate files) that help me to understand how DV make decision on classifying the variant? My goal is to train DeepVariant so that it can keep those 'PASS' variants as in the default model and detect more variants in the dataset. Please advise how I can do that. Thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/894
https://github.com/google/deepvariant/issues/894:61,modifiability,paramet,parameter,61,"issue with retrained model; Hi,. Here is a set of additional parameter I used in 'make_examples' step to create examples for retraining DeepVariant:. --min_base_quality 5 \. --min_mapping_quality 1 \. --vsc_min_fraction_snps 0.02 \. --p_error 0.1 \. After retraining DeepVariant and get the model with best score, I compared the vcf outputs using default DeepVariant and retrained DeepVariant model on HG003 sample at chromosome20. I notice that there are many variants that two models classify differently. Here is an example of the difference:. default model:. chr20 61083 . C T 33.3 PASS . GT:GQ:DP:AD:VAF:PL 0/1:33:40:19,21:0.525:33,0,42. chr20 11479054 . A G 56.6 PASS . GT:GQ:DP:AD:VAF:PL 1/1:53:29:0,29:1:56,55,0. chr20 29356747 . A G 43.4 PASS . GT:GQ:DP:AD:VAF:PL 1/1:29:26:0,26:1:43,29,0. chr20	54889360	.	G	A	56.8	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:54:39:0,39:1:56,57,0. trained model:. chr20 61083 . C T 24.9 PASS . GT:GQ:DP:AD:VAF:PL 0/1:18:41:19,21:0.512195:24,0,18. chr20 11479054 . A G 0 RefCall . GT:GQ:DP:AD:VAF:PL 0/0:36:29:0,29:1:0,47,36. chr20 29356747 . A G 0 RefCall . GT:GQ:DP:AD:VAF:PL 0/0:33:28:0,28:1:0,47,33. chr20	54889360	.	G	A	0.5	RefCall	.	GT:GQ:DP:AD:VAF:PL	./.:10:39:0,39:1:0,29,9. Is there an output from DeepVariant (e.g intermediate files) that help me to understand how DV make decision on classifying the variant? My goal is to train DeepVariant so that it can keep those 'PASS' variants as in the default model and detect more variants in the dataset. Please advise how I can do that. Thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/894
https://github.com/google/deepvariant/issues/894:1252,modifiability,interm,intermediate,1252,"issue with retrained model; Hi,. Here is a set of additional parameter I used in 'make_examples' step to create examples for retraining DeepVariant:. --min_base_quality 5 \. --min_mapping_quality 1 \. --vsc_min_fraction_snps 0.02 \. --p_error 0.1 \. After retraining DeepVariant and get the model with best score, I compared the vcf outputs using default DeepVariant and retrained DeepVariant model on HG003 sample at chromosome20. I notice that there are many variants that two models classify differently. Here is an example of the difference:. default model:. chr20 61083 . C T 33.3 PASS . GT:GQ:DP:AD:VAF:PL 0/1:33:40:19,21:0.525:33,0,42. chr20 11479054 . A G 56.6 PASS . GT:GQ:DP:AD:VAF:PL 1/1:53:29:0,29:1:56,55,0. chr20 29356747 . A G 43.4 PASS . GT:GQ:DP:AD:VAF:PL 1/1:29:26:0,26:1:43,29,0. chr20	54889360	.	G	A	56.8	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:54:39:0,39:1:56,57,0. trained model:. chr20 61083 . C T 24.9 PASS . GT:GQ:DP:AD:VAF:PL 0/1:18:41:19,21:0.512195:24,0,18. chr20 11479054 . A G 0 RefCall . GT:GQ:DP:AD:VAF:PL 0/0:36:29:0,29:1:0,47,36. chr20 29356747 . A G 0 RefCall . GT:GQ:DP:AD:VAF:PL 0/0:33:28:0,28:1:0,47,33. chr20	54889360	.	G	A	0.5	RefCall	.	GT:GQ:DP:AD:VAF:PL	./.:10:39:0,39:1:0,29,9. Is there an output from DeepVariant (e.g intermediate files) that help me to understand how DV make decision on classifying the variant? My goal is to train DeepVariant so that it can keep those 'PASS' variants as in the default model and detect more variants in the dataset. Please advise how I can do that. Thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/894
https://github.com/google/deepvariant/issues/894:1450,safety,detect,detect,1450,"issue with retrained model; Hi,. Here is a set of additional parameter I used in 'make_examples' step to create examples for retraining DeepVariant:. --min_base_quality 5 \. --min_mapping_quality 1 \. --vsc_min_fraction_snps 0.02 \. --p_error 0.1 \. After retraining DeepVariant and get the model with best score, I compared the vcf outputs using default DeepVariant and retrained DeepVariant model on HG003 sample at chromosome20. I notice that there are many variants that two models classify differently. Here is an example of the difference:. default model:. chr20 61083 . C T 33.3 PASS . GT:GQ:DP:AD:VAF:PL 0/1:33:40:19,21:0.525:33,0,42. chr20 11479054 . A G 56.6 PASS . GT:GQ:DP:AD:VAF:PL 1/1:53:29:0,29:1:56,55,0. chr20 29356747 . A G 43.4 PASS . GT:GQ:DP:AD:VAF:PL 1/1:29:26:0,26:1:43,29,0. chr20	54889360	.	G	A	56.8	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:54:39:0,39:1:56,57,0. trained model:. chr20 61083 . C T 24.9 PASS . GT:GQ:DP:AD:VAF:PL 0/1:18:41:19,21:0.512195:24,0,18. chr20 11479054 . A G 0 RefCall . GT:GQ:DP:AD:VAF:PL 0/0:36:29:0,29:1:0,47,36. chr20 29356747 . A G 0 RefCall . GT:GQ:DP:AD:VAF:PL 0/0:33:28:0,28:1:0,47,33. chr20	54889360	.	G	A	0.5	RefCall	.	GT:GQ:DP:AD:VAF:PL	./.:10:39:0,39:1:0,29,9. Is there an output from DeepVariant (e.g intermediate files) that help me to understand how DV make decision on classifying the variant? My goal is to train DeepVariant so that it can keep those 'PASS' variants as in the default model and detect more variants in the dataset. Please advise how I can do that. Thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/894
https://github.com/google/deepvariant/issues/894:21,security,model,model,21,"issue with retrained model; Hi,. Here is a set of additional parameter I used in 'make_examples' step to create examples for retraining DeepVariant:. --min_base_quality 5 \. --min_mapping_quality 1 \. --vsc_min_fraction_snps 0.02 \. --p_error 0.1 \. After retraining DeepVariant and get the model with best score, I compared the vcf outputs using default DeepVariant and retrained DeepVariant model on HG003 sample at chromosome20. I notice that there are many variants that two models classify differently. Here is an example of the difference:. default model:. chr20 61083 . C T 33.3 PASS . GT:GQ:DP:AD:VAF:PL 0/1:33:40:19,21:0.525:33,0,42. chr20 11479054 . A G 56.6 PASS . GT:GQ:DP:AD:VAF:PL 1/1:53:29:0,29:1:56,55,0. chr20 29356747 . A G 43.4 PASS . GT:GQ:DP:AD:VAF:PL 1/1:29:26:0,26:1:43,29,0. chr20	54889360	.	G	A	56.8	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:54:39:0,39:1:56,57,0. trained model:. chr20 61083 . C T 24.9 PASS . GT:GQ:DP:AD:VAF:PL 0/1:18:41:19,21:0.512195:24,0,18. chr20 11479054 . A G 0 RefCall . GT:GQ:DP:AD:VAF:PL 0/0:36:29:0,29:1:0,47,36. chr20 29356747 . A G 0 RefCall . GT:GQ:DP:AD:VAF:PL 0/0:33:28:0,28:1:0,47,33. chr20	54889360	.	G	A	0.5	RefCall	.	GT:GQ:DP:AD:VAF:PL	./.:10:39:0,39:1:0,29,9. Is there an output from DeepVariant (e.g intermediate files) that help me to understand how DV make decision on classifying the variant? My goal is to train DeepVariant so that it can keep those 'PASS' variants as in the default model and detect more variants in the dataset. Please advise how I can do that. Thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/894
https://github.com/google/deepvariant/issues/894:291,security,model,model,291,"issue with retrained model; Hi,. Here is a set of additional parameter I used in 'make_examples' step to create examples for retraining DeepVariant:. --min_base_quality 5 \. --min_mapping_quality 1 \. --vsc_min_fraction_snps 0.02 \. --p_error 0.1 \. After retraining DeepVariant and get the model with best score, I compared the vcf outputs using default DeepVariant and retrained DeepVariant model on HG003 sample at chromosome20. I notice that there are many variants that two models classify differently. Here is an example of the difference:. default model:. chr20 61083 . C T 33.3 PASS . GT:GQ:DP:AD:VAF:PL 0/1:33:40:19,21:0.525:33,0,42. chr20 11479054 . A G 56.6 PASS . GT:GQ:DP:AD:VAF:PL 1/1:53:29:0,29:1:56,55,0. chr20 29356747 . A G 43.4 PASS . GT:GQ:DP:AD:VAF:PL 1/1:29:26:0,26:1:43,29,0. chr20	54889360	.	G	A	56.8	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:54:39:0,39:1:56,57,0. trained model:. chr20 61083 . C T 24.9 PASS . GT:GQ:DP:AD:VAF:PL 0/1:18:41:19,21:0.512195:24,0,18. chr20 11479054 . A G 0 RefCall . GT:GQ:DP:AD:VAF:PL 0/0:36:29:0,29:1:0,47,36. chr20 29356747 . A G 0 RefCall . GT:GQ:DP:AD:VAF:PL 0/0:33:28:0,28:1:0,47,33. chr20	54889360	.	G	A	0.5	RefCall	.	GT:GQ:DP:AD:VAF:PL	./.:10:39:0,39:1:0,29,9. Is there an output from DeepVariant (e.g intermediate files) that help me to understand how DV make decision on classifying the variant? My goal is to train DeepVariant so that it can keep those 'PASS' variants as in the default model and detect more variants in the dataset. Please advise how I can do that. Thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/894
https://github.com/google/deepvariant/issues/894:393,security,model,model,393,"issue with retrained model; Hi,. Here is a set of additional parameter I used in 'make_examples' step to create examples for retraining DeepVariant:. --min_base_quality 5 \. --min_mapping_quality 1 \. --vsc_min_fraction_snps 0.02 \. --p_error 0.1 \. After retraining DeepVariant and get the model with best score, I compared the vcf outputs using default DeepVariant and retrained DeepVariant model on HG003 sample at chromosome20. I notice that there are many variants that two models classify differently. Here is an example of the difference:. default model:. chr20 61083 . C T 33.3 PASS . GT:GQ:DP:AD:VAF:PL 0/1:33:40:19,21:0.525:33,0,42. chr20 11479054 . A G 56.6 PASS . GT:GQ:DP:AD:VAF:PL 1/1:53:29:0,29:1:56,55,0. chr20 29356747 . A G 43.4 PASS . GT:GQ:DP:AD:VAF:PL 1/1:29:26:0,26:1:43,29,0. chr20	54889360	.	G	A	56.8	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:54:39:0,39:1:56,57,0. trained model:. chr20 61083 . C T 24.9 PASS . GT:GQ:DP:AD:VAF:PL 0/1:18:41:19,21:0.512195:24,0,18. chr20 11479054 . A G 0 RefCall . GT:GQ:DP:AD:VAF:PL 0/0:36:29:0,29:1:0,47,36. chr20 29356747 . A G 0 RefCall . GT:GQ:DP:AD:VAF:PL 0/0:33:28:0,28:1:0,47,33. chr20	54889360	.	G	A	0.5	RefCall	.	GT:GQ:DP:AD:VAF:PL	./.:10:39:0,39:1:0,29,9. Is there an output from DeepVariant (e.g intermediate files) that help me to understand how DV make decision on classifying the variant? My goal is to train DeepVariant so that it can keep those 'PASS' variants as in the default model and detect more variants in the dataset. Please advise how I can do that. Thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/894
https://github.com/google/deepvariant/issues/894:479,security,model,models,479,"issue with retrained model; Hi,. Here is a set of additional parameter I used in 'make_examples' step to create examples for retraining DeepVariant:. --min_base_quality 5 \. --min_mapping_quality 1 \. --vsc_min_fraction_snps 0.02 \. --p_error 0.1 \. After retraining DeepVariant and get the model with best score, I compared the vcf outputs using default DeepVariant and retrained DeepVariant model on HG003 sample at chromosome20. I notice that there are many variants that two models classify differently. Here is an example of the difference:. default model:. chr20 61083 . C T 33.3 PASS . GT:GQ:DP:AD:VAF:PL 0/1:33:40:19,21:0.525:33,0,42. chr20 11479054 . A G 56.6 PASS . GT:GQ:DP:AD:VAF:PL 1/1:53:29:0,29:1:56,55,0. chr20 29356747 . A G 43.4 PASS . GT:GQ:DP:AD:VAF:PL 1/1:29:26:0,26:1:43,29,0. chr20	54889360	.	G	A	56.8	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:54:39:0,39:1:56,57,0. trained model:. chr20 61083 . C T 24.9 PASS . GT:GQ:DP:AD:VAF:PL 0/1:18:41:19,21:0.512195:24,0,18. chr20 11479054 . A G 0 RefCall . GT:GQ:DP:AD:VAF:PL 0/0:36:29:0,29:1:0,47,36. chr20 29356747 . A G 0 RefCall . GT:GQ:DP:AD:VAF:PL 0/0:33:28:0,28:1:0,47,33. chr20	54889360	.	G	A	0.5	RefCall	.	GT:GQ:DP:AD:VAF:PL	./.:10:39:0,39:1:0,29,9. Is there an output from DeepVariant (e.g intermediate files) that help me to understand how DV make decision on classifying the variant? My goal is to train DeepVariant so that it can keep those 'PASS' variants as in the default model and detect more variants in the dataset. Please advise how I can do that. Thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/894
https://github.com/google/deepvariant/issues/894:555,security,model,model,555,"issue with retrained model; Hi,. Here is a set of additional parameter I used in 'make_examples' step to create examples for retraining DeepVariant:. --min_base_quality 5 \. --min_mapping_quality 1 \. --vsc_min_fraction_snps 0.02 \. --p_error 0.1 \. After retraining DeepVariant and get the model with best score, I compared the vcf outputs using default DeepVariant and retrained DeepVariant model on HG003 sample at chromosome20. I notice that there are many variants that two models classify differently. Here is an example of the difference:. default model:. chr20 61083 . C T 33.3 PASS . GT:GQ:DP:AD:VAF:PL 0/1:33:40:19,21:0.525:33,0,42. chr20 11479054 . A G 56.6 PASS . GT:GQ:DP:AD:VAF:PL 1/1:53:29:0,29:1:56,55,0. chr20 29356747 . A G 43.4 PASS . GT:GQ:DP:AD:VAF:PL 1/1:29:26:0,26:1:43,29,0. chr20	54889360	.	G	A	56.8	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:54:39:0,39:1:56,57,0. trained model:. chr20 61083 . C T 24.9 PASS . GT:GQ:DP:AD:VAF:PL 0/1:18:41:19,21:0.512195:24,0,18. chr20 11479054 . A G 0 RefCall . GT:GQ:DP:AD:VAF:PL 0/0:36:29:0,29:1:0,47,36. chr20 29356747 . A G 0 RefCall . GT:GQ:DP:AD:VAF:PL 0/0:33:28:0,28:1:0,47,33. chr20	54889360	.	G	A	0.5	RefCall	.	GT:GQ:DP:AD:VAF:PL	./.:10:39:0,39:1:0,29,9. Is there an output from DeepVariant (e.g intermediate files) that help me to understand how DV make decision on classifying the variant? My goal is to train DeepVariant so that it can keep those 'PASS' variants as in the default model and detect more variants in the dataset. Please advise how I can do that. Thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/894
https://github.com/google/deepvariant/issues/894:885,security,model,model,885,"issue with retrained model; Hi,. Here is a set of additional parameter I used in 'make_examples' step to create examples for retraining DeepVariant:. --min_base_quality 5 \. --min_mapping_quality 1 \. --vsc_min_fraction_snps 0.02 \. --p_error 0.1 \. After retraining DeepVariant and get the model with best score, I compared the vcf outputs using default DeepVariant and retrained DeepVariant model on HG003 sample at chromosome20. I notice that there are many variants that two models classify differently. Here is an example of the difference:. default model:. chr20 61083 . C T 33.3 PASS . GT:GQ:DP:AD:VAF:PL 0/1:33:40:19,21:0.525:33,0,42. chr20 11479054 . A G 56.6 PASS . GT:GQ:DP:AD:VAF:PL 1/1:53:29:0,29:1:56,55,0. chr20 29356747 . A G 43.4 PASS . GT:GQ:DP:AD:VAF:PL 1/1:29:26:0,26:1:43,29,0. chr20	54889360	.	G	A	56.8	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:54:39:0,39:1:56,57,0. trained model:. chr20 61083 . C T 24.9 PASS . GT:GQ:DP:AD:VAF:PL 0/1:18:41:19,21:0.512195:24,0,18. chr20 11479054 . A G 0 RefCall . GT:GQ:DP:AD:VAF:PL 0/0:36:29:0,29:1:0,47,36. chr20 29356747 . A G 0 RefCall . GT:GQ:DP:AD:VAF:PL 0/0:33:28:0,28:1:0,47,33. chr20	54889360	.	G	A	0.5	RefCall	.	GT:GQ:DP:AD:VAF:PL	./.:10:39:0,39:1:0,29,9. Is there an output from DeepVariant (e.g intermediate files) that help me to understand how DV make decision on classifying the variant? My goal is to train DeepVariant so that it can keep those 'PASS' variants as in the default model and detect more variants in the dataset. Please advise how I can do that. Thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/894
https://github.com/google/deepvariant/issues/894:1440,security,model,model,1440,"issue with retrained model; Hi,. Here is a set of additional parameter I used in 'make_examples' step to create examples for retraining DeepVariant:. --min_base_quality 5 \. --min_mapping_quality 1 \. --vsc_min_fraction_snps 0.02 \. --p_error 0.1 \. After retraining DeepVariant and get the model with best score, I compared the vcf outputs using default DeepVariant and retrained DeepVariant model on HG003 sample at chromosome20. I notice that there are many variants that two models classify differently. Here is an example of the difference:. default model:. chr20 61083 . C T 33.3 PASS . GT:GQ:DP:AD:VAF:PL 0/1:33:40:19,21:0.525:33,0,42. chr20 11479054 . A G 56.6 PASS . GT:GQ:DP:AD:VAF:PL 1/1:53:29:0,29:1:56,55,0. chr20 29356747 . A G 43.4 PASS . GT:GQ:DP:AD:VAF:PL 1/1:29:26:0,26:1:43,29,0. chr20	54889360	.	G	A	56.8	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:54:39:0,39:1:56,57,0. trained model:. chr20 61083 . C T 24.9 PASS . GT:GQ:DP:AD:VAF:PL 0/1:18:41:19,21:0.512195:24,0,18. chr20 11479054 . A G 0 RefCall . GT:GQ:DP:AD:VAF:PL 0/0:36:29:0,29:1:0,47,36. chr20 29356747 . A G 0 RefCall . GT:GQ:DP:AD:VAF:PL 0/0:33:28:0,28:1:0,47,33. chr20	54889360	.	G	A	0.5	RefCall	.	GT:GQ:DP:AD:VAF:PL	./.:10:39:0,39:1:0,29,9. Is there an output from DeepVariant (e.g intermediate files) that help me to understand how DV make decision on classifying the variant? My goal is to train DeepVariant so that it can keep those 'PASS' variants as in the default model and detect more variants in the dataset. Please advise how I can do that. Thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/894
https://github.com/google/deepvariant/issues/894:1450,security,detect,detect,1450,"issue with retrained model; Hi,. Here is a set of additional parameter I used in 'make_examples' step to create examples for retraining DeepVariant:. --min_base_quality 5 \. --min_mapping_quality 1 \. --vsc_min_fraction_snps 0.02 \. --p_error 0.1 \. After retraining DeepVariant and get the model with best score, I compared the vcf outputs using default DeepVariant and retrained DeepVariant model on HG003 sample at chromosome20. I notice that there are many variants that two models classify differently. Here is an example of the difference:. default model:. chr20 61083 . C T 33.3 PASS . GT:GQ:DP:AD:VAF:PL 0/1:33:40:19,21:0.525:33,0,42. chr20 11479054 . A G 56.6 PASS . GT:GQ:DP:AD:VAF:PL 1/1:53:29:0,29:1:56,55,0. chr20 29356747 . A G 43.4 PASS . GT:GQ:DP:AD:VAF:PL 1/1:29:26:0,26:1:43,29,0. chr20	54889360	.	G	A	56.8	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:54:39:0,39:1:56,57,0. trained model:. chr20 61083 . C T 24.9 PASS . GT:GQ:DP:AD:VAF:PL 0/1:18:41:19,21:0.512195:24,0,18. chr20 11479054 . A G 0 RefCall . GT:GQ:DP:AD:VAF:PL 0/0:36:29:0,29:1:0,47,36. chr20 29356747 . A G 0 RefCall . GT:GQ:DP:AD:VAF:PL 0/0:33:28:0,28:1:0,47,33. chr20	54889360	.	G	A	0.5	RefCall	.	GT:GQ:DP:AD:VAF:PL	./.:10:39:0,39:1:0,29,9. Is there an output from DeepVariant (e.g intermediate files) that help me to understand how DV make decision on classifying the variant? My goal is to train DeepVariant so that it can keep those 'PASS' variants as in the default model and detect more variants in the dataset. Please advise how I can do that. Thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/894
https://github.com/google/deepvariant/issues/894:1288,testability,understand,understand,1288,"issue with retrained model; Hi,. Here is a set of additional parameter I used in 'make_examples' step to create examples for retraining DeepVariant:. --min_base_quality 5 \. --min_mapping_quality 1 \. --vsc_min_fraction_snps 0.02 \. --p_error 0.1 \. After retraining DeepVariant and get the model with best score, I compared the vcf outputs using default DeepVariant and retrained DeepVariant model on HG003 sample at chromosome20. I notice that there are many variants that two models classify differently. Here is an example of the difference:. default model:. chr20 61083 . C T 33.3 PASS . GT:GQ:DP:AD:VAF:PL 0/1:33:40:19,21:0.525:33,0,42. chr20 11479054 . A G 56.6 PASS . GT:GQ:DP:AD:VAF:PL 1/1:53:29:0,29:1:56,55,0. chr20 29356747 . A G 43.4 PASS . GT:GQ:DP:AD:VAF:PL 1/1:29:26:0,26:1:43,29,0. chr20	54889360	.	G	A	56.8	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:54:39:0,39:1:56,57,0. trained model:. chr20 61083 . C T 24.9 PASS . GT:GQ:DP:AD:VAF:PL 0/1:18:41:19,21:0.512195:24,0,18. chr20 11479054 . A G 0 RefCall . GT:GQ:DP:AD:VAF:PL 0/0:36:29:0,29:1:0,47,36. chr20 29356747 . A G 0 RefCall . GT:GQ:DP:AD:VAF:PL 0/0:33:28:0,28:1:0,47,33. chr20	54889360	.	G	A	0.5	RefCall	.	GT:GQ:DP:AD:VAF:PL	./.:10:39:0,39:1:0,29,9. Is there an output from DeepVariant (e.g intermediate files) that help me to understand how DV make decision on classifying the variant? My goal is to train DeepVariant so that it can keep those 'PASS' variants as in the default model and detect more variants in the dataset. Please advise how I can do that. Thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/894
https://github.com/google/deepvariant/issues/894:1277,usability,help,help,1277,"issue with retrained model; Hi,. Here is a set of additional parameter I used in 'make_examples' step to create examples for retraining DeepVariant:. --min_base_quality 5 \. --min_mapping_quality 1 \. --vsc_min_fraction_snps 0.02 \. --p_error 0.1 \. After retraining DeepVariant and get the model with best score, I compared the vcf outputs using default DeepVariant and retrained DeepVariant model on HG003 sample at chromosome20. I notice that there are many variants that two models classify differently. Here is an example of the difference:. default model:. chr20 61083 . C T 33.3 PASS . GT:GQ:DP:AD:VAF:PL 0/1:33:40:19,21:0.525:33,0,42. chr20 11479054 . A G 56.6 PASS . GT:GQ:DP:AD:VAF:PL 1/1:53:29:0,29:1:56,55,0. chr20 29356747 . A G 43.4 PASS . GT:GQ:DP:AD:VAF:PL 1/1:29:26:0,26:1:43,29,0. chr20	54889360	.	G	A	56.8	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:54:39:0,39:1:56,57,0. trained model:. chr20 61083 . C T 24.9 PASS . GT:GQ:DP:AD:VAF:PL 0/1:18:41:19,21:0.512195:24,0,18. chr20 11479054 . A G 0 RefCall . GT:GQ:DP:AD:VAF:PL 0/0:36:29:0,29:1:0,47,36. chr20 29356747 . A G 0 RefCall . GT:GQ:DP:AD:VAF:PL 0/0:33:28:0,28:1:0,47,33. chr20	54889360	.	G	A	0.5	RefCall	.	GT:GQ:DP:AD:VAF:PL	./.:10:39:0,39:1:0,29,9. Is there an output from DeepVariant (e.g intermediate files) that help me to understand how DV make decision on classifying the variant? My goal is to train DeepVariant so that it can keep those 'PASS' variants as in the default model and detect more variants in the dataset. Please advise how I can do that. Thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/894
https://github.com/google/deepvariant/issues/896:1006,deployability,version,version,1006,"hap.py benchmarking; Hello, . Sorry for writing again about some questions in the analysis, I don't have any expertise on DeepVariant/variant benchmarking around me :( . I wanted to benchmark identified variants using hap.py as you suggest in the tutorial, and the output surprised me a bit. For the variants I called the recall/precision were from 0 to 0.4, which is very low... I did not change default pacbio parameters when running DeepVariant, except for asking to keep supplementary alignments. Maybe it is partially because of the complexity of HLA region, but I am not sure what is the reason. What do you think, is there something obviously wrong? singularity exec --bind /usr/lib/locale/ \. docker://google/deepvariant:${BIN_VERSION} \. /opt/deepvariant/bin/run_deepvariant \. --model_type PACBIO \. --ref $REFERENCE \. --reads $BAM_FILE \. --make_examples_extra_args=keep_supplementary_alignments=true \. --output_vcf $VCF_FILE \. --num_shards 12 \. --regions chr6:32541543-32701886. I am using version 1.6.1. . Kind regards,. Alisa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/896
https://github.com/google/deepvariant/issues/896:1006,integrability,version,version,1006,"hap.py benchmarking; Hello, . Sorry for writing again about some questions in the analysis, I don't have any expertise on DeepVariant/variant benchmarking around me :( . I wanted to benchmark identified variants using hap.py as you suggest in the tutorial, and the output surprised me a bit. For the variants I called the recall/precision were from 0 to 0.4, which is very low... I did not change default pacbio parameters when running DeepVariant, except for asking to keep supplementary alignments. Maybe it is partially because of the complexity of HLA region, but I am not sure what is the reason. What do you think, is there something obviously wrong? singularity exec --bind /usr/lib/locale/ \. docker://google/deepvariant:${BIN_VERSION} \. /opt/deepvariant/bin/run_deepvariant \. --model_type PACBIO \. --ref $REFERENCE \. --reads $BAM_FILE \. --make_examples_extra_args=keep_supplementary_alignments=true \. --output_vcf $VCF_FILE \. --num_shards 12 \. --regions chr6:32541543-32701886. I am using version 1.6.1. . Kind regards,. Alisa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/896
https://github.com/google/deepvariant/issues/896:676,interoperability,bind,bind,676,"hap.py benchmarking; Hello, . Sorry for writing again about some questions in the analysis, I don't have any expertise on DeepVariant/variant benchmarking around me :( . I wanted to benchmark identified variants using hap.py as you suggest in the tutorial, and the output surprised me a bit. For the variants I called the recall/precision were from 0 to 0.4, which is very low... I did not change default pacbio parameters when running DeepVariant, except for asking to keep supplementary alignments. Maybe it is partially because of the complexity of HLA region, but I am not sure what is the reason. What do you think, is there something obviously wrong? singularity exec --bind /usr/lib/locale/ \. docker://google/deepvariant:${BIN_VERSION} \. /opt/deepvariant/bin/run_deepvariant \. --model_type PACBIO \. --ref $REFERENCE \. --reads $BAM_FILE \. --make_examples_extra_args=keep_supplementary_alignments=true \. --output_vcf $VCF_FILE \. --num_shards 12 \. --regions chr6:32541543-32701886. I am using version 1.6.1. . Kind regards,. Alisa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/896
https://github.com/google/deepvariant/issues/896:405,modifiability,pac,pacbio,405,"hap.py benchmarking; Hello, . Sorry for writing again about some questions in the analysis, I don't have any expertise on DeepVariant/variant benchmarking around me :( . I wanted to benchmark identified variants using hap.py as you suggest in the tutorial, and the output surprised me a bit. For the variants I called the recall/precision were from 0 to 0.4, which is very low... I did not change default pacbio parameters when running DeepVariant, except for asking to keep supplementary alignments. Maybe it is partially because of the complexity of HLA region, but I am not sure what is the reason. What do you think, is there something obviously wrong? singularity exec --bind /usr/lib/locale/ \. docker://google/deepvariant:${BIN_VERSION} \. /opt/deepvariant/bin/run_deepvariant \. --model_type PACBIO \. --ref $REFERENCE \. --reads $BAM_FILE \. --make_examples_extra_args=keep_supplementary_alignments=true \. --output_vcf $VCF_FILE \. --num_shards 12 \. --regions chr6:32541543-32701886. I am using version 1.6.1. . Kind regards,. Alisa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/896
https://github.com/google/deepvariant/issues/896:412,modifiability,paramet,parameters,412,"hap.py benchmarking; Hello, . Sorry for writing again about some questions in the analysis, I don't have any expertise on DeepVariant/variant benchmarking around me :( . I wanted to benchmark identified variants using hap.py as you suggest in the tutorial, and the output surprised me a bit. For the variants I called the recall/precision were from 0 to 0.4, which is very low... I did not change default pacbio parameters when running DeepVariant, except for asking to keep supplementary alignments. Maybe it is partially because of the complexity of HLA region, but I am not sure what is the reason. What do you think, is there something obviously wrong? singularity exec --bind /usr/lib/locale/ \. docker://google/deepvariant:${BIN_VERSION} \. /opt/deepvariant/bin/run_deepvariant \. --model_type PACBIO \. --ref $REFERENCE \. --reads $BAM_FILE \. --make_examples_extra_args=keep_supplementary_alignments=true \. --output_vcf $VCF_FILE \. --num_shards 12 \. --regions chr6:32541543-32701886. I am using version 1.6.1. . Kind regards,. Alisa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/896
https://github.com/google/deepvariant/issues/896:676,modifiability,bind,bind,676,"hap.py benchmarking; Hello, . Sorry for writing again about some questions in the analysis, I don't have any expertise on DeepVariant/variant benchmarking around me :( . I wanted to benchmark identified variants using hap.py as you suggest in the tutorial, and the output surprised me a bit. For the variants I called the recall/precision were from 0 to 0.4, which is very low... I did not change default pacbio parameters when running DeepVariant, except for asking to keep supplementary alignments. Maybe it is partially because of the complexity of HLA region, but I am not sure what is the reason. What do you think, is there something obviously wrong? singularity exec --bind /usr/lib/locale/ \. docker://google/deepvariant:${BIN_VERSION} \. /opt/deepvariant/bin/run_deepvariant \. --model_type PACBIO \. --ref $REFERENCE \. --reads $BAM_FILE \. --make_examples_extra_args=keep_supplementary_alignments=true \. --output_vcf $VCF_FILE \. --num_shards 12 \. --regions chr6:32541543-32701886. I am using version 1.6.1. . Kind regards,. Alisa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/896
https://github.com/google/deepvariant/issues/896:800,modifiability,PAC,PACBIO,800,"hap.py benchmarking; Hello, . Sorry for writing again about some questions in the analysis, I don't have any expertise on DeepVariant/variant benchmarking around me :( . I wanted to benchmark identified variants using hap.py as you suggest in the tutorial, and the output surprised me a bit. For the variants I called the recall/precision were from 0 to 0.4, which is very low... I did not change default pacbio parameters when running DeepVariant, except for asking to keep supplementary alignments. Maybe it is partially because of the complexity of HLA region, but I am not sure what is the reason. What do you think, is there something obviously wrong? singularity exec --bind /usr/lib/locale/ \. docker://google/deepvariant:${BIN_VERSION} \. /opt/deepvariant/bin/run_deepvariant \. --model_type PACBIO \. --ref $REFERENCE \. --reads $BAM_FILE \. --make_examples_extra_args=keep_supplementary_alignments=true \. --output_vcf $VCF_FILE \. --num_shards 12 \. --regions chr6:32541543-32701886. I am using version 1.6.1. . Kind regards,. Alisa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/896
https://github.com/google/deepvariant/issues/896:1006,modifiability,version,version,1006,"hap.py benchmarking; Hello, . Sorry for writing again about some questions in the analysis, I don't have any expertise on DeepVariant/variant benchmarking around me :( . I wanted to benchmark identified variants using hap.py as you suggest in the tutorial, and the output surprised me a bit. For the variants I called the recall/precision were from 0 to 0.4, which is very low... I did not change default pacbio parameters when running DeepVariant, except for asking to keep supplementary alignments. Maybe it is partially because of the complexity of HLA region, but I am not sure what is the reason. What do you think, is there something obviously wrong? singularity exec --bind /usr/lib/locale/ \. docker://google/deepvariant:${BIN_VERSION} \. /opt/deepvariant/bin/run_deepvariant \. --model_type PACBIO \. --ref $REFERENCE \. --reads $BAM_FILE \. --make_examples_extra_args=keep_supplementary_alignments=true \. --output_vcf $VCF_FILE \. --num_shards 12 \. --regions chr6:32541543-32701886. I am using version 1.6.1. . Kind regards,. Alisa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/896
https://github.com/google/deepvariant/issues/896:449,safety,except,except,449,"hap.py benchmarking; Hello, . Sorry for writing again about some questions in the analysis, I don't have any expertise on DeepVariant/variant benchmarking around me :( . I wanted to benchmark identified variants using hap.py as you suggest in the tutorial, and the output surprised me a bit. For the variants I called the recall/precision were from 0 to 0.4, which is very low... I did not change default pacbio parameters when running DeepVariant, except for asking to keep supplementary alignments. Maybe it is partially because of the complexity of HLA region, but I am not sure what is the reason. What do you think, is there something obviously wrong? singularity exec --bind /usr/lib/locale/ \. docker://google/deepvariant:${BIN_VERSION} \. /opt/deepvariant/bin/run_deepvariant \. --model_type PACBIO \. --ref $REFERENCE \. --reads $BAM_FILE \. --make_examples_extra_args=keep_supplementary_alignments=true \. --output_vcf $VCF_FILE \. --num_shards 12 \. --regions chr6:32541543-32701886. I am using version 1.6.1. . Kind regards,. Alisa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/896
https://github.com/google/deepvariant/issues/896:538,safety,compl,complexity,538,"hap.py benchmarking; Hello, . Sorry for writing again about some questions in the analysis, I don't have any expertise on DeepVariant/variant benchmarking around me :( . I wanted to benchmark identified variants using hap.py as you suggest in the tutorial, and the output surprised me a bit. For the variants I called the recall/precision were from 0 to 0.4, which is very low... I did not change default pacbio parameters when running DeepVariant, except for asking to keep supplementary alignments. Maybe it is partially because of the complexity of HLA region, but I am not sure what is the reason. What do you think, is there something obviously wrong? singularity exec --bind /usr/lib/locale/ \. docker://google/deepvariant:${BIN_VERSION} \. /opt/deepvariant/bin/run_deepvariant \. --model_type PACBIO \. --ref $REFERENCE \. --reads $BAM_FILE \. --make_examples_extra_args=keep_supplementary_alignments=true \. --output_vcf $VCF_FILE \. --num_shards 12 \. --regions chr6:32541543-32701886. I am using version 1.6.1. . Kind regards,. Alisa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/896
https://github.com/google/deepvariant/issues/896:192,security,ident,identified,192,"hap.py benchmarking; Hello, . Sorry for writing again about some questions in the analysis, I don't have any expertise on DeepVariant/variant benchmarking around me :( . I wanted to benchmark identified variants using hap.py as you suggest in the tutorial, and the output surprised me a bit. For the variants I called the recall/precision were from 0 to 0.4, which is very low... I did not change default pacbio parameters when running DeepVariant, except for asking to keep supplementary alignments. Maybe it is partially because of the complexity of HLA region, but I am not sure what is the reason. What do you think, is there something obviously wrong? singularity exec --bind /usr/lib/locale/ \. docker://google/deepvariant:${BIN_VERSION} \. /opt/deepvariant/bin/run_deepvariant \. --model_type PACBIO \. --ref $REFERENCE \. --reads $BAM_FILE \. --make_examples_extra_args=keep_supplementary_alignments=true \. --output_vcf $VCF_FILE \. --num_shards 12 \. --regions chr6:32541543-32701886. I am using version 1.6.1. . Kind regards,. Alisa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/896
https://github.com/google/deepvariant/issues/896:538,security,compl,complexity,538,"hap.py benchmarking; Hello, . Sorry for writing again about some questions in the analysis, I don't have any expertise on DeepVariant/variant benchmarking around me :( . I wanted to benchmark identified variants using hap.py as you suggest in the tutorial, and the output surprised me a bit. For the variants I called the recall/precision were from 0 to 0.4, which is very low... I did not change default pacbio parameters when running DeepVariant, except for asking to keep supplementary alignments. Maybe it is partially because of the complexity of HLA region, but I am not sure what is the reason. What do you think, is there something obviously wrong? singularity exec --bind /usr/lib/locale/ \. docker://google/deepvariant:${BIN_VERSION} \. /opt/deepvariant/bin/run_deepvariant \. --model_type PACBIO \. --ref $REFERENCE \. --reads $BAM_FILE \. --make_examples_extra_args=keep_supplementary_alignments=true \. --output_vcf $VCF_FILE \. --num_shards 12 \. --regions chr6:32541543-32701886. I am using version 1.6.1. . Kind regards,. Alisa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/896
https://github.com/google/deepvariant/issues/897:127,energy efficiency,current,current,127,"Typo in `docs/deepvariant-details.md`; I noticed a small typo in the file `docs/deepvariant-details.md` on the first line. The current text is:. ```. f# DeepVariant usage guide. ```. It would be better to remove the leading ""f"":. ```. # DeepVariant usage guide. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/897
https://github.com/google/deepvariant/issues/897:171,usability,guid,guide,171,"Typo in `docs/deepvariant-details.md`; I noticed a small typo in the file `docs/deepvariant-details.md` on the first line. The current text is:. ```. f# DeepVariant usage guide. ```. It would be better to remove the leading ""f"":. ```. # DeepVariant usage guide. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/897
https://github.com/google/deepvariant/issues/897:255,usability,guid,guide,255,"Typo in `docs/deepvariant-details.md`; I noticed a small typo in the file `docs/deepvariant-details.md` on the first line. The current text is:. ```. f# DeepVariant usage guide. ```. It would be better to remove the leading ""f"":. ```. # DeepVariant usage guide. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/897
https://github.com/google/deepvariant/issues/898:55,energy efficiency,model,model,55,"Training pacbio HIFI data using the trained short-read model as a gold standard; Dear Deepvariant devolopers,. I am currently working on a Pacibio Hifi dataset from a non-model species. Unfortunately, there is no existing trio hifi dataset for a accurate training. However, we do have a trained model from the short-read pair-end data of the same species. My question is: does it make sense to call SNPs with the existing short-read model and HiC pair-end illumina data and extract high-quality SNPs as gold standard, and then apply them in the training step of Hifi data? Thank you. Zuyao",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/898
https://github.com/google/deepvariant/issues/898:116,energy efficiency,current,currently,116,"Training pacbio HIFI data using the trained short-read model as a gold standard; Dear Deepvariant devolopers,. I am currently working on a Pacibio Hifi dataset from a non-model species. Unfortunately, there is no existing trio hifi dataset for a accurate training. However, we do have a trained model from the short-read pair-end data of the same species. My question is: does it make sense to call SNPs with the existing short-read model and HiC pair-end illumina data and extract high-quality SNPs as gold standard, and then apply them in the training step of Hifi data? Thank you. Zuyao",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/898
https://github.com/google/deepvariant/issues/898:171,energy efficiency,model,model,171,"Training pacbio HIFI data using the trained short-read model as a gold standard; Dear Deepvariant devolopers,. I am currently working on a Pacibio Hifi dataset from a non-model species. Unfortunately, there is no existing trio hifi dataset for a accurate training. However, we do have a trained model from the short-read pair-end data of the same species. My question is: does it make sense to call SNPs with the existing short-read model and HiC pair-end illumina data and extract high-quality SNPs as gold standard, and then apply them in the training step of Hifi data? Thank you. Zuyao",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/898
https://github.com/google/deepvariant/issues/898:295,energy efficiency,model,model,295,"Training pacbio HIFI data using the trained short-read model as a gold standard; Dear Deepvariant devolopers,. I am currently working on a Pacibio Hifi dataset from a non-model species. Unfortunately, there is no existing trio hifi dataset for a accurate training. However, we do have a trained model from the short-read pair-end data of the same species. My question is: does it make sense to call SNPs with the existing short-read model and HiC pair-end illumina data and extract high-quality SNPs as gold standard, and then apply them in the training step of Hifi data? Thank you. Zuyao",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/898
https://github.com/google/deepvariant/issues/898:433,energy efficiency,model,model,433,"Training pacbio HIFI data using the trained short-read model as a gold standard; Dear Deepvariant devolopers,. I am currently working on a Pacibio Hifi dataset from a non-model species. Unfortunately, there is no existing trio hifi dataset for a accurate training. However, we do have a trained model from the short-read pair-end data of the same species. My question is: does it make sense to call SNPs with the existing short-read model and HiC pair-end illumina data and extract high-quality SNPs as gold standard, and then apply them in the training step of Hifi data? Thank you. Zuyao",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/898
https://github.com/google/deepvariant/issues/898:71,interoperability,standard,standard,71,"Training pacbio HIFI data using the trained short-read model as a gold standard; Dear Deepvariant devolopers,. I am currently working on a Pacibio Hifi dataset from a non-model species. Unfortunately, there is no existing trio hifi dataset for a accurate training. However, we do have a trained model from the short-read pair-end data of the same species. My question is: does it make sense to call SNPs with the existing short-read model and HiC pair-end illumina data and extract high-quality SNPs as gold standard, and then apply them in the training step of Hifi data? Thank you. Zuyao",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/898
https://github.com/google/deepvariant/issues/898:508,interoperability,standard,standard,508,"Training pacbio HIFI data using the trained short-read model as a gold standard; Dear Deepvariant devolopers,. I am currently working on a Pacibio Hifi dataset from a non-model species. Unfortunately, there is no existing trio hifi dataset for a accurate training. However, we do have a trained model from the short-read pair-end data of the same species. My question is: does it make sense to call SNPs with the existing short-read model and HiC pair-end illumina data and extract high-quality SNPs as gold standard, and then apply them in the training step of Hifi data? Thank you. Zuyao",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/898
https://github.com/google/deepvariant/issues/898:9,modifiability,pac,pacbio,9,"Training pacbio HIFI data using the trained short-read model as a gold standard; Dear Deepvariant devolopers,. I am currently working on a Pacibio Hifi dataset from a non-model species. Unfortunately, there is no existing trio hifi dataset for a accurate training. However, we do have a trained model from the short-read pair-end data of the same species. My question is: does it make sense to call SNPs with the existing short-read model and HiC pair-end illumina data and extract high-quality SNPs as gold standard, and then apply them in the training step of Hifi data? Thank you. Zuyao",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/898
https://github.com/google/deepvariant/issues/898:139,modifiability,Pac,Pacibio,139,"Training pacbio HIFI data using the trained short-read model as a gold standard; Dear Deepvariant devolopers,. I am currently working on a Pacibio Hifi dataset from a non-model species. Unfortunately, there is no existing trio hifi dataset for a accurate training. However, we do have a trained model from the short-read pair-end data of the same species. My question is: does it make sense to call SNPs with the existing short-read model and HiC pair-end illumina data and extract high-quality SNPs as gold standard, and then apply them in the training step of Hifi data? Thank you. Zuyao",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/898
https://github.com/google/deepvariant/issues/898:372,reliability,doe,does,372,"Training pacbio HIFI data using the trained short-read model as a gold standard; Dear Deepvariant devolopers,. I am currently working on a Pacibio Hifi dataset from a non-model species. Unfortunately, there is no existing trio hifi dataset for a accurate training. However, we do have a trained model from the short-read pair-end data of the same species. My question is: does it make sense to call SNPs with the existing short-read model and HiC pair-end illumina data and extract high-quality SNPs as gold standard, and then apply them in the training step of Hifi data? Thank you. Zuyao",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/898
https://github.com/google/deepvariant/issues/898:55,security,model,model,55,"Training pacbio HIFI data using the trained short-read model as a gold standard; Dear Deepvariant devolopers,. I am currently working on a Pacibio Hifi dataset from a non-model species. Unfortunately, there is no existing trio hifi dataset for a accurate training. However, we do have a trained model from the short-read pair-end data of the same species. My question is: does it make sense to call SNPs with the existing short-read model and HiC pair-end illumina data and extract high-quality SNPs as gold standard, and then apply them in the training step of Hifi data? Thank you. Zuyao",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/898
https://github.com/google/deepvariant/issues/898:171,security,model,model,171,"Training pacbio HIFI data using the trained short-read model as a gold standard; Dear Deepvariant devolopers,. I am currently working on a Pacibio Hifi dataset from a non-model species. Unfortunately, there is no existing trio hifi dataset for a accurate training. However, we do have a trained model from the short-read pair-end data of the same species. My question is: does it make sense to call SNPs with the existing short-read model and HiC pair-end illumina data and extract high-quality SNPs as gold standard, and then apply them in the training step of Hifi data? Thank you. Zuyao",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/898
https://github.com/google/deepvariant/issues/898:295,security,model,model,295,"Training pacbio HIFI data using the trained short-read model as a gold standard; Dear Deepvariant devolopers,. I am currently working on a Pacibio Hifi dataset from a non-model species. Unfortunately, there is no existing trio hifi dataset for a accurate training. However, we do have a trained model from the short-read pair-end data of the same species. My question is: does it make sense to call SNPs with the existing short-read model and HiC pair-end illumina data and extract high-quality SNPs as gold standard, and then apply them in the training step of Hifi data? Thank you. Zuyao",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/898
https://github.com/google/deepvariant/issues/898:433,security,model,model,433,"Training pacbio HIFI data using the trained short-read model as a gold standard; Dear Deepvariant devolopers,. I am currently working on a Pacibio Hifi dataset from a non-model species. Unfortunately, there is no existing trio hifi dataset for a accurate training. However, we do have a trained model from the short-read pair-end data of the same species. My question is: does it make sense to call SNPs with the existing short-read model and HiC pair-end illumina data and extract high-quality SNPs as gold standard, and then apply them in the training step of Hifi data? Thank you. Zuyao",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/898
https://github.com/google/deepvariant/pull/899:63,performance,time,time,63,Adding new blog post.; We are not taking pull requests at this time. This PR is from people on the team.,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/899
https://github.com/google/deepvariant/pull/899:99,security,team,team,99,Adding new blog post.; We are not taking pull requests at this time. This PR is from people on the team.,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/899
https://github.com/google/deepvariant/issues/900:541,availability,mask,masked,541,"Paralogous Regions Germline SNV Calling; Hi,. Thank you for this great tool. . I have a question with regard to SNV calling in paraloguous regions for WES/WGS illumina models. . As i understand, by default, candidates variants in regions with mapq = 0 are not analyzed. There are attempts to deal with with issue for other callers data https://www.nature.com/articles/s41467-023-42531-9?fromPaywallRec=true. . My question is whether you have data on this issue and if setting the mapq to zero would be advised or it is better advised to use masked genomes. Thanks",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/900
https://github.com/google/deepvariant/issues/900:168,energy efficiency,model,models,168,"Paralogous Regions Germline SNV Calling; Hi,. Thank you for this great tool. . I have a question with regard to SNV calling in paraloguous regions for WES/WGS illumina models. . As i understand, by default, candidates variants in regions with mapq = 0 are not analyzed. There are attempts to deal with with issue for other callers data https://www.nature.com/articles/s41467-023-42531-9?fromPaywallRec=true. . My question is whether you have data on this issue and if setting the mapq to zero would be advised or it is better advised to use masked genomes. Thanks",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/900
https://github.com/google/deepvariant/issues/900:168,security,model,models,168,"Paralogous Regions Germline SNV Calling; Hi,. Thank you for this great tool. . I have a question with regard to SNV calling in paraloguous regions for WES/WGS illumina models. . As i understand, by default, candidates variants in regions with mapq = 0 are not analyzed. There are attempts to deal with with issue for other callers data https://www.nature.com/articles/s41467-023-42531-9?fromPaywallRec=true. . My question is whether you have data on this issue and if setting the mapq to zero would be advised or it is better advised to use masked genomes. Thanks",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/900
https://github.com/google/deepvariant/issues/900:183,testability,understand,understand,183,"Paralogous Regions Germline SNV Calling; Hi,. Thank you for this great tool. . I have a question with regard to SNV calling in paraloguous regions for WES/WGS illumina models. . As i understand, by default, candidates variants in regions with mapq = 0 are not analyzed. There are attempts to deal with with issue for other callers data https://www.nature.com/articles/s41467-023-42531-9?fromPaywallRec=true. . My question is whether you have data on this issue and if setting the mapq to zero would be advised or it is better advised to use masked genomes. Thanks",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/900
https://github.com/google/deepvariant/issues/900:71,usability,tool,tool,71,"Paralogous Regions Germline SNV Calling; Hi,. Thank you for this great tool. . I have a question with regard to SNV calling in paraloguous regions for WES/WGS illumina models. . As i understand, by default, candidates variants in regions with mapq = 0 are not analyzed. There are attempts to deal with with issue for other callers data https://www.nature.com/articles/s41467-023-42531-9?fromPaywallRec=true. . My question is whether you have data on this issue and if setting the mapq to zero would be advised or it is better advised to use masked genomes. Thanks",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/900
https://github.com/google/deepvariant/issues/901:29,availability,error,erroring,29,"postprocess_variants step is erroring out in quickstart example; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. (A clear and concise description of what the issue is.). `run_deepvariant` is erroring out in the `postprocess_variants` step. **Setup**. - Operating system: Running inside docker image - `google/deepvariant:1.6.0-gpu`. - DeepVariant version: `1.6.0`. - Installation method (Docker, built from source, etc.): Docker image - `google/deepvariant:1.6.0-gpu`. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command: Running the quickstart cmd --. ```. /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/opt/deepvariant/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta --reads=/opt/deepvariant/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam --regions ""chr20:10,000,000-10,010,000"" --output_vcf=/opt/deepvariant/quickstart-output/output.vcf.gz --output_gvcf=/opt/deepvariant/quickstart-output/output.g.vcf.gz --intermediate_results_dir /opt/deepvariant/quickstart-output/intermediate_results_dir --num_shards=1 --verbosity=2. ```. - Error trace: (if applicable) In the `postprocess_variants` step. ```. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/opt/deepvariant/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --infile ""/opt/deepvariant/quickstart-output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --outfile ""/opt/deepvariant/quickstart-output/output.vcf.gz"" --cpus ""1"" --gvcf_outfile ""/opt/deepvariant/quickstart-output/output.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/opt/deepvariant/quickstart-output/intermediate_results_dir/gvcf.tfrecord@1.gz"". 2024-10-31 20:36:34.101345: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/901
https://github.com/google/deepvariant/issues/901:267,availability,error,erroring,267,"postprocess_variants step is erroring out in quickstart example; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. (A clear and concise description of what the issue is.). `run_deepvariant` is erroring out in the `postprocess_variants` step. **Setup**. - Operating system: Running inside docker image - `google/deepvariant:1.6.0-gpu`. - DeepVariant version: `1.6.0`. - Installation method (Docker, built from source, etc.): Docker image - `google/deepvariant:1.6.0-gpu`. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command: Running the quickstart cmd --. ```. /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/opt/deepvariant/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta --reads=/opt/deepvariant/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam --regions ""chr20:10,000,000-10,010,000"" --output_vcf=/opt/deepvariant/quickstart-output/output.vcf.gz --output_gvcf=/opt/deepvariant/quickstart-output/output.g.vcf.gz --intermediate_results_dir /opt/deepvariant/quickstart-output/intermediate_results_dir --num_shards=1 --verbosity=2. ```. - Error trace: (if applicable) In the `postprocess_variants` step. ```. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/opt/deepvariant/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --infile ""/opt/deepvariant/quickstart-output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --outfile ""/opt/deepvariant/quickstart-output/output.vcf.gz"" --cpus ""1"" --gvcf_outfile ""/opt/deepvariant/quickstart-output/output.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/opt/deepvariant/quickstart-output/intermediate_results_dir/gvcf.tfrecord@1.gz"". 2024-10-31 20:36:34.101345: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/901
https://github.com/google/deepvariant/issues/901:329,availability,Operat,Operating,329,"postprocess_variants step is erroring out in quickstart example; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. (A clear and concise description of what the issue is.). `run_deepvariant` is erroring out in the `postprocess_variants` step. **Setup**. - Operating system: Running inside docker image - `google/deepvariant:1.6.0-gpu`. - DeepVariant version: `1.6.0`. - Installation method (Docker, built from source, etc.): Docker image - `google/deepvariant:1.6.0-gpu`. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command: Running the quickstart cmd --. ```. /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/opt/deepvariant/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta --reads=/opt/deepvariant/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam --regions ""chr20:10,000,000-10,010,000"" --output_vcf=/opt/deepvariant/quickstart-output/output.vcf.gz --output_gvcf=/opt/deepvariant/quickstart-output/output.g.vcf.gz --intermediate_results_dir /opt/deepvariant/quickstart-output/intermediate_results_dir --num_shards=1 --verbosity=2. ```. - Error trace: (if applicable) In the `postprocess_variants` step. ```. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/opt/deepvariant/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --infile ""/opt/deepvariant/quickstart-output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --outfile ""/opt/deepvariant/quickstart-output/output.vcf.gz"" --cpus ""1"" --gvcf_outfile ""/opt/deepvariant/quickstart-output/output.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/opt/deepvariant/quickstart-output/intermediate_results_dir/gvcf.tfrecord@1.gz"". 2024-10-31 20:36:34.101345: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/901
https://github.com/google/deepvariant/issues/901:1222,availability,Error,Error,1222,"what the issue is.). `run_deepvariant` is erroring out in the `postprocess_variants` step. **Setup**. - Operating system: Running inside docker image - `google/deepvariant:1.6.0-gpu`. - DeepVariant version: `1.6.0`. - Installation method (Docker, built from source, etc.): Docker image - `google/deepvariant:1.6.0-gpu`. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command: Running the quickstart cmd --. ```. /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/opt/deepvariant/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta --reads=/opt/deepvariant/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam --regions ""chr20:10,000,000-10,010,000"" --output_vcf=/opt/deepvariant/quickstart-output/output.vcf.gz --output_gvcf=/opt/deepvariant/quickstart-output/output.g.vcf.gz --intermediate_results_dir /opt/deepvariant/quickstart-output/intermediate_results_dir --num_shards=1 --verbosity=2. ```. - Error trace: (if applicable) In the `postprocess_variants` step. ```. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/opt/deepvariant/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --infile ""/opt/deepvariant/quickstart-output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --outfile ""/opt/deepvariant/quickstart-output/output.vcf.gz"" --cpus ""1"" --gvcf_outfile ""/opt/deepvariant/quickstart-output/output.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/opt/deepvariant/quickstart-output/intermediate_results_dir/gvcf.tfrecord@1.gz"". 2024-10-31 20:36:34.101345: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64. 2024-10-31 20:36:34.101375: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot d",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/901
https://github.com/google/deepvariant/issues/901:423,deployability,version,version,423,"postprocess_variants step is erroring out in quickstart example; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. (A clear and concise description of what the issue is.). `run_deepvariant` is erroring out in the `postprocess_variants` step. **Setup**. - Operating system: Running inside docker image - `google/deepvariant:1.6.0-gpu`. - DeepVariant version: `1.6.0`. - Installation method (Docker, built from source, etc.): Docker image - `google/deepvariant:1.6.0-gpu`. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command: Running the quickstart cmd --. ```. /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/opt/deepvariant/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta --reads=/opt/deepvariant/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam --regions ""chr20:10,000,000-10,010,000"" --output_vcf=/opt/deepvariant/quickstart-output/output.vcf.gz --output_gvcf=/opt/deepvariant/quickstart-output/output.g.vcf.gz --intermediate_results_dir /opt/deepvariant/quickstart-output/intermediate_results_dir --num_shards=1 --verbosity=2. ```. - Error trace: (if applicable) In the `postprocess_variants` step. ```. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/opt/deepvariant/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --infile ""/opt/deepvariant/quickstart-output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --outfile ""/opt/deepvariant/quickstart-output/output.vcf.gz"" --cpus ""1"" --gvcf_outfile ""/opt/deepvariant/quickstart-output/output.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/opt/deepvariant/quickstart-output/intermediate_results_dir/gvcf.tfrecord@1.gz"". 2024-10-31 20:36:34.101345: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/901
https://github.com/google/deepvariant/issues/901:443,deployability,Instal,Installation,443,"postprocess_variants step is erroring out in quickstart example; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. (A clear and concise description of what the issue is.). `run_deepvariant` is erroring out in the `postprocess_variants` step. **Setup**. - Operating system: Running inside docker image - `google/deepvariant:1.6.0-gpu`. - DeepVariant version: `1.6.0`. - Installation method (Docker, built from source, etc.): Docker image - `google/deepvariant:1.6.0-gpu`. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command: Running the quickstart cmd --. ```. /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/opt/deepvariant/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta --reads=/opt/deepvariant/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam --regions ""chr20:10,000,000-10,010,000"" --output_vcf=/opt/deepvariant/quickstart-output/output.vcf.gz --output_gvcf=/opt/deepvariant/quickstart-output/output.g.vcf.gz --intermediate_results_dir /opt/deepvariant/quickstart-output/intermediate_results_dir --num_shards=1 --verbosity=2. ```. - Error trace: (if applicable) In the `postprocess_variants` step. ```. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/opt/deepvariant/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --infile ""/opt/deepvariant/quickstart-output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --outfile ""/opt/deepvariant/quickstart-output/output.vcf.gz"" --cpus ""1"" --gvcf_outfile ""/opt/deepvariant/quickstart-output/output.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/opt/deepvariant/quickstart-output/intermediate_results_dir/gvcf.tfrecord@1.gz"". 2024-10-31 20:36:34.101345: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/901
https://github.com/google/deepvariant/issues/901:2366,deployability,instal,installed,2366," --ref ""/opt/deepvariant/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --infile ""/opt/deepvariant/quickstart-output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --outfile ""/opt/deepvariant/quickstart-output/output.vcf.gz"" --cpus ""1"" --gvcf_outfile ""/opt/deepvariant/quickstart-output/output.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/opt/deepvariant/quickstart-output/intermediate_results_dir/gvcf.tfrecord@1.gz"". 2024-10-31 20:36:34.101345: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64. 2024-10-31 20:36:34.101375: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-10-31 20:36:35.010025: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2027] TensorFlow was not built with CUDA kernel binaries compatible with compute capability 9.0. CUDA kernels will be jit-compiled from PTX, which could take 30 minutes or longer. I1031 20:36:35.011695 132485076334400 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: NA12878. I1031 20:36:35.013445 132485076334400 postprocess_variants.py:1313] CVO sorting took 1.1885166168212891e-05 minutes. I1031 20:36:35.013573 132485076334400 postprocess_variants.py:1316] Transforming call_variants_output to variants. I1031 20:36:35.014770 132485076334400 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: NA12878. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_in6znu90/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1419, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_in6znu90/runfiles/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/901
https://github.com/google/deepvariant/issues/901:3303,deployability,modul,module,3303," please make sure the missing libraries mentioned above are installed properly. 2024-10-31 20:36:35.010025: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2027] TensorFlow was not built with CUDA kernel binaries compatible with compute capability 9.0. CUDA kernels will be jit-compiled from PTX, which could take 30 minutes or longer. I1031 20:36:35.011695 132485076334400 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: NA12878. I1031 20:36:35.013445 132485076334400 postprocess_variants.py:1313] CVO sorting took 1.1885166168212891e-05 minutes. I1031 20:36:35.013573 132485076334400 postprocess_variants.py:1316] Transforming call_variants_output to variants. I1031 20:36:35.014770 132485076334400 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: NA12878. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_in6znu90/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1419, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_in6znu90/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_in6znu90/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_in6znu90/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1385, in main. tmp_variant_file = dump_variants_to_temp_file(variant_generator). File ""/tmp/Bazel.runfiles_in6znu90/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1067, in dump_variants_to_temp_file. tfrecord.write_tfrecords(variant_protos, temp.name). File ""/tmp/Bazel.runfiles_in6znu90/runfiles/com_google_deepvariant/third_party/nucleus/io/tfrecord.py"", line 190, in write_tfrecords. for proto in protos:. File ""/tmp/Bazel.runfiles_in6znu90/runfiles/com_google_deepvariant/deepvariant/haplotypes.py"", line 91, in maybe_resolve_conflicting_variants. for overlapping_candidates in _group_overlapping_variants(sorted_varia",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/901
https://github.com/google/deepvariant/issues/901:5925,deployability,version,version,5925,"""/tmp/Bazel.runfiles_in6znu90/runfiles/com_google_deepvariant/third_party/nucleus/io/tfrecord.py"", line 190, in write_tfrecords. for proto in protos:. File ""/tmp/Bazel.runfiles_in6znu90/runfiles/com_google_deepvariant/deepvariant/haplotypes.py"", line 91, in maybe_resolve_conflicting_variants. for overlapping_candidates in _group_overlapping_variants(sorted_variants):. File ""/tmp/Bazel.runfiles_in6znu90/runfiles/com_google_deepvariant/deepvariant/haplotypes.py"", line 111, in _group_overlapping_variants. for variant in sorted_variants:. File ""/tmp/Bazel.runfiles_in6znu90/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1062, in _transform_call_variants_output_to_variants. yield _transform_call_variant_group_to_output_variant(**cvo_group_kwargs). File ""/tmp/Bazel.runfiles_in6znu90/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1036, in _transform_call_variant_group_to_output_variant. return add_call_to_variant(. File ""/tmp/Bazel.runfiles_in6znu90/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 434, in add_call_to_variant. gq, variant.quality = compute_quals(predictions, index). File ""/tmp/Bazel.runfiles_in6znu90/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 469, in compute_quals. genomics_math.ptrue_to_bounded_phred(predictions[prediction_index]). File ""/tmp/Bazel.runfiles_in6znu90/runfiles/com_google_deepvariant/third_party/nucleus/util/genomics_math.py"", line 143, in ptrue_to_bounded_phred. raise ValueError('ptrue must be between zero and one: {}'.format(ptrue)). ValueError: ptrue must be between zero and one: nan. ```. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. I'm running this code on an H100 GPU running nvidia driver - `535.183.06` and CUDA version is `12.2`",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/901
https://github.com/google/deepvariant/issues/901:403,energy efficiency,gpu,gpu,403,"postprocess_variants step is erroring out in quickstart example; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. (A clear and concise description of what the issue is.). `run_deepvariant` is erroring out in the `postprocess_variants` step. **Setup**. - Operating system: Running inside docker image - `google/deepvariant:1.6.0-gpu`. - DeepVariant version: `1.6.0`. - Installation method (Docker, built from source, etc.): Docker image - `google/deepvariant:1.6.0-gpu`. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command: Running the quickstart cmd --. ```. /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/opt/deepvariant/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta --reads=/opt/deepvariant/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam --regions ""chr20:10,000,000-10,010,000"" --output_vcf=/opt/deepvariant/quickstart-output/output.vcf.gz --output_gvcf=/opt/deepvariant/quickstart-output/output.g.vcf.gz --intermediate_results_dir /opt/deepvariant/quickstart-output/intermediate_results_dir --num_shards=1 --verbosity=2. ```. - Error trace: (if applicable) In the `postprocess_variants` step. ```. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/opt/deepvariant/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --infile ""/opt/deepvariant/quickstart-output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --outfile ""/opt/deepvariant/quickstart-output/output.vcf.gz"" --cpus ""1"" --gvcf_outfile ""/opt/deepvariant/quickstart-output/output.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/opt/deepvariant/quickstart-output/intermediate_results_dir/gvcf.tfrecord@1.gz"". 2024-10-31 20:36:34.101345: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/901
https://github.com/google/deepvariant/issues/901:539,energy efficiency,gpu,gpu,539,"postprocess_variants step is erroring out in quickstart example; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. (A clear and concise description of what the issue is.). `run_deepvariant` is erroring out in the `postprocess_variants` step. **Setup**. - Operating system: Running inside docker image - `google/deepvariant:1.6.0-gpu`. - DeepVariant version: `1.6.0`. - Installation method (Docker, built from source, etc.): Docker image - `google/deepvariant:1.6.0-gpu`. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command: Running the quickstart cmd --. ```. /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/opt/deepvariant/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta --reads=/opt/deepvariant/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam --regions ""chr20:10,000,000-10,010,000"" --output_vcf=/opt/deepvariant/quickstart-output/output.vcf.gz --output_gvcf=/opt/deepvariant/quickstart-output/output.g.vcf.gz --intermediate_results_dir /opt/deepvariant/quickstart-output/intermediate_results_dir --num_shards=1 --verbosity=2. ```. - Error trace: (if applicable) In the `postprocess_variants` step. ```. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/opt/deepvariant/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --infile ""/opt/deepvariant/quickstart-output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --outfile ""/opt/deepvariant/quickstart-output/output.vcf.gz"" --cpus ""1"" --gvcf_outfile ""/opt/deepvariant/quickstart-output/output.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/opt/deepvariant/quickstart-output/intermediate_results_dir/gvcf.tfrecord@1.gz"". 2024-10-31 20:36:34.101345: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/901
https://github.com/google/deepvariant/issues/901:1615,energy efficiency,cpu,cpus,1615,"al that is unlike the case studies?). **Steps to reproduce:**. - Command: Running the quickstart cmd --. ```. /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/opt/deepvariant/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta --reads=/opt/deepvariant/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam --regions ""chr20:10,000,000-10,010,000"" --output_vcf=/opt/deepvariant/quickstart-output/output.vcf.gz --output_gvcf=/opt/deepvariant/quickstart-output/output.g.vcf.gz --intermediate_results_dir /opt/deepvariant/quickstart-output/intermediate_results_dir --num_shards=1 --verbosity=2. ```. - Error trace: (if applicable) In the `postprocess_variants` step. ```. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/opt/deepvariant/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --infile ""/opt/deepvariant/quickstart-output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --outfile ""/opt/deepvariant/quickstart-output/output.vcf.gz"" --cpus ""1"" --gvcf_outfile ""/opt/deepvariant/quickstart-output/output.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/opt/deepvariant/quickstart-output/intermediate_results_dir/gvcf.tfrecord@1.gz"". 2024-10-31 20:36:34.101345: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64. 2024-10-31 20:36:34.101375: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-10-31 20:36:35.010025: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2027] TensorFlow was not built with CUDA kernel binaries compatible with compute capability 9.0. CUDA kernels will be jit-compiled from PTX, which could",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/901
https://github.com/google/deepvariant/issues/901:1921,energy efficiency,load,load,1921,"1mb.bam --regions ""chr20:10,000,000-10,010,000"" --output_vcf=/opt/deepvariant/quickstart-output/output.vcf.gz --output_gvcf=/opt/deepvariant/quickstart-output/output.g.vcf.gz --intermediate_results_dir /opt/deepvariant/quickstart-output/intermediate_results_dir --num_shards=1 --verbosity=2. ```. - Error trace: (if applicable) In the `postprocess_variants` step. ```. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/opt/deepvariant/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --infile ""/opt/deepvariant/quickstart-output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --outfile ""/opt/deepvariant/quickstart-output/output.vcf.gz"" --cpus ""1"" --gvcf_outfile ""/opt/deepvariant/quickstart-output/output.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/opt/deepvariant/quickstart-output/intermediate_results_dir/gvcf.tfrecord@1.gz"". 2024-10-31 20:36:34.101345: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64. 2024-10-31 20:36:34.101375: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-10-31 20:36:35.010025: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2027] TensorFlow was not built with CUDA kernel binaries compatible with compute capability 9.0. CUDA kernels will be jit-compiled from PTX, which could take 30 minutes or longer. I1031 20:36:35.011695 132485076334400 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: NA12878. I1031 20:36:35.013445 132485076334400 postprocess_variants.py:1313] CVO sorting took 1.1885166168212891e-05 minutes. I1031 20:36:35.013573 1324",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/901
https://github.com/google/deepvariant/issues/901:2288,energy efficiency,GPU,GPU,2288,". ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/opt/deepvariant/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --infile ""/opt/deepvariant/quickstart-output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --outfile ""/opt/deepvariant/quickstart-output/output.vcf.gz"" --cpus ""1"" --gvcf_outfile ""/opt/deepvariant/quickstart-output/output.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/opt/deepvariant/quickstart-output/intermediate_results_dir/gvcf.tfrecord@1.gz"". 2024-10-31 20:36:34.101345: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64. 2024-10-31 20:36:34.101375: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-10-31 20:36:35.010025: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2027] TensorFlow was not built with CUDA kernel binaries compatible with compute capability 9.0. CUDA kernels will be jit-compiled from PTX, which could take 30 minutes or longer. I1031 20:36:35.011695 132485076334400 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: NA12878. I1031 20:36:35.013445 132485076334400 postprocess_variants.py:1313] CVO sorting took 1.1885166168212891e-05 minutes. I1031 20:36:35.013573 132485076334400 postprocess_variants.py:1316] Transforming call_variants_output to variants. I1031 20:36:35.014770 132485076334400 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: NA12878. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_in6znu90/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", li",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/901
https://github.com/google/deepvariant/issues/901:2427,energy efficiency,core,core,2427,"20.unittest.fasta"" --infile ""/opt/deepvariant/quickstart-output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --outfile ""/opt/deepvariant/quickstart-output/output.vcf.gz"" --cpus ""1"" --gvcf_outfile ""/opt/deepvariant/quickstart-output/output.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/opt/deepvariant/quickstart-output/intermediate_results_dir/gvcf.tfrecord@1.gz"". 2024-10-31 20:36:34.101345: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64. 2024-10-31 20:36:34.101375: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-10-31 20:36:35.010025: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2027] TensorFlow was not built with CUDA kernel binaries compatible with compute capability 9.0. CUDA kernels will be jit-compiled from PTX, which could take 30 minutes or longer. I1031 20:36:35.011695 132485076334400 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: NA12878. I1031 20:36:35.013445 132485076334400 postprocess_variants.py:1313] CVO sorting took 1.1885166168212891e-05 minutes. I1031 20:36:35.013573 132485076334400 postprocess_variants.py:1316] Transforming call_variants_output to variants. I1031 20:36:35.014770 132485076334400 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: NA12878. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_in6znu90/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1419, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_in6znu90/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, ar",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/901
https://github.com/google/deepvariant/issues/901:2447,energy efficiency,gpu,gpu,2447,"-infile ""/opt/deepvariant/quickstart-output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --outfile ""/opt/deepvariant/quickstart-output/output.vcf.gz"" --cpus ""1"" --gvcf_outfile ""/opt/deepvariant/quickstart-output/output.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/opt/deepvariant/quickstart-output/intermediate_results_dir/gvcf.tfrecord@1.gz"". 2024-10-31 20:36:34.101345: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64. 2024-10-31 20:36:34.101375: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-10-31 20:36:35.010025: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2027] TensorFlow was not built with CUDA kernel binaries compatible with compute capability 9.0. CUDA kernels will be jit-compiled from PTX, which could take 30 minutes or longer. I1031 20:36:35.011695 132485076334400 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: NA12878. I1031 20:36:35.013445 132485076334400 postprocess_variants.py:1313] CVO sorting took 1.1885166168212891e-05 minutes. I1031 20:36:35.013573 132485076334400 postprocess_variants.py:1316] Transforming call_variants_output to variants. I1031 20:36:35.014770 132485076334400 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: NA12878. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_in6znu90/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1419, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_in6znu90/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Baze",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/901
https://github.com/google/deepvariant/issues/901:5094,energy efficiency,predict,predictions,5094,"""/tmp/Bazel.runfiles_in6znu90/runfiles/com_google_deepvariant/third_party/nucleus/io/tfrecord.py"", line 190, in write_tfrecords. for proto in protos:. File ""/tmp/Bazel.runfiles_in6znu90/runfiles/com_google_deepvariant/deepvariant/haplotypes.py"", line 91, in maybe_resolve_conflicting_variants. for overlapping_candidates in _group_overlapping_variants(sorted_variants):. File ""/tmp/Bazel.runfiles_in6znu90/runfiles/com_google_deepvariant/deepvariant/haplotypes.py"", line 111, in _group_overlapping_variants. for variant in sorted_variants:. File ""/tmp/Bazel.runfiles_in6znu90/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1062, in _transform_call_variants_output_to_variants. yield _transform_call_variant_group_to_output_variant(**cvo_group_kwargs). File ""/tmp/Bazel.runfiles_in6znu90/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1036, in _transform_call_variant_group_to_output_variant. return add_call_to_variant(. File ""/tmp/Bazel.runfiles_in6znu90/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 434, in add_call_to_variant. gq, variant.quality = compute_quals(predictions, index). File ""/tmp/Bazel.runfiles_in6znu90/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 469, in compute_quals. genomics_math.ptrue_to_bounded_phred(predictions[prediction_index]). File ""/tmp/Bazel.runfiles_in6znu90/runfiles/com_google_deepvariant/third_party/nucleus/util/genomics_math.py"", line 143, in ptrue_to_bounded_phred. raise ValueError('ptrue must be between zero and one: {}'.format(ptrue)). ValueError: ptrue must be between zero and one: nan. ```. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. I'm running this code on an H100 GPU running nvidia driver - `535.183.06` and CUDA version is `12.2`",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/901
https://github.com/google/deepvariant/issues/901:5285,energy efficiency,predict,predictions,5285,"""/tmp/Bazel.runfiles_in6znu90/runfiles/com_google_deepvariant/third_party/nucleus/io/tfrecord.py"", line 190, in write_tfrecords. for proto in protos:. File ""/tmp/Bazel.runfiles_in6znu90/runfiles/com_google_deepvariant/deepvariant/haplotypes.py"", line 91, in maybe_resolve_conflicting_variants. for overlapping_candidates in _group_overlapping_variants(sorted_variants):. File ""/tmp/Bazel.runfiles_in6znu90/runfiles/com_google_deepvariant/deepvariant/haplotypes.py"", line 111, in _group_overlapping_variants. for variant in sorted_variants:. File ""/tmp/Bazel.runfiles_in6znu90/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1062, in _transform_call_variants_output_to_variants. yield _transform_call_variant_group_to_output_variant(**cvo_group_kwargs). File ""/tmp/Bazel.runfiles_in6znu90/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1036, in _transform_call_variant_group_to_output_variant. return add_call_to_variant(. File ""/tmp/Bazel.runfiles_in6znu90/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 434, in add_call_to_variant. gq, variant.quality = compute_quals(predictions, index). File ""/tmp/Bazel.runfiles_in6znu90/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 469, in compute_quals. genomics_math.ptrue_to_bounded_phred(predictions[prediction_index]). File ""/tmp/Bazel.runfiles_in6znu90/runfiles/com_google_deepvariant/third_party/nucleus/util/genomics_math.py"", line 143, in ptrue_to_bounded_phred. raise ValueError('ptrue must be between zero and one: {}'.format(ptrue)). ValueError: ptrue must be between zero and one: nan. ```. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. I'm running this code on an H100 GPU running nvidia driver - `535.183.06` and CUDA version is `12.2`",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/901
https://github.com/google/deepvariant/issues/901:5875,energy efficiency,GPU,GPU,5875,"""/tmp/Bazel.runfiles_in6znu90/runfiles/com_google_deepvariant/third_party/nucleus/io/tfrecord.py"", line 190, in write_tfrecords. for proto in protos:. File ""/tmp/Bazel.runfiles_in6znu90/runfiles/com_google_deepvariant/deepvariant/haplotypes.py"", line 91, in maybe_resolve_conflicting_variants. for overlapping_candidates in _group_overlapping_variants(sorted_variants):. File ""/tmp/Bazel.runfiles_in6znu90/runfiles/com_google_deepvariant/deepvariant/haplotypes.py"", line 111, in _group_overlapping_variants. for variant in sorted_variants:. File ""/tmp/Bazel.runfiles_in6znu90/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1062, in _transform_call_variants_output_to_variants. yield _transform_call_variant_group_to_output_variant(**cvo_group_kwargs). File ""/tmp/Bazel.runfiles_in6znu90/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1036, in _transform_call_variant_group_to_output_variant. return add_call_to_variant(. File ""/tmp/Bazel.runfiles_in6znu90/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 434, in add_call_to_variant. gq, variant.quality = compute_quals(predictions, index). File ""/tmp/Bazel.runfiles_in6znu90/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 469, in compute_quals. genomics_math.ptrue_to_bounded_phred(predictions[prediction_index]). File ""/tmp/Bazel.runfiles_in6znu90/runfiles/com_google_deepvariant/third_party/nucleus/util/genomics_math.py"", line 143, in ptrue_to_bounded_phred. raise ValueError('ptrue must be between zero and one: {}'.format(ptrue)). ValueError: ptrue must be between zero and one: nan. ```. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. I'm running this code on an H100 GPU running nvidia driver - `535.183.06` and CUDA version is `12.2`",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/901
https://github.com/google/deepvariant/issues/901:423,integrability,version,version,423,"postprocess_variants step is erroring out in quickstart example; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. (A clear and concise description of what the issue is.). `run_deepvariant` is erroring out in the `postprocess_variants` step. **Setup**. - Operating system: Running inside docker image - `google/deepvariant:1.6.0-gpu`. - DeepVariant version: `1.6.0`. - Installation method (Docker, built from source, etc.): Docker image - `google/deepvariant:1.6.0-gpu`. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command: Running the quickstart cmd --. ```. /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/opt/deepvariant/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta --reads=/opt/deepvariant/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam --regions ""chr20:10,000,000-10,010,000"" --output_vcf=/opt/deepvariant/quickstart-output/output.vcf.gz --output_gvcf=/opt/deepvariant/quickstart-output/output.g.vcf.gz --intermediate_results_dir /opt/deepvariant/quickstart-output/intermediate_results_dir --num_shards=1 --verbosity=2. ```. - Error trace: (if applicable) In the `postprocess_variants` step. ```. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/opt/deepvariant/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --infile ""/opt/deepvariant/quickstart-output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --outfile ""/opt/deepvariant/quickstart-output/output.vcf.gz"" --cpus ""1"" --gvcf_outfile ""/opt/deepvariant/quickstart-output/output.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/opt/deepvariant/quickstart-output/intermediate_results_dir/gvcf.tfrecord@1.gz"". 2024-10-31 20:36:34.101345: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/901
https://github.com/google/deepvariant/issues/901:2965,integrability,Transform,Transforming,2965,"rror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64. 2024-10-31 20:36:34.101375: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-10-31 20:36:35.010025: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2027] TensorFlow was not built with CUDA kernel binaries compatible with compute capability 9.0. CUDA kernels will be jit-compiled from PTX, which could take 30 minutes or longer. I1031 20:36:35.011695 132485076334400 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: NA12878. I1031 20:36:35.013445 132485076334400 postprocess_variants.py:1313] CVO sorting took 1.1885166168212891e-05 minutes. I1031 20:36:35.013573 132485076334400 postprocess_variants.py:1316] Transforming call_variants_output to variants. I1031 20:36:35.014770 132485076334400 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: NA12878. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_in6znu90/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1419, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_in6znu90/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_in6znu90/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_in6znu90/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1385, in main. tmp_variant_file = dump_variants_to_temp_file(variant_generator). File ""/tmp/Bazel.runfiles_in6znu90/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1067, in dump_variants_to_temp_file. tfrecord.write_tfrecords(variant_protos, temp.name). File ""/tmp/Bazel.runfiles_in6znu90",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/901
https://github.com/google/deepvariant/issues/901:5925,integrability,version,version,5925,"""/tmp/Bazel.runfiles_in6znu90/runfiles/com_google_deepvariant/third_party/nucleus/io/tfrecord.py"", line 190, in write_tfrecords. for proto in protos:. File ""/tmp/Bazel.runfiles_in6znu90/runfiles/com_google_deepvariant/deepvariant/haplotypes.py"", line 91, in maybe_resolve_conflicting_variants. for overlapping_candidates in _group_overlapping_variants(sorted_variants):. File ""/tmp/Bazel.runfiles_in6znu90/runfiles/com_google_deepvariant/deepvariant/haplotypes.py"", line 111, in _group_overlapping_variants. for variant in sorted_variants:. File ""/tmp/Bazel.runfiles_in6znu90/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1062, in _transform_call_variants_output_to_variants. yield _transform_call_variant_group_to_output_variant(**cvo_group_kwargs). File ""/tmp/Bazel.runfiles_in6znu90/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1036, in _transform_call_variant_group_to_output_variant. return add_call_to_variant(. File ""/tmp/Bazel.runfiles_in6znu90/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 434, in add_call_to_variant. gq, variant.quality = compute_quals(predictions, index). File ""/tmp/Bazel.runfiles_in6znu90/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 469, in compute_quals. genomics_math.ptrue_to_bounded_phred(predictions[prediction_index]). File ""/tmp/Bazel.runfiles_in6znu90/runfiles/com_google_deepvariant/third_party/nucleus/util/genomics_math.py"", line 143, in ptrue_to_bounded_phred. raise ValueError('ptrue must be between zero and one: {}'.format(ptrue)). ValueError: ptrue must be between zero and one: nan. ```. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. I'm running this code on an H100 GPU running nvidia driver - `535.183.06` and CUDA version is `12.2`",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/901
https://github.com/google/deepvariant/issues/901:1876,interoperability,platform,platform,1876,"quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam --regions ""chr20:10,000,000-10,010,000"" --output_vcf=/opt/deepvariant/quickstart-output/output.vcf.gz --output_gvcf=/opt/deepvariant/quickstart-output/output.g.vcf.gz --intermediate_results_dir /opt/deepvariant/quickstart-output/intermediate_results_dir --num_shards=1 --verbosity=2. ```. - Error trace: (if applicable) In the `postprocess_variants` step. ```. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/opt/deepvariant/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --infile ""/opt/deepvariant/quickstart-output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --outfile ""/opt/deepvariant/quickstart-output/output.vcf.gz"" --cpus ""1"" --gvcf_outfile ""/opt/deepvariant/quickstart-output/output.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/opt/deepvariant/quickstart-output/intermediate_results_dir/gvcf.tfrecord@1.gz"". 2024-10-31 20:36:34.101345: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64. 2024-10-31 20:36:34.101375: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-10-31 20:36:35.010025: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2027] TensorFlow was not built with CUDA kernel binaries compatible with compute capability 9.0. CUDA kernels will be jit-compiled from PTX, which could take 30 minutes or longer. I1031 20:36:35.011695 132485076334400 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: NA12878. I1031 20:36:35.013445 132485076334400 postprocess_variants.py:1313] CVO sorting took 1.1885166168212",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/901
https://github.com/google/deepvariant/issues/901:2006,interoperability,share,shared,2006,"rt-output/output.vcf.gz --output_gvcf=/opt/deepvariant/quickstart-output/output.g.vcf.gz --intermediate_results_dir /opt/deepvariant/quickstart-output/intermediate_results_dir --num_shards=1 --verbosity=2. ```. - Error trace: (if applicable) In the `postprocess_variants` step. ```. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/opt/deepvariant/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --infile ""/opt/deepvariant/quickstart-output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --outfile ""/opt/deepvariant/quickstart-output/output.vcf.gz"" --cpus ""1"" --gvcf_outfile ""/opt/deepvariant/quickstart-output/output.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/opt/deepvariant/quickstart-output/intermediate_results_dir/gvcf.tfrecord@1.gz"". 2024-10-31 20:36:34.101345: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64. 2024-10-31 20:36:34.101375: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-10-31 20:36:35.010025: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2027] TensorFlow was not built with CUDA kernel binaries compatible with compute capability 9.0. CUDA kernels will be jit-compiled from PTX, which could take 30 minutes or longer. I1031 20:36:35.011695 132485076334400 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: NA12878. I1031 20:36:35.013445 132485076334400 postprocess_variants.py:1313] CVO sorting took 1.1885166168212891e-05 minutes. I1031 20:36:35.013573 132485076334400 postprocess_variants.py:1316] Transforming call_variants_output to variant",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/901
https://github.com/google/deepvariant/issues/901:2522,interoperability,compatib,compatible,2522,"ants_output.tfrecord.gz"" --outfile ""/opt/deepvariant/quickstart-output/output.vcf.gz"" --cpus ""1"" --gvcf_outfile ""/opt/deepvariant/quickstart-output/output.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/opt/deepvariant/quickstart-output/intermediate_results_dir/gvcf.tfrecord@1.gz"". 2024-10-31 20:36:34.101345: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64. 2024-10-31 20:36:34.101375: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-10-31 20:36:35.010025: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2027] TensorFlow was not built with CUDA kernel binaries compatible with compute capability 9.0. CUDA kernels will be jit-compiled from PTX, which could take 30 minutes or longer. I1031 20:36:35.011695 132485076334400 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: NA12878. I1031 20:36:35.013445 132485076334400 postprocess_variants.py:1313] CVO sorting took 1.1885166168212891e-05 minutes. I1031 20:36:35.013573 132485076334400 postprocess_variants.py:1316] Transforming call_variants_output to variants. I1031 20:36:35.014770 132485076334400 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: NA12878. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_in6znu90/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1419, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_in6znu90/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_in6znu90/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/901
https://github.com/google/deepvariant/issues/901:2965,interoperability,Transform,Transforming,2965,"rror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64. 2024-10-31 20:36:34.101375: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-10-31 20:36:35.010025: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2027] TensorFlow was not built with CUDA kernel binaries compatible with compute capability 9.0. CUDA kernels will be jit-compiled from PTX, which could take 30 minutes or longer. I1031 20:36:35.011695 132485076334400 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: NA12878. I1031 20:36:35.013445 132485076334400 postprocess_variants.py:1313] CVO sorting took 1.1885166168212891e-05 minutes. I1031 20:36:35.013573 132485076334400 postprocess_variants.py:1316] Transforming call_variants_output to variants. I1031 20:36:35.014770 132485076334400 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: NA12878. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_in6znu90/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1419, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_in6znu90/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_in6znu90/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_in6znu90/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1385, in main. tmp_variant_file = dump_variants_to_temp_file(variant_generator). File ""/tmp/Bazel.runfiles_in6znu90/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1067, in dump_variants_to_temp_file. tfrecord.write_tfrecords(variant_protos, temp.name). File ""/tmp/Bazel.runfiles_in6znu90",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/901
https://github.com/google/deepvariant/issues/901:5523,interoperability,format,format,5523,"""/tmp/Bazel.runfiles_in6znu90/runfiles/com_google_deepvariant/third_party/nucleus/io/tfrecord.py"", line 190, in write_tfrecords. for proto in protos:. File ""/tmp/Bazel.runfiles_in6znu90/runfiles/com_google_deepvariant/deepvariant/haplotypes.py"", line 91, in maybe_resolve_conflicting_variants. for overlapping_candidates in _group_overlapping_variants(sorted_variants):. File ""/tmp/Bazel.runfiles_in6znu90/runfiles/com_google_deepvariant/deepvariant/haplotypes.py"", line 111, in _group_overlapping_variants. for variant in sorted_variants:. File ""/tmp/Bazel.runfiles_in6znu90/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1062, in _transform_call_variants_output_to_variants. yield _transform_call_variant_group_to_output_variant(**cvo_group_kwargs). File ""/tmp/Bazel.runfiles_in6znu90/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1036, in _transform_call_variant_group_to_output_variant. return add_call_to_variant(. File ""/tmp/Bazel.runfiles_in6znu90/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 434, in add_call_to_variant. gq, variant.quality = compute_quals(predictions, index). File ""/tmp/Bazel.runfiles_in6znu90/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 469, in compute_quals. genomics_math.ptrue_to_bounded_phred(predictions[prediction_index]). File ""/tmp/Bazel.runfiles_in6znu90/runfiles/com_google_deepvariant/third_party/nucleus/util/genomics_math.py"", line 143, in ptrue_to_bounded_phred. raise ValueError('ptrue must be between zero and one: {}'.format(ptrue)). ValueError: ptrue must be between zero and one: nan. ```. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. I'm running this code on an H100 GPU running nvidia driver - `535.183.06` and CUDA version is `12.2`",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/901
https://github.com/google/deepvariant/issues/901:423,modifiability,version,version,423,"postprocess_variants step is erroring out in quickstart example; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. (A clear and concise description of what the issue is.). `run_deepvariant` is erroring out in the `postprocess_variants` step. **Setup**. - Operating system: Running inside docker image - `google/deepvariant:1.6.0-gpu`. - DeepVariant version: `1.6.0`. - Installation method (Docker, built from source, etc.): Docker image - `google/deepvariant:1.6.0-gpu`. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command: Running the quickstart cmd --. ```. /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/opt/deepvariant/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta --reads=/opt/deepvariant/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam --regions ""chr20:10,000,000-10,010,000"" --output_vcf=/opt/deepvariant/quickstart-output/output.vcf.gz --output_gvcf=/opt/deepvariant/quickstart-output/output.g.vcf.gz --intermediate_results_dir /opt/deepvariant/quickstart-output/intermediate_results_dir --num_shards=1 --verbosity=2. ```. - Error trace: (if applicable) In the `postprocess_variants` step. ```. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/opt/deepvariant/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --infile ""/opt/deepvariant/quickstart-output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --outfile ""/opt/deepvariant/quickstart-output/output.vcf.gz"" --cpus ""1"" --gvcf_outfile ""/opt/deepvariant/quickstart-output/output.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/opt/deepvariant/quickstart-output/intermediate_results_dir/gvcf.tfrecord@1.gz"". 2024-10-31 20:36:34.101345: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/901
https://github.com/google/deepvariant/issues/901:3303,modifiability,modul,module,3303," please make sure the missing libraries mentioned above are installed properly. 2024-10-31 20:36:35.010025: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2027] TensorFlow was not built with CUDA kernel binaries compatible with compute capability 9.0. CUDA kernels will be jit-compiled from PTX, which could take 30 minutes or longer. I1031 20:36:35.011695 132485076334400 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: NA12878. I1031 20:36:35.013445 132485076334400 postprocess_variants.py:1313] CVO sorting took 1.1885166168212891e-05 minutes. I1031 20:36:35.013573 132485076334400 postprocess_variants.py:1316] Transforming call_variants_output to variants. I1031 20:36:35.014770 132485076334400 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: NA12878. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_in6znu90/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1419, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_in6znu90/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_in6znu90/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_in6znu90/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1385, in main. tmp_variant_file = dump_variants_to_temp_file(variant_generator). File ""/tmp/Bazel.runfiles_in6znu90/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1067, in dump_variants_to_temp_file. tfrecord.write_tfrecords(variant_protos, temp.name). File ""/tmp/Bazel.runfiles_in6znu90/runfiles/com_google_deepvariant/third_party/nucleus/io/tfrecord.py"", line 190, in write_tfrecords. for proto in protos:. File ""/tmp/Bazel.runfiles_in6znu90/runfiles/com_google_deepvariant/deepvariant/haplotypes.py"", line 91, in maybe_resolve_conflicting_variants. for overlapping_candidates in _group_overlapping_variants(sorted_varia",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/901
https://github.com/google/deepvariant/issues/901:5925,modifiability,version,version,5925,"""/tmp/Bazel.runfiles_in6znu90/runfiles/com_google_deepvariant/third_party/nucleus/io/tfrecord.py"", line 190, in write_tfrecords. for proto in protos:. File ""/tmp/Bazel.runfiles_in6znu90/runfiles/com_google_deepvariant/deepvariant/haplotypes.py"", line 91, in maybe_resolve_conflicting_variants. for overlapping_candidates in _group_overlapping_variants(sorted_variants):. File ""/tmp/Bazel.runfiles_in6znu90/runfiles/com_google_deepvariant/deepvariant/haplotypes.py"", line 111, in _group_overlapping_variants. for variant in sorted_variants:. File ""/tmp/Bazel.runfiles_in6znu90/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1062, in _transform_call_variants_output_to_variants. yield _transform_call_variant_group_to_output_variant(**cvo_group_kwargs). File ""/tmp/Bazel.runfiles_in6znu90/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1036, in _transform_call_variant_group_to_output_variant. return add_call_to_variant(. File ""/tmp/Bazel.runfiles_in6znu90/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 434, in add_call_to_variant. gq, variant.quality = compute_quals(predictions, index). File ""/tmp/Bazel.runfiles_in6znu90/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 469, in compute_quals. genomics_math.ptrue_to_bounded_phred(predictions[prediction_index]). File ""/tmp/Bazel.runfiles_in6znu90/runfiles/com_google_deepvariant/third_party/nucleus/util/genomics_math.py"", line 143, in ptrue_to_bounded_phred. raise ValueError('ptrue must be between zero and one: {}'.format(ptrue)). ValueError: ptrue must be between zero and one: nan. ```. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. I'm running this code on an H100 GPU running nvidia driver - `535.183.06` and CUDA version is `12.2`",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/901
https://github.com/google/deepvariant/issues/901:29,performance,error,erroring,29,"postprocess_variants step is erroring out in quickstart example; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. (A clear and concise description of what the issue is.). `run_deepvariant` is erroring out in the `postprocess_variants` step. **Setup**. - Operating system: Running inside docker image - `google/deepvariant:1.6.0-gpu`. - DeepVariant version: `1.6.0`. - Installation method (Docker, built from source, etc.): Docker image - `google/deepvariant:1.6.0-gpu`. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command: Running the quickstart cmd --. ```. /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/opt/deepvariant/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta --reads=/opt/deepvariant/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam --regions ""chr20:10,000,000-10,010,000"" --output_vcf=/opt/deepvariant/quickstart-output/output.vcf.gz --output_gvcf=/opt/deepvariant/quickstart-output/output.g.vcf.gz --intermediate_results_dir /opt/deepvariant/quickstart-output/intermediate_results_dir --num_shards=1 --verbosity=2. ```. - Error trace: (if applicable) In the `postprocess_variants` step. ```. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/opt/deepvariant/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --infile ""/opt/deepvariant/quickstart-output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --outfile ""/opt/deepvariant/quickstart-output/output.vcf.gz"" --cpus ""1"" --gvcf_outfile ""/opt/deepvariant/quickstart-output/output.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/opt/deepvariant/quickstart-output/intermediate_results_dir/gvcf.tfrecord@1.gz"". 2024-10-31 20:36:34.101345: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/901
https://github.com/google/deepvariant/issues/901:267,performance,error,erroring,267,"postprocess_variants step is erroring out in quickstart example; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. (A clear and concise description of what the issue is.). `run_deepvariant` is erroring out in the `postprocess_variants` step. **Setup**. - Operating system: Running inside docker image - `google/deepvariant:1.6.0-gpu`. - DeepVariant version: `1.6.0`. - Installation method (Docker, built from source, etc.): Docker image - `google/deepvariant:1.6.0-gpu`. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command: Running the quickstart cmd --. ```. /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/opt/deepvariant/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta --reads=/opt/deepvariant/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam --regions ""chr20:10,000,000-10,010,000"" --output_vcf=/opt/deepvariant/quickstart-output/output.vcf.gz --output_gvcf=/opt/deepvariant/quickstart-output/output.g.vcf.gz --intermediate_results_dir /opt/deepvariant/quickstart-output/intermediate_results_dir --num_shards=1 --verbosity=2. ```. - Error trace: (if applicable) In the `postprocess_variants` step. ```. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/opt/deepvariant/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --infile ""/opt/deepvariant/quickstart-output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --outfile ""/opt/deepvariant/quickstart-output/output.vcf.gz"" --cpus ""1"" --gvcf_outfile ""/opt/deepvariant/quickstart-output/output.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/opt/deepvariant/quickstart-output/intermediate_results_dir/gvcf.tfrecord@1.gz"". 2024-10-31 20:36:34.101345: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/901
https://github.com/google/deepvariant/issues/901:403,performance,gpu,gpu,403,"postprocess_variants step is erroring out in quickstart example; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. (A clear and concise description of what the issue is.). `run_deepvariant` is erroring out in the `postprocess_variants` step. **Setup**. - Operating system: Running inside docker image - `google/deepvariant:1.6.0-gpu`. - DeepVariant version: `1.6.0`. - Installation method (Docker, built from source, etc.): Docker image - `google/deepvariant:1.6.0-gpu`. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command: Running the quickstart cmd --. ```. /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/opt/deepvariant/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta --reads=/opt/deepvariant/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam --regions ""chr20:10,000,000-10,010,000"" --output_vcf=/opt/deepvariant/quickstart-output/output.vcf.gz --output_gvcf=/opt/deepvariant/quickstart-output/output.g.vcf.gz --intermediate_results_dir /opt/deepvariant/quickstart-output/intermediate_results_dir --num_shards=1 --verbosity=2. ```. - Error trace: (if applicable) In the `postprocess_variants` step. ```. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/opt/deepvariant/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --infile ""/opt/deepvariant/quickstart-output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --outfile ""/opt/deepvariant/quickstart-output/output.vcf.gz"" --cpus ""1"" --gvcf_outfile ""/opt/deepvariant/quickstart-output/output.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/opt/deepvariant/quickstart-output/intermediate_results_dir/gvcf.tfrecord@1.gz"". 2024-10-31 20:36:34.101345: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/901
https://github.com/google/deepvariant/issues/901:539,performance,gpu,gpu,539,"postprocess_variants step is erroring out in quickstart example; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. (A clear and concise description of what the issue is.). `run_deepvariant` is erroring out in the `postprocess_variants` step. **Setup**. - Operating system: Running inside docker image - `google/deepvariant:1.6.0-gpu`. - DeepVariant version: `1.6.0`. - Installation method (Docker, built from source, etc.): Docker image - `google/deepvariant:1.6.0-gpu`. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command: Running the quickstart cmd --. ```. /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/opt/deepvariant/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta --reads=/opt/deepvariant/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam --regions ""chr20:10,000,000-10,010,000"" --output_vcf=/opt/deepvariant/quickstart-output/output.vcf.gz --output_gvcf=/opt/deepvariant/quickstart-output/output.g.vcf.gz --intermediate_results_dir /opt/deepvariant/quickstart-output/intermediate_results_dir --num_shards=1 --verbosity=2. ```. - Error trace: (if applicable) In the `postprocess_variants` step. ```. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/opt/deepvariant/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --infile ""/opt/deepvariant/quickstart-output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --outfile ""/opt/deepvariant/quickstart-output/output.vcf.gz"" --cpus ""1"" --gvcf_outfile ""/opt/deepvariant/quickstart-output/output.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/opt/deepvariant/quickstart-output/intermediate_results_dir/gvcf.tfrecord@1.gz"". 2024-10-31 20:36:34.101345: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/901
https://github.com/google/deepvariant/issues/901:1222,performance,Error,Error,1222,"what the issue is.). `run_deepvariant` is erroring out in the `postprocess_variants` step. **Setup**. - Operating system: Running inside docker image - `google/deepvariant:1.6.0-gpu`. - DeepVariant version: `1.6.0`. - Installation method (Docker, built from source, etc.): Docker image - `google/deepvariant:1.6.0-gpu`. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command: Running the quickstart cmd --. ```. /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/opt/deepvariant/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta --reads=/opt/deepvariant/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam --regions ""chr20:10,000,000-10,010,000"" --output_vcf=/opt/deepvariant/quickstart-output/output.vcf.gz --output_gvcf=/opt/deepvariant/quickstart-output/output.g.vcf.gz --intermediate_results_dir /opt/deepvariant/quickstart-output/intermediate_results_dir --num_shards=1 --verbosity=2. ```. - Error trace: (if applicable) In the `postprocess_variants` step. ```. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/opt/deepvariant/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --infile ""/opt/deepvariant/quickstart-output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --outfile ""/opt/deepvariant/quickstart-output/output.vcf.gz"" --cpus ""1"" --gvcf_outfile ""/opt/deepvariant/quickstart-output/output.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/opt/deepvariant/quickstart-output/intermediate_results_dir/gvcf.tfrecord@1.gz"". 2024-10-31 20:36:34.101345: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64. 2024-10-31 20:36:34.101375: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot d",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/901
https://github.com/google/deepvariant/issues/901:1325,performance,time,time,1325,"- Operating system: Running inside docker image - `google/deepvariant:1.6.0-gpu`. - DeepVariant version: `1.6.0`. - Installation method (Docker, built from source, etc.): Docker image - `google/deepvariant:1.6.0-gpu`. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command: Running the quickstart cmd --. ```. /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/opt/deepvariant/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta --reads=/opt/deepvariant/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam --regions ""chr20:10,000,000-10,010,000"" --output_vcf=/opt/deepvariant/quickstart-output/output.vcf.gz --output_gvcf=/opt/deepvariant/quickstart-output/output.g.vcf.gz --intermediate_results_dir /opt/deepvariant/quickstart-output/intermediate_results_dir --num_shards=1 --verbosity=2. ```. - Error trace: (if applicable) In the `postprocess_variants` step. ```. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/opt/deepvariant/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --infile ""/opt/deepvariant/quickstart-output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --outfile ""/opt/deepvariant/quickstart-output/output.vcf.gz"" --cpus ""1"" --gvcf_outfile ""/opt/deepvariant/quickstart-output/output.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/opt/deepvariant/quickstart-output/intermediate_results_dir/gvcf.tfrecord@1.gz"". 2024-10-31 20:36:34.101345: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64. 2024-10-31 20:36:34.101375: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/901
https://github.com/google/deepvariant/issues/901:1615,performance,cpu,cpus,1615,"al that is unlike the case studies?). **Steps to reproduce:**. - Command: Running the quickstart cmd --. ```. /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/opt/deepvariant/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta --reads=/opt/deepvariant/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam --regions ""chr20:10,000,000-10,010,000"" --output_vcf=/opt/deepvariant/quickstart-output/output.vcf.gz --output_gvcf=/opt/deepvariant/quickstart-output/output.g.vcf.gz --intermediate_results_dir /opt/deepvariant/quickstart-output/intermediate_results_dir --num_shards=1 --verbosity=2. ```. - Error trace: (if applicable) In the `postprocess_variants` step. ```. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/opt/deepvariant/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --infile ""/opt/deepvariant/quickstart-output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --outfile ""/opt/deepvariant/quickstart-output/output.vcf.gz"" --cpus ""1"" --gvcf_outfile ""/opt/deepvariant/quickstart-output/output.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/opt/deepvariant/quickstart-output/intermediate_results_dir/gvcf.tfrecord@1.gz"". 2024-10-31 20:36:34.101345: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64. 2024-10-31 20:36:34.101375: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-10-31 20:36:35.010025: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2027] TensorFlow was not built with CUDA kernel binaries compatible with compute capability 9.0. CUDA kernels will be jit-compiled from PTX, which could",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/901
https://github.com/google/deepvariant/issues/901:1921,performance,load,load,1921,"1mb.bam --regions ""chr20:10,000,000-10,010,000"" --output_vcf=/opt/deepvariant/quickstart-output/output.vcf.gz --output_gvcf=/opt/deepvariant/quickstart-output/output.g.vcf.gz --intermediate_results_dir /opt/deepvariant/quickstart-output/intermediate_results_dir --num_shards=1 --verbosity=2. ```. - Error trace: (if applicable) In the `postprocess_variants` step. ```. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/opt/deepvariant/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --infile ""/opt/deepvariant/quickstart-output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --outfile ""/opt/deepvariant/quickstart-output/output.vcf.gz"" --cpus ""1"" --gvcf_outfile ""/opt/deepvariant/quickstart-output/output.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/opt/deepvariant/quickstart-output/intermediate_results_dir/gvcf.tfrecord@1.gz"". 2024-10-31 20:36:34.101345: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64. 2024-10-31 20:36:34.101375: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-10-31 20:36:35.010025: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2027] TensorFlow was not built with CUDA kernel binaries compatible with compute capability 9.0. CUDA kernels will be jit-compiled from PTX, which could take 30 minutes or longer. I1031 20:36:35.011695 132485076334400 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: NA12878. I1031 20:36:35.013445 132485076334400 postprocess_variants.py:1313] CVO sorting took 1.1885166168212891e-05 minutes. I1031 20:36:35.013573 1324",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/901
https://github.com/google/deepvariant/issues/901:2288,performance,GPU,GPU,2288,". ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/opt/deepvariant/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --infile ""/opt/deepvariant/quickstart-output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --outfile ""/opt/deepvariant/quickstart-output/output.vcf.gz"" --cpus ""1"" --gvcf_outfile ""/opt/deepvariant/quickstart-output/output.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/opt/deepvariant/quickstart-output/intermediate_results_dir/gvcf.tfrecord@1.gz"". 2024-10-31 20:36:34.101345: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64. 2024-10-31 20:36:34.101375: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-10-31 20:36:35.010025: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2027] TensorFlow was not built with CUDA kernel binaries compatible with compute capability 9.0. CUDA kernels will be jit-compiled from PTX, which could take 30 minutes or longer. I1031 20:36:35.011695 132485076334400 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: NA12878. I1031 20:36:35.013445 132485076334400 postprocess_variants.py:1313] CVO sorting took 1.1885166168212891e-05 minutes. I1031 20:36:35.013573 132485076334400 postprocess_variants.py:1316] Transforming call_variants_output to variants. I1031 20:36:35.014770 132485076334400 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: NA12878. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_in6znu90/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", li",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/901
https://github.com/google/deepvariant/issues/901:2447,performance,gpu,gpu,2447,"-infile ""/opt/deepvariant/quickstart-output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --outfile ""/opt/deepvariant/quickstart-output/output.vcf.gz"" --cpus ""1"" --gvcf_outfile ""/opt/deepvariant/quickstart-output/output.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/opt/deepvariant/quickstart-output/intermediate_results_dir/gvcf.tfrecord@1.gz"". 2024-10-31 20:36:34.101345: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64. 2024-10-31 20:36:34.101375: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-10-31 20:36:35.010025: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2027] TensorFlow was not built with CUDA kernel binaries compatible with compute capability 9.0. CUDA kernels will be jit-compiled from PTX, which could take 30 minutes or longer. I1031 20:36:35.011695 132485076334400 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: NA12878. I1031 20:36:35.013445 132485076334400 postprocess_variants.py:1313] CVO sorting took 1.1885166168212891e-05 minutes. I1031 20:36:35.013573 132485076334400 postprocess_variants.py:1316] Transforming call_variants_output to variants. I1031 20:36:35.014770 132485076334400 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: NA12878. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_in6znu90/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1419, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_in6znu90/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Baze",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/901
https://github.com/google/deepvariant/issues/901:5875,performance,GPU,GPU,5875,"""/tmp/Bazel.runfiles_in6znu90/runfiles/com_google_deepvariant/third_party/nucleus/io/tfrecord.py"", line 190, in write_tfrecords. for proto in protos:. File ""/tmp/Bazel.runfiles_in6znu90/runfiles/com_google_deepvariant/deepvariant/haplotypes.py"", line 91, in maybe_resolve_conflicting_variants. for overlapping_candidates in _group_overlapping_variants(sorted_variants):. File ""/tmp/Bazel.runfiles_in6znu90/runfiles/com_google_deepvariant/deepvariant/haplotypes.py"", line 111, in _group_overlapping_variants. for variant in sorted_variants:. File ""/tmp/Bazel.runfiles_in6znu90/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1062, in _transform_call_variants_output_to_variants. yield _transform_call_variant_group_to_output_variant(**cvo_group_kwargs). File ""/tmp/Bazel.runfiles_in6znu90/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1036, in _transform_call_variant_group_to_output_variant. return add_call_to_variant(. File ""/tmp/Bazel.runfiles_in6znu90/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 434, in add_call_to_variant. gq, variant.quality = compute_quals(predictions, index). File ""/tmp/Bazel.runfiles_in6znu90/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 469, in compute_quals. genomics_math.ptrue_to_bounded_phred(predictions[prediction_index]). File ""/tmp/Bazel.runfiles_in6znu90/runfiles/com_google_deepvariant/third_party/nucleus/util/genomics_math.py"", line 143, in ptrue_to_bounded_phred. raise ValueError('ptrue must be between zero and one: {}'.format(ptrue)). ValueError: ptrue must be between zero and one: nan. ```. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. I'm running this code on an H100 GPU running nvidia driver - `535.183.06` and CUDA version is `12.2`",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/901
https://github.com/google/deepvariant/issues/901:5599,reliability,Doe,Does,5599,"""/tmp/Bazel.runfiles_in6znu90/runfiles/com_google_deepvariant/third_party/nucleus/io/tfrecord.py"", line 190, in write_tfrecords. for proto in protos:. File ""/tmp/Bazel.runfiles_in6znu90/runfiles/com_google_deepvariant/deepvariant/haplotypes.py"", line 91, in maybe_resolve_conflicting_variants. for overlapping_candidates in _group_overlapping_variants(sorted_variants):. File ""/tmp/Bazel.runfiles_in6znu90/runfiles/com_google_deepvariant/deepvariant/haplotypes.py"", line 111, in _group_overlapping_variants. for variant in sorted_variants:. File ""/tmp/Bazel.runfiles_in6znu90/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1062, in _transform_call_variants_output_to_variants. yield _transform_call_variant_group_to_output_variant(**cvo_group_kwargs). File ""/tmp/Bazel.runfiles_in6znu90/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1036, in _transform_call_variant_group_to_output_variant. return add_call_to_variant(. File ""/tmp/Bazel.runfiles_in6znu90/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 434, in add_call_to_variant. gq, variant.quality = compute_quals(predictions, index). File ""/tmp/Bazel.runfiles_in6znu90/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 469, in compute_quals. genomics_math.ptrue_to_bounded_phred(predictions[prediction_index]). File ""/tmp/Bazel.runfiles_in6znu90/runfiles/com_google_deepvariant/third_party/nucleus/util/genomics_math.py"", line 143, in ptrue_to_bounded_phred. raise ValueError('ptrue must be between zero and one: {}'.format(ptrue)). ValueError: ptrue must be between zero and one: nan. ```. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. I'm running this code on an H100 GPU running nvidia driver - `535.183.06` and CUDA version is `12.2`",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/901
https://github.com/google/deepvariant/issues/901:29,safety,error,erroring,29,"postprocess_variants step is erroring out in quickstart example; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. (A clear and concise description of what the issue is.). `run_deepvariant` is erroring out in the `postprocess_variants` step. **Setup**. - Operating system: Running inside docker image - `google/deepvariant:1.6.0-gpu`. - DeepVariant version: `1.6.0`. - Installation method (Docker, built from source, etc.): Docker image - `google/deepvariant:1.6.0-gpu`. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command: Running the quickstart cmd --. ```. /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/opt/deepvariant/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta --reads=/opt/deepvariant/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam --regions ""chr20:10,000,000-10,010,000"" --output_vcf=/opt/deepvariant/quickstart-output/output.vcf.gz --output_gvcf=/opt/deepvariant/quickstart-output/output.g.vcf.gz --intermediate_results_dir /opt/deepvariant/quickstart-output/intermediate_results_dir --num_shards=1 --verbosity=2. ```. - Error trace: (if applicable) In the `postprocess_variants` step. ```. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/opt/deepvariant/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --infile ""/opt/deepvariant/quickstart-output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --outfile ""/opt/deepvariant/quickstart-output/output.vcf.gz"" --cpus ""1"" --gvcf_outfile ""/opt/deepvariant/quickstart-output/output.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/opt/deepvariant/quickstart-output/intermediate_results_dir/gvcf.tfrecord@1.gz"". 2024-10-31 20:36:34.101345: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/901
https://github.com/google/deepvariant/issues/901:267,safety,error,erroring,267,"postprocess_variants step is erroring out in quickstart example; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. (A clear and concise description of what the issue is.). `run_deepvariant` is erroring out in the `postprocess_variants` step. **Setup**. - Operating system: Running inside docker image - `google/deepvariant:1.6.0-gpu`. - DeepVariant version: `1.6.0`. - Installation method (Docker, built from source, etc.): Docker image - `google/deepvariant:1.6.0-gpu`. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command: Running the quickstart cmd --. ```. /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/opt/deepvariant/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta --reads=/opt/deepvariant/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam --regions ""chr20:10,000,000-10,010,000"" --output_vcf=/opt/deepvariant/quickstart-output/output.vcf.gz --output_gvcf=/opt/deepvariant/quickstart-output/output.g.vcf.gz --intermediate_results_dir /opt/deepvariant/quickstart-output/intermediate_results_dir --num_shards=1 --verbosity=2. ```. - Error trace: (if applicable) In the `postprocess_variants` step. ```. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/opt/deepvariant/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --infile ""/opt/deepvariant/quickstart-output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --outfile ""/opt/deepvariant/quickstart-output/output.vcf.gz"" --cpus ""1"" --gvcf_outfile ""/opt/deepvariant/quickstart-output/output.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/opt/deepvariant/quickstart-output/intermediate_results_dir/gvcf.tfrecord@1.gz"". 2024-10-31 20:36:34.101345: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/901
https://github.com/google/deepvariant/issues/901:815,safety,test,testdata,815,"postprocess_variants step is erroring out in quickstart example; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. (A clear and concise description of what the issue is.). `run_deepvariant` is erroring out in the `postprocess_variants` step. **Setup**. - Operating system: Running inside docker image - `google/deepvariant:1.6.0-gpu`. - DeepVariant version: `1.6.0`. - Installation method (Docker, built from source, etc.): Docker image - `google/deepvariant:1.6.0-gpu`. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command: Running the quickstart cmd --. ```. /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/opt/deepvariant/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta --reads=/opt/deepvariant/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam --regions ""chr20:10,000,000-10,010,000"" --output_vcf=/opt/deepvariant/quickstart-output/output.vcf.gz --output_gvcf=/opt/deepvariant/quickstart-output/output.g.vcf.gz --intermediate_results_dir /opt/deepvariant/quickstart-output/intermediate_results_dir --num_shards=1 --verbosity=2. ```. - Error trace: (if applicable) In the `postprocess_variants` step. ```. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/opt/deepvariant/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --infile ""/opt/deepvariant/quickstart-output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --outfile ""/opt/deepvariant/quickstart-output/output.vcf.gz"" --cpus ""1"" --gvcf_outfile ""/opt/deepvariant/quickstart-output/output.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/opt/deepvariant/quickstart-output/intermediate_results_dir/gvcf.tfrecord@1.gz"". 2024-10-31 20:36:34.101345: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/901
https://github.com/google/deepvariant/issues/901:891,safety,test,testdata,891,"postprocess_variants step is erroring out in quickstart example; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. (A clear and concise description of what the issue is.). `run_deepvariant` is erroring out in the `postprocess_variants` step. **Setup**. - Operating system: Running inside docker image - `google/deepvariant:1.6.0-gpu`. - DeepVariant version: `1.6.0`. - Installation method (Docker, built from source, etc.): Docker image - `google/deepvariant:1.6.0-gpu`. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command: Running the quickstart cmd --. ```. /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/opt/deepvariant/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta --reads=/opt/deepvariant/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam --regions ""chr20:10,000,000-10,010,000"" --output_vcf=/opt/deepvariant/quickstart-output/output.vcf.gz --output_gvcf=/opt/deepvariant/quickstart-output/output.g.vcf.gz --intermediate_results_dir /opt/deepvariant/quickstart-output/intermediate_results_dir --num_shards=1 --verbosity=2. ```. - Error trace: (if applicable) In the `postprocess_variants` step. ```. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/opt/deepvariant/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --infile ""/opt/deepvariant/quickstart-output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --outfile ""/opt/deepvariant/quickstart-output/output.vcf.gz"" --cpus ""1"" --gvcf_outfile ""/opt/deepvariant/quickstart-output/output.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/opt/deepvariant/quickstart-output/intermediate_results_dir/gvcf.tfrecord@1.gz"". 2024-10-31 20:36:34.101345: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/901
https://github.com/google/deepvariant/issues/901:1222,safety,Error,Error,1222,"what the issue is.). `run_deepvariant` is erroring out in the `postprocess_variants` step. **Setup**. - Operating system: Running inside docker image - `google/deepvariant:1.6.0-gpu`. - DeepVariant version: `1.6.0`. - Installation method (Docker, built from source, etc.): Docker image - `google/deepvariant:1.6.0-gpu`. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command: Running the quickstart cmd --. ```. /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/opt/deepvariant/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta --reads=/opt/deepvariant/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam --regions ""chr20:10,000,000-10,010,000"" --output_vcf=/opt/deepvariant/quickstart-output/output.vcf.gz --output_gvcf=/opt/deepvariant/quickstart-output/output.g.vcf.gz --intermediate_results_dir /opt/deepvariant/quickstart-output/intermediate_results_dir --num_shards=1 --verbosity=2. ```. - Error trace: (if applicable) In the `postprocess_variants` step. ```. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/opt/deepvariant/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --infile ""/opt/deepvariant/quickstart-output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --outfile ""/opt/deepvariant/quickstart-output/output.vcf.gz"" --cpus ""1"" --gvcf_outfile ""/opt/deepvariant/quickstart-output/output.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/opt/deepvariant/quickstart-output/intermediate_results_dir/gvcf.tfrecord@1.gz"". 2024-10-31 20:36:34.101345: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64. 2024-10-31 20:36:34.101375: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot d",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/901
https://github.com/google/deepvariant/issues/901:1407,safety,test,testdata,1407,"DeepVariant version: `1.6.0`. - Installation method (Docker, built from source, etc.): Docker image - `google/deepvariant:1.6.0-gpu`. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command: Running the quickstart cmd --. ```. /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/opt/deepvariant/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta --reads=/opt/deepvariant/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam --regions ""chr20:10,000,000-10,010,000"" --output_vcf=/opt/deepvariant/quickstart-output/output.vcf.gz --output_gvcf=/opt/deepvariant/quickstart-output/output.g.vcf.gz --intermediate_results_dir /opt/deepvariant/quickstart-output/intermediate_results_dir --num_shards=1 --verbosity=2. ```. - Error trace: (if applicable) In the `postprocess_variants` step. ```. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/opt/deepvariant/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --infile ""/opt/deepvariant/quickstart-output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --outfile ""/opt/deepvariant/quickstart-output/output.vcf.gz"" --cpus ""1"" --gvcf_outfile ""/opt/deepvariant/quickstart-output/output.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/opt/deepvariant/quickstart-output/intermediate_results_dir/gvcf.tfrecord@1.gz"". 2024-10-31 20:36:34.101345: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64. 2024-10-31 20:36:34.101375: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-10-31 20:36:35.01002",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/901
https://github.com/google/deepvariant/issues/901:3303,safety,modul,module,3303," please make sure the missing libraries mentioned above are installed properly. 2024-10-31 20:36:35.010025: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2027] TensorFlow was not built with CUDA kernel binaries compatible with compute capability 9.0. CUDA kernels will be jit-compiled from PTX, which could take 30 minutes or longer. I1031 20:36:35.011695 132485076334400 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: NA12878. I1031 20:36:35.013445 132485076334400 postprocess_variants.py:1313] CVO sorting took 1.1885166168212891e-05 minutes. I1031 20:36:35.013573 132485076334400 postprocess_variants.py:1316] Transforming call_variants_output to variants. I1031 20:36:35.014770 132485076334400 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: NA12878. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_in6znu90/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1419, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_in6znu90/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_in6znu90/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_in6znu90/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1385, in main. tmp_variant_file = dump_variants_to_temp_file(variant_generator). File ""/tmp/Bazel.runfiles_in6znu90/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1067, in dump_variants_to_temp_file. tfrecord.write_tfrecords(variant_protos, temp.name). File ""/tmp/Bazel.runfiles_in6znu90/runfiles/com_google_deepvariant/third_party/nucleus/io/tfrecord.py"", line 190, in write_tfrecords. for proto in protos:. File ""/tmp/Bazel.runfiles_in6znu90/runfiles/com_google_deepvariant/deepvariant/haplotypes.py"", line 91, in maybe_resolve_conflicting_variants. for overlapping_candidates in _group_overlapping_variants(sorted_varia",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/901
https://github.com/google/deepvariant/issues/901:5094,safety,predict,predictions,5094,"""/tmp/Bazel.runfiles_in6znu90/runfiles/com_google_deepvariant/third_party/nucleus/io/tfrecord.py"", line 190, in write_tfrecords. for proto in protos:. File ""/tmp/Bazel.runfiles_in6znu90/runfiles/com_google_deepvariant/deepvariant/haplotypes.py"", line 91, in maybe_resolve_conflicting_variants. for overlapping_candidates in _group_overlapping_variants(sorted_variants):. File ""/tmp/Bazel.runfiles_in6znu90/runfiles/com_google_deepvariant/deepvariant/haplotypes.py"", line 111, in _group_overlapping_variants. for variant in sorted_variants:. File ""/tmp/Bazel.runfiles_in6znu90/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1062, in _transform_call_variants_output_to_variants. yield _transform_call_variant_group_to_output_variant(**cvo_group_kwargs). File ""/tmp/Bazel.runfiles_in6znu90/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1036, in _transform_call_variant_group_to_output_variant. return add_call_to_variant(. File ""/tmp/Bazel.runfiles_in6znu90/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 434, in add_call_to_variant. gq, variant.quality = compute_quals(predictions, index). File ""/tmp/Bazel.runfiles_in6znu90/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 469, in compute_quals. genomics_math.ptrue_to_bounded_phred(predictions[prediction_index]). File ""/tmp/Bazel.runfiles_in6znu90/runfiles/com_google_deepvariant/third_party/nucleus/util/genomics_math.py"", line 143, in ptrue_to_bounded_phred. raise ValueError('ptrue must be between zero and one: {}'.format(ptrue)). ValueError: ptrue must be between zero and one: nan. ```. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. I'm running this code on an H100 GPU running nvidia driver - `535.183.06` and CUDA version is `12.2`",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/901
https://github.com/google/deepvariant/issues/901:5285,safety,predict,predictions,5285,"""/tmp/Bazel.runfiles_in6znu90/runfiles/com_google_deepvariant/third_party/nucleus/io/tfrecord.py"", line 190, in write_tfrecords. for proto in protos:. File ""/tmp/Bazel.runfiles_in6znu90/runfiles/com_google_deepvariant/deepvariant/haplotypes.py"", line 91, in maybe_resolve_conflicting_variants. for overlapping_candidates in _group_overlapping_variants(sorted_variants):. File ""/tmp/Bazel.runfiles_in6znu90/runfiles/com_google_deepvariant/deepvariant/haplotypes.py"", line 111, in _group_overlapping_variants. for variant in sorted_variants:. File ""/tmp/Bazel.runfiles_in6znu90/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1062, in _transform_call_variants_output_to_variants. yield _transform_call_variant_group_to_output_variant(**cvo_group_kwargs). File ""/tmp/Bazel.runfiles_in6znu90/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1036, in _transform_call_variant_group_to_output_variant. return add_call_to_variant(. File ""/tmp/Bazel.runfiles_in6znu90/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 434, in add_call_to_variant. gq, variant.quality = compute_quals(predictions, index). File ""/tmp/Bazel.runfiles_in6znu90/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 469, in compute_quals. genomics_math.ptrue_to_bounded_phred(predictions[prediction_index]). File ""/tmp/Bazel.runfiles_in6znu90/runfiles/com_google_deepvariant/third_party/nucleus/util/genomics_math.py"", line 143, in ptrue_to_bounded_phred. raise ValueError('ptrue must be between zero and one: {}'.format(ptrue)). ValueError: ptrue must be between zero and one: nan. ```. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. I'm running this code on an H100 GPU running nvidia driver - `535.183.06` and CUDA version is `12.2`",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/901
https://github.com/google/deepvariant/issues/901:5620,safety,test,test,5620,"""/tmp/Bazel.runfiles_in6znu90/runfiles/com_google_deepvariant/third_party/nucleus/io/tfrecord.py"", line 190, in write_tfrecords. for proto in protos:. File ""/tmp/Bazel.runfiles_in6znu90/runfiles/com_google_deepvariant/deepvariant/haplotypes.py"", line 91, in maybe_resolve_conflicting_variants. for overlapping_candidates in _group_overlapping_variants(sorted_variants):. File ""/tmp/Bazel.runfiles_in6znu90/runfiles/com_google_deepvariant/deepvariant/haplotypes.py"", line 111, in _group_overlapping_variants. for variant in sorted_variants:. File ""/tmp/Bazel.runfiles_in6znu90/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1062, in _transform_call_variants_output_to_variants. yield _transform_call_variant_group_to_output_variant(**cvo_group_kwargs). File ""/tmp/Bazel.runfiles_in6znu90/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1036, in _transform_call_variant_group_to_output_variant. return add_call_to_variant(. File ""/tmp/Bazel.runfiles_in6znu90/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 434, in add_call_to_variant. gq, variant.quality = compute_quals(predictions, index). File ""/tmp/Bazel.runfiles_in6znu90/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 469, in compute_quals. genomics_math.ptrue_to_bounded_phred(predictions[prediction_index]). File ""/tmp/Bazel.runfiles_in6znu90/runfiles/com_google_deepvariant/third_party/nucleus/util/genomics_math.py"", line 143, in ptrue_to_bounded_phred. raise ValueError('ptrue must be between zero and one: {}'.format(ptrue)). ValueError: ptrue must be between zero and one: nan. ```. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. I'm running this code on an H100 GPU running nvidia driver - `535.183.06` and CUDA version is `12.2`",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/901
https://github.com/google/deepvariant/issues/901:5656,safety,test,test,5656,"""/tmp/Bazel.runfiles_in6znu90/runfiles/com_google_deepvariant/third_party/nucleus/io/tfrecord.py"", line 190, in write_tfrecords. for proto in protos:. File ""/tmp/Bazel.runfiles_in6znu90/runfiles/com_google_deepvariant/deepvariant/haplotypes.py"", line 91, in maybe_resolve_conflicting_variants. for overlapping_candidates in _group_overlapping_variants(sorted_variants):. File ""/tmp/Bazel.runfiles_in6znu90/runfiles/com_google_deepvariant/deepvariant/haplotypes.py"", line 111, in _group_overlapping_variants. for variant in sorted_variants:. File ""/tmp/Bazel.runfiles_in6znu90/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1062, in _transform_call_variants_output_to_variants. yield _transform_call_variant_group_to_output_variant(**cvo_group_kwargs). File ""/tmp/Bazel.runfiles_in6znu90/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1036, in _transform_call_variant_group_to_output_variant. return add_call_to_variant(. File ""/tmp/Bazel.runfiles_in6znu90/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 434, in add_call_to_variant. gq, variant.quality = compute_quals(predictions, index). File ""/tmp/Bazel.runfiles_in6znu90/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 469, in compute_quals. genomics_math.ptrue_to_bounded_phred(predictions[prediction_index]). File ""/tmp/Bazel.runfiles_in6znu90/runfiles/com_google_deepvariant/third_party/nucleus/util/genomics_math.py"", line 143, in ptrue_to_bounded_phred. raise ValueError('ptrue must be between zero and one: {}'.format(ptrue)). ValueError: ptrue must be between zero and one: nan. ```. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. I'm running this code on an H100 GPU running nvidia driver - `535.183.06` and CUDA version is `12.2`",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/901
https://github.com/google/deepvariant/issues/901:573,testability,instrument,instrument,573,"postprocess_variants step is erroring out in quickstart example; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. (A clear and concise description of what the issue is.). `run_deepvariant` is erroring out in the `postprocess_variants` step. **Setup**. - Operating system: Running inside docker image - `google/deepvariant:1.6.0-gpu`. - DeepVariant version: `1.6.0`. - Installation method (Docker, built from source, etc.): Docker image - `google/deepvariant:1.6.0-gpu`. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command: Running the quickstart cmd --. ```. /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/opt/deepvariant/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta --reads=/opt/deepvariant/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam --regions ""chr20:10,000,000-10,010,000"" --output_vcf=/opt/deepvariant/quickstart-output/output.vcf.gz --output_gvcf=/opt/deepvariant/quickstart-output/output.g.vcf.gz --intermediate_results_dir /opt/deepvariant/quickstart-output/intermediate_results_dir --num_shards=1 --verbosity=2. ```. - Error trace: (if applicable) In the `postprocess_variants` step. ```. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/opt/deepvariant/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --infile ""/opt/deepvariant/quickstart-output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --outfile ""/opt/deepvariant/quickstart-output/output.vcf.gz"" --cpus ""1"" --gvcf_outfile ""/opt/deepvariant/quickstart-output/output.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/opt/deepvariant/quickstart-output/intermediate_results_dir/gvcf.tfrecord@1.gz"". 2024-10-31 20:36:34.101345: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/901
https://github.com/google/deepvariant/issues/901:815,testability,test,testdata,815,"postprocess_variants step is erroring out in quickstart example; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. (A clear and concise description of what the issue is.). `run_deepvariant` is erroring out in the `postprocess_variants` step. **Setup**. - Operating system: Running inside docker image - `google/deepvariant:1.6.0-gpu`. - DeepVariant version: `1.6.0`. - Installation method (Docker, built from source, etc.): Docker image - `google/deepvariant:1.6.0-gpu`. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command: Running the quickstart cmd --. ```. /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/opt/deepvariant/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta --reads=/opt/deepvariant/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam --regions ""chr20:10,000,000-10,010,000"" --output_vcf=/opt/deepvariant/quickstart-output/output.vcf.gz --output_gvcf=/opt/deepvariant/quickstart-output/output.g.vcf.gz --intermediate_results_dir /opt/deepvariant/quickstart-output/intermediate_results_dir --num_shards=1 --verbosity=2. ```. - Error trace: (if applicable) In the `postprocess_variants` step. ```. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/opt/deepvariant/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --infile ""/opt/deepvariant/quickstart-output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --outfile ""/opt/deepvariant/quickstart-output/output.vcf.gz"" --cpus ""1"" --gvcf_outfile ""/opt/deepvariant/quickstart-output/output.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/opt/deepvariant/quickstart-output/intermediate_results_dir/gvcf.tfrecord@1.gz"". 2024-10-31 20:36:34.101345: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/901
https://github.com/google/deepvariant/issues/901:840,testability,unit,unittest,840,"postprocess_variants step is erroring out in quickstart example; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. (A clear and concise description of what the issue is.). `run_deepvariant` is erroring out in the `postprocess_variants` step. **Setup**. - Operating system: Running inside docker image - `google/deepvariant:1.6.0-gpu`. - DeepVariant version: `1.6.0`. - Installation method (Docker, built from source, etc.): Docker image - `google/deepvariant:1.6.0-gpu`. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command: Running the quickstart cmd --. ```. /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/opt/deepvariant/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta --reads=/opt/deepvariant/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam --regions ""chr20:10,000,000-10,010,000"" --output_vcf=/opt/deepvariant/quickstart-output/output.vcf.gz --output_gvcf=/opt/deepvariant/quickstart-output/output.g.vcf.gz --intermediate_results_dir /opt/deepvariant/quickstart-output/intermediate_results_dir --num_shards=1 --verbosity=2. ```. - Error trace: (if applicable) In the `postprocess_variants` step. ```. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/opt/deepvariant/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --infile ""/opt/deepvariant/quickstart-output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --outfile ""/opt/deepvariant/quickstart-output/output.vcf.gz"" --cpus ""1"" --gvcf_outfile ""/opt/deepvariant/quickstart-output/output.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/opt/deepvariant/quickstart-output/intermediate_results_dir/gvcf.tfrecord@1.gz"". 2024-10-31 20:36:34.101345: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/901
https://github.com/google/deepvariant/issues/901:891,testability,test,testdata,891,"postprocess_variants step is erroring out in quickstart example; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. (A clear and concise description of what the issue is.). `run_deepvariant` is erroring out in the `postprocess_variants` step. **Setup**. - Operating system: Running inside docker image - `google/deepvariant:1.6.0-gpu`. - DeepVariant version: `1.6.0`. - Installation method (Docker, built from source, etc.): Docker image - `google/deepvariant:1.6.0-gpu`. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command: Running the quickstart cmd --. ```. /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/opt/deepvariant/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta --reads=/opt/deepvariant/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam --regions ""chr20:10,000,000-10,010,000"" --output_vcf=/opt/deepvariant/quickstart-output/output.vcf.gz --output_gvcf=/opt/deepvariant/quickstart-output/output.g.vcf.gz --intermediate_results_dir /opt/deepvariant/quickstart-output/intermediate_results_dir --num_shards=1 --verbosity=2. ```. - Error trace: (if applicable) In the `postprocess_variants` step. ```. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/opt/deepvariant/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --infile ""/opt/deepvariant/quickstart-output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --outfile ""/opt/deepvariant/quickstart-output/output.vcf.gz"" --cpus ""1"" --gvcf_outfile ""/opt/deepvariant/quickstart-output/output.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/opt/deepvariant/quickstart-output/intermediate_results_dir/gvcf.tfrecord@1.gz"". 2024-10-31 20:36:34.101345: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/901
https://github.com/google/deepvariant/issues/901:1228,testability,trace,trace,1228,"he issue is.). `run_deepvariant` is erroring out in the `postprocess_variants` step. **Setup**. - Operating system: Running inside docker image - `google/deepvariant:1.6.0-gpu`. - DeepVariant version: `1.6.0`. - Installation method (Docker, built from source, etc.): Docker image - `google/deepvariant:1.6.0-gpu`. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command: Running the quickstart cmd --. ```. /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/opt/deepvariant/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta --reads=/opt/deepvariant/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam --regions ""chr20:10,000,000-10,010,000"" --output_vcf=/opt/deepvariant/quickstart-output/output.vcf.gz --output_gvcf=/opt/deepvariant/quickstart-output/output.g.vcf.gz --intermediate_results_dir /opt/deepvariant/quickstart-output/intermediate_results_dir --num_shards=1 --verbosity=2. ```. - Error trace: (if applicable) In the `postprocess_variants` step. ```. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/opt/deepvariant/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --infile ""/opt/deepvariant/quickstart-output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --outfile ""/opt/deepvariant/quickstart-output/output.vcf.gz"" --cpus ""1"" --gvcf_outfile ""/opt/deepvariant/quickstart-output/output.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/opt/deepvariant/quickstart-output/intermediate_results_dir/gvcf.tfrecord@1.gz"". 2024-10-31 20:36:34.101345: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64. 2024-10-31 20:36:34.101375: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/901
https://github.com/google/deepvariant/issues/901:1407,testability,test,testdata,1407,"DeepVariant version: `1.6.0`. - Installation method (Docker, built from source, etc.): Docker image - `google/deepvariant:1.6.0-gpu`. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command: Running the quickstart cmd --. ```. /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/opt/deepvariant/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta --reads=/opt/deepvariant/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam --regions ""chr20:10,000,000-10,010,000"" --output_vcf=/opt/deepvariant/quickstart-output/output.vcf.gz --output_gvcf=/opt/deepvariant/quickstart-output/output.g.vcf.gz --intermediate_results_dir /opt/deepvariant/quickstart-output/intermediate_results_dir --num_shards=1 --verbosity=2. ```. - Error trace: (if applicable) In the `postprocess_variants` step. ```. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/opt/deepvariant/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --infile ""/opt/deepvariant/quickstart-output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --outfile ""/opt/deepvariant/quickstart-output/output.vcf.gz"" --cpus ""1"" --gvcf_outfile ""/opt/deepvariant/quickstart-output/output.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/opt/deepvariant/quickstart-output/intermediate_results_dir/gvcf.tfrecord@1.gz"". 2024-10-31 20:36:34.101345: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64. 2024-10-31 20:36:34.101375: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-10-31 20:36:35.01002",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/901
https://github.com/google/deepvariant/issues/901:1432,testability,unit,unittest,1432,".0`. - Installation method (Docker, built from source, etc.): Docker image - `google/deepvariant:1.6.0-gpu`. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command: Running the quickstart cmd --. ```. /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/opt/deepvariant/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta --reads=/opt/deepvariant/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam --regions ""chr20:10,000,000-10,010,000"" --output_vcf=/opt/deepvariant/quickstart-output/output.vcf.gz --output_gvcf=/opt/deepvariant/quickstart-output/output.g.vcf.gz --intermediate_results_dir /opt/deepvariant/quickstart-output/intermediate_results_dir --num_shards=1 --verbosity=2. ```. - Error trace: (if applicable) In the `postprocess_variants` step. ```. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/opt/deepvariant/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --infile ""/opt/deepvariant/quickstart-output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --outfile ""/opt/deepvariant/quickstart-output/output.vcf.gz"" --cpus ""1"" --gvcf_outfile ""/opt/deepvariant/quickstart-output/output.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/opt/deepvariant/quickstart-output/intermediate_results_dir/gvcf.tfrecord@1.gz"". 2024-10-31 20:36:34.101345: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64. 2024-10-31 20:36:34.101375: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-10-31 20:36:35.010025: W tensorflow/core/comm",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/901
https://github.com/google/deepvariant/issues/901:3147,testability,Trace,Traceback,3147,"rflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 2024-10-31 20:36:35.010025: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2027] TensorFlow was not built with CUDA kernel binaries compatible with compute capability 9.0. CUDA kernels will be jit-compiled from PTX, which could take 30 minutes or longer. I1031 20:36:35.011695 132485076334400 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: NA12878. I1031 20:36:35.013445 132485076334400 postprocess_variants.py:1313] CVO sorting took 1.1885166168212891e-05 minutes. I1031 20:36:35.013573 132485076334400 postprocess_variants.py:1316] Transforming call_variants_output to variants. I1031 20:36:35.014770 132485076334400 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: NA12878. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_in6znu90/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1419, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_in6znu90/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_in6znu90/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_in6znu90/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1385, in main. tmp_variant_file = dump_variants_to_temp_file(variant_generator). File ""/tmp/Bazel.runfiles_in6znu90/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1067, in dump_variants_to_temp_file. tfrecord.write_tfrecords(variant_protos, temp.name). File ""/tmp/Bazel.runfiles_in6znu90/runfiles/com_google_deepvariant/third_party/nucleus/io/tfrecord.py"", line 190, in write_tfrecords. for proto in protos:. File ""/tmp/Bazel.runfiles_in6znu90/runfiles/com_google_deep",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/901
https://github.com/google/deepvariant/issues/901:5620,testability,test,test,5620,"""/tmp/Bazel.runfiles_in6znu90/runfiles/com_google_deepvariant/third_party/nucleus/io/tfrecord.py"", line 190, in write_tfrecords. for proto in protos:. File ""/tmp/Bazel.runfiles_in6znu90/runfiles/com_google_deepvariant/deepvariant/haplotypes.py"", line 91, in maybe_resolve_conflicting_variants. for overlapping_candidates in _group_overlapping_variants(sorted_variants):. File ""/tmp/Bazel.runfiles_in6znu90/runfiles/com_google_deepvariant/deepvariant/haplotypes.py"", line 111, in _group_overlapping_variants. for variant in sorted_variants:. File ""/tmp/Bazel.runfiles_in6znu90/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1062, in _transform_call_variants_output_to_variants. yield _transform_call_variant_group_to_output_variant(**cvo_group_kwargs). File ""/tmp/Bazel.runfiles_in6znu90/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1036, in _transform_call_variant_group_to_output_variant. return add_call_to_variant(. File ""/tmp/Bazel.runfiles_in6znu90/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 434, in add_call_to_variant. gq, variant.quality = compute_quals(predictions, index). File ""/tmp/Bazel.runfiles_in6znu90/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 469, in compute_quals. genomics_math.ptrue_to_bounded_phred(predictions[prediction_index]). File ""/tmp/Bazel.runfiles_in6znu90/runfiles/com_google_deepvariant/third_party/nucleus/util/genomics_math.py"", line 143, in ptrue_to_bounded_phred. raise ValueError('ptrue must be between zero and one: {}'.format(ptrue)). ValueError: ptrue must be between zero and one: nan. ```. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. I'm running this code on an H100 GPU running nvidia driver - `535.183.06` and CUDA version is `12.2`",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/901
https://github.com/google/deepvariant/issues/901:5656,testability,test,test,5656,"""/tmp/Bazel.runfiles_in6znu90/runfiles/com_google_deepvariant/third_party/nucleus/io/tfrecord.py"", line 190, in write_tfrecords. for proto in protos:. File ""/tmp/Bazel.runfiles_in6znu90/runfiles/com_google_deepvariant/deepvariant/haplotypes.py"", line 91, in maybe_resolve_conflicting_variants. for overlapping_candidates in _group_overlapping_variants(sorted_variants):. File ""/tmp/Bazel.runfiles_in6znu90/runfiles/com_google_deepvariant/deepvariant/haplotypes.py"", line 111, in _group_overlapping_variants. for variant in sorted_variants:. File ""/tmp/Bazel.runfiles_in6znu90/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1062, in _transform_call_variants_output_to_variants. yield _transform_call_variant_group_to_output_variant(**cvo_group_kwargs). File ""/tmp/Bazel.runfiles_in6znu90/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1036, in _transform_call_variant_group_to_output_variant. return add_call_to_variant(. File ""/tmp/Bazel.runfiles_in6znu90/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 434, in add_call_to_variant. gq, variant.quality = compute_quals(predictions, index). File ""/tmp/Bazel.runfiles_in6znu90/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 469, in compute_quals. genomics_math.ptrue_to_bounded_phred(predictions[prediction_index]). File ""/tmp/Bazel.runfiles_in6znu90/runfiles/com_google_deepvariant/third_party/nucleus/util/genomics_math.py"", line 143, in ptrue_to_bounded_phred. raise ValueError('ptrue must be between zero and one: {}'.format(ptrue)). ValueError: ptrue must be between zero and one: nan. ```. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. I'm running this code on an H100 GPU running nvidia driver - `535.183.06` and CUDA version is `12.2`",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/901
https://github.com/google/deepvariant/issues/901:5830,testability,context,context,5830,"""/tmp/Bazel.runfiles_in6znu90/runfiles/com_google_deepvariant/third_party/nucleus/io/tfrecord.py"", line 190, in write_tfrecords. for proto in protos:. File ""/tmp/Bazel.runfiles_in6znu90/runfiles/com_google_deepvariant/deepvariant/haplotypes.py"", line 91, in maybe_resolve_conflicting_variants. for overlapping_candidates in _group_overlapping_variants(sorted_variants):. File ""/tmp/Bazel.runfiles_in6znu90/runfiles/com_google_deepvariant/deepvariant/haplotypes.py"", line 111, in _group_overlapping_variants. for variant in sorted_variants:. File ""/tmp/Bazel.runfiles_in6znu90/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1062, in _transform_call_variants_output_to_variants. yield _transform_call_variant_group_to_output_variant(**cvo_group_kwargs). File ""/tmp/Bazel.runfiles_in6znu90/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1036, in _transform_call_variant_group_to_output_variant. return add_call_to_variant(. File ""/tmp/Bazel.runfiles_in6znu90/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 434, in add_call_to_variant. gq, variant.quality = compute_quals(predictions, index). File ""/tmp/Bazel.runfiles_in6znu90/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 469, in compute_quals. genomics_math.ptrue_to_bounded_phred(predictions[prediction_index]). File ""/tmp/Bazel.runfiles_in6znu90/runfiles/com_google_deepvariant/third_party/nucleus/util/genomics_math.py"", line 143, in ptrue_to_bounded_phred. raise ValueError('ptrue must be between zero and one: {}'.format(ptrue)). ValueError: ptrue must be between zero and one: nan. ```. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. I'm running this code on an H100 GPU running nvidia driver - `535.183.06` and CUDA version is `12.2`",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/901
https://github.com/google/deepvariant/issues/901:29,usability,error,erroring,29,"postprocess_variants step is erroring out in quickstart example; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. (A clear and concise description of what the issue is.). `run_deepvariant` is erroring out in the `postprocess_variants` step. **Setup**. - Operating system: Running inside docker image - `google/deepvariant:1.6.0-gpu`. - DeepVariant version: `1.6.0`. - Installation method (Docker, built from source, etc.): Docker image - `google/deepvariant:1.6.0-gpu`. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command: Running the quickstart cmd --. ```. /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/opt/deepvariant/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta --reads=/opt/deepvariant/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam --regions ""chr20:10,000,000-10,010,000"" --output_vcf=/opt/deepvariant/quickstart-output/output.vcf.gz --output_gvcf=/opt/deepvariant/quickstart-output/output.g.vcf.gz --intermediate_results_dir /opt/deepvariant/quickstart-output/intermediate_results_dir --num_shards=1 --verbosity=2. ```. - Error trace: (if applicable) In the `postprocess_variants` step. ```. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/opt/deepvariant/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --infile ""/opt/deepvariant/quickstart-output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --outfile ""/opt/deepvariant/quickstart-output/output.vcf.gz"" --cpus ""1"" --gvcf_outfile ""/opt/deepvariant/quickstart-output/output.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/opt/deepvariant/quickstart-output/intermediate_results_dir/gvcf.tfrecord@1.gz"". 2024-10-31 20:36:34.101345: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/901
https://github.com/google/deepvariant/issues/901:192,usability,clear,clear,192,"postprocess_variants step is erroring out in quickstart example; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. (A clear and concise description of what the issue is.). `run_deepvariant` is erroring out in the `postprocess_variants` step. **Setup**. - Operating system: Running inside docker image - `google/deepvariant:1.6.0-gpu`. - DeepVariant version: `1.6.0`. - Installation method (Docker, built from source, etc.): Docker image - `google/deepvariant:1.6.0-gpu`. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command: Running the quickstart cmd --. ```. /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/opt/deepvariant/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta --reads=/opt/deepvariant/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam --regions ""chr20:10,000,000-10,010,000"" --output_vcf=/opt/deepvariant/quickstart-output/output.vcf.gz --output_gvcf=/opt/deepvariant/quickstart-output/output.g.vcf.gz --intermediate_results_dir /opt/deepvariant/quickstart-output/intermediate_results_dir --num_shards=1 --verbosity=2. ```. - Error trace: (if applicable) In the `postprocess_variants` step. ```. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/opt/deepvariant/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --infile ""/opt/deepvariant/quickstart-output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --outfile ""/opt/deepvariant/quickstart-output/output.vcf.gz"" --cpus ""1"" --gvcf_outfile ""/opt/deepvariant/quickstart-output/output.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/opt/deepvariant/quickstart-output/intermediate_results_dir/gvcf.tfrecord@1.gz"". 2024-10-31 20:36:34.101345: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/901
https://github.com/google/deepvariant/issues/901:267,usability,error,erroring,267,"postprocess_variants step is erroring out in quickstart example; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. (A clear and concise description of what the issue is.). `run_deepvariant` is erroring out in the `postprocess_variants` step. **Setup**. - Operating system: Running inside docker image - `google/deepvariant:1.6.0-gpu`. - DeepVariant version: `1.6.0`. - Installation method (Docker, built from source, etc.): Docker image - `google/deepvariant:1.6.0-gpu`. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command: Running the quickstart cmd --. ```. /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/opt/deepvariant/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta --reads=/opt/deepvariant/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam --regions ""chr20:10,000,000-10,010,000"" --output_vcf=/opt/deepvariant/quickstart-output/output.vcf.gz --output_gvcf=/opt/deepvariant/quickstart-output/output.g.vcf.gz --intermediate_results_dir /opt/deepvariant/quickstart-output/intermediate_results_dir --num_shards=1 --verbosity=2. ```. - Error trace: (if applicable) In the `postprocess_variants` step. ```. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/opt/deepvariant/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --infile ""/opt/deepvariant/quickstart-output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --outfile ""/opt/deepvariant/quickstart-output/output.vcf.gz"" --cpus ""1"" --gvcf_outfile ""/opt/deepvariant/quickstart-output/output.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/opt/deepvariant/quickstart-output/intermediate_results_dir/gvcf.tfrecord@1.gz"". 2024-10-31 20:36:34.101345: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/901
https://github.com/google/deepvariant/issues/901:682,usability,Command,Command,682,"postprocess_variants step is erroring out in quickstart example; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. (A clear and concise description of what the issue is.). `run_deepvariant` is erroring out in the `postprocess_variants` step. **Setup**. - Operating system: Running inside docker image - `google/deepvariant:1.6.0-gpu`. - DeepVariant version: `1.6.0`. - Installation method (Docker, built from source, etc.): Docker image - `google/deepvariant:1.6.0-gpu`. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command: Running the quickstart cmd --. ```. /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/opt/deepvariant/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta --reads=/opt/deepvariant/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam --regions ""chr20:10,000,000-10,010,000"" --output_vcf=/opt/deepvariant/quickstart-output/output.vcf.gz --output_gvcf=/opt/deepvariant/quickstart-output/output.g.vcf.gz --intermediate_results_dir /opt/deepvariant/quickstart-output/intermediate_results_dir --num_shards=1 --verbosity=2. ```. - Error trace: (if applicable) In the `postprocess_variants` step. ```. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/opt/deepvariant/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --infile ""/opt/deepvariant/quickstart-output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --outfile ""/opt/deepvariant/quickstart-output/output.vcf.gz"" --cpus ""1"" --gvcf_outfile ""/opt/deepvariant/quickstart-output/output.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/opt/deepvariant/quickstart-output/intermediate_results_dir/gvcf.tfrecord@1.gz"". 2024-10-31 20:36:34.101345: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/901
https://github.com/google/deepvariant/issues/901:1222,usability,Error,Error,1222,"what the issue is.). `run_deepvariant` is erroring out in the `postprocess_variants` step. **Setup**. - Operating system: Running inside docker image - `google/deepvariant:1.6.0-gpu`. - DeepVariant version: `1.6.0`. - Installation method (Docker, built from source, etc.): Docker image - `google/deepvariant:1.6.0-gpu`. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command: Running the quickstart cmd --. ```. /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/opt/deepvariant/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta --reads=/opt/deepvariant/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam --regions ""chr20:10,000,000-10,010,000"" --output_vcf=/opt/deepvariant/quickstart-output/output.vcf.gz --output_gvcf=/opt/deepvariant/quickstart-output/output.g.vcf.gz --intermediate_results_dir /opt/deepvariant/quickstart-output/intermediate_results_dir --num_shards=1 --verbosity=2. ```. - Error trace: (if applicable) In the `postprocess_variants` step. ```. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/opt/deepvariant/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --infile ""/opt/deepvariant/quickstart-output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --outfile ""/opt/deepvariant/quickstart-output/output.vcf.gz"" --cpus ""1"" --gvcf_outfile ""/opt/deepvariant/quickstart-output/output.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/opt/deepvariant/quickstart-output/intermediate_results_dir/gvcf.tfrecord@1.gz"". 2024-10-31 20:36:34.101345: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64. 2024-10-31 20:36:34.101375: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot d",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/901
https://github.com/google/deepvariant/issues/901:1310,usability,command,command,1310,". **Setup**. - Operating system: Running inside docker image - `google/deepvariant:1.6.0-gpu`. - DeepVariant version: `1.6.0`. - Installation method (Docker, built from source, etc.): Docker image - `google/deepvariant:1.6.0-gpu`. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command: Running the quickstart cmd --. ```. /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/opt/deepvariant/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta --reads=/opt/deepvariant/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam --regions ""chr20:10,000,000-10,010,000"" --output_vcf=/opt/deepvariant/quickstart-output/output.vcf.gz --output_gvcf=/opt/deepvariant/quickstart-output/output.g.vcf.gz --intermediate_results_dir /opt/deepvariant/quickstart-output/intermediate_results_dir --num_shards=1 --verbosity=2. ```. - Error trace: (if applicable) In the `postprocess_variants` step. ```. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/opt/deepvariant/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --infile ""/opt/deepvariant/quickstart-output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --outfile ""/opt/deepvariant/quickstart-output/output.vcf.gz"" --cpus ""1"" --gvcf_outfile ""/opt/deepvariant/quickstart-output/output.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/opt/deepvariant/quickstart-output/intermediate_results_dir/gvcf.tfrecord@1.gz"". 2024-10-31 20:36:34.101345: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64. 2024-10-31 20:36:34.101375: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/901
https://github.com/google/deepvariant/issues/902:532,availability,error,error,532,"Unable to build docker image from source due to multiple reasons; I am trying to build the docker image of `deepvariant` but running into problems. I'm on `r1.7` branch and my branch is up to date. I am also facing the same issues on `r1.6.1` branch as well. The command I am using is the following -. ```. docker build --build-arg=FROM_IMAGE=nvidia/cuda:11.8.0-cudnn8-devel-ubuntu22.04 \. --build-arg=DV_GPU_BUILD=1 \. -t deepvariant_gpu . ```. I am building this docker image on my laptop (M3 macbook). #### PackagesNotFoundError error. The first error I get is -. ```. 1.247 Platform: linux-aarch64. 1.247 Collecting package metadata (repodata.json): ...working... done. 6.190 Solving environment: ...working... failed. 6.260. 6.260 PackagesNotFoundError: The following packages are not available from current channels:. 6.260. 6.260 - bioconda::samtools==1.15. 6.260 - bioconda::bcftools==1.15. 6.260. ```. I resolved this error by removing the version numbers. i.e., removed the `==1.15` from both the lines. #### Error in the build-prerunreq.sh script. Once, I cross the previous error, I get this error -. ```. > [builder 6/6] RUN ./build-prereq.sh && PATH=""${HOME}/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin"" ./build_release_binaries.sh # PATH for bazel:. 0.101 ========== This script is only maintained for Ubuntu 22.04. 0.101 ========== Load config settings. 0.103 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Install the runtime packages' starting. 0.104 ========== This script is only maintained for Ubuntu 22.04. 0.104 ========== Load config settings. 0.105 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Misc setup' starting. 1.955 W: GPG error: https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease' is not signed. 1.955 W: GPG e",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/902
https://github.com/google/deepvariant/issues/902:549,availability,error,error,549,"Unable to build docker image from source due to multiple reasons; I am trying to build the docker image of `deepvariant` but running into problems. I'm on `r1.7` branch and my branch is up to date. I am also facing the same issues on `r1.6.1` branch as well. The command I am using is the following -. ```. docker build --build-arg=FROM_IMAGE=nvidia/cuda:11.8.0-cudnn8-devel-ubuntu22.04 \. --build-arg=DV_GPU_BUILD=1 \. -t deepvariant_gpu . ```. I am building this docker image on my laptop (M3 macbook). #### PackagesNotFoundError error. The first error I get is -. ```. 1.247 Platform: linux-aarch64. 1.247 Collecting package metadata (repodata.json): ...working... done. 6.190 Solving environment: ...working... failed. 6.260. 6.260 PackagesNotFoundError: The following packages are not available from current channels:. 6.260. 6.260 - bioconda::samtools==1.15. 6.260 - bioconda::bcftools==1.15. 6.260. ```. I resolved this error by removing the version numbers. i.e., removed the `==1.15` from both the lines. #### Error in the build-prerunreq.sh script. Once, I cross the previous error, I get this error -. ```. > [builder 6/6] RUN ./build-prereq.sh && PATH=""${HOME}/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin"" ./build_release_binaries.sh # PATH for bazel:. 0.101 ========== This script is only maintained for Ubuntu 22.04. 0.101 ========== Load config settings. 0.103 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Install the runtime packages' starting. 0.104 ========== This script is only maintained for Ubuntu 22.04. 0.104 ========== Load config settings. 0.105 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Misc setup' starting. 1.955 W: GPG error: https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease' is not signed. 1.955 W: GPG e",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/902
https://github.com/google/deepvariant/issues/902:790,availability,avail,available,790,"Unable to build docker image from source due to multiple reasons; I am trying to build the docker image of `deepvariant` but running into problems. I'm on `r1.7` branch and my branch is up to date. I am also facing the same issues on `r1.6.1` branch as well. The command I am using is the following -. ```. docker build --build-arg=FROM_IMAGE=nvidia/cuda:11.8.0-cudnn8-devel-ubuntu22.04 \. --build-arg=DV_GPU_BUILD=1 \. -t deepvariant_gpu . ```. I am building this docker image on my laptop (M3 macbook). #### PackagesNotFoundError error. The first error I get is -. ```. 1.247 Platform: linux-aarch64. 1.247 Collecting package metadata (repodata.json): ...working... done. 6.190 Solving environment: ...working... failed. 6.260. 6.260 PackagesNotFoundError: The following packages are not available from current channels:. 6.260. 6.260 - bioconda::samtools==1.15. 6.260 - bioconda::bcftools==1.15. 6.260. ```. I resolved this error by removing the version numbers. i.e., removed the `==1.15` from both the lines. #### Error in the build-prerunreq.sh script. Once, I cross the previous error, I get this error -. ```. > [builder 6/6] RUN ./build-prereq.sh && PATH=""${HOME}/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin"" ./build_release_binaries.sh # PATH for bazel:. 0.101 ========== This script is only maintained for Ubuntu 22.04. 0.101 ========== Load config settings. 0.103 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Install the runtime packages' starting. 0.104 ========== This script is only maintained for Ubuntu 22.04. 0.104 ========== Load config settings. 0.105 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Misc setup' starting. 1.955 W: GPG error: https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease' is not signed. 1.955 W: GPG e",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/902
https://github.com/google/deepvariant/issues/902:927,availability,error,error,927,"Unable to build docker image from source due to multiple reasons; I am trying to build the docker image of `deepvariant` but running into problems. I'm on `r1.7` branch and my branch is up to date. I am also facing the same issues on `r1.6.1` branch as well. The command I am using is the following -. ```. docker build --build-arg=FROM_IMAGE=nvidia/cuda:11.8.0-cudnn8-devel-ubuntu22.04 \. --build-arg=DV_GPU_BUILD=1 \. -t deepvariant_gpu . ```. I am building this docker image on my laptop (M3 macbook). #### PackagesNotFoundError error. The first error I get is -. ```. 1.247 Platform: linux-aarch64. 1.247 Collecting package metadata (repodata.json): ...working... done. 6.190 Solving environment: ...working... failed. 6.260. 6.260 PackagesNotFoundError: The following packages are not available from current channels:. 6.260. 6.260 - bioconda::samtools==1.15. 6.260 - bioconda::bcftools==1.15. 6.260. ```. I resolved this error by removing the version numbers. i.e., removed the `==1.15` from both the lines. #### Error in the build-prerunreq.sh script. Once, I cross the previous error, I get this error -. ```. > [builder 6/6] RUN ./build-prereq.sh && PATH=""${HOME}/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin"" ./build_release_binaries.sh # PATH for bazel:. 0.101 ========== This script is only maintained for Ubuntu 22.04. 0.101 ========== Load config settings. 0.103 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Install the runtime packages' starting. 0.104 ========== This script is only maintained for Ubuntu 22.04. 0.104 ========== Load config settings. 0.105 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Misc setup' starting. 1.955 W: GPG error: https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease' is not signed. 1.955 W: GPG e",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/902
https://github.com/google/deepvariant/issues/902:1019,availability,Error,Error,1019," image from source due to multiple reasons; I am trying to build the docker image of `deepvariant` but running into problems. I'm on `r1.7` branch and my branch is up to date. I am also facing the same issues on `r1.6.1` branch as well. The command I am using is the following -. ```. docker build --build-arg=FROM_IMAGE=nvidia/cuda:11.8.0-cudnn8-devel-ubuntu22.04 \. --build-arg=DV_GPU_BUILD=1 \. -t deepvariant_gpu . ```. I am building this docker image on my laptop (M3 macbook). #### PackagesNotFoundError error. The first error I get is -. ```. 1.247 Platform: linux-aarch64. 1.247 Collecting package metadata (repodata.json): ...working... done. 6.190 Solving environment: ...working... failed. 6.260. 6.260 PackagesNotFoundError: The following packages are not available from current channels:. 6.260. 6.260 - bioconda::samtools==1.15. 6.260 - bioconda::bcftools==1.15. 6.260. ```. I resolved this error by removing the version numbers. i.e., removed the `==1.15` from both the lines. #### Error in the build-prerunreq.sh script. Once, I cross the previous error, I get this error -. ```. > [builder 6/6] RUN ./build-prereq.sh && PATH=""${HOME}/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin"" ./build_release_binaries.sh # PATH for bazel:. 0.101 ========== This script is only maintained for Ubuntu 22.04. 0.101 ========== Load config settings. 0.103 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Install the runtime packages' starting. 0.104 ========== This script is only maintained for Ubuntu 22.04. 0.104 ========== Load config settings. 0.105 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Misc setup' starting. 1.955 W: GPG error: https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease' is not signed. 1.955 W: GPG error: http://ports.ubu",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/902
https://github.com/google/deepvariant/issues/902:1086,availability,error,error,1086,"e docker image of `deepvariant` but running into problems. I'm on `r1.7` branch and my branch is up to date. I am also facing the same issues on `r1.6.1` branch as well. The command I am using is the following -. ```. docker build --build-arg=FROM_IMAGE=nvidia/cuda:11.8.0-cudnn8-devel-ubuntu22.04 \. --build-arg=DV_GPU_BUILD=1 \. -t deepvariant_gpu . ```. I am building this docker image on my laptop (M3 macbook). #### PackagesNotFoundError error. The first error I get is -. ```. 1.247 Platform: linux-aarch64. 1.247 Collecting package metadata (repodata.json): ...working... done. 6.190 Solving environment: ...working... failed. 6.260. 6.260 PackagesNotFoundError: The following packages are not available from current channels:. 6.260. 6.260 - bioconda::samtools==1.15. 6.260 - bioconda::bcftools==1.15. 6.260. ```. I resolved this error by removing the version numbers. i.e., removed the `==1.15` from both the lines. #### Error in the build-prerunreq.sh script. Once, I cross the previous error, I get this error -. ```. > [builder 6/6] RUN ./build-prereq.sh && PATH=""${HOME}/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin"" ./build_release_binaries.sh # PATH for bazel:. 0.101 ========== This script is only maintained for Ubuntu 22.04. 0.101 ========== Load config settings. 0.103 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Install the runtime packages' starting. 0.104 ========== This script is only maintained for Ubuntu 22.04. 0.104 ========== Load config settings. 0.105 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Misc setup' starting. 1.955 W: GPG error: https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy InRelease: At least one invalid signatur",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/902
https://github.com/google/deepvariant/issues/902:1104,availability,error,error,1104,"`deepvariant` but running into problems. I'm on `r1.7` branch and my branch is up to date. I am also facing the same issues on `r1.6.1` branch as well. The command I am using is the following -. ```. docker build --build-arg=FROM_IMAGE=nvidia/cuda:11.8.0-cudnn8-devel-ubuntu22.04 \. --build-arg=DV_GPU_BUILD=1 \. -t deepvariant_gpu . ```. I am building this docker image on my laptop (M3 macbook). #### PackagesNotFoundError error. The first error I get is -. ```. 1.247 Platform: linux-aarch64. 1.247 Collecting package metadata (repodata.json): ...working... done. 6.190 Solving environment: ...working... failed. 6.260. 6.260 PackagesNotFoundError: The following packages are not available from current channels:. 6.260. 6.260 - bioconda::samtools==1.15. 6.260 - bioconda::bcftools==1.15. 6.260. ```. I resolved this error by removing the version numbers. i.e., removed the `==1.15` from both the lines. #### Error in the build-prerunreq.sh script. Once, I cross the previous error, I get this error -. ```. > [builder 6/6] RUN ./build-prereq.sh && PATH=""${HOME}/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin"" ./build_release_binaries.sh # PATH for bazel:. 0.101 ========== This script is only maintained for Ubuntu 22.04. 0.101 ========== Load config settings. 0.103 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Install the runtime packages' starting. 0.104 ========== This script is only maintained for Ubuntu 22.04. 0.104 ========== Load config settings. 0.105 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Misc setup' starting. 1.955 W: GPG error: https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy InRelease: At least one invalid signature was encountered.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/902
https://github.com/google/deepvariant/issues/902:1723,availability,error,error,1723,"60. 6.260 PackagesNotFoundError: The following packages are not available from current channels:. 6.260. 6.260 - bioconda::samtools==1.15. 6.260 - bioconda::bcftools==1.15. 6.260. ```. I resolved this error by removing the version numbers. i.e., removed the `==1.15` from both the lines. #### Error in the build-prerunreq.sh script. Once, I cross the previous error, I get this error -. ```. > [builder 6/6] RUN ./build-prereq.sh && PATH=""${HOME}/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin"" ./build_release_binaries.sh # PATH for bazel:. 0.101 ========== This script is only maintained for Ubuntu 22.04. 0.101 ========== Load config settings. 0.103 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Install the runtime packages' starting. 0.104 ========== This script is only maintained for Ubuntu 22.04. 0.104 ========== Load config settings. 0.105 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Misc setup' starting. 1.955 W: GPG error: https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-updates InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-updates InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-backports InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-backports InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/902
https://github.com/google/deepvariant/issues/902:1748,availability,down,download,1748,"Error: The following packages are not available from current channels:. 6.260. 6.260 - bioconda::samtools==1.15. 6.260 - bioconda::bcftools==1.15. 6.260. ```. I resolved this error by removing the version numbers. i.e., removed the `==1.15` from both the lines. #### Error in the build-prerunreq.sh script. Once, I cross the previous error, I get this error -. ```. > [builder 6/6] RUN ./build-prereq.sh && PATH=""${HOME}/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin"" ./build_release_binaries.sh # PATH for bazel:. 0.101 ========== This script is only maintained for Ubuntu 22.04. 0.101 ========== Load config settings. 0.103 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Install the runtime packages' starting. 0.104 ========== This script is only maintained for Ubuntu 22.04. 0.104 ========== Load config settings. 0.105 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Misc setup' starting. 1.955 W: GPG error: https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-updates InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-updates InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-backports InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-backports InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-security InRelease:",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/902
https://github.com/google/deepvariant/issues/902:1905,availability,down,download,1905,". I resolved this error by removing the version numbers. i.e., removed the `==1.15` from both the lines. #### Error in the build-prerunreq.sh script. Once, I cross the previous error, I get this error -. ```. > [builder 6/6] RUN ./build-prereq.sh && PATH=""${HOME}/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin"" ./build_release_binaries.sh # PATH for bazel:. 0.101 ========== This script is only maintained for Ubuntu 22.04. 0.101 ========== Load config settings. 0.103 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Install the runtime packages' starting. 0.104 ========== This script is only maintained for Ubuntu 22.04. 0.104 ========== Load config settings. 0.105 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Misc setup' starting. 1.955 W: GPG error: https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-updates InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-updates InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-backports InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-backports InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-security InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-security InRelease' is not signed. -----",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/902
https://github.com/google/deepvariant/issues/902:1999,availability,error,error,1999," the lines. #### Error in the build-prerunreq.sh script. Once, I cross the previous error, I get this error -. ```. > [builder 6/6] RUN ./build-prereq.sh && PATH=""${HOME}/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin"" ./build_release_binaries.sh # PATH for bazel:. 0.101 ========== This script is only maintained for Ubuntu 22.04. 0.101 ========== Load config settings. 0.103 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Install the runtime packages' starting. 0.104 ========== This script is only maintained for Ubuntu 22.04. 0.104 ========== Load config settings. 0.105 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Misc setup' starting. 1.955 W: GPG error: https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-updates InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-updates InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-backports InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-backports InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-security InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-security InRelease' is not signed. ------. Dockerfile:50. --------------------. 49 |. 50 | >>> RUN ./build-prereq.sh \. 51 | >>> && P",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/902
https://github.com/google/deepvariant/issues/902:2215,availability,error,error,2215,":/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin"" ./build_release_binaries.sh # PATH for bazel:. 0.101 ========== This script is only maintained for Ubuntu 22.04. 0.101 ========== Load config settings. 0.103 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Install the runtime packages' starting. 0.104 ========== This script is only maintained for Ubuntu 22.04. 0.104 ========== Load config settings. 0.105 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Misc setup' starting. 1.955 W: GPG error: https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-updates InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-updates InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-backports InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-backports InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-security InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-security InRelease' is not signed. ------. Dockerfile:50. --------------------. 49 |. 50 | >>> RUN ./build-prereq.sh \. 51 | >>> && PATH=""${HOME}/bin:${PATH}"" ./build_release_binaries.sh # PATH for bazel. 52 |. --------------------. ERROR: failed to solve: process ""/bin/sh -c ./build-prereq.sh && PATH=\""${HOME}/bin:${PATH}\"" ./build_release_binari",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/902
https://github.com/google/deepvariant/issues/902:2447,availability,error,error,2447,"tu 22.04. 0.101 ========== Load config settings. 0.103 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Install the runtime packages' starting. 0.104 ========== This script is only maintained for Ubuntu 22.04. 0.104 ========== Load config settings. 0.105 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Misc setup' starting. 1.955 W: GPG error: https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-updates InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-updates InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-backports InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-backports InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-security InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-security InRelease' is not signed. ------. Dockerfile:50. --------------------. 49 |. 50 | >>> RUN ./build-prereq.sh \. 51 | >>> && PATH=""${HOME}/bin:${PATH}"" ./build_release_binaries.sh # PATH for bazel. 52 |. --------------------. ERROR: failed to solve: process ""/bin/sh -c ./build-prereq.sh && PATH=\""${HOME}/bin:${PATH}\"" ./build_release_binaries.sh # PATH for bazel"" did not complete successfully: exit code: 100. ```. Looks like the repositories are either old or the sign has expired. How to fix this error?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/902
https://github.com/google/deepvariant/issues/902:2683,availability,error,error,2683,"tu 22.04. 0.101 ========== Load config settings. 0.103 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Install the runtime packages' starting. 0.104 ========== This script is only maintained for Ubuntu 22.04. 0.104 ========== Load config settings. 0.105 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Misc setup' starting. 1.955 W: GPG error: https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-updates InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-updates InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-backports InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-backports InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-security InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-security InRelease' is not signed. ------. Dockerfile:50. --------------------. 49 |. 50 | >>> RUN ./build-prereq.sh \. 51 | >>> && PATH=""${HOME}/bin:${PATH}"" ./build_release_binaries.sh # PATH for bazel. 52 |. --------------------. ERROR: failed to solve: process ""/bin/sh -c ./build-prereq.sh && PATH=\""${HOME}/bin:${PATH}\"" ./build_release_binaries.sh # PATH for bazel"" did not complete successfully: exit code: 100. ```. Looks like the repositories are either old or the sign has expired. How to fix this error?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/902
https://github.com/google/deepvariant/issues/902:3102,availability,ERROR,ERROR,3102,"tu 22.04. 0.101 ========== Load config settings. 0.103 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Install the runtime packages' starting. 0.104 ========== This script is only maintained for Ubuntu 22.04. 0.104 ========== Load config settings. 0.105 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Misc setup' starting. 1.955 W: GPG error: https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-updates InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-updates InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-backports InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-backports InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-security InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-security InRelease' is not signed. ------. Dockerfile:50. --------------------. 49 |. 50 | >>> RUN ./build-prereq.sh \. 51 | >>> && PATH=""${HOME}/bin:${PATH}"" ./build_release_binaries.sh # PATH for bazel. 52 |. --------------------. ERROR: failed to solve: process ""/bin/sh -c ./build-prereq.sh && PATH=\""${HOME}/bin:${PATH}\"" ./build_release_binaries.sh # PATH for bazel"" did not complete successfully: exit code: 100. ```. Looks like the repositories are either old or the sign has expired. How to fix this error?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/902
https://github.com/google/deepvariant/issues/902:3378,availability,error,error,3378,"tu 22.04. 0.101 ========== Load config settings. 0.103 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Install the runtime packages' starting. 0.104 ========== This script is only maintained for Ubuntu 22.04. 0.104 ========== Load config settings. 0.105 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Misc setup' starting. 1.955 W: GPG error: https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-updates InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-updates InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-backports InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-backports InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-security InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-security InRelease' is not signed. ------. Dockerfile:50. --------------------. 49 |. 50 | >>> RUN ./build-prereq.sh \. 51 | >>> && PATH=""${HOME}/bin:${PATH}"" ./build_release_binaries.sh # PATH for bazel. 52 |. --------------------. ERROR: failed to solve: process ""/bin/sh -c ./build-prereq.sh && PATH=\""${HOME}/bin:${PATH}\"" ./build_release_binaries.sh # PATH for bazel"" did not complete successfully: exit code: 100. ```. Looks like the repositories are either old or the sign has expired. How to fix this error?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/902
https://github.com/google/deepvariant/issues/902:10,deployability,build,build,10,"Unable to build docker image from source due to multiple reasons; I am trying to build the docker image of `deepvariant` but running into problems. I'm on `r1.7` branch and my branch is up to date. I am also facing the same issues on `r1.6.1` branch as well. The command I am using is the following -. ```. docker build --build-arg=FROM_IMAGE=nvidia/cuda:11.8.0-cudnn8-devel-ubuntu22.04 \. --build-arg=DV_GPU_BUILD=1 \. -t deepvariant_gpu . ```. I am building this docker image on my laptop (M3 macbook). #### PackagesNotFoundError error. The first error I get is -. ```. 1.247 Platform: linux-aarch64. 1.247 Collecting package metadata (repodata.json): ...working... done. 6.190 Solving environment: ...working... failed. 6.260. 6.260 PackagesNotFoundError: The following packages are not available from current channels:. 6.260. 6.260 - bioconda::samtools==1.15. 6.260 - bioconda::bcftools==1.15. 6.260. ```. I resolved this error by removing the version numbers. i.e., removed the `==1.15` from both the lines. #### Error in the build-prerunreq.sh script. Once, I cross the previous error, I get this error -. ```. > [builder 6/6] RUN ./build-prereq.sh && PATH=""${HOME}/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin"" ./build_release_binaries.sh # PATH for bazel:. 0.101 ========== This script is only maintained for Ubuntu 22.04. 0.101 ========== Load config settings. 0.103 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Install the runtime packages' starting. 0.104 ========== This script is only maintained for Ubuntu 22.04. 0.104 ========== Load config settings. 0.105 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Misc setup' starting. 1.955 W: GPG error: https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease' is not signed. 1.955 W: GPG e",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/902
https://github.com/google/deepvariant/issues/902:81,deployability,build,build,81,"Unable to build docker image from source due to multiple reasons; I am trying to build the docker image of `deepvariant` but running into problems. I'm on `r1.7` branch and my branch is up to date. I am also facing the same issues on `r1.6.1` branch as well. The command I am using is the following -. ```. docker build --build-arg=FROM_IMAGE=nvidia/cuda:11.8.0-cudnn8-devel-ubuntu22.04 \. --build-arg=DV_GPU_BUILD=1 \. -t deepvariant_gpu . ```. I am building this docker image on my laptop (M3 macbook). #### PackagesNotFoundError error. The first error I get is -. ```. 1.247 Platform: linux-aarch64. 1.247 Collecting package metadata (repodata.json): ...working... done. 6.190 Solving environment: ...working... failed. 6.260. 6.260 PackagesNotFoundError: The following packages are not available from current channels:. 6.260. 6.260 - bioconda::samtools==1.15. 6.260 - bioconda::bcftools==1.15. 6.260. ```. I resolved this error by removing the version numbers. i.e., removed the `==1.15` from both the lines. #### Error in the build-prerunreq.sh script. Once, I cross the previous error, I get this error -. ```. > [builder 6/6] RUN ./build-prereq.sh && PATH=""${HOME}/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin"" ./build_release_binaries.sh # PATH for bazel:. 0.101 ========== This script is only maintained for Ubuntu 22.04. 0.101 ========== Load config settings. 0.103 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Install the runtime packages' starting. 0.104 ========== This script is only maintained for Ubuntu 22.04. 0.104 ========== Load config settings. 0.105 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Misc setup' starting. 1.955 W: GPG error: https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease' is not signed. 1.955 W: GPG e",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/902
https://github.com/google/deepvariant/issues/902:314,deployability,build,build,314,"Unable to build docker image from source due to multiple reasons; I am trying to build the docker image of `deepvariant` but running into problems. I'm on `r1.7` branch and my branch is up to date. I am also facing the same issues on `r1.6.1` branch as well. The command I am using is the following -. ```. docker build --build-arg=FROM_IMAGE=nvidia/cuda:11.8.0-cudnn8-devel-ubuntu22.04 \. --build-arg=DV_GPU_BUILD=1 \. -t deepvariant_gpu . ```. I am building this docker image on my laptop (M3 macbook). #### PackagesNotFoundError error. The first error I get is -. ```. 1.247 Platform: linux-aarch64. 1.247 Collecting package metadata (repodata.json): ...working... done. 6.190 Solving environment: ...working... failed. 6.260. 6.260 PackagesNotFoundError: The following packages are not available from current channels:. 6.260. 6.260 - bioconda::samtools==1.15. 6.260 - bioconda::bcftools==1.15. 6.260. ```. I resolved this error by removing the version numbers. i.e., removed the `==1.15` from both the lines. #### Error in the build-prerunreq.sh script. Once, I cross the previous error, I get this error -. ```. > [builder 6/6] RUN ./build-prereq.sh && PATH=""${HOME}/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin"" ./build_release_binaries.sh # PATH for bazel:. 0.101 ========== This script is only maintained for Ubuntu 22.04. 0.101 ========== Load config settings. 0.103 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Install the runtime packages' starting. 0.104 ========== This script is only maintained for Ubuntu 22.04. 0.104 ========== Load config settings. 0.105 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Misc setup' starting. 1.955 W: GPG error: https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease' is not signed. 1.955 W: GPG e",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/902
https://github.com/google/deepvariant/issues/902:322,deployability,build,build-arg,322,"Unable to build docker image from source due to multiple reasons; I am trying to build the docker image of `deepvariant` but running into problems. I'm on `r1.7` branch and my branch is up to date. I am also facing the same issues on `r1.6.1` branch as well. The command I am using is the following -. ```. docker build --build-arg=FROM_IMAGE=nvidia/cuda:11.8.0-cudnn8-devel-ubuntu22.04 \. --build-arg=DV_GPU_BUILD=1 \. -t deepvariant_gpu . ```. I am building this docker image on my laptop (M3 macbook). #### PackagesNotFoundError error. The first error I get is -. ```. 1.247 Platform: linux-aarch64. 1.247 Collecting package metadata (repodata.json): ...working... done. 6.190 Solving environment: ...working... failed. 6.260. 6.260 PackagesNotFoundError: The following packages are not available from current channels:. 6.260. 6.260 - bioconda::samtools==1.15. 6.260 - bioconda::bcftools==1.15. 6.260. ```. I resolved this error by removing the version numbers. i.e., removed the `==1.15` from both the lines. #### Error in the build-prerunreq.sh script. Once, I cross the previous error, I get this error -. ```. > [builder 6/6] RUN ./build-prereq.sh && PATH=""${HOME}/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin"" ./build_release_binaries.sh # PATH for bazel:. 0.101 ========== This script is only maintained for Ubuntu 22.04. 0.101 ========== Load config settings. 0.103 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Install the runtime packages' starting. 0.104 ========== This script is only maintained for Ubuntu 22.04. 0.104 ========== Load config settings. 0.105 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Misc setup' starting. 1.955 W: GPG error: https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease' is not signed. 1.955 W: GPG e",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/902
https://github.com/google/deepvariant/issues/902:392,deployability,build,build-arg,392,"Unable to build docker image from source due to multiple reasons; I am trying to build the docker image of `deepvariant` but running into problems. I'm on `r1.7` branch and my branch is up to date. I am also facing the same issues on `r1.6.1` branch as well. The command I am using is the following -. ```. docker build --build-arg=FROM_IMAGE=nvidia/cuda:11.8.0-cudnn8-devel-ubuntu22.04 \. --build-arg=DV_GPU_BUILD=1 \. -t deepvariant_gpu . ```. I am building this docker image on my laptop (M3 macbook). #### PackagesNotFoundError error. The first error I get is -. ```. 1.247 Platform: linux-aarch64. 1.247 Collecting package metadata (repodata.json): ...working... done. 6.190 Solving environment: ...working... failed. 6.260. 6.260 PackagesNotFoundError: The following packages are not available from current channels:. 6.260. 6.260 - bioconda::samtools==1.15. 6.260 - bioconda::bcftools==1.15. 6.260. ```. I resolved this error by removing the version numbers. i.e., removed the `==1.15` from both the lines. #### Error in the build-prerunreq.sh script. Once, I cross the previous error, I get this error -. ```. > [builder 6/6] RUN ./build-prereq.sh && PATH=""${HOME}/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin"" ./build_release_binaries.sh # PATH for bazel:. 0.101 ========== This script is only maintained for Ubuntu 22.04. 0.101 ========== Load config settings. 0.103 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Install the runtime packages' starting. 0.104 ========== This script is only maintained for Ubuntu 22.04. 0.104 ========== Load config settings. 0.105 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Misc setup' starting. 1.955 W: GPG error: https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease' is not signed. 1.955 W: GPG e",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/902
https://github.com/google/deepvariant/issues/902:451,deployability,build,building,451,"Unable to build docker image from source due to multiple reasons; I am trying to build the docker image of `deepvariant` but running into problems. I'm on `r1.7` branch and my branch is up to date. I am also facing the same issues on `r1.6.1` branch as well. The command I am using is the following -. ```. docker build --build-arg=FROM_IMAGE=nvidia/cuda:11.8.0-cudnn8-devel-ubuntu22.04 \. --build-arg=DV_GPU_BUILD=1 \. -t deepvariant_gpu . ```. I am building this docker image on my laptop (M3 macbook). #### PackagesNotFoundError error. The first error I get is -. ```. 1.247 Platform: linux-aarch64. 1.247 Collecting package metadata (repodata.json): ...working... done. 6.190 Solving environment: ...working... failed. 6.260. 6.260 PackagesNotFoundError: The following packages are not available from current channels:. 6.260. 6.260 - bioconda::samtools==1.15. 6.260 - bioconda::bcftools==1.15. 6.260. ```. I resolved this error by removing the version numbers. i.e., removed the `==1.15` from both the lines. #### Error in the build-prerunreq.sh script. Once, I cross the previous error, I get this error -. ```. > [builder 6/6] RUN ./build-prereq.sh && PATH=""${HOME}/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin"" ./build_release_binaries.sh # PATH for bazel:. 0.101 ========== This script is only maintained for Ubuntu 22.04. 0.101 ========== Load config settings. 0.103 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Install the runtime packages' starting. 0.104 ========== This script is only maintained for Ubuntu 22.04. 0.104 ========== Load config settings. 0.105 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Misc setup' starting. 1.955 W: GPG error: https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease' is not signed. 1.955 W: GPG e",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/902
https://github.com/google/deepvariant/issues/902:715,deployability,fail,failed,715,"Unable to build docker image from source due to multiple reasons; I am trying to build the docker image of `deepvariant` but running into problems. I'm on `r1.7` branch and my branch is up to date. I am also facing the same issues on `r1.6.1` branch as well. The command I am using is the following -. ```. docker build --build-arg=FROM_IMAGE=nvidia/cuda:11.8.0-cudnn8-devel-ubuntu22.04 \. --build-arg=DV_GPU_BUILD=1 \. -t deepvariant_gpu . ```. I am building this docker image on my laptop (M3 macbook). #### PackagesNotFoundError error. The first error I get is -. ```. 1.247 Platform: linux-aarch64. 1.247 Collecting package metadata (repodata.json): ...working... done. 6.190 Solving environment: ...working... failed. 6.260. 6.260 PackagesNotFoundError: The following packages are not available from current channels:. 6.260. 6.260 - bioconda::samtools==1.15. 6.260 - bioconda::bcftools==1.15. 6.260. ```. I resolved this error by removing the version numbers. i.e., removed the `==1.15` from both the lines. #### Error in the build-prerunreq.sh script. Once, I cross the previous error, I get this error -. ```. > [builder 6/6] RUN ./build-prereq.sh && PATH=""${HOME}/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin"" ./build_release_binaries.sh # PATH for bazel:. 0.101 ========== This script is only maintained for Ubuntu 22.04. 0.101 ========== Load config settings. 0.103 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Install the runtime packages' starting. 0.104 ========== This script is only maintained for Ubuntu 22.04. 0.104 ========== Load config settings. 0.105 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Misc setup' starting. 1.955 W: GPG error: https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease' is not signed. 1.955 W: GPG e",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/902
https://github.com/google/deepvariant/issues/902:949,deployability,version,version,949,"Unable to build docker image from source due to multiple reasons; I am trying to build the docker image of `deepvariant` but running into problems. I'm on `r1.7` branch and my branch is up to date. I am also facing the same issues on `r1.6.1` branch as well. The command I am using is the following -. ```. docker build --build-arg=FROM_IMAGE=nvidia/cuda:11.8.0-cudnn8-devel-ubuntu22.04 \. --build-arg=DV_GPU_BUILD=1 \. -t deepvariant_gpu . ```. I am building this docker image on my laptop (M3 macbook). #### PackagesNotFoundError error. The first error I get is -. ```. 1.247 Platform: linux-aarch64. 1.247 Collecting package metadata (repodata.json): ...working... done. 6.190 Solving environment: ...working... failed. 6.260. 6.260 PackagesNotFoundError: The following packages are not available from current channels:. 6.260. 6.260 - bioconda::samtools==1.15. 6.260 - bioconda::bcftools==1.15. 6.260. ```. I resolved this error by removing the version numbers. i.e., removed the `==1.15` from both the lines. #### Error in the build-prerunreq.sh script. Once, I cross the previous error, I get this error -. ```. > [builder 6/6] RUN ./build-prereq.sh && PATH=""${HOME}/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin"" ./build_release_binaries.sh # PATH for bazel:. 0.101 ========== This script is only maintained for Ubuntu 22.04. 0.101 ========== Load config settings. 0.103 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Install the runtime packages' starting. 0.104 ========== This script is only maintained for Ubuntu 22.04. 0.104 ========== Load config settings. 0.105 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Misc setup' starting. 1.955 W: GPG error: https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease' is not signed. 1.955 W: GPG e",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/902
https://github.com/google/deepvariant/issues/902:1032,deployability,build,build-prerunreq,1032," due to multiple reasons; I am trying to build the docker image of `deepvariant` but running into problems. I'm on `r1.7` branch and my branch is up to date. I am also facing the same issues on `r1.6.1` branch as well. The command I am using is the following -. ```. docker build --build-arg=FROM_IMAGE=nvidia/cuda:11.8.0-cudnn8-devel-ubuntu22.04 \. --build-arg=DV_GPU_BUILD=1 \. -t deepvariant_gpu . ```. I am building this docker image on my laptop (M3 macbook). #### PackagesNotFoundError error. The first error I get is -. ```. 1.247 Platform: linux-aarch64. 1.247 Collecting package metadata (repodata.json): ...working... done. 6.190 Solving environment: ...working... failed. 6.260. 6.260 PackagesNotFoundError: The following packages are not available from current channels:. 6.260. 6.260 - bioconda::samtools==1.15. 6.260 - bioconda::bcftools==1.15. 6.260. ```. I resolved this error by removing the version numbers. i.e., removed the `==1.15` from both the lines. #### Error in the build-prerunreq.sh script. Once, I cross the previous error, I get this error -. ```. > [builder 6/6] RUN ./build-prereq.sh && PATH=""${HOME}/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin"" ./build_release_binaries.sh # PATH for bazel:. 0.101 ========== This script is only maintained for Ubuntu 22.04. 0.101 ========== Load config settings. 0.103 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Install the runtime packages' starting. 0.104 ========== This script is only maintained for Ubuntu 22.04. 0.104 ========== Load config settings. 0.105 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Misc setup' starting. 1.955 W: GPG error: https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-por",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/902
https://github.com/google/deepvariant/issues/902:1121,deployability,build,builder,1121,"running into problems. I'm on `r1.7` branch and my branch is up to date. I am also facing the same issues on `r1.6.1` branch as well. The command I am using is the following -. ```. docker build --build-arg=FROM_IMAGE=nvidia/cuda:11.8.0-cudnn8-devel-ubuntu22.04 \. --build-arg=DV_GPU_BUILD=1 \. -t deepvariant_gpu . ```. I am building this docker image on my laptop (M3 macbook). #### PackagesNotFoundError error. The first error I get is -. ```. 1.247 Platform: linux-aarch64. 1.247 Collecting package metadata (repodata.json): ...working... done. 6.190 Solving environment: ...working... failed. 6.260. 6.260 PackagesNotFoundError: The following packages are not available from current channels:. 6.260. 6.260 - bioconda::samtools==1.15. 6.260 - bioconda::bcftools==1.15. 6.260. ```. I resolved this error by removing the version numbers. i.e., removed the `==1.15` from both the lines. #### Error in the build-prerunreq.sh script. Once, I cross the previous error, I get this error -. ```. > [builder 6/6] RUN ./build-prereq.sh && PATH=""${HOME}/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin"" ./build_release_binaries.sh # PATH for bazel:. 0.101 ========== This script is only maintained for Ubuntu 22.04. 0.101 ========== Load config settings. 0.103 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Install the runtime packages' starting. 0.104 ========== This script is only maintained for Ubuntu 22.04. 0.104 ========== Load config settings. 0.105 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Misc setup' starting. 1.955 W: GPG error: https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy InRelease: At least one invalid signature was encountered. 1.955 E: The repo",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/902
https://github.com/google/deepvariant/issues/902:1140,deployability,build,build-prereq,1140,". I'm on `r1.7` branch and my branch is up to date. I am also facing the same issues on `r1.6.1` branch as well. The command I am using is the following -. ```. docker build --build-arg=FROM_IMAGE=nvidia/cuda:11.8.0-cudnn8-devel-ubuntu22.04 \. --build-arg=DV_GPU_BUILD=1 \. -t deepvariant_gpu . ```. I am building this docker image on my laptop (M3 macbook). #### PackagesNotFoundError error. The first error I get is -. ```. 1.247 Platform: linux-aarch64. 1.247 Collecting package metadata (repodata.json): ...working... done. 6.190 Solving environment: ...working... failed. 6.260. 6.260 PackagesNotFoundError: The following packages are not available from current channels:. 6.260. 6.260 - bioconda::samtools==1.15. 6.260 - bioconda::bcftools==1.15. 6.260. ```. I resolved this error by removing the version numbers. i.e., removed the `==1.15` from both the lines. #### Error in the build-prerunreq.sh script. Once, I cross the previous error, I get this error -. ```. > [builder 6/6] RUN ./build-prereq.sh && PATH=""${HOME}/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin"" ./build_release_binaries.sh # PATH for bazel:. 0.101 ========== This script is only maintained for Ubuntu 22.04. 0.101 ========== Load config settings. 0.103 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Install the runtime packages' starting. 0.104 ========== This script is only maintained for Ubuntu 22.04. 0.104 ========== Load config settings. 0.105 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Misc setup' starting. 1.955 W: GPG error: https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/902
https://github.com/google/deepvariant/issues/902:1481,deployability,Stage,Stage,1481,"laptop (M3 macbook). #### PackagesNotFoundError error. The first error I get is -. ```. 1.247 Platform: linux-aarch64. 1.247 Collecting package metadata (repodata.json): ...working... done. 6.190 Solving environment: ...working... failed. 6.260. 6.260 PackagesNotFoundError: The following packages are not available from current channels:. 6.260. 6.260 - bioconda::samtools==1.15. 6.260 - bioconda::bcftools==1.15. 6.260. ```. I resolved this error by removing the version numbers. i.e., removed the `==1.15` from both the lines. #### Error in the build-prerunreq.sh script. Once, I cross the previous error, I get this error -. ```. > [builder 6/6] RUN ./build-prereq.sh && PATH=""${HOME}/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin"" ./build_release_binaries.sh # PATH for bazel:. 0.101 ========== This script is only maintained for Ubuntu 22.04. 0.101 ========== Load config settings. 0.103 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Install the runtime packages' starting. 0.104 ========== This script is only maintained for Ubuntu 22.04. 0.104 ========== Load config settings. 0.105 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Misc setup' starting. 1.955 W: GPG error: https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-updates InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-updates InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/902
https://github.com/google/deepvariant/issues/902:1488,deployability,Instal,Install,1488,"M3 macbook). #### PackagesNotFoundError error. The first error I get is -. ```. 1.247 Platform: linux-aarch64. 1.247 Collecting package metadata (repodata.json): ...working... done. 6.190 Solving environment: ...working... failed. 6.260. 6.260 PackagesNotFoundError: The following packages are not available from current channels:. 6.260. 6.260 - bioconda::samtools==1.15. 6.260 - bioconda::bcftools==1.15. 6.260. ```. I resolved this error by removing the version numbers. i.e., removed the `==1.15` from both the lines. #### Error in the build-prerunreq.sh script. Once, I cross the previous error, I get this error -. ```. > [builder 6/6] RUN ./build-prereq.sh && PATH=""${HOME}/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin"" ./build_release_binaries.sh # PATH for bazel:. 0.101 ========== This script is only maintained for Ubuntu 22.04. 0.101 ========== Load config settings. 0.103 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Install the runtime packages' starting. 0.104 ========== This script is only maintained for Ubuntu 22.04. 0.104 ========== Load config settings. 0.105 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Misc setup' starting. 1.955 W: GPG error: https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-updates InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-updates InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports j",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/902
https://github.com/google/deepvariant/issues/902:1681,deployability,Stage,Stage,1681,"ing environment: ...working... failed. 6.260. 6.260 PackagesNotFoundError: The following packages are not available from current channels:. 6.260. 6.260 - bioconda::samtools==1.15. 6.260 - bioconda::bcftools==1.15. 6.260. ```. I resolved this error by removing the version numbers. i.e., removed the `==1.15` from both the lines. #### Error in the build-prerunreq.sh script. Once, I cross the previous error, I get this error -. ```. > [builder 6/6] RUN ./build-prereq.sh && PATH=""${HOME}/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin"" ./build_release_binaries.sh # PATH for bazel:. 0.101 ========== This script is only maintained for Ubuntu 22.04. 0.101 ========== Load config settings. 0.103 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Install the runtime packages' starting. 0.104 ========== This script is only maintained for Ubuntu 22.04. 0.104 ========== Load config settings. 0.105 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Misc setup' starting. 1.955 W: GPG error: https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-updates InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-updates InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-backports InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-backports InRelease' is not signed. 1.955 W: GPG e",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/902
https://github.com/google/deepvariant/issues/902:2265,deployability,updat,updates,2265,"/sbin:/bin"" ./build_release_binaries.sh # PATH for bazel:. 0.101 ========== This script is only maintained for Ubuntu 22.04. 0.101 ========== Load config settings. 0.103 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Install the runtime packages' starting. 0.104 ========== This script is only maintained for Ubuntu 22.04. 0.104 ========== Load config settings. 0.105 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Misc setup' starting. 1.955 W: GPG error: https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-updates InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-updates InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-backports InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-backports InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-security InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-security InRelease' is not signed. ------. Dockerfile:50. --------------------. 49 |. 50 | >>> RUN ./build-prereq.sh \. 51 | >>> && PATH=""${HOME}/bin:${PATH}"" ./build_release_binaries.sh # PATH for bazel. 52 |. --------------------. ERROR: failed to solve: process ""/bin/sh -c ./build-prereq.sh && PATH=\""${HOME}/bin:${PATH}\"" ./build_release_binaries.sh # PATH for bazel"" did not complete successful",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/902
https://github.com/google/deepvariant/issues/902:2400,deployability,updat,updates,2400,"tu 22.04. 0.101 ========== Load config settings. 0.103 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Install the runtime packages' starting. 0.104 ========== This script is only maintained for Ubuntu 22.04. 0.104 ========== Load config settings. 0.105 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Misc setup' starting. 1.955 W: GPG error: https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-updates InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-updates InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-backports InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-backports InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-security InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-security InRelease' is not signed. ------. Dockerfile:50. --------------------. 49 |. 50 | >>> RUN ./build-prereq.sh \. 51 | >>> && PATH=""${HOME}/bin:${PATH}"" ./build_release_binaries.sh # PATH for bazel. 52 |. --------------------. ERROR: failed to solve: process ""/bin/sh -c ./build-prereq.sh && PATH=\""${HOME}/bin:${PATH}\"" ./build_release_binaries.sh # PATH for bazel"" did not complete successfully: exit code: 100. ```. Looks like the repositories are either old or the sign has expired. How to fix this error?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/902
https://github.com/google/deepvariant/issues/902:2970,deployability,build,build-prereq,2970,"tu 22.04. 0.101 ========== Load config settings. 0.103 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Install the runtime packages' starting. 0.104 ========== This script is only maintained for Ubuntu 22.04. 0.104 ========== Load config settings. 0.105 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Misc setup' starting. 1.955 W: GPG error: https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-updates InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-updates InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-backports InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-backports InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-security InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-security InRelease' is not signed. ------. Dockerfile:50. --------------------. 49 |. 50 | >>> RUN ./build-prereq.sh \. 51 | >>> && PATH=""${HOME}/bin:${PATH}"" ./build_release_binaries.sh # PATH for bazel. 52 |. --------------------. ERROR: failed to solve: process ""/bin/sh -c ./build-prereq.sh && PATH=\""${HOME}/bin:${PATH}\"" ./build_release_binaries.sh # PATH for bazel"" did not complete successfully: exit code: 100. ```. Looks like the repositories are either old or the sign has expired. How to fix this error?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/902
https://github.com/google/deepvariant/issues/902:3109,deployability,fail,failed,3109,"tu 22.04. 0.101 ========== Load config settings. 0.103 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Install the runtime packages' starting. 0.104 ========== This script is only maintained for Ubuntu 22.04. 0.104 ========== Load config settings. 0.105 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Misc setup' starting. 1.955 W: GPG error: https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-updates InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-updates InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-backports InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-backports InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-security InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-security InRelease' is not signed. ------. Dockerfile:50. --------------------. 49 |. 50 | >>> RUN ./build-prereq.sh \. 51 | >>> && PATH=""${HOME}/bin:${PATH}"" ./build_release_binaries.sh # PATH for bazel. 52 |. --------------------. ERROR: failed to solve: process ""/bin/sh -c ./build-prereq.sh && PATH=\""${HOME}/bin:${PATH}\"" ./build_release_binaries.sh # PATH for bazel"" did not complete successfully: exit code: 100. ```. Looks like the repositories are either old or the sign has expired. How to fix this error?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/902
https://github.com/google/deepvariant/issues/902:3148,deployability,build,build-prereq,3148,"tu 22.04. 0.101 ========== Load config settings. 0.103 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Install the runtime packages' starting. 0.104 ========== This script is only maintained for Ubuntu 22.04. 0.104 ========== Load config settings. 0.105 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Misc setup' starting. 1.955 W: GPG error: https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-updates InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-updates InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-backports InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-backports InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-security InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-security InRelease' is not signed. ------. Dockerfile:50. --------------------. 49 |. 50 | >>> RUN ./build-prereq.sh \. 51 | >>> && PATH=""${HOME}/bin:${PATH}"" ./build_release_binaries.sh # PATH for bazel. 52 |. --------------------. ERROR: failed to solve: process ""/bin/sh -c ./build-prereq.sh && PATH=\""${HOME}/bin:${PATH}\"" ./build_release_binaries.sh # PATH for bazel"" did not complete successfully: exit code: 100. ```. Looks like the repositories are either old or the sign has expired. How to fix this error?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/902
https://github.com/google/deepvariant/issues/902:805,energy efficiency,current,current,805,"Unable to build docker image from source due to multiple reasons; I am trying to build the docker image of `deepvariant` but running into problems. I'm on `r1.7` branch and my branch is up to date. I am also facing the same issues on `r1.6.1` branch as well. The command I am using is the following -. ```. docker build --build-arg=FROM_IMAGE=nvidia/cuda:11.8.0-cudnn8-devel-ubuntu22.04 \. --build-arg=DV_GPU_BUILD=1 \. -t deepvariant_gpu . ```. I am building this docker image on my laptop (M3 macbook). #### PackagesNotFoundError error. The first error I get is -. ```. 1.247 Platform: linux-aarch64. 1.247 Collecting package metadata (repodata.json): ...working... done. 6.190 Solving environment: ...working... failed. 6.260. 6.260 PackagesNotFoundError: The following packages are not available from current channels:. 6.260. 6.260 - bioconda::samtools==1.15. 6.260 - bioconda::bcftools==1.15. 6.260. ```. I resolved this error by removing the version numbers. i.e., removed the `==1.15` from both the lines. #### Error in the build-prerunreq.sh script. Once, I cross the previous error, I get this error -. ```. > [builder 6/6] RUN ./build-prereq.sh && PATH=""${HOME}/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin"" ./build_release_binaries.sh # PATH for bazel:. 0.101 ========== This script is only maintained for Ubuntu 22.04. 0.101 ========== Load config settings. 0.103 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Install the runtime packages' starting. 0.104 ========== This script is only maintained for Ubuntu 22.04. 0.104 ========== Load config settings. 0.105 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Misc setup' starting. 1.955 W: GPG error: https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease' is not signed. 1.955 W: GPG e",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/902
https://github.com/google/deepvariant/issues/902:1411,energy efficiency,Load,Load,1411,"D=1 \. -t deepvariant_gpu . ```. I am building this docker image on my laptop (M3 macbook). #### PackagesNotFoundError error. The first error I get is -. ```. 1.247 Platform: linux-aarch64. 1.247 Collecting package metadata (repodata.json): ...working... done. 6.190 Solving environment: ...working... failed. 6.260. 6.260 PackagesNotFoundError: The following packages are not available from current channels:. 6.260. 6.260 - bioconda::samtools==1.15. 6.260 - bioconda::bcftools==1.15. 6.260. ```. I resolved this error by removing the version numbers. i.e., removed the `==1.15` from both the lines. #### Error in the build-prerunreq.sh script. Once, I cross the previous error, I get this error -. ```. > [builder 6/6] RUN ./build-prereq.sh && PATH=""${HOME}/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin"" ./build_release_binaries.sh # PATH for bazel:. 0.101 ========== This script is only maintained for Ubuntu 22.04. 0.101 ========== Load config settings. 0.103 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Install the runtime packages' starting. 0.104 ========== This script is only maintained for Ubuntu 22.04. 0.104 ========== Load config settings. 0.105 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Misc setup' starting. 1.955 W: GPG error: https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-updates InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-updates InRel",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/902
https://github.com/google/deepvariant/issues/902:1611,energy efficiency,Load,Load,1611,"ecting package metadata (repodata.json): ...working... done. 6.190 Solving environment: ...working... failed. 6.260. 6.260 PackagesNotFoundError: The following packages are not available from current channels:. 6.260. 6.260 - bioconda::samtools==1.15. 6.260 - bioconda::bcftools==1.15. 6.260. ```. I resolved this error by removing the version numbers. i.e., removed the `==1.15` from both the lines. #### Error in the build-prerunreq.sh script. Once, I cross the previous error, I get this error -. ```. > [builder 6/6] RUN ./build-prereq.sh && PATH=""${HOME}/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin"" ./build_release_binaries.sh # PATH for bazel:. 0.101 ========== This script is only maintained for Ubuntu 22.04. 0.101 ========== Load config settings. 0.103 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Install the runtime packages' starting. 0.104 ========== This script is only maintained for Ubuntu 22.04. 0.104 ========== Load config settings. 0.105 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Misc setup' starting. 1.955 W: GPG error: https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-updates InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-updates InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-backports InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.co",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/902
https://github.com/google/deepvariant/issues/902:949,integrability,version,version,949,"Unable to build docker image from source due to multiple reasons; I am trying to build the docker image of `deepvariant` but running into problems. I'm on `r1.7` branch and my branch is up to date. I am also facing the same issues on `r1.6.1` branch as well. The command I am using is the following -. ```. docker build --build-arg=FROM_IMAGE=nvidia/cuda:11.8.0-cudnn8-devel-ubuntu22.04 \. --build-arg=DV_GPU_BUILD=1 \. -t deepvariant_gpu . ```. I am building this docker image on my laptop (M3 macbook). #### PackagesNotFoundError error. The first error I get is -. ```. 1.247 Platform: linux-aarch64. 1.247 Collecting package metadata (repodata.json): ...working... done. 6.190 Solving environment: ...working... failed. 6.260. 6.260 PackagesNotFoundError: The following packages are not available from current channels:. 6.260. 6.260 - bioconda::samtools==1.15. 6.260 - bioconda::bcftools==1.15. 6.260. ```. I resolved this error by removing the version numbers. i.e., removed the `==1.15` from both the lines. #### Error in the build-prerunreq.sh script. Once, I cross the previous error, I get this error -. ```. > [builder 6/6] RUN ./build-prereq.sh && PATH=""${HOME}/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin"" ./build_release_binaries.sh # PATH for bazel:. 0.101 ========== This script is only maintained for Ubuntu 22.04. 0.101 ========== Load config settings. 0.103 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Install the runtime packages' starting. 0.104 ========== This script is only maintained for Ubuntu 22.04. 0.104 ========== Load config settings. 0.105 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Misc setup' starting. 1.955 W: GPG error: https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease' is not signed. 1.955 W: GPG e",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/902
https://github.com/google/deepvariant/issues/902:1875,integrability,repositor,repository,1875,"a::bcftools==1.15. 6.260. ```. I resolved this error by removing the version numbers. i.e., removed the `==1.15` from both the lines. #### Error in the build-prerunreq.sh script. Once, I cross the previous error, I get this error -. ```. > [builder 6/6] RUN ./build-prereq.sh && PATH=""${HOME}/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin"" ./build_release_binaries.sh # PATH for bazel:. 0.101 ========== This script is only maintained for Ubuntu 22.04. 0.101 ========== Load config settings. 0.103 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Install the runtime packages' starting. 0.104 ========== This script is only maintained for Ubuntu 22.04. 0.104 ========== Load config settings. 0.105 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Misc setup' starting. 1.955 W: GPG error: https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-updates InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-updates InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-backports InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-backports InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-security InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-security In",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/902
https://github.com/google/deepvariant/issues/902:2121,integrability,repositor,repository,2121,"er 6/6] RUN ./build-prereq.sh && PATH=""${HOME}/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin"" ./build_release_binaries.sh # PATH for bazel:. 0.101 ========== This script is only maintained for Ubuntu 22.04. 0.101 ========== Load config settings. 0.103 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Install the runtime packages' starting. 0.104 ========== This script is only maintained for Ubuntu 22.04. 0.104 ========== Load config settings. 0.105 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Misc setup' starting. 1.955 W: GPG error: https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-updates InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-updates InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-backports InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-backports InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-security InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-security InRelease' is not signed. ------. Dockerfile:50. --------------------. 49 |. 50 | >>> RUN ./build-prereq.sh \. 51 | >>> && PATH=""${HOME}/bin:${PATH}"" ./build_release_binaries.sh # PATH for bazel. 52 |. --------------------. ERROR: failed to solve: ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/902
https://github.com/google/deepvariant/issues/902:2345,integrability,repositor,repository,2345,"script is only maintained for Ubuntu 22.04. 0.101 ========== Load config settings. 0.103 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Install the runtime packages' starting. 0.104 ========== This script is only maintained for Ubuntu 22.04. 0.104 ========== Load config settings. 0.105 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Misc setup' starting. 1.955 W: GPG error: https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-updates InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-updates InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-backports InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-backports InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-security InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-security InRelease' is not signed. ------. Dockerfile:50. --------------------. 49 |. 50 | >>> RUN ./build-prereq.sh \. 51 | >>> && PATH=""${HOME}/bin:${PATH}"" ./build_release_binaries.sh # PATH for bazel. 52 |. --------------------. ERROR: failed to solve: process ""/bin/sh -c ./build-prereq.sh && PATH=\""${HOME}/bin:${PATH}\"" ./build_release_binaries.sh # PATH for bazel"" did not complete successfully: exit code: 100. ```. Looks like the repositories are either old or the sign h",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/902
https://github.com/google/deepvariant/issues/902:2579,integrability,repositor,repository,2579,"tu 22.04. 0.101 ========== Load config settings. 0.103 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Install the runtime packages' starting. 0.104 ========== This script is only maintained for Ubuntu 22.04. 0.104 ========== Load config settings. 0.105 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Misc setup' starting. 1.955 W: GPG error: https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-updates InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-updates InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-backports InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-backports InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-security InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-security InRelease' is not signed. ------. Dockerfile:50. --------------------. 49 |. 50 | >>> RUN ./build-prereq.sh \. 51 | >>> && PATH=""${HOME}/bin:${PATH}"" ./build_release_binaries.sh # PATH for bazel. 52 |. --------------------. ERROR: failed to solve: process ""/bin/sh -c ./build-prereq.sh && PATH=\""${HOME}/bin:${PATH}\"" ./build_release_binaries.sh # PATH for bazel"" did not complete successfully: exit code: 100. ```. Looks like the repositories are either old or the sign has expired. How to fix this error?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/902
https://github.com/google/deepvariant/issues/902:2814,integrability,repositor,repository,2814,"tu 22.04. 0.101 ========== Load config settings. 0.103 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Install the runtime packages' starting. 0.104 ========== This script is only maintained for Ubuntu 22.04. 0.104 ========== Load config settings. 0.105 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Misc setup' starting. 1.955 W: GPG error: https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-updates InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-updates InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-backports InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-backports InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-security InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-security InRelease' is not signed. ------. Dockerfile:50. --------------------. 49 |. 50 | >>> RUN ./build-prereq.sh \. 51 | >>> && PATH=""${HOME}/bin:${PATH}"" ./build_release_binaries.sh # PATH for bazel. 52 |. --------------------. ERROR: failed to solve: process ""/bin/sh -c ./build-prereq.sh && PATH=\""${HOME}/bin:${PATH}\"" ./build_release_binaries.sh # PATH for bazel"" did not complete successfully: exit code: 100. ```. Looks like the repositories are either old or the sign has expired. How to fix this error?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/902
https://github.com/google/deepvariant/issues/902:3309,integrability,repositor,repositories,3309,"tu 22.04. 0.101 ========== Load config settings. 0.103 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Install the runtime packages' starting. 0.104 ========== This script is only maintained for Ubuntu 22.04. 0.104 ========== Load config settings. 0.105 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Misc setup' starting. 1.955 W: GPG error: https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-updates InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-updates InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-backports InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-backports InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-security InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-security InRelease' is not signed. ------. Dockerfile:50. --------------------. 49 |. 50 | >>> RUN ./build-prereq.sh \. 51 | >>> && PATH=""${HOME}/bin:${PATH}"" ./build_release_binaries.sh # PATH for bazel. 52 |. --------------------. ERROR: failed to solve: process ""/bin/sh -c ./build-prereq.sh && PATH=\""${HOME}/bin:${PATH}\"" ./build_release_binaries.sh # PATH for bazel"" did not complete successfully: exit code: 100. ```. Looks like the repositories are either old or the sign has expired. How to fix this error?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/902
https://github.com/google/deepvariant/issues/902:578,interoperability,Platform,Platform,578,"Unable to build docker image from source due to multiple reasons; I am trying to build the docker image of `deepvariant` but running into problems. I'm on `r1.7` branch and my branch is up to date. I am also facing the same issues on `r1.6.1` branch as well. The command I am using is the following -. ```. docker build --build-arg=FROM_IMAGE=nvidia/cuda:11.8.0-cudnn8-devel-ubuntu22.04 \. --build-arg=DV_GPU_BUILD=1 \. -t deepvariant_gpu . ```. I am building this docker image on my laptop (M3 macbook). #### PackagesNotFoundError error. The first error I get is -. ```. 1.247 Platform: linux-aarch64. 1.247 Collecting package metadata (repodata.json): ...working... done. 6.190 Solving environment: ...working... failed. 6.260. 6.260 PackagesNotFoundError: The following packages are not available from current channels:. 6.260. 6.260 - bioconda::samtools==1.15. 6.260 - bioconda::bcftools==1.15. 6.260. ```. I resolved this error by removing the version numbers. i.e., removed the `==1.15` from both the lines. #### Error in the build-prerunreq.sh script. Once, I cross the previous error, I get this error -. ```. > [builder 6/6] RUN ./build-prereq.sh && PATH=""${HOME}/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin"" ./build_release_binaries.sh # PATH for bazel:. 0.101 ========== This script is only maintained for Ubuntu 22.04. 0.101 ========== Load config settings. 0.103 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Install the runtime packages' starting. 0.104 ========== This script is only maintained for Ubuntu 22.04. 0.104 ========== Load config settings. 0.105 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Misc setup' starting. 1.955 W: GPG error: https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease' is not signed. 1.955 W: GPG e",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/902
https://github.com/google/deepvariant/issues/902:1875,interoperability,repositor,repository,1875,"a::bcftools==1.15. 6.260. ```. I resolved this error by removing the version numbers. i.e., removed the `==1.15` from both the lines. #### Error in the build-prerunreq.sh script. Once, I cross the previous error, I get this error -. ```. > [builder 6/6] RUN ./build-prereq.sh && PATH=""${HOME}/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin"" ./build_release_binaries.sh # PATH for bazel:. 0.101 ========== This script is only maintained for Ubuntu 22.04. 0.101 ========== Load config settings. 0.103 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Install the runtime packages' starting. 0.104 ========== This script is only maintained for Ubuntu 22.04. 0.104 ========== Load config settings. 0.105 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Misc setup' starting. 1.955 W: GPG error: https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-updates InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-updates InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-backports InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-backports InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-security InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-security In",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/902
https://github.com/google/deepvariant/issues/902:2121,interoperability,repositor,repository,2121,"er 6/6] RUN ./build-prereq.sh && PATH=""${HOME}/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin"" ./build_release_binaries.sh # PATH for bazel:. 0.101 ========== This script is only maintained for Ubuntu 22.04. 0.101 ========== Load config settings. 0.103 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Install the runtime packages' starting. 0.104 ========== This script is only maintained for Ubuntu 22.04. 0.104 ========== Load config settings. 0.105 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Misc setup' starting. 1.955 W: GPG error: https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-updates InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-updates InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-backports InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-backports InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-security InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-security InRelease' is not signed. ------. Dockerfile:50. --------------------. 49 |. 50 | >>> RUN ./build-prereq.sh \. 51 | >>> && PATH=""${HOME}/bin:${PATH}"" ./build_release_binaries.sh # PATH for bazel. 52 |. --------------------. ERROR: failed to solve: ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/902
https://github.com/google/deepvariant/issues/902:2345,interoperability,repositor,repository,2345,"script is only maintained for Ubuntu 22.04. 0.101 ========== Load config settings. 0.103 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Install the runtime packages' starting. 0.104 ========== This script is only maintained for Ubuntu 22.04. 0.104 ========== Load config settings. 0.105 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Misc setup' starting. 1.955 W: GPG error: https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-updates InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-updates InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-backports InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-backports InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-security InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-security InRelease' is not signed. ------. Dockerfile:50. --------------------. 49 |. 50 | >>> RUN ./build-prereq.sh \. 51 | >>> && PATH=""${HOME}/bin:${PATH}"" ./build_release_binaries.sh # PATH for bazel. 52 |. --------------------. ERROR: failed to solve: process ""/bin/sh -c ./build-prereq.sh && PATH=\""${HOME}/bin:${PATH}\"" ./build_release_binaries.sh # PATH for bazel"" did not complete successfully: exit code: 100. ```. Looks like the repositories are either old or the sign h",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/902
https://github.com/google/deepvariant/issues/902:2579,interoperability,repositor,repository,2579,"tu 22.04. 0.101 ========== Load config settings. 0.103 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Install the runtime packages' starting. 0.104 ========== This script is only maintained for Ubuntu 22.04. 0.104 ========== Load config settings. 0.105 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Misc setup' starting. 1.955 W: GPG error: https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-updates InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-updates InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-backports InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-backports InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-security InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-security InRelease' is not signed. ------. Dockerfile:50. --------------------. 49 |. 50 | >>> RUN ./build-prereq.sh \. 51 | >>> && PATH=""${HOME}/bin:${PATH}"" ./build_release_binaries.sh # PATH for bazel. 52 |. --------------------. ERROR: failed to solve: process ""/bin/sh -c ./build-prereq.sh && PATH=\""${HOME}/bin:${PATH}\"" ./build_release_binaries.sh # PATH for bazel"" did not complete successfully: exit code: 100. ```. Looks like the repositories are either old or the sign has expired. How to fix this error?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/902
https://github.com/google/deepvariant/issues/902:2814,interoperability,repositor,repository,2814,"tu 22.04. 0.101 ========== Load config settings. 0.103 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Install the runtime packages' starting. 0.104 ========== This script is only maintained for Ubuntu 22.04. 0.104 ========== Load config settings. 0.105 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Misc setup' starting. 1.955 W: GPG error: https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-updates InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-updates InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-backports InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-backports InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-security InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-security InRelease' is not signed. ------. Dockerfile:50. --------------------. 49 |. 50 | >>> RUN ./build-prereq.sh \. 51 | >>> && PATH=""${HOME}/bin:${PATH}"" ./build_release_binaries.sh # PATH for bazel. 52 |. --------------------. ERROR: failed to solve: process ""/bin/sh -c ./build-prereq.sh && PATH=\""${HOME}/bin:${PATH}\"" ./build_release_binaries.sh # PATH for bazel"" did not complete successfully: exit code: 100. ```. Looks like the repositories are either old or the sign has expired. How to fix this error?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/902
https://github.com/google/deepvariant/issues/902:3309,interoperability,repositor,repositories,3309,"tu 22.04. 0.101 ========== Load config settings. 0.103 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Install the runtime packages' starting. 0.104 ========== This script is only maintained for Ubuntu 22.04. 0.104 ========== Load config settings. 0.105 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Misc setup' starting. 1.955 W: GPG error: https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-updates InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-updates InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-backports InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-backports InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-security InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-security InRelease' is not signed. ------. Dockerfile:50. --------------------. 49 |. 50 | >>> RUN ./build-prereq.sh \. 51 | >>> && PATH=""${HOME}/bin:${PATH}"" ./build_release_binaries.sh # PATH for bazel. 52 |. --------------------. ERROR: failed to solve: process ""/bin/sh -c ./build-prereq.sh && PATH=\""${HOME}/bin:${PATH}\"" ./build_release_binaries.sh # PATH for bazel"" did not complete successfully: exit code: 100. ```. Looks like the repositories are either old or the sign has expired. How to fix this error?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/902
https://github.com/google/deepvariant/issues/902:510,modifiability,Pac,PackagesNotFoundError,510,"Unable to build docker image from source due to multiple reasons; I am trying to build the docker image of `deepvariant` but running into problems. I'm on `r1.7` branch and my branch is up to date. I am also facing the same issues on `r1.6.1` branch as well. The command I am using is the following -. ```. docker build --build-arg=FROM_IMAGE=nvidia/cuda:11.8.0-cudnn8-devel-ubuntu22.04 \. --build-arg=DV_GPU_BUILD=1 \. -t deepvariant_gpu . ```. I am building this docker image on my laptop (M3 macbook). #### PackagesNotFoundError error. The first error I get is -. ```. 1.247 Platform: linux-aarch64. 1.247 Collecting package metadata (repodata.json): ...working... done. 6.190 Solving environment: ...working... failed. 6.260. 6.260 PackagesNotFoundError: The following packages are not available from current channels:. 6.260. 6.260 - bioconda::samtools==1.15. 6.260 - bioconda::bcftools==1.15. 6.260. ```. I resolved this error by removing the version numbers. i.e., removed the `==1.15` from both the lines. #### Error in the build-prerunreq.sh script. Once, I cross the previous error, I get this error -. ```. > [builder 6/6] RUN ./build-prereq.sh && PATH=""${HOME}/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin"" ./build_release_binaries.sh # PATH for bazel:. 0.101 ========== This script is only maintained for Ubuntu 22.04. 0.101 ========== Load config settings. 0.103 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Install the runtime packages' starting. 0.104 ========== This script is only maintained for Ubuntu 22.04. 0.104 ========== Load config settings. 0.105 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Misc setup' starting. 1.955 W: GPG error: https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease' is not signed. 1.955 W: GPG e",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/902
https://github.com/google/deepvariant/issues/902:620,modifiability,pac,package,620,"Unable to build docker image from source due to multiple reasons; I am trying to build the docker image of `deepvariant` but running into problems. I'm on `r1.7` branch and my branch is up to date. I am also facing the same issues on `r1.6.1` branch as well. The command I am using is the following -. ```. docker build --build-arg=FROM_IMAGE=nvidia/cuda:11.8.0-cudnn8-devel-ubuntu22.04 \. --build-arg=DV_GPU_BUILD=1 \. -t deepvariant_gpu . ```. I am building this docker image on my laptop (M3 macbook). #### PackagesNotFoundError error. The first error I get is -. ```. 1.247 Platform: linux-aarch64. 1.247 Collecting package metadata (repodata.json): ...working... done. 6.190 Solving environment: ...working... failed. 6.260. 6.260 PackagesNotFoundError: The following packages are not available from current channels:. 6.260. 6.260 - bioconda::samtools==1.15. 6.260 - bioconda::bcftools==1.15. 6.260. ```. I resolved this error by removing the version numbers. i.e., removed the `==1.15` from both the lines. #### Error in the build-prerunreq.sh script. Once, I cross the previous error, I get this error -. ```. > [builder 6/6] RUN ./build-prereq.sh && PATH=""${HOME}/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin"" ./build_release_binaries.sh # PATH for bazel:. 0.101 ========== This script is only maintained for Ubuntu 22.04. 0.101 ========== Load config settings. 0.103 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Install the runtime packages' starting. 0.104 ========== This script is only maintained for Ubuntu 22.04. 0.104 ========== Load config settings. 0.105 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Misc setup' starting. 1.955 W: GPG error: https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease' is not signed. 1.955 W: GPG e",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/902
https://github.com/google/deepvariant/issues/902:736,modifiability,Pac,PackagesNotFoundError,736,"Unable to build docker image from source due to multiple reasons; I am trying to build the docker image of `deepvariant` but running into problems. I'm on `r1.7` branch and my branch is up to date. I am also facing the same issues on `r1.6.1` branch as well. The command I am using is the following -. ```. docker build --build-arg=FROM_IMAGE=nvidia/cuda:11.8.0-cudnn8-devel-ubuntu22.04 \. --build-arg=DV_GPU_BUILD=1 \. -t deepvariant_gpu . ```. I am building this docker image on my laptop (M3 macbook). #### PackagesNotFoundError error. The first error I get is -. ```. 1.247 Platform: linux-aarch64. 1.247 Collecting package metadata (repodata.json): ...working... done. 6.190 Solving environment: ...working... failed. 6.260. 6.260 PackagesNotFoundError: The following packages are not available from current channels:. 6.260. 6.260 - bioconda::samtools==1.15. 6.260 - bioconda::bcftools==1.15. 6.260. ```. I resolved this error by removing the version numbers. i.e., removed the `==1.15` from both the lines. #### Error in the build-prerunreq.sh script. Once, I cross the previous error, I get this error -. ```. > [builder 6/6] RUN ./build-prereq.sh && PATH=""${HOME}/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin"" ./build_release_binaries.sh # PATH for bazel:. 0.101 ========== This script is only maintained for Ubuntu 22.04. 0.101 ========== Load config settings. 0.103 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Install the runtime packages' starting. 0.104 ========== This script is only maintained for Ubuntu 22.04. 0.104 ========== Load config settings. 0.105 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Misc setup' starting. 1.955 W: GPG error: https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease' is not signed. 1.955 W: GPG e",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/902
https://github.com/google/deepvariant/issues/902:773,modifiability,pac,packages,773,"Unable to build docker image from source due to multiple reasons; I am trying to build the docker image of `deepvariant` but running into problems. I'm on `r1.7` branch and my branch is up to date. I am also facing the same issues on `r1.6.1` branch as well. The command I am using is the following -. ```. docker build --build-arg=FROM_IMAGE=nvidia/cuda:11.8.0-cudnn8-devel-ubuntu22.04 \. --build-arg=DV_GPU_BUILD=1 \. -t deepvariant_gpu . ```. I am building this docker image on my laptop (M3 macbook). #### PackagesNotFoundError error. The first error I get is -. ```. 1.247 Platform: linux-aarch64. 1.247 Collecting package metadata (repodata.json): ...working... done. 6.190 Solving environment: ...working... failed. 6.260. 6.260 PackagesNotFoundError: The following packages are not available from current channels:. 6.260. 6.260 - bioconda::samtools==1.15. 6.260 - bioconda::bcftools==1.15. 6.260. ```. I resolved this error by removing the version numbers. i.e., removed the `==1.15` from both the lines. #### Error in the build-prerunreq.sh script. Once, I cross the previous error, I get this error -. ```. > [builder 6/6] RUN ./build-prereq.sh && PATH=""${HOME}/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin"" ./build_release_binaries.sh # PATH for bazel:. 0.101 ========== This script is only maintained for Ubuntu 22.04. 0.101 ========== Load config settings. 0.103 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Install the runtime packages' starting. 0.104 ========== This script is only maintained for Ubuntu 22.04. 0.104 ========== Load config settings. 0.105 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Misc setup' starting. 1.955 W: GPG error: https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease' is not signed. 1.955 W: GPG e",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/902
https://github.com/google/deepvariant/issues/902:949,modifiability,version,version,949,"Unable to build docker image from source due to multiple reasons; I am trying to build the docker image of `deepvariant` but running into problems. I'm on `r1.7` branch and my branch is up to date. I am also facing the same issues on `r1.6.1` branch as well. The command I am using is the following -. ```. docker build --build-arg=FROM_IMAGE=nvidia/cuda:11.8.0-cudnn8-devel-ubuntu22.04 \. --build-arg=DV_GPU_BUILD=1 \. -t deepvariant_gpu . ```. I am building this docker image on my laptop (M3 macbook). #### PackagesNotFoundError error. The first error I get is -. ```. 1.247 Platform: linux-aarch64. 1.247 Collecting package metadata (repodata.json): ...working... done. 6.190 Solving environment: ...working... failed. 6.260. 6.260 PackagesNotFoundError: The following packages are not available from current channels:. 6.260. 6.260 - bioconda::samtools==1.15. 6.260 - bioconda::bcftools==1.15. 6.260. ```. I resolved this error by removing the version numbers. i.e., removed the `==1.15` from both the lines. #### Error in the build-prerunreq.sh script. Once, I cross the previous error, I get this error -. ```. > [builder 6/6] RUN ./build-prereq.sh && PATH=""${HOME}/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin"" ./build_release_binaries.sh # PATH for bazel:. 0.101 ========== This script is only maintained for Ubuntu 22.04. 0.101 ========== Load config settings. 0.103 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Install the runtime packages' starting. 0.104 ========== This script is only maintained for Ubuntu 22.04. 0.104 ========== Load config settings. 0.105 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Misc setup' starting. 1.955 W: GPG error: https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease' is not signed. 1.955 W: GPG e",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/902
https://github.com/google/deepvariant/issues/902:1365,modifiability,maintain,maintained,1365,"evel-ubuntu22.04 \. --build-arg=DV_GPU_BUILD=1 \. -t deepvariant_gpu . ```. I am building this docker image on my laptop (M3 macbook). #### PackagesNotFoundError error. The first error I get is -. ```. 1.247 Platform: linux-aarch64. 1.247 Collecting package metadata (repodata.json): ...working... done. 6.190 Solving environment: ...working... failed. 6.260. 6.260 PackagesNotFoundError: The following packages are not available from current channels:. 6.260. 6.260 - bioconda::samtools==1.15. 6.260 - bioconda::bcftools==1.15. 6.260. ```. I resolved this error by removing the version numbers. i.e., removed the `==1.15` from both the lines. #### Error in the build-prerunreq.sh script. Once, I cross the previous error, I get this error -. ```. > [builder 6/6] RUN ./build-prereq.sh && PATH=""${HOME}/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin"" ./build_release_binaries.sh # PATH for bazel:. 0.101 ========== This script is only maintained for Ubuntu 22.04. 0.101 ========== Load config settings. 0.103 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Install the runtime packages' starting. 0.104 ========== This script is only maintained for Ubuntu 22.04. 0.104 ========== Load config settings. 0.105 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Misc setup' starting. 1.955 W: GPG error: https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-updates InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/902
https://github.com/google/deepvariant/issues/902:1508,modifiability,pac,packages,1508,"ckagesNotFoundError error. The first error I get is -. ```. 1.247 Platform: linux-aarch64. 1.247 Collecting package metadata (repodata.json): ...working... done. 6.190 Solving environment: ...working... failed. 6.260. 6.260 PackagesNotFoundError: The following packages are not available from current channels:. 6.260. 6.260 - bioconda::samtools==1.15. 6.260 - bioconda::bcftools==1.15. 6.260. ```. I resolved this error by removing the version numbers. i.e., removed the `==1.15` from both the lines. #### Error in the build-prerunreq.sh script. Once, I cross the previous error, I get this error -. ```. > [builder 6/6] RUN ./build-prereq.sh && PATH=""${HOME}/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin"" ./build_release_binaries.sh # PATH for bazel:. 0.101 ========== This script is only maintained for Ubuntu 22.04. 0.101 ========== Load config settings. 0.103 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Install the runtime packages' starting. 0.104 ========== This script is only maintained for Ubuntu 22.04. 0.104 ========== Load config settings. 0.105 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Misc setup' starting. 1.955 W: GPG error: https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-updates InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-updates InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-backports InRel",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/902
https://github.com/google/deepvariant/issues/902:1565,modifiability,maintain,maintained,1565,". 1.247 Platform: linux-aarch64. 1.247 Collecting package metadata (repodata.json): ...working... done. 6.190 Solving environment: ...working... failed. 6.260. 6.260 PackagesNotFoundError: The following packages are not available from current channels:. 6.260. 6.260 - bioconda::samtools==1.15. 6.260 - bioconda::bcftools==1.15. 6.260. ```. I resolved this error by removing the version numbers. i.e., removed the `==1.15` from both the lines. #### Error in the build-prerunreq.sh script. Once, I cross the previous error, I get this error -. ```. > [builder 6/6] RUN ./build-prereq.sh && PATH=""${HOME}/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin"" ./build_release_binaries.sh # PATH for bazel:. 0.101 ========== This script is only maintained for Ubuntu 22.04. 0.101 ========== Load config settings. 0.103 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Install the runtime packages' starting. 0.104 ========== This script is only maintained for Ubuntu 22.04. 0.104 ========== Load config settings. 0.105 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Misc setup' starting. 1.955 W: GPG error: https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-updates InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-updates InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-backports InRelease: At least one invalid signature was encountered. 1.95",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/902
https://github.com/google/deepvariant/issues/902:532,performance,error,error,532,"Unable to build docker image from source due to multiple reasons; I am trying to build the docker image of `deepvariant` but running into problems. I'm on `r1.7` branch and my branch is up to date. I am also facing the same issues on `r1.6.1` branch as well. The command I am using is the following -. ```. docker build --build-arg=FROM_IMAGE=nvidia/cuda:11.8.0-cudnn8-devel-ubuntu22.04 \. --build-arg=DV_GPU_BUILD=1 \. -t deepvariant_gpu . ```. I am building this docker image on my laptop (M3 macbook). #### PackagesNotFoundError error. The first error I get is -. ```. 1.247 Platform: linux-aarch64. 1.247 Collecting package metadata (repodata.json): ...working... done. 6.190 Solving environment: ...working... failed. 6.260. 6.260 PackagesNotFoundError: The following packages are not available from current channels:. 6.260. 6.260 - bioconda::samtools==1.15. 6.260 - bioconda::bcftools==1.15. 6.260. ```. I resolved this error by removing the version numbers. i.e., removed the `==1.15` from both the lines. #### Error in the build-prerunreq.sh script. Once, I cross the previous error, I get this error -. ```. > [builder 6/6] RUN ./build-prereq.sh && PATH=""${HOME}/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin"" ./build_release_binaries.sh # PATH for bazel:. 0.101 ========== This script is only maintained for Ubuntu 22.04. 0.101 ========== Load config settings. 0.103 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Install the runtime packages' starting. 0.104 ========== This script is only maintained for Ubuntu 22.04. 0.104 ========== Load config settings. 0.105 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Misc setup' starting. 1.955 W: GPG error: https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease' is not signed. 1.955 W: GPG e",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/902
https://github.com/google/deepvariant/issues/902:549,performance,error,error,549,"Unable to build docker image from source due to multiple reasons; I am trying to build the docker image of `deepvariant` but running into problems. I'm on `r1.7` branch and my branch is up to date. I am also facing the same issues on `r1.6.1` branch as well. The command I am using is the following -. ```. docker build --build-arg=FROM_IMAGE=nvidia/cuda:11.8.0-cudnn8-devel-ubuntu22.04 \. --build-arg=DV_GPU_BUILD=1 \. -t deepvariant_gpu . ```. I am building this docker image on my laptop (M3 macbook). #### PackagesNotFoundError error. The first error I get is -. ```. 1.247 Platform: linux-aarch64. 1.247 Collecting package metadata (repodata.json): ...working... done. 6.190 Solving environment: ...working... failed. 6.260. 6.260 PackagesNotFoundError: The following packages are not available from current channels:. 6.260. 6.260 - bioconda::samtools==1.15. 6.260 - bioconda::bcftools==1.15. 6.260. ```. I resolved this error by removing the version numbers. i.e., removed the `==1.15` from both the lines. #### Error in the build-prerunreq.sh script. Once, I cross the previous error, I get this error -. ```. > [builder 6/6] RUN ./build-prereq.sh && PATH=""${HOME}/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin"" ./build_release_binaries.sh # PATH for bazel:. 0.101 ========== This script is only maintained for Ubuntu 22.04. 0.101 ========== Load config settings. 0.103 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Install the runtime packages' starting. 0.104 ========== This script is only maintained for Ubuntu 22.04. 0.104 ========== Load config settings. 0.105 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Misc setup' starting. 1.955 W: GPG error: https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease' is not signed. 1.955 W: GPG e",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/902
https://github.com/google/deepvariant/issues/902:927,performance,error,error,927,"Unable to build docker image from source due to multiple reasons; I am trying to build the docker image of `deepvariant` but running into problems. I'm on `r1.7` branch and my branch is up to date. I am also facing the same issues on `r1.6.1` branch as well. The command I am using is the following -. ```. docker build --build-arg=FROM_IMAGE=nvidia/cuda:11.8.0-cudnn8-devel-ubuntu22.04 \. --build-arg=DV_GPU_BUILD=1 \. -t deepvariant_gpu . ```. I am building this docker image on my laptop (M3 macbook). #### PackagesNotFoundError error. The first error I get is -. ```. 1.247 Platform: linux-aarch64. 1.247 Collecting package metadata (repodata.json): ...working... done. 6.190 Solving environment: ...working... failed. 6.260. 6.260 PackagesNotFoundError: The following packages are not available from current channels:. 6.260. 6.260 - bioconda::samtools==1.15. 6.260 - bioconda::bcftools==1.15. 6.260. ```. I resolved this error by removing the version numbers. i.e., removed the `==1.15` from both the lines. #### Error in the build-prerunreq.sh script. Once, I cross the previous error, I get this error -. ```. > [builder 6/6] RUN ./build-prereq.sh && PATH=""${HOME}/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin"" ./build_release_binaries.sh # PATH for bazel:. 0.101 ========== This script is only maintained for Ubuntu 22.04. 0.101 ========== Load config settings. 0.103 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Install the runtime packages' starting. 0.104 ========== This script is only maintained for Ubuntu 22.04. 0.104 ========== Load config settings. 0.105 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Misc setup' starting. 1.955 W: GPG error: https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease' is not signed. 1.955 W: GPG e",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/902
https://github.com/google/deepvariant/issues/902:1019,performance,Error,Error,1019," image from source due to multiple reasons; I am trying to build the docker image of `deepvariant` but running into problems. I'm on `r1.7` branch and my branch is up to date. I am also facing the same issues on `r1.6.1` branch as well. The command I am using is the following -. ```. docker build --build-arg=FROM_IMAGE=nvidia/cuda:11.8.0-cudnn8-devel-ubuntu22.04 \. --build-arg=DV_GPU_BUILD=1 \. -t deepvariant_gpu . ```. I am building this docker image on my laptop (M3 macbook). #### PackagesNotFoundError error. The first error I get is -. ```. 1.247 Platform: linux-aarch64. 1.247 Collecting package metadata (repodata.json): ...working... done. 6.190 Solving environment: ...working... failed. 6.260. 6.260 PackagesNotFoundError: The following packages are not available from current channels:. 6.260. 6.260 - bioconda::samtools==1.15. 6.260 - bioconda::bcftools==1.15. 6.260. ```. I resolved this error by removing the version numbers. i.e., removed the `==1.15` from both the lines. #### Error in the build-prerunreq.sh script. Once, I cross the previous error, I get this error -. ```. > [builder 6/6] RUN ./build-prereq.sh && PATH=""${HOME}/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin"" ./build_release_binaries.sh # PATH for bazel:. 0.101 ========== This script is only maintained for Ubuntu 22.04. 0.101 ========== Load config settings. 0.103 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Install the runtime packages' starting. 0.104 ========== This script is only maintained for Ubuntu 22.04. 0.104 ========== Load config settings. 0.105 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Misc setup' starting. 1.955 W: GPG error: https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease' is not signed. 1.955 W: GPG error: http://ports.ubu",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/902
https://github.com/google/deepvariant/issues/902:1086,performance,error,error,1086,"e docker image of `deepvariant` but running into problems. I'm on `r1.7` branch and my branch is up to date. I am also facing the same issues on `r1.6.1` branch as well. The command I am using is the following -. ```. docker build --build-arg=FROM_IMAGE=nvidia/cuda:11.8.0-cudnn8-devel-ubuntu22.04 \. --build-arg=DV_GPU_BUILD=1 \. -t deepvariant_gpu . ```. I am building this docker image on my laptop (M3 macbook). #### PackagesNotFoundError error. The first error I get is -. ```. 1.247 Platform: linux-aarch64. 1.247 Collecting package metadata (repodata.json): ...working... done. 6.190 Solving environment: ...working... failed. 6.260. 6.260 PackagesNotFoundError: The following packages are not available from current channels:. 6.260. 6.260 - bioconda::samtools==1.15. 6.260 - bioconda::bcftools==1.15. 6.260. ```. I resolved this error by removing the version numbers. i.e., removed the `==1.15` from both the lines. #### Error in the build-prerunreq.sh script. Once, I cross the previous error, I get this error -. ```. > [builder 6/6] RUN ./build-prereq.sh && PATH=""${HOME}/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin"" ./build_release_binaries.sh # PATH for bazel:. 0.101 ========== This script is only maintained for Ubuntu 22.04. 0.101 ========== Load config settings. 0.103 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Install the runtime packages' starting. 0.104 ========== This script is only maintained for Ubuntu 22.04. 0.104 ========== Load config settings. 0.105 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Misc setup' starting. 1.955 W: GPG error: https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy InRelease: At least one invalid signatur",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/902
https://github.com/google/deepvariant/issues/902:1104,performance,error,error,1104,"`deepvariant` but running into problems. I'm on `r1.7` branch and my branch is up to date. I am also facing the same issues on `r1.6.1` branch as well. The command I am using is the following -. ```. docker build --build-arg=FROM_IMAGE=nvidia/cuda:11.8.0-cudnn8-devel-ubuntu22.04 \. --build-arg=DV_GPU_BUILD=1 \. -t deepvariant_gpu . ```. I am building this docker image on my laptop (M3 macbook). #### PackagesNotFoundError error. The first error I get is -. ```. 1.247 Platform: linux-aarch64. 1.247 Collecting package metadata (repodata.json): ...working... done. 6.190 Solving environment: ...working... failed. 6.260. 6.260 PackagesNotFoundError: The following packages are not available from current channels:. 6.260. 6.260 - bioconda::samtools==1.15. 6.260 - bioconda::bcftools==1.15. 6.260. ```. I resolved this error by removing the version numbers. i.e., removed the `==1.15` from both the lines. #### Error in the build-prerunreq.sh script. Once, I cross the previous error, I get this error -. ```. > [builder 6/6] RUN ./build-prereq.sh && PATH=""${HOME}/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin"" ./build_release_binaries.sh # PATH for bazel:. 0.101 ========== This script is only maintained for Ubuntu 22.04. 0.101 ========== Load config settings. 0.103 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Install the runtime packages' starting. 0.104 ========== This script is only maintained for Ubuntu 22.04. 0.104 ========== Load config settings. 0.105 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Misc setup' starting. 1.955 W: GPG error: https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy InRelease: At least one invalid signature was encountered.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/902
https://github.com/google/deepvariant/issues/902:1411,performance,Load,Load,1411,"D=1 \. -t deepvariant_gpu . ```. I am building this docker image on my laptop (M3 macbook). #### PackagesNotFoundError error. The first error I get is -. ```. 1.247 Platform: linux-aarch64. 1.247 Collecting package metadata (repodata.json): ...working... done. 6.190 Solving environment: ...working... failed. 6.260. 6.260 PackagesNotFoundError: The following packages are not available from current channels:. 6.260. 6.260 - bioconda::samtools==1.15. 6.260 - bioconda::bcftools==1.15. 6.260. ```. I resolved this error by removing the version numbers. i.e., removed the `==1.15` from both the lines. #### Error in the build-prerunreq.sh script. Once, I cross the previous error, I get this error -. ```. > [builder 6/6] RUN ./build-prereq.sh && PATH=""${HOME}/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin"" ./build_release_binaries.sh # PATH for bazel:. 0.101 ========== This script is only maintained for Ubuntu 22.04. 0.101 ========== Load config settings. 0.103 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Install the runtime packages' starting. 0.104 ========== This script is only maintained for Ubuntu 22.04. 0.104 ========== Load config settings. 0.105 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Misc setup' starting. 1.955 W: GPG error: https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-updates InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-updates InRel",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/902
https://github.com/google/deepvariant/issues/902:1611,performance,Load,Load,1611,"ecting package metadata (repodata.json): ...working... done. 6.190 Solving environment: ...working... failed. 6.260. 6.260 PackagesNotFoundError: The following packages are not available from current channels:. 6.260. 6.260 - bioconda::samtools==1.15. 6.260 - bioconda::bcftools==1.15. 6.260. ```. I resolved this error by removing the version numbers. i.e., removed the `==1.15` from both the lines. #### Error in the build-prerunreq.sh script. Once, I cross the previous error, I get this error -. ```. > [builder 6/6] RUN ./build-prereq.sh && PATH=""${HOME}/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin"" ./build_release_binaries.sh # PATH for bazel:. 0.101 ========== This script is only maintained for Ubuntu 22.04. 0.101 ========== Load config settings. 0.103 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Install the runtime packages' starting. 0.104 ========== This script is only maintained for Ubuntu 22.04. 0.104 ========== Load config settings. 0.105 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Misc setup' starting. 1.955 W: GPG error: https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-updates InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-updates InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-backports InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.co",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/902
https://github.com/google/deepvariant/issues/902:1723,performance,error,error,1723,"60. 6.260 PackagesNotFoundError: The following packages are not available from current channels:. 6.260. 6.260 - bioconda::samtools==1.15. 6.260 - bioconda::bcftools==1.15. 6.260. ```. I resolved this error by removing the version numbers. i.e., removed the `==1.15` from both the lines. #### Error in the build-prerunreq.sh script. Once, I cross the previous error, I get this error -. ```. > [builder 6/6] RUN ./build-prereq.sh && PATH=""${HOME}/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin"" ./build_release_binaries.sh # PATH for bazel:. 0.101 ========== This script is only maintained for Ubuntu 22.04. 0.101 ========== Load config settings. 0.103 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Install the runtime packages' starting. 0.104 ========== This script is only maintained for Ubuntu 22.04. 0.104 ========== Load config settings. 0.105 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Misc setup' starting. 1.955 W: GPG error: https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-updates InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-updates InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-backports InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-backports InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/902
https://github.com/google/deepvariant/issues/902:1999,performance,error,error,1999," the lines. #### Error in the build-prerunreq.sh script. Once, I cross the previous error, I get this error -. ```. > [builder 6/6] RUN ./build-prereq.sh && PATH=""${HOME}/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin"" ./build_release_binaries.sh # PATH for bazel:. 0.101 ========== This script is only maintained for Ubuntu 22.04. 0.101 ========== Load config settings. 0.103 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Install the runtime packages' starting. 0.104 ========== This script is only maintained for Ubuntu 22.04. 0.104 ========== Load config settings. 0.105 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Misc setup' starting. 1.955 W: GPG error: https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-updates InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-updates InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-backports InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-backports InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-security InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-security InRelease' is not signed. ------. Dockerfile:50. --------------------. 49 |. 50 | >>> RUN ./build-prereq.sh \. 51 | >>> && P",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/902
https://github.com/google/deepvariant/issues/902:2215,performance,error,error,2215,":/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin"" ./build_release_binaries.sh # PATH for bazel:. 0.101 ========== This script is only maintained for Ubuntu 22.04. 0.101 ========== Load config settings. 0.103 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Install the runtime packages' starting. 0.104 ========== This script is only maintained for Ubuntu 22.04. 0.104 ========== Load config settings. 0.105 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Misc setup' starting. 1.955 W: GPG error: https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-updates InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-updates InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-backports InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-backports InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-security InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-security InRelease' is not signed. ------. Dockerfile:50. --------------------. 49 |. 50 | >>> RUN ./build-prereq.sh \. 51 | >>> && PATH=""${HOME}/bin:${PATH}"" ./build_release_binaries.sh # PATH for bazel. 52 |. --------------------. ERROR: failed to solve: process ""/bin/sh -c ./build-prereq.sh && PATH=\""${HOME}/bin:${PATH}\"" ./build_release_binari",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/902
https://github.com/google/deepvariant/issues/902:2447,performance,error,error,2447,"tu 22.04. 0.101 ========== Load config settings. 0.103 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Install the runtime packages' starting. 0.104 ========== This script is only maintained for Ubuntu 22.04. 0.104 ========== Load config settings. 0.105 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Misc setup' starting. 1.955 W: GPG error: https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-updates InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-updates InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-backports InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-backports InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-security InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-security InRelease' is not signed. ------. Dockerfile:50. --------------------. 49 |. 50 | >>> RUN ./build-prereq.sh \. 51 | >>> && PATH=""${HOME}/bin:${PATH}"" ./build_release_binaries.sh # PATH for bazel. 52 |. --------------------. ERROR: failed to solve: process ""/bin/sh -c ./build-prereq.sh && PATH=\""${HOME}/bin:${PATH}\"" ./build_release_binaries.sh # PATH for bazel"" did not complete successfully: exit code: 100. ```. Looks like the repositories are either old or the sign has expired. How to fix this error?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/902
https://github.com/google/deepvariant/issues/902:2683,performance,error,error,2683,"tu 22.04. 0.101 ========== Load config settings. 0.103 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Install the runtime packages' starting. 0.104 ========== This script is only maintained for Ubuntu 22.04. 0.104 ========== Load config settings. 0.105 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Misc setup' starting. 1.955 W: GPG error: https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-updates InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-updates InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-backports InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-backports InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-security InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-security InRelease' is not signed. ------. Dockerfile:50. --------------------. 49 |. 50 | >>> RUN ./build-prereq.sh \. 51 | >>> && PATH=""${HOME}/bin:${PATH}"" ./build_release_binaries.sh # PATH for bazel. 52 |. --------------------. ERROR: failed to solve: process ""/bin/sh -c ./build-prereq.sh && PATH=\""${HOME}/bin:${PATH}\"" ./build_release_binaries.sh # PATH for bazel"" did not complete successfully: exit code: 100. ```. Looks like the repositories are either old or the sign has expired. How to fix this error?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/902
https://github.com/google/deepvariant/issues/902:3102,performance,ERROR,ERROR,3102,"tu 22.04. 0.101 ========== Load config settings. 0.103 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Install the runtime packages' starting. 0.104 ========== This script is only maintained for Ubuntu 22.04. 0.104 ========== Load config settings. 0.105 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Misc setup' starting. 1.955 W: GPG error: https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-updates InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-updates InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-backports InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-backports InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-security InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-security InRelease' is not signed. ------. Dockerfile:50. --------------------. 49 |. 50 | >>> RUN ./build-prereq.sh \. 51 | >>> && PATH=""${HOME}/bin:${PATH}"" ./build_release_binaries.sh # PATH for bazel. 52 |. --------------------. ERROR: failed to solve: process ""/bin/sh -c ./build-prereq.sh && PATH=\""${HOME}/bin:${PATH}\"" ./build_release_binaries.sh # PATH for bazel"" did not complete successfully: exit code: 100. ```. Looks like the repositories are either old or the sign has expired. How to fix this error?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/902
https://github.com/google/deepvariant/issues/902:3378,performance,error,error,3378,"tu 22.04. 0.101 ========== Load config settings. 0.103 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Install the runtime packages' starting. 0.104 ========== This script is only maintained for Ubuntu 22.04. 0.104 ========== Load config settings. 0.105 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Misc setup' starting. 1.955 W: GPG error: https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-updates InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-updates InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-backports InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-backports InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-security InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-security InRelease' is not signed. ------. Dockerfile:50. --------------------. 49 |. 50 | >>> RUN ./build-prereq.sh \. 51 | >>> && PATH=""${HOME}/bin:${PATH}"" ./build_release_binaries.sh # PATH for bazel. 52 |. --------------------. ERROR: failed to solve: process ""/bin/sh -c ./build-prereq.sh && PATH=\""${HOME}/bin:${PATH}\"" ./build_release_binaries.sh # PATH for bazel"" did not complete successfully: exit code: 100. ```. Looks like the repositories are either old or the sign has expired. How to fix this error?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/902
https://github.com/google/deepvariant/issues/902:715,reliability,fail,failed,715,"Unable to build docker image from source due to multiple reasons; I am trying to build the docker image of `deepvariant` but running into problems. I'm on `r1.7` branch and my branch is up to date. I am also facing the same issues on `r1.6.1` branch as well. The command I am using is the following -. ```. docker build --build-arg=FROM_IMAGE=nvidia/cuda:11.8.0-cudnn8-devel-ubuntu22.04 \. --build-arg=DV_GPU_BUILD=1 \. -t deepvariant_gpu . ```. I am building this docker image on my laptop (M3 macbook). #### PackagesNotFoundError error. The first error I get is -. ```. 1.247 Platform: linux-aarch64. 1.247 Collecting package metadata (repodata.json): ...working... done. 6.190 Solving environment: ...working... failed. 6.260. 6.260 PackagesNotFoundError: The following packages are not available from current channels:. 6.260. 6.260 - bioconda::samtools==1.15. 6.260 - bioconda::bcftools==1.15. 6.260. ```. I resolved this error by removing the version numbers. i.e., removed the `==1.15` from both the lines. #### Error in the build-prerunreq.sh script. Once, I cross the previous error, I get this error -. ```. > [builder 6/6] RUN ./build-prereq.sh && PATH=""${HOME}/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin"" ./build_release_binaries.sh # PATH for bazel:. 0.101 ========== This script is only maintained for Ubuntu 22.04. 0.101 ========== Load config settings. 0.103 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Install the runtime packages' starting. 0.104 ========== This script is only maintained for Ubuntu 22.04. 0.104 ========== Load config settings. 0.105 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Misc setup' starting. 1.955 W: GPG error: https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease' is not signed. 1.955 W: GPG e",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/902
https://github.com/google/deepvariant/issues/902:790,reliability,availab,available,790,"Unable to build docker image from source due to multiple reasons; I am trying to build the docker image of `deepvariant` but running into problems. I'm on `r1.7` branch and my branch is up to date. I am also facing the same issues on `r1.6.1` branch as well. The command I am using is the following -. ```. docker build --build-arg=FROM_IMAGE=nvidia/cuda:11.8.0-cudnn8-devel-ubuntu22.04 \. --build-arg=DV_GPU_BUILD=1 \. -t deepvariant_gpu . ```. I am building this docker image on my laptop (M3 macbook). #### PackagesNotFoundError error. The first error I get is -. ```. 1.247 Platform: linux-aarch64. 1.247 Collecting package metadata (repodata.json): ...working... done. 6.190 Solving environment: ...working... failed. 6.260. 6.260 PackagesNotFoundError: The following packages are not available from current channels:. 6.260. 6.260 - bioconda::samtools==1.15. 6.260 - bioconda::bcftools==1.15. 6.260. ```. I resolved this error by removing the version numbers. i.e., removed the `==1.15` from both the lines. #### Error in the build-prerunreq.sh script. Once, I cross the previous error, I get this error -. ```. > [builder 6/6] RUN ./build-prereq.sh && PATH=""${HOME}/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin"" ./build_release_binaries.sh # PATH for bazel:. 0.101 ========== This script is only maintained for Ubuntu 22.04. 0.101 ========== Load config settings. 0.103 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Install the runtime packages' starting. 0.104 ========== This script is only maintained for Ubuntu 22.04. 0.104 ========== Load config settings. 0.105 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Misc setup' starting. 1.955 W: GPG error: https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease' is not signed. 1.955 W: GPG e",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/902
https://github.com/google/deepvariant/issues/902:3109,reliability,fail,failed,3109,"tu 22.04. 0.101 ========== Load config settings. 0.103 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Install the runtime packages' starting. 0.104 ========== This script is only maintained for Ubuntu 22.04. 0.104 ========== Load config settings. 0.105 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Misc setup' starting. 1.955 W: GPG error: https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-updates InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-updates InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-backports InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-backports InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-security InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-security InRelease' is not signed. ------. Dockerfile:50. --------------------. 49 |. 50 | >>> RUN ./build-prereq.sh \. 51 | >>> && PATH=""${HOME}/bin:${PATH}"" ./build_release_binaries.sh # PATH for bazel. 52 |. --------------------. ERROR: failed to solve: process ""/bin/sh -c ./build-prereq.sh && PATH=\""${HOME}/bin:${PATH}\"" ./build_release_binaries.sh # PATH for bazel"" did not complete successfully: exit code: 100. ```. Looks like the repositories are either old or the sign has expired. How to fix this error?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/902
https://github.com/google/deepvariant/issues/902:532,safety,error,error,532,"Unable to build docker image from source due to multiple reasons; I am trying to build the docker image of `deepvariant` but running into problems. I'm on `r1.7` branch and my branch is up to date. I am also facing the same issues on `r1.6.1` branch as well. The command I am using is the following -. ```. docker build --build-arg=FROM_IMAGE=nvidia/cuda:11.8.0-cudnn8-devel-ubuntu22.04 \. --build-arg=DV_GPU_BUILD=1 \. -t deepvariant_gpu . ```. I am building this docker image on my laptop (M3 macbook). #### PackagesNotFoundError error. The first error I get is -. ```. 1.247 Platform: linux-aarch64. 1.247 Collecting package metadata (repodata.json): ...working... done. 6.190 Solving environment: ...working... failed. 6.260. 6.260 PackagesNotFoundError: The following packages are not available from current channels:. 6.260. 6.260 - bioconda::samtools==1.15. 6.260 - bioconda::bcftools==1.15. 6.260. ```. I resolved this error by removing the version numbers. i.e., removed the `==1.15` from both the lines. #### Error in the build-prerunreq.sh script. Once, I cross the previous error, I get this error -. ```. > [builder 6/6] RUN ./build-prereq.sh && PATH=""${HOME}/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin"" ./build_release_binaries.sh # PATH for bazel:. 0.101 ========== This script is only maintained for Ubuntu 22.04. 0.101 ========== Load config settings. 0.103 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Install the runtime packages' starting. 0.104 ========== This script is only maintained for Ubuntu 22.04. 0.104 ========== Load config settings. 0.105 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Misc setup' starting. 1.955 W: GPG error: https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease' is not signed. 1.955 W: GPG e",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/902
https://github.com/google/deepvariant/issues/902:549,safety,error,error,549,"Unable to build docker image from source due to multiple reasons; I am trying to build the docker image of `deepvariant` but running into problems. I'm on `r1.7` branch and my branch is up to date. I am also facing the same issues on `r1.6.1` branch as well. The command I am using is the following -. ```. docker build --build-arg=FROM_IMAGE=nvidia/cuda:11.8.0-cudnn8-devel-ubuntu22.04 \. --build-arg=DV_GPU_BUILD=1 \. -t deepvariant_gpu . ```. I am building this docker image on my laptop (M3 macbook). #### PackagesNotFoundError error. The first error I get is -. ```. 1.247 Platform: linux-aarch64. 1.247 Collecting package metadata (repodata.json): ...working... done. 6.190 Solving environment: ...working... failed. 6.260. 6.260 PackagesNotFoundError: The following packages are not available from current channels:. 6.260. 6.260 - bioconda::samtools==1.15. 6.260 - bioconda::bcftools==1.15. 6.260. ```. I resolved this error by removing the version numbers. i.e., removed the `==1.15` from both the lines. #### Error in the build-prerunreq.sh script. Once, I cross the previous error, I get this error -. ```. > [builder 6/6] RUN ./build-prereq.sh && PATH=""${HOME}/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin"" ./build_release_binaries.sh # PATH for bazel:. 0.101 ========== This script is only maintained for Ubuntu 22.04. 0.101 ========== Load config settings. 0.103 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Install the runtime packages' starting. 0.104 ========== This script is only maintained for Ubuntu 22.04. 0.104 ========== Load config settings. 0.105 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Misc setup' starting. 1.955 W: GPG error: https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease' is not signed. 1.955 W: GPG e",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/902
https://github.com/google/deepvariant/issues/902:790,safety,avail,available,790,"Unable to build docker image from source due to multiple reasons; I am trying to build the docker image of `deepvariant` but running into problems. I'm on `r1.7` branch and my branch is up to date. I am also facing the same issues on `r1.6.1` branch as well. The command I am using is the following -. ```. docker build --build-arg=FROM_IMAGE=nvidia/cuda:11.8.0-cudnn8-devel-ubuntu22.04 \. --build-arg=DV_GPU_BUILD=1 \. -t deepvariant_gpu . ```. I am building this docker image on my laptop (M3 macbook). #### PackagesNotFoundError error. The first error I get is -. ```. 1.247 Platform: linux-aarch64. 1.247 Collecting package metadata (repodata.json): ...working... done. 6.190 Solving environment: ...working... failed. 6.260. 6.260 PackagesNotFoundError: The following packages are not available from current channels:. 6.260. 6.260 - bioconda::samtools==1.15. 6.260 - bioconda::bcftools==1.15. 6.260. ```. I resolved this error by removing the version numbers. i.e., removed the `==1.15` from both the lines. #### Error in the build-prerunreq.sh script. Once, I cross the previous error, I get this error -. ```. > [builder 6/6] RUN ./build-prereq.sh && PATH=""${HOME}/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin"" ./build_release_binaries.sh # PATH for bazel:. 0.101 ========== This script is only maintained for Ubuntu 22.04. 0.101 ========== Load config settings. 0.103 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Install the runtime packages' starting. 0.104 ========== This script is only maintained for Ubuntu 22.04. 0.104 ========== Load config settings. 0.105 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Misc setup' starting. 1.955 W: GPG error: https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease' is not signed. 1.955 W: GPG e",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/902
https://github.com/google/deepvariant/issues/902:927,safety,error,error,927,"Unable to build docker image from source due to multiple reasons; I am trying to build the docker image of `deepvariant` but running into problems. I'm on `r1.7` branch and my branch is up to date. I am also facing the same issues on `r1.6.1` branch as well. The command I am using is the following -. ```. docker build --build-arg=FROM_IMAGE=nvidia/cuda:11.8.0-cudnn8-devel-ubuntu22.04 \. --build-arg=DV_GPU_BUILD=1 \. -t deepvariant_gpu . ```. I am building this docker image on my laptop (M3 macbook). #### PackagesNotFoundError error. The first error I get is -. ```. 1.247 Platform: linux-aarch64. 1.247 Collecting package metadata (repodata.json): ...working... done. 6.190 Solving environment: ...working... failed. 6.260. 6.260 PackagesNotFoundError: The following packages are not available from current channels:. 6.260. 6.260 - bioconda::samtools==1.15. 6.260 - bioconda::bcftools==1.15. 6.260. ```. I resolved this error by removing the version numbers. i.e., removed the `==1.15` from both the lines. #### Error in the build-prerunreq.sh script. Once, I cross the previous error, I get this error -. ```. > [builder 6/6] RUN ./build-prereq.sh && PATH=""${HOME}/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin"" ./build_release_binaries.sh # PATH for bazel:. 0.101 ========== This script is only maintained for Ubuntu 22.04. 0.101 ========== Load config settings. 0.103 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Install the runtime packages' starting. 0.104 ========== This script is only maintained for Ubuntu 22.04. 0.104 ========== Load config settings. 0.105 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Misc setup' starting. 1.955 W: GPG error: https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease' is not signed. 1.955 W: GPG e",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/902
https://github.com/google/deepvariant/issues/902:1019,safety,Error,Error,1019," image from source due to multiple reasons; I am trying to build the docker image of `deepvariant` but running into problems. I'm on `r1.7` branch and my branch is up to date. I am also facing the same issues on `r1.6.1` branch as well. The command I am using is the following -. ```. docker build --build-arg=FROM_IMAGE=nvidia/cuda:11.8.0-cudnn8-devel-ubuntu22.04 \. --build-arg=DV_GPU_BUILD=1 \. -t deepvariant_gpu . ```. I am building this docker image on my laptop (M3 macbook). #### PackagesNotFoundError error. The first error I get is -. ```. 1.247 Platform: linux-aarch64. 1.247 Collecting package metadata (repodata.json): ...working... done. 6.190 Solving environment: ...working... failed. 6.260. 6.260 PackagesNotFoundError: The following packages are not available from current channels:. 6.260. 6.260 - bioconda::samtools==1.15. 6.260 - bioconda::bcftools==1.15. 6.260. ```. I resolved this error by removing the version numbers. i.e., removed the `==1.15` from both the lines. #### Error in the build-prerunreq.sh script. Once, I cross the previous error, I get this error -. ```. > [builder 6/6] RUN ./build-prereq.sh && PATH=""${HOME}/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin"" ./build_release_binaries.sh # PATH for bazel:. 0.101 ========== This script is only maintained for Ubuntu 22.04. 0.101 ========== Load config settings. 0.103 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Install the runtime packages' starting. 0.104 ========== This script is only maintained for Ubuntu 22.04. 0.104 ========== Load config settings. 0.105 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Misc setup' starting. 1.955 W: GPG error: https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease' is not signed. 1.955 W: GPG error: http://ports.ubu",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/902
https://github.com/google/deepvariant/issues/902:1086,safety,error,error,1086,"e docker image of `deepvariant` but running into problems. I'm on `r1.7` branch and my branch is up to date. I am also facing the same issues on `r1.6.1` branch as well. The command I am using is the following -. ```. docker build --build-arg=FROM_IMAGE=nvidia/cuda:11.8.0-cudnn8-devel-ubuntu22.04 \. --build-arg=DV_GPU_BUILD=1 \. -t deepvariant_gpu . ```. I am building this docker image on my laptop (M3 macbook). #### PackagesNotFoundError error. The first error I get is -. ```. 1.247 Platform: linux-aarch64. 1.247 Collecting package metadata (repodata.json): ...working... done. 6.190 Solving environment: ...working... failed. 6.260. 6.260 PackagesNotFoundError: The following packages are not available from current channels:. 6.260. 6.260 - bioconda::samtools==1.15. 6.260 - bioconda::bcftools==1.15. 6.260. ```. I resolved this error by removing the version numbers. i.e., removed the `==1.15` from both the lines. #### Error in the build-prerunreq.sh script. Once, I cross the previous error, I get this error -. ```. > [builder 6/6] RUN ./build-prereq.sh && PATH=""${HOME}/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin"" ./build_release_binaries.sh # PATH for bazel:. 0.101 ========== This script is only maintained for Ubuntu 22.04. 0.101 ========== Load config settings. 0.103 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Install the runtime packages' starting. 0.104 ========== This script is only maintained for Ubuntu 22.04. 0.104 ========== Load config settings. 0.105 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Misc setup' starting. 1.955 W: GPG error: https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy InRelease: At least one invalid signatur",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/902
https://github.com/google/deepvariant/issues/902:1104,safety,error,error,1104,"`deepvariant` but running into problems. I'm on `r1.7` branch and my branch is up to date. I am also facing the same issues on `r1.6.1` branch as well. The command I am using is the following -. ```. docker build --build-arg=FROM_IMAGE=nvidia/cuda:11.8.0-cudnn8-devel-ubuntu22.04 \. --build-arg=DV_GPU_BUILD=1 \. -t deepvariant_gpu . ```. I am building this docker image on my laptop (M3 macbook). #### PackagesNotFoundError error. The first error I get is -. ```. 1.247 Platform: linux-aarch64. 1.247 Collecting package metadata (repodata.json): ...working... done. 6.190 Solving environment: ...working... failed. 6.260. 6.260 PackagesNotFoundError: The following packages are not available from current channels:. 6.260. 6.260 - bioconda::samtools==1.15. 6.260 - bioconda::bcftools==1.15. 6.260. ```. I resolved this error by removing the version numbers. i.e., removed the `==1.15` from both the lines. #### Error in the build-prerunreq.sh script. Once, I cross the previous error, I get this error -. ```. > [builder 6/6] RUN ./build-prereq.sh && PATH=""${HOME}/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin"" ./build_release_binaries.sh # PATH for bazel:. 0.101 ========== This script is only maintained for Ubuntu 22.04. 0.101 ========== Load config settings. 0.103 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Install the runtime packages' starting. 0.104 ========== This script is only maintained for Ubuntu 22.04. 0.104 ========== Load config settings. 0.105 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Misc setup' starting. 1.955 W: GPG error: https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy InRelease: At least one invalid signature was encountered.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/902
https://github.com/google/deepvariant/issues/902:1365,safety,maintain,maintained,1365,"evel-ubuntu22.04 \. --build-arg=DV_GPU_BUILD=1 \. -t deepvariant_gpu . ```. I am building this docker image on my laptop (M3 macbook). #### PackagesNotFoundError error. The first error I get is -. ```. 1.247 Platform: linux-aarch64. 1.247 Collecting package metadata (repodata.json): ...working... done. 6.190 Solving environment: ...working... failed. 6.260. 6.260 PackagesNotFoundError: The following packages are not available from current channels:. 6.260. 6.260 - bioconda::samtools==1.15. 6.260 - bioconda::bcftools==1.15. 6.260. ```. I resolved this error by removing the version numbers. i.e., removed the `==1.15` from both the lines. #### Error in the build-prerunreq.sh script. Once, I cross the previous error, I get this error -. ```. > [builder 6/6] RUN ./build-prereq.sh && PATH=""${HOME}/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin"" ./build_release_binaries.sh # PATH for bazel:. 0.101 ========== This script is only maintained for Ubuntu 22.04. 0.101 ========== Load config settings. 0.103 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Install the runtime packages' starting. 0.104 ========== This script is only maintained for Ubuntu 22.04. 0.104 ========== Load config settings. 0.105 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Misc setup' starting. 1.955 W: GPG error: https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-updates InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/902
https://github.com/google/deepvariant/issues/902:1565,safety,maintain,maintained,1565,". 1.247 Platform: linux-aarch64. 1.247 Collecting package metadata (repodata.json): ...working... done. 6.190 Solving environment: ...working... failed. 6.260. 6.260 PackagesNotFoundError: The following packages are not available from current channels:. 6.260. 6.260 - bioconda::samtools==1.15. 6.260 - bioconda::bcftools==1.15. 6.260. ```. I resolved this error by removing the version numbers. i.e., removed the `==1.15` from both the lines. #### Error in the build-prerunreq.sh script. Once, I cross the previous error, I get this error -. ```. > [builder 6/6] RUN ./build-prereq.sh && PATH=""${HOME}/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin"" ./build_release_binaries.sh # PATH for bazel:. 0.101 ========== This script is only maintained for Ubuntu 22.04. 0.101 ========== Load config settings. 0.103 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Install the runtime packages' starting. 0.104 ========== This script is only maintained for Ubuntu 22.04. 0.104 ========== Load config settings. 0.105 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Misc setup' starting. 1.955 W: GPG error: https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-updates InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-updates InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-backports InRelease: At least one invalid signature was encountered. 1.95",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/902
https://github.com/google/deepvariant/issues/902:1723,safety,error,error,1723,"60. 6.260 PackagesNotFoundError: The following packages are not available from current channels:. 6.260. 6.260 - bioconda::samtools==1.15. 6.260 - bioconda::bcftools==1.15. 6.260. ```. I resolved this error by removing the version numbers. i.e., removed the `==1.15` from both the lines. #### Error in the build-prerunreq.sh script. Once, I cross the previous error, I get this error -. ```. > [builder 6/6] RUN ./build-prereq.sh && PATH=""${HOME}/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin"" ./build_release_binaries.sh # PATH for bazel:. 0.101 ========== This script is only maintained for Ubuntu 22.04. 0.101 ========== Load config settings. 0.103 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Install the runtime packages' starting. 0.104 ========== This script is only maintained for Ubuntu 22.04. 0.104 ========== Load config settings. 0.105 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Misc setup' starting. 1.955 W: GPG error: https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-updates InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-updates InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-backports InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-backports InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/902
https://github.com/google/deepvariant/issues/902:1999,safety,error,error,1999," the lines. #### Error in the build-prerunreq.sh script. Once, I cross the previous error, I get this error -. ```. > [builder 6/6] RUN ./build-prereq.sh && PATH=""${HOME}/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin"" ./build_release_binaries.sh # PATH for bazel:. 0.101 ========== This script is only maintained for Ubuntu 22.04. 0.101 ========== Load config settings. 0.103 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Install the runtime packages' starting. 0.104 ========== This script is only maintained for Ubuntu 22.04. 0.104 ========== Load config settings. 0.105 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Misc setup' starting. 1.955 W: GPG error: https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-updates InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-updates InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-backports InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-backports InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-security InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-security InRelease' is not signed. ------. Dockerfile:50. --------------------. 49 |. 50 | >>> RUN ./build-prereq.sh \. 51 | >>> && P",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/902
https://github.com/google/deepvariant/issues/902:2215,safety,error,error,2215,":/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin"" ./build_release_binaries.sh # PATH for bazel:. 0.101 ========== This script is only maintained for Ubuntu 22.04. 0.101 ========== Load config settings. 0.103 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Install the runtime packages' starting. 0.104 ========== This script is only maintained for Ubuntu 22.04. 0.104 ========== Load config settings. 0.105 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Misc setup' starting. 1.955 W: GPG error: https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-updates InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-updates InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-backports InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-backports InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-security InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-security InRelease' is not signed. ------. Dockerfile:50. --------------------. 49 |. 50 | >>> RUN ./build-prereq.sh \. 51 | >>> && PATH=""${HOME}/bin:${PATH}"" ./build_release_binaries.sh # PATH for bazel. 52 |. --------------------. ERROR: failed to solve: process ""/bin/sh -c ./build-prereq.sh && PATH=\""${HOME}/bin:${PATH}\"" ./build_release_binari",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/902
https://github.com/google/deepvariant/issues/902:2265,safety,updat,updates,2265,"/sbin:/bin"" ./build_release_binaries.sh # PATH for bazel:. 0.101 ========== This script is only maintained for Ubuntu 22.04. 0.101 ========== Load config settings. 0.103 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Install the runtime packages' starting. 0.104 ========== This script is only maintained for Ubuntu 22.04. 0.104 ========== Load config settings. 0.105 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Misc setup' starting. 1.955 W: GPG error: https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-updates InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-updates InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-backports InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-backports InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-security InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-security InRelease' is not signed. ------. Dockerfile:50. --------------------. 49 |. 50 | >>> RUN ./build-prereq.sh \. 51 | >>> && PATH=""${HOME}/bin:${PATH}"" ./build_release_binaries.sh # PATH for bazel. 52 |. --------------------. ERROR: failed to solve: process ""/bin/sh -c ./build-prereq.sh && PATH=\""${HOME}/bin:${PATH}\"" ./build_release_binaries.sh # PATH for bazel"" did not complete successful",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/902
https://github.com/google/deepvariant/issues/902:2400,safety,updat,updates,2400,"tu 22.04. 0.101 ========== Load config settings. 0.103 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Install the runtime packages' starting. 0.104 ========== This script is only maintained for Ubuntu 22.04. 0.104 ========== Load config settings. 0.105 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Misc setup' starting. 1.955 W: GPG error: https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-updates InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-updates InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-backports InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-backports InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-security InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-security InRelease' is not signed. ------. Dockerfile:50. --------------------. 49 |. 50 | >>> RUN ./build-prereq.sh \. 51 | >>> && PATH=""${HOME}/bin:${PATH}"" ./build_release_binaries.sh # PATH for bazel. 52 |. --------------------. ERROR: failed to solve: process ""/bin/sh -c ./build-prereq.sh && PATH=\""${HOME}/bin:${PATH}\"" ./build_release_binaries.sh # PATH for bazel"" did not complete successfully: exit code: 100. ```. Looks like the repositories are either old or the sign has expired. How to fix this error?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/902
https://github.com/google/deepvariant/issues/902:2447,safety,error,error,2447,"tu 22.04. 0.101 ========== Load config settings. 0.103 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Install the runtime packages' starting. 0.104 ========== This script is only maintained for Ubuntu 22.04. 0.104 ========== Load config settings. 0.105 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Misc setup' starting. 1.955 W: GPG error: https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-updates InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-updates InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-backports InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-backports InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-security InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-security InRelease' is not signed. ------. Dockerfile:50. --------------------. 49 |. 50 | >>> RUN ./build-prereq.sh \. 51 | >>> && PATH=""${HOME}/bin:${PATH}"" ./build_release_binaries.sh # PATH for bazel. 52 |. --------------------. ERROR: failed to solve: process ""/bin/sh -c ./build-prereq.sh && PATH=\""${HOME}/bin:${PATH}\"" ./build_release_binaries.sh # PATH for bazel"" did not complete successfully: exit code: 100. ```. Looks like the repositories are either old or the sign has expired. How to fix this error?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/902
https://github.com/google/deepvariant/issues/902:2683,safety,error,error,2683,"tu 22.04. 0.101 ========== Load config settings. 0.103 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Install the runtime packages' starting. 0.104 ========== This script is only maintained for Ubuntu 22.04. 0.104 ========== Load config settings. 0.105 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Misc setup' starting. 1.955 W: GPG error: https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-updates InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-updates InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-backports InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-backports InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-security InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-security InRelease' is not signed. ------. Dockerfile:50. --------------------. 49 |. 50 | >>> RUN ./build-prereq.sh \. 51 | >>> && PATH=""${HOME}/bin:${PATH}"" ./build_release_binaries.sh # PATH for bazel. 52 |. --------------------. ERROR: failed to solve: process ""/bin/sh -c ./build-prereq.sh && PATH=\""${HOME}/bin:${PATH}\"" ./build_release_binaries.sh # PATH for bazel"" did not complete successfully: exit code: 100. ```. Looks like the repositories are either old or the sign has expired. How to fix this error?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/902
https://github.com/google/deepvariant/issues/902:3102,safety,ERROR,ERROR,3102,"tu 22.04. 0.101 ========== Load config settings. 0.103 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Install the runtime packages' starting. 0.104 ========== This script is only maintained for Ubuntu 22.04. 0.104 ========== Load config settings. 0.105 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Misc setup' starting. 1.955 W: GPG error: https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-updates InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-updates InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-backports InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-backports InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-security InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-security InRelease' is not signed. ------. Dockerfile:50. --------------------. 49 |. 50 | >>> RUN ./build-prereq.sh \. 51 | >>> && PATH=""${HOME}/bin:${PATH}"" ./build_release_binaries.sh # PATH for bazel. 52 |. --------------------. ERROR: failed to solve: process ""/bin/sh -c ./build-prereq.sh && PATH=\""${HOME}/bin:${PATH}\"" ./build_release_binaries.sh # PATH for bazel"" did not complete successfully: exit code: 100. ```. Looks like the repositories are either old or the sign has expired. How to fix this error?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/902
https://github.com/google/deepvariant/issues/902:3250,safety,compl,complete,3250,"tu 22.04. 0.101 ========== Load config settings. 0.103 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Install the runtime packages' starting. 0.104 ========== This script is only maintained for Ubuntu 22.04. 0.104 ========== Load config settings. 0.105 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Misc setup' starting. 1.955 W: GPG error: https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-updates InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-updates InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-backports InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-backports InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-security InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-security InRelease' is not signed. ------. Dockerfile:50. --------------------. 49 |. 50 | >>> RUN ./build-prereq.sh \. 51 | >>> && PATH=""${HOME}/bin:${PATH}"" ./build_release_binaries.sh # PATH for bazel. 52 |. --------------------. ERROR: failed to solve: process ""/bin/sh -c ./build-prereq.sh && PATH=\""${HOME}/bin:${PATH}\"" ./build_release_binaries.sh # PATH for bazel"" did not complete successfully: exit code: 100. ```. Looks like the repositories are either old or the sign has expired. How to fix this error?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/902
https://github.com/google/deepvariant/issues/902:3378,safety,error,error,3378,"tu 22.04. 0.101 ========== Load config settings. 0.103 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Install the runtime packages' starting. 0.104 ========== This script is only maintained for Ubuntu 22.04. 0.104 ========== Load config settings. 0.105 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Misc setup' starting. 1.955 W: GPG error: https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-updates InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-updates InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-backports InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-backports InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-security InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-security InRelease' is not signed. ------. Dockerfile:50. --------------------. 49 |. 50 | >>> RUN ./build-prereq.sh \. 51 | >>> && PATH=""${HOME}/bin:${PATH}"" ./build_release_binaries.sh # PATH for bazel. 52 |. --------------------. ERROR: failed to solve: process ""/bin/sh -c ./build-prereq.sh && PATH=\""${HOME}/bin:${PATH}\"" ./build_release_binaries.sh # PATH for bazel"" did not complete successfully: exit code: 100. ```. Looks like the repositories are either old or the sign has expired. How to fix this error?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/902
https://github.com/google/deepvariant/issues/902:790,security,availab,available,790,"Unable to build docker image from source due to multiple reasons; I am trying to build the docker image of `deepvariant` but running into problems. I'm on `r1.7` branch and my branch is up to date. I am also facing the same issues on `r1.6.1` branch as well. The command I am using is the following -. ```. docker build --build-arg=FROM_IMAGE=nvidia/cuda:11.8.0-cudnn8-devel-ubuntu22.04 \. --build-arg=DV_GPU_BUILD=1 \. -t deepvariant_gpu . ```. I am building this docker image on my laptop (M3 macbook). #### PackagesNotFoundError error. The first error I get is -. ```. 1.247 Platform: linux-aarch64. 1.247 Collecting package metadata (repodata.json): ...working... done. 6.190 Solving environment: ...working... failed. 6.260. 6.260 PackagesNotFoundError: The following packages are not available from current channels:. 6.260. 6.260 - bioconda::samtools==1.15. 6.260 - bioconda::bcftools==1.15. 6.260. ```. I resolved this error by removing the version numbers. i.e., removed the `==1.15` from both the lines. #### Error in the build-prerunreq.sh script. Once, I cross the previous error, I get this error -. ```. > [builder 6/6] RUN ./build-prereq.sh && PATH=""${HOME}/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin"" ./build_release_binaries.sh # PATH for bazel:. 0.101 ========== This script is only maintained for Ubuntu 22.04. 0.101 ========== Load config settings. 0.103 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Install the runtime packages' starting. 0.104 ========== This script is only maintained for Ubuntu 22.04. 0.104 ========== Load config settings. 0.105 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Misc setup' starting. 1.955 W: GPG error: https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease' is not signed. 1.955 W: GPG e",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/902
https://github.com/google/deepvariant/issues/902:1835,security,sign,signature,1835,"ioconda::samtools==1.15. 6.260 - bioconda::bcftools==1.15. 6.260. ```. I resolved this error by removing the version numbers. i.e., removed the `==1.15` from both the lines. #### Error in the build-prerunreq.sh script. Once, I cross the previous error, I get this error -. ```. > [builder 6/6] RUN ./build-prereq.sh && PATH=""${HOME}/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin"" ./build_release_binaries.sh # PATH for bazel:. 0.101 ========== This script is only maintained for Ubuntu 22.04. 0.101 ========== Load config settings. 0.103 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Install the runtime packages' starting. 0.104 ========== This script is only maintained for Ubuntu 22.04. 0.104 ========== Load config settings. 0.105 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Misc setup' starting. 1.955 W: GPG error: https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-updates InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-updates InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-backports InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-backports InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-security InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.u",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/902
https://github.com/google/deepvariant/issues/902:1978,security,sign,signed,1978,"he `==1.15` from both the lines. #### Error in the build-prerunreq.sh script. Once, I cross the previous error, I get this error -. ```. > [builder 6/6] RUN ./build-prereq.sh && PATH=""${HOME}/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin"" ./build_release_binaries.sh # PATH for bazel:. 0.101 ========== This script is only maintained for Ubuntu 22.04. 0.101 ========== Load config settings. 0.103 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Install the runtime packages' starting. 0.104 ========== This script is only maintained for Ubuntu 22.04. 0.104 ========== Load config settings. 0.105 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Misc setup' starting. 1.955 W: GPG error: https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-updates InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-updates InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-backports InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-backports InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-security InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-security InRelease' is not signed. ------. Dockerfile:50. --------------------. 49 |. 50 | >>> RUN ./build-prere",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/902
https://github.com/google/deepvariant/issues/902:2081,security,sign,signature,2081,"error, I get this error -. ```. > [builder 6/6] RUN ./build-prereq.sh && PATH=""${HOME}/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin"" ./build_release_binaries.sh # PATH for bazel:. 0.101 ========== This script is only maintained for Ubuntu 22.04. 0.101 ========== Load config settings. 0.103 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Install the runtime packages' starting. 0.104 ========== This script is only maintained for Ubuntu 22.04. 0.104 ========== Load config settings. 0.105 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Misc setup' starting. 1.955 W: GPG error: https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-updates InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-updates InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-backports InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-backports InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-security InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-security InRelease' is not signed. ------. Dockerfile:50. --------------------. 49 |. 50 | >>> RUN ./build-prereq.sh \. 51 | >>> && PATH=""${HOME}/bin:${PATH}"" ./build_release_binaries.sh # PATH for bazel. 52 |. ------",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/902
https://github.com/google/deepvariant/issues/902:2194,security,sign,signed,2194,"n:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin"" ./build_release_binaries.sh # PATH for bazel:. 0.101 ========== This script is only maintained for Ubuntu 22.04. 0.101 ========== Load config settings. 0.103 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Install the runtime packages' starting. 0.104 ========== This script is only maintained for Ubuntu 22.04. 0.104 ========== Load config settings. 0.105 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Misc setup' starting. 1.955 W: GPG error: https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-updates InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-updates InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-backports InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-backports InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-security InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-security InRelease' is not signed. ------. Dockerfile:50. --------------------. 49 |. 50 | >>> RUN ./build-prereq.sh \. 51 | >>> && PATH=""${HOME}/bin:${PATH}"" ./build_release_binaries.sh # PATH for bazel. 52 |. --------------------. ERROR: failed to solve: process ""/bin/sh -c ./build-prereq.sh && PATH=\""${HOME}/bin:${PATH}\"" .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/902
https://github.com/google/deepvariant/issues/902:2265,security,updat,updates,2265,"/sbin:/bin"" ./build_release_binaries.sh # PATH for bazel:. 0.101 ========== This script is only maintained for Ubuntu 22.04. 0.101 ========== Load config settings. 0.103 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Install the runtime packages' starting. 0.104 ========== This script is only maintained for Ubuntu 22.04. 0.104 ========== Load config settings. 0.105 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Misc setup' starting. 1.955 W: GPG error: https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-updates InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-updates InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-backports InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-backports InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-security InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-security InRelease' is not signed. ------. Dockerfile:50. --------------------. 49 |. 50 | >>> RUN ./build-prereq.sh \. 51 | >>> && PATH=""${HOME}/bin:${PATH}"" ./build_release_binaries.sh # PATH for bazel. 52 |. --------------------. ERROR: failed to solve: process ""/bin/sh -c ./build-prereq.sh && PATH=\""${HOME}/bin:${PATH}\"" ./build_release_binaries.sh # PATH for bazel"" did not complete successful",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/902
https://github.com/google/deepvariant/issues/902:2305,security,sign,signature,2305," PATH for bazel:. 0.101 ========== This script is only maintained for Ubuntu 22.04. 0.101 ========== Load config settings. 0.103 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Install the runtime packages' starting. 0.104 ========== This script is only maintained for Ubuntu 22.04. 0.104 ========== Load config settings. 0.105 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Misc setup' starting. 1.955 W: GPG error: https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-updates InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-updates InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-backports InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-backports InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-security InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-security InRelease' is not signed. ------. Dockerfile:50. --------------------. 49 |. 50 | >>> RUN ./build-prereq.sh \. 51 | >>> && PATH=""${HOME}/bin:${PATH}"" ./build_release_binaries.sh # PATH for bazel. 52 |. --------------------. ERROR: failed to solve: process ""/bin/sh -c ./build-prereq.sh && PATH=\""${HOME}/bin:${PATH}\"" ./build_release_binaries.sh # PATH for bazel"" did not complete successfully: exit code: 100. ```. Looks like the r",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/902
https://github.com/google/deepvariant/issues/902:2400,security,updat,updates,2400,"tu 22.04. 0.101 ========== Load config settings. 0.103 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Install the runtime packages' starting. 0.104 ========== This script is only maintained for Ubuntu 22.04. 0.104 ========== Load config settings. 0.105 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Misc setup' starting. 1.955 W: GPG error: https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-updates InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-updates InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-backports InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-backports InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-security InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-security InRelease' is not signed. ------. Dockerfile:50. --------------------. 49 |. 50 | >>> RUN ./build-prereq.sh \. 51 | >>> && PATH=""${HOME}/bin:${PATH}"" ./build_release_binaries.sh # PATH for bazel. 52 |. --------------------. ERROR: failed to solve: process ""/bin/sh -c ./build-prereq.sh && PATH=\""${HOME}/bin:${PATH}\"" ./build_release_binaries.sh # PATH for bazel"" did not complete successfully: exit code: 100. ```. Looks like the repositories are either old or the sign has expired. How to fix this error?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/902
https://github.com/google/deepvariant/issues/902:2426,security,sign,signed,2426,"tu 22.04. 0.101 ========== Load config settings. 0.103 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Install the runtime packages' starting. 0.104 ========== This script is only maintained for Ubuntu 22.04. 0.104 ========== Load config settings. 0.105 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Misc setup' starting. 1.955 W: GPG error: https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-updates InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-updates InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-backports InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-backports InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-security InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-security InRelease' is not signed. ------. Dockerfile:50. --------------------. 49 |. 50 | >>> RUN ./build-prereq.sh \. 51 | >>> && PATH=""${HOME}/bin:${PATH}"" ./build_release_binaries.sh # PATH for bazel. 52 |. --------------------. ERROR: failed to solve: process ""/bin/sh -c ./build-prereq.sh && PATH=\""${HOME}/bin:${PATH}\"" ./build_release_binaries.sh # PATH for bazel"" did not complete successfully: exit code: 100. ```. Looks like the repositories are either old or the sign has expired. How to fix this error?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/902
https://github.com/google/deepvariant/issues/902:2539,security,sign,signature,2539,"tu 22.04. 0.101 ========== Load config settings. 0.103 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Install the runtime packages' starting. 0.104 ========== This script is only maintained for Ubuntu 22.04. 0.104 ========== Load config settings. 0.105 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Misc setup' starting. 1.955 W: GPG error: https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-updates InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-updates InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-backports InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-backports InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-security InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-security InRelease' is not signed. ------. Dockerfile:50. --------------------. 49 |. 50 | >>> RUN ./build-prereq.sh \. 51 | >>> && PATH=""${HOME}/bin:${PATH}"" ./build_release_binaries.sh # PATH for bazel. 52 |. --------------------. ERROR: failed to solve: process ""/bin/sh -c ./build-prereq.sh && PATH=\""${HOME}/bin:${PATH}\"" ./build_release_binaries.sh # PATH for bazel"" did not complete successfully: exit code: 100. ```. Looks like the repositories are either old or the sign has expired. How to fix this error?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/902
https://github.com/google/deepvariant/issues/902:2662,security,sign,signed,2662,"tu 22.04. 0.101 ========== Load config settings. 0.103 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Install the runtime packages' starting. 0.104 ========== This script is only maintained for Ubuntu 22.04. 0.104 ========== Load config settings. 0.105 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Misc setup' starting. 1.955 W: GPG error: https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-updates InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-updates InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-backports InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-backports InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-security InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-security InRelease' is not signed. ------. Dockerfile:50. --------------------. 49 |. 50 | >>> RUN ./build-prereq.sh \. 51 | >>> && PATH=""${HOME}/bin:${PATH}"" ./build_release_binaries.sh # PATH for bazel. 52 |. --------------------. ERROR: failed to solve: process ""/bin/sh -c ./build-prereq.sh && PATH=\""${HOME}/bin:${PATH}\"" ./build_release_binaries.sh # PATH for bazel"" did not complete successfully: exit code: 100. ```. Looks like the repositories are either old or the sign has expired. How to fix this error?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/902
https://github.com/google/deepvariant/issues/902:2733,security,secur,security,2733,"tu 22.04. 0.101 ========== Load config settings. 0.103 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Install the runtime packages' starting. 0.104 ========== This script is only maintained for Ubuntu 22.04. 0.104 ========== Load config settings. 0.105 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Misc setup' starting. 1.955 W: GPG error: https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-updates InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-updates InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-backports InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-backports InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-security InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-security InRelease' is not signed. ------. Dockerfile:50. --------------------. 49 |. 50 | >>> RUN ./build-prereq.sh \. 51 | >>> && PATH=""${HOME}/bin:${PATH}"" ./build_release_binaries.sh # PATH for bazel. 52 |. --------------------. ERROR: failed to solve: process ""/bin/sh -c ./build-prereq.sh && PATH=\""${HOME}/bin:${PATH}\"" ./build_release_binaries.sh # PATH for bazel"" did not complete successfully: exit code: 100. ```. Looks like the repositories are either old or the sign has expired. How to fix this error?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/902
https://github.com/google/deepvariant/issues/902:2774,security,sign,signature,2774,"tu 22.04. 0.101 ========== Load config settings. 0.103 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Install the runtime packages' starting. 0.104 ========== This script is only maintained for Ubuntu 22.04. 0.104 ========== Load config settings. 0.105 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Misc setup' starting. 1.955 W: GPG error: https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-updates InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-updates InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-backports InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-backports InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-security InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-security InRelease' is not signed. ------. Dockerfile:50. --------------------. 49 |. 50 | >>> RUN ./build-prereq.sh \. 51 | >>> && PATH=""${HOME}/bin:${PATH}"" ./build_release_binaries.sh # PATH for bazel. 52 |. --------------------. ERROR: failed to solve: process ""/bin/sh -c ./build-prereq.sh && PATH=\""${HOME}/bin:${PATH}\"" ./build_release_binaries.sh # PATH for bazel"" did not complete successfully: exit code: 100. ```. Looks like the repositories are either old or the sign has expired. How to fix this error?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/902
https://github.com/google/deepvariant/issues/902:2869,security,secur,security,2869,"tu 22.04. 0.101 ========== Load config settings. 0.103 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Install the runtime packages' starting. 0.104 ========== This script is only maintained for Ubuntu 22.04. 0.104 ========== Load config settings. 0.105 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Misc setup' starting. 1.955 W: GPG error: https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-updates InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-updates InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-backports InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-backports InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-security InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-security InRelease' is not signed. ------. Dockerfile:50. --------------------. 49 |. 50 | >>> RUN ./build-prereq.sh \. 51 | >>> && PATH=""${HOME}/bin:${PATH}"" ./build_release_binaries.sh # PATH for bazel. 52 |. --------------------. ERROR: failed to solve: process ""/bin/sh -c ./build-prereq.sh && PATH=\""${HOME}/bin:${PATH}\"" ./build_release_binaries.sh # PATH for bazel"" did not complete successfully: exit code: 100. ```. Looks like the repositories are either old or the sign has expired. How to fix this error?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/902
https://github.com/google/deepvariant/issues/902:2896,security,sign,signed,2896,"tu 22.04. 0.101 ========== Load config settings. 0.103 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Install the runtime packages' starting. 0.104 ========== This script is only maintained for Ubuntu 22.04. 0.104 ========== Load config settings. 0.105 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Misc setup' starting. 1.955 W: GPG error: https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-updates InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-updates InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-backports InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-backports InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-security InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-security InRelease' is not signed. ------. Dockerfile:50. --------------------. 49 |. 50 | >>> RUN ./build-prereq.sh \. 51 | >>> && PATH=""${HOME}/bin:${PATH}"" ./build_release_binaries.sh # PATH for bazel. 52 |. --------------------. ERROR: failed to solve: process ""/bin/sh -c ./build-prereq.sh && PATH=\""${HOME}/bin:${PATH}\"" ./build_release_binaries.sh # PATH for bazel"" did not complete successfully: exit code: 100. ```. Looks like the repositories are either old or the sign has expired. How to fix this error?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/902
https://github.com/google/deepvariant/issues/902:3250,security,compl,complete,3250,"tu 22.04. 0.101 ========== Load config settings. 0.103 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Install the runtime packages' starting. 0.104 ========== This script is only maintained for Ubuntu 22.04. 0.104 ========== Load config settings. 0.105 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Misc setup' starting. 1.955 W: GPG error: https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-updates InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-updates InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-backports InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-backports InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-security InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-security InRelease' is not signed. ------. Dockerfile:50. --------------------. 49 |. 50 | >>> RUN ./build-prereq.sh \. 51 | >>> && PATH=""${HOME}/bin:${PATH}"" ./build_release_binaries.sh # PATH for bazel. 52 |. --------------------. ERROR: failed to solve: process ""/bin/sh -c ./build-prereq.sh && PATH=\""${HOME}/bin:${PATH}\"" ./build_release_binaries.sh # PATH for bazel"" did not complete successfully: exit code: 100. ```. Looks like the repositories are either old or the sign has expired. How to fix this error?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/902
https://github.com/google/deepvariant/issues/902:3344,security,sign,sign,3344,"tu 22.04. 0.101 ========== Load config settings. 0.103 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Install the runtime packages' starting. 0.104 ========== This script is only maintained for Ubuntu 22.04. 0.104 ========== Load config settings. 0.105 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Misc setup' starting. 1.955 W: GPG error: https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-updates InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-updates InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-backports InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-backports InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-security InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-security InRelease' is not signed. ------. Dockerfile:50. --------------------. 49 |. 50 | >>> RUN ./build-prereq.sh \. 51 | >>> && PATH=""${HOME}/bin:${PATH}"" ./build_release_binaries.sh # PATH for bazel. 52 |. --------------------. ERROR: failed to solve: process ""/bin/sh -c ./build-prereq.sh && PATH=\""${HOME}/bin:${PATH}\"" ./build_release_binaries.sh # PATH for bazel"" did not complete successfully: exit code: 100. ```. Looks like the repositories are either old or the sign has expired. How to fix this error?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/902
https://github.com/google/deepvariant/issues/902:3353,security,expir,expired,3353,"tu 22.04. 0.101 ========== Load config settings. 0.103 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Install the runtime packages' starting. 0.104 ========== This script is only maintained for Ubuntu 22.04. 0.104 ========== Load config settings. 0.105 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Misc setup' starting. 1.955 W: GPG error: https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-updates InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-updates InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-backports InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-backports InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-security InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-security InRelease' is not signed. ------. Dockerfile:50. --------------------. 49 |. 50 | >>> RUN ./build-prereq.sh \. 51 | >>> && PATH=""${HOME}/bin:${PATH}"" ./build_release_binaries.sh # PATH for bazel. 52 |. --------------------. ERROR: failed to solve: process ""/bin/sh -c ./build-prereq.sh && PATH=\""${HOME}/bin:${PATH}\"" ./build_release_binaries.sh # PATH for bazel"" did not complete successfully: exit code: 100. ```. Looks like the repositories are either old or the sign has expired. How to fix this error?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/902
https://github.com/google/deepvariant/issues/902:263,usability,command,command,263,"Unable to build docker image from source due to multiple reasons; I am trying to build the docker image of `deepvariant` but running into problems. I'm on `r1.7` branch and my branch is up to date. I am also facing the same issues on `r1.6.1` branch as well. The command I am using is the following -. ```. docker build --build-arg=FROM_IMAGE=nvidia/cuda:11.8.0-cudnn8-devel-ubuntu22.04 \. --build-arg=DV_GPU_BUILD=1 \. -t deepvariant_gpu . ```. I am building this docker image on my laptop (M3 macbook). #### PackagesNotFoundError error. The first error I get is -. ```. 1.247 Platform: linux-aarch64. 1.247 Collecting package metadata (repodata.json): ...working... done. 6.190 Solving environment: ...working... failed. 6.260. 6.260 PackagesNotFoundError: The following packages are not available from current channels:. 6.260. 6.260 - bioconda::samtools==1.15. 6.260 - bioconda::bcftools==1.15. 6.260. ```. I resolved this error by removing the version numbers. i.e., removed the `==1.15` from both the lines. #### Error in the build-prerunreq.sh script. Once, I cross the previous error, I get this error -. ```. > [builder 6/6] RUN ./build-prereq.sh && PATH=""${HOME}/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin"" ./build_release_binaries.sh # PATH for bazel:. 0.101 ========== This script is only maintained for Ubuntu 22.04. 0.101 ========== Load config settings. 0.103 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Install the runtime packages' starting. 0.104 ========== This script is only maintained for Ubuntu 22.04. 0.104 ========== Load config settings. 0.105 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Misc setup' starting. 1.955 W: GPG error: https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease' is not signed. 1.955 W: GPG e",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/902
https://github.com/google/deepvariant/issues/902:532,usability,error,error,532,"Unable to build docker image from source due to multiple reasons; I am trying to build the docker image of `deepvariant` but running into problems. I'm on `r1.7` branch and my branch is up to date. I am also facing the same issues on `r1.6.1` branch as well. The command I am using is the following -. ```. docker build --build-arg=FROM_IMAGE=nvidia/cuda:11.8.0-cudnn8-devel-ubuntu22.04 \. --build-arg=DV_GPU_BUILD=1 \. -t deepvariant_gpu . ```. I am building this docker image on my laptop (M3 macbook). #### PackagesNotFoundError error. The first error I get is -. ```. 1.247 Platform: linux-aarch64. 1.247 Collecting package metadata (repodata.json): ...working... done. 6.190 Solving environment: ...working... failed. 6.260. 6.260 PackagesNotFoundError: The following packages are not available from current channels:. 6.260. 6.260 - bioconda::samtools==1.15. 6.260 - bioconda::bcftools==1.15. 6.260. ```. I resolved this error by removing the version numbers. i.e., removed the `==1.15` from both the lines. #### Error in the build-prerunreq.sh script. Once, I cross the previous error, I get this error -. ```. > [builder 6/6] RUN ./build-prereq.sh && PATH=""${HOME}/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin"" ./build_release_binaries.sh # PATH for bazel:. 0.101 ========== This script is only maintained for Ubuntu 22.04. 0.101 ========== Load config settings. 0.103 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Install the runtime packages' starting. 0.104 ========== This script is only maintained for Ubuntu 22.04. 0.104 ========== Load config settings. 0.105 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Misc setup' starting. 1.955 W: GPG error: https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease' is not signed. 1.955 W: GPG e",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/902
https://github.com/google/deepvariant/issues/902:549,usability,error,error,549,"Unable to build docker image from source due to multiple reasons; I am trying to build the docker image of `deepvariant` but running into problems. I'm on `r1.7` branch and my branch is up to date. I am also facing the same issues on `r1.6.1` branch as well. The command I am using is the following -. ```. docker build --build-arg=FROM_IMAGE=nvidia/cuda:11.8.0-cudnn8-devel-ubuntu22.04 \. --build-arg=DV_GPU_BUILD=1 \. -t deepvariant_gpu . ```. I am building this docker image on my laptop (M3 macbook). #### PackagesNotFoundError error. The first error I get is -. ```. 1.247 Platform: linux-aarch64. 1.247 Collecting package metadata (repodata.json): ...working... done. 6.190 Solving environment: ...working... failed. 6.260. 6.260 PackagesNotFoundError: The following packages are not available from current channels:. 6.260. 6.260 - bioconda::samtools==1.15. 6.260 - bioconda::bcftools==1.15. 6.260. ```. I resolved this error by removing the version numbers. i.e., removed the `==1.15` from both the lines. #### Error in the build-prerunreq.sh script. Once, I cross the previous error, I get this error -. ```. > [builder 6/6] RUN ./build-prereq.sh && PATH=""${HOME}/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin"" ./build_release_binaries.sh # PATH for bazel:. 0.101 ========== This script is only maintained for Ubuntu 22.04. 0.101 ========== Load config settings. 0.103 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Install the runtime packages' starting. 0.104 ========== This script is only maintained for Ubuntu 22.04. 0.104 ========== Load config settings. 0.105 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Misc setup' starting. 1.955 W: GPG error: https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease' is not signed. 1.955 W: GPG e",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/902
https://github.com/google/deepvariant/issues/902:927,usability,error,error,927,"Unable to build docker image from source due to multiple reasons; I am trying to build the docker image of `deepvariant` but running into problems. I'm on `r1.7` branch and my branch is up to date. I am also facing the same issues on `r1.6.1` branch as well. The command I am using is the following -. ```. docker build --build-arg=FROM_IMAGE=nvidia/cuda:11.8.0-cudnn8-devel-ubuntu22.04 \. --build-arg=DV_GPU_BUILD=1 \. -t deepvariant_gpu . ```. I am building this docker image on my laptop (M3 macbook). #### PackagesNotFoundError error. The first error I get is -. ```. 1.247 Platform: linux-aarch64. 1.247 Collecting package metadata (repodata.json): ...working... done. 6.190 Solving environment: ...working... failed. 6.260. 6.260 PackagesNotFoundError: The following packages are not available from current channels:. 6.260. 6.260 - bioconda::samtools==1.15. 6.260 - bioconda::bcftools==1.15. 6.260. ```. I resolved this error by removing the version numbers. i.e., removed the `==1.15` from both the lines. #### Error in the build-prerunreq.sh script. Once, I cross the previous error, I get this error -. ```. > [builder 6/6] RUN ./build-prereq.sh && PATH=""${HOME}/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin"" ./build_release_binaries.sh # PATH for bazel:. 0.101 ========== This script is only maintained for Ubuntu 22.04. 0.101 ========== Load config settings. 0.103 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Install the runtime packages' starting. 0.104 ========== This script is only maintained for Ubuntu 22.04. 0.104 ========== Load config settings. 0.105 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Misc setup' starting. 1.955 W: GPG error: https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease' is not signed. 1.955 W: GPG e",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/902
https://github.com/google/deepvariant/issues/902:1019,usability,Error,Error,1019," image from source due to multiple reasons; I am trying to build the docker image of `deepvariant` but running into problems. I'm on `r1.7` branch and my branch is up to date. I am also facing the same issues on `r1.6.1` branch as well. The command I am using is the following -. ```. docker build --build-arg=FROM_IMAGE=nvidia/cuda:11.8.0-cudnn8-devel-ubuntu22.04 \. --build-arg=DV_GPU_BUILD=1 \. -t deepvariant_gpu . ```. I am building this docker image on my laptop (M3 macbook). #### PackagesNotFoundError error. The first error I get is -. ```. 1.247 Platform: linux-aarch64. 1.247 Collecting package metadata (repodata.json): ...working... done. 6.190 Solving environment: ...working... failed. 6.260. 6.260 PackagesNotFoundError: The following packages are not available from current channels:. 6.260. 6.260 - bioconda::samtools==1.15. 6.260 - bioconda::bcftools==1.15. 6.260. ```. I resolved this error by removing the version numbers. i.e., removed the `==1.15` from both the lines. #### Error in the build-prerunreq.sh script. Once, I cross the previous error, I get this error -. ```. > [builder 6/6] RUN ./build-prereq.sh && PATH=""${HOME}/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin"" ./build_release_binaries.sh # PATH for bazel:. 0.101 ========== This script is only maintained for Ubuntu 22.04. 0.101 ========== Load config settings. 0.103 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Install the runtime packages' starting. 0.104 ========== This script is only maintained for Ubuntu 22.04. 0.104 ========== Load config settings. 0.105 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Misc setup' starting. 1.955 W: GPG error: https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease' is not signed. 1.955 W: GPG error: http://ports.ubu",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/902
https://github.com/google/deepvariant/issues/902:1086,usability,error,error,1086,"e docker image of `deepvariant` but running into problems. I'm on `r1.7` branch and my branch is up to date. I am also facing the same issues on `r1.6.1` branch as well. The command I am using is the following -. ```. docker build --build-arg=FROM_IMAGE=nvidia/cuda:11.8.0-cudnn8-devel-ubuntu22.04 \. --build-arg=DV_GPU_BUILD=1 \. -t deepvariant_gpu . ```. I am building this docker image on my laptop (M3 macbook). #### PackagesNotFoundError error. The first error I get is -. ```. 1.247 Platform: linux-aarch64. 1.247 Collecting package metadata (repodata.json): ...working... done. 6.190 Solving environment: ...working... failed. 6.260. 6.260 PackagesNotFoundError: The following packages are not available from current channels:. 6.260. 6.260 - bioconda::samtools==1.15. 6.260 - bioconda::bcftools==1.15. 6.260. ```. I resolved this error by removing the version numbers. i.e., removed the `==1.15` from both the lines. #### Error in the build-prerunreq.sh script. Once, I cross the previous error, I get this error -. ```. > [builder 6/6] RUN ./build-prereq.sh && PATH=""${HOME}/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin"" ./build_release_binaries.sh # PATH for bazel:. 0.101 ========== This script is only maintained for Ubuntu 22.04. 0.101 ========== Load config settings. 0.103 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Install the runtime packages' starting. 0.104 ========== This script is only maintained for Ubuntu 22.04. 0.104 ========== Load config settings. 0.105 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Misc setup' starting. 1.955 W: GPG error: https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy InRelease: At least one invalid signatur",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/902
https://github.com/google/deepvariant/issues/902:1104,usability,error,error,1104,"`deepvariant` but running into problems. I'm on `r1.7` branch and my branch is up to date. I am also facing the same issues on `r1.6.1` branch as well. The command I am using is the following -. ```. docker build --build-arg=FROM_IMAGE=nvidia/cuda:11.8.0-cudnn8-devel-ubuntu22.04 \. --build-arg=DV_GPU_BUILD=1 \. -t deepvariant_gpu . ```. I am building this docker image on my laptop (M3 macbook). #### PackagesNotFoundError error. The first error I get is -. ```. 1.247 Platform: linux-aarch64. 1.247 Collecting package metadata (repodata.json): ...working... done. 6.190 Solving environment: ...working... failed. 6.260. 6.260 PackagesNotFoundError: The following packages are not available from current channels:. 6.260. 6.260 - bioconda::samtools==1.15. 6.260 - bioconda::bcftools==1.15. 6.260. ```. I resolved this error by removing the version numbers. i.e., removed the `==1.15` from both the lines. #### Error in the build-prerunreq.sh script. Once, I cross the previous error, I get this error -. ```. > [builder 6/6] RUN ./build-prereq.sh && PATH=""${HOME}/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin"" ./build_release_binaries.sh # PATH for bazel:. 0.101 ========== This script is only maintained for Ubuntu 22.04. 0.101 ========== Load config settings. 0.103 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Install the runtime packages' starting. 0.104 ========== This script is only maintained for Ubuntu 22.04. 0.104 ========== Load config settings. 0.105 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Misc setup' starting. 1.955 W: GPG error: https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy InRelease: At least one invalid signature was encountered.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/902
https://github.com/google/deepvariant/issues/902:1723,usability,error,error,1723,"60. 6.260 PackagesNotFoundError: The following packages are not available from current channels:. 6.260. 6.260 - bioconda::samtools==1.15. 6.260 - bioconda::bcftools==1.15. 6.260. ```. I resolved this error by removing the version numbers. i.e., removed the `==1.15` from both the lines. #### Error in the build-prerunreq.sh script. Once, I cross the previous error, I get this error -. ```. > [builder 6/6] RUN ./build-prereq.sh && PATH=""${HOME}/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin"" ./build_release_binaries.sh # PATH for bazel:. 0.101 ========== This script is only maintained for Ubuntu 22.04. 0.101 ========== Load config settings. 0.103 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Install the runtime packages' starting. 0.104 ========== This script is only maintained for Ubuntu 22.04. 0.104 ========== Load config settings. 0.105 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Misc setup' starting. 1.955 W: GPG error: https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-updates InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-updates InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-backports InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-backports InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/902
https://github.com/google/deepvariant/issues/902:1999,usability,error,error,1999," the lines. #### Error in the build-prerunreq.sh script. Once, I cross the previous error, I get this error -. ```. > [builder 6/6] RUN ./build-prereq.sh && PATH=""${HOME}/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin"" ./build_release_binaries.sh # PATH for bazel:. 0.101 ========== This script is only maintained for Ubuntu 22.04. 0.101 ========== Load config settings. 0.103 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Install the runtime packages' starting. 0.104 ========== This script is only maintained for Ubuntu 22.04. 0.104 ========== Load config settings. 0.105 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Misc setup' starting. 1.955 W: GPG error: https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-updates InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-updates InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-backports InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-backports InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-security InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-security InRelease' is not signed. ------. Dockerfile:50. --------------------. 49 |. 50 | >>> RUN ./build-prereq.sh \. 51 | >>> && P",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/902
https://github.com/google/deepvariant/issues/902:2215,usability,error,error,2215,":/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin"" ./build_release_binaries.sh # PATH for bazel:. 0.101 ========== This script is only maintained for Ubuntu 22.04. 0.101 ========== Load config settings. 0.103 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Install the runtime packages' starting. 0.104 ========== This script is only maintained for Ubuntu 22.04. 0.104 ========== Load config settings. 0.105 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Misc setup' starting. 1.955 W: GPG error: https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-updates InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-updates InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-backports InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-backports InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-security InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-security InRelease' is not signed. ------. Dockerfile:50. --------------------. 49 |. 50 | >>> RUN ./build-prereq.sh \. 51 | >>> && PATH=""${HOME}/bin:${PATH}"" ./build_release_binaries.sh # PATH for bazel. 52 |. --------------------. ERROR: failed to solve: process ""/bin/sh -c ./build-prereq.sh && PATH=\""${HOME}/bin:${PATH}\"" ./build_release_binari",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/902
https://github.com/google/deepvariant/issues/902:2447,usability,error,error,2447,"tu 22.04. 0.101 ========== Load config settings. 0.103 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Install the runtime packages' starting. 0.104 ========== This script is only maintained for Ubuntu 22.04. 0.104 ========== Load config settings. 0.105 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Misc setup' starting. 1.955 W: GPG error: https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-updates InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-updates InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-backports InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-backports InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-security InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-security InRelease' is not signed. ------. Dockerfile:50. --------------------. 49 |. 50 | >>> RUN ./build-prereq.sh \. 51 | >>> && PATH=""${HOME}/bin:${PATH}"" ./build_release_binaries.sh # PATH for bazel. 52 |. --------------------. ERROR: failed to solve: process ""/bin/sh -c ./build-prereq.sh && PATH=\""${HOME}/bin:${PATH}\"" ./build_release_binaries.sh # PATH for bazel"" did not complete successfully: exit code: 100. ```. Looks like the repositories are either old or the sign has expired. How to fix this error?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/902
https://github.com/google/deepvariant/issues/902:2683,usability,error,error,2683,"tu 22.04. 0.101 ========== Load config settings. 0.103 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Install the runtime packages' starting. 0.104 ========== This script is only maintained for Ubuntu 22.04. 0.104 ========== Load config settings. 0.105 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Misc setup' starting. 1.955 W: GPG error: https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-updates InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-updates InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-backports InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-backports InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-security InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-security InRelease' is not signed. ------. Dockerfile:50. --------------------. 49 |. 50 | >>> RUN ./build-prereq.sh \. 51 | >>> && PATH=""${HOME}/bin:${PATH}"" ./build_release_binaries.sh # PATH for bazel. 52 |. --------------------. ERROR: failed to solve: process ""/bin/sh -c ./build-prereq.sh && PATH=\""${HOME}/bin:${PATH}\"" ./build_release_binaries.sh # PATH for bazel"" did not complete successfully: exit code: 100. ```. Looks like the repositories are either old or the sign has expired. How to fix this error?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/902
https://github.com/google/deepvariant/issues/902:3102,usability,ERROR,ERROR,3102,"tu 22.04. 0.101 ========== Load config settings. 0.103 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Install the runtime packages' starting. 0.104 ========== This script is only maintained for Ubuntu 22.04. 0.104 ========== Load config settings. 0.105 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Misc setup' starting. 1.955 W: GPG error: https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-updates InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-updates InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-backports InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-backports InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-security InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-security InRelease' is not signed. ------. Dockerfile:50. --------------------. 49 |. 50 | >>> RUN ./build-prereq.sh \. 51 | >>> && PATH=""${HOME}/bin:${PATH}"" ./build_release_binaries.sh # PATH for bazel. 52 |. --------------------. ERROR: failed to solve: process ""/bin/sh -c ./build-prereq.sh && PATH=\""${HOME}/bin:${PATH}\"" ./build_release_binaries.sh # PATH for bazel"" did not complete successfully: exit code: 100. ```. Looks like the repositories are either old or the sign has expired. How to fix this error?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/902
https://github.com/google/deepvariant/issues/902:3378,usability,error,error,3378,"tu 22.04. 0.101 ========== Load config settings. 0.103 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Install the runtime packages' starting. 0.104 ========== This script is only maintained for Ubuntu 22.04. 0.104 ========== Load config settings. 0.105 ========== [Thu Oct 31 21:28:00 UTC 2024] Stage 'Misc setup' starting. 1.955 W: GPG error: https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/sbsa InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-updates InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-updates InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-backports InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-backports InRelease' is not signed. 1.955 W: GPG error: http://ports.ubuntu.com/ubuntu-ports jammy-security InRelease: At least one invalid signature was encountered. 1.955 E: The repository 'http://ports.ubuntu.com/ubuntu-ports jammy-security InRelease' is not signed. ------. Dockerfile:50. --------------------. 49 |. 50 | >>> RUN ./build-prereq.sh \. 51 | >>> && PATH=""${HOME}/bin:${PATH}"" ./build_release_binaries.sh # PATH for bazel. 52 |. --------------------. ERROR: failed to solve: process ""/bin/sh -c ./build-prereq.sh && PATH=\""${HOME}/bin:${PATH}\"" ./build_release_binaries.sh # PATH for bazel"" did not complete successfully: exit code: 100. ```. Looks like the repositories are either old or the sign has expired. How to fix this error?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/902
https://github.com/google/deepvariant/issues/903:5,availability,slo,slow,5,Very slow performave for make_example; I am running deepvariant using singularity:. I already tested it on the provided test files. singularity run --bind $bam_PATH/:/bam --bind $REFPATH:/ref deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --reads=/bam/HG002.SequelII.merged_15kb_20kb.pbmm2.GRCh38.haplotag.10x.bam --ref=/ref/GCA_000001405.15_GRCh38_no_alt_analysis_set.fa \. --output_vcf variants_HG002.vcf.gz --logging_dir calls/deepvariant/GRCh38/NA12886_HG002/ --num_shards 10 &. I was wondering what is the expected time for deepvariant on CCS reads? .,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/903
https://github.com/google/deepvariant/issues/903:150,interoperability,bind,bind,150,Very slow performave for make_example; I am running deepvariant using singularity:. I already tested it on the provided test files. singularity run --bind $bam_PATH/:/bam --bind $REFPATH:/ref deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --reads=/bam/HG002.SequelII.merged_15kb_20kb.pbmm2.GRCh38.haplotag.10x.bam --ref=/ref/GCA_000001405.15_GRCh38_no_alt_analysis_set.fa \. --output_vcf variants_HG002.vcf.gz --logging_dir calls/deepvariant/GRCh38/NA12886_HG002/ --num_shards 10 &. I was wondering what is the expected time for deepvariant on CCS reads? .,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/903
https://github.com/google/deepvariant/issues/903:173,interoperability,bind,bind,173,Very slow performave for make_example; I am running deepvariant using singularity:. I already tested it on the provided test files. singularity run --bind $bam_PATH/:/bam --bind $REFPATH:/ref deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --reads=/bam/HG002.SequelII.merged_15kb_20kb.pbmm2.GRCh38.haplotag.10x.bam --ref=/ref/GCA_000001405.15_GRCh38_no_alt_analysis_set.fa \. --output_vcf variants_HG002.vcf.gz --logging_dir calls/deepvariant/GRCh38/NA12886_HG002/ --num_shards 10 &. I was wondering what is the expected time for deepvariant on CCS reads? .,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/903
https://github.com/google/deepvariant/issues/903:150,modifiability,bind,bind,150,Very slow performave for make_example; I am running deepvariant using singularity:. I already tested it on the provided test files. singularity run --bind $bam_PATH/:/bam --bind $REFPATH:/ref deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --reads=/bam/HG002.SequelII.merged_15kb_20kb.pbmm2.GRCh38.haplotag.10x.bam --ref=/ref/GCA_000001405.15_GRCh38_no_alt_analysis_set.fa \. --output_vcf variants_HG002.vcf.gz --logging_dir calls/deepvariant/GRCh38/NA12886_HG002/ --num_shards 10 &. I was wondering what is the expected time for deepvariant on CCS reads? .,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/903
https://github.com/google/deepvariant/issues/903:173,modifiability,bind,bind,173,Very slow performave for make_example; I am running deepvariant using singularity:. I already tested it on the provided test files. singularity run --bind $bam_PATH/:/bam --bind $REFPATH:/ref deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --reads=/bam/HG002.SequelII.merged_15kb_20kb.pbmm2.GRCh38.haplotag.10x.bam --ref=/ref/GCA_000001405.15_GRCh38_no_alt_analysis_set.fa \. --output_vcf variants_HG002.vcf.gz --logging_dir calls/deepvariant/GRCh38/NA12886_HG002/ --num_shards 10 &. I was wondering what is the expected time for deepvariant on CCS reads? .,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/903
https://github.com/google/deepvariant/issues/903:267,modifiability,PAC,PACBIO,267,Very slow performave for make_example; I am running deepvariant using singularity:. I already tested it on the provided test files. singularity run --bind $bam_PATH/:/bam --bind $REFPATH:/ref deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --reads=/bam/HG002.SequelII.merged_15kb_20kb.pbmm2.GRCh38.haplotag.10x.bam --ref=/ref/GCA_000001405.15_GRCh38_no_alt_analysis_set.fa \. --output_vcf variants_HG002.vcf.gz --logging_dir calls/deepvariant/GRCh38/NA12886_HG002/ --num_shards 10 &. I was wondering what is the expected time for deepvariant on CCS reads? .,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/903
https://github.com/google/deepvariant/issues/903:10,performance,perform,performave,10,Very slow performave for make_example; I am running deepvariant using singularity:. I already tested it on the provided test files. singularity run --bind $bam_PATH/:/bam --bind $REFPATH:/ref deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --reads=/bam/HG002.SequelII.merged_15kb_20kb.pbmm2.GRCh38.haplotag.10x.bam --ref=/ref/GCA_000001405.15_GRCh38_no_alt_analysis_set.fa \. --output_vcf variants_HG002.vcf.gz --logging_dir calls/deepvariant/GRCh38/NA12886_HG002/ --num_shards 10 &. I was wondering what is the expected time for deepvariant on CCS reads? .,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/903
https://github.com/google/deepvariant/issues/903:555,performance,time,time,555,Very slow performave for make_example; I am running deepvariant using singularity:. I already tested it on the provided test files. singularity run --bind $bam_PATH/:/bam --bind $REFPATH:/ref deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --reads=/bam/HG002.SequelII.merged_15kb_20kb.pbmm2.GRCh38.haplotag.10x.bam --ref=/ref/GCA_000001405.15_GRCh38_no_alt_analysis_set.fa \. --output_vcf variants_HG002.vcf.gz --logging_dir calls/deepvariant/GRCh38/NA12886_HG002/ --num_shards 10 &. I was wondering what is the expected time for deepvariant on CCS reads? .,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/903
https://github.com/google/deepvariant/issues/903:5,reliability,slo,slow,5,Very slow performave for make_example; I am running deepvariant using singularity:. I already tested it on the provided test files. singularity run --bind $bam_PATH/:/bam --bind $REFPATH:/ref deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --reads=/bam/HG002.SequelII.merged_15kb_20kb.pbmm2.GRCh38.haplotag.10x.bam --ref=/ref/GCA_000001405.15_GRCh38_no_alt_analysis_set.fa \. --output_vcf variants_HG002.vcf.gz --logging_dir calls/deepvariant/GRCh38/NA12886_HG002/ --num_shards 10 &. I was wondering what is the expected time for deepvariant on CCS reads? .,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/903
https://github.com/google/deepvariant/issues/903:94,safety,test,tested,94,Very slow performave for make_example; I am running deepvariant using singularity:. I already tested it on the provided test files. singularity run --bind $bam_PATH/:/bam --bind $REFPATH:/ref deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --reads=/bam/HG002.SequelII.merged_15kb_20kb.pbmm2.GRCh38.haplotag.10x.bam --ref=/ref/GCA_000001405.15_GRCh38_no_alt_analysis_set.fa \. --output_vcf variants_HG002.vcf.gz --logging_dir calls/deepvariant/GRCh38/NA12886_HG002/ --num_shards 10 &. I was wondering what is the expected time for deepvariant on CCS reads? .,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/903
https://github.com/google/deepvariant/issues/903:120,safety,test,test,120,Very slow performave for make_example; I am running deepvariant using singularity:. I already tested it on the provided test files. singularity run --bind $bam_PATH/:/bam --bind $REFPATH:/ref deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --reads=/bam/HG002.SequelII.merged_15kb_20kb.pbmm2.GRCh38.haplotag.10x.bam --ref=/ref/GCA_000001405.15_GRCh38_no_alt_analysis_set.fa \. --output_vcf variants_HG002.vcf.gz --logging_dir calls/deepvariant/GRCh38/NA12886_HG002/ --num_shards 10 &. I was wondering what is the expected time for deepvariant on CCS reads? .,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/903
https://github.com/google/deepvariant/issues/903:94,testability,test,tested,94,Very slow performave for make_example; I am running deepvariant using singularity:. I already tested it on the provided test files. singularity run --bind $bam_PATH/:/bam --bind $REFPATH:/ref deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --reads=/bam/HG002.SequelII.merged_15kb_20kb.pbmm2.GRCh38.haplotag.10x.bam --ref=/ref/GCA_000001405.15_GRCh38_no_alt_analysis_set.fa \. --output_vcf variants_HG002.vcf.gz --logging_dir calls/deepvariant/GRCh38/NA12886_HG002/ --num_shards 10 &. I was wondering what is the expected time for deepvariant on CCS reads? .,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/903
https://github.com/google/deepvariant/issues/903:120,testability,test,test,120,Very slow performave for make_example; I am running deepvariant using singularity:. I already tested it on the provided test files. singularity run --bind $bam_PATH/:/bam --bind $REFPATH:/ref deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --reads=/bam/HG002.SequelII.merged_15kb_20kb.pbmm2.GRCh38.haplotag.10x.bam --ref=/ref/GCA_000001405.15_GRCh38_no_alt_analysis_set.fa \. --output_vcf variants_HG002.vcf.gz --logging_dir calls/deepvariant/GRCh38/NA12886_HG002/ --num_shards 10 &. I was wondering what is the expected time for deepvariant on CCS reads? .,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/903
https://github.com/google/deepvariant/issues/903:10,usability,perform,performave,10,Very slow performave for make_example; I am running deepvariant using singularity:. I already tested it on the provided test files. singularity run --bind $bam_PATH/:/bam --bind $REFPATH:/ref deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --reads=/bam/HG002.SequelII.merged_15kb_20kb.pbmm2.GRCh38.haplotag.10x.bam --ref=/ref/GCA_000001405.15_GRCh38_no_alt_analysis_set.fa \. --output_vcf variants_HG002.vcf.gz --logging_dir calls/deepvariant/GRCh38/NA12886_HG002/ --num_shards 10 &. I was wondering what is the expected time for deepvariant on CCS reads? .,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/903
https://github.com/google/deepvariant/issues/904:454,availability,reliab,reliable,454,"Low hom_ref recall during model training for new organism; Dear Devs, . I am currently training a model (starting from wgs.1.6.1) for use in a fish species. The programs are running well, I have confident regions and truth variants defined, and am currently tuning hyperparameters to optimise the training. . However . . . . I notice when tracking the model eval stats (specifically f1, precision, recall), that the hom_ref classifications are much less reliable than hom_alt and het classes. My question is whether this is to be expected, or whether there might be something wrong with my training setup, or perhaps the examples. . The test example set I am using to tune the hyperparams looks like this:. ```. # Generated by shuffle_tfrecords_beam.py. # class2: 89987. # class0: 33161. # class1: 24300. name: ""Shuffle_global"". tfrecord_path: ""/home/examples_shuffled/train/shuf_test/examples_shuf3_testset.shuffled-?????-of-?????.tfrecord.gz"". num_examples: 147448. ```. The training command looks like this:. ```. LR=0.001. BS=1024. apptainer run \. --nv \. -B $WD:/home \. $DV_PATH \. /opt/deepvariant/bin/train \. --config=/home/dv_config.py:base \. --config.train_dataset_pbtxt=""/home/examples_shuffled/train/shuf_test/examples_shuf3_testset_config.pbtxt"" \. --config.tune_dataset_pbtxt=""/home/examples_shuffled/tune_test/tune_test_examples_config.pbtxt"" \. --config.num_epochs=1 \. --config.learning_rate=${LR} \. --config.num_validation_examples=0 \. --config.tune_every_steps=2000 \. --experiment_dir=/home/${OUTDIR} \. --strategy=mirrored \. --config.batch_size=${BS} \. --config.init_checkpoint=""/home/model_wgs_v1.6.1/deepvariant.wgs.ckpt"". ```. During other tests I have run training jobs with several other example sets (several times larger), for tens of thousands of steps and multiple epochs, and also using different learning rates and batch sizes. While these things of course make a difference to learning performance, the lower recall for class 0 (hom_ref) remains consistent. . ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/904
https://github.com/google/deepvariant/issues/904:1986,availability,consist,consistent,1986,"nd looks like this:. ```. LR=0.001. BS=1024. apptainer run \. --nv \. -B $WD:/home \. $DV_PATH \. /opt/deepvariant/bin/train \. --config=/home/dv_config.py:base \. --config.train_dataset_pbtxt=""/home/examples_shuffled/train/shuf_test/examples_shuf3_testset_config.pbtxt"" \. --config.tune_dataset_pbtxt=""/home/examples_shuffled/tune_test/tune_test_examples_config.pbtxt"" \. --config.num_epochs=1 \. --config.learning_rate=${LR} \. --config.num_validation_examples=0 \. --config.tune_every_steps=2000 \. --experiment_dir=/home/${OUTDIR} \. --strategy=mirrored \. --config.batch_size=${BS} \. --config.init_checkpoint=""/home/model_wgs_v1.6.1/deepvariant.wgs.ckpt"". ```. During other tests I have run training jobs with several other example sets (several times larger), for tens of thousands of steps and multiple epochs, and also using different learning rates and batch sizes. While these things of course make a difference to learning performance, the lower recall for class 0 (hom_ref) remains consistent. . Here are some lines from the log file during one such training run:. ```. I1031 10:55:27.365902 140558597089024 logging_writer.py:48] [0] epoch=0, train/categorical_accuracy=0.91796875, train/categorical_crossentropy=0.6384725570678711, train/f1_het=0.7428571581840515, train/f1_homalt=0.964401364326477, train/f1_homref=0.902255654335022, train/f1_macro=0. 8698380589485168, train/f1_micro=0.91796875, train/f1_weighted=0.9241795539855957, train/false_negatives=34.0, train/false_positives=14.0, train/learning_rate=9.999999747378752e-06, train/loss=0.6384731531143188, train/precision=0.9406779408454895, train/precision_het=0.702702701091. 7664, train/precision_homalt=0.978723406791687, train/precision_homref=1.0, train/recall=0.8671875, train/recall_het=1.0, train/recall_homalt=0.8789808750152588, train/recall_homref=0.7945205569267273, train/true_negatives=498.0, train/true_positives=222.0. I1031 11:18:53.873582 140558597089024 logging_writer.py:48] [100] epoch=0, train/categoric",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/904
https://github.com/google/deepvariant/issues/904:2029,deployability,log,log,2029,"024. apptainer run \. --nv \. -B $WD:/home \. $DV_PATH \. /opt/deepvariant/bin/train \. --config=/home/dv_config.py:base \. --config.train_dataset_pbtxt=""/home/examples_shuffled/train/shuf_test/examples_shuf3_testset_config.pbtxt"" \. --config.tune_dataset_pbtxt=""/home/examples_shuffled/tune_test/tune_test_examples_config.pbtxt"" \. --config.num_epochs=1 \. --config.learning_rate=${LR} \. --config.num_validation_examples=0 \. --config.tune_every_steps=2000 \. --experiment_dir=/home/${OUTDIR} \. --strategy=mirrored \. --config.batch_size=${BS} \. --config.init_checkpoint=""/home/model_wgs_v1.6.1/deepvariant.wgs.ckpt"". ```. During other tests I have run training jobs with several other example sets (several times larger), for tens of thousands of steps and multiple epochs, and also using different learning rates and batch sizes. While these things of course make a difference to learning performance, the lower recall for class 0 (hom_ref) remains consistent. . Here are some lines from the log file during one such training run:. ```. I1031 10:55:27.365902 140558597089024 logging_writer.py:48] [0] epoch=0, train/categorical_accuracy=0.91796875, train/categorical_crossentropy=0.6384725570678711, train/f1_het=0.7428571581840515, train/f1_homalt=0.964401364326477, train/f1_homref=0.902255654335022, train/f1_macro=0. 8698380589485168, train/f1_micro=0.91796875, train/f1_weighted=0.9241795539855957, train/false_negatives=34.0, train/false_positives=14.0, train/learning_rate=9.999999747378752e-06, train/loss=0.6384731531143188, train/precision=0.9406779408454895, train/precision_het=0.702702701091. 7664, train/precision_homalt=0.978723406791687, train/precision_homref=1.0, train/recall=0.8671875, train/recall_het=1.0, train/recall_homalt=0.8789808750152588, train/recall_homref=0.7945205569267273, train/true_negatives=498.0, train/true_positives=222.0. I1031 11:18:53.873582 140558597089024 logging_writer.py:48] [100] epoch=0, train/categorical_accuracy=0.9428125023841858, train/ca",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/904
https://github.com/google/deepvariant/issues/904:26,energy efficiency,model,model,26,"Low hom_ref recall during model training for new organism; Dear Devs, . I am currently training a model (starting from wgs.1.6.1) for use in a fish species. The programs are running well, I have confident regions and truth variants defined, and am currently tuning hyperparameters to optimise the training. . However . . . . I notice when tracking the model eval stats (specifically f1, precision, recall), that the hom_ref classifications are much less reliable than hom_alt and het classes. My question is whether this is to be expected, or whether there might be something wrong with my training setup, or perhaps the examples. . The test example set I am using to tune the hyperparams looks like this:. ```. # Generated by shuffle_tfrecords_beam.py. # class2: 89987. # class0: 33161. # class1: 24300. name: ""Shuffle_global"". tfrecord_path: ""/home/examples_shuffled/train/shuf_test/examples_shuf3_testset.shuffled-?????-of-?????.tfrecord.gz"". num_examples: 147448. ```. The training command looks like this:. ```. LR=0.001. BS=1024. apptainer run \. --nv \. -B $WD:/home \. $DV_PATH \. /opt/deepvariant/bin/train \. --config=/home/dv_config.py:base \. --config.train_dataset_pbtxt=""/home/examples_shuffled/train/shuf_test/examples_shuf3_testset_config.pbtxt"" \. --config.tune_dataset_pbtxt=""/home/examples_shuffled/tune_test/tune_test_examples_config.pbtxt"" \. --config.num_epochs=1 \. --config.learning_rate=${LR} \. --config.num_validation_examples=0 \. --config.tune_every_steps=2000 \. --experiment_dir=/home/${OUTDIR} \. --strategy=mirrored \. --config.batch_size=${BS} \. --config.init_checkpoint=""/home/model_wgs_v1.6.1/deepvariant.wgs.ckpt"". ```. During other tests I have run training jobs with several other example sets (several times larger), for tens of thousands of steps and multiple epochs, and also using different learning rates and batch sizes. While these things of course make a difference to learning performance, the lower recall for class 0 (hom_ref) remains consistent. . ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/904
https://github.com/google/deepvariant/issues/904:77,energy efficiency,current,currently,77,"Low hom_ref recall during model training for new organism; Dear Devs, . I am currently training a model (starting from wgs.1.6.1) for use in a fish species. The programs are running well, I have confident regions and truth variants defined, and am currently tuning hyperparameters to optimise the training. . However . . . . I notice when tracking the model eval stats (specifically f1, precision, recall), that the hom_ref classifications are much less reliable than hom_alt and het classes. My question is whether this is to be expected, or whether there might be something wrong with my training setup, or perhaps the examples. . The test example set I am using to tune the hyperparams looks like this:. ```. # Generated by shuffle_tfrecords_beam.py. # class2: 89987. # class0: 33161. # class1: 24300. name: ""Shuffle_global"". tfrecord_path: ""/home/examples_shuffled/train/shuf_test/examples_shuf3_testset.shuffled-?????-of-?????.tfrecord.gz"". num_examples: 147448. ```. The training command looks like this:. ```. LR=0.001. BS=1024. apptainer run \. --nv \. -B $WD:/home \. $DV_PATH \. /opt/deepvariant/bin/train \. --config=/home/dv_config.py:base \. --config.train_dataset_pbtxt=""/home/examples_shuffled/train/shuf_test/examples_shuf3_testset_config.pbtxt"" \. --config.tune_dataset_pbtxt=""/home/examples_shuffled/tune_test/tune_test_examples_config.pbtxt"" \. --config.num_epochs=1 \. --config.learning_rate=${LR} \. --config.num_validation_examples=0 \. --config.tune_every_steps=2000 \. --experiment_dir=/home/${OUTDIR} \. --strategy=mirrored \. --config.batch_size=${BS} \. --config.init_checkpoint=""/home/model_wgs_v1.6.1/deepvariant.wgs.ckpt"". ```. During other tests I have run training jobs with several other example sets (several times larger), for tens of thousands of steps and multiple epochs, and also using different learning rates and batch sizes. While these things of course make a difference to learning performance, the lower recall for class 0 (hom_ref) remains consistent. . ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/904
https://github.com/google/deepvariant/issues/904:98,energy efficiency,model,model,98,"Low hom_ref recall during model training for new organism; Dear Devs, . I am currently training a model (starting from wgs.1.6.1) for use in a fish species. The programs are running well, I have confident regions and truth variants defined, and am currently tuning hyperparameters to optimise the training. . However . . . . I notice when tracking the model eval stats (specifically f1, precision, recall), that the hom_ref classifications are much less reliable than hom_alt and het classes. My question is whether this is to be expected, or whether there might be something wrong with my training setup, or perhaps the examples. . The test example set I am using to tune the hyperparams looks like this:. ```. # Generated by shuffle_tfrecords_beam.py. # class2: 89987. # class0: 33161. # class1: 24300. name: ""Shuffle_global"". tfrecord_path: ""/home/examples_shuffled/train/shuf_test/examples_shuf3_testset.shuffled-?????-of-?????.tfrecord.gz"". num_examples: 147448. ```. The training command looks like this:. ```. LR=0.001. BS=1024. apptainer run \. --nv \. -B $WD:/home \. $DV_PATH \. /opt/deepvariant/bin/train \. --config=/home/dv_config.py:base \. --config.train_dataset_pbtxt=""/home/examples_shuffled/train/shuf_test/examples_shuf3_testset_config.pbtxt"" \. --config.tune_dataset_pbtxt=""/home/examples_shuffled/tune_test/tune_test_examples_config.pbtxt"" \. --config.num_epochs=1 \. --config.learning_rate=${LR} \. --config.num_validation_examples=0 \. --config.tune_every_steps=2000 \. --experiment_dir=/home/${OUTDIR} \. --strategy=mirrored \. --config.batch_size=${BS} \. --config.init_checkpoint=""/home/model_wgs_v1.6.1/deepvariant.wgs.ckpt"". ```. During other tests I have run training jobs with several other example sets (several times larger), for tens of thousands of steps and multiple epochs, and also using different learning rates and batch sizes. While these things of course make a difference to learning performance, the lower recall for class 0 (hom_ref) remains consistent. . ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/904
https://github.com/google/deepvariant/issues/904:248,energy efficiency,current,currently,248,"Low hom_ref recall during model training for new organism; Dear Devs, . I am currently training a model (starting from wgs.1.6.1) for use in a fish species. The programs are running well, I have confident regions and truth variants defined, and am currently tuning hyperparameters to optimise the training. . However . . . . I notice when tracking the model eval stats (specifically f1, precision, recall), that the hom_ref classifications are much less reliable than hom_alt and het classes. My question is whether this is to be expected, or whether there might be something wrong with my training setup, or perhaps the examples. . The test example set I am using to tune the hyperparams looks like this:. ```. # Generated by shuffle_tfrecords_beam.py. # class2: 89987. # class0: 33161. # class1: 24300. name: ""Shuffle_global"". tfrecord_path: ""/home/examples_shuffled/train/shuf_test/examples_shuf3_testset.shuffled-?????-of-?????.tfrecord.gz"". num_examples: 147448. ```. The training command looks like this:. ```. LR=0.001. BS=1024. apptainer run \. --nv \. -B $WD:/home \. $DV_PATH \. /opt/deepvariant/bin/train \. --config=/home/dv_config.py:base \. --config.train_dataset_pbtxt=""/home/examples_shuffled/train/shuf_test/examples_shuf3_testset_config.pbtxt"" \. --config.tune_dataset_pbtxt=""/home/examples_shuffled/tune_test/tune_test_examples_config.pbtxt"" \. --config.num_epochs=1 \. --config.learning_rate=${LR} \. --config.num_validation_examples=0 \. --config.tune_every_steps=2000 \. --experiment_dir=/home/${OUTDIR} \. --strategy=mirrored \. --config.batch_size=${BS} \. --config.init_checkpoint=""/home/model_wgs_v1.6.1/deepvariant.wgs.ckpt"". ```. During other tests I have run training jobs with several other example sets (several times larger), for tens of thousands of steps and multiple epochs, and also using different learning rates and batch sizes. While these things of course make a difference to learning performance, the lower recall for class 0 (hom_ref) remains consistent. . ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/904
https://github.com/google/deepvariant/issues/904:284,energy efficiency,optim,optimise,284,"Low hom_ref recall during model training for new organism; Dear Devs, . I am currently training a model (starting from wgs.1.6.1) for use in a fish species. The programs are running well, I have confident regions and truth variants defined, and am currently tuning hyperparameters to optimise the training. . However . . . . I notice when tracking the model eval stats (specifically f1, precision, recall), that the hom_ref classifications are much less reliable than hom_alt and het classes. My question is whether this is to be expected, or whether there might be something wrong with my training setup, or perhaps the examples. . The test example set I am using to tune the hyperparams looks like this:. ```. # Generated by shuffle_tfrecords_beam.py. # class2: 89987. # class0: 33161. # class1: 24300. name: ""Shuffle_global"". tfrecord_path: ""/home/examples_shuffled/train/shuf_test/examples_shuf3_testset.shuffled-?????-of-?????.tfrecord.gz"". num_examples: 147448. ```. The training command looks like this:. ```. LR=0.001. BS=1024. apptainer run \. --nv \. -B $WD:/home \. $DV_PATH \. /opt/deepvariant/bin/train \. --config=/home/dv_config.py:base \. --config.train_dataset_pbtxt=""/home/examples_shuffled/train/shuf_test/examples_shuf3_testset_config.pbtxt"" \. --config.tune_dataset_pbtxt=""/home/examples_shuffled/tune_test/tune_test_examples_config.pbtxt"" \. --config.num_epochs=1 \. --config.learning_rate=${LR} \. --config.num_validation_examples=0 \. --config.tune_every_steps=2000 \. --experiment_dir=/home/${OUTDIR} \. --strategy=mirrored \. --config.batch_size=${BS} \. --config.init_checkpoint=""/home/model_wgs_v1.6.1/deepvariant.wgs.ckpt"". ```. During other tests I have run training jobs with several other example sets (several times larger), for tens of thousands of steps and multiple epochs, and also using different learning rates and batch sizes. While these things of course make a difference to learning performance, the lower recall for class 0 (hom_ref) remains consistent. . ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/904
https://github.com/google/deepvariant/issues/904:352,energy efficiency,model,model,352,"Low hom_ref recall during model training for new organism; Dear Devs, . I am currently training a model (starting from wgs.1.6.1) for use in a fish species. The programs are running well, I have confident regions and truth variants defined, and am currently tuning hyperparameters to optimise the training. . However . . . . I notice when tracking the model eval stats (specifically f1, precision, recall), that the hom_ref classifications are much less reliable than hom_alt and het classes. My question is whether this is to be expected, or whether there might be something wrong with my training setup, or perhaps the examples. . The test example set I am using to tune the hyperparams looks like this:. ```. # Generated by shuffle_tfrecords_beam.py. # class2: 89987. # class0: 33161. # class1: 24300. name: ""Shuffle_global"". tfrecord_path: ""/home/examples_shuffled/train/shuf_test/examples_shuf3_testset.shuffled-?????-of-?????.tfrecord.gz"". num_examples: 147448. ```. The training command looks like this:. ```. LR=0.001. BS=1024. apptainer run \. --nv \. -B $WD:/home \. $DV_PATH \. /opt/deepvariant/bin/train \. --config=/home/dv_config.py:base \. --config.train_dataset_pbtxt=""/home/examples_shuffled/train/shuf_test/examples_shuf3_testset_config.pbtxt"" \. --config.tune_dataset_pbtxt=""/home/examples_shuffled/tune_test/tune_test_examples_config.pbtxt"" \. --config.num_epochs=1 \. --config.learning_rate=${LR} \. --config.num_validation_examples=0 \. --config.tune_every_steps=2000 \. --experiment_dir=/home/${OUTDIR} \. --strategy=mirrored \. --config.batch_size=${BS} \. --config.init_checkpoint=""/home/model_wgs_v1.6.1/deepvariant.wgs.ckpt"". ```. During other tests I have run training jobs with several other example sets (several times larger), for tens of thousands of steps and multiple epochs, and also using different learning rates and batch sizes. While these things of course make a difference to learning performance, the lower recall for class 0 (hom_ref) remains consistent. . ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/904
https://github.com/google/deepvariant/issues/904:1854,integrability,batch,batch,1854,"es_shuffled/train/shuf_test/examples_shuf3_testset.shuffled-?????-of-?????.tfrecord.gz"". num_examples: 147448. ```. The training command looks like this:. ```. LR=0.001. BS=1024. apptainer run \. --nv \. -B $WD:/home \. $DV_PATH \. /opt/deepvariant/bin/train \. --config=/home/dv_config.py:base \. --config.train_dataset_pbtxt=""/home/examples_shuffled/train/shuf_test/examples_shuf3_testset_config.pbtxt"" \. --config.tune_dataset_pbtxt=""/home/examples_shuffled/tune_test/tune_test_examples_config.pbtxt"" \. --config.num_epochs=1 \. --config.learning_rate=${LR} \. --config.num_validation_examples=0 \. --config.tune_every_steps=2000 \. --experiment_dir=/home/${OUTDIR} \. --strategy=mirrored \. --config.batch_size=${BS} \. --config.init_checkpoint=""/home/model_wgs_v1.6.1/deepvariant.wgs.ckpt"". ```. During other tests I have run training jobs with several other example sets (several times larger), for tens of thousands of steps and multiple epochs, and also using different learning rates and batch sizes. While these things of course make a difference to learning performance, the lower recall for class 0 (hom_ref) remains consistent. . Here are some lines from the log file during one such training run:. ```. I1031 10:55:27.365902 140558597089024 logging_writer.py:48] [0] epoch=0, train/categorical_accuracy=0.91796875, train/categorical_crossentropy=0.6384725570678711, train/f1_het=0.7428571581840515, train/f1_homalt=0.964401364326477, train/f1_homref=0.902255654335022, train/f1_macro=0. 8698380589485168, train/f1_micro=0.91796875, train/f1_weighted=0.9241795539855957, train/false_negatives=34.0, train/false_positives=14.0, train/learning_rate=9.999999747378752e-06, train/loss=0.6384731531143188, train/precision=0.9406779408454895, train/precision_het=0.702702701091. 7664, train/precision_homalt=0.978723406791687, train/precision_homref=1.0, train/recall=0.8671875, train/recall_het=1.0, train/recall_homalt=0.8789808750152588, train/recall_homref=0.7945205569267273, train/true_n",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/904
https://github.com/google/deepvariant/issues/904:370,interoperability,specif,specifically,370,"Low hom_ref recall during model training for new organism; Dear Devs, . I am currently training a model (starting from wgs.1.6.1) for use in a fish species. The programs are running well, I have confident regions and truth variants defined, and am currently tuning hyperparameters to optimise the training. . However . . . . I notice when tracking the model eval stats (specifically f1, precision, recall), that the hom_ref classifications are much less reliable than hom_alt and het classes. My question is whether this is to be expected, or whether there might be something wrong with my training setup, or perhaps the examples. . The test example set I am using to tune the hyperparams looks like this:. ```. # Generated by shuffle_tfrecords_beam.py. # class2: 89987. # class0: 33161. # class1: 24300. name: ""Shuffle_global"". tfrecord_path: ""/home/examples_shuffled/train/shuf_test/examples_shuf3_testset.shuffled-?????-of-?????.tfrecord.gz"". num_examples: 147448. ```. The training command looks like this:. ```. LR=0.001. BS=1024. apptainer run \. --nv \. -B $WD:/home \. $DV_PATH \. /opt/deepvariant/bin/train \. --config=/home/dv_config.py:base \. --config.train_dataset_pbtxt=""/home/examples_shuffled/train/shuf_test/examples_shuf3_testset_config.pbtxt"" \. --config.tune_dataset_pbtxt=""/home/examples_shuffled/tune_test/tune_test_examples_config.pbtxt"" \. --config.num_epochs=1 \. --config.learning_rate=${LR} \. --config.num_validation_examples=0 \. --config.tune_every_steps=2000 \. --experiment_dir=/home/${OUTDIR} \. --strategy=mirrored \. --config.batch_size=${BS} \. --config.init_checkpoint=""/home/model_wgs_v1.6.1/deepvariant.wgs.ckpt"". ```. During other tests I have run training jobs with several other example sets (several times larger), for tens of thousands of steps and multiple epochs, and also using different learning rates and batch sizes. While these things of course make a difference to learning performance, the lower recall for class 0 (hom_ref) remains consistent. . ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/904
https://github.com/google/deepvariant/issues/904:668,performance,tune,tune,668,"Low hom_ref recall during model training for new organism; Dear Devs, . I am currently training a model (starting from wgs.1.6.1) for use in a fish species. The programs are running well, I have confident regions and truth variants defined, and am currently tuning hyperparameters to optimise the training. . However . . . . I notice when tracking the model eval stats (specifically f1, precision, recall), that the hom_ref classifications are much less reliable than hom_alt and het classes. My question is whether this is to be expected, or whether there might be something wrong with my training setup, or perhaps the examples. . The test example set I am using to tune the hyperparams looks like this:. ```. # Generated by shuffle_tfrecords_beam.py. # class2: 89987. # class0: 33161. # class1: 24300. name: ""Shuffle_global"". tfrecord_path: ""/home/examples_shuffled/train/shuf_test/examples_shuf3_testset.shuffled-?????-of-?????.tfrecord.gz"". num_examples: 147448. ```. The training command looks like this:. ```. LR=0.001. BS=1024. apptainer run \. --nv \. -B $WD:/home \. $DV_PATH \. /opt/deepvariant/bin/train \. --config=/home/dv_config.py:base \. --config.train_dataset_pbtxt=""/home/examples_shuffled/train/shuf_test/examples_shuf3_testset_config.pbtxt"" \. --config.tune_dataset_pbtxt=""/home/examples_shuffled/tune_test/tune_test_examples_config.pbtxt"" \. --config.num_epochs=1 \. --config.learning_rate=${LR} \. --config.num_validation_examples=0 \. --config.tune_every_steps=2000 \. --experiment_dir=/home/${OUTDIR} \. --strategy=mirrored \. --config.batch_size=${BS} \. --config.init_checkpoint=""/home/model_wgs_v1.6.1/deepvariant.wgs.ckpt"". ```. During other tests I have run training jobs with several other example sets (several times larger), for tens of thousands of steps and multiple epochs, and also using different learning rates and batch sizes. While these things of course make a difference to learning performance, the lower recall for class 0 (hom_ref) remains consistent. . ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/904
https://github.com/google/deepvariant/issues/904:1743,performance,time,times,1743,"eam.py. # class2: 89987. # class0: 33161. # class1: 24300. name: ""Shuffle_global"". tfrecord_path: ""/home/examples_shuffled/train/shuf_test/examples_shuf3_testset.shuffled-?????-of-?????.tfrecord.gz"". num_examples: 147448. ```. The training command looks like this:. ```. LR=0.001. BS=1024. apptainer run \. --nv \. -B $WD:/home \. $DV_PATH \. /opt/deepvariant/bin/train \. --config=/home/dv_config.py:base \. --config.train_dataset_pbtxt=""/home/examples_shuffled/train/shuf_test/examples_shuf3_testset_config.pbtxt"" \. --config.tune_dataset_pbtxt=""/home/examples_shuffled/tune_test/tune_test_examples_config.pbtxt"" \. --config.num_epochs=1 \. --config.learning_rate=${LR} \. --config.num_validation_examples=0 \. --config.tune_every_steps=2000 \. --experiment_dir=/home/${OUTDIR} \. --strategy=mirrored \. --config.batch_size=${BS} \. --config.init_checkpoint=""/home/model_wgs_v1.6.1/deepvariant.wgs.ckpt"". ```. During other tests I have run training jobs with several other example sets (several times larger), for tens of thousands of steps and multiple epochs, and also using different learning rates and batch sizes. While these things of course make a difference to learning performance, the lower recall for class 0 (hom_ref) remains consistent. . Here are some lines from the log file during one such training run:. ```. I1031 10:55:27.365902 140558597089024 logging_writer.py:48] [0] epoch=0, train/categorical_accuracy=0.91796875, train/categorical_crossentropy=0.6384725570678711, train/f1_het=0.7428571581840515, train/f1_homalt=0.964401364326477, train/f1_homref=0.902255654335022, train/f1_macro=0. 8698380589485168, train/f1_micro=0.91796875, train/f1_weighted=0.9241795539855957, train/false_negatives=34.0, train/false_positives=14.0, train/learning_rate=9.999999747378752e-06, train/loss=0.6384731531143188, train/precision=0.9406779408454895, train/precision_het=0.702702701091. 7664, train/precision_homalt=0.978723406791687, train/precision_homref=1.0, train/recall=0.8671875, tra",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/904
https://github.com/google/deepvariant/issues/904:1854,performance,batch,batch,1854,"es_shuffled/train/shuf_test/examples_shuf3_testset.shuffled-?????-of-?????.tfrecord.gz"". num_examples: 147448. ```. The training command looks like this:. ```. LR=0.001. BS=1024. apptainer run \. --nv \. -B $WD:/home \. $DV_PATH \. /opt/deepvariant/bin/train \. --config=/home/dv_config.py:base \. --config.train_dataset_pbtxt=""/home/examples_shuffled/train/shuf_test/examples_shuf3_testset_config.pbtxt"" \. --config.tune_dataset_pbtxt=""/home/examples_shuffled/tune_test/tune_test_examples_config.pbtxt"" \. --config.num_epochs=1 \. --config.learning_rate=${LR} \. --config.num_validation_examples=0 \. --config.tune_every_steps=2000 \. --experiment_dir=/home/${OUTDIR} \. --strategy=mirrored \. --config.batch_size=${BS} \. --config.init_checkpoint=""/home/model_wgs_v1.6.1/deepvariant.wgs.ckpt"". ```. During other tests I have run training jobs with several other example sets (several times larger), for tens of thousands of steps and multiple epochs, and also using different learning rates and batch sizes. While these things of course make a difference to learning performance, the lower recall for class 0 (hom_ref) remains consistent. . Here are some lines from the log file during one such training run:. ```. I1031 10:55:27.365902 140558597089024 logging_writer.py:48] [0] epoch=0, train/categorical_accuracy=0.91796875, train/categorical_crossentropy=0.6384725570678711, train/f1_het=0.7428571581840515, train/f1_homalt=0.964401364326477, train/f1_homref=0.902255654335022, train/f1_macro=0. 8698380589485168, train/f1_micro=0.91796875, train/f1_weighted=0.9241795539855957, train/false_negatives=34.0, train/false_positives=14.0, train/learning_rate=9.999999747378752e-06, train/loss=0.6384731531143188, train/precision=0.9406779408454895, train/precision_het=0.702702701091. 7664, train/precision_homalt=0.978723406791687, train/precision_homref=1.0, train/recall=0.8671875, train/recall_het=1.0, train/recall_homalt=0.8789808750152588, train/recall_homref=0.7945205569267273, train/true_n",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/904
https://github.com/google/deepvariant/issues/904:1926,performance,perform,performance,1926,"tfrecord.gz"". num_examples: 147448. ```. The training command looks like this:. ```. LR=0.001. BS=1024. apptainer run \. --nv \. -B $WD:/home \. $DV_PATH \. /opt/deepvariant/bin/train \. --config=/home/dv_config.py:base \. --config.train_dataset_pbtxt=""/home/examples_shuffled/train/shuf_test/examples_shuf3_testset_config.pbtxt"" \. --config.tune_dataset_pbtxt=""/home/examples_shuffled/tune_test/tune_test_examples_config.pbtxt"" \. --config.num_epochs=1 \. --config.learning_rate=${LR} \. --config.num_validation_examples=0 \. --config.tune_every_steps=2000 \. --experiment_dir=/home/${OUTDIR} \. --strategy=mirrored \. --config.batch_size=${BS} \. --config.init_checkpoint=""/home/model_wgs_v1.6.1/deepvariant.wgs.ckpt"". ```. During other tests I have run training jobs with several other example sets (several times larger), for tens of thousands of steps and multiple epochs, and also using different learning rates and batch sizes. While these things of course make a difference to learning performance, the lower recall for class 0 (hom_ref) remains consistent. . Here are some lines from the log file during one such training run:. ```. I1031 10:55:27.365902 140558597089024 logging_writer.py:48] [0] epoch=0, train/categorical_accuracy=0.91796875, train/categorical_crossentropy=0.6384725570678711, train/f1_het=0.7428571581840515, train/f1_homalt=0.964401364326477, train/f1_homref=0.902255654335022, train/f1_macro=0. 8698380589485168, train/f1_micro=0.91796875, train/f1_weighted=0.9241795539855957, train/false_negatives=34.0, train/false_positives=14.0, train/learning_rate=9.999999747378752e-06, train/loss=0.6384731531143188, train/precision=0.9406779408454895, train/precision_het=0.702702701091. 7664, train/precision_homalt=0.978723406791687, train/precision_homref=1.0, train/recall=0.8671875, train/recall_het=1.0, train/recall_homalt=0.8789808750152588, train/recall_homref=0.7945205569267273, train/true_negatives=498.0, train/true_positives=222.0. I1031 11:18:53.873582 140558597",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/904
https://github.com/google/deepvariant/issues/904:454,reliability,reliab,reliable,454,"Low hom_ref recall during model training for new organism; Dear Devs, . I am currently training a model (starting from wgs.1.6.1) for use in a fish species. The programs are running well, I have confident regions and truth variants defined, and am currently tuning hyperparameters to optimise the training. . However . . . . I notice when tracking the model eval stats (specifically f1, precision, recall), that the hom_ref classifications are much less reliable than hom_alt and het classes. My question is whether this is to be expected, or whether there might be something wrong with my training setup, or perhaps the examples. . The test example set I am using to tune the hyperparams looks like this:. ```. # Generated by shuffle_tfrecords_beam.py. # class2: 89987. # class0: 33161. # class1: 24300. name: ""Shuffle_global"". tfrecord_path: ""/home/examples_shuffled/train/shuf_test/examples_shuf3_testset.shuffled-?????-of-?????.tfrecord.gz"". num_examples: 147448. ```. The training command looks like this:. ```. LR=0.001. BS=1024. apptainer run \. --nv \. -B $WD:/home \. $DV_PATH \. /opt/deepvariant/bin/train \. --config=/home/dv_config.py:base \. --config.train_dataset_pbtxt=""/home/examples_shuffled/train/shuf_test/examples_shuf3_testset_config.pbtxt"" \. --config.tune_dataset_pbtxt=""/home/examples_shuffled/tune_test/tune_test_examples_config.pbtxt"" \. --config.num_epochs=1 \. --config.learning_rate=${LR} \. --config.num_validation_examples=0 \. --config.tune_every_steps=2000 \. --experiment_dir=/home/${OUTDIR} \. --strategy=mirrored \. --config.batch_size=${BS} \. --config.init_checkpoint=""/home/model_wgs_v1.6.1/deepvariant.wgs.ckpt"". ```. During other tests I have run training jobs with several other example sets (several times larger), for tens of thousands of steps and multiple epochs, and also using different learning rates and batch sizes. While these things of course make a difference to learning performance, the lower recall for class 0 (hom_ref) remains consistent. . ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/904
https://github.com/google/deepvariant/issues/904:637,safety,test,test,637,"Low hom_ref recall during model training for new organism; Dear Devs, . I am currently training a model (starting from wgs.1.6.1) for use in a fish species. The programs are running well, I have confident regions and truth variants defined, and am currently tuning hyperparameters to optimise the training. . However . . . . I notice when tracking the model eval stats (specifically f1, precision, recall), that the hom_ref classifications are much less reliable than hom_alt and het classes. My question is whether this is to be expected, or whether there might be something wrong with my training setup, or perhaps the examples. . The test example set I am using to tune the hyperparams looks like this:. ```. # Generated by shuffle_tfrecords_beam.py. # class2: 89987. # class0: 33161. # class1: 24300. name: ""Shuffle_global"". tfrecord_path: ""/home/examples_shuffled/train/shuf_test/examples_shuf3_testset.shuffled-?????-of-?????.tfrecord.gz"". num_examples: 147448. ```. The training command looks like this:. ```. LR=0.001. BS=1024. apptainer run \. --nv \. -B $WD:/home \. $DV_PATH \. /opt/deepvariant/bin/train \. --config=/home/dv_config.py:base \. --config.train_dataset_pbtxt=""/home/examples_shuffled/train/shuf_test/examples_shuf3_testset_config.pbtxt"" \. --config.tune_dataset_pbtxt=""/home/examples_shuffled/tune_test/tune_test_examples_config.pbtxt"" \. --config.num_epochs=1 \. --config.learning_rate=${LR} \. --config.num_validation_examples=0 \. --config.tune_every_steps=2000 \. --experiment_dir=/home/${OUTDIR} \. --strategy=mirrored \. --config.batch_size=${BS} \. --config.init_checkpoint=""/home/model_wgs_v1.6.1/deepvariant.wgs.ckpt"". ```. During other tests I have run training jobs with several other example sets (several times larger), for tens of thousands of steps and multiple epochs, and also using different learning rates and batch sizes. While these things of course make a difference to learning performance, the lower recall for class 0 (hom_ref) remains consistent. . ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/904
https://github.com/google/deepvariant/issues/904:1671,safety,test,tests,1671,"he hyperparams looks like this:. ```. # Generated by shuffle_tfrecords_beam.py. # class2: 89987. # class0: 33161. # class1: 24300. name: ""Shuffle_global"". tfrecord_path: ""/home/examples_shuffled/train/shuf_test/examples_shuf3_testset.shuffled-?????-of-?????.tfrecord.gz"". num_examples: 147448. ```. The training command looks like this:. ```. LR=0.001. BS=1024. apptainer run \. --nv \. -B $WD:/home \. $DV_PATH \. /opt/deepvariant/bin/train \. --config=/home/dv_config.py:base \. --config.train_dataset_pbtxt=""/home/examples_shuffled/train/shuf_test/examples_shuf3_testset_config.pbtxt"" \. --config.tune_dataset_pbtxt=""/home/examples_shuffled/tune_test/tune_test_examples_config.pbtxt"" \. --config.num_epochs=1 \. --config.learning_rate=${LR} \. --config.num_validation_examples=0 \. --config.tune_every_steps=2000 \. --experiment_dir=/home/${OUTDIR} \. --strategy=mirrored \. --config.batch_size=${BS} \. --config.init_checkpoint=""/home/model_wgs_v1.6.1/deepvariant.wgs.ckpt"". ```. During other tests I have run training jobs with several other example sets (several times larger), for tens of thousands of steps and multiple epochs, and also using different learning rates and batch sizes. While these things of course make a difference to learning performance, the lower recall for class 0 (hom_ref) remains consistent. . Here are some lines from the log file during one such training run:. ```. I1031 10:55:27.365902 140558597089024 logging_writer.py:48] [0] epoch=0, train/categorical_accuracy=0.91796875, train/categorical_crossentropy=0.6384725570678711, train/f1_het=0.7428571581840515, train/f1_homalt=0.964401364326477, train/f1_homref=0.902255654335022, train/f1_macro=0. 8698380589485168, train/f1_micro=0.91796875, train/f1_weighted=0.9241795539855957, train/false_negatives=34.0, train/false_positives=14.0, train/learning_rate=9.999999747378752e-06, train/loss=0.6384731531143188, train/precision=0.9406779408454895, train/precision_het=0.702702701091. 7664, train/precision_homalt=0.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/904
https://github.com/google/deepvariant/issues/904:2029,safety,log,log,2029,"024. apptainer run \. --nv \. -B $WD:/home \. $DV_PATH \. /opt/deepvariant/bin/train \. --config=/home/dv_config.py:base \. --config.train_dataset_pbtxt=""/home/examples_shuffled/train/shuf_test/examples_shuf3_testset_config.pbtxt"" \. --config.tune_dataset_pbtxt=""/home/examples_shuffled/tune_test/tune_test_examples_config.pbtxt"" \. --config.num_epochs=1 \. --config.learning_rate=${LR} \. --config.num_validation_examples=0 \. --config.tune_every_steps=2000 \. --experiment_dir=/home/${OUTDIR} \. --strategy=mirrored \. --config.batch_size=${BS} \. --config.init_checkpoint=""/home/model_wgs_v1.6.1/deepvariant.wgs.ckpt"". ```. During other tests I have run training jobs with several other example sets (several times larger), for tens of thousands of steps and multiple epochs, and also using different learning rates and batch sizes. While these things of course make a difference to learning performance, the lower recall for class 0 (hom_ref) remains consistent. . Here are some lines from the log file during one such training run:. ```. I1031 10:55:27.365902 140558597089024 logging_writer.py:48] [0] epoch=0, train/categorical_accuracy=0.91796875, train/categorical_crossentropy=0.6384725570678711, train/f1_het=0.7428571581840515, train/f1_homalt=0.964401364326477, train/f1_homref=0.902255654335022, train/f1_macro=0. 8698380589485168, train/f1_micro=0.91796875, train/f1_weighted=0.9241795539855957, train/false_negatives=34.0, train/false_positives=14.0, train/learning_rate=9.999999747378752e-06, train/loss=0.6384731531143188, train/precision=0.9406779408454895, train/precision_het=0.702702701091. 7664, train/precision_homalt=0.978723406791687, train/precision_homref=1.0, train/recall=0.8671875, train/recall_het=1.0, train/recall_homalt=0.8789808750152588, train/recall_homref=0.7945205569267273, train/true_negatives=498.0, train/true_positives=222.0. I1031 11:18:53.873582 140558597089024 logging_writer.py:48] [100] epoch=0, train/categorical_accuracy=0.9428125023841858, train/ca",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/904
https://github.com/google/deepvariant/issues/904:26,security,model,model,26,"Low hom_ref recall during model training for new organism; Dear Devs, . I am currently training a model (starting from wgs.1.6.1) for use in a fish species. The programs are running well, I have confident regions and truth variants defined, and am currently tuning hyperparameters to optimise the training. . However . . . . I notice when tracking the model eval stats (specifically f1, precision, recall), that the hom_ref classifications are much less reliable than hom_alt and het classes. My question is whether this is to be expected, or whether there might be something wrong with my training setup, or perhaps the examples. . The test example set I am using to tune the hyperparams looks like this:. ```. # Generated by shuffle_tfrecords_beam.py. # class2: 89987. # class0: 33161. # class1: 24300. name: ""Shuffle_global"". tfrecord_path: ""/home/examples_shuffled/train/shuf_test/examples_shuf3_testset.shuffled-?????-of-?????.tfrecord.gz"". num_examples: 147448. ```. The training command looks like this:. ```. LR=0.001. BS=1024. apptainer run \. --nv \. -B $WD:/home \. $DV_PATH \. /opt/deepvariant/bin/train \. --config=/home/dv_config.py:base \. --config.train_dataset_pbtxt=""/home/examples_shuffled/train/shuf_test/examples_shuf3_testset_config.pbtxt"" \. --config.tune_dataset_pbtxt=""/home/examples_shuffled/tune_test/tune_test_examples_config.pbtxt"" \. --config.num_epochs=1 \. --config.learning_rate=${LR} \. --config.num_validation_examples=0 \. --config.tune_every_steps=2000 \. --experiment_dir=/home/${OUTDIR} \. --strategy=mirrored \. --config.batch_size=${BS} \. --config.init_checkpoint=""/home/model_wgs_v1.6.1/deepvariant.wgs.ckpt"". ```. During other tests I have run training jobs with several other example sets (several times larger), for tens of thousands of steps and multiple epochs, and also using different learning rates and batch sizes. While these things of course make a difference to learning performance, the lower recall for class 0 (hom_ref) remains consistent. . ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/904
https://github.com/google/deepvariant/issues/904:98,security,model,model,98,"Low hom_ref recall during model training for new organism; Dear Devs, . I am currently training a model (starting from wgs.1.6.1) for use in a fish species. The programs are running well, I have confident regions and truth variants defined, and am currently tuning hyperparameters to optimise the training. . However . . . . I notice when tracking the model eval stats (specifically f1, precision, recall), that the hom_ref classifications are much less reliable than hom_alt and het classes. My question is whether this is to be expected, or whether there might be something wrong with my training setup, or perhaps the examples. . The test example set I am using to tune the hyperparams looks like this:. ```. # Generated by shuffle_tfrecords_beam.py. # class2: 89987. # class0: 33161. # class1: 24300. name: ""Shuffle_global"". tfrecord_path: ""/home/examples_shuffled/train/shuf_test/examples_shuf3_testset.shuffled-?????-of-?????.tfrecord.gz"". num_examples: 147448. ```. The training command looks like this:. ```. LR=0.001. BS=1024. apptainer run \. --nv \. -B $WD:/home \. $DV_PATH \. /opt/deepvariant/bin/train \. --config=/home/dv_config.py:base \. --config.train_dataset_pbtxt=""/home/examples_shuffled/train/shuf_test/examples_shuf3_testset_config.pbtxt"" \. --config.tune_dataset_pbtxt=""/home/examples_shuffled/tune_test/tune_test_examples_config.pbtxt"" \. --config.num_epochs=1 \. --config.learning_rate=${LR} \. --config.num_validation_examples=0 \. --config.tune_every_steps=2000 \. --experiment_dir=/home/${OUTDIR} \. --strategy=mirrored \. --config.batch_size=${BS} \. --config.init_checkpoint=""/home/model_wgs_v1.6.1/deepvariant.wgs.ckpt"". ```. During other tests I have run training jobs with several other example sets (several times larger), for tens of thousands of steps and multiple epochs, and also using different learning rates and batch sizes. While these things of course make a difference to learning performance, the lower recall for class 0 (hom_ref) remains consistent. . ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/904
https://github.com/google/deepvariant/issues/904:352,security,model,model,352,"Low hom_ref recall during model training for new organism; Dear Devs, . I am currently training a model (starting from wgs.1.6.1) for use in a fish species. The programs are running well, I have confident regions and truth variants defined, and am currently tuning hyperparameters to optimise the training. . However . . . . I notice when tracking the model eval stats (specifically f1, precision, recall), that the hom_ref classifications are much less reliable than hom_alt and het classes. My question is whether this is to be expected, or whether there might be something wrong with my training setup, or perhaps the examples. . The test example set I am using to tune the hyperparams looks like this:. ```. # Generated by shuffle_tfrecords_beam.py. # class2: 89987. # class0: 33161. # class1: 24300. name: ""Shuffle_global"". tfrecord_path: ""/home/examples_shuffled/train/shuf_test/examples_shuf3_testset.shuffled-?????-of-?????.tfrecord.gz"". num_examples: 147448. ```. The training command looks like this:. ```. LR=0.001. BS=1024. apptainer run \. --nv \. -B $WD:/home \. $DV_PATH \. /opt/deepvariant/bin/train \. --config=/home/dv_config.py:base \. --config.train_dataset_pbtxt=""/home/examples_shuffled/train/shuf_test/examples_shuf3_testset_config.pbtxt"" \. --config.tune_dataset_pbtxt=""/home/examples_shuffled/tune_test/tune_test_examples_config.pbtxt"" \. --config.num_epochs=1 \. --config.learning_rate=${LR} \. --config.num_validation_examples=0 \. --config.tune_every_steps=2000 \. --experiment_dir=/home/${OUTDIR} \. --strategy=mirrored \. --config.batch_size=${BS} \. --config.init_checkpoint=""/home/model_wgs_v1.6.1/deepvariant.wgs.ckpt"". ```. During other tests I have run training jobs with several other example sets (several times larger), for tens of thousands of steps and multiple epochs, and also using different learning rates and batch sizes. While these things of course make a difference to learning performance, the lower recall for class 0 (hom_ref) remains consistent. . ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/904
https://github.com/google/deepvariant/issues/904:2029,security,log,log,2029,"024. apptainer run \. --nv \. -B $WD:/home \. $DV_PATH \. /opt/deepvariant/bin/train \. --config=/home/dv_config.py:base \. --config.train_dataset_pbtxt=""/home/examples_shuffled/train/shuf_test/examples_shuf3_testset_config.pbtxt"" \. --config.tune_dataset_pbtxt=""/home/examples_shuffled/tune_test/tune_test_examples_config.pbtxt"" \. --config.num_epochs=1 \. --config.learning_rate=${LR} \. --config.num_validation_examples=0 \. --config.tune_every_steps=2000 \. --experiment_dir=/home/${OUTDIR} \. --strategy=mirrored \. --config.batch_size=${BS} \. --config.init_checkpoint=""/home/model_wgs_v1.6.1/deepvariant.wgs.ckpt"". ```. During other tests I have run training jobs with several other example sets (several times larger), for tens of thousands of steps and multiple epochs, and also using different learning rates and batch sizes. While these things of course make a difference to learning performance, the lower recall for class 0 (hom_ref) remains consistent. . Here are some lines from the log file during one such training run:. ```. I1031 10:55:27.365902 140558597089024 logging_writer.py:48] [0] epoch=0, train/categorical_accuracy=0.91796875, train/categorical_crossentropy=0.6384725570678711, train/f1_het=0.7428571581840515, train/f1_homalt=0.964401364326477, train/f1_homref=0.902255654335022, train/f1_macro=0. 8698380589485168, train/f1_micro=0.91796875, train/f1_weighted=0.9241795539855957, train/false_negatives=34.0, train/false_positives=14.0, train/learning_rate=9.999999747378752e-06, train/loss=0.6384731531143188, train/precision=0.9406779408454895, train/precision_het=0.702702701091. 7664, train/precision_homalt=0.978723406791687, train/precision_homref=1.0, train/recall=0.8671875, train/recall_het=1.0, train/recall_homalt=0.8789808750152588, train/recall_homref=0.7945205569267273, train/true_negatives=498.0, train/true_positives=222.0. I1031 11:18:53.873582 140558597089024 logging_writer.py:48] [100] epoch=0, train/categorical_accuracy=0.9428125023841858, train/ca",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/904
https://github.com/google/deepvariant/issues/904:2546,security,loss,loss,2546," \. --config.batch_size=${BS} \. --config.init_checkpoint=""/home/model_wgs_v1.6.1/deepvariant.wgs.ckpt"". ```. During other tests I have run training jobs with several other example sets (several times larger), for tens of thousands of steps and multiple epochs, and also using different learning rates and batch sizes. While these things of course make a difference to learning performance, the lower recall for class 0 (hom_ref) remains consistent. . Here are some lines from the log file during one such training run:. ```. I1031 10:55:27.365902 140558597089024 logging_writer.py:48] [0] epoch=0, train/categorical_accuracy=0.91796875, train/categorical_crossentropy=0.6384725570678711, train/f1_het=0.7428571581840515, train/f1_homalt=0.964401364326477, train/f1_homref=0.902255654335022, train/f1_macro=0. 8698380589485168, train/f1_micro=0.91796875, train/f1_weighted=0.9241795539855957, train/false_negatives=34.0, train/false_positives=14.0, train/learning_rate=9.999999747378752e-06, train/loss=0.6384731531143188, train/precision=0.9406779408454895, train/precision_het=0.702702701091. 7664, train/precision_homalt=0.978723406791687, train/precision_homref=1.0, train/recall=0.8671875, train/recall_het=1.0, train/recall_homalt=0.8789808750152588, train/recall_homref=0.7945205569267273, train/true_negatives=498.0, train/true_positives=222.0. I1031 11:18:53.873582 140558597089024 logging_writer.py:48] [100] epoch=0, train/categorical_accuracy=0.9428125023841858, train/categorical_crossentropy=0.6131614446640015, train/f1_het=0.8813706636428833, train/f1_homalt=0.9773345589637756, train/f1_homref=0.9072573781013489, train. /f1_macro=0.9219875335693359, train/f1_micro=0.9428125023841858, train/f1_weighted=0.943286657333374, train/false_negatives=2097.0, train/false_positives=1038.0, train/learning_rate=1.089999932446517e-05, train/loss=0.613162100315094, train/precision=0.9577034115791321, train/precis. ion_het=0.8474469184875488, train/precision_homalt=0.9807273149490356, train/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/904
https://github.com/google/deepvariant/issues/904:3397,security,loss,loss,3397,"75, train/f1_weighted=0.9241795539855957, train/false_negatives=34.0, train/false_positives=14.0, train/learning_rate=9.999999747378752e-06, train/loss=0.6384731531143188, train/precision=0.9406779408454895, train/precision_het=0.702702701091. 7664, train/precision_homalt=0.978723406791687, train/precision_homref=1.0, train/recall=0.8671875, train/recall_het=1.0, train/recall_homalt=0.8789808750152588, train/recall_homref=0.7945205569267273, train/true_negatives=498.0, train/true_positives=222.0. I1031 11:18:53.873582 140558597089024 logging_writer.py:48] [100] epoch=0, train/categorical_accuracy=0.9428125023841858, train/categorical_crossentropy=0.6131614446640015, train/f1_het=0.8813706636428833, train/f1_homalt=0.9773345589637756, train/f1_homref=0.9072573781013489, train. /f1_macro=0.9219875335693359, train/f1_micro=0.9428125023841858, train/f1_weighted=0.943286657333374, train/false_negatives=2097.0, train/false_positives=1038.0, train/learning_rate=1.089999932446517e-05, train/loss=0.613162100315094, train/precision=0.9577034115791321, train/precis. ion_het=0.8474469184875488, train/precision_homalt=0.9807273149490356, train/precision_homref=0.9931716322898865, train/recall=0.9180859327316284, train/recall_het=0.9800729155540466, train/recall_homalt=0.9496662616729736, train/recall_homref=0.8124356865882874, train/true_negative. s=50162.0, train/true_positives=23503.0. I1031 11:42:21.111832 140558597089024 logging_writer.py:48] [200] epoch=0, train/categorical_accuracy=0.9450390338897705, train/categorical_crossentropy=0.6096971035003662, train/f1_het=0.9036118984222412, train/f1_homalt=0.9778183698654175, train/f1_homref=0.9041261672973633, train. /f1_macro=0.9285187721252441, train/f1_micro=0.9450390338897705, train/f1_weighted=0.9446096420288086, train/false_negatives=1829.0, train/false_positives=1089.0, train/learning_rate=1.1799999811046291e-05, train/loss=0.6096978187561035, train/precision=0.9561946988105774, train/pre. cision_het=0.8650889992713928, t",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/904
https://github.com/google/deepvariant/issues/904:4295,security,loss,loss,4295,"se_negatives=2097.0, train/false_positives=1038.0, train/learning_rate=1.089999932446517e-05, train/loss=0.613162100315094, train/precision=0.9577034115791321, train/precis. ion_het=0.8474469184875488, train/precision_homalt=0.9807273149490356, train/precision_homref=0.9931716322898865, train/recall=0.9180859327316284, train/recall_het=0.9800729155540466, train/recall_homalt=0.9496662616729736, train/recall_homref=0.8124356865882874, train/true_negative. s=50162.0, train/true_positives=23503.0. I1031 11:42:21.111832 140558597089024 logging_writer.py:48] [200] epoch=0, train/categorical_accuracy=0.9450390338897705, train/categorical_crossentropy=0.6096971035003662, train/f1_het=0.9036118984222412, train/f1_homalt=0.9778183698654175, train/f1_homref=0.9041261672973633, train. /f1_macro=0.9285187721252441, train/f1_micro=0.9450390338897705, train/f1_weighted=0.9446096420288086, train/false_negatives=1829.0, train/false_positives=1089.0, train/learning_rate=1.1799999811046291e-05, train/loss=0.6096978187561035, train/precision=0.9561946988105774, train/pre. cision_het=0.8650889992713928, train/precision_homalt=0.9727717638015747, train/precision_homref=0.9934629201889038, train/recall=0.9285547137260437, train/recall_het=0.9818640947341919, train/recall_homalt=0.973392903804779, train/recall_homref=0.807692289352417, train/true_negativ. es=50111.0, train/true_positives=23771.0. I1031 12:05:48.379206 140558597089024 logging_writer.py:48] [300] epoch=0, train/categorical_accuracy=0.9505468606948853, train/categorical_crossentropy=0.6057209968566895, train/f1_het=0.9090908765792847, train/f1_homalt=0.9804965853691101, train/f1_homref=0.9048975706100464, train. /f1_macro=0.9314950108528137, train/f1_micro=0.9505468606948853, train/f1_weighted=0.9502355456352234, train/false_negatives=1770.0, train/false_positives=957.0, train/learning_rate=1.269999938813271e-05, train/loss=0.6057215332984924, train/precision=0.961391031742096, train/precis. ion_het=0.8758693337440491, train",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/904
https://github.com/google/deepvariant/issues/904:5190,security,loss,loss,5190,"alse_negatives=1829.0, train/false_positives=1089.0, train/learning_rate=1.1799999811046291e-05, train/loss=0.6096978187561035, train/precision=0.9561946988105774, train/pre. cision_het=0.8650889992713928, train/precision_homalt=0.9727717638015747, train/precision_homref=0.9934629201889038, train/recall=0.9285547137260437, train/recall_het=0.9818640947341919, train/recall_homalt=0.973392903804779, train/recall_homref=0.807692289352417, train/true_negativ. es=50111.0, train/true_positives=23771.0. I1031 12:05:48.379206 140558597089024 logging_writer.py:48] [300] epoch=0, train/categorical_accuracy=0.9505468606948853, train/categorical_crossentropy=0.6057209968566895, train/f1_het=0.9090908765792847, train/f1_homalt=0.9804965853691101, train/f1_homref=0.9048975706100464, train. /f1_macro=0.9314950108528137, train/f1_micro=0.9505468606948853, train/f1_weighted=0.9502355456352234, train/false_negatives=1770.0, train/false_positives=957.0, train/learning_rate=1.269999938813271e-05, train/loss=0.6057215332984924, train/precision=0.961391031742096, train/precis. ion_het=0.8758693337440491, train/precision_homalt=0.9790242314338684, train/precision_homref=0.9892578125, train/recall=0.930859386920929, train/recall_het=0.9778823256492615, train/recall_homalt=0.9663954377174377, train/recall_homref=0.8126103281974792, train/true_negatives=50243. .0, train/true_positives=23830.0. ... I1031 18:45:29.237352 140558597089024 logging_writer.py:48] [2000] epoch=0, train/categorical_accuracy=0.9649609327316284, train/categorical_crossentropy=0.5881873965263367, train/f1_het=0.9483578205108643, train/f1_homalt=0.9847753643989563, train/f1_homref=0.9196805953979492, trai. n/f1_macro=0.9509379267692566, train/f1_micro=0.9649609327316284, train/f1_weighted=0.9644672274589539, train/false_negatives=1148.0, train/false_positives=706.0, train/learning_rate=2.7999998565064743e-05, train/loss=0.588188111782074, train/precision=0.971937358379364, train/preci. sion_het=0.944876492023468, train/p",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/904
https://github.com/google/deepvariant/issues/904:6085,security,loss,loss,6085,"/false_negatives=1770.0, train/false_positives=957.0, train/learning_rate=1.269999938813271e-05, train/loss=0.6057215332984924, train/precision=0.961391031742096, train/precis. ion_het=0.8758693337440491, train/precision_homalt=0.9790242314338684, train/precision_homref=0.9892578125, train/recall=0.930859386920929, train/recall_het=0.9778823256492615, train/recall_homalt=0.9663954377174377, train/recall_homref=0.8126103281974792, train/true_negatives=50243. .0, train/true_positives=23830.0. ... I1031 18:45:29.237352 140558597089024 logging_writer.py:48] [2000] epoch=0, train/categorical_accuracy=0.9649609327316284, train/categorical_crossentropy=0.5881873965263367, train/f1_het=0.9483578205108643, train/f1_homalt=0.9847753643989563, train/f1_homref=0.9196805953979492, trai. n/f1_macro=0.9509379267692566, train/f1_micro=0.9649609327316284, train/f1_weighted=0.9644672274589539, train/false_negatives=1148.0, train/false_positives=706.0, train/learning_rate=2.7999998565064743e-05, train/loss=0.588188111782074, train/precision=0.971937358379364, train/preci. sion_het=0.944876492023468, train/precision_homalt=0.9782115817070007, train/precision_homref=0.9757440090179443, train/recall=0.9551562666893005, train/recall_het=0.9551445245742798, train/recall_homalt=0.9889228343963623, train/recall_homref=0.8598886132240295, train/true_negative. s=50494.0, train/true_positives=24452.0. I1031 19:09:02.961704 140558597089024 logging_writer.py:48] [2100] epoch=0, train/categorical_accuracy=0.9671875238418579, train/categorical_crossentropy=0.5857771635055542, train/f1_het=0.9489831328392029, train/f1_homalt=0.9863211512565613, train/f1_homref=0.9253288507461548, trai. n/f1_macro=0.9535443782806396, train/f1_micro=0.9671875238418579, train/f1_weighted=0.9668003916740417, train/false_negatives=1088.0, train/false_positives=626.0, train/learning_rate=2.8899999961140566e-05, train/loss=0.5857776999473572, train/precision=0.9750974774360657, train/pre. cision_het=0.9460923075675964, tra",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/904
https://github.com/google/deepvariant/issues/904:6981,security,loss,loss,6981,"alse_negatives=1148.0, train/false_positives=706.0, train/learning_rate=2.7999998565064743e-05, train/loss=0.588188111782074, train/precision=0.971937358379364, train/preci. sion_het=0.944876492023468, train/precision_homalt=0.9782115817070007, train/precision_homref=0.9757440090179443, train/recall=0.9551562666893005, train/recall_het=0.9551445245742798, train/recall_homalt=0.9889228343963623, train/recall_homref=0.8598886132240295, train/true_negative. s=50494.0, train/true_positives=24452.0. I1031 19:09:02.961704 140558597089024 logging_writer.py:48] [2100] epoch=0, train/categorical_accuracy=0.9671875238418579, train/categorical_crossentropy=0.5857771635055542, train/f1_het=0.9489831328392029, train/f1_homalt=0.9863211512565613, train/f1_homref=0.9253288507461548, trai. n/f1_macro=0.9535443782806396, train/f1_micro=0.9671875238418579, train/f1_weighted=0.9668003916740417, train/false_negatives=1088.0, train/false_positives=626.0, train/learning_rate=2.8899999961140566e-05, train/loss=0.5857776999473572, train/precision=0.9750974774360657, train/pre. cision_het=0.9460923075675964, train/precision_homalt=0.9813895225524902, train/precision_homref=0.9797391891479492, train/recall=0.9574999809265137, train/recall_het=0.9564493298530579, train/recall_homalt=0.9893515706062317, train/recall_homref=0.8688845634460449, train/true_negat. ives=50574.0, train/true_positives=24512.0. I1031 19:32:36.750034 140558597089024 logging_writer.py:48] [2200] epoch=0, train/categorical_accuracy=0.9658593535423279, train/categorical_crossentropy=0.5868217349052429, train/f1_het=0.9465685486793518, train/f1_homalt=0.9850433468818665, train/f1_homref=0.9267298579216003, trai. n/f1_macro=0.952780544757843, train/f1_micro=0.9658593535423279, train/f1_weighted=0.9654529094696045, train/false_negatives=1091.0, train/false_positives=686.0, train/learning_rate=2.9799999538226984e-05, train/loss=0.5868225693702698, train/precision=0.9727723598480225, train/prec. ision_het=0.9420636892318726, t",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/904
https://github.com/google/deepvariant/issues/904:7879,security,loss,loss,7879,"se_negatives=1088.0, train/false_positives=626.0, train/learning_rate=2.8899999961140566e-05, train/loss=0.5857776999473572, train/precision=0.9750974774360657, train/pre. cision_het=0.9460923075675964, train/precision_homalt=0.9813895225524902, train/precision_homref=0.9797391891479492, train/recall=0.9574999809265137, train/recall_het=0.9564493298530579, train/recall_homalt=0.9893515706062317, train/recall_homref=0.8688845634460449, train/true_negat. ives=50574.0, train/true_positives=24512.0. I1031 19:32:36.750034 140558597089024 logging_writer.py:48] [2200] epoch=0, train/categorical_accuracy=0.9658593535423279, train/categorical_crossentropy=0.5868217349052429, train/f1_het=0.9465685486793518, train/f1_homalt=0.9850433468818665, train/f1_homref=0.9267298579216003, trai. n/f1_macro=0.952780544757843, train/f1_micro=0.9658593535423279, train/f1_weighted=0.9654529094696045, train/false_negatives=1091.0, train/false_positives=686.0, train/learning_rate=2.9799999538226984e-05, train/loss=0.5868225693702698, train/precision=0.9727723598480225, train/prec. ision_het=0.9420636892318726, train/precision_homalt=0.9787166714668274, train/precision_homref=0.9793538451194763, train/recall=0.9573827981948853, train/recall_het=0.9550970792770386, train/recall_homalt=0.9905757308006287, train/recall_homref=0.8709622621536255, train/true_negati. ves=50514.0, train/true_positives=24509.0. ... I1101 03:23:30.847490 140558597089024 logging_writer.py:48] [4000] epoch=0, train/categorical_accuracy=0.9678124785423279, train/categorical_crossentropy=0.5838660597801208, train/f1_het=0.9544981122016907, train/f1_homalt=0.9849750399589539, train/f1_homref=0.9294350743293762, trai. n/f1_macro=0.9563027024269104, train/f1_micro=0.9678124785423279, train/f1_weighted=0.9675065279006958, train/false_negatives=1036.0, train/false_positives=650.0, train/learning_rate=4.5999997382750735e-05, train/loss=0.5838666558265686, train/precision=0.9742206931114197, train/pre. cision_het=0.96426868438720",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/904
https://github.com/google/deepvariant/issues/904:8782,security,loss,loss,8782,"gatives=1091.0, train/false_positives=686.0, train/learning_rate=2.9799999538226984e-05, train/loss=0.5868225693702698, train/precision=0.9727723598480225, train/prec. ision_het=0.9420636892318726, train/precision_homalt=0.9787166714668274, train/precision_homref=0.9793538451194763, train/recall=0.9573827981948853, train/recall_het=0.9550970792770386, train/recall_homalt=0.9905757308006287, train/recall_homref=0.8709622621536255, train/true_negati. ves=50514.0, train/true_positives=24509.0. ... I1101 03:23:30.847490 140558597089024 logging_writer.py:48] [4000] epoch=0, train/categorical_accuracy=0.9678124785423279, train/categorical_crossentropy=0.5838660597801208, train/f1_het=0.9544981122016907, train/f1_homalt=0.9849750399589539, train/f1_homref=0.9294350743293762, trai. n/f1_macro=0.9563027024269104, train/f1_micro=0.9678124785423279, train/f1_weighted=0.9675065279006958, train/false_negatives=1036.0, train/false_positives=650.0, train/learning_rate=4.5999997382750735e-05, train/loss=0.5838666558265686, train/precision=0.9742206931114197, train/pre. cision_het=0.964268684387207, train/precision_homalt=0.9791640043258667, train/precision_homref=0.9672790169715881, train/recall=0.9595312476158142, train/recall_het=0.936170220375061, train/recall_homalt=0.9912803769111633, train/recall_homref=0.8901215195655823, train/true_negativ. es=50550.0, train/true_positives=24564.0. I1101 03:47:04.138323 140558597089024 logging_writer.py:48] [4100] epoch=0, train/categorical_accuracy=0.9671093821525574, train/categorical_crossentropy=0.5843069553375244, train/f1_het=0.9511468410491943, train/f1_homalt=0.9851624965667725, train/f1_homref=0.9291577339172363, trai. n/f1_macro=0.9551556706428528, train/f1_micro=0.9671093821525574, train/f1_weighted=0.9667912721633911, train/false_negatives=1039.0, train/false_positives=662.0, train/learning_rate=4.690000059781596e-05, train/loss=0.5843074917793274, train/precision=0.9737541079521179, train/prec. ision_het=0.9606503248214722, tra",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/904
https://github.com/google/deepvariant/issues/904:9678,security,loss,loss,9678,"alse_negatives=1036.0, train/false_positives=650.0, train/learning_rate=4.5999997382750735e-05, train/loss=0.5838666558265686, train/precision=0.9742206931114197, train/pre. cision_het=0.964268684387207, train/precision_homalt=0.9791640043258667, train/precision_homref=0.9672790169715881, train/recall=0.9595312476158142, train/recall_het=0.936170220375061, train/recall_homalt=0.9912803769111633, train/recall_homref=0.8901215195655823, train/true_negativ. es=50550.0, train/true_positives=24564.0. I1101 03:47:04.138323 140558597089024 logging_writer.py:48] [4100] epoch=0, train/categorical_accuracy=0.9671093821525574, train/categorical_crossentropy=0.5843069553375244, train/f1_het=0.9511468410491943, train/f1_homalt=0.9851624965667725, train/f1_homref=0.9291577339172363, trai. n/f1_macro=0.9551556706428528, train/f1_micro=0.9671093821525574, train/f1_weighted=0.9667912721633911, train/false_negatives=1039.0, train/false_positives=662.0, train/learning_rate=4.690000059781596e-05, train/loss=0.5843074917793274, train/precision=0.9737541079521179, train/prec. ision_het=0.9606503248214722, train/precision_homalt=0.9785905480384827, train/precision_homref=0.9699148535728455, train/recall=0.9594140648841858, train/recall_het=0.934234619140625, train/recall_homalt=0.991542398929596, train/recall_homref=0.891943633556366, train/true_negatives. =50538.0, train/true_positives=24561.0. I1101 04:10:37.281655 140558597089024 logging_writer.py:48] [4200] epoch=0, train/categorical_accuracy=0.9688281416893005, train/categorical_crossentropy=0.5830131769180298, train/f1_het=0.9537984728813171, train/f1_homalt=0.9860970973968506, train/f1_homref=0.9311457872390747, trai. n/f1_macro=0.9570137858390808, train/f1_micro=0.9688281416893005, train/f1_weighted=0.9684778451919556, train/false_negatives=988.0, train/false_positives=644.0, train/learning_rate=4.780000017490238e-05, train/loss=0.5830137133598328, train/precision=0.9745011329650879, train/preci. sion_het=0.9634146094322205, train",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/904
https://github.com/google/deepvariant/issues/904:10572,security,loss,loss,10572,"n/false_negatives=1039.0, train/false_positives=662.0, train/learning_rate=4.690000059781596e-05, train/loss=0.5843074917793274, train/precision=0.9737541079521179, train/prec. ision_het=0.9606503248214722, train/precision_homalt=0.9785905480384827, train/precision_homref=0.9699148535728455, train/recall=0.9594140648841858, train/recall_het=0.934234619140625, train/recall_homalt=0.991542398929596, train/recall_homref=0.891943633556366, train/true_negatives. =50538.0, train/true_positives=24561.0. I1101 04:10:37.281655 140558597089024 logging_writer.py:48] [4200] epoch=0, train/categorical_accuracy=0.9688281416893005, train/categorical_crossentropy=0.5830131769180298, train/f1_het=0.9537984728813171, train/f1_homalt=0.9860970973968506, train/f1_homref=0.9311457872390747, trai. n/f1_macro=0.9570137858390808, train/f1_micro=0.9688281416893005, train/f1_weighted=0.9684778451919556, train/false_negatives=988.0, train/false_positives=644.0, train/learning_rate=4.780000017490238e-05, train/loss=0.5830137133598328, train/precision=0.9745011329650879, train/preci. sion_het=0.9634146094322205, train/precision_homalt=0.9787381291389465, train/precision_homref=0.9703365564346313, train/recall=0.9614062309265137, train/recall_het=0.9402523040771484, train/recall_homalt=0.9935504198074341, train/recall_homref=0.8891792893409729, train/true_negativ. es=50556.0, train/true_positives=24612.0. I1101 04:34:10.308057 140558597089024 logging_writer.py:48] [4300] epoch=0, train/categorical_accuracy=0.9663281440734863, train/categorical_crossentropy=0.5852743983268738, train/f1_het=0.9510709643363953, train/f1_homalt=0.98508220911026, train/f1_homref=0.9242424964904785, train/. f1_macro=0.9534652233123779, train/f1_micro=0.9663281440734863, train/f1_weighted=0.9659736752510071, train/false_negatives=1079.0, train/false_positives=673.0, train/learning_rate=4.86999997519888e-05, train/loss=0.5852747559547424, train/precision=0.9732872843742371, train/precisi. on_het=0.9643771648406982, trai",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/904
https://github.com/google/deepvariant/issues/904:11467,security,loss,loss,11467,"l_het=0.934234619140625, train/recall_homalt=0.991542398929596, train/recall_homref=0.891943633556366, train/true_negatives. =50538.0, train/true_positives=24561.0. I1101 04:10:37.281655 140558597089024 logging_writer.py:48] [4200] epoch=0, train/categorical_accuracy=0.9688281416893005, train/categorical_crossentropy=0.5830131769180298, train/f1_het=0.9537984728813171, train/f1_homalt=0.9860970973968506, train/f1_homref=0.9311457872390747, trai. n/f1_macro=0.9570137858390808, train/f1_micro=0.9688281416893005, train/f1_weighted=0.9684778451919556, train/false_negatives=988.0, train/false_positives=644.0, train/learning_rate=4.780000017490238e-05, train/loss=0.5830137133598328, train/precision=0.9745011329650879, train/preci. sion_het=0.9634146094322205, train/precision_homalt=0.9787381291389465, train/precision_homref=0.9703365564346313, train/recall=0.9614062309265137, train/recall_het=0.9402523040771484, train/recall_homalt=0.9935504198074341, train/recall_homref=0.8891792893409729, train/true_negativ. es=50556.0, train/true_positives=24612.0. I1101 04:34:10.308057 140558597089024 logging_writer.py:48] [4300] epoch=0, train/categorical_accuracy=0.9663281440734863, train/categorical_crossentropy=0.5852743983268738, train/f1_het=0.9510709643363953, train/f1_homalt=0.98508220911026, train/f1_homref=0.9242424964904785, train/. f1_macro=0.9534652233123779, train/f1_micro=0.9663281440734863, train/f1_weighted=0.9659736752510071, train/false_negatives=1079.0, train/false_positives=673.0, train/learning_rate=4.86999997519888e-05, train/loss=0.5852747559547424, train/precision=0.9732872843742371, train/precisi. on_het=0.9643771648406982, train/precision_homalt=0.9781907796859741, train/precision_homref=0.9655511975288391, train/recall=0.9578515887260437, train/recall_het=0.9316239356994629, train/recall_homalt=0.9919866919517517, train/recall_homref=0.8829882740974426, train/true_negatives. =50527.0, train/true_positives=24521.0. ```. Thanks in advance for your help! . Dan",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/904
https://github.com/google/deepvariant/issues/904:637,testability,test,test,637,"Low hom_ref recall during model training for new organism; Dear Devs, . I am currently training a model (starting from wgs.1.6.1) for use in a fish species. The programs are running well, I have confident regions and truth variants defined, and am currently tuning hyperparameters to optimise the training. . However . . . . I notice when tracking the model eval stats (specifically f1, precision, recall), that the hom_ref classifications are much less reliable than hom_alt and het classes. My question is whether this is to be expected, or whether there might be something wrong with my training setup, or perhaps the examples. . The test example set I am using to tune the hyperparams looks like this:. ```. # Generated by shuffle_tfrecords_beam.py. # class2: 89987. # class0: 33161. # class1: 24300. name: ""Shuffle_global"". tfrecord_path: ""/home/examples_shuffled/train/shuf_test/examples_shuf3_testset.shuffled-?????-of-?????.tfrecord.gz"". num_examples: 147448. ```. The training command looks like this:. ```. LR=0.001. BS=1024. apptainer run \. --nv \. -B $WD:/home \. $DV_PATH \. /opt/deepvariant/bin/train \. --config=/home/dv_config.py:base \. --config.train_dataset_pbtxt=""/home/examples_shuffled/train/shuf_test/examples_shuf3_testset_config.pbtxt"" \. --config.tune_dataset_pbtxt=""/home/examples_shuffled/tune_test/tune_test_examples_config.pbtxt"" \. --config.num_epochs=1 \. --config.learning_rate=${LR} \. --config.num_validation_examples=0 \. --config.tune_every_steps=2000 \. --experiment_dir=/home/${OUTDIR} \. --strategy=mirrored \. --config.batch_size=${BS} \. --config.init_checkpoint=""/home/model_wgs_v1.6.1/deepvariant.wgs.ckpt"". ```. During other tests I have run training jobs with several other example sets (several times larger), for tens of thousands of steps and multiple epochs, and also using different learning rates and batch sizes. While these things of course make a difference to learning performance, the lower recall for class 0 (hom_ref) remains consistent. . ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/904
https://github.com/google/deepvariant/issues/904:1671,testability,test,tests,1671,"he hyperparams looks like this:. ```. # Generated by shuffle_tfrecords_beam.py. # class2: 89987. # class0: 33161. # class1: 24300. name: ""Shuffle_global"". tfrecord_path: ""/home/examples_shuffled/train/shuf_test/examples_shuf3_testset.shuffled-?????-of-?????.tfrecord.gz"". num_examples: 147448. ```. The training command looks like this:. ```. LR=0.001. BS=1024. apptainer run \. --nv \. -B $WD:/home \. $DV_PATH \. /opt/deepvariant/bin/train \. --config=/home/dv_config.py:base \. --config.train_dataset_pbtxt=""/home/examples_shuffled/train/shuf_test/examples_shuf3_testset_config.pbtxt"" \. --config.tune_dataset_pbtxt=""/home/examples_shuffled/tune_test/tune_test_examples_config.pbtxt"" \. --config.num_epochs=1 \. --config.learning_rate=${LR} \. --config.num_validation_examples=0 \. --config.tune_every_steps=2000 \. --experiment_dir=/home/${OUTDIR} \. --strategy=mirrored \. --config.batch_size=${BS} \. --config.init_checkpoint=""/home/model_wgs_v1.6.1/deepvariant.wgs.ckpt"". ```. During other tests I have run training jobs with several other example sets (several times larger), for tens of thousands of steps and multiple epochs, and also using different learning rates and batch sizes. While these things of course make a difference to learning performance, the lower recall for class 0 (hom_ref) remains consistent. . Here are some lines from the log file during one such training run:. ```. I1031 10:55:27.365902 140558597089024 logging_writer.py:48] [0] epoch=0, train/categorical_accuracy=0.91796875, train/categorical_crossentropy=0.6384725570678711, train/f1_het=0.7428571581840515, train/f1_homalt=0.964401364326477, train/f1_homref=0.902255654335022, train/f1_macro=0. 8698380589485168, train/f1_micro=0.91796875, train/f1_weighted=0.9241795539855957, train/false_negatives=34.0, train/false_positives=14.0, train/learning_rate=9.999999747378752e-06, train/loss=0.6384731531143188, train/precision=0.9406779408454895, train/precision_het=0.702702701091. 7664, train/precision_homalt=0.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/904
https://github.com/google/deepvariant/issues/904:2029,testability,log,log,2029,"024. apptainer run \. --nv \. -B $WD:/home \. $DV_PATH \. /opt/deepvariant/bin/train \. --config=/home/dv_config.py:base \. --config.train_dataset_pbtxt=""/home/examples_shuffled/train/shuf_test/examples_shuf3_testset_config.pbtxt"" \. --config.tune_dataset_pbtxt=""/home/examples_shuffled/tune_test/tune_test_examples_config.pbtxt"" \. --config.num_epochs=1 \. --config.learning_rate=${LR} \. --config.num_validation_examples=0 \. --config.tune_every_steps=2000 \. --experiment_dir=/home/${OUTDIR} \. --strategy=mirrored \. --config.batch_size=${BS} \. --config.init_checkpoint=""/home/model_wgs_v1.6.1/deepvariant.wgs.ckpt"". ```. During other tests I have run training jobs with several other example sets (several times larger), for tens of thousands of steps and multiple epochs, and also using different learning rates and batch sizes. While these things of course make a difference to learning performance, the lower recall for class 0 (hom_ref) remains consistent. . Here are some lines from the log file during one such training run:. ```. I1031 10:55:27.365902 140558597089024 logging_writer.py:48] [0] epoch=0, train/categorical_accuracy=0.91796875, train/categorical_crossentropy=0.6384725570678711, train/f1_het=0.7428571581840515, train/f1_homalt=0.964401364326477, train/f1_homref=0.902255654335022, train/f1_macro=0. 8698380589485168, train/f1_micro=0.91796875, train/f1_weighted=0.9241795539855957, train/false_negatives=34.0, train/false_positives=14.0, train/learning_rate=9.999999747378752e-06, train/loss=0.6384731531143188, train/precision=0.9406779408454895, train/precision_het=0.702702701091. 7664, train/precision_homalt=0.978723406791687, train/precision_homref=1.0, train/recall=0.8671875, train/recall_het=1.0, train/recall_homalt=0.8789808750152588, train/recall_homref=0.7945205569267273, train/true_negatives=498.0, train/true_positives=222.0. I1031 11:18:53.873582 140558597089024 logging_writer.py:48] [100] epoch=0, train/categorical_accuracy=0.9428125023841858, train/ca",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/904
https://github.com/google/deepvariant/issues/904:986,usability,command,command,986,"Low hom_ref recall during model training for new organism; Dear Devs, . I am currently training a model (starting from wgs.1.6.1) for use in a fish species. The programs are running well, I have confident regions and truth variants defined, and am currently tuning hyperparameters to optimise the training. . However . . . . I notice when tracking the model eval stats (specifically f1, precision, recall), that the hom_ref classifications are much less reliable than hom_alt and het classes. My question is whether this is to be expected, or whether there might be something wrong with my training setup, or perhaps the examples. . The test example set I am using to tune the hyperparams looks like this:. ```. # Generated by shuffle_tfrecords_beam.py. # class2: 89987. # class0: 33161. # class1: 24300. name: ""Shuffle_global"". tfrecord_path: ""/home/examples_shuffled/train/shuf_test/examples_shuf3_testset.shuffled-?????-of-?????.tfrecord.gz"". num_examples: 147448. ```. The training command looks like this:. ```. LR=0.001. BS=1024. apptainer run \. --nv \. -B $WD:/home \. $DV_PATH \. /opt/deepvariant/bin/train \. --config=/home/dv_config.py:base \. --config.train_dataset_pbtxt=""/home/examples_shuffled/train/shuf_test/examples_shuf3_testset_config.pbtxt"" \. --config.tune_dataset_pbtxt=""/home/examples_shuffled/tune_test/tune_test_examples_config.pbtxt"" \. --config.num_epochs=1 \. --config.learning_rate=${LR} \. --config.num_validation_examples=0 \. --config.tune_every_steps=2000 \. --experiment_dir=/home/${OUTDIR} \. --strategy=mirrored \. --config.batch_size=${BS} \. --config.init_checkpoint=""/home/model_wgs_v1.6.1/deepvariant.wgs.ckpt"". ```. During other tests I have run training jobs with several other example sets (several times larger), for tens of thousands of steps and multiple epochs, and also using different learning rates and batch sizes. While these things of course make a difference to learning performance, the lower recall for class 0 (hom_ref) remains consistent. . ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/904
https://github.com/google/deepvariant/issues/904:1835,usability,learn,learning,1835,"ath: ""/home/examples_shuffled/train/shuf_test/examples_shuf3_testset.shuffled-?????-of-?????.tfrecord.gz"". num_examples: 147448. ```. The training command looks like this:. ```. LR=0.001. BS=1024. apptainer run \. --nv \. -B $WD:/home \. $DV_PATH \. /opt/deepvariant/bin/train \. --config=/home/dv_config.py:base \. --config.train_dataset_pbtxt=""/home/examples_shuffled/train/shuf_test/examples_shuf3_testset_config.pbtxt"" \. --config.tune_dataset_pbtxt=""/home/examples_shuffled/tune_test/tune_test_examples_config.pbtxt"" \. --config.num_epochs=1 \. --config.learning_rate=${LR} \. --config.num_validation_examples=0 \. --config.tune_every_steps=2000 \. --experiment_dir=/home/${OUTDIR} \. --strategy=mirrored \. --config.batch_size=${BS} \. --config.init_checkpoint=""/home/model_wgs_v1.6.1/deepvariant.wgs.ckpt"". ```. During other tests I have run training jobs with several other example sets (several times larger), for tens of thousands of steps and multiple epochs, and also using different learning rates and batch sizes. While these things of course make a difference to learning performance, the lower recall for class 0 (hom_ref) remains consistent. . Here are some lines from the log file during one such training run:. ```. I1031 10:55:27.365902 140558597089024 logging_writer.py:48] [0] epoch=0, train/categorical_accuracy=0.91796875, train/categorical_crossentropy=0.6384725570678711, train/f1_het=0.7428571581840515, train/f1_homalt=0.964401364326477, train/f1_homref=0.902255654335022, train/f1_macro=0. 8698380589485168, train/f1_micro=0.91796875, train/f1_weighted=0.9241795539855957, train/false_negatives=34.0, train/false_positives=14.0, train/learning_rate=9.999999747378752e-06, train/loss=0.6384731531143188, train/precision=0.9406779408454895, train/precision_het=0.702702701091. 7664, train/precision_homalt=0.978723406791687, train/precision_homref=1.0, train/recall=0.8671875, train/recall_het=1.0, train/recall_homalt=0.8789808750152588, train/recall_homref=0.794520556926",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/904
https://github.com/google/deepvariant/issues/904:1917,usability,learn,learning,1917,"?-of-?????.tfrecord.gz"". num_examples: 147448. ```. The training command looks like this:. ```. LR=0.001. BS=1024. apptainer run \. --nv \. -B $WD:/home \. $DV_PATH \. /opt/deepvariant/bin/train \. --config=/home/dv_config.py:base \. --config.train_dataset_pbtxt=""/home/examples_shuffled/train/shuf_test/examples_shuf3_testset_config.pbtxt"" \. --config.tune_dataset_pbtxt=""/home/examples_shuffled/tune_test/tune_test_examples_config.pbtxt"" \. --config.num_epochs=1 \. --config.learning_rate=${LR} \. --config.num_validation_examples=0 \. --config.tune_every_steps=2000 \. --experiment_dir=/home/${OUTDIR} \. --strategy=mirrored \. --config.batch_size=${BS} \. --config.init_checkpoint=""/home/model_wgs_v1.6.1/deepvariant.wgs.ckpt"". ```. During other tests I have run training jobs with several other example sets (several times larger), for tens of thousands of steps and multiple epochs, and also using different learning rates and batch sizes. While these things of course make a difference to learning performance, the lower recall for class 0 (hom_ref) remains consistent. . Here are some lines from the log file during one such training run:. ```. I1031 10:55:27.365902 140558597089024 logging_writer.py:48] [0] epoch=0, train/categorical_accuracy=0.91796875, train/categorical_crossentropy=0.6384725570678711, train/f1_het=0.7428571581840515, train/f1_homalt=0.964401364326477, train/f1_homref=0.902255654335022, train/f1_macro=0. 8698380589485168, train/f1_micro=0.91796875, train/f1_weighted=0.9241795539855957, train/false_negatives=34.0, train/false_positives=14.0, train/learning_rate=9.999999747378752e-06, train/loss=0.6384731531143188, train/precision=0.9406779408454895, train/precision_het=0.702702701091. 7664, train/precision_homalt=0.978723406791687, train/precision_homref=1.0, train/recall=0.8671875, train/recall_het=1.0, train/recall_homalt=0.8789808750152588, train/recall_homref=0.7945205569267273, train/true_negatives=498.0, train/true_positives=222.0. I1031 11:18:53.87358",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/904
https://github.com/google/deepvariant/issues/904:1926,usability,perform,performance,1926,"tfrecord.gz"". num_examples: 147448. ```. The training command looks like this:. ```. LR=0.001. BS=1024. apptainer run \. --nv \. -B $WD:/home \. $DV_PATH \. /opt/deepvariant/bin/train \. --config=/home/dv_config.py:base \. --config.train_dataset_pbtxt=""/home/examples_shuffled/train/shuf_test/examples_shuf3_testset_config.pbtxt"" \. --config.tune_dataset_pbtxt=""/home/examples_shuffled/tune_test/tune_test_examples_config.pbtxt"" \. --config.num_epochs=1 \. --config.learning_rate=${LR} \. --config.num_validation_examples=0 \. --config.tune_every_steps=2000 \. --experiment_dir=/home/${OUTDIR} \. --strategy=mirrored \. --config.batch_size=${BS} \. --config.init_checkpoint=""/home/model_wgs_v1.6.1/deepvariant.wgs.ckpt"". ```. During other tests I have run training jobs with several other example sets (several times larger), for tens of thousands of steps and multiple epochs, and also using different learning rates and batch sizes. While these things of course make a difference to learning performance, the lower recall for class 0 (hom_ref) remains consistent. . Here are some lines from the log file during one such training run:. ```. I1031 10:55:27.365902 140558597089024 logging_writer.py:48] [0] epoch=0, train/categorical_accuracy=0.91796875, train/categorical_crossentropy=0.6384725570678711, train/f1_het=0.7428571581840515, train/f1_homalt=0.964401364326477, train/f1_homref=0.902255654335022, train/f1_macro=0. 8698380589485168, train/f1_micro=0.91796875, train/f1_weighted=0.9241795539855957, train/false_negatives=34.0, train/false_positives=14.0, train/learning_rate=9.999999747378752e-06, train/loss=0.6384731531143188, train/precision=0.9406779408454895, train/precision_het=0.702702701091. 7664, train/precision_homalt=0.978723406791687, train/precision_homref=1.0, train/recall=0.8671875, train/recall_het=1.0, train/recall_homalt=0.8789808750152588, train/recall_homref=0.7945205569267273, train/true_negatives=498.0, train/true_positives=222.0. I1031 11:18:53.873582 140558597",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/904
https://github.com/google/deepvariant/issues/904:1986,usability,consist,consistent,1986,"nd looks like this:. ```. LR=0.001. BS=1024. apptainer run \. --nv \. -B $WD:/home \. $DV_PATH \. /opt/deepvariant/bin/train \. --config=/home/dv_config.py:base \. --config.train_dataset_pbtxt=""/home/examples_shuffled/train/shuf_test/examples_shuf3_testset_config.pbtxt"" \. --config.tune_dataset_pbtxt=""/home/examples_shuffled/tune_test/tune_test_examples_config.pbtxt"" \. --config.num_epochs=1 \. --config.learning_rate=${LR} \. --config.num_validation_examples=0 \. --config.tune_every_steps=2000 \. --experiment_dir=/home/${OUTDIR} \. --strategy=mirrored \. --config.batch_size=${BS} \. --config.init_checkpoint=""/home/model_wgs_v1.6.1/deepvariant.wgs.ckpt"". ```. During other tests I have run training jobs with several other example sets (several times larger), for tens of thousands of steps and multiple epochs, and also using different learning rates and batch sizes. While these things of course make a difference to learning performance, the lower recall for class 0 (hom_ref) remains consistent. . Here are some lines from the log file during one such training run:. ```. I1031 10:55:27.365902 140558597089024 logging_writer.py:48] [0] epoch=0, train/categorical_accuracy=0.91796875, train/categorical_crossentropy=0.6384725570678711, train/f1_het=0.7428571581840515, train/f1_homalt=0.964401364326477, train/f1_homref=0.902255654335022, train/f1_macro=0. 8698380589485168, train/f1_micro=0.91796875, train/f1_weighted=0.9241795539855957, train/false_negatives=34.0, train/false_positives=14.0, train/learning_rate=9.999999747378752e-06, train/loss=0.6384731531143188, train/precision=0.9406779408454895, train/precision_het=0.702702701091. 7664, train/precision_homalt=0.978723406791687, train/precision_homref=1.0, train/recall=0.8671875, train/recall_het=1.0, train/recall_homalt=0.8789808750152588, train/recall_homref=0.7945205569267273, train/true_negatives=498.0, train/true_positives=222.0. I1031 11:18:53.873582 140558597089024 logging_writer.py:48] [100] epoch=0, train/categoric",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/904
https://github.com/google/deepvariant/issues/904:11900,usability,help,help,11900,"l_het=0.934234619140625, train/recall_homalt=0.991542398929596, train/recall_homref=0.891943633556366, train/true_negatives. =50538.0, train/true_positives=24561.0. I1101 04:10:37.281655 140558597089024 logging_writer.py:48] [4200] epoch=0, train/categorical_accuracy=0.9688281416893005, train/categorical_crossentropy=0.5830131769180298, train/f1_het=0.9537984728813171, train/f1_homalt=0.9860970973968506, train/f1_homref=0.9311457872390747, trai. n/f1_macro=0.9570137858390808, train/f1_micro=0.9688281416893005, train/f1_weighted=0.9684778451919556, train/false_negatives=988.0, train/false_positives=644.0, train/learning_rate=4.780000017490238e-05, train/loss=0.5830137133598328, train/precision=0.9745011329650879, train/preci. sion_het=0.9634146094322205, train/precision_homalt=0.9787381291389465, train/precision_homref=0.9703365564346313, train/recall=0.9614062309265137, train/recall_het=0.9402523040771484, train/recall_homalt=0.9935504198074341, train/recall_homref=0.8891792893409729, train/true_negativ. es=50556.0, train/true_positives=24612.0. I1101 04:34:10.308057 140558597089024 logging_writer.py:48] [4300] epoch=0, train/categorical_accuracy=0.9663281440734863, train/categorical_crossentropy=0.5852743983268738, train/f1_het=0.9510709643363953, train/f1_homalt=0.98508220911026, train/f1_homref=0.9242424964904785, train/. f1_macro=0.9534652233123779, train/f1_micro=0.9663281440734863, train/f1_weighted=0.9659736752510071, train/false_negatives=1079.0, train/false_positives=673.0, train/learning_rate=4.86999997519888e-05, train/loss=0.5852747559547424, train/precision=0.9732872843742371, train/precisi. on_het=0.9643771648406982, train/precision_homalt=0.9781907796859741, train/precision_homref=0.9655511975288391, train/recall=0.9578515887260437, train/recall_het=0.9316239356994629, train/recall_homalt=0.9919866919517517, train/recall_homref=0.8829882740974426, train/true_negatives. =50527.0, train/true_positives=24521.0. ```. Thanks in advance for your help! . Dan",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/904
https://github.com/google/deepvariant/issues/905:46,deployability,stage,stages,46,"Is it possible to run deepvariant in discreet stages with discreet resource requests?; Hi folks,. Our users are running deepvariant on our HPC and resource requests are proving quite tricky for them as different stages of the pipeline seem to have different resource needs. This leaves execution nodes essentially idle for much of the time of the jobs' running. In the two days runtime you can see below that a user who has asked for 48 cpus doesn't use most of the cores for most of the time:. ![Image](https://github.com/user-attachments/assets/c631a80d-a7b3-435a-ac50-97a1743f7638). ```. singularity run deepvariant_1.6.1.sif /opt/deepvariant/bin/run_deepvariant \. --model_type ONT_R104 \. --ref /path/to/their/reference.fasta \. --reads /path/to/their/input.bam \. --sample_name unique_name \. --output_vcf /path/to/their/unique_name.vcf.gz \. --output_gvcf /path/to/their/unique_name.g.vcf.gz \. --num_shards 48. ```. Is there a way that each stage of the pipeline with discreet resource requests so that the bits that can be cleanly parallelized can go in one job submission and the stages that don't can be in separate jobs/commands, to avoid having requested and reserved resources being idle? Cheers",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/905
https://github.com/google/deepvariant/issues/905:67,deployability,resourc,resource,67,"Is it possible to run deepvariant in discreet stages with discreet resource requests?; Hi folks,. Our users are running deepvariant on our HPC and resource requests are proving quite tricky for them as different stages of the pipeline seem to have different resource needs. This leaves execution nodes essentially idle for much of the time of the jobs' running. In the two days runtime you can see below that a user who has asked for 48 cpus doesn't use most of the cores for most of the time:. ![Image](https://github.com/user-attachments/assets/c631a80d-a7b3-435a-ac50-97a1743f7638). ```. singularity run deepvariant_1.6.1.sif /opt/deepvariant/bin/run_deepvariant \. --model_type ONT_R104 \. --ref /path/to/their/reference.fasta \. --reads /path/to/their/input.bam \. --sample_name unique_name \. --output_vcf /path/to/their/unique_name.vcf.gz \. --output_gvcf /path/to/their/unique_name.g.vcf.gz \. --num_shards 48. ```. Is there a way that each stage of the pipeline with discreet resource requests so that the bits that can be cleanly parallelized can go in one job submission and the stages that don't can be in separate jobs/commands, to avoid having requested and reserved resources being idle? Cheers",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/905
https://github.com/google/deepvariant/issues/905:147,deployability,resourc,resource,147,"Is it possible to run deepvariant in discreet stages with discreet resource requests?; Hi folks,. Our users are running deepvariant on our HPC and resource requests are proving quite tricky for them as different stages of the pipeline seem to have different resource needs. This leaves execution nodes essentially idle for much of the time of the jobs' running. In the two days runtime you can see below that a user who has asked for 48 cpus doesn't use most of the cores for most of the time:. ![Image](https://github.com/user-attachments/assets/c631a80d-a7b3-435a-ac50-97a1743f7638). ```. singularity run deepvariant_1.6.1.sif /opt/deepvariant/bin/run_deepvariant \. --model_type ONT_R104 \. --ref /path/to/their/reference.fasta \. --reads /path/to/their/input.bam \. --sample_name unique_name \. --output_vcf /path/to/their/unique_name.vcf.gz \. --output_gvcf /path/to/their/unique_name.g.vcf.gz \. --num_shards 48. ```. Is there a way that each stage of the pipeline with discreet resource requests so that the bits that can be cleanly parallelized can go in one job submission and the stages that don't can be in separate jobs/commands, to avoid having requested and reserved resources being idle? Cheers",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/905
https://github.com/google/deepvariant/issues/905:212,deployability,stage,stages,212,"Is it possible to run deepvariant in discreet stages with discreet resource requests?; Hi folks,. Our users are running deepvariant on our HPC and resource requests are proving quite tricky for them as different stages of the pipeline seem to have different resource needs. This leaves execution nodes essentially idle for much of the time of the jobs' running. In the two days runtime you can see below that a user who has asked for 48 cpus doesn't use most of the cores for most of the time:. ![Image](https://github.com/user-attachments/assets/c631a80d-a7b3-435a-ac50-97a1743f7638). ```. singularity run deepvariant_1.6.1.sif /opt/deepvariant/bin/run_deepvariant \. --model_type ONT_R104 \. --ref /path/to/their/reference.fasta \. --reads /path/to/their/input.bam \. --sample_name unique_name \. --output_vcf /path/to/their/unique_name.vcf.gz \. --output_gvcf /path/to/their/unique_name.g.vcf.gz \. --num_shards 48. ```. Is there a way that each stage of the pipeline with discreet resource requests so that the bits that can be cleanly parallelized can go in one job submission and the stages that don't can be in separate jobs/commands, to avoid having requested and reserved resources being idle? Cheers",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/905
https://github.com/google/deepvariant/issues/905:226,deployability,pipelin,pipeline,226,"Is it possible to run deepvariant in discreet stages with discreet resource requests?; Hi folks,. Our users are running deepvariant on our HPC and resource requests are proving quite tricky for them as different stages of the pipeline seem to have different resource needs. This leaves execution nodes essentially idle for much of the time of the jobs' running. In the two days runtime you can see below that a user who has asked for 48 cpus doesn't use most of the cores for most of the time:. ![Image](https://github.com/user-attachments/assets/c631a80d-a7b3-435a-ac50-97a1743f7638). ```. singularity run deepvariant_1.6.1.sif /opt/deepvariant/bin/run_deepvariant \. --model_type ONT_R104 \. --ref /path/to/their/reference.fasta \. --reads /path/to/their/input.bam \. --sample_name unique_name \. --output_vcf /path/to/their/unique_name.vcf.gz \. --output_gvcf /path/to/their/unique_name.g.vcf.gz \. --num_shards 48. ```. Is there a way that each stage of the pipeline with discreet resource requests so that the bits that can be cleanly parallelized can go in one job submission and the stages that don't can be in separate jobs/commands, to avoid having requested and reserved resources being idle? Cheers",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/905
https://github.com/google/deepvariant/issues/905:258,deployability,resourc,resource,258,"Is it possible to run deepvariant in discreet stages with discreet resource requests?; Hi folks,. Our users are running deepvariant on our HPC and resource requests are proving quite tricky for them as different stages of the pipeline seem to have different resource needs. This leaves execution nodes essentially idle for much of the time of the jobs' running. In the two days runtime you can see below that a user who has asked for 48 cpus doesn't use most of the cores for most of the time:. ![Image](https://github.com/user-attachments/assets/c631a80d-a7b3-435a-ac50-97a1743f7638). ```. singularity run deepvariant_1.6.1.sif /opt/deepvariant/bin/run_deepvariant \. --model_type ONT_R104 \. --ref /path/to/their/reference.fasta \. --reads /path/to/their/input.bam \. --sample_name unique_name \. --output_vcf /path/to/their/unique_name.vcf.gz \. --output_gvcf /path/to/their/unique_name.g.vcf.gz \. --num_shards 48. ```. Is there a way that each stage of the pipeline with discreet resource requests so that the bits that can be cleanly parallelized can go in one job submission and the stages that don't can be in separate jobs/commands, to avoid having requested and reserved resources being idle? Cheers",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/905
https://github.com/google/deepvariant/issues/905:949,deployability,stage,stage,949,"Is it possible to run deepvariant in discreet stages with discreet resource requests?; Hi folks,. Our users are running deepvariant on our HPC and resource requests are proving quite tricky for them as different stages of the pipeline seem to have different resource needs. This leaves execution nodes essentially idle for much of the time of the jobs' running. In the two days runtime you can see below that a user who has asked for 48 cpus doesn't use most of the cores for most of the time:. ![Image](https://github.com/user-attachments/assets/c631a80d-a7b3-435a-ac50-97a1743f7638). ```. singularity run deepvariant_1.6.1.sif /opt/deepvariant/bin/run_deepvariant \. --model_type ONT_R104 \. --ref /path/to/their/reference.fasta \. --reads /path/to/their/input.bam \. --sample_name unique_name \. --output_vcf /path/to/their/unique_name.vcf.gz \. --output_gvcf /path/to/their/unique_name.g.vcf.gz \. --num_shards 48. ```. Is there a way that each stage of the pipeline with discreet resource requests so that the bits that can be cleanly parallelized can go in one job submission and the stages that don't can be in separate jobs/commands, to avoid having requested and reserved resources being idle? Cheers",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/905
https://github.com/google/deepvariant/issues/905:962,deployability,pipelin,pipeline,962,"Is it possible to run deepvariant in discreet stages with discreet resource requests?; Hi folks,. Our users are running deepvariant on our HPC and resource requests are proving quite tricky for them as different stages of the pipeline seem to have different resource needs. This leaves execution nodes essentially idle for much of the time of the jobs' running. In the two days runtime you can see below that a user who has asked for 48 cpus doesn't use most of the cores for most of the time:. ![Image](https://github.com/user-attachments/assets/c631a80d-a7b3-435a-ac50-97a1743f7638). ```. singularity run deepvariant_1.6.1.sif /opt/deepvariant/bin/run_deepvariant \. --model_type ONT_R104 \. --ref /path/to/their/reference.fasta \. --reads /path/to/their/input.bam \. --sample_name unique_name \. --output_vcf /path/to/their/unique_name.vcf.gz \. --output_gvcf /path/to/their/unique_name.g.vcf.gz \. --num_shards 48. ```. Is there a way that each stage of the pipeline with discreet resource requests so that the bits that can be cleanly parallelized can go in one job submission and the stages that don't can be in separate jobs/commands, to avoid having requested and reserved resources being idle? Cheers",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/905
https://github.com/google/deepvariant/issues/905:985,deployability,resourc,resource,985,"Is it possible to run deepvariant in discreet stages with discreet resource requests?; Hi folks,. Our users are running deepvariant on our HPC and resource requests are proving quite tricky for them as different stages of the pipeline seem to have different resource needs. This leaves execution nodes essentially idle for much of the time of the jobs' running. In the two days runtime you can see below that a user who has asked for 48 cpus doesn't use most of the cores for most of the time:. ![Image](https://github.com/user-attachments/assets/c631a80d-a7b3-435a-ac50-97a1743f7638). ```. singularity run deepvariant_1.6.1.sif /opt/deepvariant/bin/run_deepvariant \. --model_type ONT_R104 \. --ref /path/to/their/reference.fasta \. --reads /path/to/their/input.bam \. --sample_name unique_name \. --output_vcf /path/to/their/unique_name.vcf.gz \. --output_gvcf /path/to/their/unique_name.g.vcf.gz \. --num_shards 48. ```. Is there a way that each stage of the pipeline with discreet resource requests so that the bits that can be cleanly parallelized can go in one job submission and the stages that don't can be in separate jobs/commands, to avoid having requested and reserved resources being idle? Cheers",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/905
https://github.com/google/deepvariant/issues/905:1090,deployability,stage,stages,1090,"Is it possible to run deepvariant in discreet stages with discreet resource requests?; Hi folks,. Our users are running deepvariant on our HPC and resource requests are proving quite tricky for them as different stages of the pipeline seem to have different resource needs. This leaves execution nodes essentially idle for much of the time of the jobs' running. In the two days runtime you can see below that a user who has asked for 48 cpus doesn't use most of the cores for most of the time:. ![Image](https://github.com/user-attachments/assets/c631a80d-a7b3-435a-ac50-97a1743f7638). ```. singularity run deepvariant_1.6.1.sif /opt/deepvariant/bin/run_deepvariant \. --model_type ONT_R104 \. --ref /path/to/their/reference.fasta \. --reads /path/to/their/input.bam \. --sample_name unique_name \. --output_vcf /path/to/their/unique_name.vcf.gz \. --output_gvcf /path/to/their/unique_name.g.vcf.gz \. --num_shards 48. ```. Is there a way that each stage of the pipeline with discreet resource requests so that the bits that can be cleanly parallelized can go in one job submission and the stages that don't can be in separate jobs/commands, to avoid having requested and reserved resources being idle? Cheers",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/905
https://github.com/google/deepvariant/issues/905:1181,deployability,resourc,resources,1181,"Is it possible to run deepvariant in discreet stages with discreet resource requests?; Hi folks,. Our users are running deepvariant on our HPC and resource requests are proving quite tricky for them as different stages of the pipeline seem to have different resource needs. This leaves execution nodes essentially idle for much of the time of the jobs' running. In the two days runtime you can see below that a user who has asked for 48 cpus doesn't use most of the cores for most of the time:. ![Image](https://github.com/user-attachments/assets/c631a80d-a7b3-435a-ac50-97a1743f7638). ```. singularity run deepvariant_1.6.1.sif /opt/deepvariant/bin/run_deepvariant \. --model_type ONT_R104 \. --ref /path/to/their/reference.fasta \. --reads /path/to/their/input.bam \. --sample_name unique_name \. --output_vcf /path/to/their/unique_name.vcf.gz \. --output_gvcf /path/to/their/unique_name.g.vcf.gz \. --num_shards 48. ```. Is there a way that each stage of the pipeline with discreet resource requests so that the bits that can be cleanly parallelized can go in one job submission and the stages that don't can be in separate jobs/commands, to avoid having requested and reserved resources being idle? Cheers",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/905
https://github.com/google/deepvariant/issues/905:67,energy efficiency,resourc,resource,67,"Is it possible to run deepvariant in discreet stages with discreet resource requests?; Hi folks,. Our users are running deepvariant on our HPC and resource requests are proving quite tricky for them as different stages of the pipeline seem to have different resource needs. This leaves execution nodes essentially idle for much of the time of the jobs' running. In the two days runtime you can see below that a user who has asked for 48 cpus doesn't use most of the cores for most of the time:. ![Image](https://github.com/user-attachments/assets/c631a80d-a7b3-435a-ac50-97a1743f7638). ```. singularity run deepvariant_1.6.1.sif /opt/deepvariant/bin/run_deepvariant \. --model_type ONT_R104 \. --ref /path/to/their/reference.fasta \. --reads /path/to/their/input.bam \. --sample_name unique_name \. --output_vcf /path/to/their/unique_name.vcf.gz \. --output_gvcf /path/to/their/unique_name.g.vcf.gz \. --num_shards 48. ```. Is there a way that each stage of the pipeline with discreet resource requests so that the bits that can be cleanly parallelized can go in one job submission and the stages that don't can be in separate jobs/commands, to avoid having requested and reserved resources being idle? Cheers",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/905
https://github.com/google/deepvariant/issues/905:147,energy efficiency,resourc,resource,147,"Is it possible to run deepvariant in discreet stages with discreet resource requests?; Hi folks,. Our users are running deepvariant on our HPC and resource requests are proving quite tricky for them as different stages of the pipeline seem to have different resource needs. This leaves execution nodes essentially idle for much of the time of the jobs' running. In the two days runtime you can see below that a user who has asked for 48 cpus doesn't use most of the cores for most of the time:. ![Image](https://github.com/user-attachments/assets/c631a80d-a7b3-435a-ac50-97a1743f7638). ```. singularity run deepvariant_1.6.1.sif /opt/deepvariant/bin/run_deepvariant \. --model_type ONT_R104 \. --ref /path/to/their/reference.fasta \. --reads /path/to/their/input.bam \. --sample_name unique_name \. --output_vcf /path/to/their/unique_name.vcf.gz \. --output_gvcf /path/to/their/unique_name.g.vcf.gz \. --num_shards 48. ```. Is there a way that each stage of the pipeline with discreet resource requests so that the bits that can be cleanly parallelized can go in one job submission and the stages that don't can be in separate jobs/commands, to avoid having requested and reserved resources being idle? Cheers",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/905
https://github.com/google/deepvariant/issues/905:258,energy efficiency,resourc,resource,258,"Is it possible to run deepvariant in discreet stages with discreet resource requests?; Hi folks,. Our users are running deepvariant on our HPC and resource requests are proving quite tricky for them as different stages of the pipeline seem to have different resource needs. This leaves execution nodes essentially idle for much of the time of the jobs' running. In the two days runtime you can see below that a user who has asked for 48 cpus doesn't use most of the cores for most of the time:. ![Image](https://github.com/user-attachments/assets/c631a80d-a7b3-435a-ac50-97a1743f7638). ```. singularity run deepvariant_1.6.1.sif /opt/deepvariant/bin/run_deepvariant \. --model_type ONT_R104 \. --ref /path/to/their/reference.fasta \. --reads /path/to/their/input.bam \. --sample_name unique_name \. --output_vcf /path/to/their/unique_name.vcf.gz \. --output_gvcf /path/to/their/unique_name.g.vcf.gz \. --num_shards 48. ```. Is there a way that each stage of the pipeline with discreet resource requests so that the bits that can be cleanly parallelized can go in one job submission and the stages that don't can be in separate jobs/commands, to avoid having requested and reserved resources being idle? Cheers",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/905
https://github.com/google/deepvariant/issues/905:314,energy efficiency,idl,idle,314,"Is it possible to run deepvariant in discreet stages with discreet resource requests?; Hi folks,. Our users are running deepvariant on our HPC and resource requests are proving quite tricky for them as different stages of the pipeline seem to have different resource needs. This leaves execution nodes essentially idle for much of the time of the jobs' running. In the two days runtime you can see below that a user who has asked for 48 cpus doesn't use most of the cores for most of the time:. ![Image](https://github.com/user-attachments/assets/c631a80d-a7b3-435a-ac50-97a1743f7638). ```. singularity run deepvariant_1.6.1.sif /opt/deepvariant/bin/run_deepvariant \. --model_type ONT_R104 \. --ref /path/to/their/reference.fasta \. --reads /path/to/their/input.bam \. --sample_name unique_name \. --output_vcf /path/to/their/unique_name.vcf.gz \. --output_gvcf /path/to/their/unique_name.g.vcf.gz \. --num_shards 48. ```. Is there a way that each stage of the pipeline with discreet resource requests so that the bits that can be cleanly parallelized can go in one job submission and the stages that don't can be in separate jobs/commands, to avoid having requested and reserved resources being idle? Cheers",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/905
https://github.com/google/deepvariant/issues/905:437,energy efficiency,cpu,cpus,437,"Is it possible to run deepvariant in discreet stages with discreet resource requests?; Hi folks,. Our users are running deepvariant on our HPC and resource requests are proving quite tricky for them as different stages of the pipeline seem to have different resource needs. This leaves execution nodes essentially idle for much of the time of the jobs' running. In the two days runtime you can see below that a user who has asked for 48 cpus doesn't use most of the cores for most of the time:. ![Image](https://github.com/user-attachments/assets/c631a80d-a7b3-435a-ac50-97a1743f7638). ```. singularity run deepvariant_1.6.1.sif /opt/deepvariant/bin/run_deepvariant \. --model_type ONT_R104 \. --ref /path/to/their/reference.fasta \. --reads /path/to/their/input.bam \. --sample_name unique_name \. --output_vcf /path/to/their/unique_name.vcf.gz \. --output_gvcf /path/to/their/unique_name.g.vcf.gz \. --num_shards 48. ```. Is there a way that each stage of the pipeline with discreet resource requests so that the bits that can be cleanly parallelized can go in one job submission and the stages that don't can be in separate jobs/commands, to avoid having requested and reserved resources being idle? Cheers",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/905
https://github.com/google/deepvariant/issues/905:466,energy efficiency,core,cores,466,"Is it possible to run deepvariant in discreet stages with discreet resource requests?; Hi folks,. Our users are running deepvariant on our HPC and resource requests are proving quite tricky for them as different stages of the pipeline seem to have different resource needs. This leaves execution nodes essentially idle for much of the time of the jobs' running. In the two days runtime you can see below that a user who has asked for 48 cpus doesn't use most of the cores for most of the time:. ![Image](https://github.com/user-attachments/assets/c631a80d-a7b3-435a-ac50-97a1743f7638). ```. singularity run deepvariant_1.6.1.sif /opt/deepvariant/bin/run_deepvariant \. --model_type ONT_R104 \. --ref /path/to/their/reference.fasta \. --reads /path/to/their/input.bam \. --sample_name unique_name \. --output_vcf /path/to/their/unique_name.vcf.gz \. --output_gvcf /path/to/their/unique_name.g.vcf.gz \. --num_shards 48. ```. Is there a way that each stage of the pipeline with discreet resource requests so that the bits that can be cleanly parallelized can go in one job submission and the stages that don't can be in separate jobs/commands, to avoid having requested and reserved resources being idle? Cheers",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/905
https://github.com/google/deepvariant/issues/905:985,energy efficiency,resourc,resource,985,"Is it possible to run deepvariant in discreet stages with discreet resource requests?; Hi folks,. Our users are running deepvariant on our HPC and resource requests are proving quite tricky for them as different stages of the pipeline seem to have different resource needs. This leaves execution nodes essentially idle for much of the time of the jobs' running. In the two days runtime you can see below that a user who has asked for 48 cpus doesn't use most of the cores for most of the time:. ![Image](https://github.com/user-attachments/assets/c631a80d-a7b3-435a-ac50-97a1743f7638). ```. singularity run deepvariant_1.6.1.sif /opt/deepvariant/bin/run_deepvariant \. --model_type ONT_R104 \. --ref /path/to/their/reference.fasta \. --reads /path/to/their/input.bam \. --sample_name unique_name \. --output_vcf /path/to/their/unique_name.vcf.gz \. --output_gvcf /path/to/their/unique_name.g.vcf.gz \. --num_shards 48. ```. Is there a way that each stage of the pipeline with discreet resource requests so that the bits that can be cleanly parallelized can go in one job submission and the stages that don't can be in separate jobs/commands, to avoid having requested and reserved resources being idle? Cheers",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/905
https://github.com/google/deepvariant/issues/905:1181,energy efficiency,resourc,resources,1181,"Is it possible to run deepvariant in discreet stages with discreet resource requests?; Hi folks,. Our users are running deepvariant on our HPC and resource requests are proving quite tricky for them as different stages of the pipeline seem to have different resource needs. This leaves execution nodes essentially idle for much of the time of the jobs' running. In the two days runtime you can see below that a user who has asked for 48 cpus doesn't use most of the cores for most of the time:. ![Image](https://github.com/user-attachments/assets/c631a80d-a7b3-435a-ac50-97a1743f7638). ```. singularity run deepvariant_1.6.1.sif /opt/deepvariant/bin/run_deepvariant \. --model_type ONT_R104 \. --ref /path/to/their/reference.fasta \. --reads /path/to/their/input.bam \. --sample_name unique_name \. --output_vcf /path/to/their/unique_name.vcf.gz \. --output_gvcf /path/to/their/unique_name.g.vcf.gz \. --num_shards 48. ```. Is there a way that each stage of the pipeline with discreet resource requests so that the bits that can be cleanly parallelized can go in one job submission and the stages that don't can be in separate jobs/commands, to avoid having requested and reserved resources being idle? Cheers",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/905
https://github.com/google/deepvariant/issues/905:1197,energy efficiency,idl,idle,1197,"Is it possible to run deepvariant in discreet stages with discreet resource requests?; Hi folks,. Our users are running deepvariant on our HPC and resource requests are proving quite tricky for them as different stages of the pipeline seem to have different resource needs. This leaves execution nodes essentially idle for much of the time of the jobs' running. In the two days runtime you can see below that a user who has asked for 48 cpus doesn't use most of the cores for most of the time:. ![Image](https://github.com/user-attachments/assets/c631a80d-a7b3-435a-ac50-97a1743f7638). ```. singularity run deepvariant_1.6.1.sif /opt/deepvariant/bin/run_deepvariant \. --model_type ONT_R104 \. --ref /path/to/their/reference.fasta \. --reads /path/to/their/input.bam \. --sample_name unique_name \. --output_vcf /path/to/their/unique_name.vcf.gz \. --output_gvcf /path/to/their/unique_name.g.vcf.gz \. --num_shards 48. ```. Is there a way that each stage of the pipeline with discreet resource requests so that the bits that can be cleanly parallelized can go in one job submission and the stages that don't can be in separate jobs/commands, to avoid having requested and reserved resources being idle? Cheers",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/905
https://github.com/google/deepvariant/issues/905:226,integrability,pipelin,pipeline,226,"Is it possible to run deepvariant in discreet stages with discreet resource requests?; Hi folks,. Our users are running deepvariant on our HPC and resource requests are proving quite tricky for them as different stages of the pipeline seem to have different resource needs. This leaves execution nodes essentially idle for much of the time of the jobs' running. In the two days runtime you can see below that a user who has asked for 48 cpus doesn't use most of the cores for most of the time:. ![Image](https://github.com/user-attachments/assets/c631a80d-a7b3-435a-ac50-97a1743f7638). ```. singularity run deepvariant_1.6.1.sif /opt/deepvariant/bin/run_deepvariant \. --model_type ONT_R104 \. --ref /path/to/their/reference.fasta \. --reads /path/to/their/input.bam \. --sample_name unique_name \. --output_vcf /path/to/their/unique_name.vcf.gz \. --output_gvcf /path/to/their/unique_name.g.vcf.gz \. --num_shards 48. ```. Is there a way that each stage of the pipeline with discreet resource requests so that the bits that can be cleanly parallelized can go in one job submission and the stages that don't can be in separate jobs/commands, to avoid having requested and reserved resources being idle? Cheers",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/905
https://github.com/google/deepvariant/issues/905:962,integrability,pipelin,pipeline,962,"Is it possible to run deepvariant in discreet stages with discreet resource requests?; Hi folks,. Our users are running deepvariant on our HPC and resource requests are proving quite tricky for them as different stages of the pipeline seem to have different resource needs. This leaves execution nodes essentially idle for much of the time of the jobs' running. In the two days runtime you can see below that a user who has asked for 48 cpus doesn't use most of the cores for most of the time:. ![Image](https://github.com/user-attachments/assets/c631a80d-a7b3-435a-ac50-97a1743f7638). ```. singularity run deepvariant_1.6.1.sif /opt/deepvariant/bin/run_deepvariant \. --model_type ONT_R104 \. --ref /path/to/their/reference.fasta \. --reads /path/to/their/input.bam \. --sample_name unique_name \. --output_vcf /path/to/their/unique_name.vcf.gz \. --output_gvcf /path/to/their/unique_name.g.vcf.gz \. --num_shards 48. ```. Is there a way that each stage of the pipeline with discreet resource requests so that the bits that can be cleanly parallelized can go in one job submission and the stages that don't can be in separate jobs/commands, to avoid having requested and reserved resources being idle? Cheers",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/905
https://github.com/google/deepvariant/issues/905:1071,integrability,sub,submission,1071,"Is it possible to run deepvariant in discreet stages with discreet resource requests?; Hi folks,. Our users are running deepvariant on our HPC and resource requests are proving quite tricky for them as different stages of the pipeline seem to have different resource needs. This leaves execution nodes essentially idle for much of the time of the jobs' running. In the two days runtime you can see below that a user who has asked for 48 cpus doesn't use most of the cores for most of the time:. ![Image](https://github.com/user-attachments/assets/c631a80d-a7b3-435a-ac50-97a1743f7638). ```. singularity run deepvariant_1.6.1.sif /opt/deepvariant/bin/run_deepvariant \. --model_type ONT_R104 \. --ref /path/to/their/reference.fasta \. --reads /path/to/their/input.bam \. --sample_name unique_name \. --output_vcf /path/to/their/unique_name.vcf.gz \. --output_gvcf /path/to/their/unique_name.g.vcf.gz \. --num_shards 48. ```. Is there a way that each stage of the pipeline with discreet resource requests so that the bits that can be cleanly parallelized can go in one job submission and the stages that don't can be in separate jobs/commands, to avoid having requested and reserved resources being idle? Cheers",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/905
https://github.com/google/deepvariant/issues/905:314,interoperability,idl,idle,314,"Is it possible to run deepvariant in discreet stages with discreet resource requests?; Hi folks,. Our users are running deepvariant on our HPC and resource requests are proving quite tricky for them as different stages of the pipeline seem to have different resource needs. This leaves execution nodes essentially idle for much of the time of the jobs' running. In the two days runtime you can see below that a user who has asked for 48 cpus doesn't use most of the cores for most of the time:. ![Image](https://github.com/user-attachments/assets/c631a80d-a7b3-435a-ac50-97a1743f7638). ```. singularity run deepvariant_1.6.1.sif /opt/deepvariant/bin/run_deepvariant \. --model_type ONT_R104 \. --ref /path/to/their/reference.fasta \. --reads /path/to/their/input.bam \. --sample_name unique_name \. --output_vcf /path/to/their/unique_name.vcf.gz \. --output_gvcf /path/to/their/unique_name.g.vcf.gz \. --num_shards 48. ```. Is there a way that each stage of the pipeline with discreet resource requests so that the bits that can be cleanly parallelized can go in one job submission and the stages that don't can be in separate jobs/commands, to avoid having requested and reserved resources being idle? Cheers",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/905
https://github.com/google/deepvariant/issues/905:1197,interoperability,idl,idle,1197,"Is it possible to run deepvariant in discreet stages with discreet resource requests?; Hi folks,. Our users are running deepvariant on our HPC and resource requests are proving quite tricky for them as different stages of the pipeline seem to have different resource needs. This leaves execution nodes essentially idle for much of the time of the jobs' running. In the two days runtime you can see below that a user who has asked for 48 cpus doesn't use most of the cores for most of the time:. ![Image](https://github.com/user-attachments/assets/c631a80d-a7b3-435a-ac50-97a1743f7638). ```. singularity run deepvariant_1.6.1.sif /opt/deepvariant/bin/run_deepvariant \. --model_type ONT_R104 \. --ref /path/to/their/reference.fasta \. --reads /path/to/their/input.bam \. --sample_name unique_name \. --output_vcf /path/to/their/unique_name.vcf.gz \. --output_gvcf /path/to/their/unique_name.g.vcf.gz \. --num_shards 48. ```. Is there a way that each stage of the pipeline with discreet resource requests so that the bits that can be cleanly parallelized can go in one job submission and the stages that don't can be in separate jobs/commands, to avoid having requested and reserved resources being idle? Cheers",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/905
https://github.com/google/deepvariant/issues/905:67,performance,resourc,resource,67,"Is it possible to run deepvariant in discreet stages with discreet resource requests?; Hi folks,. Our users are running deepvariant on our HPC and resource requests are proving quite tricky for them as different stages of the pipeline seem to have different resource needs. This leaves execution nodes essentially idle for much of the time of the jobs' running. In the two days runtime you can see below that a user who has asked for 48 cpus doesn't use most of the cores for most of the time:. ![Image](https://github.com/user-attachments/assets/c631a80d-a7b3-435a-ac50-97a1743f7638). ```. singularity run deepvariant_1.6.1.sif /opt/deepvariant/bin/run_deepvariant \. --model_type ONT_R104 \. --ref /path/to/their/reference.fasta \. --reads /path/to/their/input.bam \. --sample_name unique_name \. --output_vcf /path/to/their/unique_name.vcf.gz \. --output_gvcf /path/to/their/unique_name.g.vcf.gz \. --num_shards 48. ```. Is there a way that each stage of the pipeline with discreet resource requests so that the bits that can be cleanly parallelized can go in one job submission and the stages that don't can be in separate jobs/commands, to avoid having requested and reserved resources being idle? Cheers",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/905
https://github.com/google/deepvariant/issues/905:147,performance,resourc,resource,147,"Is it possible to run deepvariant in discreet stages with discreet resource requests?; Hi folks,. Our users are running deepvariant on our HPC and resource requests are proving quite tricky for them as different stages of the pipeline seem to have different resource needs. This leaves execution nodes essentially idle for much of the time of the jobs' running. In the two days runtime you can see below that a user who has asked for 48 cpus doesn't use most of the cores for most of the time:. ![Image](https://github.com/user-attachments/assets/c631a80d-a7b3-435a-ac50-97a1743f7638). ```. singularity run deepvariant_1.6.1.sif /opt/deepvariant/bin/run_deepvariant \. --model_type ONT_R104 \. --ref /path/to/their/reference.fasta \. --reads /path/to/their/input.bam \. --sample_name unique_name \. --output_vcf /path/to/their/unique_name.vcf.gz \. --output_gvcf /path/to/their/unique_name.g.vcf.gz \. --num_shards 48. ```. Is there a way that each stage of the pipeline with discreet resource requests so that the bits that can be cleanly parallelized can go in one job submission and the stages that don't can be in separate jobs/commands, to avoid having requested and reserved resources being idle? Cheers",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/905
https://github.com/google/deepvariant/issues/905:258,performance,resourc,resource,258,"Is it possible to run deepvariant in discreet stages with discreet resource requests?; Hi folks,. Our users are running deepvariant on our HPC and resource requests are proving quite tricky for them as different stages of the pipeline seem to have different resource needs. This leaves execution nodes essentially idle for much of the time of the jobs' running. In the two days runtime you can see below that a user who has asked for 48 cpus doesn't use most of the cores for most of the time:. ![Image](https://github.com/user-attachments/assets/c631a80d-a7b3-435a-ac50-97a1743f7638). ```. singularity run deepvariant_1.6.1.sif /opt/deepvariant/bin/run_deepvariant \. --model_type ONT_R104 \. --ref /path/to/their/reference.fasta \. --reads /path/to/their/input.bam \. --sample_name unique_name \. --output_vcf /path/to/their/unique_name.vcf.gz \. --output_gvcf /path/to/their/unique_name.g.vcf.gz \. --num_shards 48. ```. Is there a way that each stage of the pipeline with discreet resource requests so that the bits that can be cleanly parallelized can go in one job submission and the stages that don't can be in separate jobs/commands, to avoid having requested and reserved resources being idle? Cheers",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/905
https://github.com/google/deepvariant/issues/905:335,performance,time,time,335,"Is it possible to run deepvariant in discreet stages with discreet resource requests?; Hi folks,. Our users are running deepvariant on our HPC and resource requests are proving quite tricky for them as different stages of the pipeline seem to have different resource needs. This leaves execution nodes essentially idle for much of the time of the jobs' running. In the two days runtime you can see below that a user who has asked for 48 cpus doesn't use most of the cores for most of the time:. ![Image](https://github.com/user-attachments/assets/c631a80d-a7b3-435a-ac50-97a1743f7638). ```. singularity run deepvariant_1.6.1.sif /opt/deepvariant/bin/run_deepvariant \. --model_type ONT_R104 \. --ref /path/to/their/reference.fasta \. --reads /path/to/their/input.bam \. --sample_name unique_name \. --output_vcf /path/to/their/unique_name.vcf.gz \. --output_gvcf /path/to/their/unique_name.g.vcf.gz \. --num_shards 48. ```. Is there a way that each stage of the pipeline with discreet resource requests so that the bits that can be cleanly parallelized can go in one job submission and the stages that don't can be in separate jobs/commands, to avoid having requested and reserved resources being idle? Cheers",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/905
https://github.com/google/deepvariant/issues/905:437,performance,cpu,cpus,437,"Is it possible to run deepvariant in discreet stages with discreet resource requests?; Hi folks,. Our users are running deepvariant on our HPC and resource requests are proving quite tricky for them as different stages of the pipeline seem to have different resource needs. This leaves execution nodes essentially idle for much of the time of the jobs' running. In the two days runtime you can see below that a user who has asked for 48 cpus doesn't use most of the cores for most of the time:. ![Image](https://github.com/user-attachments/assets/c631a80d-a7b3-435a-ac50-97a1743f7638). ```. singularity run deepvariant_1.6.1.sif /opt/deepvariant/bin/run_deepvariant \. --model_type ONT_R104 \. --ref /path/to/their/reference.fasta \. --reads /path/to/their/input.bam \. --sample_name unique_name \. --output_vcf /path/to/their/unique_name.vcf.gz \. --output_gvcf /path/to/their/unique_name.g.vcf.gz \. --num_shards 48. ```. Is there a way that each stage of the pipeline with discreet resource requests so that the bits that can be cleanly parallelized can go in one job submission and the stages that don't can be in separate jobs/commands, to avoid having requested and reserved resources being idle? Cheers",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/905
https://github.com/google/deepvariant/issues/905:488,performance,time,time,488,"Is it possible to run deepvariant in discreet stages with discreet resource requests?; Hi folks,. Our users are running deepvariant on our HPC and resource requests are proving quite tricky for them as different stages of the pipeline seem to have different resource needs. This leaves execution nodes essentially idle for much of the time of the jobs' running. In the two days runtime you can see below that a user who has asked for 48 cpus doesn't use most of the cores for most of the time:. ![Image](https://github.com/user-attachments/assets/c631a80d-a7b3-435a-ac50-97a1743f7638). ```. singularity run deepvariant_1.6.1.sif /opt/deepvariant/bin/run_deepvariant \. --model_type ONT_R104 \. --ref /path/to/their/reference.fasta \. --reads /path/to/their/input.bam \. --sample_name unique_name \. --output_vcf /path/to/their/unique_name.vcf.gz \. --output_gvcf /path/to/their/unique_name.g.vcf.gz \. --num_shards 48. ```. Is there a way that each stage of the pipeline with discreet resource requests so that the bits that can be cleanly parallelized can go in one job submission and the stages that don't can be in separate jobs/commands, to avoid having requested and reserved resources being idle? Cheers",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/905
https://github.com/google/deepvariant/issues/905:985,performance,resourc,resource,985,"Is it possible to run deepvariant in discreet stages with discreet resource requests?; Hi folks,. Our users are running deepvariant on our HPC and resource requests are proving quite tricky for them as different stages of the pipeline seem to have different resource needs. This leaves execution nodes essentially idle for much of the time of the jobs' running. In the two days runtime you can see below that a user who has asked for 48 cpus doesn't use most of the cores for most of the time:. ![Image](https://github.com/user-attachments/assets/c631a80d-a7b3-435a-ac50-97a1743f7638). ```. singularity run deepvariant_1.6.1.sif /opt/deepvariant/bin/run_deepvariant \. --model_type ONT_R104 \. --ref /path/to/their/reference.fasta \. --reads /path/to/their/input.bam \. --sample_name unique_name \. --output_vcf /path/to/their/unique_name.vcf.gz \. --output_gvcf /path/to/their/unique_name.g.vcf.gz \. --num_shards 48. ```. Is there a way that each stage of the pipeline with discreet resource requests so that the bits that can be cleanly parallelized can go in one job submission and the stages that don't can be in separate jobs/commands, to avoid having requested and reserved resources being idle? Cheers",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/905
https://github.com/google/deepvariant/issues/905:1040,performance,parallel,parallelized,1040,"Is it possible to run deepvariant in discreet stages with discreet resource requests?; Hi folks,. Our users are running deepvariant on our HPC and resource requests are proving quite tricky for them as different stages of the pipeline seem to have different resource needs. This leaves execution nodes essentially idle for much of the time of the jobs' running. In the two days runtime you can see below that a user who has asked for 48 cpus doesn't use most of the cores for most of the time:. ![Image](https://github.com/user-attachments/assets/c631a80d-a7b3-435a-ac50-97a1743f7638). ```. singularity run deepvariant_1.6.1.sif /opt/deepvariant/bin/run_deepvariant \. --model_type ONT_R104 \. --ref /path/to/their/reference.fasta \. --reads /path/to/their/input.bam \. --sample_name unique_name \. --output_vcf /path/to/their/unique_name.vcf.gz \. --output_gvcf /path/to/their/unique_name.g.vcf.gz \. --num_shards 48. ```. Is there a way that each stage of the pipeline with discreet resource requests so that the bits that can be cleanly parallelized can go in one job submission and the stages that don't can be in separate jobs/commands, to avoid having requested and reserved resources being idle? Cheers",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/905
https://github.com/google/deepvariant/issues/905:1181,performance,resourc,resources,1181,"Is it possible to run deepvariant in discreet stages with discreet resource requests?; Hi folks,. Our users are running deepvariant on our HPC and resource requests are proving quite tricky for them as different stages of the pipeline seem to have different resource needs. This leaves execution nodes essentially idle for much of the time of the jobs' running. In the two days runtime you can see below that a user who has asked for 48 cpus doesn't use most of the cores for most of the time:. ![Image](https://github.com/user-attachments/assets/c631a80d-a7b3-435a-ac50-97a1743f7638). ```. singularity run deepvariant_1.6.1.sif /opt/deepvariant/bin/run_deepvariant \. --model_type ONT_R104 \. --ref /path/to/their/reference.fasta \. --reads /path/to/their/input.bam \. --sample_name unique_name \. --output_vcf /path/to/their/unique_name.vcf.gz \. --output_gvcf /path/to/their/unique_name.g.vcf.gz \. --num_shards 48. ```. Is there a way that each stage of the pipeline with discreet resource requests so that the bits that can be cleanly parallelized can go in one job submission and the stages that don't can be in separate jobs/commands, to avoid having requested and reserved resources being idle? Cheers",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/905
https://github.com/google/deepvariant/issues/905:442,reliability,doe,doesn,442,"Is it possible to run deepvariant in discreet stages with discreet resource requests?; Hi folks,. Our users are running deepvariant on our HPC and resource requests are proving quite tricky for them as different stages of the pipeline seem to have different resource needs. This leaves execution nodes essentially idle for much of the time of the jobs' running. In the two days runtime you can see below that a user who has asked for 48 cpus doesn't use most of the cores for most of the time:. ![Image](https://github.com/user-attachments/assets/c631a80d-a7b3-435a-ac50-97a1743f7638). ```. singularity run deepvariant_1.6.1.sif /opt/deepvariant/bin/run_deepvariant \. --model_type ONT_R104 \. --ref /path/to/their/reference.fasta \. --reads /path/to/their/input.bam \. --sample_name unique_name \. --output_vcf /path/to/their/unique_name.vcf.gz \. --output_gvcf /path/to/their/unique_name.g.vcf.gz \. --num_shards 48. ```. Is there a way that each stage of the pipeline with discreet resource requests so that the bits that can be cleanly parallelized can go in one job submission and the stages that don't can be in separate jobs/commands, to avoid having requested and reserved resources being idle? Cheers",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/905
https://github.com/google/deepvariant/issues/905:67,safety,resourc,resource,67,"Is it possible to run deepvariant in discreet stages with discreet resource requests?; Hi folks,. Our users are running deepvariant on our HPC and resource requests are proving quite tricky for them as different stages of the pipeline seem to have different resource needs. This leaves execution nodes essentially idle for much of the time of the jobs' running. In the two days runtime you can see below that a user who has asked for 48 cpus doesn't use most of the cores for most of the time:. ![Image](https://github.com/user-attachments/assets/c631a80d-a7b3-435a-ac50-97a1743f7638). ```. singularity run deepvariant_1.6.1.sif /opt/deepvariant/bin/run_deepvariant \. --model_type ONT_R104 \. --ref /path/to/their/reference.fasta \. --reads /path/to/their/input.bam \. --sample_name unique_name \. --output_vcf /path/to/their/unique_name.vcf.gz \. --output_gvcf /path/to/their/unique_name.g.vcf.gz \. --num_shards 48. ```. Is there a way that each stage of the pipeline with discreet resource requests so that the bits that can be cleanly parallelized can go in one job submission and the stages that don't can be in separate jobs/commands, to avoid having requested and reserved resources being idle? Cheers",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/905
https://github.com/google/deepvariant/issues/905:147,safety,resourc,resource,147,"Is it possible to run deepvariant in discreet stages with discreet resource requests?; Hi folks,. Our users are running deepvariant on our HPC and resource requests are proving quite tricky for them as different stages of the pipeline seem to have different resource needs. This leaves execution nodes essentially idle for much of the time of the jobs' running. In the two days runtime you can see below that a user who has asked for 48 cpus doesn't use most of the cores for most of the time:. ![Image](https://github.com/user-attachments/assets/c631a80d-a7b3-435a-ac50-97a1743f7638). ```. singularity run deepvariant_1.6.1.sif /opt/deepvariant/bin/run_deepvariant \. --model_type ONT_R104 \. --ref /path/to/their/reference.fasta \. --reads /path/to/their/input.bam \. --sample_name unique_name \. --output_vcf /path/to/their/unique_name.vcf.gz \. --output_gvcf /path/to/their/unique_name.g.vcf.gz \. --num_shards 48. ```. Is there a way that each stage of the pipeline with discreet resource requests so that the bits that can be cleanly parallelized can go in one job submission and the stages that don't can be in separate jobs/commands, to avoid having requested and reserved resources being idle? Cheers",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/905
https://github.com/google/deepvariant/issues/905:258,safety,resourc,resource,258,"Is it possible to run deepvariant in discreet stages with discreet resource requests?; Hi folks,. Our users are running deepvariant on our HPC and resource requests are proving quite tricky for them as different stages of the pipeline seem to have different resource needs. This leaves execution nodes essentially idle for much of the time of the jobs' running. In the two days runtime you can see below that a user who has asked for 48 cpus doesn't use most of the cores for most of the time:. ![Image](https://github.com/user-attachments/assets/c631a80d-a7b3-435a-ac50-97a1743f7638). ```. singularity run deepvariant_1.6.1.sif /opt/deepvariant/bin/run_deepvariant \. --model_type ONT_R104 \. --ref /path/to/their/reference.fasta \. --reads /path/to/their/input.bam \. --sample_name unique_name \. --output_vcf /path/to/their/unique_name.vcf.gz \. --output_gvcf /path/to/their/unique_name.g.vcf.gz \. --num_shards 48. ```. Is there a way that each stage of the pipeline with discreet resource requests so that the bits that can be cleanly parallelized can go in one job submission and the stages that don't can be in separate jobs/commands, to avoid having requested and reserved resources being idle? Cheers",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/905
https://github.com/google/deepvariant/issues/905:757,safety,input,input,757,"Is it possible to run deepvariant in discreet stages with discreet resource requests?; Hi folks,. Our users are running deepvariant on our HPC and resource requests are proving quite tricky for them as different stages of the pipeline seem to have different resource needs. This leaves execution nodes essentially idle for much of the time of the jobs' running. In the two days runtime you can see below that a user who has asked for 48 cpus doesn't use most of the cores for most of the time:. ![Image](https://github.com/user-attachments/assets/c631a80d-a7b3-435a-ac50-97a1743f7638). ```. singularity run deepvariant_1.6.1.sif /opt/deepvariant/bin/run_deepvariant \. --model_type ONT_R104 \. --ref /path/to/their/reference.fasta \. --reads /path/to/their/input.bam \. --sample_name unique_name \. --output_vcf /path/to/their/unique_name.vcf.gz \. --output_gvcf /path/to/their/unique_name.g.vcf.gz \. --num_shards 48. ```. Is there a way that each stage of the pipeline with discreet resource requests so that the bits that can be cleanly parallelized can go in one job submission and the stages that don't can be in separate jobs/commands, to avoid having requested and reserved resources being idle? Cheers",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/905
https://github.com/google/deepvariant/issues/905:985,safety,resourc,resource,985,"Is it possible to run deepvariant in discreet stages with discreet resource requests?; Hi folks,. Our users are running deepvariant on our HPC and resource requests are proving quite tricky for them as different stages of the pipeline seem to have different resource needs. This leaves execution nodes essentially idle for much of the time of the jobs' running. In the two days runtime you can see below that a user who has asked for 48 cpus doesn't use most of the cores for most of the time:. ![Image](https://github.com/user-attachments/assets/c631a80d-a7b3-435a-ac50-97a1743f7638). ```. singularity run deepvariant_1.6.1.sif /opt/deepvariant/bin/run_deepvariant \. --model_type ONT_R104 \. --ref /path/to/their/reference.fasta \. --reads /path/to/their/input.bam \. --sample_name unique_name \. --output_vcf /path/to/their/unique_name.vcf.gz \. --output_gvcf /path/to/their/unique_name.g.vcf.gz \. --num_shards 48. ```. Is there a way that each stage of the pipeline with discreet resource requests so that the bits that can be cleanly parallelized can go in one job submission and the stages that don't can be in separate jobs/commands, to avoid having requested and reserved resources being idle? Cheers",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/905
https://github.com/google/deepvariant/issues/905:1145,safety,avoid,avoid,1145,"Is it possible to run deepvariant in discreet stages with discreet resource requests?; Hi folks,. Our users are running deepvariant on our HPC and resource requests are proving quite tricky for them as different stages of the pipeline seem to have different resource needs. This leaves execution nodes essentially idle for much of the time of the jobs' running. In the two days runtime you can see below that a user who has asked for 48 cpus doesn't use most of the cores for most of the time:. ![Image](https://github.com/user-attachments/assets/c631a80d-a7b3-435a-ac50-97a1743f7638). ```. singularity run deepvariant_1.6.1.sif /opt/deepvariant/bin/run_deepvariant \. --model_type ONT_R104 \. --ref /path/to/their/reference.fasta \. --reads /path/to/their/input.bam \. --sample_name unique_name \. --output_vcf /path/to/their/unique_name.vcf.gz \. --output_gvcf /path/to/their/unique_name.g.vcf.gz \. --num_shards 48. ```. Is there a way that each stage of the pipeline with discreet resource requests so that the bits that can be cleanly parallelized can go in one job submission and the stages that don't can be in separate jobs/commands, to avoid having requested and reserved resources being idle? Cheers",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/905
https://github.com/google/deepvariant/issues/905:1181,safety,resourc,resources,1181,"Is it possible to run deepvariant in discreet stages with discreet resource requests?; Hi folks,. Our users are running deepvariant on our HPC and resource requests are proving quite tricky for them as different stages of the pipeline seem to have different resource needs. This leaves execution nodes essentially idle for much of the time of the jobs' running. In the two days runtime you can see below that a user who has asked for 48 cpus doesn't use most of the cores for most of the time:. ![Image](https://github.com/user-attachments/assets/c631a80d-a7b3-435a-ac50-97a1743f7638). ```. singularity run deepvariant_1.6.1.sif /opt/deepvariant/bin/run_deepvariant \. --model_type ONT_R104 \. --ref /path/to/their/reference.fasta \. --reads /path/to/their/input.bam \. --sample_name unique_name \. --output_vcf /path/to/their/unique_name.vcf.gz \. --output_gvcf /path/to/their/unique_name.g.vcf.gz \. --num_shards 48. ```. Is there a way that each stage of the pipeline with discreet resource requests so that the bits that can be cleanly parallelized can go in one job submission and the stages that don't can be in separate jobs/commands, to avoid having requested and reserved resources being idle? Cheers",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/905
https://github.com/google/deepvariant/issues/905:67,testability,resourc,resource,67,"Is it possible to run deepvariant in discreet stages with discreet resource requests?; Hi folks,. Our users are running deepvariant on our HPC and resource requests are proving quite tricky for them as different stages of the pipeline seem to have different resource needs. This leaves execution nodes essentially idle for much of the time of the jobs' running. In the two days runtime you can see below that a user who has asked for 48 cpus doesn't use most of the cores for most of the time:. ![Image](https://github.com/user-attachments/assets/c631a80d-a7b3-435a-ac50-97a1743f7638). ```. singularity run deepvariant_1.6.1.sif /opt/deepvariant/bin/run_deepvariant \. --model_type ONT_R104 \. --ref /path/to/their/reference.fasta \. --reads /path/to/their/input.bam \. --sample_name unique_name \. --output_vcf /path/to/their/unique_name.vcf.gz \. --output_gvcf /path/to/their/unique_name.g.vcf.gz \. --num_shards 48. ```. Is there a way that each stage of the pipeline with discreet resource requests so that the bits that can be cleanly parallelized can go in one job submission and the stages that don't can be in separate jobs/commands, to avoid having requested and reserved resources being idle? Cheers",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/905
https://github.com/google/deepvariant/issues/905:147,testability,resourc,resource,147,"Is it possible to run deepvariant in discreet stages with discreet resource requests?; Hi folks,. Our users are running deepvariant on our HPC and resource requests are proving quite tricky for them as different stages of the pipeline seem to have different resource needs. This leaves execution nodes essentially idle for much of the time of the jobs' running. In the two days runtime you can see below that a user who has asked for 48 cpus doesn't use most of the cores for most of the time:. ![Image](https://github.com/user-attachments/assets/c631a80d-a7b3-435a-ac50-97a1743f7638). ```. singularity run deepvariant_1.6.1.sif /opt/deepvariant/bin/run_deepvariant \. --model_type ONT_R104 \. --ref /path/to/their/reference.fasta \. --reads /path/to/their/input.bam \. --sample_name unique_name \. --output_vcf /path/to/their/unique_name.vcf.gz \. --output_gvcf /path/to/their/unique_name.g.vcf.gz \. --num_shards 48. ```. Is there a way that each stage of the pipeline with discreet resource requests so that the bits that can be cleanly parallelized can go in one job submission and the stages that don't can be in separate jobs/commands, to avoid having requested and reserved resources being idle? Cheers",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/905
https://github.com/google/deepvariant/issues/905:258,testability,resourc,resource,258,"Is it possible to run deepvariant in discreet stages with discreet resource requests?; Hi folks,. Our users are running deepvariant on our HPC and resource requests are proving quite tricky for them as different stages of the pipeline seem to have different resource needs. This leaves execution nodes essentially idle for much of the time of the jobs' running. In the two days runtime you can see below that a user who has asked for 48 cpus doesn't use most of the cores for most of the time:. ![Image](https://github.com/user-attachments/assets/c631a80d-a7b3-435a-ac50-97a1743f7638). ```. singularity run deepvariant_1.6.1.sif /opt/deepvariant/bin/run_deepvariant \. --model_type ONT_R104 \. --ref /path/to/their/reference.fasta \. --reads /path/to/their/input.bam \. --sample_name unique_name \. --output_vcf /path/to/their/unique_name.vcf.gz \. --output_gvcf /path/to/their/unique_name.g.vcf.gz \. --num_shards 48. ```. Is there a way that each stage of the pipeline with discreet resource requests so that the bits that can be cleanly parallelized can go in one job submission and the stages that don't can be in separate jobs/commands, to avoid having requested and reserved resources being idle? Cheers",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/905
https://github.com/google/deepvariant/issues/905:985,testability,resourc,resource,985,"Is it possible to run deepvariant in discreet stages with discreet resource requests?; Hi folks,. Our users are running deepvariant on our HPC and resource requests are proving quite tricky for them as different stages of the pipeline seem to have different resource needs. This leaves execution nodes essentially idle for much of the time of the jobs' running. In the two days runtime you can see below that a user who has asked for 48 cpus doesn't use most of the cores for most of the time:. ![Image](https://github.com/user-attachments/assets/c631a80d-a7b3-435a-ac50-97a1743f7638). ```. singularity run deepvariant_1.6.1.sif /opt/deepvariant/bin/run_deepvariant \. --model_type ONT_R104 \. --ref /path/to/their/reference.fasta \. --reads /path/to/their/input.bam \. --sample_name unique_name \. --output_vcf /path/to/their/unique_name.vcf.gz \. --output_gvcf /path/to/their/unique_name.g.vcf.gz \. --num_shards 48. ```. Is there a way that each stage of the pipeline with discreet resource requests so that the bits that can be cleanly parallelized can go in one job submission and the stages that don't can be in separate jobs/commands, to avoid having requested and reserved resources being idle? Cheers",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/905
https://github.com/google/deepvariant/issues/905:1181,testability,resourc,resources,1181,"Is it possible to run deepvariant in discreet stages with discreet resource requests?; Hi folks,. Our users are running deepvariant on our HPC and resource requests are proving quite tricky for them as different stages of the pipeline seem to have different resource needs. This leaves execution nodes essentially idle for much of the time of the jobs' running. In the two days runtime you can see below that a user who has asked for 48 cpus doesn't use most of the cores for most of the time:. ![Image](https://github.com/user-attachments/assets/c631a80d-a7b3-435a-ac50-97a1743f7638). ```. singularity run deepvariant_1.6.1.sif /opt/deepvariant/bin/run_deepvariant \. --model_type ONT_R104 \. --ref /path/to/their/reference.fasta \. --reads /path/to/their/input.bam \. --sample_name unique_name \. --output_vcf /path/to/their/unique_name.vcf.gz \. --output_gvcf /path/to/their/unique_name.g.vcf.gz \. --num_shards 48. ```. Is there a way that each stage of the pipeline with discreet resource requests so that the bits that can be cleanly parallelized can go in one job submission and the stages that don't can be in separate jobs/commands, to avoid having requested and reserved resources being idle? Cheers",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/905
https://github.com/google/deepvariant/issues/905:102,usability,user,users,102,"Is it possible to run deepvariant in discreet stages with discreet resource requests?; Hi folks,. Our users are running deepvariant on our HPC and resource requests are proving quite tricky for them as different stages of the pipeline seem to have different resource needs. This leaves execution nodes essentially idle for much of the time of the jobs' running. In the two days runtime you can see below that a user who has asked for 48 cpus doesn't use most of the cores for most of the time:. ![Image](https://github.com/user-attachments/assets/c631a80d-a7b3-435a-ac50-97a1743f7638). ```. singularity run deepvariant_1.6.1.sif /opt/deepvariant/bin/run_deepvariant \. --model_type ONT_R104 \. --ref /path/to/their/reference.fasta \. --reads /path/to/their/input.bam \. --sample_name unique_name \. --output_vcf /path/to/their/unique_name.vcf.gz \. --output_gvcf /path/to/their/unique_name.g.vcf.gz \. --num_shards 48. ```. Is there a way that each stage of the pipeline with discreet resource requests so that the bits that can be cleanly parallelized can go in one job submission and the stages that don't can be in separate jobs/commands, to avoid having requested and reserved resources being idle? Cheers",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/905
https://github.com/google/deepvariant/issues/905:411,usability,user,user,411,"Is it possible to run deepvariant in discreet stages with discreet resource requests?; Hi folks,. Our users are running deepvariant on our HPC and resource requests are proving quite tricky for them as different stages of the pipeline seem to have different resource needs. This leaves execution nodes essentially idle for much of the time of the jobs' running. In the two days runtime you can see below that a user who has asked for 48 cpus doesn't use most of the cores for most of the time:. ![Image](https://github.com/user-attachments/assets/c631a80d-a7b3-435a-ac50-97a1743f7638). ```. singularity run deepvariant_1.6.1.sif /opt/deepvariant/bin/run_deepvariant \. --model_type ONT_R104 \. --ref /path/to/their/reference.fasta \. --reads /path/to/their/input.bam \. --sample_name unique_name \. --output_vcf /path/to/their/unique_name.vcf.gz \. --output_gvcf /path/to/their/unique_name.g.vcf.gz \. --num_shards 48. ```. Is there a way that each stage of the pipeline with discreet resource requests so that the bits that can be cleanly parallelized can go in one job submission and the stages that don't can be in separate jobs/commands, to avoid having requested and reserved resources being idle? Cheers",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/905
https://github.com/google/deepvariant/issues/905:523,usability,user,user-attachments,523,"Is it possible to run deepvariant in discreet stages with discreet resource requests?; Hi folks,. Our users are running deepvariant on our HPC and resource requests are proving quite tricky for them as different stages of the pipeline seem to have different resource needs. This leaves execution nodes essentially idle for much of the time of the jobs' running. In the two days runtime you can see below that a user who has asked for 48 cpus doesn't use most of the cores for most of the time:. ![Image](https://github.com/user-attachments/assets/c631a80d-a7b3-435a-ac50-97a1743f7638). ```. singularity run deepvariant_1.6.1.sif /opt/deepvariant/bin/run_deepvariant \. --model_type ONT_R104 \. --ref /path/to/their/reference.fasta \. --reads /path/to/their/input.bam \. --sample_name unique_name \. --output_vcf /path/to/their/unique_name.vcf.gz \. --output_gvcf /path/to/their/unique_name.g.vcf.gz \. --num_shards 48. ```. Is there a way that each stage of the pipeline with discreet resource requests so that the bits that can be cleanly parallelized can go in one job submission and the stages that don't can be in separate jobs/commands, to avoid having requested and reserved resources being idle? Cheers",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/905
https://github.com/google/deepvariant/issues/905:757,usability,input,input,757,"Is it possible to run deepvariant in discreet stages with discreet resource requests?; Hi folks,. Our users are running deepvariant on our HPC and resource requests are proving quite tricky for them as different stages of the pipeline seem to have different resource needs. This leaves execution nodes essentially idle for much of the time of the jobs' running. In the two days runtime you can see below that a user who has asked for 48 cpus doesn't use most of the cores for most of the time:. ![Image](https://github.com/user-attachments/assets/c631a80d-a7b3-435a-ac50-97a1743f7638). ```. singularity run deepvariant_1.6.1.sif /opt/deepvariant/bin/run_deepvariant \. --model_type ONT_R104 \. --ref /path/to/their/reference.fasta \. --reads /path/to/their/input.bam \. --sample_name unique_name \. --output_vcf /path/to/their/unique_name.vcf.gz \. --output_gvcf /path/to/their/unique_name.g.vcf.gz \. --num_shards 48. ```. Is there a way that each stage of the pipeline with discreet resource requests so that the bits that can be cleanly parallelized can go in one job submission and the stages that don't can be in separate jobs/commands, to avoid having requested and reserved resources being idle? Cheers",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/905
https://github.com/google/deepvariant/issues/905:1132,usability,command,commands,1132,"Is it possible to run deepvariant in discreet stages with discreet resource requests?; Hi folks,. Our users are running deepvariant on our HPC and resource requests are proving quite tricky for them as different stages of the pipeline seem to have different resource needs. This leaves execution nodes essentially idle for much of the time of the jobs' running. In the two days runtime you can see below that a user who has asked for 48 cpus doesn't use most of the cores for most of the time:. ![Image](https://github.com/user-attachments/assets/c631a80d-a7b3-435a-ac50-97a1743f7638). ```. singularity run deepvariant_1.6.1.sif /opt/deepvariant/bin/run_deepvariant \. --model_type ONT_R104 \. --ref /path/to/their/reference.fasta \. --reads /path/to/their/input.bam \. --sample_name unique_name \. --output_vcf /path/to/their/unique_name.vcf.gz \. --output_gvcf /path/to/their/unique_name.g.vcf.gz \. --num_shards 48. ```. Is there a way that each stage of the pipeline with discreet resource requests so that the bits that can be cleanly parallelized can go in one job submission and the stages that don't can be in separate jobs/commands, to avoid having requested and reserved resources being idle? Cheers",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/905
